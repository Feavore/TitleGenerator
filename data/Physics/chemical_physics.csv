URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10239v1,Linear response pCCD-based methods: LR-pCCD and LR-pCCD+S approaches for the efficient and reliable modelling of excited state properties,"Abstract: In this work, we derive working equations for the Linear Response pair Coupled Cluster Doubles (LR-pCCD) ansatz and its extension to singles (S), LR-pCCD+S. These methods allow us to compute electronic excitation energies and transition dipole moments based on a pCCD reference function. We benchmark the LR-pCCD+S model against the linear response coupled-cluster singles and doubles method for modeling electronic spectra (excitation energies and transition dipole moments) of the BH, \ceH2O, \ceH2CO, and furan molecules. We also analyze the effect of orbital optimization within pCCD on the resulting LR-pCCD+S transition dipole moments and oscillator strengths and perform a statistical error analysis. We show that the LR-pCCD+S method can correctly reproduce the transition dipole moments features, thus representing a reliable and cost-effective alternative to standard, more expensive electronic structure methods for modeling electronic spectra of simple molecules. Specifically, the proposed models require only mean-field-like computational cost, while excited-state properties may approach the CCSD level of accuracy. Moreover, we demonstrate the capability of our model to simulate electronic transitions with non-negligible contributions of double excitations and the electronic spectra of polyenes of various chain lengths, for which standard electronic structure methods perform purely.","Electronic spectroscopy plays a pivotal role in various scientific disciplines, from chemistry to physics, biology, and astronomy. Electronic spectra provide a fingerprint of an investigated system. They are crucial for understanding the behavior of electrons in atoms and molecules and the design of new complexes and materials. Experimentally, the electronic spectrum is recorded via absorption or emission processes. The emission spectrum is generated when electrons transition from higher to lower energy levels, emitting photons. The absorption spectrum is produced by electrons absorbing photons to move from lower to higher energy levels. An absorption spectrum is essentially the reverse of an emission spectrum, both provide characteristic molecular features. Baker, Brundle, and Thompson (1972); Harris and Bertolucci (1989) In recent years, quantum chemistry has become increasingly essential in predicting and interpreting atomic and molecular electronic spectra. Bartlett (1989); Dreuw and Head-Gordon (2005) Two main families of quantum chemistry methods emerged: density functional theory approximations (DFAs) and wave function theory (WFT) based methods. While DFAs are generally more cost-effective, it is well-accepted that WFT provides more reliable results. Specifically, the quality of DFAs’ electronic spectra strongly depends on the applied approximation to the exchange–correlation functional. Several classes of approximate exchange–correlation functionals have been developed so far, ranging from the simplest local and semi-local, to hybrid, meta-hybrid, and double-hybrid, to more complex range-separated exchange–correlation functionals. Becke (2014) While some of the approximations to the exchange–correlation functional provide reliable results for molecular structures, others perform well in predicting electronic excitation energies. Barbatti, Aquino, and Lischka (2010); Tecmer et al. (2013) However, none of them is universal. Particularly challenging for DFAs are so-called multi-reference systems with a significant amount of strong electron correlation. Such strongly-correlated electrons can be encountered, for instance, when stretching multiple bonds or in extended \pi-systems. In WFT, the exact solution to the electronic Schrödinger equation (in a given basis) can be obtained from the full configuration interaction (FCI) approach. Unfortunately, such calculations are computationally feasible only for some small model systems, comprising usually less than 20 electrons and/or orbitals, as the number of degrees of freedom scales binomially with system size. That technical deficiency led to the development of approximate WFT-based methods (including the hybrid WFT/DFA methods Fromager, Knecht, and Jensen (2013)), among which the coupled cluster (CC) theory Bartlett and Musiał (2007) emerged as the most promising one. Conventional CC theory, like the coupled cluster singles and doubles (CCSD) and CCSD with perturbative triples (CCSD(T) Raghavachari et al. (1989)), can be used to accurately model large molecular systems whose electronic structures are well-represented by a single Slater determinant, that is, dominated by dynamic electron correlation effects. The pair Coupled-Cluster Doubles Limacher et al. (2013); Stein, Henderson, and Scuseria (2014) (pCCD) model represents a cost-effective alternative for reliable description of strongly correlated systems. Tecmer and Boguslawski (2022) Combined with an efficient orbital optimization protocol, Boguslawski et al. (2014a); Limacher et al. (2014a); Boguslawski et al. (2014b, c) and dynamic energy correction Limacher et al. (2014b); Boguslawski and Ayers (2015); Boguslawski and Tecmer (2017); Nowak and Boguslawski (2023); Garza et al. (2015); Leszczyk et al. (2022) pCCD-based approaches represent a versatile tool for large-scale modeling of complex systems. Boguslawski et al. (2021); Tecmer et al. (2023); Gałyńska et al. (2024); Kriebel et al. (2024) Employing the equation of motion (EOM) formalism Rowe (1968); Stanton and Bartlett (1993); Bartlett (2012) on top of a pCCD reference function allows us to obtain a large number of electronically excited states in one single calculation. Boguslawski (2016, 2017, 2019) The resulting excitation energies are size-intensive. An advantage of EOM-pCCD-based methods over the standard EOM-CC approaches is the low computational cost and the ability to model electronically excited states of large \pi-conjugated systems Jahani, Boguslawski, and Tecmer (2023), where the electron pair excitation energies can play a significant role. Boguslawski (2016, 2019) Unfortunately, the computation of oscillator strengths from EOM-CC methods, including the pCCD-based variants, requires the determination of both the right (as for excitation energies) and left eigenvectors of the EOM-CC equations, which essentially doubles the cost of excited-state calculations compared to the calculations of excitation energies only. Stanton and Bartlett (1993) Alternatively, the electronic spectra can be obtained from the linear response (LR) formulation of CC theory (LR-CC). Sekino and Bartlett (1984); Koch and Jørgensen (1990); Koch et al. (1990a); Christiansen, Jørgensen, and Hättig (1998) In that case, the excitation energies remain identical with EOM-CC, Watts (2008); Christiansen, Jørgensen, and Hättig (1998) the computation of transition dipole moments still requires left and right eigenvectors, but the resulting transition dipole moments are size-intensive. Koch et al. (1994); Christiansen, Jørgensen, and Hättig (1998) The standard CCSD-based excitation energies can be further corrected for triple excitations using iterativeHald et al. (2001) and non-iterative techniques Christiansen, Koch, and Jørgensen (1996); Christiansen et al. (1996). The exceptional performance of EOM-pCCD-based methods for modeling electronic excitation energies of complex systems Boguslawski (2016, 2019); Nowak, Tecmer, and Boguslawski (2019) and the advantages of the LR-CC formalism motivate us to develop the LR-CC models based on a pCCD reference function (with and without orbital optimization). In this work, we provide working equations for the LR-pCCD and LR-pCCD+S (LR-pCCD with the inclusion of singly excited states) models. Our focus is on excited state properties, not excitation energies, which have been assessed before. Boguslawski (2016, 2019); Nowak, Tecmer, and Boguslawski (2019) We benchmark the LR-pCCD+S transition dipole moments (TDM) and oscillator strengths (OS) against the LR-CCSD and EOM-CCSD results for small model systems and various basis set sizes. Finally, we show the ability of LR-pCCD+S to model electronic spectra of all trans-polyenes of different chain lengths."
https://arxiv.org/html/2411.10122v1,"Self-learning path integral hybrid Monte Carlo with mixed 
and machine learning potentials for modeling nuclear quantum effects in water","The introduction of machine learned potentials (MLPs) has greatly expanded the space available for studying Nuclear Quantum Effects computationally with ab initio path integral (PI) accuracy, with the MLPs’ promise of an accuracy comparable to that of ab initio at a fraction of the cost. One of the challenges in development of MLPs is the need for a large and diverse training set calculated by ab initio methods. This data set should ideally cover the entire phase space, while not searching this space using ab initio methods, as this would be counterproductive and generally intractable with respect to computational time. In this paper, we present the self-learning PI hybrid Monte Carlo Method using a mixed ab initio and ML potential (SL-PIHMC-MIX), where the mixed potential allows for the study of larger systems and the extension of the original SL-HMC method [Nagai et al., Phys. Rev. B 102, 041124 (2020)] to PI methods and larger systems. While the MLPs generated by this method can be directly applied to run long-time ML-PIMD simulations, we demonstrate that using PIHMC-MIX with the trained MLPs allows for an exact reproduction of the structure obtained from ab initio PIMD. Specifically, we find that the PIHMC-MIX simulations require only 5,000 evaluations of the 32-bead structure, compared to the 100,000 evaluations needed for the ab initio PIMD result.","Nuclear Quantum Effects (NQEs) play a large role in determining the properties of matter containing light atoms and, by extension, the isotope effects seen when hydrogen (H) is exchanged for deuterium (D) or tritium (T). One example of this is the observed differences between light (H2O) and heavy (D2O) water,Ceriotti et al. (2016) which has recently been investigated by a series of experiments. Zeidler et al. (2011, 2012); Soper (2013); Kameda et al. (2018) We have also previously reported some structural and reactive differences between the two liquids and other isotopologues of water Thomsen and Shiga (2021a, 2022) from ab initio or first principles (FP) simulations. Modeling of NQEs in bulk systems relies on path integral (PI) methods based on the Feynman path formulation of quantum mechanics. Feynman (1972); Feynman, Hibbs, and Styer (2010); Schulman (2012) Implementations of these methodsShiga (2018); Kapil et al. (2019) typically require the simultaneous evaluation of energies and gradients of P copies of the system in each time step. P is generally considered in tens or low hundreds for simulations at room temperature and, thus, adds significantly to the cost of performing FP simulations required for the accurate description of NQEs in materials. In the 1990s, methods were suggested for generating machine learned potentials (MLPs),Blank et al. (1995); Brown, Gibbs, and Clary (1996); Lorenz, Groß, and Scheffler (2004) with accuracy close to those of FP calculations but at a much-reduced computational cost. However, MLPs were initially limited to the study of small gas phase clusters. It was only with the introduction of high-dimensional neural network potentials Behler and Parrinello (2007); Behler (2014, 2015, 2017) by Behler and Parrinello that the MLPs were extended to the study of bulk-phase systems. The development of these MLPs is continuing, with later generations including more physics informed terms, such as machine learned atomic chargesArtrith, Morawietz, and Behler (2011); Morawietz, Sharma, and Behler (2012) and global charge equilibration,Behler (2021) for the accurate description of charge separation. From the first MLPs used for the simulation of liquid water, Morawietz et al. (2016) the study of bulk phase water using MLPs has undergone a rapid development,Omranpour et al. (2024) with the low cost of evaluation of the MLP allowing for the molecular dynamics (MD) simulations of very large systems both withKrishnamoorthy et al. (2021) and without Lu et al. (2021) NQEs. Generally, fewer FP calculations are needed when training an MLP, and one can thus explore more expensive FP methods for describing the electronic potential in water simulations. MB-PolBabin, Leforestier, and Paesani (2013); Babin, Medders, and Paesani (2014); Medders, Babin, and Paesani (2014) presents one physics based model for water, which has recentlyMedders et al. (2015); Zhu et al. (2023) been adjusted to fit CCSD(T), i.e., the gold standard of quantum chemistry, data for the interaction potentials in water. This model along with other recent fitted MLPs based on FP data from CCSD(T)Yu et al. (2022); Daru et al. (2022); Chen et al. (2023) have been shown to accurately reproduce both equilibrium and dynamic properties of water when NQEs are considered. The investigation of NQEs has also been undertaken by a number of studies due to the reduced cost of PI simulations when an MLP is employed,Cheng, Behler, and Ceriotti (2016); Kapil, Behler, and Ceriotti (2016); Kapil et al. (2020); Yao and Kanai (2020); Li, Paesani, and Voth (2022); Yao and Kanai (2021) including comparisons of isotopologues of water Ko et al. (2019); Xu et al. (2020) and the effect of NQEs on the behavior of the hydroxide and hydronium ionsAtsango et al. (2023) in the liquid phase. Shared by all MLP models is the need for a training set made up of FP data, which should ideally cover the entire phase space while not stemming from an exhaustive search using FP methods. To efficiently carry out the search, one can use on-the-fly learning Li, Kermode, and De Vita (2015); Jinnouchi et al. (2019); Cheng et al. (2020); Young et al. (2021); Montero de Hijes et al. (2024) to train a cheap potential representation, which can be used to accelerate the search. Several of the authors recently suggested the self-learning hybrid Monte Carlo (SL-HMC) method Nagai et al. (2020); Kobayashi et al. (2021) based on the hybrid Monte Carlo (HMC) method. Gottlieb et al. (1987); Duane et al. (1987); Mehlig, Heermann, and Forrest (1992); Tuckerman et al. (1993); Shinoda, Shiga, and Mikami (2004); Nakayama, Taketsugu, and Shiga (2009) In the SL-HMC method, a short ML-MD simulation is run between each HMC step to allow efficient sampling of phase space while training an MLP for the system being studied. Extension of this method to larger systems and the PI domain is, however, hindered by the limitations of HMC as the acceptance ratio scales inversely with the size of the system. Here, we introduce the self-learning path integral hybrid Monte Carlo method using a mixed FP and ML potential (SL-PIHMC-MIX) to overcome this limitation. In brief, this method allows for larger discrepancies between the FP and ML potential energies through the potential mixing, thus enabling larger acceptance ratios and faster sampling of the phase space of the mixed potential Hamiltonian. Thus, reweightingMiao et al. (2014) and longer trajectories are necessary to sample the phase space of the FP Hamiltonian. The savings enabled by the larger acceptance rate of the potential mixing scheme are, however, great enough that the effective length of the trajectory using potential mixing exceeds those using the pure FP potentials. The SL-PIHMC-MIX method is furthermore, as the SL-HMC method, fully general with respect to the FP model used and the MLP model used. In this study, we will use SL-PIHMC-MIX to train an MLP to model room temperature water. After training the MLP, it will be used in a production run using the PIHMC-MIX method, which allows us to rapidly converge the radial distribution functions (RDFs) and, thus, predict the structure of water using only 5000 FP calculations along the bead chain, compared to the 100 000 calculations needed in our previous FP-PIMD studiesThomsen and Shiga (2021a, 2022) to converge the water RDFs. The structure of water has long been a topic of discussion,Finney (2024) and FP based studies of water using density functional theory (DFT) have since the first report,Chen et al. (2003) and until the emergence of coupled cluster based MLPs, been the state of the art for studying water, with several studies comparing the accuracy of functionals for this purpose. Gillan, Alfè, and Michaelides (2016); Villard, Bircher, and Rothlisberger (2024) Recent advances in algorithms for PI propagation have allowed for the study of dynamics, including NQEs using hybrid functionals,Marsalek and Markland (2017) and FP-based molecular dynamics ( FP-MD) studies have also been conducted at the MP2Del Ben, Hutter, and VandeVondele (2015) and quantum Monte CarloZen et al. (2015) levels of theory. DFT and other FP based studies remain relevant in the context of solvated systems where no general high quality MLP or model is currently available. This paper is organized as follows. First, we will extend the SL-HMC and HMC methods to the PI formalism and introduce the SL-PIHMC-MIX and PIHMC-MIX methods that allow the study of systems containing many particles. Reweighting of the results from PIHMC-MIX to get the structural properties of the DFT ensemble will also be described in this section. In Sec. III, the computational details of the simulations used in this work are given. In Sec. IV, the results from the PIHMC-MIX method using an MLP that was fitted using SL-PIHMC-MIX will be compared to the results of FP-PIMD for the RPBE-D3 functional. The effects of the mixed potential method and the accuracy of the MLPs produced by the SL-PIHMC-MIX method will then be discussed. We will briefly discuss the description of heavy water (D2O) using the PIHMC-MIX method and the MLPs produced by the SL-PIHMC-MIX method. We will then go on to compare the results of PIHMC-MIX for SCAN, rev-vdW-DF2, and optB88-vdW functionals with both experimental data and those from the RPBE-D3 functional. For each of the SCAN, rev-vdW-DF2 and optB88-vdW functionals a unique MLP has been fitted using the SL-PIHMC-MIX method. Finally, we will provide a summary of the findings of this study in Sec. V."
https://arxiv.org/html/2411.10075v1,Thermodynamic Interpolation: A generative approach to molecular thermodynamics and kinetics,"Using normalizing flows and reweighting, Boltzmann Generators enable equilibrium sampling from a Boltzmann distribution, defined by an energy function and thermodynamic state. In this work, we introduce Thermodynamic Interpolation (TI), which allows for generating sampling statistics in a temperature-controllable way. We introduce TI flavors that work directly in the ambient configurational space, mapping between different thermodynamic states or through a latent, normally distributed reference state. Our ambient-space approach allows for the specification of arbitrary target temperatures, ensuring generalizability within the temperature range of the training set and demonstrating the potential for extrapolation beyond it. We validate the effectiveness of TI on model systems that exhibit metastability and non-trivial temperature dependencies. Finally, we demonstrate how to combine TI-based sampling to estimate free energy differences through various free energy perturbation methods and provide corresponding approximated kinetic rates estimated through generator extended dynamic mode decomposition (gEDMD).","Computing molecular properties and observables, such as free energies, is of great interest in numerous scientific and engineering applications. In statistical mechanics, we can express many of these observables directly through the partition function, or normalizing constant of statistical distribution over microscopic configurations of a molecular system 1. Such a statistical distribution, or ensemble is defined by the macroscopic control variables, such as temperature, volume, pressure, and chemical potential, which are kept constant. The canonical Boltzmann distribution, \mu(\mathbf{x})=\mathcal{Z}^{-1}\exp(-E(\mathbf{x})/kT) is for example characterized by constant temperature (T), volume (V), and particle number (N). Due to the high-dimensionality of molecular systems, direct computation of the partition function is intractable. Instead, we rely on simulation strategies such as Markov Chain Monte Carlo (MCMC) or Molecular Dynamics (MD) to draw samples from the distribution 2. However, for molecular systems, the high-dimensional free energy landscapes lead to impractically long simulations, to ensure the generation of independent sampling statistics. Numerous enhanced sampling methods are available, all aiming to accelerate sampling. These methods, modify the statistical ensemble to ensure faster traversal between free energy basins, or couple multiple thermodynamic ensembles replicas, or a combination of the two — albeit with the constraint, that it is possible to reweigh the generated samples back to the correct ensemble 3, 4. Some influential examples include meta dynamics 5, or conformational flooding 6, replica-exchange and parallel tempering, 7 umbrella sampling 8. Hénin et al. recently surveyed numerous other approaches 9. Machine learning is having a dramatic impact on these strategies, in particular in helping identify collective variables 10, 11, 12, 13, which is lowering the need for manual trial-and-error optimization, and transformations which lower the number of replicas 14 needed to ensure effective simulation. Current enhanced sampling methods allow us to compute stationary observables such as free energies. However, as they usually involve biasing the molecular dynamics, recovery of unbiased dynamics or kinetics, is only possible in certain situations 15, 16, 6. Kinetic modeling using Markov state models (MSM) 17, 18, 19, 20, 21, Koopman operator approaches 22, 23, 24, dynamic graphical models 25, 26, transition path sampling 27, 28, 29, 30 and deep learning infused approaches 31, 32, 33, 34, take an alternative approach, leveraging either long unbiased simulations, or massively parallel short simulations collected using adaptive sampling strategies 35, 36, 37, 38. These approaches allow us to uncover unbiased dynamics and facilitate the calculation of unbiased stationary and dynamic observables, yet remain costly from a computational perspective. Deep generative models enable the development of fundamentally new approaches to equilibrium sampling and sampling of stochastic dynamics 39, 40, 41, 42, 43, 44. An important example is Boltzmann generators (BG) 45 where an invertible deep neural network model, is trained to transform samples from a simple distribution, e.g. a normal distribution, to a complicated distribution, e.g. a Boltzmann distribution. In practice, this is often implemented using a normalizing flow 46, 47, 45. Subsequent efforts to improve accuracy and transferability of BGs, leverage alternative neural networks, including diffusion models 48, and continuous normalizing flows 49, 50, in a manner that account for molecular symmetries. A variation of this idea, called ‘Boltzmann Emulators’ generate ensembles in a reduced configurational space, e.g. by parameterizing a generative model over torsion angles, and keeping bond-lengths and angles at idealized values, have also shown some success 48, 51, 52. The connections between statistical mechanics, and deep generative models have further fueled a zoo new methods for sampling. Many of these are either inspired by perturbative methods or perturbative in nature including thermodynamic maps 53, which learn a coarse-grained multi-temperature model from replica-exchange data. Other examples include mapping between cheap reference potentials and expensive quantum mechanical models 54, computing free energies 55, or decreasing the number of replicas in a replica exchange scheme 14. More recently, a denoising diffusion model was used to perform a learned thermodynamic integration between in ideal gas and a Lennard-Jones liquid 56. Finally, an early example proposed constructing normalizing flows that were steerable under temperature transformations 57, allowing for some generalization across temperature. In this work, we propose Thermodynamic Interpolation (TI) as a method for generating samples across multiple thermodynamic states, through a learned map between different Boltzmann distributions. We present two different TI methods Ambient TI and Latent TI. Ambient TI transforms between two thermodynamic states directly in the configurational space, while latent TI transform samples between thermodynamic ensembles through a normally distributed latent space distribution. We implement both TI approaches using new simulation-free training schemes developed for continuous normalizing flows 58, and consequently, we can both transform samples between distributions and compute their change in log probabilities. Using temperature transformations as an example, we demonstrate that our ambient TI approach enables transformations between ensembles at different temperatures in configuration space. Our latent TI models similarly enable transformations between ensembles albeit through a shared latent space distribution, or reference state. Further, since the latent TI is implemented using a temperature conditioned BG we can generate samples at multiple different temperatures on-demand. We find both methods can be trained very efficiently with limited simulation data, and information is shared between thermodynamically similar ensembles. We evaluate our approach on a one-dimensional double-well model system and then scale it to MD simulations 48 of two molecules from the QM9 dataset 59: N-Methylformamide (N-Me) and 3-propan-2-ylhex-1-yne (3p2y1y). For all models, we achieve high sampling efficiency, even outside the training data, allowing us to estimate equilibrium properties such as free energy differences and dynamic properties like kinetic transition rates at temperatures not encountered during training. We thus present a framework that enables flexible transformations between arbitrary thermodynamic states, along with access to corresponding probabilities. As a result, we believe our TI approach offers a robust and generalizable tool for accurately predicting thermodynamic and kinetic properties across a wide range of thermodynamic states."
https://arxiv.org/html/2411.09932v1,"Estimating Fluid-solid Interfacial Free Energies
for Wettabilities: A Review of Molecular Simulation Methods","Fluid-solid interfacial free energy (IFE) is a fundamental parameter influencing wetting behaviors, which play a crucial role across a broad range of industrial applications. Obtaining reliable data for fluid-solid IFE remains challenging with experimental and semi-empirical methods, and the applicability of first-principle theoretical methods is constrained by a lack of accessible computational tools. In recent years, a variety of molecular simulation methods have been developed for determining the fluid-solid IFE. This review provides a comprehensive summary and critical evaluation of these techniques. The developments, fundamental principles, and implementations of various simulation methods are presented from mechanical routes, such as the contact angle approach, the technique using Bakker’s equation, and the Wilhelmy simulation method, as well as thermodynamic routes, including the cleaving wall method, the Frenkel-Ladd technique, and the test-volume/area methods. These approaches can be applied to compute various fluid-solid interfacial properties, including IFE, relative IFE, surface stress, and superficial tension, although these properties are often used without differentiation in the literature. Additionally, selected applications of these methods are reviewed to provide insight into the behavior of fluid-solid interfacial energies in diverse systems. We also illustrate two interpretations of the fluid-solid IFE based on the theory of Navascués and Berry and Bakker’s equation. It is shown that the simulation methods developed from these two interpretations are identical. This review advocates for the broader adoption of molecular simulation methods in estimating fluid-solid IFE, which is essential for advancing our understanding of wetting behaviors in various chemical systems.","Accurately characterizing wetting interactions at liquid-solid interfaces is essential for optimizing processes in industries such as oil recovery, food production, pharmaceuticals, and coatings, where interfacial phenomena directly influence material performance and process efficiency.1, 2 Historically, determining the interfacial properties of materials has advanced in parallel with the development of thermodynamic principles, with foundational work by Gibbs3 setting the stage for modern investigations. In particular, interfacial free energy (IFE) plays a key role in interface science.4, 5, 6, 7 Understanding IFE is essential for the theoretical explanation of the interfacial phenomenon and for accurate predictions of material behavior in different industrial and engineering applications. In the three-phase contact region of fluid-fluid-solid systems, IFEs are balanced as described by Young’s equation:8 \gamma_{\rm F_{1}F_{2}}\cdot\rm cos\ \theta=\gamma_{\rm SF_{2}}-\gamma_{\rm SF% _{1}}, (1) where \theta is the wettability of fluid phase 1 (\rm F_{1}) on solid phase (\rm S) surrounded by fluid phase 2 (\rm F_{2}), \gamma_{\rm F_{1}F_{2}}, \gamma_{\rm SF_{2}}, and \gamma_{\rm SF_{1}} are the IFEs between phases denoted in the subscript. In experiments, although fluid-fluid IFE \gamma_{\rm F_{1}F_{2}} and wettability \theta can be directly obtained,9, 10 the measurement of fluid-solid IFE \gamma_{\rm SF} is difficult and usually inaccurate.11 Many techniques12, 13, 14 exist for ascertaining the vacuum-solid IFE and a substantial body of experimental findings has been systematically correlated by Kumikov and Khokonov.15 Meanwhile, due to the limitations of experimental techniques when approaching the nanoscale interfaces, indirect methods have been developed for the fluid-solid IFE of various systems, including cleavage test,16 solubility test,17 adhesion force measurement,18 deformation analysis on the solid film,19 contact angle/contact line curvature measurement,20 and contact angle experiment combined with Makkonen hypothesis.21 A recent review comprehensively discusses both indirect and direct techniques for determining the IFE of fluid-solid interfaces in experiments, highlighting advancements and ongoing challenges.11 However, precisely determining fluid-solid IFE experimentally remains challenging due to factors such as the size effects, contaminations, and irregularities of surfaces.22, 23, 11 Semi-empirical theories have been extensively employed to estimate fluid-solid IFE using measured contact angle data. These theories encompass approaches like Neumann’s equation of state approach,24, 25 Zisman method,26 Fowkes method,27 geometric-mean approach,28 harmonic-mean approach,29 and van Oss-Good method.30 A comprehensive summary of these semi-empirical theories, along with their assumptions, is provided by Żenkiewicz.31 However, limited research has focused on providing a microscopic foundation for these semi-empirical theories, and significant controversies remain over the validity of several ad hoc assumptions inherent in their formulations.32, 33, 34, 11 First-principle theories have also been developed for determining the interfacial energies. In the statistical mechanical theory of Navascués and Berry35, the Kirkwood-Buff method36 was extended to the case where fluids are in contact with a rigid solid phase, and the fluid-solid IFE was split into one solid and two fluid-solid contributions. Note that this theory was later combined with molecular simulation37 for estimating the fluid-solid relative IFE, which will be discussed in detail in the next section. The square gradient theory, which was first introduced by Rayleigh38 and van der Waals39 and later rediscovered by Cahn and Hilliard,40 was applied to study wetting problems.41, 42 In square gradient theory, the fluid-solid relative IFE is derived from the surface excess transverse stress, where principal stress profiles are computed based on density distribution across the interface.42, 43 Meanwhile, classical density functional theory (cDFT) has become a pivotal tool for analyzing wettability phenomena at the molecular level.44, 32, 45 Within the cDFT framework, the fluid-solid relative IFE is typically calculated using excess grand potential: \gamma_{\rm SF}^{*}=(\Omega+pV)/A, where \Omega, p, V, and A are the grand potential, bulk pressure, volume of the fluid, and interfacial area, respectively. The cDFT is a robust and versatile tool grounded in thermodynamic principles, offering exceptional accuracy and efficiency.46, 47 The cDFT has been used for computing the fluid-solid IFE for a broad range of systems including confined fluid,48 chemically patterned wall,49 and heterogeneous surface,50 while the application of other first-principle theories has been relatively rare nowadays. Despite the demonstrated precision and efficacy of cDFT, it remains underutilized across experimental, theoretical, and computational communities. Major obstacles to its wider adoption include the theoretical complexity and a lack of accessible, user-friendly software for fluid-solid IFE computations.51, 52, 53 Molecular simulation is a powerful tool for investigating fluid-solid IFE due to several distinct advantages. Firstly, there is a wealth of open-source software available, offering a wide array of simulation tools to choose from.54, 55, 56 Moreover, molecular simulations are based on precise atomic-level representations, offering a robust physical foundation for IFE calculations.57, 58 Furthermore, molecular simulations provide flexibility, enabling the study of diverse fluid-solid interfaces across a wide range of chemical systems. This versatility arises from the extensive library of force field parameters available in the literature.59, 60, 61, 62, 63, 64 Although certain acceleration techniques, such as coarse-grained modeling,65, 66, 67, 68, 69 can reduce computational time, molecular simulation methods remain more computationally intensive than semi-empirical and first-principle approaches. Despite the advancement of various molecular simulation methods for estimating fluid-solid IFE, there remains a scarcity of comprehensive reviews. Jiang and Patel70 published a review paper focusing on molecular simulation techniques for estimating contact angles. Those methods are useful for calculating the differences of IFE. Nevertheless, several essential methodologies for the direct estimation of fluid-solid IFE remain uncovered in the previous review, and numerous innovative techniques have emerged over the past few years. This review aims to bridge these gaps by providing a comprehensive analysis of state-of-the-art molecular simulation methodologies for calculating fluid-solid IFE. The molecular simulation methods for estimating IFE can be broadly classified into two primary categories: mechanical and thermodynamic approaches. The mechanical approach encompasses methods such as the contact angle approach, the method using Bakker’s equation, and the Wilhelmy simulation method, each of which will be discussed in detail. For the thermodynamic approach, key methods include the cleaving wall technique, the Frenkel-Ladd technique, and the test-volume/area methods. Note that while there are various experimental71, 72, 73, 74, 75, 76 and theoretical77, 78, 79 methods available for studying fluid-solid IFE in the context of crystallization/nucleation, the focus of this review is on wetting problems and methods that are not suitable for studying common wetting problems were not included in the above discussion. Therefore, this review will not cover molecular simulation techniques such as the capillary fluctuation technique,80 umbrella sampling,81 extrapolation method,82, 83 metadynamics,84, 85, 86, 87 the superheating and undercooling method,88, 89, 90 the seeding technique,91, 92, 93 tethered Monte Carlo,94 and the mold integration method95."
https://arxiv.org/html/2411.10177v1,Dissociative photoionization of EUV lithography photoresist models,"The dissociative photoionization of tert-butyl methyl methacrylate, a monomer unit found in many ESCAP resists, was investigated in a gas phase photoelectron photoion coincidence experiment employing extreme ultraviolet (EUV) synchrotron radiation at 13.5 nm. It was found that the interaction of EUV photons with the molecules leads almost exclusively to dissociation. However, the ionization can also directly deprotect the ester function, thus inducing the solubility switch wanted in a resist film. These results serve as a building block to reconstruct the full picture of the mechanism in widely used chemically amplified resist thin films, provide a knob to tailor more performant resist materials, and will aid interpreting advanced ultrafast time-resolved experiments.","1 INTRODUCTION The move from deep ultraviolet (DUV) photolithography using 248-193 nm (4.8-6.4 eV) to extreme ultraviolet (EUV) at 13.5 nm (92 eV) means that the way light interacts with a photoresist thin film has changed fundamentally. While DUV light selectively activates chemical bonds in the resist material by resonant excitation, the high photon energy of EUV intrinsically triggers ionization events, but this process only has a low local selectivity. The primary photoionization events furthermore lead to a complex radiation chemistry in a resist thin film. In order to design potent resist materials for EUV lithography that are suited for imaging feature sizes below 20 nm, it is crucial to understand and ultimately control the physical and chemical processes in a photoresist film imaged with EUV radiation. In this paper, the dissociative photoionization of tert-butyl methylacrylate (TBMA), a monomer unit that is widely used in (co-)polymers of chemically-amplified resists (CARs), is investigated using photoelectron photoion coincidence (PEPICO) spectroscopy in the gas phase. This reduces the complexity of the chemistry by focusing only on the initial step in the interaction of EUV photons with resists and gaining deep fundamental insights that would not be accessible without this isolated view. Together with further complementary experiments, these insights are one basic building block in deciphering the full chemical and physical processes in EUV photolithography. The interaction of a EUV photon with a photoresist material leads to photoionization, i.e., the emission of a primary photoelectron. The ionization energy of organic molecules lies typically in the 10 eV range. Thus, the produced photoelectrons can possess a significant amount of kinetic energy at 92 eV photon energy, which leads to a second important reaction step in the EUV exposure mechanism: The primary electrons interact further with the material inducing a chain reaction of more ionization events and the creation of secondary electrons albeit with less kinetic energy. These low energy secondary electrons are assumed to mainly drive the radiation chemistry in EUV resists by electron impact dissociation and electron attachment processes. In CARs, either of these processes can lead to the generation of the photoacid, which then catalyses the deprotection of a functional group of the base polymer and therefore leads to a solubility switch. Here, also diffusion processes become relevant that make it even more challenging to obtain the desired resolution of the imaged pattern. Most of the studies on EUV photochemistry follow the pathway of the electrons generated by photoionization. However, removal of an electron can weaken a chemical bond and it is possible that a fragmentation is directly induced at this step leading to potentially reactive dissociation products. Although the electron chemistry is probably the main driving force in the solubility switch, the unavoidable fragmentations by photoionization must not be neglected since they will often lead to unwanted side reactions deteriorating the performance of a resist. The complex reaction sequences in the condensed phase make it very challenging to investigate EUV photochemistry directly in thin resist films with established analysis methods.[1] An alternative approach is therefore to use complementary experimental techniques and investigate the various processes individually in an isolated gas phase environment first in order to get fundamental insights into the chemistry occurring in each step.[2, 3] Gas phase photoelectron spectroscopy and photoionization mass spectrometry yield information on the initial photoionization step,[3, 4, 5] whereas the chemistry induced by secondary low energy electrons can be investigated using focused electron beams to study dissociative electron impact ionization and dissociative electron attachment in the gas phase.[6] The deep insights gained in such experiments can then be used to understand experiments on thin films, such as photoemission, which also adds information on the kinetic energy distribution of secondary electrons, [7, 8, 9] or outgassing experiments. The latter can identify charged and neutral fragment species that leave the surface of the thin film during EUV exposure.[10] Techniques like infrared and x-ray photoemission spectroscopy before and after exposure of the film provide information on the chemical net change in the resist upon exposure. Combining this uncomplete list of techniques helps to draw a more complete picture of the photoresist chemistry in EUV lithography. In this paper, we report on PEPICO experiments of a prototypical CAR monomer, tert-butyl methacrylate, in the gas phase providing novel fundamental insights that can be transferred to better understand the photoionization of resists by EUV photons. PEPICO combines photoelectron spectroscopy and photoionization mass spectrometry by detecting electrons and ions in coincidence.[11] Hereby, photoelectron spectra yielding the kinetic energy distribution of the primary photoelectrons are obtained as well as mass spectra, from which fragmentation products and their respective ratio produced by dissociative photoionization are obtained. In addition, PEPICO allows to combine these two datasets by correlating electrons and ions for each single ionization event. In practice, the intensity of the photon source should be so low that one photon pulse does not lead to more than one ionization event in order to guarantee an unambiguous assignment of electrons and ions. Consequently, PEPICO experiments are best conducted with light sources which operate at a high repetition rate, such as synchrotron storage rings with repetition rates in the MHz range, in order to balance acquisition time and statistics. The appearance of fragment ions can then be assigned to electrons with a certain kinetic energy in the photoelectron spectrum. Through PEPICO it can be understood which electronic states lead to which fragment ions. For photoresists there might be fragmentation channels, which actively contribute to the solubility switch by dissociative photoionization, while others lead to reactive side products. PEPICO experiments can give an idea on how to try to change the electronic structure of the resist/molecule, e.g., by different functional groups, in order to enhance (suppress) the formation of wanted (unwanted) dissociation products. TBMA is a monomer used in many common CARs and containing a tert-butyl ester side group, which is hydrolyzed upon exposure with EUV (and DUV) light leading to a higher solubility in protic solvents. Here we find that TBMA almost exclusively undergoes dissociative photoionization at 92 eV and induces a number of fragmentations, which could decrease the performance of resists containing TBMA monomers. However, one of the channels yields directly the deprotected free acid in a McLafferty rearrangement and the PEPICO technique combined with quantum chemical computations allowed to assign this dissociation channel mainly to ionization out of the HOMO-2 orbital."
https://arxiv.org/html/2411.10048v1,Physics-informed neural networks need a physicist to be accurate: the case of mass and heat transport in Fischer-Tropsch catalyst particles,"Physics-Informed Neural Networks (PINNs) have emerged as an influential technology, merging the swift and automated capabilities of machine learning with the precision and dependability of simulations grounded in theoretical physics. PINNs are often employed to solve algebraic or differential equations to replace some or even all steps of multi-stage computational workflows, leading to their significant speed-up. However, wide adoption of PINNs is still hindered by reliability issues, particularly at extreme ends of the input parameter ranges. In this study, we demonstrate this in the context of a system of coupled non-linear differential reaction-diffusion and heat transfer equations related to Fischer-Tropsch synthesis, which are solved by a finite-difference method with a PINN used in evaluating their source terms. It is shown that the testing strategies traditionally used to assess the accuracy of neural networks as function approximators can overlook the peculiarities which ultimately cause instabilities of the finite-difference solver. We propose a domain knowledge-based modifications to the PINN architecture ensuring its correct asymptotic behavior. When combined with an improved numerical scheme employed as an initial guess generator, the proposed modifications are shown to recover the overall stability of the simulations, while preserving the speed-up brought by PINN as the workflow component. We discuss the possible applications of the proposed hybrid transport equation solver in context of chemical reactors simulations.","The outstanding abilities of neural networks (NNs) in approximating complex relations have resulted in their successful application in many fields, ranging from image recognition and text comprehension to mimicking the solutions of differential equations encountered in complex engineering problems 1. One of the benefits brought by employing NNs as an alternative to traditional numerical methods is shifting the computational burden to the training phase, which is performed only once, thus enabling faster solution generation during the inference phase. This can be especially helpful in accelerating multi-stage simulations when the output of one computational method is used as an input to another one, as often encountered in engineering problems or digital twins designs 2, 3. An illustrative example can be found in chemical engineering problems related to ground-up modeling of chemical reactor or even entire chemical plants. In such applications, theoretical models are commonly available for finding the rates of both the micro-scale phenomena (e.g., molecular-level chemical reactions) and macro-scale phenomena (e.g., heat and mass transport). Their coupling results then in a system of equations which should be solved self-consistently, e.g., by solving the ‘micro-scale’ equations as a sub-task each time when the evaluation of the source terms in ‘macro-scale’ equations is required. Replacing solution of such sub-tasks with NNs is then an attractive option to accelerate the overal simulation. Despite their advantages, NNs, like many other models which learn from data, often lack interpretability. This makes their reliability in scientific or mission-critical applications questionable. Physics-informed neural network (PINN) approach has been proposed to partially overcome this drawback by incorporating the available theoretical knowledge into the NN training process 4. This approach suggests using exact equations known from the theory as the objectives that the function approximated by NN is expected to satisfy. Imposing such type of constraints often appears sufficient to make NN fit the solution of a theory-based (typically, physics-based) equation and in this way to become more interpretable. The physics-informed paradigm also requires minimal changes to the NN architecture and can be conveniently implemented in one of numerous specialized programming frameworks. However, as the loss function which is minimized during any NN training does not commonly reach exactly zero during or after this process, the theory-based constraints can only be satisfied approximately. Thus, the transfer of the theoretical knowledge into the PINN achieved by the physics-informed method remains incomplete. As will be discussed below, this can have significant consequences for incorporating PINNs into the multi-stage simulations. More broadly, PINNs can be viewed in context of wider family of methods, commonly known as the physics-informed machine learning (PIML). Within this family, there are other methods which are also intended to fuse theory-based and data-driven methods into a single computational model, but achieve this by modifying the architecture of the NN itself in order to make its output by design fulfil certain theory-based constraints exactly (e.g., 5, 6, 7, 8). Although none of the PIML approaches typically achieves complete transfer of all available theoretical knowledge into the NN, different approaches prioritize different aspects of it. To make this point more concrete, it is instructive to distinguish between the accuracy of the numerical values produced by NNs and the correctness of their dependence on the NN input parameters on the asymptotics. In this paper, we demonstrate that minor numerical inaccuracies of PINN as a function approximator can significantly affect the overall result of a multi-stage simulation, when the PINN acts as a source term in a diffusion-like equation (subsection 2.3). We further investigate the asymptotics suggested by the theory-based equations (subsection 3.1) and propose a modified PINN architecture which ensures the model follows them by design (subsections 3.2, 3.3). This is done for the particular case of reaction-diffusion system related to Fischer-Tropsch synthesis (FTS) process, which is widely used in chemical industry to produce synthetic hydrocarbons (the underlying equations are reviewed in subsections 2.1 and 2.2, along with the benefits of leveraging PINN for solving them). Finally, we demonstrate that a well-defined and guaranteed asymptotic behavior of a modified PINN is essential for constructing a conventional finite-difference equation solver enabling a stable convergence for the considered problem (subsection 3.4)."
https://arxiv.org/html/2411.09631v1,NEP-MB-pol: A unified machine-learned framework for fast and accurate prediction of water’s thermodynamic and transport properties,"Water’s unique hydrogen-bonding network and anomalous properties present significant challenges for accurately modeling its structural, thermodynamic, and transport behavior across varied conditions. Although machine-learned potentials have advanced the prediction of individual properties, a unified computational framework capable of simultaneously capturing water’s complex and subtle properties with high accuracy has remained elusive. Here, we address this challenge by introducing NEP-MB-pol, a highly accurate and efficient neuroevolution potential trained on extensive MB-pol reference data with coupled-cluster-level accuracy, combined with path-integral molecular dynamics and quantum-correction techniques to incorporate nuclear quantum effects. This NEP-MB-pol framework reproduces experimentally measured structural, thermodynamic, and transport properties of water across a broad temperature range, achieving simultaneous, fast, and accurate prediction of self-diffusion coefficient, viscosity, and thermal conductivity. Our approach provides a unified and robust tool for exploring thermodynamic and transport properties of water under diverse conditions, with significant potential for broader applications across research fields.","I Methods The NEP model. In the NEP approach, the site energy U_{i} of atom i can be written as U_{i}=\sum_{\mu=1}^{N_{\mathrm{neu}}}w^{(1)}_{\mu}\tanh\left(\sum_{\nu=1}^{N_{% \mathrm{des}}}w^{(0)}_{\mu\nu}q^{i}_{\nu}-b^{(0)}_{\mu}\right)-b^{(1)}, (1) where \tanh(x) is the activation function, \mathbf{w}^{(0)}, \mathbf{w}^{(1)}, \mathbf{b}^{(0)}, and b^{(1)} are the weight and bias parameters. The descriptor q_{i}^{\nu} is an abstract vector whose components group into radial and angular parts. The radial descriptor components q_{n}^{i} (0\leq{n}\leq n_{\rm max}^{\rm R}) are defined as q_{n}^{i}=\sum_{j\neq{i}}g_{n}(r_{ij}), (2) where r_{ij} is the distance between atoms i and j and g_{n}(r_{ij}) are a set of radial functions, each of which is formed by a linear combination of Chebyshev polynomials. The angular components include n-body (n=3,4,5) correlations. For the 3-body part, the descriptor components are defined as (0\leq{n}\leq n_{\rm max}^{\rm A}, 1\leq{l}\leq l_{\rm max}^{\rm 3body}) q_{nl}^{i}=\sum_{m}(-1)^{m}A_{nlm}^{i}A_{nl(-m)}^{i}; (3) A_{nlm}^{i}=\sum_{j\neq i}g_{n}(r_{ij})Y_{lm}(\hat{\bm{r}}_{ij}). (4) Here, Y_{lm} are the spherical harmonics and \hat{\bm{r}}_{ij} is the unit vector of \bm{r}_{ij}. Note that the radial functions g_{n}(r_{ij}) for the radial and angular descriptor components can have different cutoff radii, which are denoted as r_{\rm c}^{\rm R} and r_{\rm c}^{\rm A}, respectively. These and other hyperparameters used in our NEP-MB-pol and NEP-SCAN models are presented in Supplementary Notes 1. Density-functional theory. The SCAN dataset is generated using the Vienna Ab initio Simulation Package (VASP, version 6.3.0)[68] to calculate energy, force, and virial. The SCAN energy functional is employed to model the exchange-correlation energy. To account for the non-spherical contributions to the gradient correction within the PAW sphere, the flag LASPH is set to TRUE. A kinetic energy cutoff of 1500 eV is applied for the plane waves, with a reciprocal space sampling grid spacing of 0.5 Å-1. The self-consistent field (SCF) iterations are considered converged when the difference in total energy and band structure is below 10-6 eV. Molecular dynamics. For all the MD simulations for computing the physical properties presented in the main text, the simulation system is a periodic cubic box with 24\,567 atoms, which has a dimension of about 6.2 nm in each direction. The time step for integration is set to 0.5 fs for both classical and path-integral MD simulations. To calculate the density of water at each temperature, the system is equilibrated for 50 ps in the isothermal-isobaric ensemble. The pressure of the system is set to 1 bar, and the temperature is varied from 280 K to 370 K with an interval of 10 K. Isobaric heat capacity. The isobaric heat capacity Cp is defined as the rate of change of enthalpy H with respect to temperature under constant pressure conditions: C_{p}=(\frac{\partial H}{\partial T})_{P} (5) where, H=U+PV, and U,T,P,V represent the internal energy, temperature, pressure, and volume, respectively. Substituting this expression into the above formula, we obtain the following convenient relation for calculating isobaric heat capacity in molecular dynamics simulations C_{p}=\frac{\partial U}{\partial T}+P\frac{\partial V}{\partial T} (6) To compute Cp, the value of H is calculated at a series of temperature points with the same pressure P. A quadratic function is then fitted to the relationship between H and T, and its first derivative provides the Cp as a function of T. Self-diffusion coefficient. The running SDC for water is calculated using the following Green-Kubo relation: D(t)=\frac{1}{3}\int_{\tau=0}^{t}C_{vv}(\tau)\rm{d}\tau (7) where the velocity auto-correlation function is defined as C_{vv}(\tau)=\frac{1}{N}\sum_{i}^{N}\langle\mathbf{v}_{i}(0)\cdot\mathbf{v}_{i% }(\tau)\rangle.. Here, N is the number of atoms in the systems, and \mathbf{v}_{i} is the velocity of atom i. Shear viscosity. The shear viscosity is defined as \eta=\frac{1}{3}\left(\eta_{xy}+\eta_{xz}+\eta_{yz}\right), where the running integral of \eta_{\alpha\beta} is calculated using the following Green-Kubo relation: \eta_{\alpha\beta}(t)=\frac{V}{k_{\rm B}T}\int_{0}^{t}C_{PP}(\tau)\rm{d}\tau. (8) Here, C_{PP}(\tau)=\langle(P_{\alpha\beta}(0)-\langle P_{\alpha\beta}\rangle)(P_{% \alpha\beta}(\tau)-\langle P_{\alpha\beta}\rangle)\rangle is the pressure auto-correlation function, V is the volume, k_{\rm B} is Boltzmann’s constant, T is temperature, and P_{\alpha\beta} is the pressure tensor. Thermal conductivity. Similarly, we can use a Green–Kubo relation to calculate thermal conductivity: \kappa(t)=\frac{1}{k_{\rm B}T^{2}V}\int_{0}^{t}dt^{\prime}\langle\mathbf{J}(t^% {\prime})\cdot\mathbf{J}(0)\rangle, (9) where \mathbf{J}(t) is the heat current and \langle\mathbf{J}(t^{\prime})\cdot\mathbf{J}(0)\rangle is the heat current auto-correlation function. For liquid system, the heat current has two contributions, \mathbf{J}=\mathbf{J}^{\rm k}+\mathbf{J}^{\rm p}. The kinetic term is \mathbf{J}^{\rm k}=\sum_{i}{\mathbf{v}_{i}E_{i}}, where, E_{i} and \mathbf{v}_{i} are the total energy and velocity of atom i, respectively. The potential term for many-body potentials is [69] \mathbf{J}^{\rm p}=\sum_{i}\mathbf{W}_{i}\cdot\mathbf{v}_{i}, where \mathbf{W}_{i}=\sum_{j\neq i}\mathbf{r}_{ij}\otimes\frac{\partial U_{j}}{% \partial\mathbf{r}_{ji}} is the virial tensor of aotm i and \mathbf{r}_{ij}=\mathbf{r}_{j}-\mathbf{r}_{i}, \mathbf{r}_{i} being thee position of atom i. According to the decomposition of the heat current, the thermal conductivity can be decomposed into three terms: \kappa(t)=\kappa^{\rm pp}(t)+\kappa^{\rm kk}(t)+\kappa^{\rm pk}(t), where the potential-potential term \kappa^{\rm pp}, the kinetic-kinetic term \kappa^{\rm kk}, and the cross term \kappa^{\rm pk} correspond to the following heat current auto-correlation functions: \langle\mathbf{J}^{\rm p}(t)\cdot\mathbf{J}^{\rm p}(0)\rangle, \langle\mathbf{J}^{\rm k}(t)\cdot\mathbf{J}^{\rm k}(0)\rangle, and \langle\mathbf{J}^{\rm p}(t)\cdot\mathbf{J}^{\rm k}(0)\rangle+\langle\mathbf{J% }^{\rm k}(t)\cdot\mathbf{J}^{\rm p}(0)\rangle. Besides, we use the homogeneous nonequilibrium MD method [64] to calculate the thermal conductivity of water. In this method, an external driving force \mathbf{F}_{i}^{\mathrm{ext}}=E_{i}\mathbf{F}_{\mathrm{e}}+\mathbf{F}_{\mathrm% {e}}\cdot\mathbf{W}_{i} is exerted on each atom i, driving the system out of equilibrium. Here, \mathbf{F}_{\mathrm{e}} is the driving force parameter with the dimension of inverse length. In this work, the magnitude of F_{\mathrm{e}} was chosen as 0.001 Å-1, which has been tested to be small enough to keep the system within the linear response regime. The driving force will induce an ensemble-averaged steady-state non-equilibrium heat current \mathbf{J}, which is related to the thermal conductivity tensor \kappa^{\alpha\beta}: \frac{\left\langle J^{\alpha}\right\rangle}{TV}=\sum_{\beta}\kappa^{\alpha% \beta}F_{\mathrm{e}}^{\beta}. (10)"
https://arxiv.org/html/2411.09399v1,OVB analysis of chemical bonding in three-membered ring systems,"The formation of the four three-ring systems ethene, disilene, silirane, and disilirane by addition of methylene and silylene to the double bond in ethene, disilene, and silaethene, as well as the elimination of the methylene analogs from the three-rings, was studied with CAS(4,4) wave functions in both C_{2v} and C_{s} symmetry. To reveal charge and spin redistribution during these reactions the CAS(4,4) wave functions were analyzed using the OVB method (orthogonal valence bond). The potential energy curves, different internal coordinates, and the results of the OVB analysis show, that frequently the addition and elimination reactions follow differen minimum energy paths, because they are diabatic reactions. In these cases, there are no energy barriers corresponding to saddle points on the potential energy surfaces but there is an energy increase during one diabatic reaction, then the system jumps to the other diabatic state and the energy decreases. This happens for reactions in C_{2v} symmetry, as soon as the system can change to the lower symmetry, the diabatic states combine to an adiabatic and the reaction follow the single minimum energy path.","In 1981, two manuscripts were submitted for publication, in which the synthesis of disilenes, hitherto unknown molecules with silicon-silicon double bonds, were described. West et al. reported in their paper[1] the dimerization of silylenes, whereas Masamune et al.[2] prepared disilene by photofragmentation of a cyclotrisilane, another hitherto unknown molecule. That hexakis(2,6-dimethylphenyl)cyclotrisilane was “stable to oxygen, moisture, and heat to its melting point” indicated unexpected thermodynamic stability. Only when the cyclotrisilane was irradiated with ultraviolet light for 5 minutes, it was nearly quantitatively converted into disilene and silylene.[2] This suggests that large aryl substituents increase the kinetic stabilization of the three-membered ring against oxidation and fragmentation, at least in the electronic ground state. When the aryl substituents were replaced by alkyl substituents[3], the cyclotrisilanes were found to be rather sensitive to exposure to oxygen; but the light induced fragmentation took several hours. These experimental results did not explain why the cyclotrisilanes were that stable; after all, according to chemical knowledge, both the smallest cyclic silanes and unsaturated silanes were regarded as nonexistent compounds or compounds of low stability[4]. To explain the lower stability of the silicon species when compared with the carbon analogs, the overlap of silicon valence orbitals was claimed to be much poorer. In case of disilenes, the side-on overlap of pπ AOs (atomic orbital) was considered to be too small, in case of small ring systems the small overlap of sp3 AOs was claimed to be the cause of low stability and of high reactivity. The high stability caused by suitable substituents was surprising and demanded a correction of the explanation. Bonding is the stabilizing process in a system composed of several subsystems,[5] in molecular systems the subsystems are either atoms or stable atom groups; stable means that the atom group does not spontaneously disintegrate into smaller atom groups or atoms. Stable atom groups, also termed molecular species or molecular compounds, can be radicals or molecules; molecules are molecular species that do not react violently with other species of its own kind.[6] In this paper, we will call any subsystem of a molecular system a fragment. An important criterion for any kind of bonding is the total energy: if the total energy of a system decreases during some process the system is stabilized and thus bonded. For chemists, the following structural criterion must be fulfilled for chemical or covalent bonding in a system: at least one atom group with a significant short interatomic distance, which did not exist in the system before the stabilization process started, must be created. This criterion together with the claimed role of the Lewis electron pair and the valence concept is the basis of the traditional chemical explanation of covalent bonding. According to Lewis, the formation of the atom groups is caused by electron pairs shared between the atoms, meaning that each atom in the atom group contributes one electron to the electron pair (Lewis’ rule of two). The valence of an atom is equal to the number of unpaired electrons it has and to the number of electron pairs the atom can share with other atoms. In chemistry parlance, one speaks of a covalent single AB bond if the AB atom group is the result of the formation of one shared electron pair between atoms A and B. If not all of the N unpaired valence electrons are used to form single bonds to different atoms, two or more electron pairs can stabilize an AB group and one speaks then of the existence of double bonds, triple bonds etc. in the AB group. Pairs of valence electrons that are located at one atom but are not shared electron pairs are called lone pairs. A serious deficiency of Lewis’ electron pair model is that it does not say when electrons will pair. As soon as the fermionic character of electrons was recognized, it became clear that a shared electron pair is an electron distribution in a singlet spin state, called a low-spin state. That means, the two electrons must be in spin projection states with different quantum numbers, in chemical parlance, one electron has \alpha spin, the other has \beta spin or, simply said, they are singlet coupled. If the spins of both electrons are in the same spin projection state, either both are alpha or both are \beta electrons, the electron distribution is in a high-spin triplet state, the electrons are unpaired. Singlet coupled valence electrons are always paired and cannot immediately participate in the formation of shared electron pairs, whereas triplet coupled valence electrons are unpaired and therefore immediately ready for bonding. The difference in the dimerization of methylene and of silylene demonstrates this nicely. The ground state of methylene is a triplet state, the two valence electrons are triplet coupled lone pair electrons, which are ready for the formation of a double bond. The ground state of silylene, however, is a low spin singlet state, the lone pair electrons are nor ready for bonding but must be prepared by exciting the lone pair from the low-spin state to the high-spin state.[7] However, pairing of unpaired electrons is not sufficient for covalent bonding. Since the first quantum theoretical studies of bonding in the hydrogen molecule, it is known that charge shifts during bonding must be accounted for.[8] And the more valence electrons the atoms connected by covalent bonds have the more inter- and intra-fragment interactions can occur and must be properly treated. These interactions may cause dramatic changes in the distribution of charges and spins and, accordingly, in the structure of the molecules involved; MCSCF (multi-configurational self-consistent field) wave functions, especially the CASSCF (complete active space self-consistent field) variant, allow the sound description of reactions in such molecular systems. But local effects remain hidden if the wave functions are built with delocalized molecular orbitals (MO), and they can be revealed when valence bond (VB) methods based on localized orbitals are used. The OVB (orthogonal valence bond) analysis of CASSCF wave functions[7] was developed to reveal the hidden local features by transforming delocalized CASSCF MOs onto localized fragment MOs (FMO). To find out which processes are constitutive for creating or breaking of covalent bonds, comparative studies of reactions with homologous reactants are helpful. The insertion of methylene[9] and silylene[10, 11, 12] into the hydrogen molecule were the first reactions that stimulated a re-investigation with the OVB method, followed by the dimerization of methylene and silylene to ethene and disilene, respectively, as well as the formation of silaethene from methylene and silylene.[7] The insertion reaction into hydrogen is a prototype reaction for insertions of all carbene analogs into sigma single bonds. In these reactions the bonding electron pair of the sigma bond and the singlet coupled lone pair of the carbene analogs must simultaneously be excited from low- to high-spin states, and, since all reactions are studied in systems with singlet ground states, these spin rearrangements in the reactants must occur simultaneously. Depending on the system’s symmetry, polarization of the charge distribution can enhance the decoupling, and make symmetry-forbidden reactions symmetry-allowed, as found for the dimerization of carbene analogs.[13] In this paper, the elimination of methylene and silylene from cyclic three-rings and the reverse addition of methylene and silylene to the \pi bonds in ethene, disilene, and silaethene are studied in both high C_{2v} and low C_{s} symmetry. In high symmetry, elimination of carbene analogs is costly, in low symmetry elimination proceeds without any barriers. This was found for all three-rings, and explains, why three-rings with large, bulky substituents, which prohibit a deformation to C_{s} symmetry, are rather stable. Comparison of the reactions in the cyclopropane and cyclotrisilane systems show intrinsic similarities and differences of the two small ring systems. The reactions of silacyclopropane and disilacyclopropane show the differences in the electron structure between a molecular system with a C-C double bond and silylene compared with the system with an Si-Si double bond and methylene."
https://arxiv.org/html/2411.09448v1,Diffusive dynamics of charge regulated macro-ion solutions,"Onsager’s variational principle is generalized to address the diffusive dynamics of an electrolyte solution composed of charge-regulated macro-ions and counterions. The free energy entering the Rayleighian corresponds to the Poisson-Boltzmann theory augmented by the charge-regulation mechanism. The dynamical equations obtained by minimizing the Rayleighian include the classical Poisson-Nernst-Planck equations, the Debye-Falkenhagen equation, and their modifications in the presence of charge regulation. By analyzing the steady state, we show that the charge regulation has an important impact on the non-equilibrium macro-ion spatial distribution and their effective charge, deviating significantly from their equilibrium values. Our model, based on Onsager’s variational principle offers a unified approach to the diffusive dynamics of electrolytes containing components that undergo various charge association/dissociation processes.","References [1] Lund, M.; Jönsson, B. Charge regulation in biomolecular solution. Q. Rev. Biophys. 2013, 46, 265–281. [2] Markovich, T.; Andelman, D.; Podgornik, R. Charged membranes: Poisson–Boltzmann theory, the DLVO paradigm, and beyond. In Handbook of lipid membranes; CRC Press, 2021; pp 99–128. [3] Avni, Y.; Andelman, D.; Podgornik, R. Charge regulation with fixed and mobile charged macromolecules. Curr. Opin. Electrochem. 2019, 13, 70–77. [4] Zhou, H.-X.; Pang, X. Electrostatic interactions in protein structure, folding, binding, and condensation. Chem. Rev. 2018, 118, 1691–1741. [5] Božič, A.; Podgornik, R. Site correlations, capacitance, and polarizability from protein protonation fluctuations. J. Phys. Chem. B 2021, 125, 12902–12908. [6] Ong, G. M.; Gallegos, A.; Wu, J. Modeling surface charge regulation of colloidal particles in aqueous solutions. Langmuir 2020, 36, 11918–11928. [7] Borkovec, M.; Jönsson, B.; Koper, G. J. Ionization processes and proton binding in polyprotic systems: small molecules, proteins, interfaces, and polyelectrolytes. In Surface and Colloid Science; Springer, 2001; pp 99–339. [8] Borukhov, I.; Andelman, D.; Borrega, R.; Cloitre, M.; Leibler, L.; Orland, H. Polyelectrolyte titration: theory and experiment. J. Phys. Chem. B 2000, 104, 11027–11034. [9] Celora, G. L.; Blossey, R.; Münch, A.; Wagner, B. Counterion-controlled phase equilibria in a charge-regulated polymer solution. J. Chem. Phys. 2023, 159, 184902. [10] da Silva, F. L. B.; Derreumaux, P.; Pasquali, S. Protein-RNA complexation driven by the charge regulation mechanism. Biochem. Biophys. Res. Commun. 2018, 498, 264–273. [11] Zheng, B.; Avni, Y.; Andelman, D.; Podgornik, R. Phase separation of polyelectrolytes: the effect of charge regulation. J. Phys. Chem. B 2021, 125, 7863–7870. [12] Hyltegren, K.; Skepö, M. Adsorption of polyelectrolyte-like proteins to silica surfaces and the impact of pH on the response to ionic strength. a Monte Carlo simulation and ellipsometry study. J. Colloid Interface Sci. 2017, 494, 266–273. [13] Obstbaum, T.; Sivan, U. Thermodynamics of charge regulation near surface neutrality. Langmuir 2022, 38, 8477–8483. [14] Hong, Y.; Brown, D. G. Electrostatic behavior of the charge-regulated bacterial cell surface. Langmuir 2008, 24, 5003–5009. [15] Nap, R. J.; Božič, A. L.; Szleifer, I.; Podgornik, R. The role of solution conditions in the bacteriophage PP7 capsid charge regulation. Biophys. J. 2014, 107, 1970–1979. [16] Ong, G. M.; Gallegos, A.; Wu, J. Modeling surface charge regulation of colloidal particles in aqueous solutions. Langmuir 2020, 36, 11918–11928. [17] Yuan, J.; Takae, K.; Tanaka, H. Impact of charge regulation on self-assembly of zwitterionic nanoparticles. Phys. Rev. Lett. 2022, 128, 158001. [18] Ninham, B. W.; Parsegian, V. A. Electrostatic potential between surfaces bearing ionizable groups in ionic equilibrium with physiologic saline solution. J. Theor. Biol. 1971, 31, 405–428. [19] Diamant, H.; Andelman, D. Kinetics of surfactant adsorption at fluid-fluid interfaces. J. Phys. Chem. 1996, 100, 13732–13742. [20] Werkhoven, B.; Samin, S.; van Roij, R. Dynamic stern layers in charge-regulating electrokinetic systems: three regimes from an analytical approach. Eur. Phys. J.: Spec. Top. 2019, 227, 2539–2557. [21] Everts, J. C.; Samin, S.; Elbers, N. A.; van der Hoeven, J. E. S.; van Blaaderen, A.; van Roij, R. Colloid–oil–water-interface interactions in the presence of multiple salts: charge regulation and dynamics. Phys. Chem. Chem. Phys. 2017, 19, 14345–14357. [22] Biesheuvel, P.; Bazant, M. Analysis of ionic conductance of carbon nanotubes. Phys. Rev. E 2016, 94, 050601. [23] Jiang, Z.; Stein, D. Charge regulation in nanopore ionic field-effect transistors. Phys. Rev. E 2011, 83, 031203. [24] Ritt, C. L.; de Souza, J. P.; Barsukov, M. G.; Yosinski, S.; Bazant, M. Z.; Reed, M. A.; Elimelech, M. Thermodynamics of charge regulation during ion transport through silica nanochannels. ACS Nano 2022, 16, 15249–15260. [25] Bazant, M. Z.; Kilic, M. S.; Storey, B. D.; Ajdari, A. Towards an understanding of induced-charge electrokinetics at large applied voltages in concentrated solutions. Adv. Colloid Interface Sci. 2009, 152, 48–88. [26] Kilic, M. S.; Bazant, M. Z.; Ajdari, A. Steric Effects in the dynamics of electrolytes at large applied voltages. II. modified Poisson-Nernst-Planck equations. Phys. Rev. E 2007, 75, 021503. [27] Avni, Y.; Markovich, T.; Podgornik, R.; Andelman, D. Charge regulating macro-ions in salt solutions: screening properties and electrostatic interactions. Soft Matter 2018, 14, 6058–6069. [28] Avni, Y.; Podgornik, R.; Andelman, D. Critical behavior of charge-regulated macro-ions. J. Chem. Phys. 2020, 153, 024901. [29] Podgornik, R. General theory of charge regulation and surface differential capacitance. J. Chem. Phys. 2018, 149. [30] Markovich, T.; Andelman, D.; Podgornik, R. Complex fluids with mobile charge regulating macro-ions. EPL 2018, 120, 26001. [31] Doi, M. Onsager’s variational principle in soft matter. J. Phys.: Condens. Matter 2011, 23, 284118. [32] Doi, M. Onsager principle in polymer dynamics. Prog. Polym. Sci. 2021, 112, 101339. [33] Arroyo, M.; Walani, N.; Torres-Sánchez, A.; Kaurin, D. Onsager’s variational principle in soft matter: introduction and application to the dynamics of adsorption of proteins onto fluid membranes. In The role of mechanics in the study of lipid bilayers; Springer, 2018; pp 287–332. [34] Wang, H.; Qian, T.; Xu, X. Onsager’s Variational principle in active soft matter. Soft Matter 2021, 17, 3634–3653. [35] Lin, L.-S.; Yasuda, K.; Ishimoto, K.; Hosaka, Y.; Komura, S. Onsager’s variational principle for nonreciprocal systems with odd elasticity. J. Phys. Soc. Jpn. 2023, 92, 033001. [36] Xu, S.; Eisenberg, R.; Song, Z.; Huang, H. Coupled chemical reactions: effects of electric field, diffusion, and boundary control. Phys. Rev. E 2023, 108, 064413. [37] Gu, J.; Gaspard, P. Stochastic approach and fluctuation theorem for charge transport in diodes. Phys. Rev. E 2018, 97, 052138. [38] Bazant, M. Z. Theory of chemical kinetics and charge transfer based on nonequilibrium thermodynamics. Acc. Chem. Res. 2013, 46, 1144–1160. [39] Gavish, N.; Elad, D.; Yochelis, A. From solvent-free to dilute electrolytes: essential components for a continuum theory. J. Phys. Chem. Lett. 2018, 9, 36–42. [40] Janssen, M.; Bier, M. Transient dynamics of electric double-layer capacitors: exact expressions within the Debye-Falkenhagen approximation. Phys. Rev. E 2018, 97, 052616. [41] Bier, M. Non-equilibrium steady states of electrolyte interfaces. New J. Phys. 2024, 26, 013008. [42] Fedorov, M. V.; Kornyshev, A. A. Towards understanding the structure and capacitance of electrical double layer in ionic liquids. Electrochimica Acta 2008, 53, 6835–6840."
https://arxiv.org/html/2411.09039v1,Hidden nonlinear optical susceptibilities in linear polaritonic spectra,"Linear spectra of molecular polaritons formed by N molecules coupled to a microcavity photon mode are usually well described by classical linear optics, raising the question of where the expected nonlinear effects in these strongly coupled systems are. In this work, we derive a general expression for the polaritonic linear spectra that reveal previously overlooked finite-size quantum corrections due to vacuum-mediated molecular Raman processes. Using a 1/N expansion, we demonstrate that these nonlinearities are suppressed in typical low-Q cavities due to an emergent timescale separation in polariton dynamics yet manifest in high-Q single-mode cavities where the photon loss is comparable to the single-molecule light-matter coupling strength.","References Coles et al. [2014] D. M. Coles, N. Somaschi, P. Michetti, C. Clark, P. G. Lagoudakis, P. G. Savvidis, and D. G. Lidzey, Nature Materials 13, 712 (2014). Reitz et al. [2018] M. Reitz, F. Mineo, and C. Genes, Scientific Reports 8, 9050 (2018). Koner et al. [2023] A. Koner, M. Du, S. Pannir-Sivajothi, R. H. Goldsmith, and J. Yuen-Zhou, Chemical Science 14, 7753 (2023). Hutchison et al. [2012] J. A. Hutchison, T. Schwartz, C. Genet, E. Devaux, and T. W. Ebbesen, Angewandte Chemie International Edition 51, 1592 (2012). Herrera and Owrutsky [2020] F. Herrera and J. Owrutsky, The Journal of Chemical Physics 152 (2020). Freire-Fernández et al. [2024] F. Freire-Fernández, N. G. Sinai, M. J. Hui Tan, S.-M. Park, E. R. Koessler, T. Krauss, P. Huo, and T. W. Odom, ACS Nano 18, 15177 (2024), pMID: 38808728, https://doi.org/10.1021/acsnano.4c03164 . Bennenhei et al. [2023] C. Bennenhei, M. Struve, S. Stephan, N. Kunte, V. N. Mitryakhin, F. Eilenberger, J. Ohmer, U. Fischer, M. Silies, C. Schneider, and M. Esmann, Opt. Mater. Express 13, 2633 (2023). Daskalakis et al. [2017] K. S. Daskalakis, S. A. Maier, and S. Kéna-Cohen, Quantum Plasmonics , 151 (2017). Schwennicke et al. [2024] K. Schwennicke, A. Koner, J. B. Pérez-Sánchez, W. Xiong, N. C. Giebink, M. L. Weichman, and J. Yuen-Zhou, “When do molecular polaritons behave like optical filters?” (2024), arXiv:2408.05036 [physics.chem-ph] . Zhu et al. [1990] Y. Zhu, D. J. Gauthier, S. Morin, Q. Wu, H. Carmichael, and T. Mossberg, Physical Review Letters 64, 2499 (1990). Schubert [1996] M. Schubert, Physical Review B 53, 4265 (1996). Yariv and Yeh [2007] A. Yariv and P. Yeh, Photonics: optical electronics in modern communications (Oxford University Press, 2007). Német et al. [2020] N. Német, D. White, S. Kato, S. Parkins, and T. Aoki, Physical Review Applied 13, 064010 (2020). Ćwik et al. [2016] J. A. Ćwik, P. Kirton, S. De Liberato, and J. Keeling, Physical Review A 93, 033840 (2016). Gunasekaran et al. [2023] S. Gunasekaran, R. F. Pinard, and A. J. Musser, arXiv preprint arXiv:2308.08744 (2023). Yuen-Zhou and Koner [2024] J. Yuen-Zhou and A. Koner, The Journal of Chemical Physics 160, 154107 (2024), https://pubs.aip.org/aip/jcp/article-pdf/doi/10.1063/5.0183683/19883191/154107_1_5.0183683.pdf . Pérez-Sánchez and Yuen-Zhou [2024] J. B. Pérez-Sánchez and J. Yuen-Zhou, “Radiative pumping vs vibrational relaxation of molecular polaritons: a bosonic mapping approach,” (2024), arXiv:2407.20594 [quant-ph] . Gegg and Richter [2016] M. Gegg and M. Richter, New J. Phys. 18, 043037 (2016). Shammah et al. [2018] N. Shammah, S. Ahmed, N. Lambert, S. De Liberato, and F. Nori, Phys. Rev. A 98, 063815 (2018). Zeb [2022] M. A. Zeb, Comp. Phys. Commun. 276, 108347 (2022). Silva and Feist [2022] R. E. F. Silva and J. Feist, Phys. Rev. A 105, 043704 (2022). Sukharnikov et al. [2023] V. Sukharnikov, S. Chuchurka, A. Benediktovitch, and N. Rohringer, Phys. Rev. A 107, 053707 (2023). Pérez-Sánchez et al. [2024] J. B. Pérez-Sánchez, A. Koner, S. Raghavan-Chitra, and J. Yuen-Zhou, “Cut-e as a 1/n expansion for multiscale molecular polariton dynamics,” (2024), arXiv:2410.14175 [quant-ph] . Philpott [1971] M. R. Philpott, J. Chem. Phys. 55, 2039 (1971). Herrera and Spano [2017] F. Herrera and F. C. Spano, Phys. Rev. Lett. 118, 223601 (2017). Pérez-Sánchez et al. [2023a] J. B. Pérez-Sánchez, A. Koner, N. P. Stern, and J. Yuen-Zhou, Proceedings of the National Academy of Sciences 120, e2219223120 (2023a). Velev and Butler [2004] J. Velev and W. Butler, Journal of Physics: Condensed Matter 16, R637 (2004). Pastawski et al. [1983] H. M. Pastawski, J. F. Weisz, and S. Albornoz, Phys. Rev. B 28, 6896 (1983). Hänggi et al. [1978] P. Hänggi, F. Rösel, and D. Trautmann, Zeitschrift für Naturforschung A 33, 402 (1978). Mukamel [1995] S. Mukamel, Principles of nonlinear optical spectroscopy (Oxford University Press, 1995). Zeb et al. [2018] M. A. Zeb, P. G. Kirton, and J. Keeling, ACS Photonics 5, 249 (2018). Pérez-Sánchez et al. [2023b] J. B. Pérez-Sánchez, F. Mellini, N. C. Giebink, and J. Yuen-Zhou, arXiv preprint arXiv:2308.03954 (2023b). Muthukrishnan et al. [2004] A. Muthukrishnan, G. S. Agarwal, and M. O. Scully, Phys. Rev. Lett. 93, 093002 (2004). Seidelmann et al. [2022] T. Seidelmann, C. Schimpf, T. K. Bracht, M. Cosacchi, A. Vagov, A. Rastelli, D. E. Reiter, and V. M. Axt, Phys. Rev. Lett. 129, 193604 (2022). Glenn et al. [2015] R. Glenn, K. Bennett, K. E. Dorfman, and S. Mukamel, Journal of Physics B: Atomic, Molecular and Optical Physics 48, 065401 (2015). Fetter and Walecka [2003] A. Fetter and J. Walecka, Quantum Theory of Many-particle Systems, Dover Books on Physics (Dover Publications, 2003). Engelhardt and Cao [2023] G. Engelhardt and J. Cao, Phys. Rev. Lett. 130, 213602 (2023). Xue et al. [2016] C.-h. Xue, Y. Ding, H.-t. Jiang, Y. Li, Z.-s. Wang, Y.-w. Zhang, and H. Chen, Phys. Rev. B 93, 125310 (2016). Fujii and Tanabe [2020] S. Fujii and T. Tanabe, Nanophotonics 9, 1087 (2020). García Jomaso et al. [2024] Y. A. García Jomaso, B. Vargas, D. L. Domínguez, R. J. Armenta-Rico, H. E. Sauceda, C. L. Ordoñez-Romero, H. A. Lara-García, A. Camacho-Guardian, and G. Pirruccio, Nature Communications 15, 2915 (2024). Baboux et al. [2016] F. Baboux, L. Ge, T. Jacqmin, M. Biondi, E. Galopin, A. Lemaître, L. Le Gratiet, I. Sagnes, S. Schmidt, H. E. Türeci, A. Amo, and J. Bloch, Phys. Rev. Lett. 116, 066402 (2016)."
https://arxiv.org/html/2411.08831v1,"Machine Learning-Based Enhancements of Empirical Energy
Functions: Structure, Dynamics and Spectroscopy of Modified
Benzenes","The effect of replacing individual contributions to an empirical energy function are assessed for halogenated benzenes (X-Bz, X = H, F, Cl, Br) and chlorinated phenols (Cl-PhOH). Introducing electrostatic models based on distributed charges (MDCM) instead of usual atom-centered point charges yields overestimated hydration free energies unless the van der Waals parameters are reparametrized. Scaling van der Waals ranges by 10 % to 20 % for three Cl-PhOH and most X-Bz yield results within experimental error bars, which is encouraging, whereas for benzene (H-Bz) point charge-based models are sufficient. Replacing the bonded terms by a neural network-trained energy function with either fluctuating charges or MDCM electrostatics also yields qualitatively correct hydration free energies which still require adaptation of the van der Waals parameters. The infrared spectroscopy of Cl-PhOH is rather well predicted by all models although the ML-based energy function performs somewhat better in the region of the framework modes. It is concluded that refinements of empirical energy functions for targeted applications is a meaningful way towards more quantitative simulations.","The success of empirical energy functions rests on two ingredients: i) their functional dependence is sufficiently simple to allow rapid evaluation for stable and long-time (\mus or longer) simulations of large systems (10^{6} atoms or larger) and ii) their acceptable accuracy in modelling intra- and intermolecular interactions which allows qualitative or semi-quantitative molecular-level studies, depending on the observable(s) considered and the agreement with experiments sought. While existing force fields exploit new hardware to simulate ever larger systems and longer timescales,1 increased computational power also provides an opportunity to include more detail to refine force fields that are still applicable to systems and timescales of chemical or biochemical interest. Crucial to this task is determining to what extent increasing the detail of each term provides greater accuracy in describing the intermolecular interactions.2 At the same time, the final model needs to be widely applicable with the possibility to parametrize it even for highly heterogeneous chemical systems, such as ionic liquids.3, 4 Empirical energy functions have a long and successful history as exemplified by the widely used parametrizations are the CHARMM,5 Amber,6 Gromos,7 and OPLS8 energy functions. Such energy functions were and are being successfully applied to study proteins,9 nucleic acids,10 organic crystals,11 or materials,12 to name only a few applications. One of the broadly applicable empirical energy functions is the CGenFF parametrization which is the CHARMM General Force Field.13, 14 This energy function is available as an additive and a polarizable variant using the Drude-oscillator approach. On the other hand, most terms in an empirical energy function are first-order approximations to more physically meaningful terms. One example concerns harmonic, quadratic terms for chemical bonds which are suitable to describe equilibrium structures of molecules and small-amplitude vibrations within a normal mode approximation. However, for anharmonic vibrations one needs to go beyond such an approximation and include higher-order terms (cubic, quartic) such as done, e.g., in the Merck Molecular Force Field (MMFF).15 There are alternative possibilities such as replacing the harmonic terms by Morse-oscillators or machine-learned energy functions using reproducing kernels or neural networks.16, 17, 18, 19 For studying the infrared spectroscopy of small molecules in heterogeneous environments and comparing with experiments to provide interpretations and understanding, the simplest parametrizations are clearly insufficient.20, 21 Similarly, to characterized energy flow in molecules, the coupling between different internal degrees of freedom needs to be captured considerably more precisely for meaningful analysis and potentially predictive simulations.22, 23 In all these cases, replacing specific terms in the empirical energy functions by more appropriate functional forms will enhance the performance and improve the quality of the simulations carried out with these energy functions. Along similar lines, atom-centered point charges as an approximation to the more general multipolar expansion of electrostatic interactions can be replaced by, for example, extended charge models,24, 25, 26, 27, 28 atom-centered multipoles,29, 30, 31, 32, 33 or off-centered distributed point charges.34, 35, 36, 37, 38, 39 Such more elaborate models for the electrostatics capture the anisotropy of the charge distribution around a particular interaction site. This is, for example, relevant when representing lone pairs as for water or \sigma-holes for halogenated compounds.40, 41 It is also possible to yet include changes in the electrostatics as the structure of a molecule changes along a MD trajectory. Such “fluctuating charges” or “fluctuating multipoles” are also capable of encapsulating bond polarization42, 43, 44, 45, 46, 37, 38 or qualitatively describing charge reorganization for bond breaking and bond-formation.47 The present work explores the effects of replacing bonded and electrostatic interactions in the CGenFF empirical energy functions for halogenated benzenes and Chloro-phenol with the chloride atom at its o-, p-, and m-positions relative to the hydroxyl. First, the computational methods are presented, followed by structural, spectroscopic and thermodynamic properties."
https://arxiv.org/html/2411.08751v2,Generalized coupled cluster theory for ground and excited state intersections,"Coupled cluster theory in the standard formulation is unable to correctly describe conical intersections among states of the same symmetry. This limitation has restricted the practical application of an otherwise highly accurate electronic structure model, particularly in nonadiabatic dynamics. Recently, the intersection problem among the excited states was fully characterized and resolved. However, intersections with the ground state remain an open challenge, and addressing this problem is our objective here. We present a generalized coupled cluster framework that correctly accounts for the geometric phase effect and avoids bifurcations of the solutions to the ground state equations. Several applications are presented that demonstrate the correct description of ground state conical intersections. We also propose how the framework can be used for other electronic-structure methods.","0.1 Introduction Molecular systems with quasi-degeneracies or conical intersections between the ground and excited states present a significant challenge for single-reference coupled cluster methods. Although numerous multireference coupled cluster methods have been proposed over the past forty years, comprehensive assessments indicate that no satisfactory solution has yet been found.1, 2, 3 As a result, coupled cluster methods have not been used to describe ground state conical intersections, even though such degeneracies are critically important to non-radiative relaxation processes found in a wide range of biological and chemical systems.4 In this paper, we do not aim to solve the general multireference case, which for instance is needed to describe the dissociation of molecules, limiting ourselves to the specific case of conical intersections between the ground and excited states. The description of excited state intersections is also flawed in standard coupled cluster theory, 5, 6, 7 except for the geometric phase effect. 8 However, it is now known that the problems associated with excited state intersections (distortion of potential energy surfaces, complex energies, and incorrect topology) can be corrected by enforcing orthogonality relations between the electronic states. This is the main idea behind similarity constrained coupled cluster (SCC) theory,9, 10 which provides a small correction to standard coupled cluster theory that restores a correct description of conical intersections. This method was recently applied successfully in nonadiabatic dynamics simulations on gas-phase thymine,11, 12 opening up a range of applications to excited-state relaxation processes. Recently Kjønstad and Koch13 demonstrated that the ground state coupled cluster wave function fails to account for the geometric phase encountered when traversing a path around a conical intersection. This leads to divergences in the coupled cluster wave function and results in a multi-valued potential energy surface, where different surfaces can arise depending on the direction of the path taken around the conical intersection. As shown in Ref. 13, these divergences are not only confined to small regions of the potential energy surface but extend throughout the entire configuration space encircling a ground state conical intersection. Another complication arises when the Jacobian matrix becomes nearly singular, which occurs near the intersection. This situation defines a bifurcation point14 in the amplitude equations, leading to multiple possible solutions. These solutions have been studied in great detail previously.15, 16, 17 However, to the best of our knowledge, a wave function parametrization that eliminates these bifurcations has not been proposed. Each of the multiple solutions may be a reasonable approximation in some regions but completely unphysical in others, and there can be regions of internal coordinate space where the amplitude equations cannot be solved when the amplitudes are restricted to be real. We will show examples of these cases below. The study of regions near ground state conical intersections in coupled cluster theory is highly challenging due to the bifurcation of solutions and the breakdowns caused by the phase effect. 13 This is probably the reason why this area is largely unexplored in the community. The algorithm recently described by Angelico, Kjønstad, and Koch18 is therefore an indispensable tool when exploring the configuration space near intersections. This algorithm determines structures on an enveloped seam (also referred to as a tube) that is large enough to avoid the unphysical regions and sufficiently small to give reliable minimum energy conical intersection structures. These structures are denoted as \varepsilon-MECI, where \varepsilon corresponds to the extent of the tube that is wrapped around the seam. In this work, we derive a generalized coupled cluster theory (GCC) that avoids all the unphysical behaviors mentioned above. The complications related to matrix defects in the non-Hermitian eigenvalue problem can be handled using the techniques developed in similarity-constrained coupled cluster theory and will not be discussed here. The application of GCC with singles and doubles excitations (GCCSD) will be illustrated for several molecular systems where the coupled cluster singles and doubles (CCSD) model fails to give a correct description. We will also formulate the GCC2 model, which is a generalization of the well-established CC2 model.19 Finally, we will propose a procedure to eliminate bifurcations in Hartree-Fock and density functional theory, which in their present formulation are unable to describe ground state conical intersections.20, 21"
https://arxiv.org/html/2411.08598v1,Space-local memory in generalized master equations: Reaching the thermodynamic limit for the cost of a small lattice simulation,"The exact quantum dynamics of lattice models can be computationally intensive, especially when aiming for large system sizes and extended simulation times necessary to converge transport coefficients. By leveraging finite memory times to access long-time dynamics using only short-time data, generalized master equations (GMEs) can offer a route to simulating the dynamics of lattice problems efficiently. However, such simulations are limited to small lattices whose dynamics exhibit finite-size artifacts that contaminate transport coefficient predictions. To address this problem, we introduce a novel approach that exploits finite memory in time and space to efficiently predict the many-body dynamics of dissipative lattice problems involving short-range interactions. This advance enables one to leverage the short-time dynamics of small lattices simulate arbitrarily large systems over long times. We demonstrate the strengths of this method by focusing on nonequilibrium polaron relaxation and transport in the dispersive Holstein model, successfully simulating lattice dynamics in one and two dimensions free from finite-size effects, reducing the computational expense of such simulations by multiple orders of magnitude. Our method is broadly applicable and provides an accurate and efficient means to investigate nonequilibrium relaxation with microscopic resolution over mesoscopic length and time scales that are relevant to experiment.","Lattice models play a key role in understanding physical and chemical phenomena. For instance, the Holstein Holstein (1959a, b) and Fröhlich Fröhlich (1954) models shed light on polaron formation and electrical transport in semiconductors Hulea et al. (2006); Fetherolf, Golež, and Berkelbach (2020), the Hubbard model Hubbard (1963) helps elucidate the mechanisms of high-temperature superconductivity Arrigoni, Fradkin, and Kivelson (2004), and the Ising model Ising (1925) is used to interrogate magnetism Newell and Montroll (1953) and phase transitions Dziarmaga (2005). However, while modern algorithms can efficiently simulate the quantum dynamics of small lattices over short times Tanimura and Kubo (1989); Makri and Makarov (1995); Wang, Thoss, and Miller (2001); Thoss, Wang, and Miller (2001); Suess, Eisfeld, and Strunz (2014); Wang (2015); De Vega and Bañuls (2015); Strathearn et al. (2018); Tamascelli et al. (2019); Schröder et al. (2019); Xie et al. (2019); Kloss, Reichman, and Tempelaar (2019); Makri (2021); Bose and Walters (2022); Gribben et al. (2022); Fux et al. (2023); Lacroix et al. (2024), reaching sufficiently large systems and long times to compare to experiments remains a fundamental challenge. is is because these methods often scale exponentially or, at best, polynomially with lattice size and simulation time, rendering the thermodynamic limit inaccessible. The severity of this limitation becomes clear when calculating dynamic properties, e.g., conductivities, viscosities, and diffusion constants, which are sensitive to finite-size effects Kikugawa, Nakano, and Ohara (2015); Simonnin et al. (2017); Cox and Geissler (2018); Jamali et al. (2018); Samanta, Ghosh, and Mohanty (2018); Bertini et al. (2021); Celebi et al. (2021); Cox and Geissler (2022). For example, finite-size effects can cause simulations to underestimate diffusion constants of polymers near the glass-transition Ray and Binder (1994), relaxation times of glass-forming liquids Berthier et al. (2012), the Curie temperature for Ni nanoparticles Dos Santos, Urbassek, and Bringa (2024), and the diffusion constant and viscosity of model fluids Yeh and Hummer (2004); overestimate the critical fermion-phonon coupling causing the metal-to-Peierls phase transition in a Holstein-Hubbard lattice Hébert et al. (2019); and yield apparently non-converging mobilities of dispersive Holstein polarons Bhattacharyya, Sayer, and Montoya-Castillo (2024a). These examples reveal the need of computing the dynamics of lattice models in thermodynamically large systems over long timescales. Generalized Master Equations (GMEs) have emerged as a powerful tool for reducing the computational cost of dynamical simulations Shi and Geva (2003, 2004); Zhang, Ka, and Geva (2006); Cohen and Rabani (2011); Cohen, Wilner, and Rabani (2013); Kelly and Markland (2013); Kidon, Wilner, and Rabani (2015); Kelly, Brackbill, and Markland (2015); Kelly et al. (2016); Montoya-Castillo and Reichman (2016, 2016); Pfalzgraff et al. (2019); Mulvihill et al. (2019); Ng, Limmer, and Rabani (2021); Mulvihill and Geva (2022); Amati et al. (2022); Lyu et al. (2023); Wang et al. (2023); Sayer and Montoya-Castillo (2023, 2024a, 2024b). GMEs are exact non-Markovian equations of motion for nonequilibrium averages, correlation functions, and even multi-time correlators of select variables that encapsulate the effects of an environment into a memory kernel Nakajima (1958); Zwanzig (1960); Mori (1965). In dissipative systems, the memory kernel decays to zero over a finite memory lifetime, which can be shorter than the relaxation time of the desired correlation function. Thus, in principle, one can use a reference simulation over the memory lifetime to construct a GME that predicts the dynamics of the desired correlation function to arbitrarily long times. This temporal truncation of memory at its lifetime can reduce the computational cost of simulating the quantum or classical dynamics of complex many-body systems in different problems, including charge transfer reactions in solution Pfalzgraff, Kelly, and Markland (2015); Liu, Mulvihill, and Geva (2024), protein folding Cao et al. (2020); Dominic et al. (2023); Cao et al. (2023), nonlinear spectroscopy Ivanov and Breuer (2015); Sayer and Montoya-Castillo (2024a), and transport Yan et al. (2019); Bhattacharyya, Sayer, and Montoya-Castillo (2024b). However, to construct a GME from a short-time reference simulation, it must satisfy two conditions: (1) the simulation time must span the memory kernel lifetime, and (2) the reference calculation must be performed in the same system whose dynamics one intends to interrogate with the GME. If one constructs a GME using a small lattice simulation, particles encounter the lattice boundaries and manifest finite-size effects: one reduces the cost but still obtains the wrong answer. Hence, one must be able to afford an admittedly short-time reference simulation, but of a thermodynamically large lattice. The poor scaling of dynamical methods with system size renders this calculation at best impractical and at worst impossible. Here, we propose a novel approach to lattice problems that exploits our observation that certain GME formulations display a finite spatial memory to motivate truncating memory in time and space. This allows us to employ short-time reference simulations of small lattices to generate the exact quantum dynamics of thermodynamically large lattices over arbitrarily long times for the cost of only the small reference calculation. We demonstrate the strengths of this method by applying it to nonequilibrium polaron formation and transport in dispersive Holstein lattices. Enabled by our space-local GME, we simulate, for the first time, the exact nonequilibrium quantum dynamics of small polaron formation, relaxation, and flow in thermodynamically large one-(1D) and two-dimensional (2D) lattices with up to 900 sites over 100 ps, free of finite-size contamination. Our method is model-agnostic and can be expected to enable the efficient investigation of nonequilibrium excitation dynamics in dissipative lattices displaying local interactions."
https://arxiv.org/html/2411.08226v1,Cholesky Decomposition and the Second-Derivative Two-Electron Integrals Required for the Computation of Magnetizabilities using Gauge-Including Atomic Orbitals,"The computation of magnetizability tensors using gauge-including atomic orbitals is discussed in the context of Cholesky decomposition for the two-electron repulsion integrals with a focus on the involved doubly differentiated integrals. Three schemes for their handling are suggested: the first exploits the DF aspect of Cholesky decomposition, the second uses expressions obtained by differentiating the CD expression for the unperturbed two-electron integrals, while the third addresses the issue that the first two schemes are not able to represent the doubly differentiated integrals with arbitrary accuracy. This scheme uses a separate Cholesky decomposition for the cross terms in the doubly differentiated two-electron integrals. Test calculations reveal that all three schemes are able to represent the integrals with similar accuracy and yield indistinguishable results for the values of the computed magnetizability tensor elements. Thus, we recommend our first scheme which has the lowest computational cost for routine computations. The applicability of our CD schemes is further shown in large-scale Hartree-Fock calculations of the magnetizability tensor of coronene (C24H12) with a doubly polarized triple-zeta basis consisting of 684 basis functions.","Cholesky decomposition (CD) of the two-electron repulsion integrals has been proven an efficient means for speeding up quantum-chemical computations, thus enabling the quantum-chemical treatment of larger molecules.1 CD of the two-electron integrals was first proposed by Beebe and Linderberg2 in the 1970ies. Koch et al. have later demonstrated the great potential of this idea for quantum-chemical computations.3 Today, CD is used to enable large-scale second-order Møller-Plesset (MP2) perturbation theory,3, 4, 5, 6 multiconfigurational self-consistent-field,7, 8 multiconfigurational second-order perturbation theory,9 and coupled-cluster (CC) treatments.10, 11, 12, 13, 14, 15, 16, 17, 18 The key idea of the CD of two-electron integrals is that the two-electron integrals as four-index quantities are represented as a product of three-index quantities, i.e., the so-called Cholesky vectors, which are obtained by applying a decomposition first proposed by Cholesky19 to the symmetric and semi-positive definite two-electron integral matrix. In this way, the cost for evaluating the two-electron integrals is reduced (as only a subset of them needs to be computed), I/O bottlenecks are avoided (as the resulting Cholesky vectors can typically be held in memory unlike the full set of two-electron integrals), and the resulting programs can be parallelized rather easily. In recent years, further improvements to the CD scheme have been suggested; noteworthy is here in particular the idea20, 21, 22, 23 to replace the original one-step decomposition procedure by a two-step scheme, in which the Cholesky basis for the decomposition is determined in a first step and the actual Cholesky vectors are computed in the second step. While CD is nowadays routinely used in quantum-chemical computations of energies and wave functions,1 the use of CD in the computation of molecular properties is less explored. Schemes have been suggested for the computation of nuclear forces 24, 25, 26, 27 required for geometry optimizations and the computation of nuclear magnetic resonance (NMR) shielding constants.28, 29, 23 The quantum-chemical calculation of both properties involve the computation of differentiated two-electron integrals. The challenge is, how one deals with the differentiated two-electron integrals in the CD context. CD cannot be applied directly to differentiated two-electron integrals, because their matrix representation does not constitute a symmetric/Hermitian semi-positive definite matrix. However, CD expressions for differentiated two-electron integrals can be obtained by differentiating the original CD expression for the undifferentiated two-electron integrals. It has been demonstrated that this idea works well for nuclear forces and NMR shielding constants and provides appropriate expressions for differentiated Cholesky vectors. Some reorganization of the obtained expressions allow computational improvements and in particular a further reduction of the computational cost.23, 26 The use of CD in computations that require second derivatives of the two-electron integrals, has so far not been investigated. The interesting question is here whether for those integrals suitable CD expressions can be obtained via differentiation. To a certain extent, this depends also on the objective: Do we want to obtain a good approximation to the results (integrals, values for properties) obtained in computation without CD (in our opinion, what one should aim for) or yield just the correct second derivative of the energy within the CD procedure. In this paper, we explore the use of CD for the computation of the second derivatives of the two-electron integrals with respect to an external magnetic field. These derivative integrals are required for the computation of the magnetizability tensor30, 31 when using gauge-including atomic orbitals (GIAOs).32, 33, 34, 35, 36, 37 We discuss the challenges and offer solutions which enable treatments consistent with the overall CD procedure."
https://arxiv.org/html/2411.08213v1,"Quantum electrodynamic corrections for molecules:
Vacuum polarisation and electron self energy in a two-component
relativistic framework","Vacuum polarisation (VP) and electron self energy (SE) are implemented and evaluated as quantum electrodynamic (QED) corrections in a (quasi-relativistic) two-component zeroth order regular approximation (ZORA) framework. For VP, the Uehling potential is considered, and for SE, the effective potentials proposed by Flambaum and Ginges as well as the one proposed by Pyykkö and Zhao. QED contributions to ionisation energies of various atoms and group 2 monofluorides, group 1 and 11 valence orbital energies, {}^{2}\mathrm{P}_{1/2}\leftarrow{}^{2}\mathrm{S}_{1/2} and {}^{2}\mathrm{P}_{3/2}\leftarrow{}^{2}\mathrm{S}_{1/2} transition energies of Li-, Na-, and Cu-like ions of nuclear charge Z = 10, 20, …, 90 as well as \Pi_{1/2}\leftarrow\Sigma_{1/2} and \Pi_{3/2}\leftarrow\Sigma_{1/2} transition energies of BaF and RaF are presented. Furthermore, perturbative and self-consistent treatments of QED corrections are compared for Kohn–Sham orbital energies of gold. It is demonstrated, that QED corrections can be obtained in a two-component ZORA framework efficiently and in excellent agreement with corresponding four-component results.","Relativistic effects play a crucial role for the quantitative description of heavy-element containing molecules Pyykkö (1988, 2012). The usual starting point for a relativistic description of the electronic motion in a molecule is the free-particle Dirac equation Dirac (1928a, b) combined with a classical Coulomb-type potential for the description of leading order particle-particle interactions Saue (2011). This formalism describes the motion of electrons in accord with special relativity, but not its interactions, which are due to the Coulomb potential instantaneous. Within quantum electrodynamics (QED), i.e. the relativistic theory of the electromagnetic force, interactions are not instantaneous but are mediated by virtual photons at the speed of light. Therefore, the Coulomb potential arises only as leading order contribution to the electromagnetic particle-particle interaction in a perturbation theory expansion in the fine-structure constant. Largest QED effects are expected for the electron-nucleus potential Greiner and Reinhardt (2009), to which we will refer in the following exclusively and as retardation effects of the electron-electron interactions. The latter are however usually not as important as QED corrections of the electron-nucleus potential. Larger corrections to the electron-electron interactions are expected via the Breit interaction Breit (1929), which appears due to consideration of current-current interactions and the inclusion of the correct gauge of the interaction within a Lorentz invariant framework. Photon-frequency dependent retardation corrections to the Breit interaction are usually less important than QED corrections of the electron-nucleus potential considered in this work. It is expected that QED corrections reduce the total relativistic effects by about 1 % in heavy atom containing-molecules Indelicato et al. (2011); Pyykkö (2012). For the hydrogen atom this QED correction of the electron-nucleus potential leads to the so-called Lamb shift, which splits n\mathrm{s}_{1/2} and n\mathrm{p}_{1/2} states in one-electron systems Lamb and Retherford (1947). In the search for new physics beyond the standard model, high-precision spectroscopy is an essential tool to test the fundamental symmetries, such as space- and time-reversal parity and its violations Safronova et al. (2018); Berger and Stohner (2019). Because of the numerically small effects, it is important to investigate systems with a number of traits, which enhance effects of these violations. Certain molecules are particularly suited for such purposes. One promising candidate is radium monofluoride (RaF). It was first proposed because of its predicted nuclear-spin-dependent parity violation and expected suitability for laser cooling Isaev et al. (2010); Isaev and Berger (2013). The pear-shaped octupole deformation Gaffney et al. (2013); Butler et al. (2020) of the heavy 222,224,226Ra isotopes enhances symmetry violation effects further. Synthesis of the open-shell short-lived isotopically pure radioactive RaF molecules and successive spectroscopy was first achieved with the collinear resonance ionisation spectroscopy (CRIS) method at the ISOLDE ion-beam facility at CERN Garcia Ruiz et al. (2020). Applicable for other molecules, such as RaOH, RaO, RaH, AcF and ThO, and nuclei with half-lives of just milliseconds, it paved the way for high-precision spectroscopy of radioactive isotope containing molecules. In recent experiments, the rovibronic structure of 226Ra19F was obtained with a resolution, which is two orders of magnitude larger compared to previous experiments Udrescu et al. (2024). Also, eleven electronic states and excitations were reported Athanasakis-Kaklamanakis et al. (2023). Thus, theoretical predictions and proposals of suited molecules for precision tests play an essential role. However, as the experiments have reached unprecedented accuracies, and the investigated symmetry violations are even smaller, it is necessary to develop sophisticated theoretical frameworks further as well. While QED corrections have been studied in atoms for a long time Mohr (1974a); Blundell (1993); Schneider et al. (1994); Mohr et al. (1998); Sunnergren et al. (1998); Labzowsky et al. (1999); Artemyev et al. (2005); Karshenboim (2005); Indelicato et al. (2007); Thierfelder and Schwerdtfeger (2010); Shabaev et al. (2013); Schwerdtfeger et al. (2015); Ginges and Berengut (2016a, b); Smits et al. (2023), they have gained attention in molecular frameworks only recently Kozioł et al. (2018); Sunaga and Saue (2021); Skripnikov et al. (2021); Sunaga et al. (2022); Zaitsevskii et al. (2022); Colombo Jofré et al. (2022); Flynn et al. (2024a, b). In high-precision calculations of atoms, the leading order QED corrections have shown to be the missing contributions to the first ionisation energy and electron affinity of the gold atom in order to reach meV accuracy, compared to the experimental values Pašteka et al. (2017). Pašteka et al. also noted, that higher excitations in the coupled cluster (CC) method have less impact on the result, compared to the QED corrections. Because QED contributions grow with increasing nuclear charge, as they are relativistic effects, they are expected to contribute mainly to molecules containing heavy nuclei such as RaF. Overall, the effects in molecules and the influence on properties are largely unknown and it is thus desirable to have efficient, yet accurate, options to approximate the corrections reliably. In this work, the leading order QED corrections are included as effective potentials within the two-component ZORA framework. Within this framework, one can obtain accurate results for the QED corrections, although the overall error of ZORA, compared to four-component approaches, is in the same order of magnitude. This incremental approach allows for an efficient treatment of QED effects in atoms and molecules, suited to predict size, trends and relevance. Results of variational and perturbative treatments are compared to four-component variational and numerical Dirac-Hartree-Fock (DHF) calculations."
https://arxiv.org/html/2411.08209v2,Understanding failures in electronic structure methods arising from the geometric phase effect,"We show that intermediate normalization of the electronic wave function, where a constant component is enforced, will lead to an asymptotic discontinuity at one point along any path that encloses a ground state conical intersection. For some electronic structure methods, this gives rise to severe global artifacts in the ground and excited state potential energy surfaces. We investigate how this affects two electronic structure methods: coupled cluster theory and Møller-Plesset perturbation theory. The analysis suggests that intermediate normalization is problematic not only in near-degenerate regions, such as in the vicinity of conical intersections. In particular, since problems will occur for any path that encloses a ground state intersection, the affected methods can unexpectedly break down in regions of internal coordinate space that are normally considered within their range of validity.","Analytical model It is instructive to first consider a two-state Hamiltonian where the two states are the ground and the first excited state. In the case of a real Hamiltonian, we write \displaystyle\boldsymbol{H}=\begin{pmatrix}v&0\\ 0&v\end{pmatrix}+\begin{pmatrix}w&h\\ h&-w\end{pmatrix}=v\boldsymbol{I}+\boldsymbol{H}_{c}. (4) The eigenvectors of \boldsymbol{H} are uniquely determined by \boldsymbol{H}_{c} and the v\boldsymbol{I} term only provides a constant shift of the energies. We will therefore restrict our analysis to \boldsymbol{H}_{c}. Considering \boldsymbol{H}_{c}, we can express its eigenvectors and eigenvalues using polar coordinates, \displaystyle w=r\cos 2\vartheta,\quad h=r\sin 2\vartheta. (5) Note that \vartheta=0 to \vartheta=\pi corresponds to a full revolution about the origin. The eigenvalues and eigenvectors are \lambda_{\pm}=\pm r=\pm\sqrt{w^{2}+h^{2}} and \displaystyle\boldsymbol{v}_{-}(\vartheta)=\begin{pmatrix}-\sin\vartheta\\ \cos\vartheta\end{pmatrix},\quad\boldsymbol{v}_{+}(\vartheta)=\begin{pmatrix}% \cos\vartheta\\ \sin\vartheta\end{pmatrix} (6) respectively. This provides a useful framework for investigating the phase effect associated with degeneracies because a path about a degeneracy in internal coordinate space corresponds to a path about the (w,h) origin.8, 9, 10 Indeed, by varying \vartheta from 0 to \pi (corresponding to a full revolution about the degeneracy), we find that the eigenvectors continuously change their sign upon returning to the same point: \displaystyle\boldsymbol{v}_{\pm}(\pi)=-\boldsymbol{v}_{\pm}(0). (7) This is the geometric phase effect. Intermediate normalization changes this analysis in important ways. When \displaystyle\tilde{\boldsymbol{v}}_{\pm}(\vartheta)=N_{\pm}(\vartheta)% \boldsymbol{v}_{\pm}(\vartheta),\quad N_{-}(\vartheta)=-\frac{1}{\sin\vartheta% },\quad N_{+}(\vartheta)=\frac{1}{\cos\vartheta}, (8) we can ensure that the first component of both eigenvectors always has the same weight: \displaystyle\tilde{\boldsymbol{v}}_{-}(\vartheta)=\begin{pmatrix}1\\ -\cot\vartheta\end{pmatrix},\quad\tilde{\boldsymbol{v}}_{+}(\vartheta)=\begin{% pmatrix}1\\ \tan\vartheta\end{pmatrix}. (9) However, the norm of these vectors diverges at the points where the first component of the normalized vectors goes through zero, and in these points, the sign of the diverging component changes discontinuously. These asymptotic discontinuities are shown in Fig. 2. We note that any path around the origin will pass through one such point. The result is a plane of asymptotic discontinuities (see also Fig. 1). Figure 2: A. The energies \lambda_{\pm} in the (w,h) plane. B. The diverging component of the intermediately normalized ground state \tilde{\boldsymbol{v}}_{-} in the (w,h) plane. A similar divergence occurs for the excited state \tilde{\boldsymbol{v}}_{+}. The plane where the divergence occurs is shown in blue."
https://arxiv.org/html/2411.08207v2,"Determining minimum energy conical intersections by enveloping the seam:
exploring ground and excited state intersections in coupled cluster theory","Minimum energy conical intersections can be used to rationalize photochemical processes. In this Letter, we examine an algorithm to locate these structures that does not require the evaluation of nonadiabatic coupling vectors, showing that it minimizes the energy on hypersurfaces that envelop the intersection seam. By constraining the states to be separated by a small non-zero energy difference, the algorithm ensures that numerical artifacts and convergence problems of coupled cluster theory at conical intersections are not encountered during the optimization. In this way, we demonstrate for various systems that minimum energy conical intersections with the ground state are well described by the coupled cluster singles and doubles model, suggesting that coupled cluster theory may in some cases provide a good description of relaxation to the ground state in nonadiabatic dynamics simulations.","Author contributions SA and EFK conceived the project and performed calculations. HK supervised the project. SA and HK analyzed the results and wrote the first draft of the manuscript. All authors discussed and revised the manuscript. {acknowledgement} We thank Marcus T. Lexander and Federico Rossi for enlightening discussions. This work was supported by the European Research Council (ERC) under the European Union’s Horizon 2020 Research and Innovation Program (grant agreement No. 101020016). {suppinfo} Study of the convergence of the algorithm, comparison of CCSD and SCCSD S1/S2 \varepsilon-MECIs for uracil, and additional data for the S0/S1 \varepsilon-MECIs for uracil and azobenzene."
https://arxiv.org/html/2411.08065v1,h-CMD: An efficient hybrid fast centroid and quasi-centroid molecular dynamics method for the simulation of vibrational spectra,"Developing efficient path integral (PI) methods for atomistic simulations of vibrational spectra in heterogeneous condensed phases and interfaces has long been a challenging task. Here, we present the h-CMD method, short for hybrid centroid molecular dynamics, that combines the recently introduced fast quasi-CMD (f-QCMD) method with fast CMD (f-CMD). In this scheme, molecules that are believed to suffer more seriously from the curvature problem of CMD, e.g., water, are treated with f-QCMD, while the rest, e.g., solid surfaces, are treated with f-CMD. To test the accuracy of the newly introduced scheme, the infrared spectra of the interfacial D2O confined in the archetypal ZIF-90 framework are simulated using h-CMD compared to a variety of other PI methods, including thermostatted ring-polymer molecular dynamics (T-RPMD) and partially adiabatic CMD as well as f-CMD and experiment as reference. Comparisons are also made to classical MD, where nuclear quantum effects are neglected entirely. Our detailed comparisons at different temperatures of 250-600 K show that h-CMD produces O–D stretches that are in close agreement with the experiment, correcting the known curvature problem and red-shifting of the stretch peaks of CMD. h-CMD also corrects the known issues associated with too artificially dampened and broadened spectra of T-RPMD, which leads to missing the characteristic doublet feature of the interfacial confined water, rendering it unsuitable for these systems. The new h-CMD method broadens the applicability of f-QCMD to heterogeneous condensed phases and interfaces, where defining curvilinear coordinates for the entire system is not feasible.","Liquid-air, liquid-liquid, and liquid-solid interfaces play critical roles in various chemical, biological, materials, and environmental processes. Vibrational infrared (IR) spectroscopy provides a wealth of information about interactions of molecules in condensed phases and at different interfaces, especially in aqueous environments.Sharma et al. (2008); Le Caër et al. (2011); Catafesta et al. (2014); Perakis et al. (2016) Specifically, IR spectra can reveal key fundamental insights into the complex hydrogen bond (HB) network of water and how it is influenced by temperature, pH, reducing or oxidizing potentials, and the presence of different ions, among others. Reliable atomistic molecular dynamics (MD) simulation of vibrational spectra requires an efficient way of incorporating nuclear quantum effects (NQEs). However, while the role of NQEs in chemical and material sciences is a widely acknowledged fact, the development of efficient computational methods and software platforms capable of incorporating them into MD simulations of complex systems has been a challenging task.Markland and Ceriotti (2018) Path-integral approaches, including path-integral MD (PIMD)Parrinello and Rahman (1984), centroid MD (CMD),Cao and Voth (1994a, b, c, d) and ring polymer MD (RPMD),Craig and Manolopoulos (2004, 2005a, 2005b) as well as a myriad of more sophisticated methods branched from them,Habershon et al. (2013) have emerged as the leading platform for the incorporation of NQEs in large-scale condensed-phase simulations. In these methods, NQEs are captured using Feynman’s imaginary-time path-integral formalism Feynman and Hibbs (1965); Feynman (1972) by taking advantage of the so-called isomorphism between the quantum-mechanical partition function and the partition function of a classical ring polymer (RP). Every nuclear degree of freedom (DOF) is represented by an RP comprised of n copies of the system, known as “beads”, connected by harmonic springs. The extended phase space of this RP captures NQEs, such as zero-point energy and nuclear tunneling. Hence, accurate yet computationally efficient path integral (PI) techniques provide powerful alternatives to prohibitively expensive full quantum-mechanical dynamical simulations. However, when it comes to calculating the IR spectra of complex heterogeneous condensed phases and interfaces, the quantum dynamic community has struggled to propose a computationally efficient PI method that can accurately capture NQEs, which are more pronounced in spectra than other structural and dynamical properties. One of the most well-known formalisms to approximate the real-time dynamics while incorporating NQEs in the PI framework is CMD. In CMD, the dynamics of the particles are performed under the effective mean-field potential of the imaginary-time path-integral whose centroid is constrained to be at the position of the particle. For low dimensional systems, this effective potential can be calculated on a grid prior to dynamical simulations, while for large systems, it must be calculated “on-the-fly,” which is referred to as adiabatic CMD (ACMD).Cao and Voth (1994c) This is achieved by introducing an adiabatic separation between the centroid and internal modes by using the physical mass of the particle as the centroid mass, scaling down the mass of the internal modes of the RP, and attaching them to a thermostat so that they sample the equilibrium distribution while being constrained to the position of the slower moving centroid.Cao and Voth (1994c) Full adiabatic separation in CMD requires a very small mass for the internal modes and, thus, a very small simulation time step for the dynamics to be accurate. The computational cost associated with such choices led to the development of the partially adiabatic CMD (PA-CMD) method, where the mass scaling is not as extreme, allowing for a larger time step while still providing accurate dynamics.Hone, Rossky, and Voth (2006) Further work in reducing the computational cost of CMD comes in the form of fast CMD (f-CMD), where the effective potential is learned beforehand from PIMD simulations using force matching to create a new classical analytical force field Hone, Izvekov, and Voth (2005) or neural network potential (NNP) Loose, Sahrmann, and Voth (2022). It has been documented that vibrational spectra calculated using CMD methods exhibit red-shifting of peaks, primarily of stretch bands, which is worsened with the lowering of temperatures and/or for lighter particles.Ivanov et al. (2010) This phenomenon, dubbed the “curvature problem”, is a result of the RP spreading out along the angular coordinates of a system when approaching the inside of the stretching coordinates. This stretching reduces the force along the stretching coordinate, lowering the oscillation frequency of that coordinate and red-shifting the spectra. One approach to overcome the curvature problem is the quasi-centroid MD (QCMD) method introduced by Althorpe and coworkers. Trenins, Willatt, and Althorpe (2019a); Haggard et al. (2021); Trenins, Haggard, and Althorpe (2022a) QCMD works by defining a quasi-centroid (QC) for the molecule using curvilinear coordinates and determining the effective mean-field potential using an imaginary time RP that has its QC constrained to the particle position as opposed to its Cartesian centroid. Trenins, Willatt, and Althorpe (2019a) The resulting potential does not exhibit the same flattening on the inside of stretching curves as in CMD and thus does not have the red-shifting of vibrational spectra. The original adiabatic implementation of QCMD does not lend itself to scaling to complex chemical systems due to computational complexity and cost. Trenins, Willatt, and Althorpe (2019a); Trenins, Haggard, and Althorpe (2022a) Inspired by the f-CMD approach, Manolopoulos and coworkers developed the f-QCMD method. Fletcher et al. (2021); Lawrence et al. (2023a) In f-QCMD, a corrective potential to the classical force field is learned to create QCMD-like dynamics in classical simulations, but the corrections are found using iterative Boltzmann inversion (IBI) Soper (1996); Reith, Pütz, and Müller-Plathe (2003) on a set of distribution functions instead of force matching. While f-QCMD has shown reduced computational cost compared to QCMD, Fletcher et al. (2021); Lawrence et al. (2023a) determining the distribution functions for large molecules/frameworks poses a challenge. In a similar vein, Kapil and coworkers developed the temperature elevation PI coarse-graining simulations (Te PIGS) method. Musil et al. (2022) Like with some f-CMD implementations, a classical NNP is learned through force matching a PIMD simulation to incorporate NQEs. However, the PIMD simulations are performed at a high temperature where the RP distribution is more compact. Musil et al. (2022) The resulting NNP is then used for calculating vibrational spectra at lower temperatures without the curvature problem of CMD. Musil et al. (2022) While offering a simpler implementation for complex systems compared to f-QCMD, performing the high-temperature simulations to obtain the NNP could pose challenges for delicate systems or when using an NNP for the PIMD simulation where bond breaking/forming is possible at high temperatures. Here, to circumvent the curvature problem and create an accurate yet efficient scheme for calculating vibrational spectra of complex condensed phases and interfaces, we have devised a new method coined hybrid CMD (h-CMD) that combines f-QCMD and f-CMD methods. This method allows us to simulate interfacial systems involving complex frameworks with high accuracy for the most important degrees of freedom and reduced complexity for the others. To bring f-QCMD and f-CMD methods on equal computational footing, the latter f-CMD method is implemented with the regularized IBI method used in f-QCMD. We showcase the accuracy of our new hybrid h-CMD method on simulating IR spectra of D2O confined in zeolitic-imidazolate framework-90 (ZIF-90) compared to the experiment as reference. By comparing the spectra using our hybrid h-CMD method to PA-CMD and T-RPMD, as well as f-CMD and classical MD at different temperatures, we provide detailed insights into the applicability of this new scheme to complex interfaces. This work is structured as follows: In Section II, we outline our h-CMD method, followed by the methods used for calculating vibrational spectra. Simulation details are provided in Section III. In section IV, we provide our detailed analyses of the IR spectra of interfacial D2O confined in ZIF-90 at different temperatures, followed by conclusions and future works."
https://arxiv.org/html/2411.08058v1,"Enzymatic Mpemba Effect:
Slowing of biochemical reactions by increasing enzyme concentration","Increasing the enzyme concentration generally speeds up enzymatic reactions. However, in this Letter, we show that increasing the enzyme concentration can also slow down the enzymatic reaction. We consider a simple allosteric protein with multiple modification sites, catalyzed by two enzymes with the same catalytic activity, but slightly different affinities. We show that increasing the concentration of one enzyme can slow the relaxation to the equilibrium state. The mechanism for this slowing is similar the Markovian Mpemba effect, and we name this phenomenon as the Enzymatic Mpemba effect.","Appendix A Derivation of the binding probability of an enzyme We consider the probability of binding of only a single enzyme. Proteins with the different number of relaxed monomers have different binding energies, and a binding energy of the enzyme j to a substrate in the \sigma=i state is given by E^{\mathrm{b}j}_{i}. Therefore, the grand partition function and the average number of binding enzymes \langle N_{{\mathrm{E}nz}j}\rangle in equilibrium are represented in a similar manner as Langmuir’s adsorption isotherm and are given by \displaystyle\Xi \displaystyle= \displaystyle\prod_{i=0}^{M}\left\{1+\exp\left[\beta\left(E^{\mathrm{b}j}_{i}+% \mu\right)\right]\right\}^{N_{i}}, (6) \displaystyle\langle N_{\mathrm{Enz}j}\rangle \displaystyle= \displaystyle\sum_{i=0}^{M}N_{i}\frac{\exp(\beta\mu)}{\exp\left(-\beta E^{% \mathrm{b}j}_{i}\right)+\exp(\beta\mu)}, (7) where N_{i} is the number of substrate in the \sigma=i state. For both in vivo and in vitro reactions, N and N_{\mathrm{Enz}j} are almost constant and are the control parameters of the system. Here, we assume that \langle N_{\mathrm{Enz}j}\rangle is the same as N_{\mathrm{Enz}j}, and that the chemical potential \mu is a function of N_{\mathrm{Enz}j} and \{N_{i}\}. This assumption is justified when N and N_{\mathrm{Enz}j} are sufficiently large, i.e., at the thermodynamic limit. Then, the chemical potential \mu can be calculated from Eq. 7. Note that, in the limit N_{\mathrm{Enz}j}\rightarrow N, \mu approaches -\infty, and all molecules bind to the enzyme. The arguments so far can be summarized to give the binding probability p^{\mathrm{b}j}_{i}=\frac{\langle N_{\mathrm{Enz}j,i}\rangle}{N_{i}}=\frac{% \exp(\beta\mu)}{\exp\left(-\beta E^{\mathrm{b}j}_{i}\right)+\exp(\beta\mu)}, (8) where N_{\mathrm{Enz}j,i} is the number of enzyme j that bind to the a substrate in the \sigma=i state."
https://arxiv.org/html/2411.08153v1,"Leidenfrost drop dynamics: 
An approach to follow the complete evolution","A new model to follow the complete evolution of a drop in Leidenfrost state is presented in this work. The main ingredients of the phenomenon were considered, including: 1) the shape and weight of a sessile drop, according to its size, compared to the capillary length, using the Young-Laplace equation; 2) the evaporation at the entire surface of the drop, due to the heat transfer across the vapor film, to the proximitiy of a hot plate and to the diffusion in air; 3) the velocity, pressure and temperature fields at the vapor film, between the drop and the hot plate, which are recovered by means of a Hankel transform method, being valid for any size of drops and any thickness of vapor films (below the vapor film stability threshold); 4) an estimation of the thermo-capillary Marangoni convection flow, without simulating numerically the flow within the drop. The aforementioned features were addressed and calculated, in order to include their effect within a single non-linear ODE, describing the temporal evolution of the size of the drop, through the Bond number. Three dimensionless parameters, relating the thermophysical properties of the drop fluid and the surrounding air, control the development of the phenomenon. All those properties were calculated according to the ideal gas approximation and to widely used empirical correlations, without any fitting parameter. The model predictions were compared against experimental results, using different organic and inorganic compounds, for which a good agreement has been found, when no bounce or rotation of the drop spontaneously occurs","The first observations of a liquid drop levitating over a hot plate, due to the generation of a vapor cushion beneath the drop, were made more than 250 years ago [1]. Nowadays, a very large number of documents addressing different phenomena related to the Leidenfrost effect on drops can be found in the literature [2, 3, 4]. Self-propulsion [5, 6, 7, 8, 9, 10, 11], jumping [12, 13, 14, 15], shape oscillation [16, 17, 18, 19, 20], and multi-component interaction [21, 22, 23] are a few examples of the topics that had been derived from the study of single drops in the Leidenfrost state. In the past two decades, several attempts had been performed to predict the complete dynamics of Leidenfrost drops, considering direct numerical simulations [24, 25, 26, 27, 28, 29] and analytic models [30, 31, 32, 33]. Numerical simulations solve for the motion and temperature distribution both within the vapor and the internal liquid, by means of multiphase techniques, phase change models and by possibly taking into account more complex effects such as Marangoni convection. They are particularly challenging to perform, and imply significant computation power and time, due to the multiscale nature of the problem, since the vapor film between the drop and the hot plate can be several orders of magnitude smaller than the drop. Therefore, extremely fine spatial grids are required in the film region, as well as the use of very small time steps to capture the drop dynamics, for stability purpose of the numerical method. Thus, functionality of such numerical simulations depends as much on the mesh density, within the vapor domain and at the liquid-vapor interface, as on the reliability of the numerical methods to capture a two-phase flow with jump conditions at the interface, related to phase change. However, accurate numerical simulations are highly valuable to evaluate the relative importance of different phenomena in the dynamics of the levitating droplets, through comparisons with experimental data. For instance, recent numerical simulations from Mialhe et al. [29] have revealed that thermo-capillary effects are important for setting the film thickness between the drop and the substrate: the Marangoni convection, induced by temperature gradients along the interface, induces a significant internal circulation in the droplet, which favors the drainage rate of the film, making it to be thinner when this effect is accounted for, consistently with experimental results [12]. Such comparisons, to validate the impact of different phenomena, can also be performed between experiments and simplified theoretical models that describe the shape of the drop and the motion of the vapor, which are also highly interesting due to the wide range of thermophysical mechanisms that are involved in the phenomenon. In this way, some theoretical studies focus on the geometry, as well as the stability of the vapor film [34, 35, 36], considering a snapshot of the drop at a given time during its evaporation. A precise instantaneous description of the liquid-vapor system is obtained by simultaneously solving the Young-Laplace equation and the lubrication approximation, while considering a constant evaporation flux. For instance, good agreement is observed on the geometrical characteristics of the vapor layer between prediction, from the theoretical approach of Sobac et al. [35], and experimental measurements, by interferometry of the bottom of water drops by Burton et al. [37]. Additionally, a main result of these kind of works is the maximum size, a radial extent of around 3.95 times the capillary length, before the vapor layer becomes unstable and vapor chimneys disturb the shape of the drop [34]. Other studies are directed towards the dynamics of Leidenfrost drops, considering the different heat transfer mechanisms that are involved. Based on a quasi-static approach, time-dependent scaling laws for the radius of the drops and the thickness of the vapor films were developed for the first time by Biance et al. [30]. The drop radius r_{\text{max}} and the vapor film thickness h evolve with time t, respectively as: \displaystyle r_{\text{max}}(t) \displaystyle=r_{\text{max},0}\left(1-\dfrac{t}{\mathcal{T}}\right)^{n}\ , (1a) \displaystyle h(t) \displaystyle=h_{0}\left(1-\dfrac{t}{\mathcal{T}}\right)^{m}\ , (1b) where \mathcal{T} is the lifetime of the drop and h_{0} is the initial film thickness, both related to the initial drop radius r_{\text{max},0}, the hot plate temperature T_{\text{p}} and the thermophysical properties of the fluid. For puddles, which are drops with an extent above the capillary length, the exponents take the values n=2 and m=n/2, whereas for marbles, which are quasi-spherical drops with a radius below the capillary length, n=1/2 and m=4n/3. It is also important to denote that \mathcal{T} and h_{0} have different definitions, according to the size of the drop, for instance \mathcal{T}\sim r_{\text{max},0}^{1/n}. In the aforementioned study, the evaporation and phase change at the base of the drops was considered for all the drop sizes, whereas the evaporation from the entire drop surface was only considered for marble drops. This characterization with decoupled regimes avoids following the complete dynamics of an above-millimeter-sized drop, from its deposition on the hot plate till its full evaporation, with a continuous transition between the dynamics of a puddle and a marble. Two recent works address the phenomenon based on simple arguments and ideas, for large drops with extents above the capillary length, both pointing towards power laws with the same description given by eqs. (1b). The first is a theoretical analysis with strong simplifications on the drop shape [38], considering a hemispherical geometry, which leads to different values of the exponents, i.e. n=4/5 and m=n/4, also with \mathcal{T}\sim r_{\text{max},0}^{1/n} and additional fitting results that are in the range n\in\left(0.9,1.5\right). Unfortunately, this model leads to estimates of the vapor thermal conductivity that are at least 3 orders of magnitude smaller than the values found in the literature. The second is an experimental analysis that, based on the observations and a linear fitting of the drop mass in terms of the area projected over the hot plate [39], leads to n=1 and \mathcal{T}\sim r_{\text{max},0}^{1/n} as well. Besides the dependence on several fitting parameters, this model yields an overall heat transfer coefficient that varies with the size of the drop and, as a consequence, with time. It is worth noting that both studies take into account the evaporation at the bottom of the drop, and the consequent generation of the vapor cushion, but neglect the evaporation from the top of the drop towards the surrounding air. However, it has been shown that evaporation takes place over the entire surface, and not only in the film, when the drop is small and quasi-spherical [40], even if the contribution from the vapor film is largely dominant in the case of puddles. Both phenomena should therefore be taken into account to develop a dynamic model of the evaporation of a drop in the Leidenfrost state. Another two works attempt to follow the complete drop dynamics, through models that consider a quasi-static evolution of the drops [31, 33]. The first employs the lubrication approximation and pure heat conduction at the vapor layer, which is considered to have a uniform thickness. Relatively large drops are considered in this work, starting from initial radii of around 3.95 times the capillary length. Two fitting parameters are employed, i.e. a substrate-to-vapor heat transfer coefficient and an evaporation rate [31]. The second also includes the lubrication approximation, and incorporates heat conduction and radiation at the vapor layer, which is considered to have a thickness that varies with the radial position, as a previous quasi-static study [35]. Additionally, mass diffusion is considered for the top region of the drops, but considering a spherical drop approach and the gas around the upper part of the drop as a pure vapor phase [33], which may not be the case in experiments. Besides, despite the completeness of this work, it is limited by reduced extents of the drops, which requires initial radii either around or below the capillary length. Evidently, in all the aforementioned studies [38, 39, 31, 33], there is partial agreement between the experimental results and the developed models, either because of the reduced range of application (small or large drops) or the employment of fitting parameters. To date, different power laws had been presented, and several models and procedures that work on limited ranges had been developed, but still a common basis for the complete evolution of Leidenfrost drops, with relatively large initial radii (up to 3.5 times the capillary length), has not been established yet. Among other outcomes of the phenomenon, the dependence of the lifetime of the drops on the different physical parameters, such as initial drop size and plate temperature, remains empirical. In a recent study [40], considering pure conduction at the air surrounding the drop, the drop lifetime \mathcal{T} has been overestimated with respect to experimental data. Simultaneously, the authors propose an empiric power law for \mathcal{T}: \displaystyle\mathcal{T} \displaystyle=aV_{0}^{n}\ , (2) where V_{0} is the initial volume, while a and n are fitting parameters. According to experimental results and a fitting procedure, a is strongly dependent on the temperature of the plate T_{\text{p}}, whereas n remains nearly constant. For instance a\approx 8.9\times 10^{4} s\cdotm-3n for T_{\text{p}}=470\,^{\circ}\text{C}, while a\approx 1.6\times 10^{5} s\cdotm-3n for T_{\text{p}}=300\,^{\circ}\text{C}, whereas n\approx 0.4 throughout the same temperature range. In another work from the same authors, the following power law is proposed to assess the dependence of the drop lifetime on the temperature difference [36]: \displaystyle\mathcal{T} \displaystyle=A\left(T_{\text{p}}-T_{\text{l}}\right)^{-3/4}\ , (3) where T_{\text{l}} is the drop temperature and A\approx 4.6\times 10^{4} s\cdot^{\circ}C3/4 is a fitting parameter for the same initial volume V_{0}\approx 1.5\times 10^{-4} m3. This relation shows a very good agreement with experimental data when increased gravity conditions are implemented and the puddle regime is observed for small volume drops, but, once more, overestimates the experimental lifetime of drops at normal gravity conditions. An estimation of the drop evolution and lifetime is essential for many applications, including friction reduction [41, 42], microfluidics [43, 44, 45, 46], and cooling techniques [47, 48], among other possible usages that are still unveiled. Therefore, further research is required to provide a complete description of the dynamics of Leidenfrost drops. In this study, we revisit the Leidenfrost effect, with the aim of developing a simple but effective strategy to estimate outputs, for instance the drop size dependence on time and its lifetime, in terms of the input parameters, such as the hot plate temperature and the thermophysical properties of the fluid. Considering that the flow and heat transfer at the vapor film occurs at a much shorter time scale than the size reduction of the drop due to the evaporation, a quasi-static approximation is employed to develop a complete dynamic model. For an axisymmetric configuration the following procedure is performed: 1) the Young-Laplace equation is solved to find the shape of the drop for a given volume; 2) a Stokes flow is obtained for the vapor film, that is generated from the evaporation at the bottom of the drop and is expelled radially due to the weight of the drop; 3) the temperature distribution at the vapor film is obtained from heat conduction; 4) the evaporation rate is deduced from the Stefan condition at the bottom of the drop, from the heat transfer at the lateral region of the lower hemisphere, and from the Stefan convective evaporation flow at the top hemisphere of the drop; 5) a mass balance is applied to follow the evolution of the drop. Compared to previous modelling approaches of the phenomena [31, 33], there is no lubrication assumption for the flow in the vapor film, the analytical model being thus valid without any limiting value of the film thickness compared to the drop radius, which allows to deal continuously with both puddles and quasi-spherical drops. Besides, different contributions for evaporation are systematically considered in the model (within the vapor film, in the upper part of the drop and at its lateral region), without assuming a pure vapor for the ambient gas in the neighboring of the northern drop hemisphere. This approach allows us to study the dynamics of a drop in Leidenfrost state, from its initial size and shape (above or below the capillary threshold) until it disappears due to its full evaporation. Experiments were carried out using seven fluids, to serve as a basis for assessing the relevance of the analytical model that is proposed. The latter is written in dimensionless form and can be easily extended, if further contributions need to be included such as radiation or natural convection effects, which have not been taken into account in the range of temperature explored in this investigation. It is important to mention that no fitting parameters are employed in the proposed methodology."
https://arxiv.org/html/2411.07831v1,Impact of dipole self-energy on cavity-induced nonadiabatic dynamics,"The coupling of matter to the quantized electromagnetic field of a plasmonic or optical cavity can be harnessed to modify and control chemical and physical properties of molecules. In optical cavities, a term known as the dipole self-energy (DSE) appears in the Hamiltonian to assure gauge invariance. The aim of this work is twofold. First, we introduce a method, which has its own merits and complements existing methods, to compute the DSE. Second, we study the impact of the DSE on cavity-induced nonadiabatic dynamics in a realistic system. For that purpose, various matrix elements of the DSE are computed as functions of the nuclear coordinates and the dynamics of the system after laser excitation is investigated. The cavity is known to induce conical intersections between polaritons, which gives rise to substantial nonadiabatic effects. The DSE is shown to slightly affect these light-induced conical intersections and, in particular, break their symmetry.","Molecular polaritonics is an emerging and rapidly developing field of research.1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13 The quantized radiation field of optical or plasmonic nanocavities can interact with the dipole moment of molecules, which gives rise to new hybrid light-matter (so-called polaritonic) states, carrying both excitonic and photonic features. Depending on their characteristic frequencies, quantized radiation modes can couple to electronic or vibrational degrees of freedom, leading to vibronic or vibrational polaritons 8. Over the last decade, an array of experimental 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25 and theoretical 26, 27, 28, 29, 30, 4, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53 works have demonstrated that polaritonic states can dramatically modify or even control the physical and chemical properties of molecules. Indeed, the presence of the quantized radiation field can amplify 54 or suppress 27 certain physical processes and even induce new ones. We mention the possibility of strongly varying the rate of spontaneous emission 55, or influencing the rate of energy transfer 56, 57 and charge transfer processes 58, 59, 60. In chemistry, the formation of molecular polaritons offers the possibility of controlling chemical reactions 28, 61, 62, 11, 63 such as photochemical reactivity 64, 65, photoisomerization 66, 67, photodissociation 68, 69, photoionization 70 or photoassociation 71 of molecules. The strong coupling regime is reached when the rate of energy exchange between cavity photons and the molecule is larger than the rate of photon loss and system dephasing. Strong coupling can be achieved easier with plasmonic nanocavities since plasmonic modes are confined to much smaller volumes than optical cavity photons. However, the lifetime of plasmonic modes is much shorter due to high photon leakage. Modes in plasmonic nanostructures almost always correspond to material excitations (see also Refs. 72, 73, 74 for the quantization of medium-assisted electromagnetic fields). Therefore, the interaction between plasmonic modes and molecules is mostly guided by the Coulomb interaction which is not affected by the Power–Zienau–Woolley transformation.75, 76, 77 Consequently, the cavity-molecule interaction can be described with the usual \vec{\mathrm{E}}\cdot\vec{\mathrm{d}} term (electric dipole approximation), without including the dipole self-energy (DSE). In contrast, for electromagnetic fields in optical or Fabry–Pérot cavities, only the transverse component of the vector potential exists, therefore, the DSE term should be included in the interaction term.78 Hereafter, we will consider the electromagnetic confinement to be an optical cavity. Although strong coupling in optical cavities is currently feasible only for molecular ensembles in experiments, our computations assume a single molecule coupled to an optical cavity in the strong coupling regime. Light-matter interaction can also induce nonadiabatic effects that are similar in nature to natural nonadiabatic phenomena.79, 33, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95 In case of light-induced nonadiabaticity, the radiation field strongly mixes the vibrational, rotational and electronic degrees of freedom of molecules. As a result, light-induced conical intersections (LICIs) are created between polaritonic potential energy surfaces (PESs), leading to the breakdown of the Born–Oppenheimer (BO) approximation.96 In optical cavities, the DSE term requires the evaluation of matrix elements of the squared dipole moment in the basis of electronic states, which is not available in standard electronic structure program packages. Current techniques for treating the DSE include the resolution-of-identity approach97 or approximating the DSE term with the square of the ground-state molecular dipole moment for vibrational polaritons.98 Here, we propose a method that we expect to be more accurate and robust for computing the DSE term. Namely, electronic matrix elements of the squared dipole moment are evaluated directly in the basis of the ground and excited electronic states using the toolbox of electronic structure theory. Thus, no additional approximations are introduced in our treatment on top of the standard ones used in quantum chemistry. To the best of our knowledge, this is the first such implementation treating both the ground and excited electronic states. It is important to note that a similar approach was employed in Ref. 48 where the ground-state expectation value of the squared dipole moment was obtained directly using Hartree–Fock theory. In this work, we demonstrate how the inclusion of the DSE term affects light-induced nonadiabatic quantum dynamics. Special emphasis is placed on how the position of the LICI changes due to the DSE term and what quantum-dynamical consequences (such as modified conditions for resonant cavity-molecule coupling) the DSE has for a single molecule coupled to an optical cavity mode. The structure of the paper is as follows. Section 2 provides the theoretical description of the cavity-molecule system and the details of electronic structure computations necessary to incorporate the DSE in our procedure. In Section 3 the computational models are described. Section 4 presents and discusses the results of the current study, while conclusion and outlook are given in Section 5."
https://arxiv.org/html/2411.07616v1,Stochastic resonance in vibrational polariton chemistry,"In this work, we systematically investigate the impact of ambient noise intensity on the rate modifications of ground-state chemical reactions in an optical cavity under vibrational strong-coupling conditions. To achieve this, we utilize a numerically exact open quantum system approach–the hierarchical equations of motion in twin space, combined with a flexible tree tensor network state solver. Our findings reveal a stochastic resonance phenomenon in cavity-modified chemical reactivities: an optimal reaction rate enhancement occurs at an intermediate noise level. In other words, this enhancement diminishes if ambient noise, sensed by the cavity-molecule system through cavity leakage, is either too weak or excessively strong. In the collective coupling regime, when the cavity is weakly damped, rate enhancement strengthens as more molecules couple to the cavity. In contrast, under strong cavity damping, reaction rates decline as the number of molecules grows.","Placing reactive molecules within an optical microcavity under conditions of vibrational strong coupling (VSC) has recently shown promise for manipulating chemical reactions, such as cavity catalysis and cavity-induced reaction selectivities, even in the absence of light.Ebbesen (2016) This concept has been demonstrated in several experiments, which suggests that adjusting the distance between two reflective dielectric mirrors in a Fabry-Pérot cavity so that the cavity frequency resonates with specific molecular vibrations can alter reaction rates or product ratios.Thomas et al. (2016); Vergauwe et al. (2019); Lather et al. (2019); Thomas et al. (2019); Hiura, Shalabney, and George (2019); Thomas et al. (2020); Hirai, Hutchison, and Uji-i (2020); Hirai et al. (2020); Sau et al. (2021); Lather et al. (2022); Ahn et al. (2023); Ebbesen et al. (2023) However, two independent experimental attempts to replicate these findings, while successfully reproducing VSC conditions, did not observe noticeable rate changes in an on-resonant cavity.Imperatore, Asbury, and Giebink (2021); Wiesehan and Xiong (2021) Different outcomes in the experiments suggest that additional factors beyond VSC, factors that may have been previously overlooked, could play a critical role in achieving cavity-induced modifications of ground-state chemical reactivities. In this study, we aim to explore one such experimental variable: the damping strength of the cavity mode. This damping, caused by ambient noise surrounding the cavity due to the unavoidable cavity leakage, may influence the extent of cavity-induced rate modifications. Naturally, this intriguing yet controversial phenomenon has spurred a substantial amount of theoretical research.Galego, Garcia-Vidal, and Feist (2016, 2017); Galego et al. (2019); Campos-Gonzalez-Angulo and Yuen-Zhou (2020); Mandal, Montillo Vega, and Huo (2020); Yang and Cao (2021); Li, Mandal, and Huo (2021a); Li, Nitzan, and Subotnik (2020); Li, Mandal, and Huo (2021b); Sun and Vendrell (2022); Schäfer et al. (2022); Mandal, Li, and Huo (2022); Lindoy, Mandal, and Reichman (2022); Wang et al. (2022); Fischer, Anders, and Saalfrank (2022); Fiechter et al. (2023); Sokolovskii and Groenhof (2023); Pavošević, Smith, and Rubio (2023) Recent studies using quantum dynamical simulations underscore the necessity of a quantum discrete state description for both molecular vibrations and the cavity mode.Lindoy, Mandal, and Reichman (2023, 2024); Ying and Huo (2023); Hu, Ying, and Huo (2023); Ke, Borrelli, and Thoss (2022); Ke and Richardson (2024) However, this requirement introduces significant challenges, particularly in the collective regime, where a large ensemble of molecules couples to the cavity mode. To address the computational challenges, we employ the hierarchical equations (HEOM) of motion along with a tree tensor network state (TTNS) solver.Ke (2023) The HEOM method is a well-established, numerically exact approach for open quantum system dynamics,Tanimura and Kubo (1989); Yan et al. (2004); Ishizaki and Tanimura (2005); Xu and Yan (2007); Shi et al. (2009); Yan (2014); Jin, Zheng, and Yan (2008); Schinabeck, Härtle, and Thoss (2018); Hsieh and Cao (2018); Shi et al. (2018); Tanimura (2020) enabling a non-perturbative and non-Markovian treatment of system dynamics and bath-related observables. The TTNS,Shi, Duan, and Vidal (2006); Tagliacozzo, Evenbly, and Vidal (2009); Murg et al. (2010); Li, von Delft, and Xiang (2012); Changlani et al. (2013); Nakatani and Chan (2013); Lubich et al. (2013); Murg et al. (2015); Gunst et al. (2018); Schröder et al. (2019); Larsson (2019); Ferrari, Magnifico, and Montangero (2022); Montangero, Rico, and Silvi (2022); Sulz et al. (2024) in addition, provides an efficient data compression scheme for storing and propagating the high-dimensional composite system-plus-bath wavefunction. To gain a preliminary understanding of how chemical reactions inside a cavity respond to ambient noise–stemming from interactions between the confined cavity mode and the continuum of far-field electromagnetic modes, which dampens the cavity’s oscillatory dynamics–we begin our study on the single-molecule level. Our results show that reaction rate enhancements within the cavity exhibit a typical stochastic resonance featureGammaitoni et al. (1998): neither excessively weak nor overly strong damping of cavity dynamics supports effective cavity-induced rate modifications. Instead, the rate constant inside a resonant cavity reaches its peak at an intermediate level of cavity damping. In the collective coupling regime, where multiple molecules are interconnected through a shared coupling with the cavity mode, rate modifications can display distinct behaviors as the system size grows. Under weak ambient noise, the rate enhancement strengthens as more molecules are coupled to the cavity mode. On the contrary, under conditions of strong cavity damping, the rate enhancement is attenuated with the increased number of coupled molecules. These observations lead us to ask an essential question: Could an ensemble of molecules on the macroscopic scale, immersed in a solvent and thus exposed to significant background noise, act cooperatively through collective coupling to the cavity mode, and synergetically harness a feeble external fluctuation to optimize the reaction efficiency? The following sections present a detailed account of our findings. Sec. II outlines an open quantum system model that describes chemical reactions in a condensed-phase optical cavity and the quantum dynamics methodology used. Sec. III presents and discusses the numerical results, followed by a summary and perspectives for our future research in Sec. IV."
https://arxiv.org/html/2411.07615v1,Real-time propagation of adaptive sampling selected configuration interaction wave function,"We have developed a new time propagation method, time-dependent adaptive sampling configuration interaction (TD-ASCI), to describe the dynamics of a strongly correlated system. We employ the short iterative Lanczos (SIL) method as the time-integrator, which provides a unitary, norm-conserving, and stable long-time propagation scheme. We used the TD-ASCI method to evaluate the time-domain correlation functions of molecular systems. The accuracy of the correlation function was assessed by Fourier transforming (FT) into the frequency domain to compute the dipole-allowed absorption spectra. The FT has been carried out with a short-time signal of the correlation function to reduce the computation time, using an efficient alternative FT scheme based on the ESPRIT signal processing algorithm. We have applied the TD-ASCI method to prototypical strongly correlated molecular systems and compared the absorption spectra to spectra evaluated using the equation of motion coupled cluster (EOMCC) method with a truncation at single-doubles-triples (SDT) level.","An explicit solution of the time-dependent Schrödinger equation opens up numerous new possibilities for studying electron dynamics in many-body systems. This includes ultrafast charge and energy migration [1, 2, 3], as well as various spectroscopic techniques, such as photoionization [4, 5], X-ray absorption [6, 7, 8], and valence electron UV/vis spectroscopy [9, 10]. In spectroscopic methods, electronic responses are typically studied in the presence of a time-dependent external electromagnetic field, from which molecular information about energy eigenstates is extracted. While frequency-domain approaches, commonly used in the quantum chemistry community, can also extract such information, these face several challenges: the computational method scales linearly with the number of requested roots, and finding interior roots is often difficult [11, 12]. In contrast, time-domain methods allow us to extract spectral information over a broad frequency range from the resulting signals. We focus here on evaluating one such signal, time-dependent correlation functions, specifically the dipole-dipole autocorrelation function, from which a system’s linear absorption spectrum can be obtained. Just as for time-independent electronic structure theory, in time-domain methods, the underlying description of electron correlation plays a crucial role. The choice of which method is used for this determines: a) whether the time evolution operator will be unitary so that the wave function norm is conserved during long-time evolution, and b) whether the strongly correlated nature of the ground state and the propagated wave function is adequately captured. Amongst the high-accuracy electronic structure methods, configuration interaction (CI) [13, 14] and coupled cluster (CC) [15, 16] wave functions have been used for time propagation in recent works. However, when low excitation rank truncation is employed, both CI-based and CC-based time propagation fail in the strongly correlated regime. Additionally, apart from the simple CIS method, CI-based time propagation is unreliable as the system size is increased, while CC-based time propagation fails to maintain unitarity, particularly when the wave function becomes strongly correlated. Another time propagation method, the time-dependent density matrix renormalization group (TD-DMRG) [17], has achieved greater success than the previously mentioned methods. Nevertheless, because the area law of entanglement, which underlies the efficiency of DMRG ground state calculations, often does not hold for time-propagated wave functions, the success of time-dependent DMRG is somewhat limited compared to time-independent frameworks [18, 19]. These experiences motivate the development of an accurate and efficient time propagation method for a strongly correlated wave function. In this work, we explore the time propagation of another wave function, namely the adaptive sampling configuration interaction (ASCI) wavefunction [20, 21], which can accurately describe strongly correlated ground state wave functions. We refer to this method as TD-ASCI. We shall develop the TD-ASCI methodology that provides unitary electronic dynamics and will explore its ability to describe strong correlation of molecular systems during time propagation. In this first work we have selected several prototypical strongly correlated molecular systems for detailed study, to benchmark the method and analyze its numerical features. In the future, we shall also address extensions and broader applications of the method to reduced dynamics for large numbers of electrons and to open quantum systems dynamics in which electronic excitations are coupled to non-Markovian vibrational degrees of freedom. The choice of numerical integration technique for time propagation is of vital importance for this work. The widely used fourth-order Runge-Kutta (RK4) does not obey the symplectic nature of the time-propagation. Various other schemes, in particular, the split operator (SO) technique [22] and the second order difference (SOD) method [23] employed with TD-CC and TD-CI methods also suffer from the same issue, especially for long-time propagation. Therefore in this work, we shall employ the short iterative Lanczos (SIL) time-integration scheme first proposed by Park and Light [24]. The SIL procedure provides a unitary, symplectic time-integration scheme which can be applied for long-time dynamics with a suitable update of the Krylov subspace. A related time-integration scheme is the Chebyshev orthogonal polynomial-based integrator (CH) [25], which provides a compact global propagator. The accuracy and computational effort of the CH scheme is comparable with that of the method. But, in contrast, the CH scheme is not unitary, is valid only for Hermitian Hamiltonians, and is limited to time-independent Hamiltonians. Despite the advantages of the time-domain methods mentioned above, application of all of these to obtaining high-resolution absorption spectra is limited by the fact that the simulated signal requires a long-time evolution. Many efforts have been made to obtain high-resolution spectra from short-time signals. These include methods such as the filter diagonalization technique [26], the Padé-based [27] FT, and the machine learning(ML)-based [28] FT. In this work, we proposed a new technique to obtain spectra from short-time signals that is inspired by the signal processing technique ESPRIT [29], which has been found to be successful in reducing the circuit depth of quantum phase estimation (QPE) algorithms [30]. The rest of the manuscript is organized as follows. In Section II we first summarize the ASCI algorithm to prepare the ground state. In Section III we outline our implementation of the Lanczos-based time evolution algorithm, with a particular emphasis on how the long-time dynamics is carried out. In Section IV we present the algorithmic details required for evaluation of the dipole autocorrelation function. In Section VI we present the novel FT scheme of the short-time signal based on ESPRIT. Section VIII then presents simulations of the absorption spectra of several multireference molecular systems that demonstrate the efficiency of the dynamics scheme and of the novel FT scheme. Section IX summarizes and concludes with an outlook for future applications."
https://arxiv.org/html/2411.07565v1,"Parallel Multi-Coordinate Descent Methods for Full
Configuration Interaction","We develop a multi-threaded parallel coordinate descent full configuration interaction algorithm (mCDFCI), for the electronic structure ground-state calculation in the configuration interaction framework. The FCI problem is reformulated as an unconstrained minimization problem, and tackled by a modified block coordinate descent method with a deterministic compression strategy. mCDFCI is designed to prioritize determinants based on their importance, with block updates enabling efficient parallelization on shared-memory, multi-core computing infrastructure. We demonstrate the efficiency of the algorithm by computing an accurate benchmark energy for the chromium dimer in the Ahlrichs SV basis (48e, 42o), which explicitly includes 2.07\times 10^{9} variational determinants. We also provide the binding curve of the nitrogen dimer under the cc-pVQZ basis set (14e, 110o). Benchmarks show up to 79.3\% parallel efficiency on 128 cores.","Understanding the chemical properties of molecules relies on solving the many-body time-independent electronic Schrödinger equation. However, traditional methods, such as density functional theory (DFT) or coupled-cluster with single, double, and perturbative triple excitations (CCSD(T)), often struggle to accurately describe the electronic structure of strongly correlated systems. This limitation is particularly evident in molecules with transition metals or those in non-equilibrium geometries. Full configuration interaction (FCI) provides a numerically exact solution under a predefined basis set by describing the wavefunction as a superposition of all possible Slater determinants. However, FCI methods scale exponentially with the number of orbitals and electrons, leading to the curse of dimensionality. To leverage this challenge and apply FCI methods to large systems, it becomes necessary to compress the wavefunction. This can be achieved by employing different wavefunction ansatze, such as the matrix product state (MPS) in the density matrix renormalization group (DMRG) method 1, 2, 3, 4, 5, or by representing the wavefunction as a population of random particles, as in the full configuration interaction quantum Monte Carlo (FCIQMC) method 6, 7, 8, 9, 10. Another approach involves selecting important Slater determinants, guided by the extensive sparsity of the FCI wavefunction 11. The method we describe in this paper falls into this category, which is known as selected CI method. A variety of selected CI methods have been developed, starting from the earliest work in 1973 known as Configuration Interaction using a Perturbative Selection done Iteratively (CIPSI) 12, to recent advancements including Adaptive Sampling CI (ASCI) 13, Heat-bath CI (HCI) 14, Semistochastic Heat-bath CI (SHCI) 15, 16, Coordinate Descent FCI (CDFCI) 17, Fast Randomized Iteration method for FCI (FCI-FRI) 18, Reinforcement Learning CI (RLCI) 19, and others. These methods share the common iterative approach of expanding a primary configuration space, filtering determinants based on some importance estimate, and computing the leading eigenpair to obtain an enhanced approximation of the wavefunction until convergence is achieved. Typically, Epstein–Nesbet second-order perturbation theory is further employed in the secondary space to account for the remaining correlation that is not captured by the variational SCI treatment. Selected CI variants significantly reduce the computational cost of FCI by diminishing the dimension of the primary SCI space compared to the N-electron Hilbert space, while they differ by having distinct selection principles and implementations. This paper extends the coordinate descent FCI (CDFCI)17 method previously proposed by one of our authors and his collaborators, which provides selection rules from an optimization perspective. Initially, it transforms the FCI eigenvalue problem into an unconstrained minimization problem, with local minima corresponding to the ground state of the system. Next, it employs the coordinate descent method for the following advantages: (i) The gradient of the objective function provides a natural determinant selection rule, adding important determinants into the variational space until it reaches the memory limit; (ii) The special structure of the problem allows us to perform an exact line search, accelerating the energy convergence; (iii) In each iteration, updating only one coordinate of the optimization vector involves only one column of the Hamiltonian matrix, avoiding operations with the entire Hamiltonian matrix, thus reducing the computation cost associated with unappreciative determinants. The CDFCI method obtains the ground-state energy and wavefunction without explicitly extracting the Hamiltonian submatrix for direct diagonalization. This makes immense room for the storage of the wavefunction, making it possible for larger systems and more accurate approximations. The effective determinant selection rule and the low storage cost are the main reasons why CDFCI becomes a competitive FCI solver. Although CDFCI demonstrates accelerated performance in experiments, its parallelization capability is restricted by the inherent sequential nature of the method. In this paper, we present a novel algorithm to address the minimization problem, which extends update of one coordinate to multiple coordinates per iteration. To achieve this, the algorithm introduces an additional search dimension to enable the exact line search. This extension not only accelerates convergence but also opens up new possibilities for parallelization. Benefiting from fully parallelizable coordinate updates, our new algorithm achieves an accuracy of 10^{-5} Ha for \chC2 and \chN2 using the cc-pVDZ basis in 10 and 30 minutes respectively, nearly twenty times faster than the single-threaded version reported in the original CDFCI work. When compared to the multi-threaded version of the original CDFCI that supports parallel hashtable updates, our algorithm delivers a 3.0\times speedup. Additionally, it computes the ground state of all-electron \chCr2 with Ahlrichs SV basis in 5.8 days, matching the accuracy of the original CDFCI, which previously required one month for the same task. In the rest of this paper, we present the algorithm in section 2 and discuss the implementation details in section 3. In section 4, we demonstrate the accuracy and the parallel efficiency of our method by applying it to various molecules including \chC2, \chN2 and \chCr2. The binding curve of \chN2 under cc-pVQZ basis is also characterized. Finally, we conclude and look ahead to future work in section 5."
https://arxiv.org/html/2411.07352v1,Efficient Implementation of the Random Phase Approximation with Domain-based Local Pair Natural Orbitals,"We present an efficient implementation of the random phase approximation (RPA) for molecular systems within the domain-based local pair natural orbital (DLPNO) framework. With optimized parameters, DLPNO-RPA achieves approximately 99.9\% accuracy in the total correlation energy compared to a canonical implementation, enabling highly accurate reaction energies and potential energy surfaces to be computed while substantially reducing computational costs. As an application, we demonstrate the capability of DLPNO-RPA to efficiently calculate basis set-converged binding energies for a set of large molecules, with results showing excellent agreement with high-level reference data from both coupled cluster and diffusion Monte Carlo. This development paves the way for the routine use of RPA-based methods in molecular quantum chemistry.","Positioned on the fifth rung of Jacob’s ladder Perdew and Schmidt (2001), the random phase approximation Bohm and Pines (1953); Gell-Mann and Brueckner (1957); Ren et al. (2012a); Zhang and Xu (2021) (RPA) is a powerful approach for incorporating non-local many-electron correlation effects into Kohn-Sham density functional theory Hohenberg and Kohn (1964); Kohn and Sham (1965) (DFT). RPA’s strength in capturing long-range dispersion interactions and the accurate modeling of metallic systems has made it a valuable tool for applications such as surface adsorption Schimka et al. (2010); Ren, Rinke, and Scheffler (2009); Olsen et al. (2011); Rohlfing and Bredow (2008); Ma et al. (2011); Kim et al. (2012); Schmidt and Thygesen (2018); Sheldon et al. (2024), molecular crystals Lu et al. (2009); Del Ben, Hutter, and VandeVondele (2013); Klimeš (2016); Zen et al. (2018); Pham, Modrzejewski, and Klimeš (2023), layered materials Marini, García-González, and Rubio (2006); Hellgren and Baguet (2021), liquid water Yao and Kanai (2021); Villard, Bircher, and Rothlisberger (2024), and thermochemistry Ren et al. (2013); Waitt, Ferrara, and Eshuis (2016); Bates et al. (2017); Chedid, Ferrara, and Eshuis (2018); Millican et al. (2022); Rey et al. (2024). Despite these successes, routine RPA calculations for systems of more than 100 atoms in the complete basis set (CBS) limit remain computationally challenging. Most practical implementations of RPA rely on the adiabatic connection fluctuation-dissipation theorem (ACFDT) Gunnarsson and Lundqvist (1976); Langreth and Perdew (1977), which has a computational cost scaling of \mathcal{O}(N^{4}) with system size N, using either plane-wave basis sets or atom-centered basis sets with the density fitting (DF) approximation [also known as resolution of the identity (RI)] Ren et al. (2012b); Eshuis, Yarkony, and Furche (2010); Del Ben, Hutter, and VandeVondele (2013). Recent developments, including the space-time algorithm Rojas, Godby, and Needs (1995); Kaltak, Klimeš, and Kresse (2014), local RI Shi et al. (2024) or RI with an overlap metric Wilhelm et al. (2016), stochastic sampling Neuhauser, Rabani, and Baer (2013), and interpolative separable DF Lu and Thicke (2017), have been demonstrated to reduce this scaling and therefore increase its application range for materials simulations. Alternatively, RPA can be formulated within the coupled-cluster Bartlett and Musiał (2007) (CC) framework as direct ring CC with double excitations (drCCD) Scuseria, Henderson, and Sorensen (2008)—an approximation to CC with single and double excitations (CCSD) that retains only the direct particle-hole ring diagrams. Although CC-based RPA typically scales as \mathcal{O}(N^{6}) like CCSD, the cost can be reduced to \mathcal{O}(N^{4}) using DF techniques Scuseria, Henderson, and Sorensen (2008); Heßelmann (2012); Kállay (2015). Within this framework, a linear-scaling implementation of RPA has been reported using the local natural orbital (LNO) approximation Kállay (2015). In this work, we present a reduced-scaling implementation of CC-based RPA using the domain-based local pair natural orbital (DLPNO) approximation Neese, Hansen, and Liakos (2009); Neese, Wennmohs, and Hansen (2009). Compared to ACFDT-RPA or LNO-RPA, an advantage of the DLPNO-RPA method is that it yields the global wavefunction amplitudes, in addition to the correlation energy, which facilitates calculations of other properties. As a versatile local correlation framework, DLPNO has been successfully applied to achieve linear scaling in methods such as second-order Møller-Plesset perturbation theory Pinski et al. (2015); Werner et al. (2015) (MP2), CCSD Neese, Hansen, and Liakos (2009); Riplinger and Neese (2013), and its extension CCSD(T) Riplinger et al. (2013, 2016), which includes perturbative triple excitations Raghavachari et al. (1989). The accuracy of DLPNO-based methods can be finely controlled by adjusting PNO truncation thresholds, often achieving better than 99.7\% accuracy in the total correlation energy and deviations of less than 1 kcal/mol in energy differences compared to the corresponding canonical methods Liakos et al. (2015). In the following, we detail the implementation of DLPNO-RPA, highlighting its high accuracy and computational efficiency compared to canonical ACFDT-RPA across a range of numerical examples. As an application, we calculate basis set-converged binding energies for a series of large molecules using DLPNO-RPA with a PBE reference and find excellent agreement with high-level correlated wavefunction methods at only a fraction of the computational cost."
https://arxiv.org/html/2411.07341v1,Two-component relativistic equation-of-motion coupled cluster for electron ionization,"We present an implementation of relativistic ionization-potential (IP) equation-of-motion coupled-cluster (EOMCC) with up to 3-hole–2-particle (3h2p) excitations that makes use of the molecular mean-field exact two-component (mmfX2C) framework and the full Dirac–Coulomb–Breit Hamiltonian. The closed-shell nature of the reference state in an X2C-IP-EOMCC calculation allows for accurate predictions of spin-orbit splittings in open-shell molecules without breaking degeneracies, as would occur in an excitation-energy EOMCC calculation carried out directly on an unrestricted open-shell reference. We apply X2C-IP-EOMCC to the ground and first excited state of the HCCX+ (X = Cl, Br, I) cations, where it is demonstrated that a large basis set (i.e., quadruple-zeta quality) and 3h2p correlation effects are necessary for accurate absolute energetics. The maximum error in calculated adiabatic IPs is on the order of 0.1 eV, whereas spin-orbit splittings themselves are accurate to \approx 0.01 eV, as compared to experimentally obtained values.","Open-shell molecular systems arise in a variety of interesting contexts, including radical intermediate species in chemical reactions,[1, 2, 3] spin-crossover complexes,[4, 5, 6] single-molecule magnets,[7, 8, 9, 10] and molecular spin qubits.[11, 12, 13] An accurate ab initio description of such systems is critical and yet can be challenging due to the significant multi-reference (MR) character that open-shell molecules often display, as opposed to the mostly single-reference (SR) nature of closed-shell systems. Rather than deal with the complexities and subtleties of MR electronic structure theory, which can be non-trivial, it is possible to treat open-shell molecular systems in a simple, reliable way using SR methodologies, given a suitably chosen ansatz. A popular SR framework for many-body electronic structure calculations is coupled-cluster (CC) theory, [14, 15, 16, 17, 18, 19, 20] which can be extended to the description of excited states via the equation-of-motion (EOM)[21, 22, 23] formalism. CC/EOMCC theory forms a family of robust, reliable, and systematically improvable approaches for the high-accuracy description of correlated many-electron systems. Particularly accurate results can be obtained when one considers methods that go beyond the basic CC/EOMCC with single and double excitations (CCSD/EOMCCSD),[24, 25, 23] such as those including up to triple (CCSDT/EOMCCSDT)[26, 27, 28, 29] or quadruple excitations (CCSDTQ/EOMCCSDTQ),[30, 31, 32, 33] and this hierarchy quickly converges to the full configuration interaction (CI) limit.[20] Despite these strengths, the direct application of CC/EOMCC to open-shell systems can be problematic. For example, spin contamination effects associated with an unrestricted or generalized Hartree–Fock (UHF or GHF, respectively) reference configuration can lead to a loss in proper spin-degeneracy structure, which can be a significant issue in some applications. An alternative strategy that still falls within the CC/EOMCC family is to begin with a reference state that is well-described by a SR method but differs from the target open-shell state by particle number. For example, the ionization potential (IP) EOMCC approach[34, 35, 36, 37, 38, 39, 40, 41, 42] begins with a closed-shell N-electron state, which should be well-described by the CC hierarchy applied to a restricted Hartree–Fock (RHF) reference configuration, and parametrizes the open-shell (N-1)-electron state (the ionized state) using non-particle-conserving excitation operators that remove an electron from the reference state. The key benefit of this approach is that, by starting from properly spin-adapted reference wave function that does not break desired orbital degeneracies, the subsequent open-shell energetics should retain this property. This advantage becomes more apparent when considering energy splittings due to spin–orbit coupling (SOC) effects in relativistic calculations, where spin-contamination-induced degeneracy issues could lead to energy errors on the order of the splittings themselves. Moreover, even though S_{z} and S^{2} are technically not good quantum numbers upon the introduction of SOC, one can still take advantage of time-reversal symmetry in the form of Kramers pairs for closed-shell determinants, which in practice produces degenerate pairs of spinors as one would obtain in the non-relativistic RHF case.[43, 44, 45] This symmetry preservation extends the benefits of IP-EOMCC to the relativistic domain, as the underlying structure of relativistic CC calculations would be analogous to that of non-relativistic singlet spin-adapted CC.[46] This work uses CC/IP-EOMCC to examine ionization potentials of HCCX (X = Cl, Br, I) systems, which have been characterized both experimentally and theoretically, from as far back as the 1970s.[47, 48, 49, 50, 51, 52, 53, 54, 55, 56] More recently, the theoretical study presented in Ref. 57 provided great details about the geometries, vibrational frequencies, and both vertical and adiabatic IP values of these molecules. However, that study did not account for relativistic effects, which are necessary to describe SOC-induced splitting of the doublet ground and excited states of HCCX+. Here, we apply relativistic CC/IP-EOMCC to this problem, and the relativistic treatment we employ falls within the exact two-component (X2C) [58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81] family of methods. There are a number of prior studies that extend the IP-EOMCC approach to the relativistic domain using X2C[82, 83, 84, 85, 86] or other[87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97] relativistic frameworks. Focusing on the X2C-based calculations, the majority of these investigations used spin-free X2C, and the most sophisticated calculations have considered only the Dirac–Coulomb (DC) or Dirac–Coloumb–Gaunt (DCG) Hamiltonians, as opposed to the full Dirac–Coulomb–Breit (DCB) Hamiltonian.[84, 86] As for correlation effects, to the best of our knowledge, only one of these studies has gone beyond the IP-EOMCCSD level of theory; Ref. 85 treated K-edge ionization features at up to the IP-EOMCCSDTQ level, but it should be noted that these high-order correlation effects were assessed only within a spin-free X2C formalism. The present study aims to assess high-order correlation effects (up to triple excitations in both the ground-state CC and IP-EOM parts of the algorithm), as well as a mean-field treatment of the full DCB Hamiltonian through the molecular mean-field (mmf)[98, 99, 100, 79] X2C formalism. The remainder of this paper is organized in the following manner. Section II provides the pertinent details of the X2C and CC/IP-EOMCC approaches. Section III describes the details of our computations, the results of which are presented in Section IV, including analyses of geometry, basis set, and correlation effects. Some concluding remarks can be found in Section V."
https://arxiv.org/html/2411.07325v1,Density Matrix Renormalization Group Approach Based on the Coupled-Cluster Downfolded Hamiltonians,"The Density Matrix Renormalization Group (DMRG) method has become a prominent tool for simulating strongly correlated electronic systems characterized by dominant static correlation effects. However, capturing the full scope of electronic interactions, especially for complex chemical processes, requires an accurate treatment of static and dynamic correlation effects, which remains a significant challenge in computational chemistry. This study presents a new approach integrating a Hermitian coupled-cluster-based downfolding technique, incorporating dynamic correlation into active-space Hamiltonians, with the DMRG method. By calculating the ground-state energies of these effective Hamiltonians via DMRG, we achieve a more comprehensive description of electronic structure. We demonstrate the accuracy and efficiency of this combined method for advancing simulations of strongly correlated systems using benchmark calculations on molecular systems, including N2, benzene, and tetramethyleneethane (TME).","1 Acknowledgement This material is based upon work supported by the “Transferring exascale computational chemistry to cloud computing environment and emerging hardware technologies (TEC4)” project, which is funded by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, the Division of Chemical Sciences, Geosciences, and Biosciences (under FWP 82037). This work used resources from the Pacific Northwest National Laboratory (PNNL). PNNL is operated by Battelle for the U.S. Department of Energy under Contract DE-AC05-76RL01830. LV and JB also acknowledge financial support from the Czech Science Foundation (grant no. 23-05486S), the Ministry of Education, Youth and Sports of the Czech Republic through the e-INFRA CZ (ID:90254), and the Advanced Multiscale Materials for Key Enabling Technologies project, supported by the Ministry of Education, Youth, and Sports of the Czech Republic. Project No. CZ.02.01.01/00/22_008/0004558, Co-funded by the European Union."
https://arxiv.org/html/2411.07920v1,Classical Pre-optimization Approach for ADAPT-VQE: Maximizing the Potential of High-Performance Computing Resources to Improve Quantum Simulation of Chemical Applications,"The ADAPT-VQE algorithm is a promising method for generating a compact ansatz based on derivatives of the underlying cost function, and it yields accurate predictions of electronic energies for molecules. In this work we report the implementation and performance of ADAPT-VQE with our recently developed sparse wavefunction circuit solver (SWCS) in terms of accuracy and efficiency for molecular systems with up to 52 spin-orbitals. The SWCS can be tuned to balance computational cost and accuracy, which extends the application of ADAPT-VQE for molecular electronic structure calculations to larger basis sets and larger number of qubits. Using this tunable feature of the SWCS, we propose an alternative optimization procedure for ADAPT-VQE to reduce the computational cost of the optimization. By pre-optimizing a quantum simulation with a parameterized ansatz generated with ADAPT-VQE/SWCS, we aim to utilize the power of classical high-performance computing in order to minimize the work required on noisy intermediate-scale quantum hardware, which offers a promising path toward demonstrating quantum advantage for chemical applications.","Quantum computing has the potential to radically transform the field of computational chemistry and materials science by improving the efficiency and accuracy of electronic structure calculations, an important aspect of modeling physical systems [1, 2, 3]. Quantum simulation of the electronic structure problem promises to avoid the exponential scaling of full configuration interaction (FCI) to obtain accurate electronic energies, but current quantum hardware is plagued by short coherence times and limited numbers of available qubits, which restrict potential problem sizes to small molecules with low-quality basis sets. Although simulations based on the quantum phase estimation may be preferred for future fault-tolerant quantum computers [4, 5, 6, 7, 8], the limitations of current and near-term noisy devices make such approaches unfeasible [9]. The variational quantum eigensolver (VQE) is a hybrid quantum-classical approach that reduces the coherence time requirement by limiting the work performed on the quantum computer and using classical resources to drive the optimization of the wavefunction [10, 11, 12, 13]. Various strategies have been proposed to move more of the simulation work on to classical hardware [14, 15, 16, 17, 18, 19], and in this work we ask the question of whether we can further reduce the work required on near-term machines by maximizing the work done using classical resources to realize a quantum advantage in computational chemistry? In VQE, the wavefunction is represented by a parameterized circuit consisting of quantum gates. Optimized ansatz parameters are sought that minimize the electronic energy. Choosing a wavefunction ansatz that is flexible enough to represent the desired electronic state and efficient enough to be employed on current computing resources is key to a successful VQE optimization. There are two broad categories of commonly used ansätze: chemically inspired ansatz and hardware efficient ansatz (HEA) [20]. The unitary coupled cluster (UCC) ansatz is an example of the chemically motivated ansatz that has seen widespread use in VQE research [21]. Unfortunately, the UCC ansatz can lead to deep circuits that may be prohibitive on near-term hardware. Although the HEA may lead to efficient circuits due to its use of hardware-native quantum gates, it is not clear that they offer a long-term advantage to UCC-inspired ansätze for chemical applications. To avoid the deep circuits that can result from the UCC ansatz but retain the physical basis of such a chemically motivated ansatz, Grimsley et al. introduced the Adaptive Derivative-Assembled Problem-Tailored ansatz Variational Quantum Eigensolver (ADAPT-VQE), an algorithm to obtain a chemically inspired ansatz that is problem-specific [22]. The key idea behind ADAPT-VQE is that the ansatz is iteratively grown with unitaries chosen from a user-defined pool of operators one at a time, based on energy derivative information collected at runtime [22]. Ansatz-growth steps are interleaved with ordinary VQE cycles; and since large gradient operators are appended to the ansatz, ADAPT-VQE results in arbitrarily accurate guess states that are resistant to barren plateaus [23]. Choosing a good initial state and operator pool is crucial for a successful and efficient ADAPT-VQE experiment. While standard UCC-type operator pools were used in the original implementation of ADAPT-VQE, proposals that trade off variational parameter economy for increased hardware efficiency to various degrees have been studied extensively [24, 25, 26]. Different operator screening and selection schemes as well as objective functions have also been investigated [25, 27, 26, 28, 29, 30]. The success of ADAPT-VQE for chemical systems has prompted researchers to extend the framework to problems in condensed matter [31, 32], high energy physics [33], and even classical optimization [34]. Although ADAPT-VQE offers promising, systematic methods to obtain efficient quantum circuits for preparing accurate states on near-term hardware, exact state vector simulations of the algorithm on classical hardware are limited to small physical systems. Recently, we have introduced a sparse wavefunction circuit solver (SWCS) that performs UCC-based optimizations on classical computers and greatly reduces the computational requirements of standard VQE by truncating the wavefunction during the evaluation of the UCC circuit [15, 18]. The approach is inspired by selected configuration interaction (CI) methods on classical computers where only the most relevant determinants are kept in the CI expansion to reduce that size of the diagonalization that is needed to obtain electronic energies [35, 36, 37]. These calculations take advantage of the sparsity of the electronic Hamiltonian and the limited number of determinants required to achieve chemically accurate energies. By using these ideas in the SWCS, we can reduce the computational workload required to simulate VQE with a UCC ansatz on classical computers. We take advantage of recent work to evaluate the factorized form of the UCC ansatz on classical computers [38]. Using the SWCS, we are able to calculate approximate energies using VQE with the UCCSD ansatz for problems up to 64 spin orbitals; this is equivalent to using 64 qubits with the Jordan–Wigner mapping. These developments allow us to probe the applicability of VQE for larger molecular systems as well as explore approaches to bridge classical and quantum resources to achieve quantum advantage for chemical applications. Although the SWCS has been demonstrated to work well for standard VQE optimizations, further research is needed to explore its utility in ADAPT-VQE optimizations. We note here that similar approaches to SWCS can be performed with other approximate circuit simulators. [16, 39, 40]. In this work we describe our implementation of ADAPT-VQE with our recent SWCS and report initial benchmarks to explore the efficiency and accuracy of this approach for small molecules with up to 52 spin orbitals, which is equivalent to a 52-qubit simulation. This approach can identify a compact wavefunction ansatz using only classical computers, which can be used as in initial state for simulation using quantum hardware. In the next two sections we describe our theoretical approach (Section II) and the computational details (Section III) employed here. We then analyze the results of this initial benchmark study of the approach (Section IV). We also discuss alternative optimization strategies for ADAPT-VQE that use the features of the SWCS to extend the applicability of ADAPT-VQE for chemical problems."
https://arxiv.org/html/2411.07886v1,Simulating Quantum Many-Body States with Neural-Network Exponential Ansatz,"Preparing quantum many-body states on classical or quantum devices is a very challenging task that requires accounting for exponentially large Hilbert spaces. Although this complexity can be managed with exponential ansätze (such as in the coupled-cluster method), these approaches are often tailored to specific systems, which limits their universality. Recent work has shown that the contracted Schrödinger equation enables the construction of universal, formally exact exponential ansätze for quantum many-body physics. However, while the ansatz is capable of resolving arbitrary quantum systems, it still requires a full calculation of its parameters whenever the underlying Hamiltonian changes, even slightly. Here, inspired by recent progress in operator learning, we develop a surrogate neural network solver that generates the exponential ansatz parameters using the Hamiltonian parameters as inputs, eliminating the need for repetitive computations. We illustrate the effectiveness of this approach by training neural networks of several quantum many-body systems, including the Fermi-Hubbard model.","Rapid progress in quantum technologies promises substantial computational advances in a diverse range of fields, from simulating quantum many-body systems with quantum devices to developing hybrid quantum-classical algorithms for optimization tasks Lloyd (1996); Georgescu et al. (2014); A et al. (2018); Bauer et al. (2020); Somma et al. (2003); Shaydulin et al. (2024). Among the numerous challenges ahead, a critical aspect of simulating the dynamics of quantum many-body systems on quantum hardware is the efficient preparation of quantum states described in exponentially large Hilbert spaces. Although such quantum states can be prepared using, for example, adiabatic techniques Veis and Pittner (2014); Du et al. (2010) or quantum imaginary time evolution Motta et al. (2020); Huang et al. (2023), these methods require selecting non-degenerated evolution paths or performing time propagation (either imaginary or real), which, depending on the Hamiltonian spectrum or the initial overlap with the target state, can be highly time-consuming, computationally demanding, or even unfeasible in practical situations Bauer et al. (2020). An alternative approach to quantum state preparation, which is also applicable to estimating eigenstates on classical computers, leverages well-designed ansätze that reduces the complexity of the wave function while retaining its essential structural features. In quantum chemistry, for example, a powerful class of exponential wave-function ansätze is available within the coupled-cluster theory, both in its standard non-unitary form Cizek and Paldus (1980); Bartlett and Musiał (2007) and in its unitary variant Lee et al. (2019); Anand et al. (2022); Shavitt and Bartlett (2009). When impurities are present, however, quantum systems often undergo significant changes that limit the effectiveness of simpler perturbative or mean-field approaches Grusdt and Demler (2016). Consequently, various ansätze have been proposed to address these complexities, including the Chevy (or polaron) ansatz for polarized atomic Fermi gases at zero temperature Chevy (2006); Grusdt et al. (2024), variational ansätze for dressed dimers Combescot et al. (2010), or more sophisticated ansätze for rotating molecules in bosonic environments X. Li and Lemeshko (2019). Although the need to engineer wave-function ansätze spands across various domains of quantum physics, no universal framework has yet emerged for constructing ansatz of general quantum many-body systems Szenes et al. (2024); Magoulas and Evangelista (2023). In fact, each field of research (and, in some cases, each interaction range within a research field) tends to develop its own set of wave-function ansätze, resulting in a fragmentation of results that poses significant challenges for drawing broad conclusions about different phases of matter, transferring knowledge between sub-fields of research, or studying complex phenomena involving various types of excitations (e.g., fermionic or bosonic). An even more significant problem is that parameterizing such wave-function ansätze for different Hamiltonian parameters (e.g., the classical nuclear coordinates in molecular systems) requires high-dimensional configuration spaces. As a result, there is a growing need for an efficient, formally universal, ab initio framework capable of designing quantum many-body ansätze, one that does not rely on the specific form of the underlying Hamiltonian and can potentially be implemented in near-term quantum simulators Pavošević and Flick (2021); Ribeiro et al. (2018); Du and Yuen-Zhou (2022); Mordovina et al. (2020); Ryabinkin et al. (2018). Recent progress in formulating the quantum many-body problem using the contracted Schrödinger equation has highlighted the existence of a universal, formally exact exponential ansatz Mazziotti (2006a). This is an iterative ansatz that can be used to prepare ground and excited states for electronic and bosonic systems, as well as for fermion-boson or boson-boson mixtures, such as those encountered in polaritonic quantum chemistry or supersolidity Smart and Mazziotti (2021, 2024a); Benavides-Riveros et al. (2024a); Smart and Mazziotti (2022); Warren et al. (2024); Benavides-Riveros et al. (2024b). Beyond this remarkable universality, a key feature of this ansatz is that it retains precisely the same number of degrees of freedom as the original quantum many-body Hamiltonian. Unlike other exponential ansätze, the number and the operational form of the terms in the exponent are fixed and correspond to those of the Hamiltonian Boyn and Mazziotti (2021); Boyn et al. (2021a). Yet, despite this remarkable mathematical structure, the family of contracted quantum (and classical) eigensolvers proposed in the literature requires an indefinite number of iterative calculations, along with a complete recalculation of its parameters whenever the underlying Hamiltonian changes, even slightly. This limitation diminishes the universality of the ansatz and constrain its capacity to explore diverse correlation regimes or uncover new states of matter. In this paper, inspired by recent advances in operator learning, we develop a surrogate neural network solver that directly outputs the parameters of the universal, formally exact exponential ansatz of quantum many-body physics. By design, our neural network captures the implicit nonlinear functional relationship between the Hamiltonian and the ansatz parameters. This approach not only eliminates the need for repetitive and computationally demanding calculations but also reinforces the method’s universality. The paper is organized as follows. In the first part, we discuss the main ingredients of the exact exponential ansatz and present its main connections with the family of contracted quantum eigensolvers. We introduce a crucial modification to those eigensolvers that makes the learning process unambiguous. Next, we introduce our surrogate neural solver for the exact ansatz and present our numerical results. We finish with a conclusion section where we also discuss potential implications of our results."
https://arxiv.org/html/2411.07477v1,Density matrix renormalization group in the discrete variable representation basis,"We present a numerical implementation of the density matrix renormalization group (DMRG) using the discrete variable representation (DVR) basis set. One main advantage of using the local DVR basis sets is that the computations of one-electron integral and two-electron repulsion integrals are drastically simplified. For comparison, we further implemented DVR complete active space configuration interaction (CASCI) using canonical molecular orbitals. These methods are applied to a one-dimensional pseudo-hydrogen chain under screened Coulomb potential. The DMRG ground state energy agrees with CASCI up to 0.1 \mathrm{m\text{ $E_{\textup{ h }}$ }} with a very small number of bond dimensions.","Electronic structure is the cornerstone of modern chemistry and is now routinely performed for molecules and materials to understand their physicochemical properties and spectroscopy [1]. Most of the electronic structure codes employ Gaussian-type orbitals as the atomic integrals can be analytically computed. The two-electron integrals are fundamental components required for any electronic structure computations [2], e.g., to construct the Fock matrix in the Hartree-Fock (HF) method. The evaluation of electron-repulsion integrals is computationally demanding as it scales N^{4} with the size of the basis set N. Real-space grids provide an alternative universal basis set for electronic structure computations [3, 4, 5, 6, 7, 8, 9, 10]. The discrete variable representation (DVR) basis set using both a finite number of basis functions and a set of grid points, has been widely used in solving the molecular vibrational eigenstates problems [11, 12, 13, 14, 15, 16] as it simplifies the computations of both kinetic energy and potential energy operator matrix elements. However, much less is explored to use DVR basis sets for electronic structure computations, especially in advanced multi-configurational methods [17, 6]. Here we present an implementation of the density matrix renormalization group (DMRG) using DVR basis sets. DMRG is a numerical method developed to study quantum many-body systems, particularly in one-dimensional systems. Originally introduced by White in 1992 [18], DMRG has become one of the most powerful techniques in condensed matter physics and, more recently, in quantum chemistry for calculating ground states and low-energy excited states of quantum systems [19, 20, 21]. DMRG represents many-body states using matrix product states or tensor networks, composed of interconnected tensors with a restricted entanglement. While conventionally the quantum chemistry DMRG uses the canonical molecular orbitals as sites, using the localized basis can enhance its performance [22]. Besides locality, one main advantage of using a DVR basis set is the electron-repulsion integral scales, instead of \mathcal{O}(N^{4}) using Gaussian-type orbitals, linearly with the number of basis functions \mathcal{O}(N). For comparison, we also implement the complete active space configuration interaction (CASCI) method employing DVR basis sets, with the complete active space defined by the HF canonical molecular orbitals. CASCI includes all possible electronic configurations (Slater determinants) by distributing electrons among the active orbitals[23]. Unlike the complete active space self-consistent field, the active orbitals are predetermined, e.g. canonical HF molecular orbitals. All codes are implemented in our in-house Python-based package PyQED. An illustration of the DMRG/DVR and CASCI/DVR method is shown for a one-dimensional pseudo-hydrogen chain with screened Coulomb potential. This paper is organized as follows. In Sec. II, we present the method of DMRG in a DVR basis set and then describe the implementation details. The application to a one-dimensional pseudo-hydrogen chain model is shown in Sec. III. We discuss the challenges and future perspectives of DVR basis sets in Sec. IV. Atomic units \hbar=e=m_{\text{e}}=1 are used throughout."
https://arxiv.org/html/2411.06756v1,Ro-vibrational Dynamics of the Neon Dimer,"Short intense laser pulses are routinely used to induce rotational wave packet dynamics of molecules. Ro-vibrational wave packet dynamics has been explored comparatively infrequently, focusing predominantly on extremely light and rigid molecules such as H{}_{2}^{+}, H2, and D2. This work presents quantum mechanical calculations that account for the rotational and the vibrational degrees of freedom for a heavier and rather floppy diatomic molecule, namely the neon dimer. For pumping by a strong and short non-resonant pump pulse, we identify several phenomena that depend critically on the vibrational (i.e., radial) degree of freedom. Our calculations show (i) fingerprints of the radial dynamics in the alignment signal; (ii) laser-kick induced dissociative dynamics on very short time scales (ejection of highly structured “jets”); and (iii) tunneling dynamics that signifies the existence of resonance states, which are supported by the effective potential curves for selected finite relative angular momenta. Our theory predictions can be explored by existing state-of-the-art experiments.","Ultrafast spectroscopy, including pump-probe and pump-dump-probe spectroscopy, is an extremely powerful tool that has provided insights into electronic correlations of atoms and molecules embedded into liquids or solids as well as isolated atoms and molecules. While the spectral response provides enormous insights, more recently direct imaging techniques have been developed for use, among others, in molecular beam experiments COLTRIMS ; COLTRIMS2 ; schouder2022 . The ability to record spatially and temporally resolved images experimentally with unprecedented precision opens the possibility to follow the pump-pulse induced dynamics of all degrees of freedom as a function of the delay time. Pump-probe spectroscopy has, e.g., allowed for the creation of rotational wave packets that display unique revivals as a function of the delay time RMP ; RMP2 ; seideman1999 ; corkum2003 ; rotational ; rotational2 . Such revivals have been observed in diatomic molecules as well as larger molecules for a wide range of pump pulse shapes and polarizations lin2020 . In addition to being of fundamental relevance for understanding light-matter interactions, laser-kicked molecules promise a rich foray of applications, including sensing and high-harmonic generation RMP . Comparatively few studies of vibrational wave packets exist. Early work investigated the spreading and recurrences of vibrational wave packets after electronic excitation or ionization baumert . Moreover, the distance-dependence of the ionization probability has been investigated in great detail distance-dependent-ionization ; distance-dependent-ionization2 . Vibrational or ro-vibrational wave packet dynamics have been studied in light molecules such as H{}_{2}^{+}, D{}_{2}^{+}, H2, and D2, where there exists an intriguing interplay also with the electronic degrees of freedom rovibrational ; rovibrational2 ; rovibrational3 . An interplay of rotational and vibrational degrees of freedom is also seen in heavier optically centrifuged super-rotors villeneuve ; centrifuge2 . Very recently, quantum control of the ro-vibrational dynamics has been investigated in the context of light-induced molecular chirality in comparatively heavy molecules koch2024 . This work considers a simple linearly polarized Gaussian pump-pulse with intensities and pulse length comparable to those used in many experiments over the past several decades, namely peak intensities I up to 1.2\times 10^{14} W/cm2 and pulse lengths up to 900 fs. As an example, we consider the neon dimer. Compared to the helium dimer ground state, which is a weakly-bound quantum halo, the neon dimer ground state is more strongly bound and more compact. Relatedly, the neon dimer possesses, unlike the helium dimer, several ro-vibrationally excited bound states. On the other hand, the characteristic rotational energy of the neon dimer is only about an order of magnitude smaller than the vibrational energy scale, i.e., the scale separation is much smaller than in heavier rare gas dimers hellmann_potential ; rotational ; heavydimer . This comparatively small scale separation is an important prerequisite for identifying several novel phenomena that depend critically on the internal dynamics of the molecule. A second ingredient decisive for the observed phenomena is the significant variation of the polarization anisotropy across the internuclear distances present in the neon dimer. Specifically, we identify several phenomena that are entirely absent in the rigid-rotor treatment rigidbody . We observe so-called Lochfrass, an effect that was first seen in seminal work on molecular hydrogen saenz , where the pump-laser triggers population transfer away from small internuclear distances, an effect that is absent in the rigid-rotor based description. Moreover, we observe unbound wave packet portions that fly away as “structured jets” with a speed of around a few Bohr radii per picosecond. Wave packet portions that travel at much smaller speeds are a signature of resonance states, which decay by quantum tunneling through the potential barrier created by the relative angular momentum of the dimer. Furthermore, we highlight the distance-dependence of the alignment. The remainder of this article is structured as follows. Section II introduces the system under study and briefly introduces the theory framework employed. Section III presents our results. Finally, Sec. IV provides a summary and outlook. Technical details are relegated to Appendix A."
https://arxiv.org/html/2411.06712v1,A non-Hermitian quantum mechanics approach for extracting and emulating continuum physics based on bound-state-like calculations: technical details,"This work applies a reduced basis method to study the continuum physics of a finite quantum system—either few or many-body. Specifically, we develop reduced-order models, or emulators, for the underlying inhomogeneous Schrödinger equation and train the emulators against the equation’s bound-state-like solutions at complex energies. The emulators can quickly and accurately interpolate and extrapolate the matrix elements of the Hamiltonian resolvent operator (Green’s function) in a parameter space that encompasses the complex energy plane as well as other real-valued parameters in the Schrödinger equation. The spectra, discretized and compressed as the result of emulation, and the associated resolvent matrix elements (or amplitudes), have the defining characteristics of non-Hermitian quantum mechanics calculations, featuring complex eigenenergies with negative imaginary parts and resolvent matrix elements with branch cuts moved below the real axis in the complex energy plane. Therefore, we now have a method that extracts continuum physics from bound-state-like calculations and emulates them in the input parameter space. Some significant results have previously been presented in a short report (arXiv:2408.03309). Here, we provide details of the study and an in-depth analysis, including how this method could be coupled with existing approaches to compute and emulate bound and continuum states.","In a recent paper Zhang (2024), we reported on a new application of the reduced basis method (RBM) Duguet et al. (2024); Drischler et al. (2023); Melendez et al. (2022) in the study of continuum physics of finite quantum systems. Technical details of the study are provided in this paper. Readers are advised to read the short report first, which could facilitate reading the current paper. By continuum physics, we mean the part of the spectrum of a Hamiltonian operator where the system can break up into subsystems (i.e., above the system’s lowest threshold) and the states and observables associated with that sector of the spectrum. To be quantitative, let H(\bm{\theta}) be the Hamiltonian operator. An important operator is H’s resolvent or Green’s function111We are working with time-independent Schrödinger equations in this work.. Its matrix element between two source states |{S}(\bm{\theta})\rangle and |\tilde{{S}}(\bm{\theta})\rangle is named amplitude \mathcal{A}, with \displaystyle\mathcal{A}(E,\bm{\theta})\equiv\left\langle\tilde{{S}}(\bm{% \theta})\left|\frac{1}{E-H(\bm{\theta})}\right|{S}(\bm{\theta})\right\rangle\,. (2) The vector \bm{\theta} collects the parameters of H, {S}, and \tilde{{S}}. \mathcal{A} represents an array of continuum physics observables, such as response functions and scattering amplitudes, depending on the construction of the source states. See Sec. II.1 for the details. The analytical properties of \mathcal{A} in the complex E plane, such as isolated poles and branch cuts (BCTs), are directly connected to the basic features of H’s spectrum Newton (1982). This informs an interesting numeric computational framework, called non-Hermitian quantum mechanics (NHQM) Reinhardt (1982); Moiseyev (2011), as discussed in Sec. II.2. Since the approximations of \mathcal{A} produced in a broad class of calculations (including NHQM) could be viewed as rational approximations Trefethen (2023) in terms of the variable E, a recent and relevant development on this subject is mentioned in Sec. II.3. In principle, we can solve the inhomogeneous Schrödinger equation, (E-H)|\Psi\rangle=|S\rangle\,, (3) or \langle\tilde{\Psi}|(E-H)=\langle\tilde{{S}}|\,, (4) and compute \displaystyle\mathcal{A}=\langle\tilde{{S}}|\Psi\rangle=\langle\tilde{\Psi}|{S% }\rangle\,. (5) To simplify our notation, we assume the E and \bm{\theta} dependence is implicit unless otherwise stated. These equations and \mathcal{A} are the main targets of this study. We aim to develop RBM-based reduced-order models (ROMs), or emulators, for the solutions of Eqs. (3) and (4) and \mathcal{A} so that we can extrapolate them in the complex E plane and interpolate them in the space of \bm{\theta}. Extrapolation in E is a crucial capability, from which \mathcal{A} at real Es can be inferred from the solutions at complex Es. Solving these equations directly at real Es poses severe numeric challenges, but at complex Es, it becomes a more feasible bound-state-like calculation. The emulation in \bm{\theta} enables rapid explorations of the continuum physics calculations in the parameter space, another helpful functionality. As a model-order-reduction (MOR) tool for a parameterized equation system Hesthaven et al. (2015); Quarteroni et al. (2016); Benner et al. (2017a, b, 2015), the RBM first constructs a subspace spanned by the equation’s full (or high-fidelity) solution at a sample of parameter sets, called snapshots, during the so-called offline training stage. Afterward, the equation system is projected into the subspace to form a ROM, which can be used to emulate the solutions and the associated observables in the parameter space. The dimension of the subspace is typically low and scales mildly with the number of parameters Duguet et al. (2024). Consequently, the computing cost for running emulators at the online emulation stage is dramatically reduced compared to simply repeating high-fidelity calculations, e.g., when exploring the parameter space of the calculations. The basic principle of the RBM was recently rediscovered in nuclear theory as the eigenvector continuation method Frame et al. (2018), where the focus was solving the eigenvalue problem. The RBM-based emulators have gained much attention and further development, including for nuclear-bound states Sarkar and Lee (2021a, 2022); König et al. (2020); Demol et al. (2020); Ekström and Hagen (2019); Demol et al. (2021); Yoshida and Shimizu (2022); Anderson et al. (2022); Giuliani et al. (2023); Yapa et al. (2023), resonant states Yapa et al. (2023, 2024) and general continuum scattering states Furnstahl et al. (2020); Drischler et al. (2021); Melendez et al. (2021); Zhang and Furnstahl (2022); Bai and Ren (2021); Drischler and Zhang (2022); Melendez et al. (2022); Drischler et al. (2023); Bai (2022); Garcia et al. (2023); Odell et al. (2024). One difference in our work’s RBM aspect is emulating inhomogeneous linear equations with continuous spectra222Ref. Melendez et al. (2022) surveyed different ROMs, including for the inhomogeneous equations. However, the continuous spectrum aspect was not illuminated.. In contrast, most previous quantum physics-related studies have considered emulating a specific eigenstate of a Hamiltonian operator, either a bound, resonance, or scattering state at a real energy E. More significantly, this is the first time to consider the complex E plane as part of the parameter space, in addition to the other model input parameters, such as \bm{\theta} in Eqs. (3) and (4). Our RBM formalism is discussed in detail in Sec. III. If we only consider the E variable, our complex-E emulation (CEE) is superficially similar to the rational Krylov methods Antoulas (2005); Van Beeumen et al. (2017); Peng et al. (2019) applied in studying finite linear equation systems. However, the CEE generalizes the Krylov methods to studying linear systems with continuous spectra. We also gain insights about a potential connection, mentioned throughout this paper, between the CEE and the (near)-optimal rational approximations Trefethen (2023) of a univariate function with branch points. Such a connection does not exist in the case of a linear system with only a discrete spectrum. When including emulation in other real-valued parameters, our study further extends the rational Krylov methods to the case with higher-dimensional parameter spaces; it also generalizes the univariate rational approximation to a multivariate one. We call it CERPE, an abbreviation for “complex-energy real-parameter emulator.” Further discussions on the related works can be found in Sec. III.5 On the physics front, our CEE is a new NHQM method for computing continuum states and observables. This is demonstrated numerically with two and three-body systems in Secs. IV and V. Some analytic understanding of the NHQM aspect of our CEE and the existing NHQM methods, including integration-contour deformation Glöckle (1983), complex scaling of different variants Reinhardt (1982); Moiseyev (2011); Myo et al. (2014); Lazauskas and Carbonell (2011); Lazauskas (2012); Papadimitriou and Vary (2015); Lazauskas (2015); Lazauskas and Carbonell (2020), and Berggren-basis based methods Michel and Płoszajczak (2021); Li et al. (2021); Berggren (1968); Michel et al. (2002, 2003); Id Betan et al. (2003); Hagen et al. (2006); Rotureau et al. (2006); Fossez et al. (2017); Hu et al. (2020); Michel et al. (2022), are presented in Sec. II.2. The generic strategies behind these methods are elaborated in that section using a simple model. However, our method differs significantly from existing NHQM approaches. The fundamental distinction is in constructing a finite-dimensional non-Hermitian Hamiltonian H matrix—a step we call “non-Hermitization.”333This can also be viewed as breaking time-reversal symmetry in the basis. This difference and its implications are discussed in Sec. III.3. The CERPE component of this study is also useful for continuum physics studies. Both Hamiltonian spectra and \mathcal{A} can be interpolated, extrapolated, or emulated in the space of \bm{\theta} in the inhomogeneous Schrödinger equations. The functionality of CERPE follows the same argument of existing emulators: they provide efficient interfaces for the users to access computationally expensive calculations with dramatically reduced computing costs Zhang and Furnstahl (2022). For example, with this emulator technology, model calibration and uncertainty quantification, particularly those based on Bayesian statistics, would become feasible for complex models and expensive calculations. In short, with CEE, continuum physics can potentially be extracted from bound-state-like calculations—an advantage of the NHQM methods. The CERPE further expands the functionality of such continuum physics calculations by reaching more users. Another new physics insight is concerned with complex-energy (CE) Schlessinger and Schwartz (1966); Schlessinger (1968a, b); McDonald and Nuttall (1969); Uzu et al. (2003); Deltuva and Fonseca (2012, 2013a, 2013b, 2014) and Lorentz integral transformation (LIT) methods Efros (1985a); Efros et al. (1994, 2007); Orlandini et al. (2014); Sobczyk et al. (2021, 2024); Bonaiti et al. (2024). The inhomogeneous Schrödinger equations are also solved at complex energies in the LIT calculations and effectively in the CE calculations.444In the existing implementation of the CE method Uzu et al. (2003); Deltuva and Fonseca (2012, 2013a, 2013b, 2014), the Lippmann-Schwinger and the Faddeev equations are solved for the on- and off-shell scattering amplitudes. However, the wave functions can be computed with those amplitudes and vice versa Schlessinger and Schwartz (1966). Using their procedures, these methods connect the complex-E results to the real-E ones. Our results suggest that these existing calculations can be viewed from the lens of the general NHQM framework. Perhaps more importantly, the CERPE developed here can be applied directly to emulate these existing calculations. The general procedures for achieving this can be found in Sec. VI. One counterintuitive understanding of computing continuum physics is worth a brief mention. The results shown in this work suggest that the CEE, which approximates \mathcal{A} using a small non-Hermitian H-matrix in Eq. (2), produces better results at real energies than the high-fidelity calculations based on a large Hermitian H-matrix. What is puzzling is that the two agree numerically in the instances with complex energies, i.e., the emulator is trained by these high-fidelity calculations. In contrast, in the existing emulator studies, emulators are supposed to reproduce high-fidelity calculations, including during extrapolations. We inevitably conclude that the CEE (and thus CERPE) as an extrapolant for E is biased to the physical continuum physics instead of the high-fidelity results based on a discrete spectrum. The non-Hermitization of H plays a key role here. This is further discussed in Sec. VII. We emphasize that although numerical results are only presented for simple two- and three-body systems with short-range interactions, both CEE and CERPE should work for general finite systems, as the applicability of the RBM method and the working of non-Hermitization are general, without specific reference to the size and the interaction nature of the system. The RBM method requires smooth dependence of the solution on the input parameters, which have been found to hold up in few and many-body studies. Meanwhile, as explained later, the non-Hermitization depends on the spectrum’s continuous nature and the training points’ setup in the complex E plane. However, we also need to point out that all the numeric calculations here are performed with high accuracy, with relative errors on the order of 10^{-12} in the training calculations. Our understanding of the methods developed here is based on such calculations. In practice, the training calculations, although attainable using bound-state methods, can have more significant errors. How the errors impact the performance of the emulator’s extrapolation and ways to stabilize the extrapolation need to be studied in the future. A summary of the organization of the rest of the paper is as follows. In Sec. II, a general discussion about H’s spectrum, its resolvent operator, and their connections to the continuum observables are provided. Recent developments in rational approximation studies are mentioned in light of their relevance in this work. Section III discusses the RBM framework used in this study. Numerical experiments of the CEE and CERPE in both two and three-body systems are discussed and analyzed carefully in Secs. IV and V. In Sec. VI, we discuss the potential couplings between our methods and other calculation methods. In Sec. VII, a summary is provided. The appendices collect some detailed information needed to reproduce the numerical calculations in this work."
https://arxiv.org/html/2411.02409v1,Reply to “Comment on “Unified Framework for Open Quantum Dynamics with Memory””,"We present our response to the commentary piece by Makri et al. [arXiv:2410.08239], which raises critiques of our work [Nat. Commun. 15, 8087 (2024)]. In our paper, we considered various settings of open-quantum system dynamics, including non-commuting, non-diagonalizable system-bath coupling, and bosonic/spin/fermionic baths. For these, we showed a direct and explicit relationship between the discrete-time memory kernel (\mathcal{K}) of the generalized quantum master equation (GQME) and the discrete-time influence functions (I) of the path integrals. As an application of this, we showed one can construct \mathcal{K} without projection-free dynamics inputs that conventional methods require, and we also presented a quantum sensing protocol that characterizes the bath spectral density from reduced system dynamics. As the Comment focused on the relationship between (\mathcal{K}) and I in one specific setup (i.e., commuting, diagonalizable system-bath coupling with a bosonic bath), we focus on that aspect in this response. In summary, we could not find a set of equations that explicitly connect I and \mathcal{K} from Makri’s 2020 paper [J. Chem. Theory Comput. 16, 4038 (2020)]. Furthermore, while our analysis is specific to the choice of discretization of path-integral and GQME, we have not found issues with the GQME discretization employed. As per critiques on citations, in our paper, we note that we had acknowledged Makri’s driven SMatPI work and Wang and Cai’s tree-based SMatPI work for the number of Dyck paths needed for the computation of the memory kernel.","References Ivander et al. (2024) F. Ivander, L. P. Lindoy, and J. Lee, Nature Communications 15, 8087 (2024). Makri et al. (2024) N. Makri, S. Kundu, Z. Cai, and G. Wang, “Comment on ”unified framework for open quantum dynamics with memory”,” (2024), arXiv:2410.08239 [quant-ph] . Makri (2020) N. Makri, Journal of Chemical Theory and Computation 16, 4038 (2020). Makri (2021) N. Makri, The Journal of Physical Chemistry A 125, 10500 (2021), pMID: 34812645, https://doi.org/10.1021/acs.jpca.1c08230 . Wang and Cai (2022) G. Wang and Z. Cai, “Tree-based implementation of the small matrix path integral for system-bath dynamics,” (2022), arXiv:2207.11830 [quant-ph] . Cerrillo and Cao (2014) J. Cerrillo and J. Cao, Phys. Rev. Lett. 112, 110401 (2014). Golosov et al. (1999) A. A. Golosov, R. A. Friesner, and P. Pechukas, The Journal of chemical physics 110, 138 (1999). Strathearn et al. (2018) A. Strathearn, P. Kirton, D. Kilda, J. Keeling, and B. W. Lovett, Nature Communications 9, 3322 (2018). Jørgensen and Pollock (2019) M. R. Jørgensen and F. A. Pollock, Physical review letters 123, 240602 (2019). Jørgensen and Pollock (2020) M. R. Jørgensen and F. A. Pollock, Phys. Rev. A 102, 052206 (2020). Wang and Cai (2024) G. Wang and Z. Cai, Comm. Comput. Phys. 36, 389 (2024)."
