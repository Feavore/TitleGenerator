URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10387v1,Phase and gain stability for adaptive dynamical networks,"In adaptive dynamical networks, the dynamics of the nodes and the edges influence each other. We show that we can treat such systems as a closed feedback loop between edge and node dynamics. Using recent advances on the stability of feedback systems from control theory, we derive local, sufficient conditions for steady states of such systems to be linearly stable. These conditions are local in the sense that they are written entirely in terms of the (linearized) behavior of the edges and nodes.We apply these conditions to the Kuramoto model with inertia written in adaptive form, and the adaptive Kuramoto model. For the former we recover a classic result, for the latter we show that our sufficient conditions match necessary conditions where the latter are available, thus completely settling the question of linear stability in this setting. The method we introduce can be readily applied to a vast class of systems. It enables straightforward evaluation of stability in highly heterogeneous systems.","Many systems can be conceptualized as networks in which the network topology is evolving while there are also simultaneously dynamics in the network nodes. If these types of dynamics interact, a feedback loop between local and topological dynamics is formed, and the system can be called an adaptive network Gross and Blasius (2007). Adaptive networks can exhibit rich dynamics and complex self-organization as the network topology can act as a memory that is shaped by past dynamics and thus effectively increases the dimensionality of the phase space. Dynamics of adaptive networks play a role in a wide range of phenomena including social distancing in epidemics Gross, Dommar D’Lima, and Blasius (2006); Marceau et al. (2010); Scarpino, Allard, and Hébert-Dufresne (2016), opinion formation processes in humans Kozma and Barrat (2008); Rainer and Krause (2002); Vazquez, Eguíluz, and Miguel (2008) and animalsCouzin et al. (2011), strategic interactionsSkyrms and Pemantle (2009); Do, Rudolf, and Gross (2010), neural self-organizationBornholdt and Rohlf (2000); Meisel and Gross (2009); Kuehn (2012), and ecology Raimundo, Guimaraes, and Evans (2018), among many others Berner et al. (2023). Due to the dynamical interplay between state and topology, mathematical analysis of the dynamics of adaptive networks is difficult. Hence, much of the earlier literature in the field focuses on discrete-state adaptive networks that can be modeled by systems of ordinary differential equations using moment expansions Demirel et al. (2014). More recently, the master stability function approachSegel and Levin (1976); Pecora and Carroll (1998) has been generalized to broad classes of adaptive networksBerner et al. (2021); Berner and Yanchuk (2021). However, the use of master stability functions hinges on the symmetry between network nodes. Hence, this approach only allows for stability and bifurcation analysis of homogeneous states of adaptive networks. In this work, we introduce a new method to analyze the stability of heterogeneous adaptive dynamical networks by leveraging recent advances in linear algebra and control theory. The key ingredient is to write the system in the form of a feedback loop between node and edge variables, represented by transfer matrices with a block diagonal structure. The central new tool that enables this analysis is the concept of the phase of a matrix Wang et al. (2020). This gives information complementary to the information in the singular values. It was already observed in Wang et al. (2023) that these phases reveal interesting information on the Laplacian of a graph. The central result of Chen et al. (2024) is that the phases of transfer matrices can be used to give sufficient stability conditions for interconnected systems. Zhao, Chen, and Qiu (2022) observed that phase and gain information can be combined to cover a much broader class of systems. In this paper, we combine the observation that phase analysis is well-behaved for Laplacian-like systems, with the results of Chen et al. (2024); Zhao, Chen, and Qiu (2022) to provide novel sufficient stability conditions for adaptive dynamical systems. Furthermore, we leverage the natural block structure of adaptive networks to obtain local instead of global conditions. We apply these conditions to the paradigmatic adaptive Kuramoto model, and find that the sufficient stability condition we provide, matches the necessary stability condition of Do et al. (2016) where the latter is applicable. Together, these results completely characterize the stable steady state configurations of the adaptive Kuramoto model. This demonstrates that, despite their generality, the conditions are not very conservative in this important special case. Furthermore, we recover standard results for the classical Kuramoto model, and the Kuramoto model with inertia. A companion paper Niehues, Delabays, and Hellmann (2024) develops the necessary formulations and results to apply these methods to complex oscillator models of power grids Kogler et al. (2022); Büttner and Hellmann (2024). Our paper proceeds as follows: In II, we provide an intuitive introduction to the concepts of controlling feedback systems. In III.1, we recall important fundamental notions in control theory. Readers familiar with control theory can skip these two sections, and start with section III.2 which gives the central definitions we need for our paper, and III.3 which gives the recent results on the feedback stability of systems that we build upon. In IV, we give our main results by adapting these concepts to the analysis of adaptive dynamical networks. In V we apply them to example systems. We recover state-of-the-art results and extend them to heterogeneous systems. Throughout the paper we write capital bold letters for matrices, e.g., \bm{M}, and lower case bold letters for vectors, e.g., \bm{x}."
https://arxiv.org/html/2411.09168v1,Theory of Mind Enhances Collective Intelligence,"Collective Intelligence plays a central role in a large variety of fields, from economics and evolutionary theory to neural networks and eusocial insects, and it is also core to much of the work on emergence and self-organisation in complex systems theory. However, in human collective intelligence there is still much more to be understood in the relationship between specific psychological processes at the individual level and the emergence of self-organised structures at the social level. Previously psychological factors have played a relatively minor role in the study of collective intelligence as the principles are often quite general and applicable to humans just as readily as insects or other agents without sophisticated psychologies. In this article we emphasise, with examples from other complex adaptive systems, the broad applicability of collective intelligence principles while the mechanisms and time-scales differ significantly between examples. We contend that flexible collective intelligence in human social settings is improved by our use of a specific cognitive tool: our Theory of Mind. We identify several key characteristics of psychologically mediated collective intelligence and show that the development of a Theory of Mind is a crucial factor distinguishing social collective intelligence from general collective intelligence. We then place these capabilities in the context of the next steps in artificial intelligence embedded in a future that includes an effective human-AI hybrid social ecology.","All intelligence is collective intelligence. [70] Collectives are capable of achieving things that individuals alone cannot. Notwithstanding the simplicity or complexity of the individuals, their aggregate behaviour can often be understood as a complex processing of information that individuals store, modify, and transfer between each other producing ‘useful’ collective behaviour at the scale of the whole collective. In most instances of Collective Intelligence (CI), where the agents might be ants in an ant colony, bees in a beehive, or neurons in a neural network, the individual is not aware of the drivers of their behaviour or the behaviour of other agents. For example, a single neuron is neither aware of its own internal processes nor that of a neuron it is connected to, nor is it aware of the end goal to which its activity contributes. Despite both this lack of awareness and the lack of a centralised controller, evolutionary and learning processes have produced an intricate, precise, and highly adaptive system that is capable of functional behaviour that would be impossible for any single neuron to achieve. In other instances of CI, such as teams of humans, or businesses interacting in economic markets, the agents themselves may be highly complex and exhibit varying degrees of purposefulness and awareness. Within this context, we draw attention to the role of psychological factors in improving the CI of human social collectives and quantifying the intelligence of social collectives, both natural and artificial. In order to understand how collectives process information, we first consider the variety of ways in which agents interact. The topology of the network describing agent-to-agent interactions is well known to be important for the proper functioning of social groups [83, 79]. In particular it has been shown that mammalian social groups exhibit patterns of fractal-like topologies [40, 51] that are a result of a cognitive ability to form discrete social connections between conspicifics [49]. These links are often both spatially and temporally transient; people meet for a while, go their separate ways, and come back together later. Despite this transience, individual connections are often the basis of long term social relationships between specific individuals as in pair-bonding and friendships. Consequently an important distinction can be made regarding connections between agents in complex adaptive systems: they can be more fluid-like or more solid-like [101]. For example the links between neurons in the brain are relatively fixed in nature when compared to the brief communicative interactions between ants, either instantaneous interactions between individual ants or via transient pheromone trails that coordinate the behaviour of large numbers of ants. Solé and colleagues [101, 88] identify a distinction between solid brains, in which interactions between agents fixed in place are highly persistent in time (e.g. neural networks, spin glasses) and liquid brains, in which interactions between highly mobile agents are much more short-lived (e.g. ants, immune cells). As Solé et al. note regarding liquid brains [101]: “Here there are no neural-like elements and yet in many ways these systems solve complex problems, exhibit learning and memory, and make decisions in response to environmental conditions.” All biological agents are composed of sub-units such as organs, cells, and molecular networks [67, 69, 71]. Cells in particular are the simplest living organisms with individual intelligence, or competencies [67, 33], within their native contexts. Here, we briefly focus on the archetypal single-cell intelligence, the neural cells. It is well understood that the central nervous system is a highly developed, adaptive, complex system that exhibits emergent computational characteristics [52], both in biological and artificial neural networks. Naturally the artificial models are simplifications but the extent to which they are simplifications is not so well understood. In a 2021 study, Beniaguev et al. [9] concluded that between five and eight layers of an artificial deep neural network are required to approximate the input–output mapping of a (single) cortical neuron and that the dendritic branches can be understood as spatiotemporal pattern detectors. This demonstrates that a single neural cell can be modelled as an artificial agent with highly complex computational capabilities situated within an adaptive, complex network of other highly complex agents, all signalling to one another. These results can be compared with earlier studies in which neurons were modelled as a Bayesian agent that is trying to infer the state of a hidden variable [25]. In each of these interpretations, a single cell can be seen as an agent with computational competencies situated within the context of a network that is slowly and adaptively changing around it. We can also compare the competencies of neural cells in networks to the individual competencies of ants in an ant colony. In a recent study [56] it was shown that social structures of some ant colonies are conserved between species that are separated by more than 100 million years of evolution. In the five species studied by Kay et al. [56], they found two social clusters and similarities in the division of labour that are preserved between the species. In a different study, Richardson et al. [91] showed that individuals within an ant colony play an important leadership role and that the behaviour of these individuals significantly improved the collective performance of the ants. Ants are also capable of changing their social structure in the event of pathogenic infestation of their colony. In a 2021 article, Stockmaier and colleagues [102] review the research on social distancing and other social restructuring that occurs with conspecifics in order to reduce the impact of pathogens by changing their social cues, signals, and other behaviours for the collective benefit of the colony. These two very different systems, neural networks and ant colonies, are examples of complex collective intelligences where the individuals (neurons, ants) are complex in their own right, but they signal each other in order to restructure their relationships so as to adapt their collective competencies to external signals. The neural networks are prototypical solid brains and ant colonies are prototypical liquid brains. Human social interactions can also be viewed as a form of liquid intelligence. Migliano et al. [79] discuss the ‘fluidity’ of social relations in early human societies: “Quantification and mapping of hunter–gatherers’ social networks has revealed details of a fluid and multilevel sociality, where friendship links connect unrelated mobile households into camps of temporary composition”. They describe the key characteristics of early human society, such as egalitarianism, division of labour, cooperative living with unrelated individuals, multi-locality, fluid social structures, and high mobility between campsites, which might be thought of as a liquid brain composed of social interactions that both cluster and disperse in order to store, modify, and transfer information via social networks. The notion that human social interaction might be a form of computation is not new: Mirowski, Axtell and colleagues [82, 60, 81] have suggested that economic markets are a form of computation by which prices can be derived, and Harré recently hypothesised [45] that this could be measured using information theory as had been done earlier for financial markets [47, 42]. As Axtell et al. [60] wrote: “There is a close connection between agent computing in the positive social sciences and distributed computation in computer science, in which individual processors have heterogeneous information that they compute with and then communicate to other processors.” The emergence of computation in multi-agent systems is a well-studied area of complex adaptive systems [64, 84]. For example neuroscience has used information theory to describe the storage, transfer, and modification of bits of information in biological neural processes [117]. More broadly, Integrated Information Theory (IIT) [107, 77] has been put forward as a measure of the emergence of ‘consciousness’ in generic (non-biological, non-neural) systems. In this case, some forms of IIT explicitly use information theory [8, 78] to measure the amount of non-trivial computation a system is carrying out. More generally, there is a move towards understanding complex adaptive systems in computational terms [89, 74] by empirically measuring the inter-agent flow of information [12]. In this article we use information theory to quantify how much computation in a CI is ‘emergent’ and how much is simply independent information processing by single agents. In general, we wish to capture the notion of the whole (computational process) being greater than the sum of the (independent) parts. We translate this to the simple notion that to the extent to which this inequality holds: Whole - \sum(Parts)>0 is the extent to which we will say a system exhibits non-trivial CI, noting that there are multiple possible implementations of this approach [54]. The Parts is how much computation a single agent is carrying out from one time step to the next such that the sum is the total of all agents’ independent computations. The Whole is the totality of computation in the system, it includes all single agent computations, pairwise computations, and higher order interactions between agents. Our measure will not be unique in any of its specifics, but it serves to quantify the CI of a system for comparative analysis. This approach also has much in common with that of Moore et al. [84] in which information theory is used to measure the collective intelligence in biological systems. Not only is there diversity in the types of systems that can show positive measures of CI, but the ways in which agents manipulate a system’s computations is diverse as well. Take for example Watson and Levin’s discussion of a scientist manipulating the intercellular signalling in order to change their collective outcome [110]: This framework [of collective cellular intelligence] makes a strong prediction: if intercellular signalling (not genes) is the cognitive medium of a morphogenetic individual, it should be possible to exploit the tools of behavioural and neuro-science and learn to read, interpret and re-write its information content in a way that allows predictive control over its behaviour (in this case, growth and form) without genetic changes. A counter question is: How can single agents, such as human leaders, have predictive control over a social group? Just as a scientist external to a cell collective can manipulate inter-cellular signalling to control the outcomes of the cell collective, a leader internal to a human collective can manipulate inter-personal behaviours to control the outcomes of the human collective. In both cases, an agent with a goal-directed psychology is acting on inter-agent relationships, i.e. inter-cellular or inter-personal, to control outcomes at the next level higher, i.e. organism-scale or societal-scale. In this work we will ask an analogous question of human agents: What is there in human psychology that allows us to learn to read, interpret, and re-write our interpersonal information content in a way that allows predictive control over our collective behaviour? We will not be able to explore all of the possible interpretations of this question here, but we posit that our Theory of Mind (ToM) is a suite of cognitive skills that allows individuals to have goal directed control over collective outcomes. Originally ToM was used to describe our ability to infer the unobserved mental states of other people [34] such as desires and beliefs, an ability humans are particularly good at and other animals much less so [86, 59]. But recently it has been shown that ToM is predictive of group performance as well [121, 31], empirically demonstrating the role of ToM in going beyond representations of the internal states of others to using that knowledge in a social setting to improve the collective outcomes for the group. In order to model ToM in a tractable fashion, we will focus on the narrower game theory of mind [123], and the Beliefs, Preferences, and Constraints (BPC) interpretation of game-theoretic decisions put forward by Gintis [35]. In this approach, what agents understand of other agents’ hidden states are the BPC that structure their observable behaviours. We will consider this question in the framework of agent interactions that extend agent utilities in a simple but novel way. We quantify our results using information theory to show the impact that a correctly deployed ToM has to direct agents’ behaviours in order to increase our CI. The models are simple but they illustrate the central notion that understanding the “beliefs, preferences, and constraints” [36, 37] of others can be used to improve the CI of a complex social system. In Section 2, we describe the liquid–solid dichotomy of interacting agents, review extant models of ToM, and provide perspective on the interplay between social network structures and ToM. In Section 3, we provide illustrative examples supporting different aspects of our argument, introducing our measure of computation and applying it to a simple empirical example. In Section 4 we review the psychology of social fluidity and the variety of social outcomes that this fluidity makes possible. We also use a simple multi-agent system to describe how a ToM can be used to improve the computational processes, i.e. the CI, of interacting agents. Finally, in Section 5, we discuss the broader implications of this approach."
https://arxiv.org/html/2411.09004v1,The geometry of the Deep Linear Network,"This article provides an expository account of training dynamics in the Deep Linear Network (DLN) from the perspective of the geometric theory of dynamical systems. Rigorous results by several authors are unified into a thermodynamic framework for deep learning.The analysis begins with a characterization of the invariant manifolds and Riemannian geometry in the DLN. This is followed by exact formulas for a Boltzmann entropy, as well as stochastic gradient descent of free energy using a Riemannian Langevin Equation. Several links between the DLN and other areas of mathematics are discussed, along with some open questions.","In its simplest form, deep learning is a version of function approximation by neural networks, where the parameters of the network are determined by given data. The best fit is determined, or the network is trained, by minimizing an empirical cost function using gradient descent. Many of the mysteries of deep learning concern training dynamics: Do we have convergence? If so, how fast and to what? How do we make training more efficient? How do the training dynamics depend on the network architecture or on the size of data? This article focuses on mathematical foundations. Our goal is to illustrate the utility of the geometric theory of dynamical systems for the study of these questions. While gradient flows have been studied in mathematics since the 1930s, gradient flows arising in deep learning have two subtle aspects –overparametrization and degenerate loss functions – that prevent naive applications of the standard theory of gradient flows (see Section 3.2) . We present a geometric framework for a simplified model, the Deep Linear Network (DLN), where these aspects can be studied with complete rigor. The DLN is deep learning for linear functions. This reduces the training dynamics to gradient flows on spaces of matrices. Despite its apparent simplicity, the model has a rich mathematical structure. Overparametrization provides a foliation of phase space by invariant manifolds. Of these, there is a fundamental class of invariant manifolds, the balanced manifolds, which are themselves foliated by group orbits. This geometric structure allows us to define a natural Boltzmann entropy (the logarithm of the volume of a group orbit) that may be computed explicitly. Microscopic fluctuations that underlie the entropy may be described by Riemannian Langevin equations. This approach unifies the work of several authors into a thermodynamic framework. In particular, it suggests an entropic origin for implicit regularization. My view is that the DLN is a gift to mathematics from computer science. On one hand, it is subtle, but tractable, providing a rich set of practical questions and insights. On the other hand, the study of the DLN is filled with sharp theorems, exact formulas and unexpected mathematical structure. While the gradient dynamics of the DLN are different from the standard theory, we also see familiar aspects in surprising combinations. This gives the analysis a classical feel, even though all the results here were obtained in the very recent past. There is plenty more to be discovered and the real purpose of this article is to explain why. In order to apply the methods of dynamical systems theory, what is of most value is to understand the dynamicists ‘way of seeing’. This is not so much a collection of theorems, as a systematic use of geometry, and particular examples, to figure out what questions one should ask. Geometric methods provide a powerful intuition that is often a source of new discoveries. This is the approach we use in this article. All the theorems we prove are guided by the work of computer scientists in the area. While this article does include some advanced mathematics, especially Riemannian geometry and random matrix theory, we stress explicit calculations, heuristic insights and representative examples. We hope this approach reveals the conceptual power of dynamical systems theory while remaining of interest to practitioners. The references are representative, not exhaustive, since our aim in this article is to provide a pedagogical treatment. We include a brief discussion of the literature on the DLN in Section 13.2. For broader surveys of deep learning that include related mathematical ideas, the reader is referred to the recent books [1, 37]. The article concludes with open questions that emerge from this perspective. These include specific mathematical questions on the DLN, as well as the extension of our entropy formula to gauge groups arising in deep learning."
https://arxiv.org/html/2411.07323v1,Mean-field analysis for cognitively-grounded opinion dynamics with confirmation bias,"Understanding how individuals’ beliefs and attitudes evolve within a population is crucial for explaining social phenomena such as polarization and consensus formation. We explore a persuasive arguments model incorporating confirmation bias, where individuals preferentially accept information aligning with their existing beliefs. By employing a mean-field approach, widely used in statistical physics, we simplify complex processes of argument exchange within the population. Our analysis proceeds by projecting the model onto continuous opinion dynamics and further reducing it through mean-field reasoning. The findings highlight the robustness of mean-field predictions and their compatibility with agent-based simulations, capturing the transition from consensus to polarization induced by confirmation bias.","Understanding how individuals’ beliefs and attitudes evolve within a population is crucial for explaining social phenomena such as polarization, consensus formation, and the spread of misinformation. Opinion dynamics models have been instrumental in providing insights into these processes by simulating the interactions and influences among individuals [1, 2, 3, 4, 5]. Our research explores a persuasive arguments model [6] where agents exchange pro and con arguments, thereby shaping their opinions through social interactions. A key element of the model is the incorporation of confirmation bias, a cognitive mechanism where individuals preferentially accept information that aligns with their existing beliefs while discounting contradictory evidence. This bias is known to play a significant role in real-world opinion dynamics [7, 8, 9, 10], leading to the reinforcement of existing beliefs and the potential for increased polarization within a population [11, 12, 6, 13]. To analyze the complex socio-cognitive interactions within the population, we employ a mean-field approach. Mean-field theory, widely used in physics to simplify complex systems, has been applied in various domains such as epidemics [14] and neural networks [15]. The use of mean-field theory in social dynamics has been extensively reviewed by Castellano et al. [16], highlighting its effectiveness in capturing the macroscopic behavior of social systems from microscopic interactions. Persuasive argument models [17, 18, 19, 6] explicitly model a cognitive layer of arguments. Therefore, model reduction proceeds in two main steps. First, we project the original model [6] onto the space of continuous opinion dynamics [4, 20], deriving an influence response function (IRF, [21, 22]) that governs the expected opinion change. This projection enables a comparison between the reduced and the original model through simulations. Second, we further reduce the model by a mean-field reasoning, dividing the population into two compartments. Using dynamical systems tools, we provide a comprehensive examination of the critical points and transitions in this idealized compartment model. The study demonstrates that mean-field treatment can effectively simplify the analysis of cognitively-grounded opinion dynamics, capturing essential features such as critical points and phase transitions to a high degree of accuracy."
https://arxiv.org/html/2411.07110v1,Hierarchical genotype networks and incipient ecological speciation in Q\beta phage quasispecies,"Understanding how viral mutant spectra organize and explore genotype space is essential for unraveling the mechanisms driving evolution at the finest scale. Here we use deep-sequencing data of an amplicon in the A2 protein of the RNA bacteriophage Q\beta to reconstruct genotype networks with tens of thousands of different haplotypes. The study of populations evolved under different temperature regimes uncovers generic topological features conditioned by fundamental structural motifs of genotype networks—tetrahedrons, triangles, and squares—that govern their local architecture. Mutant swarms display a hierarchical structure where sequences cluster around a highly connected and abundant sequence core that sustains population diversity. The immediate neighborhood of this core is comprehensively sampled, with no signs of selection, while a few mutations away sampling becomes dynamical and sparse, showing signs of purifying selection. By aggregating genotype networks from populations adapted to different temperatures, we capture the early stages of evolutionary divergence, with overlapping populations that remain connected through short mutational paths. Even at the time scale of these experiments, evolutionary pathways might be multiple, preventing the backward reconstruction of unique trajectories once mutations have been fixed. This analysis provides a detailed view of the local, fine-scale processes shaping viral quasispecies evolution and underscores the usefulness of genotype networks as an enlightening visualization of the organization of mutant swarms.","Results Empirical data and genotype network reconstruction Figure 1 depicts a summary of the experiments and protocols carried out to reconstruct genotype networks for evolved populations of the Q\beta phage. This phage has a short RNA genome (4217 nt) that encodes four proteins, Figure 1A. It infects the bacterium Escherichia coli using as receptor the conjugative F pilus. Its optimal replication temperature is 37∘C, although it can easily adapt to replicate at 30∘C and 43∘C [42, 36, 43, 44]. For this study, the phage was evolved at three different (30∘C, 37∘C, 43∘C), yet constant each, temperatures starting with a common ancestral population (see Materials and Methods and Fig. 1B). The evolution temperatures were chosen according to the lab’s previous experience [42, 36, 43, 44] and taking into account that two of them impose strong selective pressures on the virus. At 30∘C, all host metabolic processes are slowed down and, at 43∘C, the heat shock response is fully activated in E. coli. The fragment from 1060 to 1331 was deep-sequenced in populations at passage 60. Nucleotides from positions 1060 to 1320 code for a fragment of the A2 maturation-lysis protein, 1321 to 1323 correspond to a termination codon and 1324 to 1331 are non-coding positions. The curation of the raw data consisted of removing low-quality sequences not aligned to the reference genome and sequences with insertion and deletion events. This process resulted in high-quality sequences of equal length that were later collapsed into unique sequences while keeping a record of their abundance (see Materials and Methods and Figure 1C, D). Figure 1: Schematic of evolution experiments, data processing and network reconstruction. A. The Q\beta phage has a linear, single-stranded RNA genome of positive polarity with a length of 4217 nucleotides. It is composed of four proteins: a maturation-lysis protein (A2), a capsid protein (CP), a read-through protein (A1), and an RNA-dependent RNA-polymerase (Replicase). A computational model of the icosahedral capsid is shown. B. Three replicates of an ancestral population pre-adapted to 37∘C for two passages, P^{0}_{37} have been propagated for 60 passages at three different temperatures (see details in Materials and Methods). C. A lineage of the three replicas evolved in each condition was deep sequenced. A fragment with a length of 271 nt belonging to the A2 protein and a small non-coding region was selected. D. Sequencing yielded single-genome fragments (raw data) that were curated through a devoted pipeline, eventually returning populations with about 2-3\times 10^{5} high-quality, equal length, aligned reads. We observed differences in the consensus sequence of each evolved population. Each set was scanned for repeated sequences through an abundance count algorithm. E. Individual and aggregated genotype networks were reconstructed. Each sequence corresponds to a node of the network, with size proportional to the logarithm of the abundance of the sequence; two nodes are connected through a link if they differ in a single point mutation. After data curation, we were left with three sets of unique sequences (one for each experimental condition) and their abundances. In the remaining of this paper we only refer to these selected subsets, subsequently used to reconstruct one genotype network for each condition. The three networks for each evolved population are noted G(T), with T=30,37,43 labeling the temperature. The aggregated network is noted G\equiv\cup_{T}G(T). Each node in a genotype network corresponds to a specific sequence in the final sets; two nodes are connected if they differ in a single nucleotide, Figure 1E. Table 1 summarizes the size of each of the final sets, showing the total number s(T) of sequences in the curated sets, the number N(T) of different sequences at each temperature and the total number of links N^{L}(T). These networks are the largest connected component of the set of sequences in the curated sets. A small fraction of genotypes (below 0,3% in all cases) not connected through observed genotypes to the connected component are not included in the analysis. Finally, in our representation of genotype networks we depict each node with a size proportional to the logarithm of the abundance \ln s_{i} of that sequence i (i.e., the number of times that the corresponding sequence was found in our curated datasets, \sum_{i}s(i)=s(T) for sequences in each of the experiments). As it will be shown, node size directly affects the structure of reconstructed networks. For later convenience, we define the root sequence as the most abundant sequence in each population. G(30^{\circ}C) G(37^{\circ}C) G(43^{\circ}C) s(T) 222 785 243 043 315 912 N(T) 9\>188 11\>252 12\>724 N^{L}(T) 19\>531 24\>652 28\>189 \left<k\right> 4.3\pm 13.5 4.4\pm 13.8 4.4\pm 14.1 \alpha 2.63(6) 2.67(7) 2.51(4) \beta 0.73(1) 0.71(2) 0.69(2) r -0.989 -0.980 -0.970 Fixed G1122A T1295C A1088G mutations G1312A Table 1: Summary of values for network size and main topological properties. Total number of sequences s(T) after raw data curation, and number of nodes N(T) and links N^{L}(T) in the largest connected component of networks reconstructed from our data sets. Lines 4 to 7 show main topological properties: average degree \langle k\rangle and its standard deviation, the exponent of the power-law in the fit to degree abundance (\alpha) and to the neighbor connectivity k_{nn}(k) (\beta) with the corresponding fitting error between brackets, and Pearson’s assortativity coefficient r. Last two lines indicate the mutations fixed in the consensus sequence of each population with respect to the wild type; only G1122A is a synonymous mutation. Tetrahedrons, triangles, and squares are the universal building blocks of genotype networks Figure 2: Microscopic structure of genotype networks and local search. (a) Basic tetrahedron motif generated by considering all possible values of a specific DNA sequence nucleotide. (b) Necklace structure, with the root sequence as backbone, generated by considering all mutants at distance d=1 from the root sequence. (c) Basic square motif generated by considering the two paths leading to a double mutation. (d) Hierarchies emerge in genotype networks of a viral quasispecies as the building motifs are explored and combined. (d1) Hierarchical representation of empirical data from the root (d=0) to mutants at each distance found in the deep sequencing of the Q\beta-phage populations. Data correspond to network G(43). The ensemble of sequences at distance d=1 (d2) and d=2 (d3) form simple motifs that, within each level, are disconnected. For genotype networks to be connected, mutants at various distances from the root need to be included. (e-h) Genotype network motifs are exhaustively explored near the root in Q\beta populations; averages at each distance are performed over the ensemble represented in (d1) and over the two remaning populations: blue lines correspond to T=30^{\circ}C, green to T=37^{\circ}C and red to T=43^{\circ}C. (e) Number of unique sequences identified at distance d from the root. (f) Fraction of sequence space explored as a function of distance. (g) Total abundance of sequences sampled at each distance from the root. (h) Ratio of non-silent versus silent mutation fraction at each distance. Violin plots represent the density of dN/dS values at each distance in G(43). Violin plots for G(30) and G(37) are similar, but here omitted for clarity (see Appendix D). Basic building blocks (structural motifs) of genotype networks can be derived from the mathematical properties of sequence spaces. Take the root sequence as reference and focus on one of its nucleotides. All possible mutations on that site, while holding the rest of the sequence unchanged, results in A-1 mutant sequences at distance d=1 from the root, where A is the size of the alphabet (A=4 for RNA or DNA sequences). These mutants are connected to the root and are also at distance d=1 from each other, thus also mutually connected. This generates a clique or simplex of A=4 elements, with the topology of a tetrahedron (Fig. 2a). The same reasoning is valid about any other nucleotide in the root, thus we have a tetrahedron associated to each site along the sequence. All those tetrahedrons share a node, the root, so that the genotype network at distance 1 looks like a necklace of strung-together 4-cliques (Fig. 2b): for simplicity, only the mutated nucleotide is shown in the illustration, but each of those mutations is found in a full sequence that shares the composition at all other sites with the root sequence. The tetrahedron simplex is the main motif of genotype graphs. Larger-scale network structures are built by combining tetrahedrons (or parts thereof) around each new sequence. The root acts as a backbone holding together the tetrahedron necklace. If the root is removed, each 4-element simplex is reduced to a 3-node clique, forming a second elementary motif: the triangle. These triangles contain all the sequences at distance d=1 (of which there are 3L different ones). In the absence of the root, they are disconnected from each other, revealing that the set of mutants at distance d=1 is massively fragmented. The same is true about the set with all sequences at distance d=2. The triangle motif somehow acts as a generator of diversity at fixed distances from the root (see Appendix A). Genotype networks become connected through links between sequences at two different distances from the root. If we focus on mutations in two nucleotide positions, while holding the rest unchanged, we obtain pathways that diverge from the root and meet at the vertex of another set of strung-together tetrahedrons (Fig. 2c). These pathways conform a square, the third relevant motif. Squares involve two changes in distance from the reference sequence, but they result in the integration of the fragmented subsets: While triangle motifs generate all sequence diversity at fixed distances, the resulting subspaces are fragmented; square motifs link them and make them mutually accessible. Q\beta quasispecies perform exhaustive local searches in sequence space There are 4^{271}\sim 10^{163} different sequences of length L=271. The total number of virus particles on Earth is estimated at 10^{31} [45], while natural quasiespecies rarely exceed 10^{12} viral genomes within a host. Therefore, natural populations may only sample a tiny fraction of the total sequence space; an even smaller amount (of order 10^{6} sequences) is available to study through deep sequencing methods. Since viral genomes in a natural quasispecies are connected through replication and mutation processes, they typically cluster in sequence space. Our dataset reveals, for each final population, a highly abundant, different sequence (coinciding in the three experiments with the consensus sequence of each population): one or more mutations have been fixed along adaptation to different temperatures. Tetrahedrons, triangles, and squares constitute an abstract scaffolding that underlies every network built from DNA or RNA sequences. This does not imply that all motifs have to appear in empirical networks, as these might be undersampled. As triangles and squares are composed along increasing distances from the root sequence, the connected network of related mutants builds up. Though its basic topology results from the fundamental building blocks described in the previous section, a non-trivial, hierarchical structure emerges as the quasispecies explores nearby mutants (Fig. 2d1 and Figure S1). Figure 2d shows how fragmented groups of genotypes at each distance from the root (Fig. 2d2-3) are held together by paths linking sequences across different levels in the hierarchy. For sequences of length L and an alphabet of A letters the number S(d) of different sequences at a distance d from the root follows \displaystyle S(d) \displaystyle= \displaystyle\frac{(A-1)^{d}L!}{(L-d)!\>d!}\,, (1) with an asymptotic behavior S(d)\sim L^{d} for sufficiently large distances, but far from the length considered, L\gg d\gg 1. A comparison with our empirical data allows to estimate the genotype space covering of the populations. Close to the root, coverage is almost complete, and decreases as distance increases: we have found around 95\% of all mutants at distance d=1 in either population. At d=2, S(2)=329\>265 for L=271. Of these, 5\>013 (1.5%), 4\>677 (1.4\%), and 4\>394 (1.3\%) are found in our experiments at 30, 37, and 43^{\circ}C respectively. Though empirical sequence diversity peaks at distances d=2 or d=3 from the root (Fig. 2e), the fraction of sequence space explored decays monotonically, and near to exponentially fast with d (Fig. 2f). The decay in total sequence abundance with distance (Fig. 2g) suggests that mutation plays a role analogous to diffusion in this high-dimensional space. The population is anchored around the root, which could be interpreted as a sequence of high replicative ability (or high fitness, in this context): its copies abundantly cover the neighborhood at distance d=1 and, through a cascade-like process, also cover fractions of mutants at higher distances, with a substantial decrease in abundance as the number of mutations increases. Since the number of different sequences grows exponentially fast as d increases, the abundance per node decreases rapidly, and the exhaustive exploration of mutant sequences results severely suppressed a few mutants away from the root: low abundance should correlate with low degree. Figures S4-S6 (Appendix E) represent full networks of G(T) centered at the root and with nodes occupying concentric circles at each distance, thus highlighting their hierarchical structure and qualitatively illustrating the description above. This hierarchical structure is robust and independent of the temperature at which each population has evolved. In particular, there are no obvious signatures of an underlying fitness landscape affecting network structure or preference for certain sequences. In order to quantify the strength and mode of selection in the quasispecies, we have measured the fraction of non-synonymous versus synonymous mutations q(i|d)=dN(i|d)/dS(i|d) in the coding fragment of every sequence, in all three populations. With this notation, we explicitly indicate the distance d at which sequence i is found. First, the set of possible non-synonymous N(i|d) and synonymous S(i|d) mutations for each sequence i has been found. Next, we have counted how many non-synonymous \tilde{N}(i|d) and synonymous \tilde{S}(i|d) mutations are observed in the set of nearest neighbors of sequence i in each sampled population, to obtain q(i|d)=\frac{dN(i|d)}{dS(i|d)}=\frac{\tilde{N}(i|d)/N(i|d)}{\tilde{S}(i|d)/S(i% |d)}\,. (2) Figure 3h summarizes the obtained results by showing the average ratio \bar{q}_{d}=\sum_{i|d}q(i|d) at each distance d to the root for the three populations, and the density of q(i|d) values in G(43). For the root sequence, with d=0, \bar{q}_{0}\simeq 1, so its nearest neighbors cover almost all possible mutations, regardless their selective value. No dispersion is shown for d=0, since only the root sequence is included. At d=1, we observe that an average value q_{1}\lesssim 1 accompanies the massive coverage of neighboring sequences, as shown by the high dispersion of the distribution of q(i|1) values. In Appendix D, violin plots are shown in full, as well as the the distributions corresponding to populations at 30 and 37^{\circ}C, Figure S3. As d increases, the average value \bar{q}_{d} decreases towards 0, with an accompanying diminishing dispersion in q(i|d) values, which progressively cluster around 0. These results highlight once more the deep correlation between high sequence abundance and exploration of nearby mutants. We interpret that the fitness landscape shows up through purifying selection only at low sequence abundance, limiting in turn the number of deleterious mutants sampled. Altogether, the exploration of variants is restricted to the nearest neighborhood of highly abundant sequences due to the dilution caused by random mutation in the high-dimensional spaces where quasispecies evolve. Topological properties are conditioned by the hierarchical structure of Q\beta genotype networks Figure 3: Macroscopic structure of quasispecies’s genotype networks. (a) Degree frequency of genotype networks at 30^{\circ}C (blue triangles), 37^{\circ}C (green crosses), and 43^{\circ}C (red squares). A dashed vertical line marks maximum degree k_{M}=3L (also in panels b and e). (b) Scatter plot of sequence abundance versus degree. (c,d) Number of triangles \triangle_{i} as a function of the degree k of the sequence in linear (c) and logarithmic (d) axes. The polygon enclosed by thin continuous lines is defined by maximum \triangle_{M} and minimum \triangle_{m} values of \triangle_{i}; the thick continuous line is the expected value \triangle_{\rm rnd} for a random distribution of links, with standard deviation shown as shadings (\sigma_{\triangle}, dark grey, and 2\sigma_{\triangle}, light grey). (e) Network assortativity: average neighbor degree k_{nn}(i) of a sequence’s neighbors as a function of sequence degree k_{i}. The left-most part of this plot corresponds to undersampled, peripheral nodes with very low degree, while the right-most part of the plot is dominated by nodes with degree close to saturation, k_{i}\simeq 3L. Only the central part of the plot is statistically representative. The three genotype networks reconstructed from each of our experiments display quantitatively identical topological features, despite the different evolutionary history of each population and variations among consensus sequences. Their structural similarity is revealed through an analysis from a complex networks viewpoint [46]. In this section, we present and discuss three main topological quantities: the degree distribution, the abundance of triangles (related to the clustering coefficient) and the assortativity of reconstructed genotype networks. Degree. The degree k_{i} of a node i is defined as the number of links a node has. In our case, it corresponds to the number of sequences in the 1-mutant neighborhood present in the population sample. A histogram of the abundance of nodes with each degree yields a clear signature of a hierarchical organization in the reconstructed networks. Figure 3a shows that all degree-frequency histograms H(k) are well fit by a power-law function of the form H(k)\propto k^{-\alpha} in the interval 2\leq k\leq 2L (see also Table 1). Nodes with degree k=1 are typically undersampled because of their low abundance, while we find an over abundance of nodes with degree close to the maximum possible, k_{M}=3L. In these populations, the abundance of a sequence in the sample and the number of neighbors it has (its degree) are positively correlated (Figure 3b): more abundant sequences typically produce more progeny and, under unfaithful replication, populate its immediate neighborhood with higher frequency. The hierarchical structure of these networks also implies that highly abundant sequences (the root and the set of its nearest neighbors, plus some isolated variants at higher distances) have degree higher than average, while the majority of peripheral sequences (d\geq 4) are rare and have typically below-average degrees. Actually, the average degree is similar in all three networks, but this value is not representative of a typical node. This is the rule for quantities with power-law-like probability distributions, where the fat tail has a large impact on the average, thus affected by a large standard deviation (see Table 1). Triangles and clustering. The local clustering coefficient is a broadly-used measure of the degree of connectivity among neighboring nodes. It is defined as the ratio between the number of triangles formed between a given node and its nearest neighbors and the total number of possible triangles, typically assuming that all nearest neighbors can be mutually connected. But this is not the case in sequence spaces, where a large fraction of triangles cannot be formed, as described above (see Fig. 2b). A more informative quantity of clustering is the absolute number of triangles \triangle_{i} in the 1-mutant neighborhood of a sequence i (i.e. the numerator in the definition of local clustering coefficient above). Figures 3c and d display \triangle_{i} as a function of the degree k_{i} of each sequence. The hierarchical structure of quasispecies networks and the nature of the compounding basic motifs have direct consequences in the number of triangles that can be formed. Consider a specific nucleotide in a given sequence, which can contribute at most a basic tetrahedron motif if the three possible mutations at that site are found in the sample (Fig. 2a). If none or only one of the sequences with a mutation at this site are present, this site contributes no triangles to the reference sequence; if two of the mutated sequences are found, then one triangle is formed, and if all three mutations are present, three triangles are formed (the complete tetrahedron). The maximum \triangle_{M} and minimum \triangle_{m} number of triangles, defined as the sum of triangles contributed by all sites in a sequence of degree k, define a polygon represented in Fig. 3c, d. If mutations are randomly distributed along a sequence, the expected number of triangles is \triangle_{\rm rnd}=k^{2}/(3L) (thick solid line). The derivation of these functions, as well as the standard deviation \sigma_{\triangle} with respect to the random case is included in Appendix C. Figures 3c and 3d show how measured values of \triangle_{i} compare to \triangle_{M}, \triangle_{\rm rnd} and \triangle_{m}. For degrees k\gtrsim L, the empirical value agrees with the random expectation, \triangle_{i}(k\geq L)\in\{\triangle_{\rm rnd}-\sigma_{\triangle},\triangle_{% \rm rnd}+\sigma_{\triangle}\}; one standard deviation corresponds to the dark-grey shadow in Fig. 3c, and two standard deviations to the light-grey shadow. However, the number of triangles significantly deviates from random expectations at lower values of the degree, especially for k\lesssim 60, with an asymmetric trend to show many more triangles than expected. Note that cases close to \triangle_{M} or even at this value (there are instances for k=3 and k=6) entail that mutations preferentially cluster in a few sites of the sequence, while most other sites do not accept any mutation. These deviations from random expectations show a strong preference to mutate in silent positions, avoiding changes in sites that may affect fitness. This is consistent with measures of the \frac{dN}{dS} ratio: purifying selection becomes more prominent in low-abundance, low-degree sequences. Assortativity. Assortativity quantifies how similar two nodes are with respect to a certain property, in this case node degree. The average neighbor degree, k_{nn}(i)={\frac{1}{k_{i}}}\sum_{j=1}^{k_{i}}k_{j} measures the average degree of the nearest neighbors of node i. Figure 3e represents k_{nn}(i) as a function of k for the three networks studied, showing an inverse dependence between both quantities in the representative region of k values; k_{nn}(i)\propto k^{-\beta}, with \beta>0 is a decreasing function of k. An additional measure is the assortativity coefficient -1\leq r\leq 1 (Tab. 1) (aka the Pearson correlation coefficient of degree between pairs of linked nodes), which measures the correlation between nodes of different degree [47]. Both quantities show that Q\beta genotype networks are highly disassortative (see Table 1), as the neighbors of sequences with high degree preferentially connect to low-degree mutants, while a Pearson coefficient r\simeq-1 corresponds to networks that are near complete disassortativity. The aggregated genotype network uncovers incipient speciation Figure 4: Visualizing all three genotype networks together. The color of nodes is weighted proportionally to the sum of the logarithm of the abundances in each network, see Appendix B for details. Pure blue, green or red color correspond to nodes only found in G(30), G(37) or G(43), respectively. Nodes with mixed colors are found in two or more populations. Yellow circles signal the wild-type ancestral sequence, as labeled, and white circles highlight the root sequence of each adapting quasispecies, with labels R30, R37 and R43. a. Spring layout representation of all sequences in the aggregated network G. b. All sequences in a triangle representation. Each experimental condition is mapped in a different vertex. Sequences exclusive of a given environment are collapsed in the corresponding vertex; sequences along edges are found in the two environmental conditions linked by this edge; sequences in the interior of the triangle have been found in all three environments. c. Spring layout representation of top 100 most abundant nodes. d. Top 100 most abundant nodes in triangle representation. Each individual genotype network corresponds to a quasispecies adapting to a specific experimental condition. Though the three networks are indistinguishable regarding their topological properties, they are centered at different positions in sequence space, since they have fixed at least one mutation in their root sequence with respect to the wild type (see Table 1), and roots are two or three mutations away from each other. These networks are all part of a larger network, and jointly cover a larger fraction of the genotype space available to Q\beta quasispecies. By examining the aggregated set of sequences in all three experiments, we get a hint of how this larger space is connected and explored by viral populations in response to environmental changes. In Figure 4 two different representations of the complete network G, Fig. 4a, b, and a subset of its most abundant nodes Fig. 4c, d, illustrate its overall architecture. In all four plots, the wild type sequence and the root sequences of G(30), G(37) and G(43) (labeled R30, R37 and R43, respectively), are highlighted. Fig. 4a shows all viral variants within the aggregated network G. This representation has been generated in spring layout, a widely used algorithm that treats every link as a spring and determines the position of each node in the image as that which minimizes tension among nodes. In this way, groups of more strongly connected nodes are typically placed closer to each other (and around the center of the illustration), and less connected nodes occupy the periphery. To aid in the visualization of G(T) and to account for specific features of the network (as a sum of sequences in three independent experiments), we have devised an alternative representation in Fig. 4b. Here, nodes have been arranged over an equilateral triangle. Each experimental condition (30^{\circ}C, 37^{\circ}C, and 43^{\circ}C) is associated to a corner and a color (bottom left and blue, bottom right and green, top and red; respectively). Each node’s position is a weighted average according to each sequence’s abundance under each temperature. Nodes are also colored similarly to their positions, by weighting blue, green, and red (see Appendix B). Only color has been projected into Fig. 4a, while color and position carry the same information in Fig. 4b. In both panels, each node’s size is proportional to the logarithm of the corresponding sequence’s abundance summed across all three genotype networks. To further clarify the organization of the aggregated network, Figs. 4c and d show a subset of G containing only the 100 most abundant sequences at each experimental condition, all other specifications being the same. Sequences found only at a given temperature appear therefore collapsed at the vertices in Fig. 4b and d, while in Fig. 4 c they unfold as a fan of nodes connected to the root at each temperature. Note that if each viral population would contain sequences only adapted to the specific environment where it has evolved along the 60 passages, triangles in Fig. 4b and d would be populated only at the three vertices, and empty elsewhere. Sequences present in samples at two temperatures are found along the edges of the triangle. The least-populated area in the triangle lies near the edge between the 30^{\circ}C and 43^{\circ}C corners with a set of sequences populating the edge that apparently work well at both extremes, but not at 37^{\circ}C. Sequences strictly inside the triangle, which is well populated, show up in all three experimental conditions. Thus, at each temperature, the quasispecies sustains a large variability of genotypes also potentially adapted to other conditions. These versatile sequences appear in notable abundance (large node sizes). Supporting figure S2 offers a more dynamic view of how the aggregated network is occupied and explored by depicting each network separately. Maintaining node location and color as here described, it informs of each variant across experiments. The joint representation of the three populations adapting to different environments shows how quasispecies start diverging along ecological adaptation. The consensus sequence of the ancestral population P_{37}^{0} for all three experiments (labeled ”wild type”) is located near the triangle center. After 60 passages, each quasispecies has incorporated mutations in a root sequence that has dragged the accompanying ensemble towards a different region of sequence space. The wild type is still present in all three populations, and these show a large overlap among variants that are potentially preadapted to different environmental conditions. In physics terms, we witness a process of symmetry breaking, where mutation fixation opens a region of sequence space but limits access to other possibilities, in a drifting process along which the original state becomes progressively forgotten. In the triangle representation, this process can be visualized as a flux from the center to each corner. Still, all possible variants are connected in a single network, suggesting that, at this stage of adaptation, the process is reversible should the environmental conditions vary."
