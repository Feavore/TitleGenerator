URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10105v1,Parametric Autoresonance with Time-Delayed Control,"We investigate how a constant time delay influences a parametric autoresonant system. This is a nonlinear system driven by a parametrically chirped force with a negative delay-feedback that maintains adiabatic phase locking with the driving frequency. This phase locking results in a continuous amplitude growth, regardless of parameter changes. Our study reveals a critical threshold for delay strength; above this threshold, autoresonance is sustained, while below it, autoresonance diminishes. We examine the interplay between time delay and autoresonance stability, using multi-scale perturbation methods to derive analytical results, which are corroborated by numerical simulations. Ultimately, the goal is to understand and control autoresonance stability through the time-delay parameters.","A specific type of nonlinear system in which the system becomes phase-locked with a driving force in an adiabatic manner, where the frequency of the forcing gradually changes over time. This phenomenon, widely known as autoresonance, leverages the system’s nonlinearity to maintain resonance and effectively increase the system’s amplitude over an extended period, despite changes in the system’s parameters sanjuanbook ; fajans2001autoresonant . Typically, when the parameters of a nonlinear system change, the resonant frequency also shifts, causing the system to become detuned from resonance. In autoresonance, however, the system remains naturally phase-locked with the driving force in an adiabatic manner, allowing for self-adjustment of both amplitude and frequency. Since the initial observation of autoresonance ms_livingstone , a plethora of studies have been conducted across various fields. The use and application of autoresonance have been explored in atomic physics meerson1990strong ; liu1995nonlinear , plasma physics fajans1999autoresonant1 ; fajans1999autoresonant2 ; andresen2011autoresonant ; baker2015electron , nonlinear wave interactions friedland1998autoresonance3 ; friedland1998autoresonant4 ; yaakobi2013complete , planetary dynamics malhotra1999migrating ; friedland2001migration ; lanza2022tidal , and fluid dynamics friedland1999control . The theoretical framework of autoresonance has been extensively developed over the past few years. Some of the foundational work has been carried out by L. Friedland et al. friedland1997variational ; fajans2001dampingeffect ; fajans1999collective ; fajans2000secondharmonic ; nakar1999passage ; barth2014quantum . Studies can be found on asymptotic analysis and stability of autoresonance by L.A. Kalyakin et al. kalyakin2008asymptotic ; kalyakin2013stability . Kovaleva et al. kovaleva2013limiting have contributed an array of excellent works, including the limiting phase trajectory description of autoresonance and investigations of autoresonance in nonlinear coupled chains manevitch2016autoresonant ; kovaleva2018autoresonance ; kovaleva2016autoresonance . Additionally, R. Chacón et al. chacon2005energy ; chacon2010universal ; chacon2008breakdown have developed an energy-based theory and conducted notable research on chaos and the breakdown of autoresonance . While autoresonance induced by external forcing has garnered significant attention, relatively few studies have focused on parametric autoresonance khain2001parametric ; assaf2005parametric ; kiselev2007capture ; friedland2016parametric . In this article, we have investigated the effect of time delay on a parametric autoresonant system. The control of resonance response whether deterministic or stochastic, in various nonlinear systems with time delay has proven to be an efficient strategy over the years hu1998resonances ; mei2009effects ; jeevarathinam2011theory ; cantisan2020delay ; zakharova2017time ; maccari2003vibration . In a recent work, the effect of delay has been discussed in a externally driven autoresonant array of Duffing-Ueda oscillator chacon2024 . Although time delay has been employed in systems with externally applied chirped forcing, its role in parametric autoresonant systems warrants attention due to its potential for effective applications across diverse fields. Driven by an interest in parametric autoresonance, we aim to investigate the effect of time delay in such systems, an aspect that has received limited attention in the existing literature, to the best of our knowledge. Our findings demonstrate that the delay strength can serve as a powerful mechanism to control the growth of the autoresonant system. The structure of this article is as follows. Section \mathrm{II} outlines the essential mathematical formulations. In Sect. \mathrm{III}, we present numerical results to validate our analytical findings. Lastly, Sect. \mathrm{IV} provides the concluding remarks."
https://arxiv.org/html/2411.10320v1,Ghost states underlying spatial and temporal patterns: how non-existing invariant solutions control nonlinear dynamics,"Close to a saddle-node bifurcation, when two invariant solutions collide and disappear, the behavior of a dynamical system can closely resemble that of a solution which is no longer present at the chosen parameter value. For bifurcating equilibria in low-dimensional ODEs, the influence of such ‘ghosts’ on the temporal behavior of the system, namely delayed transitions, has been studied previously. We consider spatio-temporal PDEs and characterize the phenomenon of ghosts by defining representative state-space structures, which we term ‘ghost states,’ as minima of appropriately chosen cost functions. Using recently developed variational methods, we can compute and parametrically continue ghost states of equilibria, periodic orbits, and other invariant solutions. We demonstrate the relevance of ghost states to the observed dynamics in various nonlinear systems including chaotic maps, the Lorenz ODE system, the spatio-temporally chaotic Kuramoto–Sivashinsky PDE, the buckling of an elastic arc, and 3D Rayleigh–Bénard convection.","Characterizing dynamical systems from a geometrical point of view provides a powerful approach to complex nonlinear systems, where obtaining analytical or closed-form solutions is typically impossible. In this approach, the state of the system at a given time is viewed as a ‘point,’ and its evolution is viewed as a ‘trajectory’ within an abstract, possibly very high-dimensional, and often formally infinite-dimensional state space. Instead of describing the behavior of individual solutions for given initial conditions, a geometrical approach characterizes the dynamics in terms of the topology of the ensemble of all these trajectories, known as the phase portrait of the system. The idea for such a geometrical approach was initiated in the late nineteenth century [1, 2], which later became a key element in the study of deterministic chaos [3]. Thanks to advances in computational resources and methods over the past three decades, this approach has been successfully transferred from low-dimensional dynamical systems governed by ordinary differential equations (ODEs) to those governed by partial differential equations (PDEs). The function space of a PDE is infinite-dimensional, which, in discretized form, results in finite but very high-dimensional problems. Examples of such PDE systems include fluid flows [4, 5] and nonlinear optics [6, 7], among others, where a geometrical approach has proven to be particularly useful. A geometrical approach aims first to characterize how general trajectories are organized within the state space of a dynamical system, and then to discover how this organization changes as the control parameters of the system are varied. The shape of the general trajectories is determined by special trajectories corresponding to dynamically invariant solutions with a simple dependence on time. The simplest of these invariant solutions include steady states, where the system does not evolve over time, and periodic orbits, where the state recurs exactly after a given period. These invariant solutions might be dynamically unstable and, thus, never realized naturally in a numerical simulation or a laboratory experiment. However, their local dynamics and the dynamical connections between them dictate the shape of the other trajectories. When the control parameters of a dynamical system are varied, a geometrical description is typically concerned with bifurcations. A bifurcation is the appearance of a topologically nonequivalent phase portrait at precise parameter values [8]. This topological change involves the appearance or disappearance of fixed points, periodic orbits, or more complex invariant sets, or changes in their stability properties. A bifurcation is local if its associated topological change can be detected within any small neighborhood of the invariant solution involved in the bifurcation; if this change cannot be identified within small neighborhoods of the invariant solution, then the bifurcation is global. Through a local bifurcation, the shape and dynamical properties of trajectories outside a small neighborhood around the involved invariant solution do not change immediately. Consequently, whenever two invariant solutions collide and annihilate in a saddle-node (fold) bifurcation, the properties of these solutions are still ‘felt’ by the dynamics even though the solutions are not present anymore. This phenomenon is called the ‘ghost’ of the saddle-node bifurcation [9]. When two fixed points collide in a saddle-node bifurcation, slow evolution emerges in the ghost region as the key remaining property of the disappeared equilibria. The ghost region attracts and slows down the flow of nearby trajectories, delaying their transition to another attracting region in the state space. As the control parameter approaches the bifurcation value, the time spent in the vicinity of the ghost (or, equivalently, the transition time needed for the system to pass the ghost and move to some other equilibrium state) increases and diverges in a predictable manner. The scaling of the transition time with the distance from the bifurcation point in the parameter space has been extensively studied before [10, 11, 12]. Some authors [11, 13], particularly in quantum mechanics [14, 15], interpret ghosts by extending the real-valued state space of the dynamics to the space of complex-valued state variables. In this picture, two fixed points in the real-valued subspace collide and disappear from that subspace, giving rise to two repelling fixed points outside the real-valued subspace. The effect of these complex-valued repellers on the real-valued subspace, i.e., the original state space of the system, is what we identify as the ghost phenomenon. Such an approach, however, does not generalize to very complicated systems such as PDEs. Ghosts of equilibrium solutions have been investigated across a variety of applications. These include electronic circuits [16], population dynamics and catalytic hypercycles of biochemical reactions [17], the buckling of elastic solid structures [18], and understanding and predicting financial crises [19, 20], to name a few. Ghosts of equilibria play a significant role in so-called critical transitions: when the control parameter of a system, which is at a stable equilibrium state, is changed slowly toward and then beyond a critical value, where the equilibrium solution disappears through a saddle-node bifurcation or loses stability through other bifurcations, the system transitions to a new attracting region of the state space. In the case of a saddle-node bifurcation, the transition time is controlled by the ghost. This phenomenon is known as a critical transition, and the critical threshold is often referred to as the tipping point. The significance of a critical transition is that the new equilibrium state may be undesirable while, due to strong hysteresis, the transition cannot be reversed immediately by returning to a parameter value for which the desirable equilibrium exists again [21, 22]. Recently, Calsina et al. [23] considered a one-dimensional (1D) PDE model for a spatially extended population dynamics. They studied how the strength of the diffusion term in their model affects the delayed transition times to extinction. The transition time is governed by the ghost, as the parameter value is chosen close to a saddle-node bifurcation through which two other equilibria disappear and leave the uniform zero as the only attracting solution. However, the majority of previous research has investigated simple ODE systems. In this work, we formalize the ghost phenomenon by defining representative state-space structures without the necessity of being asymptotically close to the saddle-node bifurcation point in the parameter space. We term these representative structures the ‘ghost states.’ Characterizing the ghost phenomenon in terms of the representative ghost states enables us to follow three main objectives that have not been fully addressed previously. First, unlike previous works that study the ghost phenomenon as the system approaches the bifurcation point in the parameter space, we are interested in this phenomenon as the system moves away from it, so that less time is expected to be spent in the ghost region. The ghost states enable us to investigate how the ghost region evolves and whether it remains relevant to the dynamics as the control parameter is varied further from the bifurcation value. Secondly, we are interested in the ghost phenomenon in spatially extended dynamical systems governed by PDEs, such as fluid flows. We aim to explore the relevance of ghosts to both the spatial and temporal properties of the dynamics, rather than solely the temporal characteristics of delayed transitions, which have been the primary focus of previous studies. If the numerical computation of the ghost states can be scaled to high-dimensional problems, as will be demonstrated, the proposed characterization of the ghost phenomenon can be applied to high-dimensional discretizations of PDEs as well as low-dimensional ODEs. Finally, in addition to equilibrium solutions, we are interested in the ghosts resulting from the saddle-node bifurcation of time-varying invariant solutions, which has not been explored previously. We propose a family of methods that, based on a single unifying idea, defines and computes the ghost states for different types of invariant solutions. This enables us to pursue the previous two objectives for the ghosts of invariant solutions of various types. Specifically, we study the ghosts of periodic orbits as well as equilibria in the present work. We define the ghost state in the space of all sets that have the same topological structure as the invariant solutions involved in the saddle-node bifurcation. For the ghosts of equilibria and periodic orbits, this space includes all points and all loops in the state space, respectively. Within the respective search space, we formulate invariant solutions as the global minima (zeros) of a suitably defined non-negative cost function. Following this formulation, we define the ghost states as the non-zero minima of the cost function, which lift from zero as soon as the control parameter passes the bifurcation value. As the control parameter approaches the bifurcation value, the minimum value of the cost function decreases to zero, and the ghost state becomes the invariant solution itself, by construction and as expected. We demonstrate that as the control parameter is varied further from the bifurcation value, the ghost state captures the essential properties of the ghost phenomenon. Defined as such, the ghost of an equilibrium solution represents the locally slowest point in the state space at the chosen parameter value, and the ghost of a periodic orbit represents the best-fit loop to the vector field induced by the governing equations. A recently developed family of variational methods [24, 25, 26, 27] enables us to apply this approach to high-dimensional dynamical systems, including discretizations of PDEs. However, the cost functions whose minima represent the ghost states are not uniquely defined. Therefore, the ghost states are not purely a property of the dynamical system, and their exact properties depend on the specific choice of the cost function. Nevertheless, we will see that the ghost states defined based on different cost functions consistently capture the characteristics of the ghost phenomenon, providing important insight into the dynamics of a system. One particular application of ghosts is to intermittent chaos. In some instances (the type-1 transition of Pomeau and Manneville [28]), intermittent chaos is preceded by the saddle-node bifurcation of a periodic orbit. The trajectories of the subsequent chaotic attractor intermittently visit the region of the state space where the solutions formerly existed—the ghost of the bifurcation. We compute the ghost of such a periodic orbit in the Lorenz system. We demonstrate that, compared to the periodic orbit at the bifurcation point, the ghost state provides a better match with the regions of the state space frequently visited by the intermittent chaos at the studied parameter value. This paper proceeds as follows: in Sec. II, we present the mathematical background of ghosts. Section III details the general principles of the family of methods we have developed. In Sec. IV, we present several examples of applying our methods to problems of various complexities, to show the power but also the pitfalls of our methods. In Sec. V, we apply our methods to the three-dimensional (3D) Rayleigh–Bénard convection problem. We give concluding remarks in Sec. VI."
https://arxiv.org/html/2411.09667v1,Chaos in hyperscaling violating Lifshitz theories,"We holographically study quantum chaos in hyperscaling-violating Lifshitz (HVL) theories (with charge). Particularly, we present a detailed computation of the out-of-time ordered correlator (OTOC) via the shockwave analysis in the bulk HVL geometry with a planar horizon topology. We also compute the butterfly velocity (v_{B}) using the entanglement wedge reconstruction and find that the result matches the one obtained from shockwave analysis. Furthermore, we analyze in detail, the behavior of v_{B} with respect to the dynamical critical exponent (z), hyperscaling-violating parameter (\theta), charge (Q) and the horizon radius (r_{h}). We interestingly find non-monotonic behavior of v_{B} with respect to z (in the allowed region and for certain (not all) fixed, permissible values of \theta, Q and r_{h}) and \theta (in the allowed region and for certain (not all) fixed, permissible values of z, Q and r_{h}). Moreover, v_{B} is found to monotonically decrease with an increase in charge (for all permissible, fixed values of z, \theta and r_{h}), whereas it is found to monotonically increase with r_{h} (for all fixed, permissible values of z, \theta and Q). Unpacking these features can offer some valuable insights into the chaotic nature of HVL theories.","Abstract We holographically study quantum chaos in hyperscaling-violating Lifshitz (HVL) theories (with charge). Particularly, we present a detailed computation of the out-of-time ordered correlator (OTOC) via the shockwave analysis in the bulk HVL geometry with a planar horizon topology. We also compute the butterfly velocity (v_{B}) using the entanglement wedge reconstruction and find that the result matches the one obtained from shockwave analysis. Furthermore, we analyze in detail, the behavior of v_{B} with respect to the dynamical critical exponent (z), hyperscaling-violating parameter (\theta), charge (Q) and the horizon radius (r_{h}). We interestingly find non-monotonic behavior of v_{B} with respect to z (in the allowed region and for certain (not all) fixed, permissible values of \theta, Q and r_{h}) and \theta (in the allowed region and for certain (not all) fixed, permissible values of z, Q and r_{h}). Moreover, v_{B} is found to monotonically decrease with an increase in charge (for all permissible, fixed values of z, \theta and r_{h}), whereas it is found to monotonically increase with r_{h} (for all fixed, permissible values of z, \theta and Q). Unpacking these features can offer some valuable insights into the chaotic nature of HVL theories."
https://arxiv.org/html/2411.08694v1,Intensity landscapes in elliptical and oval billiards with a circular absorbing region,"Billiard models of single particles moving freely in two-dimensional regions enclosed by hard walls, have long provided ideal toy models for the investigation of dynamical systems and chaos. Recently, billiards with (semi-)permeable walls and internal holes have been used to study open systems. Here we introduce a billiard model containing an internal region with partial absorption. The absorption does not change the trajectories, but instead reduces an intensity variable associated with each trajectory. The value of the intensity can be tracked as a function of the initial configuration and the number of reflections from the wall and depicted in intensity landscapes over the Poincaré phase space. This is similar in spirit to escape time diagrams that are often considered in dynamical systems with holes. We analyse the resulting intensity landscapes for three different geometries; a circular, elliptic, and oval billiard, respectively, all with a centrally placed circular absorbing region. The intensity landscapes feature increasingly more complex structures, organised around the sets of points that are a particular number of iteration away from the absorbing region, and enriched by effects arising from multiple absorption events for a given trajectory.","Billiard models play a prominent role in our understanding of chaos and dynamical systems. In their simplest form they consist of two-dimensional regions with hard walls at the boundary, where free particles or rays may traverse without friction and reflect from the hard walls. While the corresponding phase space is four-dimensional, the simple behaviour of the trajectories between reflections from the walls, and the scaling invariance with respect to the total momentum of a trajectory, allows for the analysis of the dynamical behaviour on a two-dimensional Poincaré section \Omega=S\times p, spanned by Poincaré-Birkhoff coordinates (S,p), characterising the points of reflection. The billiard dynamics can thus be described in the form of a symplectic map T:(S_{n},p_{n})\to(S_{n+1},p_{n+1}) on the Poincaré section, the dynamical behaviour of which is determined by the shape of the billiard boundary [1, 2, 3]. Integrable (regular) dynamics can be studied through e.g., circular and elliptical boundaries; and globally chaotic dynamics through e.g. a stadium boundary or Sinai geometries. The generic case of mixed dynamics arises in many perturbations of these shapes, such as in ovals or in billiards with an internal boundary/scatterer such as annulus or iris billiards [4, 5]. In particular the investigation of mixed and chaotic billiards and their classical maps, has played an important role in the development of the theory of quantum and wave chaos, where quantum counterparts of these systems provide important theoretical examples [6, 7, 8, 9, 10]. Experimentally these systems can be implemented for example as quasi-two-dimensional cavities for microwaves [11, 12] or for light [13, 14, 15, 16, 17]. Recently there has also been intense interest in relativistic billiards [18, 19, 20, 21]. While classical dissipative chaos is a well developed field, the study of wave chaos in the presence of loss is still in the early stages and many phenomena such as multifractal distributions of eigenstates and the fractal Weyl law are still only partially understood [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]. This has motivated various studies of modified classical billiard dynamics, which include a loss mechanism. In particular, leaking billiards - billiards with partial or total escape through a region in the boundary - have been studied in some detail [33, 34, 35, 36]. A hole placed at the boundary corresponds to escape through a simple rectangular area in the Poincaré section, and does not affect the mapping T, but stops the iteration of the map when the hole is first encountered. The study of escape time diagrams, where initial points on the Poincaré section are colour-coded in correspondence with the number of iterations by which they are separated from the hole, has uncovered rich dynamical structures and provided a new tool for understanding the corresponding wave systems [30]. In [37] leaking billiards with a hole in the inside of the billiard, rather than on its boundary, were studied. The dynamics again terminate on first encounter of a trajectory with the hole, and escape time diagrams and average escape times can be studied. In contrast to a hole in the boundary a hole in the interior is not connected to a static area in the Poincaré section. The behaviour of the escape times was found to depend crucially on the dynamical nature of the billiard, with characteristic features associated to chaotic versus regular cases. The concept of a partial leak, on the other hand does not terminate trajectories on encounter with the leaking region, but can be described by a loss of intensity - an additional coordinate attached to the trajectories that changes due to the leak [33, 34, 38, 31, 39]. Hitherto partial leaks have only been investigated on the boundary of the system, corresponding to losses from a static region in the Poincaré phase space. In the present paper we consider a loss region in the interior of the billiard. The loss region itself is considered spatially homogeneous and does not change the dynamics encoded in T. However, due to the finite size of the loss region, different trajectories spend different amounts of time within the loss region between iterations, leading to a nontrivial change in intensity that cannot be connected to a static area of loss in the two-dimensional Poincaré phase space. The intensity dynamics can be visualised as false colour plots on the Poincaré phase space, displaying the value of the intensity after a given number of iterations in dependence of the initial phase-space point. The resulting intensity landscapes have been found to unravel classical structures underlying quantum systems with decay in simpler model systems [31, 39]. Here we investigate billiards with elliptic and oval boundaries, (corresponding to regular and mixed chaotic-regular maps T) with a partial leak from a central circular region within the billiard. We observe that the intensity landscapes over time develop characteristics of the Poincaré section for the closed billiard, and the interplay with the absorbing region. We show that the intensity landscapes are organised around a union of sets related to the infinite absorption limit (i.e. the limit in which the absorbing region acts as a hole), and are modulated with intricate intensity variations arising from a finite absorption strength. The paper is organised as follows. We begin with a brief summary of the background and notation of the billiard dynamics expressed as a symplectic map in Poincaré-Birkhoff coordinates and introduce the concept of the intensity landscape in section II. Then we discuss the intensity landscapes in detail for three examples (circle, ellipse, and oval) in sections III, IV, and V. We finish with a short summary and outlook in section VI."
https://arxiv.org/html/2411.08511v1,"Conceptualizing the chaotic perception, demands and challenges","One propounded theory for the presence of chaos in biological neural networks is that it could be involved in discriminating different olfactory stimuli. Inspired by the idea, in this paper, we define the visual “chaotic perception” and spell out the challenges we face when conceptualizing it.","1. Defining the chaotic perception Topologically equivalent dynamical systems[1] and linking matrix of strange attractors[2] are what we need to characterize the act of recognition chaotically. Let us review topological equivalence in the first place. 1.1. Topological equivalence Assume that S is the state space of a dynamical system, and \varphi^{t}:\,S\to S,t\in\tau, \tau being a number set, is the evolution operator, which satisfies \varphi^{0}X=X,\varphi^{t+t^{\prime}}=\varphi^{t}(\varphi^{t^{\prime}}). An “orbit” (or trajectory) setting off from X_{0}\in S is an ordered subset of the state space, i.e, \{X\in S;\,X=\varphi^{t}X_{0},t\in\tau\}. Two dynamical systems are topologically equivalent if there is a homeomorphism \xi:S_{1}\to S_{2} mapping orbits of the first system onto the second one. If S\subset X, for any t\in\tau \varphi^{t}S\subseteq S is called an invariant set. Clearly, each orbit is an invariant set. Invariant subsets are stable if for any U\supset S (U a small neighborhood), there exists V (another neighborhood) such that \varphi^{t}x\in U for any x\in V,t\in T. Or, there exists U\supset S for any x\in U we have \varphi^{t}x\to S as t\to\infty. The former one is called Lyapunov stability and the latter one is said to be asymptotic stability111None of the aforementioned stabilities implies the other one.. Seeing such stable invariant sets (or attractors) as geometric objects, they are termed strange if their dimension is fractional. 1.2. Linking matrix of the strange attractors There are two sets of attributes of strange attractors, dynamical and topological. The former one, known as “old” chaos quantifiers, are fractal dimension, the metric entropy, and the spectrum of Lyapunov exponents[3]. The latter attribute, all being topological invariants (or fingerprints) of strange attractors, could be linking numbers, topological entropy, and rotation rates (if the associated phase space is \mathbb{R}^{3}\times S^{1}). Because the topological organization breaks down in higher dimensions, the finger prints are applicable merely in 3-space[2]. Let us focus on the first topological property. In a chaotic time series, there are sections that are so close to some periodic orbits. These sections are called “surrogate periodic orbits”, the stabilization of which yields Unstable Periodic Orbits (UPOs). Then, the motion on the attractor may be conceived as hopping from one UPO to another. In this paper, we choose to work with linking numbers. In principle, to find the linking matrix superpose the extracted UPOs, detect the crossings, and use the conventions depicted in fig. 1. The linking number is half the sum of the assigned crossings L(\mathcal{A},\mathcal{B})=\frac{1}{2}\sum_{i}\alpha_{i}(\mathcal{A},\mathcal{% B}), \mathcal{A}, and \mathcal{B} are two UPOs. Self-linking number, on the other hand, is defined to be L(\mathcal{A},\mathcal{A})=\sum_{i}\alpha_{i}(\mathcal{A},\mathcal{A}). The linking Matrix will be of the form \NiceMatrixOptionscode-for-first-row = ,code-for-first-col= (1.1) \mathrm{M}=\pNiceArray{>{}ccccc}[first-row,first-col=1,margin,extra-margin=2pt% ,colortbl-like]&p_{1}p_{2}p_{3}p_{4}\cdots\\ p_{1}SL_{11}L_{12}L_{13}L_{14}\cdots\\ p_{2}L_{12}SL_{22}L_{23}L_{24}\cdots\\ p_{3}L_{13}L_{23}SL_{33}L_{34}\cdots\\ p_{4}L_{14}L_{24}L_{34}SL_{44}\vdots\\ \cdots\vdots\vdots\vdots\vdots\ddots. Figure 1. +,- are not affected by clockwise and counter-clockwise rotations. While linking numbers are topological invariants, the self-linking numbers are not unless the underlying cyclic phase space is of type \mathbb{R}^{2}\times S^{1}. 1.3. Global topological equivalence and chaotic perception While topological equivalence of dynamics can be local, having two strange attractors with the same linking matrix will refer to such equivalence globally. One possible usage of global equivalence could be in face recognition, in a narrow sense of course. After descrying the presence of chaos in biological neural networks[4], “Which artificial networks are generative of chaos?”, “What does chaos justify in real networks?” have been among researchers’ concerns. One suggested theory for this latter question is chaotic perception. Initially, in the late 80s, the functionality of discrimination was credited to limit cycles[5]. Then, Ashwin and Timme argued that chaos might afford a means to discriminate different olfactory stimuli[6]. In their paper[7], Marro and colleagues proposed a model for dynamic associative memory based on hopping from regularity to irregularity (chaos), the latter mimicking the brain states of attention and searching. Suppose we are to recognize a person from a group of people. From experience, we know that the brain is so fast in doing so, a trait that is justified thanks to face symmetry (hence minimizing the information) and other distinguishing factors like gender, age, color, stature, and facial shape. Now, what if we are to distinguish identical twins? In case we do not have any of the mentioned features to resort to, how does a brain decide who is who? This is the place we may hypothesize that low-dimensional strange attractors may come to help the following way. Chaotic perception. Seeing objects of perception as invariant sets of fractal dimension, we may see the act of recognition as the comparison of the fingerprints of two globally equivalent strange attractors, one constructed and saved already when learning the object and the other one reconstructed at the time of perceiving the object. The topology of chaos teaches us that linking matrices are fingerprints of attractors with unique off-diagonal and non-unique diagonal entries. While the former entries may refer to the twins as a group, the latter would designate a matrix for each group member."
https://arxiv.org/html/2410.23971v1,"Stochastic Reconstruction of Gappy Lagrangian Turbulent Signals 
by Conditional Diffusion Models","We present a stochastic method for reconstructing missing spatial and velocity data along the trajectories of small objects passively advected by turbulent flows with a wide range of temporal or spatial scales, such as small balloons in the atmosphere or drifters in the ocean. Our approach makes use of conditional generative diffusion models, a recently proposed data-driven machine learning technique. We solve the problem for two paradigmatic open problems, the case of 3D tracers in homogeneous and isotropic turbulence, and 2D trajectories from the NOAA-funded Global Drifter Program. We show that for both cases, our method is able to reconstruct velocity signals retaining non-trivial scale-by-scale properties that are highly non-Gaussian and intermittent. A key feature of our method is its flexibility in dealing with the location and shape of data gaps, as well as its ability to naturally exploit correlations between different components, leading to superior accuracy, with respect to Gaussian process regressions, for both pointwise reconstruction and statistical expressivity. Our method shows promising applications also to a wide range of other Lagrangian problems, including multi-particle dispersion in turbulence, dynamics of charged particles in astrophysics and plasma physics, and pedestrian dynamics.",".1 Conditional DMs for reconstruction Here we give a detailed description of the C-DMs used in this work to reconstruct Lagrangian trajectories from partial velocity measurements. As briefly introduced above, C-DMs consist of two main processes: the forward and the backward process, see Fig.8a. The one-step forward transition probability can be written as: q(\mathcal{V}^{(n)}_{g}|\mathcal{V}^{(n-1)}_{g})\to\mathcal{V}^{(n)}_{g}\sim% \mathcal{N}(\sqrt{1-\beta_{n}}\mathcal{V}^{(n-1)}_{g},\beta_{n}\bm{I}), (12) where the initial realization inside the gap coincides with the ground truth signal, \mathcal{V}^{(0)}_{g}=\mathcal{V}_{g}, and the variance schedule, \{\beta_{1},\ldots,\beta_{N}\}, is predefined to progressively destroy the correlations between the data in the gap and the measured signal, \mathcal{V}_{m}, resulting in a smooth transition to the pure Gaussian state, \mathcal{V}^{(N)}_{g}\sim\mathcal{N}(0,\bm{I}). We can formally express the forward process as q(\mathcal{V}^{(1:N)}_{g}|\mathcal{V}^{(0)}_{g})\coloneqq\prod_{n=1}^{N}q(% \mathcal{V}^{(n)}_{g}|\mathcal{V}^{(n-1)}_{g}), (13) where the notation \mathcal{V}^{(1:N)}_{g} denotes the entire sequence of noisy trajectories, \{\mathcal{V}^{(1)}_{g},\mathcal{V}^{(2)}_{g},\dots,\mathcal{V}^{(N)}_{g}\}, generated from the initial trajectory \mathcal{V}^{(0)}_{g} in the gap. Note that the data within the measurement region is never accessed in the forward process. The backward process models each step of the denoising conditional probability given measurements outside the gap, p_{\theta}(\mathcal{V}^{(n-1)}_{g}|\mathcal{V}^{(n)}_{g},\mathcal{V}_{m}), using a neural network with parameters \theta. Once trained, the C-DM reconstructs the trajectory within the gap, starting from pure Gaussian noise, \mathcal{V}^{(N)}_{g}, and conditioning on the measurements, \mathcal{V}_{m}, by iteratively reversing the forward diffusion process as introduced in Eq. (1). In the continuous diffusion limit, where a large number of diffusion steps are used and the noise variance \beta_{n} is chosen to be small, we can assume that the backward transition probability, p_{\theta}(\mathcal{V}^{(n-1)}_{g}|\mathcal{V}^{(n)}_{g},\mathcal{V}_{m}), follows the same Gaussian functional form as the forward step [80, 81]. The neural network is then tasked with predicting the mean, \mu_{\theta}(\mathcal{V}^{(n)}_{g},\mathcal{V}_{m},n), and the covariance, \Sigma_{\theta}(\mathcal{V}^{(n)}_{g},\mathcal{V}_{m},n), for each denoising step. Following [61], we set \Sigma_{\theta}=\beta_{n}\mathbf{I}, using step-dependent constants that remain untrained. Consequently, each one-step backward sampling is reformulated as: p_{\theta}(\mathcal{V}^{(n-1)}_{g}|\mathcal{V}^{(n)}_{g})\to\mathcal{V}^{(n-1)% }_{g}\sim\mathcal{N}(\mu_{\theta}(\mathcal{V}^{(n)}_{g},\mathcal{V}_{m},n),% \beta_{n}\bm{I}). (14) The model optimization is performed by minimizing a variational upper bound on the negative log-likelihood, as in standard generative DMs. The additional conditioning is explicitly expressed in both the target distribution, p(\mathcal{V}_{g}|\mathcal{V}_{m}), and the approximated distribution, p_{\theta}(\mathcal{V}^{(0)}_{g}|\mathcal{V}_{m}): \mathbb{E}_{p(\mathcal{V}_{g}|\mathcal{V}_{m})}[-\log(p_{\theta}(\mathcal{V}^{% (0)}_{g}|\mathcal{V}_{m}))]. (15) A detailed derivation of the loss function can be found in [58, 50]. The backbone neural network for the C-DMs in this work is based on a U-Net architecture [82], building upon the design previously used for unconditional Lagrangian turbulence generation [50]. To incorporate conditioning on the measurements, the input is modified as a combination of the measurement data and the noisy generation inside the gap, \mathcal{V}_{m}\cup\mathcal{V}_{g}^{(n)}, with additional channels that consist of the measurement and random noise within the gap. Fig. 8 provides a graphical representation of the U-Net architecture and its role in the C-DM refilling process. The U-Net architecture consists of two main components: a downsampling stack and an upsampling stack, which are arranged symmetrically. Both stacks perform four steps of downsampling and upsampling respectively, resulting in five stages from left to right for each stack. Across these five stages, the residual blocks are configured with channel sizes of \{1C,1C,2C,3C,4C\}, where C is 128. The last two stages of both stacks contain multi-head attention blocks, each with four heads. Connecting the downsampling and upsampling stacks is an intermediate module containing two residual blocks surrounding a central four-head attention block. The optimal noise schedule from [50] is applied, with a total of N=800 diffusion steps. Each specific C-DM case is trained with a batch size of 256 on four NVIDIA A100 GPUs, taking approximately 24 hours. (a)(b) Figure 8: (a) Schematic of the C-DM protocol for turbulent signal reconstruction. In the forward process (from right to left), noise is gradually added to the signal within the unknown region, \mathcal{V}_{g}=\mathcal{V}_{g}^{(0)}, over N steps according to a predefined schedule. The noisy signal at step n within the gap, \mathcal{V}_{g}^{(n)}, is represented by green lines. Partial measurements, \mathcal{V}_{s}, are represented by black points (for interpolation, top) or black lines (for gap filling, middle). In the backward process (from left to right), reconstruction starts with pure noise within the gap, \mathcal{V}_{g}^{(N)}, which is combined with the measurements to progressively denoise the missing information using the trained neural network. (b) The U-Net architecture of the neural network for a denoising step, p_{\theta}(\mathcal{V}^{(n-1)}_{g}|\mathcal{V}^{(n)}_{g},\mathcal{V}_{m}). The noisy signal at step n, \mathcal{V}_{g}^{(n)}, is first combined with the measurements to form a complete signal, which is then concatenated along the channel dimension with a signal consisting of the measurements outside the gap and random noise inside the gap. The network output has the length of a full signal, and only the part inside the gap is filtered out as \mathcal{V}_{g}^{(n-1)}."
https://arxiv.org/html/2411.07522v1,Protected chaos in a topological lattice,"The erratic nature of chaotic behavior is thought to erode the stability of periodic behavior, including topological oscillations. However, we discover that in the presence of chaos, non-trivial topology not only endures but also provides robust protection to chaotic dynamics within a topological lattice hosting non-linear oscillators. Despite the difficulty in defining topological invariants in non-linear settings, non-trivial topological robustness still persists in the parametric state of chaotic boundary oscillations. We demonstrate this interplay between chaos and topology by incorporating chaotic Chua’s circuits into a topological Su-Schrieffer-Heeger (SSH) circuit. By extrapolating from the linear limit to deep into the non-linear regime, we find that distinctive correlations in the bulk and edge scroll dynamics effectively capture the topological origin of the protected chaos. Our findings suggest that topologically protected chaos can be robustly achieved across a broad spectrum of periodically-driven systems, thereby offering new avenues for the design of resilient and adaptable non-linear networks.","Chaotic dynamics, despite being notoriously unpredictable and sensitive to initial conditions [1], govern the behavior of many complex systems [2, 3] such as networks of coupled oscillators and dynamical non-linear lattices [4, 5, 6, 7, 8]. In such coupled dynamical networks, even small perturbations are amplified rapidly, leading to complex global behaviors [4, 9, 10]. While synchronization can appear at times, chaos, with its inherent unpredictability, disrupts this order and makes the system decidedly irregular in the long run. However, we discover that this well-established pattern of behavior may no longer hold when a network of coupled chaotic oscillators is arranged in a topological manner. Despite the lack of well-defined band topological invariants in non-linear systems, we find that topological robustness potently persists, even as chaotic behavior introduces randomness that would erode the bulk periodicity and threaten any semblance of topological bulk-boundary correspondence. Surprisingly, not only can topological robustness be well-preserved in certain chaotic systems, it even protects chaotic oscillations from strong perturbations, demonstrating a parametric robustness inherited from band topology. This protection stems from the stability of non-trivial edge oscillations, whose absence would lead to the rapid decay of bulk chaotic attractors, as observed in the case of trivial edge oscillations. In this work, we choose chaotic Chua circuits among various potential candidates to implement the Lorenz system, as they offer an experimentally accessible and easily tunable platform for investigating chaotic dynamics [11, 12, 13]. Identical Chua circuits are coupled such that they form a one-dimensional topological Su-Schrieffer-Heeger (SSH) circuit array with onsite chaotic Chua oscillators [14, 15, 16, 17, 18, 19, 20, 21, 22]. In our setup, the degree of non-linearity can be adjusted by tuning the current-voltage characteristics of the Chua diodes, with high non-linearity typically expected to substantially distort linear eigenstates. In non-linear systems, a key challenge in attributing robustness to band topology is the difficulty in defining bulk topological invariants [23], which are inherently properties of linear band structures. To overcome this, we continuously deform the Chua circuit array from its linear SSH limit by tuning its non-linear Chua diodes. Notably, the topological edge oscillations are preserved remarkably well even deep into the non-linear regime. This allows for the identification of non-linear topological boundaries, which can be made further precise with the aid of machine learning techniques. Importantly, we emphasize that although we shall demonstrate topologically protected chaos only with Chua circuits, this novel form of robustness is not specific to the Lorenz equations, and extends generally to chaotic attractors with well-defined bounded oscillations. Furthermore, the physical implementation is applicable to any medium which can host the requisite non-linear dynamics, not just electronic circuit metamaterials. As such, our discovery of topologically protected chaos also opens up new possibilities in fields as diverse as neural networks [24, 25], chaotic quantum dynamics [26] and mechanical metamaterials [27]."
https://arxiv.org/html/2411.06755v1,Complexity measure of extreme events,"Complexity is an important metric for appropriate characterization of different classes of irregular signals, observed in the laboratory or in nature. The literature is already rich in the description of such measures using a variety of entropy and disequilibrium measures, separately or in combination. Chaotic signal was given prime importance in such studies while no such measure was proposed so far, how complex were the extreme events when compared to non-extreme chaos. We address here this question of complexity in extreme events and investigate if we can distinguish them from non-extreme chaotic signal. The normalized Shannon entropy in combination with disequlibrium is used for our study and it is able to distinguish between extreme chaos and non-extreme chaos and moreover, it depicts the transition points from periodic to extremes via Pomeau-Manneville intermittency and, from small amplitude to large amplitude chaos and its transition to extremes via interior crisis. We report a general trend of complexity against a system parameter that increases during a transition to extreme events, reaches a maximum, and then starts decreasing. We employ three models, a nonautonomous Liénard system, 2-dimensional Ikeda map and a 6-dimensional coupled Hindmarh-Rose system to validate our proposition.","The knowledge of extreme events, particularly in deterministic dynamical systems, has advanced significantly during the past three decades[1, 2, 3, 4, 5, 6]. Recent studies have primarily focused on real-world extreme phenomena. Extreme events are recognized as significantly large occasional deviations from long-term nominal behavior. The large deviations are short-living but occur recurrently or non-recurrently. Such extremes often have a size of more than 4 to 8 times the standard deviation of mean event size [7]. These phenomena have been studied across various disciplines, including oceanography [8, 9], climate science [10], sociology, economics [11, 12] and natural events like floods [13], earthquake and forest fire, for many years[14]. Since then a number of studies have been made on extreme events in a variety of systems including experiments such as optical fiber [15], laser systems [16, 17, 18, 19], mechanical systems [20, 21], electronic circuits [22, 23], and other systems [24, 25]. To develop a better understanding of extreme events, in general, the dynamical models are often used as basic tools for studies in addition to dealing with real-world data. These efforts led to finding tools which are now able to explain the origin of extremes in high-dimensional systems and networks of systems [26, 27, 28] and more complex natural events [5, 3]. The primary concern of extreme events research is to predict the time of arrival of such extremes and to address the most difficult question of predicting the magnitude of events. We address here another important question how to measure complexity that may distinguish extreme events from non-extreme complex dynamics such as the nominal chaos and if possible, locate the transition point from non-extreme to extreme events and vice versa in a parameter space. It is expected that complexity of extreme events shall be different due to the presence of occasional larger events, and distinguishable from nominal chaos when the trajectory is bounded in state space. The existing complexity measures depend primary on three categories of metrics, namely, Lyapunov exponent (LE) [29], fractal dimension [30, 31] and entropy [32, 33] that are usually used for chaos in deterministic dynamical systems. Researchers from other disciplines, physiology [34], painting [35], and machine learning [36], showed interest in identifying the complexity of signals from the general entropy measure. We emphasize here on Shannon entropy, which has been mainly proposed [37] as a measure of information content in a communication channel, however, it has also been used later for divergence measures [38]. Several other measures [39] have been developed from the Shannon entropy and used more frequently to characterize and for a possible quantification of complexity of dynamical systems’ behaviors from time series data. It includes, but is not limited to, topological entropy that measures the exponential growth rate of the systems’ distinguishable orbits [40], Kolmogorov–Sinai entropy that measures chaos and complexity of motion that occurs in dynamical systems [41]. However, the Shannon entropy itself, based on symbolic dynamics [42] or recurrence plot [43] although naturally produced large increase in complexity during a transition from periodic to chaotic state with a large amplitude, but they failed to recognize the emergence of extremes against a change of parameter. On the other hand, permutation entropy (PE) was proposed [44] as an important complexity measure basing on identification of ordinal patterns and their probability in a data sequence. The PE has dependence on selective parameters, namely, the embedding dimension and time delay. From a close look at the results presented earlier [44, 45], it is noticed that PE shows a large change of complexity during a transition from periodic or small amplitude to large amplitude chaos at least in the logistic map. The complexity then slowly increases reaching a saturation against the system parameter. Alternatively, entropy and disequilibrium have been combined [46, 47] for statistical complexity measure of observed signals in many systems. Disequilibrium is based on Euclidean distance [46], Wootters distance [48], entropy of Kullback-Shannon (or Tsallis or Rényi) [49], and the divergence of Jensen-Shannon (or Tsallis or Rényi) [50]. In a recent study, PE in combination with Jensen-Shannon disequilibrium was used [51] to measure complexity of chaos in logistic map. This work was also successful to record both the sudden large change in complexity during transitions from low amplitude chaos to large amplitude chaos against a parameter and the transition from periodic to large amplitude chaos in another parameter range. Once again, complexity increases sharply from small amplitude to large amplitude chaos and then saturates against a system parameter. A similar trend is seen during a transition from periodic to large amplitude chaos. However, none of the earlier works [42, 43, 44, 45, 51] dealt with systems or time series that showed occasional extremely large amplitude events. We are concerned about signals that show occasional large events. How complex are the extreme events and it changes during transitions from periodic to large amplitude chaotic state via PM intermittency [52] and low amplitude chaos to large amplitude chaos via interior crisis [53] when signature of extreme events does appear? Three exemplary systems that show origin of extreme events, are used for numerical validation of our proposed measure: Forced Liénard system [54], the Ikeda map [55] and a 6-dimensional coupled spiking-bursting Hindmarsh-Rose (HR) systems [56, 57] that shows a more complex basin structure [58]. We consider the product of Shannon entropy and disequilibrium that provides a consistency in complexity measure. The Shannon entropy is preferred to PE since it records information of each local maxima of a time series or a data sequence and then takes care of their probability measures. In PE measure, information on occasional large events are missing during symbolic representation of data sequence in search of ordinal patterns. We plot the bifurcation diagram for each of the considered systems against a parameter and delineate the regions of transitions via PM intermittency and interior crisis when extreme events appear. And capture the corresponding signal or time series (long enough) for each parameter and take care of each events (local maxima) in a time series or data sequence so that no information on the occasional large events are missed or ignored. Then we derive the normalized Shannon entropy and disequlibrium to estimate complexity as a product of both. We plot the complexity measure against a parameter and compare with the bifurcation diagram of each of the systems. The complexity shows a sharp increase during the PM intermittency when a transition occurs from periodicity to large amplitude chaos with the presence of occasional extreme events. After reaching a maximum against a parameter, complexity continues to decrease slowly with a transition to non-extreme chaos. Similarly, during the interior-crisis, we find a sharp rise in complexity during the transition from small amplitude chaos to large amplitude chaos with occasional extremes and then a slow decrease in complexity against a parameter after reaching a maximum. Our results show a trend of complexity different from the earlier reports [44, 45, 46, 47, 51]. and justify a trend of slow decrease in complexity beyond the regime of extreme events when the occasional large events gradually become more and more frequent. Thereby we are able to distinguish non-extreme chaotic events and extreme events and, their transitions against a parameter. For all the three systems, a similar trend is found for the two different nonlinear processes of origin of extreme events."
https://arxiv.org/html/2411.06199v1,"Control of the classical dynamics of a particle in the 
Morse-soft-Coulomb potential","We introduce the one-dimensional Morse-soft-Coulomb (MsC) potential consisting of a Morse repulsive barrier smoothly connected with a soft-core Coulomb potential at the origin. This new potential has a single parameter that controls the softness of the repulsive barrier and the well depth. When this softening-depth parameter tends to zero, the MsC potential approaches the Coulomb potential with an infinite repulsive barrier, a known successful model for the hydrogen atom. We investigate the classical chaotic dynamics of the MsC potential subjected to time-dependent external fields, comparing the results with the Coulomb potential. We show that the MsC potential reproduces the dynamics and the ionization probabilities of the Coulomb potential for sufficiently small values of the softening parameter. We also investigate the role of the softening parameter in the phase-space structures, showing that the increasing of its value leads to the increasing of the chaotic sea and consequently to the rise of the ionization probability. Finally, we address the problem of controlling the dynamics of a particle in the MsC potential from the perspective of optimal control theory, which cannot be easily applied in the case of the Coulomb potential due to the singularity at the origin. We analize a particular optimal solution to the problem of transferring a given amount of energy to the system at minimum cost. Our results show that the MsC potential can be a useful simple model for investigating the hydrogen atom.","One-dimensional model potentials are of fundamental importance for Physics since they contribute to a clear understanding of diverse complex atomic and molecular processes such as ionization and dissociation [1, 2, 3, 4, 5]. Standard examples are the Morse potential and the one-dimensional Coulomb potential used, respectively, in the study of dissociation of diatomic molecules and ionization of the hydrogen atom [6, 7, 8, 9, 10, 11, 12]. These models in conjunction with the tools of classical nonlinear dynamics provide important means of gaining physical insight in complicate situations. In particular, the classical approach has been proved to be a powerful tool for analysing the ionization of hydrogen atoms. For instance, the classical driven one-dimensional hydrogen atom yields good agreement with the experimentally determined ionization thresholds [13, 14, 15]. Nonlinear dynamics provides a general description for the escaping of a particle from a potential well, which can be regarded as atomic ionization or molecular dissociation depending on the model potential [8, 16, 17, 18, 19]. In the absence of external fields, the phase space is composed by a bound region, where the particle undergoes periodic motion, and by an unbound region, where the particle can depart from the potential well. Periodic time-dependent external fields can induce transitions from the bound to the unbound region by means of chaotic routes. For small field strength, some invariant curves remain in phase space, the so-called Kolmogorov–Arnold–Moser (KAM) tori, except in the vicinity of the nonlinear resonances, where resonance islands emerge enclosed by a localized chaotic regions. In this scenario, no escaping occurs, since the motion is still restricted in phase space. However, with increasing field strength, the resonance islands grows and overlap each other leading to the destruction of the KAM tori. The phase-space is then dominated by resonance islands and by a connected chaotic sea, where the particle can diffuse erratically and eventually escapes from the potential well. Although this the the main known escaping mechanism, we mention in passing that there exist also nonchaotic routes which leads to the escaping of the particle through deformed KAM tori [20]. When referring to the one-dimensional hydrogen atom model, two distinct Coulomb-like potentials are often considered: one is symmetric around the origin V(r)\propto-1/|r|, and the other has an infinite repulsive barrier at the origin V(r)\propto-1/r, such that the particle is constrained to move in the positive semi-axis r\geq 0. In both cases, the singularity has to be tackled to perform numerical calculations and to this end some techniques based on extended phase space have been developed [21, 22]. However, the issue with the singularity becomes more severe, or even prohibitive, when one tries to apply optimal control theory to these problems because the associated Euler-Lagrange equations involves spatial derivatives of the potential function. Since the optimal control of classically chaotic system is an important part of the control of molecular system [23, 24, 25], alternative approaches to the classical control of these singular potentials should be developed. To circumvent the singularity problem in the case of the symmetric Coulomb potential, Eberly and co-workers proposed the soft-Coulomb potential V(r)\propto-1/\sqrt{r^{2}+\alpha^{2}}, a well-behaved potential with a softening parameter \alpha [26, 27, 28, 29, 30, 2, 31, 32]. However, there has been no singularity-free, simple potential to mimic the Coulomb potential with an infinite repulsive barrier. To fill this gap, we introduce the Morse-soft-Coulomb (MsC) potential consisting of a Morse repulsive barrier smoothly connected with a soft-core Coulomb potential at the origin. This potential is differentiable up to second order while possessing a single parameter that sets the softness of the repulsive barrier and the well depth. The MsC potential approaches the Coulomb potential with an infinite repulsive barrier as the softening-depth parameter tends to zero. We consider the chaotic dynamics of the MsC potential subjected to harmonic driving field and show that the MsC potential reproduces the dynamics and the ionization probabilities of the Coulomb potential for small values of the softening parameter. We analyze the impact of the softening parameter in the phase-space structures, verifying that the increasing of its value leads to the increasing of the chaotic sea and to the rise of the ionization probability. We also address the problem of controlling the dynamics of a particle in the MsC potential using optimal control theory. We consider the problem of transferring a given amount of energy to the system at minimum effort and investigate a particular solution, termed intrinsic optimal solution [33]."
https://arxiv.org/html/2411.07005v1,"Detecting time-irreversibility in multiscale systems: 
correlation and response functions in the Lorenz96 model","Due to their relevance to geophysical systems, the investigation of multiscale systems through the lens of statistical mechanics has gained popularity in recent years. The aim of our work is the characterization of the nonequilibrium properties of the well-known two-scales Lorenz96 model, a dynamical system much used for testing ideas in geophysics, by studying either higher-order correlation functions or response to external perturbations of the energy. These tools in both equilibrium (inviscid) or non-equilibrium (viscous) systems provide clear evidence of their suitability for detecting time-reversal symmetry breaking and for characterizing transport properties also in this class of models. In particular, we characterize how localized energy perturbations are transported between the different scales, highlighting that perturbations of synoptic variables greatly impact advective variables but perturbations of the latter have a practically negligible effect on synoptic scales. Finally, we show that responses of global observables to finite size perturbations strongly depend on the perturbation protocol. This prevents the physical understanding of the system from observations of the relaxation process alone, a fact often overlooked.","The study of geophysical phenomena is notoriously challenging for both mathematicians and physicists. The inherent complexity can be attributed to the nontrivial interactions existing between the system components possessing different length and time scales, but also to the mere difficulty (even computational) of properly taking into account the enormous amount of variables needed to describe any relevant observable. These difficulties could be overcome with a clever modelization of the phenomenon, having the twofold aim of simplifying the interactions appearing in the original equations and reduce the number of degrees of freedom. Naturally the procedure of discarding variables and interactions is rather delicate: the resulting equations still need to be a valid approximation of the original ones, and have to reproduce as faithfully as possible the features (either dynamical or statistical) of our system. E. N. Lorenz clearly understood the advantages of simplified models Lorenz (2005) to gain some insight on complex phenomena, especially when dealing with geophysical flows. The “Lorenz63 model"" Lorenz (1963), a hyper-simplified modelization of thermal convection, had an enormous impact on chaos theory and fluid mechanics, and arguably represents the prototypical chaotic model for most computational studies. Less popular, yet with quite a considerable influence, is another model that became known as “Lorenz96"" Lorenz (1995). The original aim was the study of atmospheric predictability, and the possibility to gain information about the spreading of initial small uncertainties by exploiting dynamical models attempting to reproduce atmospheric circulation. Lorenz presented two versions of the model. He first introduced a single-scale model where the dynamical variables, placed along a latitude circle, have asymmetric nonlinear couplings and are subject to constant forcing and linear damping. The combination of these three actions can roughly account for most geophysical phenomena taking place in the atmosphere. In the same work, Lorenz also proposed a two-scales version of the model, where the interacting variables have either slow or fast dynamics. Resolving the faster scales as well should make the model more adherent to real physics. The wide influence of the Lorenz96 model is proved by the plethora of works which adopted it as the core of their studies or as a case study for applying new concepts. It was employed likewise in physics Boffetta et al. (2000); Lacorata and Vulpiani (2007); Karimi and Paul (2010); Gallavotti and Lucarini (2014); van Kekem and Sterk (2018), mathematics Orrell and Smith (2003); Stappers and Barkmeijer (2012); de Leeuw et al. (2018); Kerin and Engler (2020) and geosciences Basnarkov and Kocarev (2012); Sterk et al. (2012); Carlu et al. (2019), just to mention a few. In this work we are interested in the characterization, in the two-scales Lorenz96 model, of temporal nonequilibrium properties as revealed by two effective indicators of the absence of statistical equilibrium: high-order time correlation functions Pomeau (1982) and response functions Kubo (1966); Marconi et al. (2008). There are several reasons for choosing the Lorenz96 model for our purposes: the presence of nonlinear interactions between variables hinders the use of the solid theoretical framework built for linear systems, thereby making necessary the use of computer simulations. Since we have access to the explicit evolution equations, we can choose to study the ‘standard’ model, namely a driven dissipative system, which is far from statistical equilibrium, or else the ‘reversible’ model, where damping and external forcing are put to zero and the total energy is a global conserved quantity, so that the system is in statistical equilibrium in the microcanonical sense. In the following we will refer to the original model as “viscous"" or “irreversible"" Lorenz96, and to the model without forcing and damping as “inviscid"" or “reversible"" Lorenz96. In this respect, it becomes especially interesting to analyze the differences between the two above-mentioned indicators when they refer to the former or the latter version of the model. Non-symmetric third-order time correlation functions provide results that fit well with recent studies Lucente et al. (2023a); Cocciaglia, Cencini, and Vulpiani (2024), for what concerns their ability to discriminate between statistical equilibrium and nonequilibrium: correlation functions in the reversible model show very small deviations from zero, while the same functions in the irreversible model are characterized by a large short-time peak followed by relaxation to zero, thus the time dependence is more nontrivial. The second indicators, namely the response functions Marconi et al. (2008) of the ‘local’ (related to a single d.o.f.) energies, reveal interesting dynamical properties. Specifically, the spreading of an initially-localized energy perturbation highlights the presence of statistical fluxes that behave as travelling waves. This happens only in the irreversible model, while in the reversible case the response functions display an asymptotic approach to equipartition, as expected from equilibrium statistical mechanics considerations. The paper is structured as follows: in Sec. II we introduce the model and delineate the main differences between the reversible and irreversible versions. In Sec III, the statistical properties of the system are characterized through the lens of non-equilibrium statistical mechanics. In particular, Sec. III.1 deals with higher-order correlation functions while Sec. III.2 examines the responses of the system to external perturbations. Finally, in Sec. IV we draw the main conclusions and present possible perspectives."
https://arxiv.org/html/2411.06847v1,Human game experiment to verify the equilibrium selection controlled by design,"We conducted a laboratory experiment involving human subjects to test the theoretical hypothesis that equilibrium selection can be impacted by manipulating the games dynamics process, by using modern control theory. Our findings indicate that human behavior consists with the predictions derived from evolutionary game theory paradigm. The consistency is supported by three key observations: (1) the long-term distribution of strategies in the strategy space, (2) the cyclic patterns observed within this space, and (3) the speed of convergence to the selected equilibrium. These findings suggest that the design of controllers aimed at equilibrium selection can indeed achieve their theoretical intended purpose. The location of this study in the knowledge tree of evolutionary game science is presented.","The primary objective of this experiment study is to validate the consistency between theoretical predictions and experimental results. In our prior theoretical research [22], we demonstrated how to manipulate game equilibrium selection using the pole assignment method, which is a sophisticated full-state feedback technique rooted in modern control theory [14, 7, 4]. While previous experimental work has shown how to implement the pole assignment approach for controlling dynamic structures in laboratory experiment involving human subjects [21, 1], there has been no exploration of its application to equilibrium selection in such contexts. Figure 1 shows the location of this study (in red text), equilibrium selection by controller, in the knowledge tree of evolutionary game theory and experiment. The tree represents the fundamental concepts of dynamics system theory in mathematics. Differential Equations \dot{x}=f(x)Equilibrium x^{*}Jacobian J\big{|}_{x^{*}}Velocity \dot{x}\big{|}_{x}[10, 17, 16]Eigenvalue \lambdaReImReImEigenvector \etaStability \tau[2, 11, 3]Angular velocity \omega[15]Eigencycle \sigma[19, 23]Coherence \kappaMulti modes [13]Distribution [8, 18, 6, 23, 3]Collapse [20]ControllerEquilibrium selection[22] and This studyMode control [21] Figure 1: The location of this study, equilibrium selection (in red text) by controller, in the knowledge tree of evolutionary game theory and experiment, or called as evolutionary game science. This knowledge tree is presented in the linearization paradigm of dynamics system theory in mathematics. The controller is using pole assignment approach in modern control theory in engineering. The references for related concepts are the existed experimental literatures with associated theory. This experimental study is based on the previous theoretical work [22], where a five-strategy game was employed to demonstrate the pool assignment method to control the equilibrium selection. In this experimental study, we will utilize the same five-strategy game to realize the control and to verify the consistency. 1.1 Theoretical background Table 1: The game matrix x1 x2 x3 x4 x5 x1 0 0 2 0 -2 x2 2 0 0 -2 0 x3 0 2 0 2 -1 x4 -2 0 1 0 1 x5 0 -2 -2 1 0 The theoretical study [22] used a symmetric 5-strategy one population game, whose payoff matrix is shown in Table 1. The game has and only has two equilibrium (Nash_1 and Nash_2) as shown in Fig. 2. The locations of the two Nash equilibrium of the game are \displaystyle{\text{Nash\_1}}=\!\frac{1}{3}(1,1,1,0,0) (1) \displaystyle{\text{Nash\_2}}=\!\frac{1}{2}(0,0,0,1,1) (2) In replicator dynamics [9] as the estimator, the eigenvalues at the Nash_1 denoted as \lambda^{o}_{\text{Nash\_1}} are \lambda^{o}_{\text{Nash\_1}}=\left[\begin{array}[]{rrrrr}-\frac{1-\sqrt{3}i}{3% }&-\frac{1+\sqrt{3}i}{3}&-\frac{2}{3}&-1&-2\\ \end{array}\right]. (3) The associated eigenvector, v_{\text{Nash\_1}}, which presents the dynamics structure, is as follow. v_{\text{Nash\_1}}=\left[\begin{array}[]{rrrrr}(-.289&(-.289&.577&.151&-.161\\ -.5i)&+.5i)&&&\\ (-.289&(-.289&.577&-.030&-.462\\ +.5i)&-.5i)&&&\\ .577&.577&.577&-.757&-.221\\ 0&0&0&.636&0\\ 0&0&0&0&.844\\ \end{array}\right] (4) Notice that, the imaginary part of the first two eigenvalues are not zero, then the performance of the two associated eigenvectors (1st and 2nd columns) could be a rock-paper-scissors cycle, which is known recently [23, 19] Utilizing the pole assignment approach, we can manipulate the eigenvalues at the Nash equilibrium point, Nash_1. In simpler terms, we employ pole assignment to regulate the eigenvalues, which determine the stability of the game evolution, of Nash_1 by introducing various constant values b for different experimental treatment. This can be mathematically expressed as follows: \displaystyle\lambda^{c}_{\text{Nash\_1}} \displaystyle= \displaystyle\lambda^{o}_{\text{Nash\_1}}+b~{}\Big{[}~{}1~{}~{}1~{}~{}0~{}~{}0% ~{}~{}0~{}\Big{]} (5) \displaystyle= \displaystyle\left[\begin{array}[]{rrrrr}\big{(}b-\frac{1-\sqrt{3}i}{3}\big{)}% &\big{(}b-\frac{1+\sqrt{3}i}{3}\big{)}&-\frac{2}{3}&-1&-2\\ \end{array}\right]. (7) It is clear that, the original system (b=0 condition) is stable at Nash_1. At the same time, b=1/3 is the marginal value for control to switch the stability form stable (when b<1/3) to unstable (when b>1/3). Referring to the control parameter b, the performance of the game system should be difference, which can be derive in dynamics theory and provides a series of theoretical predictions [22]. Figure 2: Conceptual figure: In a five strategy game, the two equilibrium (Nash_1 and Nash_2) locate in the two sub space S_{1}(x_{1},x_{2},x_{3}) and S_{2}(x_{4},x_{5}), respectively. The pole assignment can be designed to make the Nash_1 being unstable. As consequence, the long run trajectory will converge to Nash_2, which means that the equilibrium Nash_2 is selected. Alternatively, the pole assignment can be designed to make the Nash_1 being more stable, then Nash_1 will be long rum distribution center. This figure comes from [22]. 1.2 Theoretical predictions In theory, we have completed the controller design, utilizing the workflow outlined in [22]. Furthermore, the theoretical predictions of the controller have been validated through numerical agent-based simulations, demonstrating good consistency. In human game experiments, the theoretical predictions remain valid and will be verified. 1. When b<1/3, Nash_1 will be selected equilibrium; when b>1/3, Nash_2 will be selected equilibrium. 2. The convergence speed will be faster, when \Big{|}b-1/3\Big{|} being larger. 3. When When b<1/3, cycles exist constantly; when b>1/3, cycles do not exist."
https://arxiv.org/html/2411.06472v1,"Generalized Eigenspaces and Pseudospectra 
of Nonnormal and Defective
Matrix-Valued Dynamical Systems","We consider nonnormal matrix-valued dynamical systems with discrete time. For an eigenvalue of matrix, the number of times it appears as a root of the characteristic polynomial is called the algebraic multiplicity. On the other hand, the geometric multiplicity is the dimension of the linear space of eigenvectors associated with that eigenvalue. If the former exceeds the latter, then the eigenvalue is said to be defective and the matrix becomes nondiagonalizable by any similarity transformation. The discrete-time of our dynamics is identified with the geometric multiplicity of the zero eigenvalue \lambda_{0}=0. Its algebraic multiplicity takes about half of the matrix size at t=1 and increases stepwise in time, which keeps excess to the geometric multiplicity until their coincidence at the final time. Our model exhibits relaxation processes from far-from-normal to near-normal matrices, in which the defectivity of \lambda_{0} is recovering in time. We show that such processes are realized as size reductions of pseudospectrum including \lambda_{0}. Here the pseudospectra are the domains on the complex plane which are not necessarily exact spectra but in which the resolvent of matrix takes extremely large values. The defective eigenvalue \lambda_{0} is sensitive to perturbation and the eigenvalues of the perturbed systems are distributed densely in the pseudospectrum including \lambda_{0}. By constructing generalized eigenspace for \lambda_{0}, we give the Jordan block decomposition for the resolvent of matrix and characterize the pseudospectrum dynamics. Numerical study of the systems perturbed by Gaussian random matrices supports the validity of the present analysis.Keywords: Nonnormal matrices, Defective eigenvalue, Pseudospectrum dynamics, Generalized eigenspaces, Jordan decompositions of resolvents, Symbol curves2020 Mathematics Subject Classification: 15A18; 15A20; 15B05; 47A10; 60B20","Consider a matrix M\in\mathbb{C}^{n\times n}. We write its Hermitian conjugate as M^{\dagger} defined by the complex conjugate of the transpose; M^{\dagger}:=\overline{M^{\mathsf{T}}}. If it satisfies the equality M^{\dagger}M=MM^{\dagger}, then it is said to be normal and can be diagonalized by a unitary transformation. Hermitian matrices satisfying M^{\dagger}=M fall in this class. We introduce two notions of degeneracy of eigenvalues. The algebraic multiplicity is the number of times the eigenvalue appears as a root of the characteristic polynomial of M, while the geometric multiplicity is the dimension of the linear space of the eigenvectors associated to the eigenvalue. When the geometric multiplicity is equal to the algebraic multiplicity for all eigenvalues, the matrix M has a complete set of eigenvectors. In this case, even if M is nonnormal, it can be reduced to a diagonal matrix \Lambda by a similarity transformation as \Lambda=V^{-1}MV. Here the j-th column of V is given by the j-th linearly independent eigenvector, j=1,2,\dots,n, and V^{-1} is well defined. But if the algebraic multiplicity of an eigenvalue exceeds the geometric multiplicity, then that eigenvalue is said to be defective and the matrix becomes nondiagoralizable. Consider the shift matrix with size n\geq 2, S=S_{n}:=\Big{(}\delta_{j\,k-1}\Big{)}_{1\leq j,k\leq n}=\left(\begin{array}[]% {cccccc}0&1&&&\smash{\lower 7.3194pt\hbox{\bg 0}}&\\ &0&1&&&\\ &\ldots&\ldots&&&\\ &&\ldots&\ldots&&\\ &&&0&1&\\ &&&&0&1\\ &\smash{\hbox{\bg 0}}&&&&0\end{array}\right), (1.1) where \delta_{jk} denotes the Kronecker delta. It is obvious that S^{k}=0 for k\geq n. Let b_{j}\in\mathbb{C}, j=1,2,\dots, and consider nilpotent Toeplitz matrices, S(m):=S^{m}+b_{1}S^{m+1}+\cdots+b_{n-m-1}S^{n-1}, (1.2) for m=1,2,\dots,n-1. Notice that S(m), m=1,2,\dots,n-1 are non-Hermitian and nonnormal. Since all the elements of the diagonal and lower triangular part of S(m) are zero, \lambda_{0}:=0 is the only eigenvalue. Hence, the algebraic multiplicity of \lambda_{0}, which is denoted by a_{0}(m), is n for any m=1,2,\dots,n-1. For each m=1,2,\dots,n-1, any vector \bm{v}_{0}(m) in the form \bm{v}_{0}(m)=(v_{01}(m),v_{02}(m),\cdots,v_{0m}(m),0,\cdots,0)^{\mathsf{T}} can be an eigenvector for \lambda_{0}. The dimension of the complex space spanned by these eigenvectors is m. Hence the geometric multiplicity g_{0}(m) of \lambda_{0} is m. We notice that g_{0}(1)=a_{0}(1)=1, but g_{0}(m)<a_{0}(m),\quad m=2,3,\dots,n-1. That is, the eigenvectors fail to span \mathbb{C}^{n}. In this case, the eigenvalue \lambda_{0} is defective and there is no similarity transformation which reduces S(m) to any diagonal form. Although S(m) is nondiagonalizable, a similarity transformation can reduce the matrix to the Jordan canonical form, \mathbb{J}(m)=V(m)^{-1}S(m)V(m). The diagonal elements of \mathbb{J}(m) are still all zero, but some of the upper 2nd-diagonal elements can be 1. More precisely, \mathbb{J}(m) is decomposed into g_{0}(m)-ple Jordan blocks which are given by shift matrices (1.1), \mathbb{J}(m)=\bigoplus_{\ell=1}^{g_{0}(m)}S_{d_{0}^{(\ell)}(m)}, (1.3) where the sizes of them are denoted by d_{0}^{(\ell)}(m), \ell=1,2,\dots,g_{0}(m). By convention, we assume the non-increasing order, d_{0}^{(1)}(m)\geq d_{0}^{(2)}(m)\geq\cdots\geq d_{0}^{(g_{0}(m))}(m). Each d_{0}^{(\ell)}(m) gives the dimension of the generalized sub-eigenspace which includes the \ell-th eigenvector \bm{v}_{0}^{(\ell)}(m) associated with the zero-eigenvalue \lambda_{0}, \ell=1,2,\dots,g_{0}(m). They satisfy the sum rule \sum_{\ell=1}^{g_{0}(m)}d_{0}^{(\ell)}(m)=a_{0}(m). By definition, if d_{0}^{(\ell)}\equiv 1, \ell=1,2,\dots,g_{0}, then g_{0}=a_{0} and the matrix is normal. Therefore, k_{0}(m):=\max\{d_{0}^{(\ell)}(m):\ell=1,2,\dots,g_{0}(m)\}=d_{0}^{(1)}(m) (1.4) will indicate the degree of defectivity of the zero-eigenvalue \lambda_{0} measuring how far from being normal. It is called the index of \lambda_{0}. Eigenvalue analysis is one of the most successful method of applied mathematics. Roughly speaking, eigenvalues give us the abstraction of a matrix by plotting the set of them (spectra) on a complex plane \mathbb{C}. For defective matrices, however, eigenvalue analysis fails. In the above case with S(m), the unique eigenvalue at zero with full algebraic multiplicity a_{0}(m)\equiv n misleads us to identify S(m) with the null (all-zero) matrix O. The Jordan-block structure with zero diagonal can not be represented only by spectra. (a) (b) (c) Figure 1: (a) One sampling result of numerically obtained eigenvalues of the system with Gaussian perturbation matrix Z; S^{(b)}(m,\delta Z)=S^{m}+bS^{m+1}+(1/\sqrt{2n})Z, where n=5000, m=3, and b=1. (b) Superpositions of 50 samples. (c) Symbol curve of \widehat{S}^{m}+b\widehat{S}^{m+1} with m=3 and b=1. The structure of S(m) hidden in eigenvalue analysis is revealed by its sensitivity to perturbation. Let Z be a matrix with independently and normally distributed complex entries; Z_{jk}=X_{jk}+iY_{jk} with X_{jk}\sim{\rm N}(0,1), Y_{jk}\sim{\rm N}(0,1), i:=\sqrt{-1}. Here we consider a simple case for (1.2) such that b_{1}=b\in\mathbb{C}, b_{j}=0 for j\geq 2. Figure 1 shows plots of the numerically obtained eigenvalues, when the complex Gaussian random matrix Z is added, S^{(b)}(m,\widetilde{\delta}Z):=S^{m}+bS^{m+1}+\widetilde{\delta}Z, (1.5) where n=5000, m=3, b=1, and the coefficient of Z is given by \widetilde{\delta}=\widetilde{\delta}(n)=1/\sqrt{2n}=1/100. The dots are not the eigenvalues of the original matrix, S^{(b)}(m,0)=S^{m}+bS^{m+1}, but they represent the structure of this defective matrix in the sense explained below. Hence they are called the pseudo-eigenvalues of S^{(b)}(m,0). (More precisely speaking, the domains on \mathbb{C} in which the eigenvalues of randomly perturbed matrix are distributed are called the pseudospectra of the original unperturbed matrix having defective eigenvalues [6, 22, 25].) Instead of the n\times n shift matrix (1.1), here we consider an infinite-size shift matrix, \widehat{S}:=S_{\infty}=(\delta_{j\,k-1})_{1\leq j,k<\infty}. (1.6) which will represent a nilpotent Toeplitz operator. We also consider an infinite-dimensional vector \widehat{\bm{v}} in the form \widehat{\bm{v}}=(1,z,z^{2},z^{3},\cdots)^{\mathsf{T}}, z\in\mathbb{C}. Then we see that (\widehat{S}^{m}+b\widehat{S}^{m+1})\widehat{\bm{v}}=f(z)\widehat{\bm{v}}\quad% \mbox{with}\quad f(z)=z^{m}+bz^{m+1}. (1.7) The 2-norm of \widehat{\bm{v}}, \|\widehat{\bm{v}}\|:=(\sum_{j=1}^{\infty}|\widehat{v}_{j}|^{2})^{1/2}=(1-|z|^% {2})^{-1/2}, is finite if z is inside the unit circle \mathbb{T}:=\{z\in\mathbb{C}:|z|=1\}. The function f(z) is known as the symbol of the Toeplitz operator \widehat{S}^{m}+b\widehat{S}^{m+1}. The image of \mathbb{T} by the map f, f(\mathbb{T}), is called the symbol curve of \widehat{S}^{m}+b\widehat{S}^{m+1} and is drawn in Fig.1 for b=1 [6, 25]. In Fig.1, the plots of eigenvalues of the perturbed systems line up along the symbol curve f(\mathbb{T}). For all z\in\mathbb{C}, |z|<1, the vectors \widehat{\bm{v}} satisfying (1.7) give eigenvectors of eigenvalues f(z)=z^{m}+bz^{m+1}, m-1,2,\dots,n-1 in \ell^{2}-space. It is proved that the spectrum of the Toeplitz operator \widehat{S}^{m}+b\widehat{S}^{m+1} is equal to f(\mathbb{T}) with all the points enclosed by this curve (see, [22, Theorem 2.1], [25, Theorem 7.1]), and Section 5 (i) below). If numerically obtained eigenvalues of (1.5) were all superposed, they will fill the region bounded by the outmost curve of the symbol curve f(\mathbb{T}). Figure 1 shows superposition of the plots of 50 samples. Mathematical study of random perturbations of banded Toeplitz matrices, see [1, 2, 3, 4, 5, 23] and references therein. Recently, the notion of pseudospectra has attracted much attention in stochastic analysis of time-dependent random matrix theory [13, 19]. The non-Hermitian matrix-valued Brownian motion (BM) is defined by M(t)=(M_{jk}(t))_{1\leq j,k\leq n}:=\left(\frac{1}{\sqrt{2n}}(B^{{\rm R}}_{jk}% (t)+iB^{{\rm I}}_{jk}(t))\right)_{1\leq j,k\leq n},\quad t\geq 0, where (B^{{\rm R}}_{jk}(t))_{t\geq 0}, (B^{{\rm I}}_{jk}(t))_{t\geq 0}, 1\leq j,k\leq n are 2n^{2} independent one-dimensional standard BMs [7, 8, 9, 12, 17]. This process is regarded as the dynamical extension of the complex Ginibre ensemble, since if it starts from the null matrix, M(0)=O, the distribution of eigenvalues at an arbitrary time t>0 is identified with the complex Ginibre ensemble of eigenvalues with variance t [16], which has been extensively studied in random matrix theory [10, 13]. Burda et al. [9] studied the process (M(t))_{t\geq 0} starting from M(0)=S. By numerical simulation they found that the eigenvalues seem to expand instantly from \lambda_{0} to a unit circle \mathbb{T}. For the time interval 0<t<1, the dots form a growing annulus. Then the inner radius of the annulus shrinks to zero at t=1 and dots fill up a full unit disk. This observation shall be compared with the eigenvalues of the matrix (1.5) with m=1 and b=0, where perturbation was given by a Gaussian complex random-matrix Z. When m=1 and b=0, the symbol is f(z)=z and hence the symbol curve is simply a unit circle, f(\mathbb{T})=\mathbb{T}. The transition from a unit circle to a unit disk in the time period t\in(0,1] reported by Burda et al. [9] will be regarded as a sampling process of eigenvalues for the perturbed nilpotent Toeplitz matrix. They seem to cluster along the symbol curve \mathbb{T} when the sampling number is small, while they tend to fill the unit disk as the sampling number becomes large. Motivated by the above consideration, we will study the following matrix-valued dynamical system [20], S^{(b)}(t,\delta J):=S^{t+1}+bS^{t+2}+\delta J, (1.8) with discrete time t=0,1,\dots,T, where the final time is defined by T=T(n):=n-2. Here b,\delta\in\mathbb{C} and J is the all-ones matrix; J=(J_{jk})_{1\leq j,k\leq n} with J_{jk}\equiv 1,\quad j,k=1,2,\dots n, which gives the additive rank 1 perturbation [14] to the nilpotent Toeplitz matrices, S^{(b)}(t,0)=S^{t+1}+bS^{t+2}. Figure 2: Time-evolution of the geometric multiplicity g_{0}, the algebraic multiplicity a_{0}, and the degree k_{0} of \lambda_{0} are shown by black, red, and blue dots, respectively, for t=1,2,\dots,T:=n-2 with n=100. Figure 3: Time evolution of Young diagram representing the dynamics of the Jordan canonical form associated with \lambda_{0}. The upper-left diagram is for the initial time t=1 with \lfloor n/2\rfloor boxes and the right diagram is for the final time t=T with n-2 boxes. Here we have drawn the case with n=17. The lower-left diagram shows the intermediate state at time t=5. In this case n=17 is indivisible by t+1=6; (t+1)\nmid n. Then k_{0}=\lfloor n/(t+1)\rfloor+1=3, n-(t+1)\lfloor n/(t+1)\rfloor-1=4. We will show the following. (i) The discrete time t is equal to the geometric multiplicity of \lambda_{0}, g_{0}(t)=t,\quad t=0,1,\dots,T. (1.9) (See Proposition 3.1 in Section 3.1.) In other words, we consider the matrix-valued dynamical system such that the dimension of the eigenspace in the narrow sense associated with \lambda_{0} is growing in time. (ii) All non-zero eigenvalues of S^{(b)}(t,\delta J) are given by simple roots of a polynomial equation with degree p_{1}(t)+1 with p_{1}(t):=\left\lfloor\frac{n-1}{t+1}\right\rfloor, (1.10) where \lfloor x\rfloor denotes the greatest integer less than or equal to x\in\mathbb{R} (the floor function of x) [20]. This determines the algebraic multiplicity of \lambda_{0} as a_{0}(t)=n-p_{1}(t)-1,\quad t=0,1,\dots,T. (1.11) (See Theorem 2.1 in Section 2.) Note that with a fixed n, a_{0}(t) is increasing stepwise in t [20]. Notice that a_{0}(0)=0; that is, the origin is not an eigenvalue at t=0. When the origin becomes an eigenvalue at t=1, its algebraic multiplicity has a large value \lfloor n/2\rfloor, that is, approximately half of the matrix size n, while the system has only one (g_{0}(1)=1) eigenvector. Non-zero eigenvalues are being absorbed one by one to the origin [20], and the algebraic multiplicity a_{0}(t) increases stepwise in time. The speed of increment of a_{0}(t) is slowing down as t increases, but it keeps excess to g_{0}(t) until t=n-3. At the final time t=T, \lambda_{0} has a_{0}(T)=n-2=T leaving only two non-zero eigenvalues on \mathbb{C}. There are g_{0}(T)=T linearly independent eigenvalues at that time. The coincidence a_{0}(T)=g_{0}(T) makes the matrix be diagonalizable. (iii) Although g_{0}(0)=a_{0}(0)=0 and g_{0}(T)=a_{0}(T)=T, the inequality holds as g_{0}(t)<a_{0}(t),\quad t=1,2,\dots,T-1. That is, the matrices S^{(b)}(t,\delta J) are nonnormal and \lambda_{0} is defective. We will construct the generalized eigenspaces associated with \lambda_{0} explicitly and prove that the index of \lambda_{0} is given by k_{0}(t)=\begin{cases}\displaystyle{\frac{n}{t+1}},&\quad\mbox{if $(t+1)\mid n% $},\cr\cr\displaystyle{\left\lfloor\frac{n}{t+1}\right\rfloor+1},&\quad\mbox{% if $(t+1)\nmid n$},\end{cases} (1.12) where (t+1)\mid n (resp. (t+1)\nmid n) means that n is divisible (resp. indivisible) by t+1. (See Proposition 3.2 in Section 3.1.) The degree of nonnormality is the highest value at the beginning; k_{0}(1)=n/2 if n is even and k_{0}(1)=(n+1)/2 if n is odd. The defectivity of \lambda_{0} is then decreasing stepwise in time. We put k_{0}(T)=1 by convention. See Fig.2 (iv) At each time t=1,2,\dots,T-1, by a similarity transformation, S^{(b)}(t,\delta J) is reduced to the following form, \mathbb{J}(t)\oplus{\rm diag}(\lambda_{1}(t),\lambda_{2}(t),\dots,\lambda_{p_{% 1}(t)+1}), (1.13) where the Jordan canonical form \mathbb{J}(t) is decomposed into t-ple Jordan blocks as \mathbb{J}(t)=\begin{cases}\underbrace{S_{k_{0}(t)}\oplus\cdots\oplus S_{k_{0}% (t)}}_{t},&\mbox{if $(t+1)\mid n$},\cr\underbrace{S_{k_{0}(t)}\oplus\cdots% \oplus S_{k_{0}(t)}}_{n-(t+1)\lfloor n/(t+1)\rfloor-1}\oplus\underbrace{S_{k_{% 0}(t)-1}\oplus\cdots\oplus S_{k_{0}(t)-1}}_{t-n+(t+1)\lfloor n/(t+1)\rfloor+1}% ,&\mbox{if $(t+1)\nmid n$}.\end{cases} (1.14) (See Section 3.1.) The Jordan canonical form is represented by a Young diagram [11, 15]. Figure 3 shows dynamics of Young diagram corresponding to (1.14). It starts from a single row diagram with \lfloor n/2\rfloor boxes at time t=1 and ends with a single column diagram with n-2 boxes at time t=T. (As mentioned at the end of (ii) above, at the final time t=T, S^{(b)}(T,\delta J)=S^{n-1}+\delta J can be diagonalized into the form, {\rm diag}(\underbrace{0,\cdots,0}_{T},\lambda_{1}(T),\lambda_{2}(T)), |\lambda_{1}(T)|>|\lambda_{2}(T)|>0 instead of (1.13).) The time t is identified with the number of rows and the total number of boxes is given by a_{0}(t) which increases stepwise in time. The relaxation process of the defectivity of \lambda_{0} is represented by the stepwise decreasing of the number of columns. In summary, the present dynamical systems (S^{(b)}(t,\delta J))_{1\leq t\leq T}, b,\delta\in\mathbb{C}, represent relaxation processes of matrices from being far-from-normal to being near-normal, in which the defective eigenvalue \lambda_{0} is recovering in time. The paper is organized as follows. In Section 2 we derive the polynomial equation for the non-zero eigenvalues and discuss their time-evolution. Section 3 is devoted to the analytical study of the pseudospectra, in particular, the pseudospectrum including the defective eigenvalue \lambda_{0}=0. In Section 3.1 we explain how to construct the generalized eigenspace associated with \lambda_{0}, which is decomposed into t sub-spaces and gives the t-ple Jordan blocks for the similarity transformation of the matrix at each time t, We perform the Jordan decomposition of resolvent of the matrix, introduce the notion of generalized condition number, and then evaluate the 2-norm of the resolvent (Proposition 3.6) in Section 3.2. In Section 3.3, we give the first definition of \varepsilon-pseudospectrum (Definition 3). Then an estimation of the \varepsilon-pseudospectra is given by Theorem 3.8. This theorem clarifies the (t,n)-dependence of the pseudospectrum including \lambda_{0}. In order to show the validity of our analytical study, we perform numerical calculation for the processes perturbed by Gaussian complex random matrices in Section 4. In Section 4.1, we show the second definition of \varepsilon-pseudospectrum (Definition 4.1) which is equivalent with the first one. By this definition, the pseudospectrum is characterized by the sensitivity of \lambda_{0} with respect to perturbations. Actually, we show in Section 4.2, that (t,n)-dependence of the domain, in which the eigenvalues of the perturbed systems are accumulated, is consistent with Theorem 3.8 for the pseudospectrum including \lambda_{0}. Finally in Section 5 future problems are listed out."
https://arxiv.org/html/2411.06304v1,Widespread neuronal chaos induced by slow oscillating currents,"This paper investigates the origin and onset of chaos in a mathematical model of an individual neuron, arising from the intricate interaction between 3D fast and 2D slow dynamics governing its intrinsic currents. Central to the chaotic dynamics are multiple homoclinic connections and bifurcations of saddle equilibria and periodic orbits. This neural model reveals a rich array of codimension-2 bifurcations, including Shilnikov-Hopf, Belyakov, Bautin, and Bogdanov-Takens points, which play a pivotal role in organizing the complex bifurcation structure of the parameter space. We explore various routes to chaos occurring at the intersections of quiescent, tonic-spiking, and bursting activity regimes within this space, and provide a thorough bifurcation analysis. Despite a high dimensionality of the model, its fast-slow dynamics allow a reduction to a one-dimensional return map, accurately capturing and explaining the complex dynamics of the neural model. Our approach integrates parameter continuation analysis, newly developed symbolic techniques, and Lyapunov exponents, collectively unveiling the intricate dynamical and bifurcation structures present in the system.","Figure 1: (A) Close-up of the widespread chaotic region (red) in a bi-parametric sweep of \rm\Delta[Ca] and \rm\Delta V_{x}. The colormap illustrates the Lyapunov spectrum, with each RGB component representing a different Lyapunov exponent. The red channel corresponds to positive largest Lyapunov exponents (LLE). Green and blue both correspond to negative second Lyapunov exponents, but at different magnitudes - green indicates values closer to zero, and blue represents more negative values. Chaotic regions appear red, while non-chaotic regions are blue. Representative voltage traces are overlaid on the parameter space: tonic spiking (left), a hyperpolarized quiescent state (bottom), and regular bursting (top-right). The chaotic region is centered around the bifurcation curve \rm homSF (yellow line) corresponding to a Shilnikov saddle-focus. This curve extends from the codimension-2 Shilnikov-Hopf (ShH) bifurcation point located on the subcritical Andronov-Hopf (\rm AH_{sub}) bifurcation line (green dashed line). The \rm homPO_{t} curve (orange line), which separates the chaotic region from the quiescent region below, corresponds to a non-transverse homoclinic to a saddle periodic orbit (PO). In the region marked by the orange dot, situated between the \rm AH_{\rm sub} curve and the \rm homPO_{t} curve, the model exhibits bistability between chaotic and hyperpolarized quiescent attractors (see Fig. 15). Thin white lines within the chaotic region indicate saddle-node bifurcations of periodic orbits, adjacent to stability windows. (B) Chaotic voltage trace corresponding to the parameter values at the red diamond in panel A, showing the irregular bursting dynamics observed within the chaotic region. Chaos in bursting neuronal systems can be compared to a kaleidoscope, where a single object fractures into intricate, shifting patterns – each rotation revealing new layers of complexity [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]. This analogy reflects the central focus of our study: an unusually broad region of chaos in a conductance-based neuronal model of the Hodgkin-Huxley type. In our model, the topological structure of the system amplifies chaotic dynamics, where a small seed of chaos is repeatedly fragmented and replicated, leading to widespread complexity. This amplification is driven by the underlying geometry of spike generation, which propagates and multiplies the seeds of chaos across a broad parameter space. We were intrigued by the vastness of this chaotic region, which far exceeds the narrow bands of chaos typically observed in both biologically realistic and phenomenological models during transitions, such as spike-adding. This finding challenges the prevailing view that chaotic behavior is confined to narrow parameter ranges. By studying a region where chaotic dynamics are naturally widespread and robust, we aim to uncover new insights into the mechanisms enabling flexible and adaptable oscillatory patterns, which may align more closely with the variability observed in biological neurons. In this paper, we provide a detailed exploration of this expansive chaotic region, emphasizing the diverse pathways leading to chaos across its boundaries. One of the key features of neuronal systems, including isolated neurons in both normal and dysfunctional states, is the occurrence of self-sustained oscillations, regular or irregular, with varying recurrence times [13, 14, 15, 16, 17]. These oscillations are typically stable in the Lyapunov sense [18], whereas chaotic oscillations are inherently unstable [19]. Current mathematical models of neurons, however, often struggle to reproduce the desired neuronal qualities, such as variability and flexibility [20], due to the deterministic nature of the modeling approach. Introducing noise into the model can address this limitation, particularly when the system is positioned close to semi-global bifurcations underlying transitions between activity types such as quiescent states (stable equilibria), tonic spiking and bursting oscillations (stable periodic orbits) – where the dynamics become sensitive to small perturbations [21]. In contrast, far from bifurcations, mathematical models with exponentially stable (i.e., structurally stable) solutions remain robust against noise and other small perturbations, persistently exhibiting the same activity patterns [22, 23]. The rigidity of most neuronal models arises from their classification as slow-fast systems with significant time-scale disparities between variables. In such models, typically consisting of two slow and one fast variable (or the reverse configuration), variability in the dynamics is only observed within narrow intervals corresponding to rapid transitions in parameter space [22]. Although noise can artificially widen these transition intervals, this approach remains a synthetic approximation of the fluidity observed in biological systems. The absence of well-explored neuronal models that exhibit flexible or widespread chaotic oscillations highlights the importance of our study. By developing a comprehensive framework for studying these chaotic oscillations, our work lays the groundwork for in-depth studies of other neural models that more accurately capture the adaptability and variability of neuronal activity. These insights could prove invaluable in both theoretical neuroscience and in the design of artificial systems that emulate biological flexibility. The key to generating flexible self-oscillations in this neuron model lies in the natural widening and overlapping of spike-adding transitions as they approach a Shilnikov saddle-focus bifurcation in the parameter space. This bifurcation is well known in the dynamical systems community [24, 25, 26, 27, 28, 29], but less familiar in the context of neuronal modeling [30, 31]. The homoclinic bifurcation culminates in a more exotic phenomenon, the cod-2 Shilnikov-Hopf (ShH) or Belyakov-I point [32], where the Shilnikov homoclinic saddle-focus meets the subcritical Andronov-Hopf (\rm AH_{sub}) bifurcation in the parameter space of the model. Globally, the homoclinic structure interacts with the spiking manifold \rm M_{PO}, which expands, coils, and folds the flow, generating a topological Smale horseshoe in the phase space of the neuron model. The interaction of the homoclinic structure with the tonic spiking manifold constitutes a rich bifurcation and dynamical “Klondike” in the model under investigation: its codimension-1 (cod-1) and codimension-2 (cod-2) bifurcations far exceed the typical range. These include other bifurcations of equilibria with characteristic exponents (0,0) (the Bogdanov-Takens point) and (0,\,\pm i\omega) (fold-Hopf due to Gavrilov and Guckenheimer), sub- and super-critical Andronov-Hopf bifurcations, the cod-2 Bautin point, multiple homoclinic bifurcations [33, 34], another cod-2 Belyakov-II bifurcation describing a homoclinic saddle to saddle-focus transition [35], the blue-sky catastrophe [23, 39, 36, 37, 38], period-doubling cascades, likely a torus bifurcation with 1:2-resonance, and various hereto-dimensional cycles, among others. To explore this wealth of dynamical phenomena, we employ a comprehensive set of topological and computational tools, including slow-fast decomposition, MATCONT parameter continuation, symbolic dynamics, conditional block entropy, templates, Lyapunov exponents, and one-dimensional return maps. This paper is structured as follows: it begins with a description of the model, followed by theoretical background to provide context and foundational concepts. The main results start with the interpretation of three two-dimensional bifurcation diagrams, followed by illustrations of the homoclinic structure arising from the saddle-focus. Next, we illustrate the topology of the pseudo-attractor using templates. Finally, we employ one-dimensional maps to investigate the routes to chaos through the Shilnikov-Hopf bifurcation, the degeneration of spike-adding transitions, and homoclinic tangencies. The paper concludes with an in-depth discussion of these results, their implications, and future research directions."
https://arxiv.org/html/2411.05792v1,"Events in Noise-Driven Oscillators: Markov Renewal Processes and the
“Unruly” Breakdown of Phase-Reduction Theory","We introduce an extension to the standard reduction of oscillatory systems to a single phase variable. The standard reduction is often insufficient, particularly when the oscillations have variable amplitude and the magnitude of each oscillatory excursion plays a defining role in the impact of that oscillator on other systems, i.e. on its output. For instance, large excursions in bursting or mixed-mode neural oscillators may constitute events like action potentials, which trigger output to other neurons, while smaller, sub-threshold oscillations generate no output and therefore induce no coupling between neurons. Noise induces diffusion-like dynamics of the oscillator phase on top of its otherwise constant rate-of-change, resulting in the irregular occurrence of these output events. We model the events as corresponding to distinguished crossings of a Poincare section. Using a linearization of the noisy Poincare map and its description under phase-isostable coordinates, we determine the diffusion coefficient for the occurrence and timing of the events using Markov renewal theory. We show that for many oscillator models the corresponding point process can exhibit “unruly” diffusion: with increasing input noise strength the diffusion coefficient vastly increases compared to the standard phase reduction analysis, and, strikingly, it also decreases when the input noise strength is increased further. We provide a thorough analysis in the case of planar oscillators, which exhibit unruliness in a finite region of the natural parameter space. Our results in part explain the surprising synchronization behavior obtained in pulse-coupled, mixed-mode oscillators as they arise, e.g., in neural systems.","1 Introduction 1.1 Background: Phase reduction, Population Dynamics of Coupled and Noise-driven Oscillators, and Limitations Phase reduction is a well-established dimension-reduction technique for dynamical systems that exhibit limit cycle oscillations (Winfree,, 1980; Kuramoto,, 1984; Ermentrout and Terman,, 2010; Schultheiss et al.,, 2012). In appropriate limits, such as weak perturbative forcing or strong contraction to the limit cycle, it replaces the possibly high-dimensional oscillator state by a single phase variable \phi, which represents the oscillator’s ‘internal clock’, and allows one to describe the long-time dynamics of the oscillator by a single differential equation for \phi. Since this achieves a substantial reduction in the complexity of the description, phase reduction is a powerful tool for the analysis of individual and coupled oscillators (Kuramoto,, 1984) and their applications in many areas, including neuroscience (Stiefel and Ermentrout,, 2016) and circadian rhythms (Gunawan and Doyle,, 2006). In the presence of noise and in the limit of infinitely many oscillators, globally coupled oscillators can be described by a nonlinear, non-local Fokker-Planck equation for the population distribution \rho(\phi,t) of the phase (Shinomoto and Kuramoto,, 1986; Strogatz and Mirollo,, 1991; Kilpatrick and Ermentrout,, 2011; Karamchandani et al.,, 2018), \frac{\partial\rho(\phi,t)}{\partial t}=D_{\textit{phase}}\frac{\partial^{2}% \rho(\phi,t)}{\partial\phi^{2}}-\frac{\partial}{\partial\phi}\left[f_{0}\rho(% \phi,t)+\gamma\left(\mbox{nonlinear, nonlocal interaction term}\right)\right]. (1) In this framework, a key role in determining the tendency of the oscillators to synchronize is played by the diffusion coefficient of the phase, D_{\textit{phase}}. It represents the leading impact of the noise on the oscillators, which tends to distribute their phases uniformly. (1) quantifies the intuition that, as long as the diffusion is small in comparison with the strength \gamma of the interactions between the oscillators, coherent population-level dynamics, like synchronous states, will emerge. In particular, (1) predicts that coherent states arise for coupling strengths \gamma above a critical value \gamma_{\textit{crit}} that is proportional to D_{\textit{phase}}: \gamma>\gamma_{\textit{crit}}\propto D_{\textit{phase}} (Figure 1c, dashed line). This prediction should be accurate in the limit of weak interactions and weak noise. In previous work (Karamchandani et al.,, 2018), we applied the Fokker-Planck framework to mixed-mode oscillations comprised dichotomously of large- and small-amplitude oscillations (Figure 1a). This model arose in a neuronal context where only the large oscillations, which represent action potentials, lead to any output to other neurons via chemical synapses. Therefore, from the perspective of the other neurons in the network only these large-amplitude oscillations are relevant events, and it is their timing that determines the population-level dynamics. Numerical simulations reveal transitions from asynchrony to synchrony and more exotic coherent states, which depend on the strength of the noise D_{\textit{in}}. Standard phase reduction provides a direct linear connection between D_{\textit{in}} and D_{\textit{phase}}, and thus the Fokker-Planck theory (1) predicts the onset \gamma_{\textit{crit}} for these coherent states as a function of the input noise strength D_{\textit{in}}. For the mixed-mode oscillations investigated in Karamchandani et al., (2018), that prediction fails spectacularly when compared to simulation of the full system, even when the noise and the interactions are relatively weak (compare the dashed line and blue dots in Figure 1c). To wit, it vastly underestimates the strength of the oscillator interactions needed to overcome the independent noise and produce coherent dynamics states. In our previous work, we found that the amount of diffusion is substantially underestimated by the phase reduction theory, since D_{\textit{phase}} does not take into account the fact that the oscillators interact only via the amplitude-dependent events. Standard phase reduction, it turns out, fails because it discards key amplitude information. 1.2 Going Beyond Standard Phase Reduction: Events and Effective Phase The need to go beyond the standard phase reduction has been recognized previously in various other contexts, e.g. in shear-induced chaos (Lin and Young,, 2008) and systems involving multiple time scales (Monga and Moehlis,, 2021; Lin et al.,, 2013). Recent works have considered augmenting the phase variable with one or more amplitude-like variables to increase the fidelity of the reduction (see e.g. Wedgwood et al., (2013); Castejon and Guillamon, (2013)). Of particular interest is the phase-isostable reduction (Wilson and Moehlis,, 2016), offering a coordinate system in which the unperturbed oscillator has especially simple dynamics. Here we offer an event-centric extension to the standard phase reduction. In particular, we address the influence of noise on oscillators in which the oscillatory excursions can be divided into two classes: excursions that qualify as events and excursions that do not. More concretely, describing each oscillatory excursion as the crossing of a Poincare section, events correspond to a crossing within a limited domain of the Poincare section; crossings outside that domain constitute non-events. In the neuronal mixed-mode oscillators, for example, only the large-amplitude peaks in the voltage are events (action potentials), whereas small-amplitude extrema are non-events. In noise-driven oscillators, the events occur in an irregular fashion and define a stochastic point process. We are particularly interested in the long-term statistics of the events that reflect the degree of diffusion in the stochastic process. The quantity that is of central interest for the description of the event irregularity is the growth rate of the variance of the total number of events with time, which we propose to call the “temporal variance growth rate” (TVGR)111This quantity has also been referred to as “the slope of the variance-time curve” (Cox,, 1966). and represent by the symbol \mathcal{V}_{E}^{\left(t\right)}. As it turns out, this quantity has a direct relationship to the phase diffusion coefficient D_{\textit{phase}} in the limit of weak noise. Namely, \mathcal{V}_{E}^{\left(t\right)}\sim 2D_{\textit{phase}} as D_{\textit{in}}\rightarrow 0. This connection between the event-based TVGR and the phase diffusion motivates us to introduce an effective phase that increases by 1 between events, whose diffusion coefficient is given by an effective phase diffusion D_{\textit{eff}}\equiv\frac{1}{2}\mathcal{V}_{E}^{\left(t\right)}. In our previous work (Karamchandani et al.,, 2018), we suggested that D_{\textit{phase}} be replaced by D_{\textit{eff}} in (1) as a way to remedy the deficiencies in the Fokker-Planck theory. We determined D_{\textit{eff}} computationally via simulations of a single, uncoupled oscillator and found that it indeed compensates for the discrepancy in the predictions and recovers the actual onset of coherent states (Figure 1b,c). The effective phase thus not only provides an intuitive picture of the long-time dynamics of the events for an isolated oscillator, but also captures quantitatively the synchronization behavior of a large ensemble of such oscillators when their interaction is contingent on the events. Comparing the effective diffusion with the phase diffusion shows just how poorly the standard phase reduction performs: D_{\textit{eff}}, which accounts for the fact that the oscillators interact only via the amplitude-dependent events, is orders of magnitude larger than D_{\textit{phase}} (Figure 1b). Strikingly, we find that the effective diffusion coefficient, exhibits “unruly” behavior for a wide range of oscillators: while in the limit of weak noise the effective diffusion coefficient D_{\textit{eff}} converges to the diffusion coefficient D_{\textit{phase}} obtained from the standard phase reduction, already for surprisingly small values of the noise it can become orders of magnitude larger than D_{\textit{phase}}, only to decrease when noise is increased further to larger values (see Figure 1b for an example). For coupled such oscillators, this implies strongly enhanced sensitivity to desynchronization for intermediate noise values and reduced sensitivity for strong noise (Karamchandani et al.,, 2018). In the present work, we address the source and abundance of the unruliness in the TVGR and thus the effective diffusion coefficient. In contrast with our prior, purely computational approach, we obtain explicit expressions for the TVGR by considering the point process that arises from a linearized Poincare map. The paradigm of point processes has already previously been used in the analysis of oscillatory and excitable systems. In neuroscience, for example, the times T_{n} at which action potentials occur in a neuron are often considered to arise from a point process. Indeed, the distribution of so-called inter-spike-intervals, T_{n+1}-T_{n}, is a subject of great interest (see e.g. (Gabbiani and Cox,, 2010)). More broadly, point-process theory offers various measures of the temporal variability in oscillatory and excitable dynamics (Table 1). The Fano factor, for instance, has been used to measure the similarity of a given point process to a Poisson process, which has a Fano factor of 1. For noise-driven, nonlinear oscillatory and excitable systems, the Fano factor and effective diffusion coefficient have each been used to identify a variety of “resonances” that appear as a function of input noise strength: coherence resonance and incoherence maximization (Pikovsky and Kurths,, 1997; Lindner et al.,, 2002). The analysis of point processes is often limited to renewal processes, i.e. to point processes in which the intervals between events are independent and identically distributed. Noise-driven limit-cycle oscillators will, however, in general maintain correlations from one cycle to the next and therefore do not fit the framework of renewal processes. Indeed, non-renewal dynamics are seen in real world oscillatory systems (Farkhooi et al.,, 2009; Gabbiani and Cox,, 2010; Avila-Akerberg and Chacron,, 2011). These correlations do not preclude a description of the oscillators within the framework of point processes. In this work, we therefore include correlations in the time intervals between events by considering the Markov renewal process associated with the stochastic Poincare map. Figure 1: Effective Diffusion in a Mixed-Mode Oscillator (Karamchandani et al.,, 2018). (a): Sample voltage traces of a neural mixed-mode oscillator driven by noise. Only the large-amplitude excursions are events in which the oscillator produces “output”; the small-amplitude excursions are non-events. In the absence of noise, a fixed, periodic pattern of alternating large-amplitude and small-amplitude oscillations is produced. With noise D_{\textit{in}}, “phase slips” perturb the pattern, in which events are added or omitted. (b): The phase diffusion D_{\textit{phase}} from phase reduction theory and the effective diffusion D_{\textit{eff}} (same data shown on two different scales), treating large-amplitude oscillations as events. As a function of the input diffusion strength, D_{\textit{eff}} initially agrees with D_{\textit{phase}}. But it becomes greatly amplified for moderate noise strengths and then eventually decreases as the noise strength increases. We call this qualitative non-monotonic behavior “unruly”. (c): A phase diagram for population states in globally coupled oscillators. Standard phase reduction with the Fokker-Planck theory, (1), predicts that the boundary between stable coherent states and stable incoherence is linear. The theory only agrees with the full, coupled-oscillator simulation once D_{\textit{phase}} is replaced with D_{\textit{eff}}. 1.3 Organization of the Paper The paper is organized as follows. In Section 2 we introduce the effective phase via the events and their variance statistics and outline in more detail our approach for its analysis. In the somewhat technical Section 3 and the corresponding Supplementary Information (SI) Section S1, we review the theory for variance statistics of Markov and Markov renewal reward processes, offering a novel formula for the TVGR. We use that formula in Section 4 to demonstrate in a simple toy model how unruliness can arise in \mathcal{V}_{E}^{\left(t\right)}, offering an simple explanation of the eventual decrease of the TVGR with increasing noise strength. We then apply the general theory to the linearization of Poincare map dynamics for limit cycle oscillators in the Section 5 and the corresponding SI Section S3. In Section 6 we narrow our focus to two-dimensional oscillators and make an argument that unruliness in \mathcal{V}_{E}^{\left(t\right)} is a common occurrence. We conclude with plausible extensions to this work in Section 7 and a broader discussion in Section 8."
