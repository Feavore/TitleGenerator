URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.04953v1,Quantum Threshold is Powerful,"In 2005, Høyer and Špalek showed that constant-depth quantum circuits augmented with multi-qubit Fanout gates are quite powerful, able to compute a wide variety of Boolean functions as well as the quantum Fourier transform. They also asked what other multi-qubit gates could rival Fanout in terms of computational power, and suggested that the quantum Threshold gate might be one such candidate. Threshold is the gate that indicates if the Hamming weight of a classical basis state input is greater than some target value.We prove that Threshold is indeed powerful—there are polynomial-size constant-depth quantum circuits with Threshold gates that compute Fanout to high fidelity. Our proof is a generalization of a proof by Rosenthal that exponential-size constant-depth circuits with generalized Toffoli gates can compute Fanout. Our construction reveals that other quantum gates able to “weakly approximate” Parity can also be used as substitutes for Fanout.","To what extent are large multi-qubit gates useful for quantum computation? On the one hand, it is well-known that every multi-qubit gate can be decomposed into a circuit of simpler 1111- and 2222-qubit gates. On the other hand, this decomposition may introduce large overheads both in terms of gate count and circuit depth. Given that some multi-qubit gates might be experimentally feasible [22, 14, 16], it’s natural to ask what kinds of computational powers they unlock. Specifically, we focus on the power of these large multi-qubit gates in constant depth. Such shallow circuits are experimentally appealing due to the possibility for less decoherence. Moreover, even shallow quantum circuits with 1111- and 2222-qubit gates are known to be surprisingly powerful, exhibiting quantum advantage in a variety of settings [4, 9, 25, 11]. Given the inherent complexity of simulating such circuits, there is the exciting possibility that augmenting these circuit models with large multi-qubit gates might lead to constant-depth implementations of practical quantum algorithms. Much of the excitement about such circuit models is driven by a single gate—the multi-qubit Fanout gate—which is the quantum operation that copies classical information: 𝖥n⁢\ket⁢b,x1,…,xn:=\ket⁢b,x1⊕b,…,xn⊕bformulae-sequenceassignsubscript𝖥𝑛\ket𝑏subscript𝑥1…subscript𝑥𝑛\ket𝑏direct-sumsubscript𝑥1𝑏…direct-sumsubscript𝑥𝑛𝑏\mathsf{F}_{n}\ket{b,x_{1},\ldots,x_{n}}:=\ket{b,x_{1}\oplus b,\ldots,x_{n}% \oplus b}sansserif_F start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊕ italic_b , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ⊕ italic_b for all b,x1,…,xn∈{0,1}𝑏subscript𝑥1…subscript𝑥𝑛01b,x_{1},\ldots,x_{n}\in\{0,1\}italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ { 0 , 1 }. This seemingly innocuous gate (which is included for free in almost every classical circuit model) turns out to be quite powerful. For starters, it is locally equivalent via conjugation by Hadamard gates to the quantum Parity gate [17], 𝖯n⁢\ket⁢b,x1,…,xn:=\ket⁢b⊕(x1⊕⋯⊕xn),x1,…,xn,formulae-sequenceassignsubscript𝖯𝑛\ket𝑏subscript𝑥1…subscript𝑥𝑛direct-sum\ket𝑏direct-sumsubscript𝑥1⋯subscript𝑥𝑛subscript𝑥1…subscript𝑥𝑛\mathsf{P}_{n}\ket{b,x_{1},\ldots,x_{n}}:=\ket{b\oplus(x_{1}\oplus\cdots\oplus x% _{n}),x_{1},\ldots,x_{n}},sansserif_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := italic_b ⊕ ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊕ ⋯ ⊕ italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , which is a duality that has no classical counterpart [1]. Moreover, there are constant-depth quantum circuits with Fanout (and arbitrary single-qubit gates) for a wide variety of other symmetric Boolean operations such as And/Or and Majority [13, 24]. Perhaps most impressively, constant-depth quantum circuits with Fanout gates can factor integers with polynomial-time classical post-processing [13]. Given the centrality of Fanout to the story of low-depth circuits with multi-qubit gates, there has been significant work in trying to understand if other multi-qubit gates are similarly powerful. Most notably, it is widely believed that the multi-qubit generalization of the Toffoli gate is fundamentally less powerful than the Fanout gate in constant depth, and there is long line of work giving evidence that these generalized Toffoli gates cannot compute Fanout [3, 6, 21, 19, 18, 2]. In some sense, all of these results are grappling with a fundamental tension in the study of these low-depth circuit models—the high entanglement in the states produced by these circuits is an obstacle to proving lower bounds, but it is simultaneously unclear how one could leverage this complexity to implement a useful quantum algorithm. There is a surprising dearth of low-depth circuit models with multi-qubit gates that are as powerful as Fanout. One natural111This candidate looks considerably more natural after considering the analogous landscape of classical circuits, which we discuss in Section 1.1. candidate for a gate that could be as powerful as Fanout is the quantum Threshold gate, a multi-qubit gate parameterized by some value k∈ℕ𝑘ℕk\in\mathbb{N}italic_k ∈ blackboard_N: 𝖳𝗁kn⁢\ket⁢b,x1,…,xn:=\ket⁢b⊕𝕀|x|≥k,x1,…,xnformulae-sequenceassignsubscriptsuperscript𝖳𝗁𝑛𝑘\ket𝑏subscript𝑥1…subscript𝑥𝑛direct-sum\ket𝑏subscript𝕀𝑥𝑘subscript𝑥1…subscript𝑥𝑛\mathsf{Th}^{n}_{k}\ket{b,x_{1},\ldots,x_{n}}:=\ket{b\oplus\mathbb{I}_{|x|\geq k% },x_{1},\ldots,x_{n}}sansserif_Th start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := italic_b ⊕ blackboard_I start_POSTSUBSCRIPT | italic_x | ≥ italic_k end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT where 𝕀|x|≥ksubscript𝕀𝑥𝑘\mathbb{I}_{|x|\geq k}blackboard_I start_POSTSUBSCRIPT | italic_x | ≥ italic_k end_POSTSUBSCRIPT indicates if the Hamming weight of the input bit string x=x1⁢⋯⁢xn∈{0,1}n𝑥subscript𝑥1⋯subscript𝑥𝑛superscript01𝑛x=x_{1}\cdots x_{n}\in\{0,1\}^{n}italic_x = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⋯ italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is at least the target value k𝑘kitalic_k. In fact, Høyer and Špalek asked almost 20 years ago about the power of Threshold in constant depth [13]: “Can we simulate unbounded fan-out in constant depth using unbounded fan-in gates, e.g. threshold⁡[t]threshold𝑡\operatorname{threshold}[t]roman_threshold [ italic_t ] or exact⁡[t]exact𝑡\operatorname{exact}[t]roman_exact [ italic_t ]?” This question was reiterated more pointedly by Takahashi and Tani in 2011 [24]: “Does there exist a fundamental gate that is as powerful as an unbounded fan-out gate?” We directly answer both of these questions in the affirmative by giving explicit constructions for Fanout using quantum Threshold gates: Theorem 1. There are poly-size constant-depth quantum circuits consisting of Threshold gates and arbitrary single-qubit gates that compute Fanout with high fidelity. Formally, \ComplexityFont⁢B⁢Q⁢T⁢C0=\BQNCw⁢f0\ComplexityFont𝐵𝑄𝑇superscript𝐶0subscriptsuperscript\BQNC0𝑤𝑓\ComplexityFont{BQTC}^{0}=\BQNC^{0}_{wf}italic_B italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT. The construction from this theorem actually reveals a number of other gates that are as fundamentally powerful as the Fanout gate. As it turns out, the salient feature of Threshold for our purposes is that it can be used to construct a sort of “weak” Parity gate—a gate that only acts non-trivially on inputs of the same parity. Based on this idea, we introduce a class of multi-qubit phase gates that exhibit a generalization of this behavior. Formally, these gates are defined with respect to a set S⊂{0,1}n𝑆superscript01𝑛S\subset\{0,1\}^{n}italic_S ⊂ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT in the following way: US⁢\ket⁢x1,…,xn:=(−1)𝕀x∈S⁢\ket⁢x1,…,xn.formulae-sequenceassignsubscript𝑈𝑆\ketsubscript𝑥1…subscript𝑥𝑛superscript1subscript𝕀𝑥𝑆\ketsubscript𝑥1…subscript𝑥𝑛U_{S}\ket{x_{1},\ldots,x_{n}}:=(-1)^{\mathbb{I}_{x\in S}}\ket{x_{1},\ldots,x_{% n}}.italic_U start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := ( - 1 ) start_POSTSUPERSCRIPT blackboard_I start_POSTSUBSCRIPT italic_x ∈ italic_S end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT . Crucially, we restrict our attention to “parity-restricted” sets S𝑆Sitalic_S, that is, sets where all elements have the same parity (i.e., x,y∈S⟹|x|≡|y|(mod2)𝑥𝑦𝑆𝑥annotated𝑦pmod2x,y\in S\implies|x|\equiv|y|\pmod{2}italic_x , italic_y ∈ italic_S ⟹ | italic_x | ≡ | italic_y | start_MODIFIER ( roman_mod start_ARG 2 end_ARG ) end_MODIFIER). We show that these weak parity gates can be bootstrapped in constant depth into true Parity gates (which, recall, are locally-equivalent to Fanout) albeit with the help of a few generalized Toffoli gates: Theorem 2. Let {Sn}nsubscriptsubscript𝑆𝑛𝑛\{S_{n}\}_{n}{ italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT be a family of parity-restricted sets with size |Sn|=Θ⁢(2n/\poly⁢(n))subscript𝑆𝑛Θsuperscript2𝑛\poly𝑛|S_{n}|=\Theta(2^{n}/\poly(n))| italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT | = roman_Θ ( 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT / ( italic_n ) ). There are poly-size constant-depth quantum circuits consisting of USnsubscript𝑈subscript𝑆𝑛U_{S_{n}}italic_U start_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT gates, generalized Toffoli gates, and arbitrary single-qubit gates that compute Fanout with high fidelity. Since it is widely believed that multi-qubit Toffoli gates are not themselves sufficient to implement Fanout, the power of this construction likely derives from the weak parity gates. In fact, the reason these Toffoli gates were not required for Theorem 1 is due to the fact that Threshold can directly simulate Toffoli. In that vein, we also give conditions under which the USnsubscript𝑈subscript𝑆𝑛U_{S_{n}}italic_U start_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT gates alone suffice to simulate Parity; namely, when |Sn|≥2n−O⁢(1)subscript𝑆𝑛superscript2𝑛𝑂1|S_{n}|\geq 2^{n-O(1)}| italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT | ≥ 2 start_POSTSUPERSCRIPT italic_n - italic_O ( 1 ) end_POSTSUPERSCRIPT or |Sn|≤2(1−ϵ)⁢nsubscript𝑆𝑛superscript21italic-ϵ𝑛|S_{n}|\leq 2^{(1-\epsilon)n}| italic_S start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT | ≤ 2 start_POSTSUPERSCRIPT ( 1 - italic_ϵ ) italic_n end_POSTSUPERSCRIPT. Though, the later condition will result in circuits of super-polynomial size. While it has long been thought that Fanout/Parity gates were morally equivalent to other quantum modular arithmetic gates, those constructions seem to also require these generalized Toffoli gates [8]. By a careful inspection of the original construction presented in [8] we find that generalized Toffoli gates are in fact not necessary. Formally, the quantum Mod-p𝑝pitalic_p gates is defined as 𝖬𝖮𝖣pn⁢\ket⁢b,x1,…,xn:=\ket⁢b⊕\Modpn⁢(x),x1,…,xn,formulae-sequenceassignsuperscriptsubscript𝖬𝖮𝖣𝑝𝑛\ket𝑏subscript𝑥1…subscript𝑥𝑛direct-sum\ket𝑏superscriptsubscript\Mod𝑝𝑛𝑥subscript𝑥1…subscript𝑥𝑛\mathsf{MOD}_{p}^{n}\ket{b,x_{1},\ldots,x_{n}}:=\ket{b\oplus\Mod_{p}^{n}(x),x_% {1},\ldots,x_{n}},sansserif_MOD start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_b , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT := italic_b ⊕ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_x ) , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , where \Modpn⁢(x)superscriptsubscript\Mod𝑝𝑛𝑥\Mod_{p}^{n}(x)start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_x ) is 1111 when p𝑝pitalic_p divides the Hamming weight of x=x1,⋯,xn∈{0,1}nformulae-sequence𝑥subscript𝑥1⋯subscript𝑥𝑛superscript01𝑛x=x_{1},\cdots,x_{n}\in\{0,1\}^{n}italic_x = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. For example, the Mod-2222 gate is essentially the Parity gate (up to a single-qubit X𝑋Xitalic_X gate). It is implicit in [8] that Fanout can be computed by a circuit consisting of Mod-p𝑝pitalic_p gates and one- and two-qubit gates, yielding \QNCw⁢f0=\QNC0⁢[2]⊆\QNC0⁢[q]subscriptsuperscript\QNC0𝑤𝑓superscript\QNC0delimited-[]2superscript\QNC0delimited-[]𝑞\QNC^{0}_{wf}=\QNC^{0}[2]\subseteq\QNC^{0}[q]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ 2 ] ⊆ start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_q ] for all q≥2𝑞2q\geq 2italic_q ≥ 2, but not necessarily that \QNC0⁢[p]=\QNC0⁢[q]superscript\QNC0delimited-[]𝑝superscript\QNC0delimited-[]𝑞\QNC^{0}[p]=\QNC^{0}[q]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ] = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_q ] for distinct p𝑝pitalic_p and q𝑞qitalic_q. The result they make explicit is that when Toffoli gates are allowed, any Mod-q𝑞qitalic_q gate can be obtained using any other Mod-p𝑝pitalic_p gate (by first implementing Fanout with Mod-q𝑞qitalic_q gates and then computing Mod-p𝑝pitalic_p with Fanout and generalized Toffoli gates). Concretely; \QAC0⁢[p]=\QAC0⁢[q]superscript\QAC0delimited-[]𝑝superscript\QAC0delimited-[]𝑞\QAC^{0}[p]=\QAC^{0}[q]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ] = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_q ] for p,q≥2𝑝𝑞2p,q\geq 2italic_p , italic_q ≥ 2. Only later was it shown that generalized Toffoli gates can be implemented using Fanout and single- and two-qubit gates i.e. that \QNCw⁢f0=\QACw⁢f0subscriptsuperscript\QNC0𝑤𝑓subscriptsuperscript\QAC0𝑤𝑓\QNC^{0}_{wf}=\QAC^{0}_{wf}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT [13, 24]. In light of these results we observe the following: Theorem 3. For all p,q≥2𝑝𝑞2p,q\geq 2italic_p , italic_q ≥ 2, there are poly-size constant-depth quantum circuits consisting of Mod-p𝑝pitalic_p gates and single-qubit gates that compute the Mod-q𝑞qitalic_q operation. Formally, \QNC0⁢[p]=\QNC0⁢[q]superscript\QNC0delimited-[]𝑝superscript\QNC0delimited-[]𝑞\QNC^{0}[p]=\QNC^{0}[q]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ] = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_q ]. 1.1 Comparison to the classical setting Our focus on shallow circuits draws considerable inspiration from the analogous study of classical constant-depth circuit classes with large fan-in gates, which has been hugely influential in classical complexity theory. For instance, initial work in Boolean circuits saw the development of techniques for proving unconditional lower bounds such as random restrictions [1, 7, 27, 12], Fourier analytic methods [15], and polynomial methods [20, 23]. So how do we compare the quantum and classical settings? And what does this comparison tell us about the power of quantum circuits in constant depth? To start, classical circuits classes (e.g., \NC0superscript\NC0\NC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, \AC0superscript\AC0\AC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, \TC0superscript\TC0\TC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, …) typically assume that the output of any gate can be used as input for any number of other other gates (i.e., a gate’s output can be “fanned out” to other gates). Of course, this is exactly the kind of fanout that immediately becomes so powerful when given to a constant-depth quantum circuit. In fact, because of this fanout, the classical Threshold gate reigns supreme amongst similar classical circuit complexity classes. This is due to the fact that constant-depth classical circuits with Fanout and Threshold can compute any Boolean function where the output depends only on the Hamming weight of the input.222To see this, first notice that for any k𝑘kitalic_k, there is a constant-depth circuit with two Threshold gates that computes whether or not the input has Hamming weight exactly k𝑘kitalic_k. Since any symmetric Boolean function can be expressed as a disjunction over these “exact-k𝑘kitalic_k” clauses, the claim immediately follows due to the fact that a threshold of 1111 is equivalent to the Or function. Formally, the complexity class \TC0superscript\TC0\TC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, which contains all languages computed by constant-depth classical circuits with Threshold, contains all other similarly defined classical circuit classes with other large fan-in gates: \NC0⁢[p]superscript\NC0delimited-[]𝑝\NC^{0}[p]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ], \AC0superscript\AC0\AC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, \AC0⁢[p]superscript\AC0delimited-[]𝑝\AC^{0}[p]start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ], and \ACC\ACC\ACC.333See Definition 14 for precise definitions. In many cases, Threshold is provably more powerful, e.g., \AC0⊊\TC0superscript\AC0superscript\TC0\AC^{0}\subsetneq\TC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⊊ start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [1, 7] and \AC0⁢[p]⊊\TC0superscript\AC0delimited-[]𝑝superscript\TC0\AC^{0}[p]\subsetneq\TC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [ italic_p ] ⊊ start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [20, 23]. This is why the Threshold gate was a tantalizing target for quantum exploration. Prior to our work, it was not known whether the quantum version of \TC0superscript\TC0\TC^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT—i.e., \ComplexityFont⁢B⁢Q⁢T⁢C0\ComplexityFont𝐵𝑄𝑇superscript𝐶0\ComplexityFont{BQTC}^{0}italic_B italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT—was as powerful as the quantum versions of the other classical complexity classes. In fact, given the surprising power of Fanout in the quantum world, the exact opposite was known: \BQNCw⁢f0⊇\ComplexityFont⁢B⁢Q⁢T⁢C0\ComplexityFont𝐵𝑄𝑇superscript𝐶0subscriptsuperscript\BQNC0𝑤𝑓\BQNC^{0}_{wf}\supseteq\ComplexityFont{BQTC}^{0}start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT ⊇ italic_B italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [13]. That is, constant-depth quantum circuits with Fanout could simulate constant-depth circuits with Threshold. Our work restores order to the usually classical hierarchy, placing Threshold alongside Fanout as one of the most powerful quantum gates in constant depth: \ComplexityFont⁢B⁢Q⁢T⁢C0=\BQNCw⁢f0\ComplexityFont𝐵𝑄𝑇superscript𝐶0subscriptsuperscript\BQNC0𝑤𝑓\ComplexityFont{BQTC}^{0}=\BQNC^{0}_{wf}italic_B italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT. 1.2 Proof techniques and overview The constructions in Theorem 1 and Theorem 2 follow a general outline pioneered by Rosenthal [21]. There, it is shown that constant-depth quantum circuits can compute Fanout using generalized Toffoli gates provided exponential-sized circuits are allowed. While not phrased in this language, Rosenthal’s construction shows a proof-of-principle technique for taking a very “weak” Parity gate (indeed, Toffoli non-trivially computes Parity for exactly one input!) and boosting it to a full Parity gate. We show that when we start with a gate (like Threshold) which is closer to Parity, this construction can be altered to yield circuits of polynomial size. The proof goes in two steps. First, define a certain cat-like state called a “nekomata” [21]: \ket⁢0n⊗\ket⁢ψ0+\ket⁢1n⊗\ket⁢ψ12tensor-product\ketsuperscript0𝑛\ketsubscript𝜓0tensor-product\ketsuperscript1𝑛\ketsubscript𝜓12\frac{\ket{0^{n}}\otimes\ket{\psi_{0}}+\ket{1^{n}}\otimes\ket{\psi_{1}}}{\sqrt% {2}}divide start_ARG 0 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ⊗ italic_ψ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ⊗ italic_ψ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 2 end_ARG end_ARG where \ket⁢ψ0\ketsubscript𝜓0\ket{\psi_{0}}italic_ψ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and \ket⁢ψ1\ketsubscript𝜓1\ket{\psi_{1}}italic_ψ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT are arbitrary states. Following a similar idea to that of Green et al. [8], such states can be used to compute Parity in constant depth using the the relative phase between the \ket⁢0n\ketsuperscript0𝑛\ket{0^{n}}0 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and \ket⁢1n\ketsuperscript1𝑛\ket{1^{n}}1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT part of the state. Second, show there is an explicit constant-depth construction for a nekomata state. Here, we show the key ingredient is the ability to create a “noisy” version of a usual cat state, where the all-zeroes and all-ones outcomes have noticeably larger amplitudes than those on the other outcomes. Threshold gates are significantly better at this task than the Toffoli gates in Rosenthal’s original construction. Finally, these states can be combined together (using Toffoli or Threshold gates) to form a high-fidelity nekomata state, completing the construction. 1.3 Related work Our work shares some similarity to that of [10], where the authors explore quantum advantage with constant-depth quantum circuits. They also make a similar claim suggesting that \ComplexityFont⁢Q⁢T⁢C0=\QNCw⁢f0\ComplexityFont𝑄𝑇superscript𝐶0subscriptsuperscript\QNC0𝑤𝑓\ComplexityFont{QTC}^{0}=\QNC^{0}_{wf}italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_w italic_f end_POSTSUBSCRIPT, but crucially, their results hold in a circuit model with intermediate measurements and classical fanout. The classical fanout in their circuit model allows them to bootstrap the poor man’s cat state construction of Bene Watts et al. [26] to construct an actual cat state, an idea that was also explored in [5]. To be clear, our circuit model and definition of \ComplexityFont⁢B⁢Q⁢T⁢C0\ComplexityFont𝐵𝑄𝑇superscript𝐶0\ComplexityFont{BQTC}^{0}italic_B italic_Q italic_T italic_C start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT follows in a traditional line of work (e.g, [17, 8, 13, 24, 19, 21, 18]), where no such intermediate measurements or classical fanout is allowed. Therefore, we must use entirely different techniques. 1.4 Future directions One immediate open question left open by our work is whether the approximation error inherent in the construction used to prove Theorem 1 can be eliminated without incurring a size or depth blow-up. More generally, we ask which other conditions on a family of multi-qubit gates lead to powerful shallow circuits. One explicit approach would be to ask what properties of the sets S𝑆Sitalic_S parameterizing our phase gates USsubscript𝑈𝑆U_{S}italic_U start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT are sufficient to compute Fanout. Is there something beyond being parity restricted? Another interesting question concerns the circuit complexity of restricted families of threshold functions. Specifically, consider the Exact-k𝑘kitalic_k gate, which indicates if the Hamming weight of the input is exactly k𝑘kitalic_k. Notice that Exact-k𝑘kitalic_k can be constructed from two Threshold gates. Moreover, for k≈n/2𝑘𝑛2k\approx n/2italic_k ≈ italic_n / 2, Exact-k𝑘kitalic_k can be used to compute Threshold. This latter statement is not obvious and follows from the fact that our proof of Theorem 1 actually uses Exact gates rather than Threshold gates. However, for other values of k≪n/2much-less-than𝑘𝑛2k\ll n/2italic_k ≪ italic_n / 2, it is not simple to see how Exact-k𝑘kitalic_k could be used to simulate Exact-(k+1)𝑘1(k+1)( italic_k + 1 )."
https://arxiv.org/html/2411.04874v1,Hardness of approximation for ground state problems,"After nearly two decades of research, the question of a quantum PCP theorem for quantum Constraint Satisfaction Problems (CSPs) remains wide open. As a result, proving QMA-hardness of approximation for ground state energy estimation, analogous to hardness of approximation for MAX-k𝑘kitalic_k-CSP, has remained elusive. (QMA is Quantum Merlin-Arthur, a quantum generalization of NP with a quantum proof and quantum verifier.) Recently, it was shown [Bittel, Gharibian, Kliesch, CCC 2023] that a natural problem involving variational quantum circuits is QCMA-hard to approximate within ratio N1−ϵsuperscript𝑁1italic-ϵN^{1-\epsilon}italic_N start_POSTSUPERSCRIPT 1 - italic_ϵ end_POSTSUPERSCRIPT for any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0 and N𝑁Nitalic_N the input size. (Quantum Classical Merlin-Arthur is QMA, but with a classical proof.) Unfortunately, this problem was not related to quantum CSPs, leaving the question of hardness of approximation for quantum CSPs open.In this work, we show that if instead of focusing on ground state energies (analogous to the optimal number of satisfied clauses), one considers computing properties of the ground space (analogous to computing properties of the MAX-k𝑘kitalic_k-CSP solution space), QCMA-hardness of computing ground space properties can be shown. In particular, we show that it is (1) QCMA-complete within ratio N1−ϵsuperscript𝑁1italic-ϵN^{1-\epsilon}italic_N start_POSTSUPERSCRIPT 1 - italic_ϵ end_POSTSUPERSCRIPT to approximate the Ground State Connectivity problem (GSCON), and (2) QCMA-hard within the same ratio to estimate the amount of entanglement of a local Hamiltonian’s ground state, denoted Ground State Entanglement (GSE). As a bonus, a simplification of our construction yields NP-completeness of approximation for a natural k𝑘kitalic_k-SAT reconfiguration problem, to be contrasted with the recent PCP-based PSPACE-hardness of approximation results for a different definition of k𝑘kitalic_k-SAT reconfiguration [Karthik C.S. and Manurangsi, 2023, and Hirahara, Ohsaka, STOC 2024].","Boolean constraint satisfaction problems (CSPs) and their quantum generalization, local Hamiltonian problems, have enjoyed a close relationship over the last decade, both in terms of relevance and complexity. For starters, just as MAX-k𝑘kitalic_k-SAT is the canonical NP-complete problem for k≥2𝑘2k\geq 2italic_k ≥ 2, the k𝑘kitalic_k-local Hamiltonian problem (k𝑘kitalic_k-LH) is the canonical Quantum Merlin-Arthur (QMA)-complete problem for k≥2𝑘2k\geq 2italic_k ≥ 2 [KSV02, KR03, KKR06]. Likewise, whereas 2222-SAT can be solved in linear time and 3333-SAT is NP-complete, its analogous local Hamiltonian problem, dubbed Quantum k𝑘kitalic_k-SAT [Bra06], is linear-time solvable for k=2𝑘2k=2italic_k = 2 [ASSZ16, BG16] and QMA1subscriptQMA1\textup{QMA}_{1}QMA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-complete333QMA1subscriptQMA1\textup{QMA}_{1}QMA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is QMA with perfect completeness. for k≥3𝑘3k\geq 3italic_k ≥ 3 [Bra06, GN13]. Fancy a quantum generalization of Schaeffer’s dichotomy theorem, which says that Boolean constraint satisfaction problems are either in P or NP-complete [Sch78]? Quantum CSPs have one of those too, stating that k𝑘kitalic_k-LH is either in P, NP-complete, StoqMA-complete, or QMA-complete [CM16]. Of course, the stars have not always aligned between classical and quantum CSPs — for example, while Max-2222-SAT on a 1D chain is efficiently solvable, 2222-LH on the line remains QMA-complete (for sufficiently large, but constant, local dimension) [AGIK09, HNN13], even when all constraints on the chain are identical (i.e. the translationally invariant setting) [GI09, BCO17]. But by and large, life in the world of classical versus quantum CSPs has been arguably…peachy. That is, of course, until one brings up the topic of PCP theorems, or the closely related question of hardness of approximation. An infamous 2006 blog post issued the community a challenge: To establish a potential quantum PCP theorem. The blog also stated that the problem was expected to be hard, and this has indeed proven true. For it was not until 2022 that the field celebrated arguably its first major victory against the quantum PCP conjecture with the establishment of the No Low-Energy Trivial States (NLTS) theorem [FH14, ABN23]. For the first time, this gave (explicit) local Hamiltonians whose ground state energy could not be approximated by constant depth quantum circuits. This, in turn, is important, because if one believes NP≠QMANPQMA\textup{NP}\neq\textup{QMA}NP ≠ QMA, then local Hamiltonians H𝐻Hitalic_H arising from any candidate quantum PCP theorem should not have “good” NP witnesses, and constant-depth quantum circuits constitute one possible family of NP witnesses444This follows from a straightforward light-cone argument, since the local terms of H𝐻Hitalic_H each act only on k∈O⁢(1)𝑘𝑂1k\in O(1)italic_k ∈ italic_O ( 1 ) qubits.. With this said, it is unfortunately not clear how current NLTS constructions can be used to encode hard computational problems, leaving the question of hardness of approximation for QMA via a quantum PCP theorem open. Quantum hardness of approximation without a quantum PCP theorem. In this paper, we thus study the question — can one nevertheless obtain hardness of approximation for quantum complexity classes without a quantum PCP theorem? The answer is known to be yes. In 1999, Umans showed how to obtain classical hardness of approximation for the second level of the Polynomial Hierarchy, Σ2psuperscriptsubscriptΣ2𝑝\Sigma_{2}^{p}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT, without utilizing a PCP theorem; rather, the construction utilized dispersers [Uma99]. By extending this approach to the quantum setting, the first quantum hardness of approximation result for a quantum complexity class was shown: The quantum SUCCINCT SET COVER problem is hard to approximate for a quantum generalization of the second level of the Polynomial Hierarchy, cq-⁢Σ2cq-subscriptΣ2\textup{cq-}\Sigma_{2}cq- roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [GK12b]. (cq-⁢Σ2cq-subscriptΣ2\textup{cq-}\Sigma_{2}cq- roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is a bounded-error quantum generalization of Σ2psuperscriptsubscriptΣ2𝑝\Sigma_{2}^{p}roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT, where the existentially quantified proof is classical, and the universally quantified proof is quantum.) The shortcoming of this was that, unlike in the classical setting, quantum polynomial hierarchies (the plural is not a typo!) have not yet risen to the level of prominence of their classical cousin, PH; indeed, the area is in its infancy [Yam02, LG17, GSS+18, FGN23, GY24, AGKR24, agarwalOracleSeparationsQuantumClassical2024]. As a result, hardness of approximation for a more established class like QMA or one if its many variants (e.g. QCMA, QMA(2), etc…; see [Gha24] for a survey) would be preferable. Here, we focus on Quantum Classical Merlin-Arthur (QCMA) [AN02], arguably second in prominence behind QMA, and defined as QMA but with a classical proof. In [GK12b], it was observed that a simple modification to the cq-⁢Σ2cq-subscriptΣ2\textup{cq-}\Sigma_{2}cq- roman_Σ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-hardness results therein also yields QCMA-hardness of approximation for an artificial problem, Quantum Monotone Minimum Satisfying Assignment (QMSA, Definition 5). Building on this, the first natural hardness of approximation result for QCMA was given [BGK23], namely for the problem of estimating the optimal depth of a variational quantum circuit (MIN-VQA). Local Hamiltonians, ground spaces, and GSCON. This brings us full circle to the starting theme of this paper — CSPs. Specifically, MIN-VQA is not related to a quantum CSP. So, can one show QCMA-hardness of approximation for a natural computational problem for quantum CSPs? To answer this, recall first that a k𝑘kitalic_k-local Hamiltonian is an n𝑛nitalic_n-qubit 2n×2nsuperscript2𝑛superscript2𝑛2^{n}\times 2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT × 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT complex Hermitian matrix H𝐻Hitalic_H with a succinct representation H=∑iHi𝐻subscript𝑖subscript𝐻𝑖H=\sum_{i}H_{i}italic_H = ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, where analogous to a MAX-k𝑘kitalic_k-SAT clause acting on k𝑘kitalic_k out of n bits, each Hisubscript𝐻𝑖H_{i}italic_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a Hermitian matrix or clause acting non-trivially on some subset of k𝑘kitalic_k out of n𝑛nitalic_n qubits. The problem k𝑘kitalic_k-LH then asks, given H𝐻Hitalic_H, to estimate the ground state energy, i.e. the smallest eigenvalue λmin⁢(H)subscript𝜆𝐻\lambda_{\min}(H)italic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_H ). The corresponding set of optimal quantum assignments then form the ground space, i.e. the span of eigenvectors |ψ⟩∈ℂ2nket𝜓superscriptℂsuperscript2𝑛|\psi\rangle\in{\mathbb{C}}^{2^{n}}| italic_ψ ⟩ ∈ blackboard_C start_POSTSUPERSCRIPT 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT with eigenvalue λmin⁢(H)subscript𝜆𝐻\lambda_{\min}(H)italic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_H ). The quantum CSP formulation of the quantum PCP conjecture [AAV13] then posits555For clarity, in this formulation we are assuming that H𝐻Hitalic_H is rescaled so that ‖H‖≤1norm𝐻1\left\|\,H\,\right\|\leq 1∥ italic_H ∥ ≤ 1, for ∥⋅∥\left\|\,\cdot\,\right\|∥ ⋅ ∥ the spectral norm. that it is QMA-hard to decide if for positive semidefinite H𝐻Hitalic_H, λmin⁢(H)=0subscript𝜆𝐻0\lambda_{\min}(H)=0italic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_H ) = 0 or λmin≥csubscript𝜆𝑐\lambda_{\min}\geq citalic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ≥ italic_c for some fixed constant c>0𝑐0c>0italic_c > 0, under the promise that one of these cases holds. As stated above, however, resolving this conjecture remains a difficult challenge. Here, we show that by instead focusing on the natural problem of computing properties of the ground space (i.e. the space of optimal solutions), as opposed to the ground state energy (i.e the value attained by all optimal solutions), QCMA-hardness of approximation can be achieved. Results. We now introduce the two and a “half” computational problems we study, and state our results. The first of these, GSCON, also has a natural classical counterpart from the classical study of reconfiguration problems [GKMP09], for which we show an analogous NP-hardness of approximation result; this is the “half” we refer to above. Result 1: Ground State Connectivity (GSCON). Introduced in [GS15], Ground State Connectivity (Definition 2) is the physically motivated problem of deciding if the ground space of H𝐻Hitalic_H has an energy barrier. The input is a k𝑘kitalic_k-local Hamiltonian H𝐻Hitalic_H, two ground states |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ and |ϕ⟩ketitalic-ϕ|\phi\rangle| italic_ϕ ⟩ (specified via quantum circuits), and natural number m𝑚mitalic_m. The output is whether there exists a sequence of at most m𝑚mitalic_m 2222-local unitary gates (U1,U2,…⁢Um)subscript𝑈1subscript𝑈2…subscript𝑈𝑚(U_{1},U_{2},\ldots U_{m})( italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … italic_U start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ), such that two properties hold: 1. (the unitary sequence maps |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ to |ϕ⟩ketitalic-ϕ|\phi\rangle| italic_ϕ ⟩) Um⁢⋯⁢U2⁢U1⁢|ψ⟩≈|ϕ⟩subscript𝑈𝑚⋯subscript𝑈2subscript𝑈1ket𝜓ketitalic-ϕU_{m}\cdots U_{2}U_{1}|\psi\rangle\approx|\phi\rangleitalic_U start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ⋯ italic_U start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_ψ ⟩ ≈ | italic_ϕ ⟩, and 2. (all intermediate states are ground states) for all i∈[m]𝑖delimited-[]𝑚i\in[m]italic_i ∈ [ italic_m ], |ψi⟩:=Ui⁢⋯⁢U1⁢|ψ⟩assignketsubscript𝜓𝑖subscript𝑈𝑖⋯subscript𝑈1ket𝜓|\psi_{i}\rangle:=U_{i}\cdots U_{1}|\psi\rangle| italic_ψ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⟩ := italic_U start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋯ italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_ψ ⟩ is a ground state of H𝐻Hitalic_H. Originally shown QCMA-complete for k=5𝑘5k=5italic_k = 5 [GS15], it was subsequently found that, surprisingly666This is in contrast to the fact that k𝑘kitalic_k-LH for commuting Hamiltonians is not known to remain QMA-hard, and in fact is in NP for certain cases [BV05, AE11, Sch11, AKV18, IJ23]., GSCON remains QCMA-complete even on Hamiltonians with pairwise commuting terms [GMV17]. In the 1D translation invariant setting, GSCON remains hard, being QCMAEXP-complete [WBG23]. We now state our first main result, which shows that GSCON is QCMA-hard to approximate. For this, we reformulate GSCON to have two thresholds m≤m′𝑚superscript𝑚′m\leq m^{\prime}italic_m ≤ italic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. We add the promise that there always exists a unitary sequence of length poly⁢(N′)polysuperscript𝑁′\textup{poly}(N^{\prime})poly ( italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) satisfying conditions (1) and (2) above. In the YES case, this sequence has length at most m𝑚mitalic_m, whereas in the NO case, any such sequence is length at least m′superscript𝑚′m^{\prime}italic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. That such a sequence always exists even in the NO case is important to ensure the approximation ratio m′/msuperscript𝑚′𝑚m^{\prime}/mitalic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT / italic_m is well-defined, for if no such unitary sequence satisfying (1) and (2) existed777Existing GSCON QCMA-hardness constructions indeed have no such sequence in the NO case., the ratio can trivially be set to m′/m≈∞superscript𝑚′𝑚m^{\prime}/m\approx\inftyitalic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT / italic_m ≈ ∞ by choosing arbitrarily large m′superscript𝑚′m^{\prime}italic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT for the NO case. Theorem 1. For all ε>0𝜀0\varepsilon>0italic_ε > 0 and k≥5𝑘5k\geq 5italic_k ≥ 5, GSCON with k𝑘kitalic_k-local Hamiltonians is QCMA-complete for m′m∈Θ⁢(N′⁣1−ϵ)superscript𝑚′𝑚Θsuperscript𝑁′1italic-ϵ\frac{m^{\prime}}{m}\in\Theta(N^{\prime 1-\epsilon})divide start_ARG italic_m start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_ARG start_ARG italic_m end_ARG ∈ roman_Θ ( italic_N start_POSTSUPERSCRIPT ′ 1 - italic_ϵ end_POSTSUPERSCRIPT ), for N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT the encoding size of the GSCON instance. In words, the length of the minimal unitary sequence satisfying conditions (1) and (2) is QCMA-hard to approximate, even within large relative error scaling essentially linearly in the input size, N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Three comments: (1) The local Hamiltonians in Theorem 1 do not obey any particular geometry constraints. (2) It is important that all hardness ratios in this paper be written relative to the encoding size of the input of the problem being reduced to, and not, e.g., the number of qubits, n𝑛nitalic_n. This correctly captures standard classical hardness of approximation results for classical Boolean k𝑘kitalic_k-CSPs, where the hardness ratio is relative to the number satisfied clauses. This is because the input size, N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, also scales with the number of clauses, assuming each clause has size k∈O⁢(1)𝑘𝑂1k\in O(1)italic_k ∈ italic_O ( 1 ). Our setting has this property as well, since all clauses are norm at most 1111. (3) The reason we are careful to make point (2) is because, in general, the number of clauses can be superlinear in n𝑛nitalic_n. Thus, mapping an approximation ratio given relative to n𝑛nitalic_n to one relative to N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT can yield an asymptotically smaller ratio. This is why simple promise gap amplification techniques, such as taking parallel copies of all clauses, typically do not suffice to achieve hardness of approximation ratios such as in Theorem 1. Result 1.5: Classical analogue of GSCON, Boolean reconfiguration. The origins of GSCON as a computational problem are rooted in the classical study of reconfiguration problems, to which we now make a detour. First studied in [GKMP09], classical reconfiguration problems have since evolved into an entire research area (see, e.g., [Nis18] for an introductory survey). In the case of k𝑘kitalic_k-SAT, the reconfiguration problem is specified as follows: Given an input k𝑘kitalic_k-SAT formula ϕitalic-ϕ\phiitalic_ϕ and satisfying assignments x𝑥xitalic_x and y𝑦yitalic_y, does there exist a sequence of bit flips from x𝑥xitalic_x to y𝑦yitalic_y, so that each intermediate string obtained is also satisfying for ϕitalic-ϕ\phiitalic_ϕ? This is the classical analogue of GSCON, with the exception that the input does not specify a bound m𝑚mitalic_m on the number of bit flips allowed — in the worst case, one may require an exponential number of bit flips. As a result, its complexity is more difficult than NP, being PSPACE-complete [GKMP09]. Recently, the first PCP theorems for reconfiguration problems have been established [IDH+11, Ohs23, SM24, HO24], allowing for the first PSPACE-hardness of approximation results for many reconfiguration problems [SM24, HO24]. By leveraging our proof technique for GSCON from Theorem 1, we are able to give our own hardness of approximation result for k𝑘kitalic_k-SAT reconfiguration, albeit with respect to a different parameter than [SM24, HO24]. We will first state our result, followed by a discussion of how it differs from [SM24, HO24]. For this, we define the approximation problem Boolean Reconfiguration (BR, Definition 10), which is the k𝑘kitalic_k-SAT reconfiguration problem above, but with thresholds hℎhitalic_h and h′superscriptℎ′h^{\prime}italic_h start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT on the number of bit flips allowed in the YES and NO cases (analogous to GSCON), respectively. Theorem 2. BR is NP-hard to approximate for h′/h∈Θ⁢(N1−ε)superscriptℎ′ℎΘsuperscript𝑁1𝜀h^{\prime}/h\in\Theta(N^{1-\varepsilon})italic_h start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT / italic_h ∈ roman_Θ ( italic_N start_POSTSUPERSCRIPT 1 - italic_ε end_POSTSUPERSCRIPT ), for any constant ε>0𝜀0\varepsilon>0italic_ε > 0 and N𝑁Nitalic_N the size of the input BR instance. The main differences between Theorem 1 and [SM24, HO24] are now as follows. First, our proof does not rely on a PCP as in [SM24, HO24], but rather uses Umans’ disperser-based hardness gap construction as a starting point. Second, our hardness of approximation is with respect to the length of the reconfiguration sequence. In [SM24, HO24], in contrast, there is no length parameter m𝑚mitalic_m. Rather, hardness of approximation therein is shown in the following sense: There exists a constant ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0 such that, in the YES case, there exists a satisfying reconfiguration sequence from x𝑥xitalic_x to y𝑦yitalic_y, and in the NO case, for any reconfiguration sequence, there exists an intermediate string which satisfies at most a (1−ϵ)1italic-ϵ(1-\epsilon)( 1 - italic_ϵ )-fraction of the clauses of ϕitalic-ϕ\phiitalic_ϕ, for some fixed constant ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0. In this sense, Theorem 2 is complementary to [SM24, HO24] in both its proof technique and actual result. Result 2. Ground State Entanglement (GSE). We now return to the quantum setting, and define the second natural quantum problem we study, which asks whether a given local Hamiltonian has a ground state of low entanglement. More formally, we define the Ground State Entanglement problem (GSE, Definition 8), for which the input is a local Hamiltonian H𝐻Hitalic_H, prespecified cut A𝐴Aitalic_A versus A′superscript𝐴′A^{\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT of the qubits H𝐻Hitalic_H acts on, and inverse polynomially separated thresholds η4>η3subscript𝜂4subscript𝜂3\eta_{4}>\eta_{3}italic_η start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT > italic_η start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. The output is to decide whether H𝐻Hitalic_H has a ground state with entanglement entropy at most η3subscript𝜂3\eta_{3}italic_η start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT across the A𝐴Aitalic_A versus A′superscript𝐴′A^{\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT cut, or whether all ground states have entanglement entropy at least η4subscript𝜂4\eta_{4}italic_η start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT across this cut? Here, the entanglement entropy is a standard entanglement measure, defined for a bipartite pure state |ψ⟩A⁢A′subscriptket𝜓𝐴superscript𝐴′|\psi\rangle_{AA^{\prime}}| italic_ψ ⟩ start_POSTSUBSCRIPT italic_A italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT as S⁢(ρA)𝑆subscript𝜌𝐴S(\rho_{A})italic_S ( italic_ρ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ), for reduced state ρA:=TrA′⁢(ρA⁢A′)assignsubscript𝜌𝐴subscriptTrsuperscript𝐴′subscript𝜌𝐴superscript𝐴′\rho_{A}:={\rm Tr}_{A^{\prime}}(\rho_{AA^{\prime}})italic_ρ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT := roman_Tr start_POSTSUBSCRIPT italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_ρ start_POSTSUBSCRIPT italic_A italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) and S(ρ):=−Tr(ρlogρS(\rho):=-{\rm Tr}(\rho\log\rhoitalic_S ( italic_ρ ) := - roman_Tr ( italic_ρ roman_log italic_ρ) the von Neumann entropy. Our second main result is as follows. Theorem 3. For all ε>0𝜀0\varepsilon>0italic_ε > 0 and k≥5𝑘5k\geq 5italic_k ≥ 5, GSE is QCMA-hard for η4η3∈Θ⁢(N′⁣1−ϵ)subscript𝜂4subscript𝜂3Θsuperscript𝑁′1italic-ϵ\frac{\eta_{4}}{\eta_{3}}\in\Theta(N^{\prime 1-\epsilon})divide start_ARG italic_η start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT end_ARG start_ARG italic_η start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_ARG ∈ roman_Θ ( italic_N start_POSTSUPERSCRIPT ′ 1 - italic_ϵ end_POSTSUPERSCRIPT ), for N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT the encoding size of the GSE instance. In words, it is QCMA-hard to estimate the minimal entanglement entropy over all states in the ground space, even within large relative error N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Two comments: First, unlike Theorem 1, it is not clear that GSE is also in in QCMA. This is because verifying the entropy of a given quantum state |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ is, in general, at least as hard as Quantum Statistical Zero Knowledge (QSZK) [Wat02]. In particular, when one has access to a poly-size quantum circuit preparing |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩, the problem is QSZK-complete [BST08]. However, in GSE one does not have access to such a circuit, since |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ is an unknown ground state of H𝐻Hitalic_H! Second, there are two previous works [GH24, BFG+24] we are aware of which study questions similar to GSE, whose relationship to Theorem 3 we now clarify. The first [GH24] defines the Hamiltonian Quantum Entropy Difference (HQED) problem, which takes two local Hamiltonians as input and a pre-specified cut A𝐴Aitalic_A versus A′superscript𝐴′A^{\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, and asks: Among all ground states |ψ1⟩ketsubscript𝜓1|\psi_{1}\rangle| italic_ψ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⟩ of H1subscript𝐻1H_{1}italic_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and |ψ2⟩ketsubscript𝜓2|\psi_{2}\rangle| italic_ψ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ⟩ of H2subscript𝐻2H_{2}italic_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of minimal entanglement entropy, which of |ψ1⟩ketsubscript𝜓1|\psi_{1}\rangle| italic_ψ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⟩ or |ψ2⟩ketsubscript𝜓2|\psi_{2}\rangle| italic_ψ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ⟩ has larger entanglement entropy across A𝐴Aitalic_A versus A′superscript𝐴′A^{\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT? Here, the promise gap in entropy is an additive constant (i.e. it is not a hardness of approximation result), and the hardness obtained is for the Learning With Errors (LWE) problem [Reg09], not QCMA. In words, Reference [GH24] shows that if one could efficiently estimate the entanglement entropy difference between ground states of two given Hamiltonians within constant additive error, then one could solve LWE. Note the relationship between LWE and QCMA is not known, other than the belief that LWE is not in BQP (e.g. [Mah18]), and thus not in QCMA (since BQP⊆QCMABQPQCMA\textup{BQP}\subseteq\textup{QCMA}BQP ⊆ QCMA by definition). The second relevant work [BFG+24] introduces the Learning Ground State Entanglement Structure (LGSES) problem. The question is then, roughly, to determine whether the ground states of a geometrically constrained H𝐻Hitalic_H have volume law or area law entanglement across a given set of cuts. First, the differences: Like [GH24], the hardness results obtained in [BFG+24] are for LWE, not QCMA. Second, the input model to LGSES is not the standard one used in defining complexity classes, but rather has a cryptographic flavor. Namely, there are two families of computationally indistinguishable Hamiltonians, ℋnlowsuperscriptsubscriptℋ𝑛low\mathcal{H}_{n}^{\textup{low}}caligraphic_H start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT low end_POSTSUPERSCRIPT and ℋnhighsuperscriptsubscriptℋ𝑛high\mathcal{H}_{n}^{\textup{high}}caligraphic_H start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT high end_POSTSUPERSCRIPT (which we call “YES” and “NO” cases for reference), so that when H𝐻Hitalic_H is drawn from either ℋnlowsuperscriptsubscriptℋ𝑛low\mathcal{H}_{n}^{\textup{low}}caligraphic_H start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT low end_POSTSUPERSCRIPT or ℋnhighsuperscriptsubscriptℋ𝑛high\mathcal{H}_{n}^{\textup{high}}caligraphic_H start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT high end_POSTSUPERSCRIPT according to an appropriate random distribution, with overwhelming probability the entanglement entropy will be low or high, respectively. In constrast, our input to GSE is a single Hamiltonian H𝐻Hitalic_H along with a cut A𝐴Aitalic_A versus A′superscript𝐴′A^{\prime}italic_A start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT (i.e. the standard QCMA input model). Now, the similarity: The promise gap for [BFG+24] on the entanglement entropy between the “YES” and “NO” cases is O⁢(polylog⁢(n))𝑂polylog𝑛O(\textup{polylog}(n))italic_O ( polylog ( italic_n ) ) versus Ω⁢(n)Ω𝑛\Omega(n)roman_Ω ( italic_n ), i.e. a ratio of (n/polylog⁢(n))𝑛polylog𝑛(n/\textup{polylog}(n))( italic_n / polylog ( italic_n ) ). However, this gap is relative to the number of qubits n𝑛nitalic_n, not the encoding size of the input, N′superscript𝑁′N^{\prime}italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, as in Theorem 3. Our understanding888Due to the multiplication of an n×n𝑛𝑛n\times nitalic_n × italic_n matrix A𝐴Aitalic_A with n𝑛nitalic_n-bit string x𝑥xitalic_x in Definition 3.2 of the arxiv version[BFG+24]. is that N′∈Ω⁢(n2)superscript𝑁′Ωsuperscript𝑛2N^{\prime}\in\Omega(n^{2})italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) in [BFG+24], yielding ratio at most N′/polylog⁢(N′)superscript𝑁′polylogsuperscript𝑁′\sqrt{N^{\prime}}/\textup{polylog}(N^{\prime})square-root start_ARG italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_ARG / polylog ( italic_N start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ). Thus, relative to the input model therein, this may be viewed as an LWE-hardness of approximation result, albeit with a quadratically weaker ratio than Theorem 3. Finally, we remark there are minor overlaps between our techniques and those of [GH24, BFG+24], such as the use of circuit-to-Hamiltonian constructions. However, the key underlying approach for obtaining our QCMA-hardness results is completely different. Techniques. We begin by discussing Theorem 1 for GSCON, followed by Theorem 3 for GSE. The proof of Theorem 2 for BR is a classical analogue of the proof for GSCON, with some modifications to the clock construction; as such we omit it here. Techniques for GSCON. We show a gap-preserving reduction from the artificial QCMA-hard to approximate problem Quantum Monotone Minimum Satisfying Assignment (QMSA, Definition 5), roughly defined as follows: The input is a quantum circuit V=VT⁢⋯⁢V1𝑉subscript𝑉𝑇⋯subscript𝑉1V=V_{T}\cdots V_{1}italic_V = italic_V start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ⋯ italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT accepting a non-empty monotone set S⊆{0,1}n𝑆superscript01𝑛S\subseteq\{0,1\}^{n}italic_S ⊆ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, and integer thresholds 0≤g≤g′≤n0𝑔superscript𝑔′𝑛0\leq g\leq g^{\prime}\leq n0 ≤ italic_g ≤ italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ≤ italic_n. The output is to decide whether there is a low Hamming weight string x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, meaning of Hamming weight at most g𝑔gitalic_g, accepted by V𝑉Vitalic_V, or if every x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT of Hamming weight at most g′superscript𝑔′g^{\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is rejected by V𝑉Vitalic_V, with the promise that one of these two cases holds. Our starting point is the QCMA-hardness construction of [GS15], which we must briefly sketch (more details in Section 2). Namely, one first applies a circuit-to-Hamiltonian construction [KSV02] to V𝑉Vitalic_V, obtaining a local Hamiltonian Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT encoding the action of V𝑉Vitalic_V as follows: (1) λmin⁢(H)subscript𝜆𝐻\lambda_{\min}(H)italic_λ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT ( italic_H ) is “small” if and only if V𝑉Vitalic_V accepts the string x𝑥xitalic_x it is given, and (2) the quantum state achieving this low energy is the history state of V𝑉Vitalic_V, |ψhist⁢(x)⟩:=1T+1⁢∑t=0TVi⁢⋯⁢V1⁢|x⟩B⊗|0⟩C⊗|t⟩D,assignketsubscript𝜓hist𝑥1𝑇1superscriptsubscript𝑡0𝑇tensor-productsubscript𝑉𝑖⋯subscript𝑉1subscriptket𝑥𝐵subscriptket0𝐶subscriptket𝑡𝐷|\psi_{\textup{hist}}(x)\rangle:=\frac{1}{\sqrt{T+1}}\sum_{t=0}^{T}V_{i}\cdots V% _{1}|x\rangle_{B}\otimes|0\rangle_{C}\otimes|t\rangle_{D},| italic_ψ start_POSTSUBSCRIPT hist end_POSTSUBSCRIPT ( italic_x ) ⟩ := divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_T + 1 end_ARG end_ARG ∑ start_POSTSUBSCRIPT italic_t = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋯ italic_V start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | italic_x ⟩ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ⊗ | 0 ⟩ start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ⊗ | italic_t ⟩ start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT , (1) where x𝑥xitalic_x is the string fed to V𝑉Vitalic_V in register B𝐵Bitalic_B, C𝐶Citalic_C is the ancilla, and D𝐷Ditalic_D is the clock register tracking time, t𝑡titalic_t. To turn this into a GSCON instance, one then appends a 3333-qubit “GO” register E𝐸Eitalic_E, and sets the final Hamiltonian to H=(Hkit)B⁢C⁢D⊗PE𝐻tensor-productsubscriptsubscript𝐻kit𝐵𝐶𝐷subscript𝑃𝐸H=(H_{\textup{kit}})_{BCD}\otimes P_{E}italic_H = ( italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_B italic_C italic_D end_POSTSUBSCRIPT ⊗ italic_P start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT for P:=(I−|000⟩⁢⟨000|−|111⟩⁢⟨111|)Eassign𝑃subscript𝐼ket000bra000ket111bra111𝐸P:=(I-|000\rangle\!{\langle 000|}-|111\rangle\!{\langle 111|})_{E}italic_P := ( italic_I - | 000 ⟩ ⟨ 000 | - | 111 ⟩ ⟨ 111 | ) start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT. Finally, the initial and target states are |ψ⟩=|0⁢⋯⁢0⟩B⁢C⁢D⁢|000⟩Eket𝜓subscriptket0⋯0𝐵𝐶𝐷subscriptket000𝐸|\psi\rangle=|0\cdots 0\rangle_{BCD}|000\rangle_{E}| italic_ψ ⟩ = | 0 ⋯ 0 ⟩ start_POSTSUBSCRIPT italic_B italic_C italic_D end_POSTSUBSCRIPT | 000 ⟩ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT and |ϕ⟩=|0⁢⋯⁢0⟩B⁢C⁢D⁢|111⟩Eketitalic-ϕsubscriptket0⋯0𝐵𝐶𝐷subscriptket111𝐸|\phi\rangle=|0\cdots 0\rangle_{BCD}|111\rangle_{E}| italic_ϕ ⟩ = | 0 ⋯ 0 ⟩ start_POSTSUBSCRIPT italic_B italic_C italic_D end_POSTSUBSCRIPT | 111 ⟩ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT, respectively. The intuition is now as follows: In the YES case, an honest prover can first prepare the history state |ψhist⁢(x)⟩ketsubscript𝜓hist𝑥|\psi_{\textup{hist}}(x)\rangle| italic_ψ start_POSTSUBSCRIPT hist end_POSTSUBSCRIPT ( italic_x ) ⟩ on registers B⁢C⁢D𝐵𝐶𝐷BCDitalic_B italic_C italic_D based on a Hamming weight g𝑔gitalic_g string x𝑥xitalic_x, obtaining |ψhist⁢(x)⟩B⁢C⁢D⁢|000⟩Esubscriptketsubscript𝜓hist𝑥𝐵𝐶𝐷subscriptket000𝐸|\psi_{\textup{hist}}(x)\rangle_{BCD}|000\rangle_{E}| italic_ψ start_POSTSUBSCRIPT hist end_POSTSUBSCRIPT ( italic_x ) ⟩ start_POSTSUBSCRIPT italic_B italic_C italic_D end_POSTSUBSCRIPT | 000 ⟩ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT, which is still in the null space of H𝐻Hitalic_H. The goal is now to flip the GO qubits, but since we are restricted to 2222-local gates, this must be done in two steps, e.g. the first two bits of E𝐸Eitalic_E are first flipped to |11⟩ket11|11\rangle| 11 ⟩. At this point, our state has high overlap with PEsubscript𝑃𝐸P_{E}italic_P start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT, “switching on” the Hamiltonian Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT, which checks that our history state indeed has low energy. The last bit of E𝐸Eitalic_E can now be flipped, and the history state uncomputed in order to arrive at target state |ϕ⟩ketitalic-ϕ|\phi\rangle| italic_ϕ ⟩. Soundness follows via the Traversal Lemma (Lemma 4), which shows that it is impossible999Actually, this statement is not entirely true — it is always possible to perform such a mapping without ever having more than inverse exponential overlap with P𝑃Pitalic_P [GS15, GR23]. However, this necessarily requires an exponential number of 2222-qubit gates. to map |000⟩Esubscriptket000𝐸|000\rangle_{E}| 000 ⟩ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT to |111⟩Esubscriptket111𝐸|111\rangle_{E}| 111 ⟩ start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT via 2222-local gates without preparing an intermediate state with non-trivial overlap with P𝑃Pitalic_P. And when this overlap occurs, Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT will administer a large energy penalty to any history state prepared in B⁢C⁢D𝐵𝐶𝐷BCDitalic_B italic_C italic_D based on a string of Hamming weight at most g′superscript𝑔′g^{\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. At first glance, this construction already seems to give hardness of approximation when applied to V𝑉Vitalic_V from QMSA — in the YES case, the history state is based on a low Hamming weight g𝑔gitalic_g string x𝑥xitalic_x, whereas in the NO case, any low-energy history state must encode a high Hamming weight g′superscript𝑔′g^{\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT string. Since g′/g∈Θ⁢(N1−ϵ)superscript𝑔′𝑔Θsuperscript𝑁1italic-ϵg^{\prime}/g\in\Theta(N^{1-\epsilon})italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT / italic_g ∈ roman_Θ ( italic_N start_POSTSUPERSCRIPT 1 - italic_ϵ end_POSTSUPERSCRIPT ), this suggests preparing the history state in the YES case requires much fewer gates than in the NO case, which translates into a short unitary sequence for GSCON in the YES case versus a long one in the NO case. The catch is that, while it takes g𝑔gitalic_g (respectively, g′superscript𝑔′g^{\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT) bits to prepare x𝑥xitalic_x in the YES (respectively, NO) case, the cost of preparing the superposition in |ψhist⁢(x)⟩ketsubscript𝜓hist𝑥|\psi_{\textup{hist}}(x)\rangle| italic_ψ start_POSTSUBSCRIPT hist end_POSTSUBSCRIPT ( italic_x ) ⟩ given x𝑥xitalic_x depends on the number of gates T𝑇Titalic_T in V𝑉Vitalic_V, which we have no control over! Thus, the approximation ratio achieved scales roughly as (g+T)/(g′+T)𝑔𝑇superscript𝑔′𝑇(g+T)/(g^{\prime}+T)( italic_g + italic_T ) / ( italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT + italic_T ), which approaches 1111 if T𝑇Titalic_T grows superlinearly in the proof size, which is in general the case. A similar problem was overcome in the QCMA-hardness of approximation result for MIN-VQA by artificially “amplifying the cost” of flipping each bit while preparing string x𝑥xitalic_x [BGK23], so as to make the cost of preparing x𝑥xitalic_x scale roughly as g⁢T𝑔𝑇gTitalic_g italic_T rather than T𝑇Titalic_T. However, one has much more control for MIN-VQA when designing a reduction, for the following reason. The input therein is a set of local Hamiltonians {G1,…⁢Gl}subscript𝐺1…subscript𝐺𝑙{\left\{G_{1},\ldots G_{l}\right\}}{ italic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … italic_G start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT }, and the question is whether given an initial state |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩, one can prepare a specified target state |ϕ⟩ketitalic-ϕ|\phi\rangle| italic_ϕ ⟩ by applying Hamiltonian evolution according to the Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, i.e. ei⁢Gjd⁢θjd⁢⋯⁢ei⁢Gj1⁢θj1⁢|ψ⟩≈|ϕ⟩superscript𝑒𝑖subscript𝐺subscript𝑗𝑑subscript𝜃subscript𝑗𝑑⋯superscript𝑒𝑖subscript𝐺subscript𝑗1subscript𝜃subscript𝑗1ket𝜓ketitalic-ϕe^{iG_{j_{d}}\theta_{j_{d}}}\cdots e^{iG_{j_{1}}\theta_{j_{1}}}|\psi\rangle% \approx|\phi\rangleitalic_e start_POSTSUPERSCRIPT italic_i italic_G start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⋯ italic_e start_POSTSUPERSCRIPT italic_i italic_G start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_θ start_POSTSUBSCRIPT italic_j start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUPERSCRIPT | italic_ψ ⟩ ≈ | italic_ϕ ⟩ (here, the Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are allowed to be applied in any order with repetition, and with arbitrary evolution angles θ𝜃\thetaitalic_θ)? Thus, when designing a hardness of approximation reduction, one can construct the Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT so that flipping a bit of x𝑥xitalic_x is artificially costly in terms of the depth d𝑑ditalic_d of the sequence of Hamiltonian evolutions. In contrast, for GSCON we do not have the luxury of forcing a prover to evolve according to any particular set of Hamiltonians — a dishonest prover can simply apply any sequence of unitaries desired, so long as each gate is 2222-local. To overcome this challenge, we begin with the basic GSCON setup outlined above, but move to a triple clock construction. Briefly, in addition to register B⁢C⁢D⁢E𝐵𝐶𝐷𝐸BCDEitalic_B italic_C italic_D italic_E where B𝐵Bitalic_B stores the n𝑛nitalic_n-bit string input to V𝑉Vitalic_V, we (1) add two additional clock registers K𝐾Kitalic_K and L𝐿Litalic_L of sizes 4⁢n4𝑛4n4 italic_n and 2222, respectively, (2) add two registers F𝐹Fitalic_F and G𝐺Gitalic_G each of size n𝑛nitalic_n and intended to hold copies of proof x𝑥xitalic_x, and (3) finally an “amplification” register M𝑀Mitalic_M. The basic premise is now that an honest prover proceeds in two phases. In the first phase, it manipulates clocks K⁢L𝐾𝐿KLitalic_K italic_L to be able to first prepare its desired proof x𝑥xitalic_x in B𝐵Bitalic_B. The Hamiltonian constraints we design are such that there is a unique time step tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT in which bits Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, Fisubscript𝐹𝑖F_{i}italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can be acted on. At time tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, if desired, the prover flips bits Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, Fisubscript𝐹𝑖F_{i}italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, thus creating triple redundancy. It is then forced to flip all (roughly) T𝑇Titalic_T bits in the amplification register M𝑀Mitalic_M from all zeroes to all ones, because the next time step ti+1subscript𝑡𝑖1t_{i}+1italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 1 will administer an energy penalty if Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT was set to 1111 but the qubits of M𝑀Mitalic_M still 00. It is now the triple redundancy on B⁢F⁢G𝐵𝐹𝐺BFGitalic_B italic_F italic_G that ensures that, once we leave timestep tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, it is impossible to change bit Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, because any single 2222-local gate will break the equality constraints we place between Bisubscript𝐵𝑖B_{i}italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, Fisubscript𝐹𝑖F_{i}italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and Gisubscript𝐺𝑖G_{i}italic_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT on all time steps other than tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Next, moving to time ti+2subscript𝑡𝑖2t_{i}+2italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 2, the prover is allowed to uncompute M𝑀Mitalic_M, and subsequently goes to time ti+3subscript𝑡𝑖3t_{i}+3italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 3, activating another Hamiltonian check that register M𝑀Mitalic_M is correctly reset to all zeroes. Finally, we move to time ti+4subscript𝑡𝑖4t_{i}+4italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 4, and the entire process repeats for the next proof bit Bi+1subscript𝐵𝑖1B_{i+1}italic_B start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT. This first phase continues until we arrive at the final time step on clocks K⁢L𝐾𝐿KLitalic_K italic_L, which de-activates a constraint preventing the GO register E𝐸Eitalic_E from being acted upon. In the second phase, the prover can now build a history state on registers B⁢C⁢D𝐵𝐶𝐷BCDitalic_B italic_C italic_D, and subsequently flip the GO qubits as in the basic setup to activate Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT, which checks the history state. For clarity, it is the flipping of all T𝑇Titalic_T bits in the amplification register, M𝑀Mitalic_M, which allows us to achieve our desired approximation ratio. To make this logic sound, it is imperative for the clocks K⁢L𝐾𝐿KLitalic_K italic_L to be carefully designed. The clock sequence we construct for the first phase is |00000⁢…⁢0⟩K⁢|00⟩L,subscriptket00000…0𝐾subscriptket00𝐿\displaystyle|00000\ldots 0\rangle_{K}|00\rangle_{L},| 00000 … 0 ⟩ start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT | 00 ⟩ start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT , (2) |10000⁢…⁢0⟩K⁢|10⟩L,subscriptket10000…0𝐾subscriptket10𝐿\displaystyle|10000\ldots 0\rangle_{K}|10\rangle_{L},| 10000 … 0 ⟩ start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT | 10 ⟩ start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT , (3) |11000⁢…⁢0⟩K⁢|11⟩L,subscriptket11000…0𝐾subscriptket11𝐿\displaystyle|11000\ldots 0\rangle_{K}|11\rangle_{L},| 11000 … 0 ⟩ start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT | 11 ⟩ start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT , (4) |11100⁢…⁢0⟩K⁢|01⟩L,subscriptket11100…0𝐾subscriptket01𝐿\displaystyle|11100\ldots 0\rangle_{K}|01\rangle_{L},| 11100 … 0 ⟩ start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT | 01 ⟩ start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT , (5) |11110⁢…⁢0⟩K⁢|00⟩L⁢, etc⁢….subscriptket11110…0𝐾subscriptket00𝐿, etc…\displaystyle|11110\ldots 0\rangle_{K}|00\rangle_{L}\text{, etc}\ldots.| 11110 … 0 ⟩ start_POSTSUBSCRIPT italic_K end_POSTSUBSCRIPT | 00 ⟩ start_POSTSUBSCRIPT italic_L end_POSTSUBSCRIPT , etc … . (6) which has three important properties enabling the soundness analysis to work: (1) Moving from a timestep tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to ti+1subscript𝑡𝑖1t_{i+1}italic_t start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT requires application of a 2222-qubit unitary on a unique pair of qubits qi,1subscript𝑞𝑖1q_{i,1}italic_q start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT and qi,2subscript𝑞𝑖2q_{i,2}italic_q start_POSTSUBSCRIPT italic_i , 2 end_POSTSUBSCRIPT. (2) It is impossible to jump from tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to (say) ti+2subscript𝑡𝑖2t_{i}+2italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT + 2 via a single 2222-local gate. (3) To satisfy the YES case conditions of GSCON, every intermediate state |ψl⟩ketsubscript𝜓𝑙|\psi_{l}\rangle| italic_ψ start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT ⟩ computed must have essentially all its amplitude on some single timestep tilsubscript𝑡subscript𝑖𝑙t_{i_{l}}italic_t start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT end_POSTSUBSCRIPT — for if not, any 2222-qubit unitary attempting to increment the time from tisubscript𝑡𝑖t_{i}italic_t start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT to ti+1subscript𝑡𝑖1t_{i+1}italic_t start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT will necessarily lead to non-trivial weight being placed on an invalid clock state, which is penalized. Techniques for GSE. We now discuss Theorem 3 for estimating ground state entanglement, which again proceeds via a gap-preserving reduction from QMSA. Thus, given a circuit V𝑉Vitalic_V which either accepts a low Hamming weight g𝑔gitalic_g proof or only high Hamming weight g′superscript𝑔′g^{\prime}italic_g start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT proofs, our goal is to construct a Hamiltonian with a low-energy state of low entanglement across a pre-specified cut in the YES case, or only highly entangled low-energy states in the NO case. The main idea is to add additional gates to V𝑉Vitalic_V, each of which is controlled on a different proof qubit. Then, for each proof qubit set to 1111, the corresponding added gate creates a Bell pair on a new register. This ensures that when there is a low (respectively, high) Hamming proof in the proof register, V𝑉Vitalic_V prepares a low- (respectively, high-) entanglement proof across a certain cut. Applying Kitaev’s circuit-to-Hamiltonian construction [KSV02] now yields a local Hamiltonian whose history state is correspondingly entangled. This works as desired for the YES case, when the history state is also a low energy state of Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT. However, the main technical hurdle is that in the NO case, we must show that all low energy states are highly entangled, not just the honest prover history state. For example, if the proof register contains a superposition over multiple high Hamming weight proofs (each of whose amplitudes can differ, and whose 1111’s can be in different positions), it is not as straightforward to argue that the corresponding ground state generated is highly entangled. A natural first idea is to try the standard QCMA trick [WZ06] of having V𝑉Vitalic_V immediately measure its proof register upon reading it to destroy such a superposition, or equivalently immediately copy its proof to a fresh ancilla and apply the principle of deferred measurement. However, this principle requires all qubit copies in the output to be traced out at the end of the computation, which is indeed the case for a general QCMA verifier interested in just measurement statistics on its designated output qubit. In our case, in contrast, we wish to quantify entanglement of the full output state across our cut. To bypass this, we instead coherently copy the proof to two new registers, and do not assume any qubits of our circuit’s output are traced out. Crucially, these registers will be on different sides of the cut for the entanglement entropy. Thus, when we consider a Schmidt decomposition for computing the entropy across this cut, it will depend on amplitudes corresponding to standard basis states which contain both a classical proof and some standard basis state on the Bell pair register. This allows us to reduce the analysis to the case where the proof register just contains one classical state. A soundness analysis can now be run when the prover sends an arbitrary history state. However, when the prover sends an arbitrary low energy state, two more tricks are required. First, we weight the Hin+Hprop+Hstabsubscript𝐻insubscript𝐻propsubscript𝐻stabH_{\rm in}+H_{\rm prop}+H_{\rm stab}italic_H start_POSTSUBSCRIPT roman_in end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT roman_prop end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT roman_stab end_POSTSUBSCRIPT terms of Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT with a large penalty term and apply the (Extended) Projection Lemma [KR03, GY19] to argue that any low-energy state must be close to a history state. We then apply the Fannes inequality [Fan73], which roughly says that states close in trace distance are also close in entanglement. Open questions. We have shown that computing properties of solution spaces to quantum CSPs is QCMA-hard to approximate. As the study of hardness of approximation for quantum complexity classes remains in its infancy, there are many open questions, aside from the natural question of a quantum PCP for QMA. First, in terms of GSCON, a curious fact is that it remains QCMA-complete even on commuting Hamiltonians [GMV17]. Does QCMA-hardness of approximation also hold in this setting? For GSE, we have studied the estimation of ground state entanglement across a specified cut. Can one also show QCMA-hardness of approximation for detecting other entanglement structures, such as area law versus volume law entanglement as in the LWE-hardness results of [BFG+24]? There are two challenges here. The first is that in contrast to [boulandComplexityVerificationQuantum2019], we must account for the entanglement created by the QMSA verification circuit V𝑉Vitalic_V embedded in our construction, which we have no control over. This can be partially alleviated by first modifying V𝑉Vitalic_V to copy its output to an ancilla qubit, subsequently applying V†superscript𝑉†V^{\dagger}italic_V start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT to undo the entanglement created by V𝑉Vitalic_V, and then padding by identity gates. However, this is not ideal, as we cannot blow up the size of V𝑉Vitalic_V by a superlinear factor (otherwise our approximation ratio suffers); thus, we can at best linearly suppress the entanglement generated by V𝑉Vitalic_V. The second (bigger) problem is that even in the YES case for QMSA, the construction of [GK12b] can have linear Hamming weight accepting proofs (relative to the size of the proof register, not the instance encoding size), leading to the creation of linearly many Bell pairs in our GSE YES case. In contrast, a 1D area law requires O⁢(1)𝑂1O(1)italic_O ( 1 ) (or at most polylog) entanglement entropy across cuts. Finally, are there other natural QCMA-hard to approximate problems? An excellent candidate is one of the first QCMA-complete problems, approximating the length of the minimum circuit preparing a ground state of a given local Hamiltonian (MIN-CIRCUIT) [WZ06], under the additional promise that a poly-length preparation circuit exists. Can one show that this minimum circuit size is QCMA-hard to approximate? (Note that unlike the classic Minimum Circuit Size Problem (MCSP), in which one is given a Boolean truth table T𝑇Titalic_T as input and asked for a minimum size circuit computing T𝑇Titalic_T, this question is different in that the input is analogous to a k𝑘kitalic_k-CSP formula rather than a truth table.) Our techniques do not obviously extend to MIN-CIRCUIT for a seemingly crucial reason — for GSCON recall our main challenge was to increase the cost of preparing a history state without altering the length of the circuit V𝑉Vitalic_V on which we apply Kitaev’s circuit-to-Hamiltonian construction. This was critical, because we needed the cost of proof preparation to scale linearly with the size of V𝑉Vitalic_V, so that we could translate a hardness gap for QMSA into one for GSCON. In contrast, MIN-CIRCUIT is a fairly “bare-bones” problem, e.g. there is no path through a ground space we can carve out or set of evolution Hamiltonians as in MIN-VQA through which one might attempt to exert control on a dishonest prover. Thus, it seems unclear how to amplify the cost of preparing a proof without complicating the circuit V𝑉Vitalic_V fed into the circuit-to-Hamiltonian construction, which would blow up the encoding size of Hkitsubscript𝐻kitH_{\textup{kit}}italic_H start_POSTSUBSCRIPT kit end_POSTSUBSCRIPT and thus degrade the hardness ratio obtained."
https://arxiv.org/html/2411.04846v1,On the Complexity of 2-club Cluster Editing with Vertex Splitting,"Editing a graph to obtain a disjoint union of s𝑠sitalic_s-clubs is one of the models for correlation clustering, which seeks a partition of the vertex set of a graph so that elements of each resulting set are close enough according to some given criterion. For example, in the case of editing into s𝑠sitalic_s-clubs, the criterion is proximity since any pair of vertices (in an s𝑠sitalic_s-club) are within a distance of s𝑠sitalic_s from each other. In this work we consider the vertex splitting operation, which allows a vertex to belong to more than one cluster. This operation was studied as one of the parameters associated with the Cluster Editing problem. We study the complexity and parameterized complexity of the s𝑠sitalic_s-Club Cluster Edge Deletion with Vertex Splitting and s𝑠sitalic_s-Club Cluster Vertex Splitting problems. Both problems are shown to be \NP\NP\NP-Complete and \APX\APX\APX-hard. On the positive side, we show that both problems are Fixed-Parameter Tractable with respect to the number of allowed editing operations and that s𝑠sitalic_s-Club Cluster Vertex Splitting is solvable in polynomial-time on the class of forests.","Correlation clustering is viewed as a graph modification problem where the objective is to perform a sequence of editing operations (or modifications) to obtain a disjoint union of clusters. Many variants of this problem have been studied in the literature, each with a different definition either of what a cluster means or of the various types of allowed modifications. In the Cluster Editing problem, for example, a cluster was defined to be a clique and the allowed editing operations were edge additions and deletions [12, 22, 18]. Later, some relaxation models such as s𝑠sitalic_s-Clubs and s𝑠sitalic_s-Clans emerged as they were deemed ideal models for clustering Biological Networks [7, 27]. Subsequent efforts studied overlapping clusters in a graph theoretical context [10, 15, 4]. In this work, we deal with overlapping communities by performing vertex splitting, which allows a vertex to be cloned and placed in more than one cluster. This operation was introduced in [4] in the study of the Cluster editing with Vertex Splitting problem. The notion of vertex splitting was first introduced in [19] but not in the context of correlation clustering. The Cluster Editing and Cluster Deletion problems were shown to be \NP\NP\NP-Complete in [22, 28]. Several other variants of the problem have also been proved to be \NP\NP\NP-Complete. This includes Cluster Vertex Deletion [23], 2-club Cluster Editing [25], 2-club Cluster Vertex Deletion [25], 2-club Cluster Edge Deletion [25] , Cluster Vertex Splitting [17], and Cluster Editing with Vertex Splitting [2, 5]. From a parameterized complexity standpoint, Cluster Editing, Cluster Deletion, and Cluster Vertex Deletion are known to be Fixed-Parameter Tractable (\FPT\FPT\FPT) [18, 21]. The same holds for the two club-variants: 2-club Cluster Edge Deletion and 2-club Cluster Vertex Deletion [25], while 2-club Cluster Editing was shown to be \W⁢[2]\Wdelimited-[]2\W[2][ 2 ]-Hard [16]. Furthermore, the Cluster Editing with Vertex Splitting problem has also been show to be \FPT\FPT\FPT [2, 5]. From a polynomial-time approximation standpoint, the Cluster Editing and Cluster Edge Deletion problems are \APX\APX\APX-Hard and have O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n ) approximation algorithms [13]. On the other hand, Cluster Vertex Deletion has a factor-two approximation algorithm [6]. To the best of our knowledge, problem variants with s𝑠sitalic_s-clubs or vertex splitting do not have any known approximation results. The problems mentioned above are all considered different models of correlation clustering. The s𝑠sitalic_s-Club models were shown to be effective in some networks where a clique could not capture all information needed to form better clusters [7, 27]. Vertex splitting proved to be useful, and in fact essential, when the input data has overlapping clusters, such as in protein networks [26]. So far, vertex splitting has been used along with cluster editing. In this paper we introduce the operation to the club-clustering variant by introducing two new problems: 2-club Cluster Vertex Splitting (2CCVS) and 2-club Cluster Edge Deletion with Vertex Splitting (2CCEDVS). These problems seek to modify a graph into a 2-clubs graph by performing a series of vertex splitting (2CCVS and 2CCEDVS) and edge deletion (2CCEDVS) operations. Our contribution. We prove that 2CCVS and 2CCEDVS are \NP\NP\NP-Complete. On the positive side, we prove that both problems are \FPT\FPT\FPT and that 2CCVS is solvable in polynomial-time on forests. We also show that, unless ¶=\NP¶\NP\P=\NP¶ =, the two problems cannot be approximated in polynomial time with a ratio better than a certain constant >1absent1>1> 1."
https://arxiv.org/html/2411.04566v1,On the average-case hardness of BosonSampling,"BosonSampling is a popular candidate for near-term quantum advantage, which has now been experimentally implemented several times. The original proposal of Aaronson and Arkhipov from 2011 showed that classical hardness of BosonSampling is implied by a proof of the “Gaussian Permanent Estimation” conjecture. This conjecture states that e−n⁢log⁡n−n−O⁢(log⁡n)superscript𝑒𝑛𝑛𝑛𝑂𝑛e^{-n\log{n}-n-O(\log n)}italic_e start_POSTSUPERSCRIPT - italic_n roman_log italic_n - italic_n - italic_O ( roman_log italic_n ) end_POSTSUPERSCRIPT additive error estimates to the output probability of most random BosonSampling experiments are #P-hard. Proving this conjecture has since become the central question in the theory of quantum advantage.In this work we make progress by proving that e−n⁢log⁡n−n−O⁢(nδ)superscript𝑒𝑛𝑛𝑛𝑂superscript𝑛𝛿e^{-n\log n-n-O(n^{\delta})}italic_e start_POSTSUPERSCRIPT - italic_n roman_log italic_n - italic_n - italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT additive error estimates to output probabilities of most random BosonSampling experiments are #P-hard, for any δ>0𝛿0\delta>0italic_δ > 0. In the process, we circumvent all known barrier results for proving the hardness of BosonSampling experiments. This is nearly the robustness needed to prove hardness of BosonSampling—the remaining hurdle is now “merely” to show that the nδsuperscript𝑛𝛿n^{\delta}italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT in the exponent can be improved to O⁢(log⁡n).𝑂𝑛O(\log n).italic_O ( roman_log italic_n ) . We also obtain an analogous result for Random Circuit Sampling.Our result allows us to show, for the first time, a hardness of classical sampling result for random BosonSampling experiments, under an anticoncentration conjecture. Specifically, we prove the impossibility of multiplicative-error sampling from random BosonSampling experiments with probability 1−e−O⁢(n)1superscript𝑒𝑂𝑛1-e^{-O(n)}1 - italic_e start_POSTSUPERSCRIPT - italic_O ( italic_n ) end_POSTSUPERSCRIPT, unless the Polynomial Hierarchy collapses.","We have seen the first claims of “quantum advantage”: the first experimental demonstration of an exponential quantum speedup [Aru19, Mor24, Wu21, Zho20, Zho21, Den23, YGE+24, Mad22]. While these experiments differ from one another dramatically, theoretically they are all solving average-case quantum sampling problems. In other words, the task is to sample from the output distribution of a quantum circuit chosen from some particular distribution. In this work we will focus on proving the classical hardness of BosonSampling experiments, in which the circuits are chosen randomly from a family of linear optical circuits [AA13]. Variants of this experiment have been implemented several times by groups at USTC, Xanadu, and NIST [Zho20, Zho21, Den23, Mad22, YGE+24]. Aaronson and Arkhipov showed that to prove the classical hardness of sampling from these experiments it suffices to prove that a problem known as GPE, or Gaussian Permanent Estimation, is #P-hard. Roughly speaking the GPE conjecture is asking if obtaining a multiplicative estimate to an output probability of a random BosonSampling experiments is #P-hard. Moreover, assuming a statistical “flatness” property about the output distribution known as anticoncentration (which we also assume in this work), it suffices to prove that obtaining an additive error estimate of e−n⁢log⁡n−n−O⁢(log⁡n)superscript𝑒𝑛𝑛𝑛𝑂𝑛e^{-n\log{n}-n-O(\log n)}italic_e start_POSTSUPERSCRIPT - italic_n roman_log italic_n - italic_n - italic_O ( roman_log italic_n ) end_POSTSUPERSCRIPT to the output probability of most random experiments is #P-hard. This latter problem is known as GPE±. In the last decade, progress has been made toward proving the hardness of GPE± [AA13, BFLL22, Kro23]. While Aaronson and Arkhipov’s initial work showed computing additive error estimates of e−O⁢(n4)superscript𝑒𝑂superscript𝑛4e^{-O(n^{4})}italic_e start_POSTSUPERSCRIPT - italic_O ( italic_n start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT to the output probability of most BosonSampling experiments is #P-hard [AB16], this error tolerance was subsequently improved to e−6⁢n⁢log⁡n−O⁢(n)superscript𝑒6𝑛𝑛𝑂𝑛e^{-6n\log{n}-O(n)}italic_e start_POSTSUPERSCRIPT - 6 italic_n roman_log italic_n - italic_O ( italic_n ) end_POSTSUPERSCRIPT by Bouland, Fefferman, Landau, and Liu [BFLL22], and then to e−4⁢n⁢log⁡n−O⁢(n)superscript𝑒4𝑛𝑛𝑂𝑛e^{-4n\log{n}-O(n)}italic_e start_POSTSUPERSCRIPT - 4 italic_n roman_log italic_n - italic_O ( italic_n ) end_POSTSUPERSCRIPT in unpublished work of Krovi [Kro23] (personal communication). Therefore the remaining gap to establish the hardness of BosonSampling is to improve the robustness of this result by a constant factor in the exponent. This seems amazingly “close” to the mark in additive terms yet exponentially far away in relative terms. We note the analogous conjectures for all other quantum advantage experiments remain open as well, such as Random Circuit Sampling [BIS+18], despite much progress in the area [BFNV19, Mov23, BFLL22, KMM22, ODMZ22, Kro22]. Why has it been so difficult to improve the robustness of this result and prove classical hardness of BosonSampling or any other quantum advantage experiment? One of the major reasons is that there are well-known barrier results that show that new techniques are needed to prove hardness of sampling. The first such barrier was noted in Aaronson and Arkhipov’s original paper, which we call the “convexity barrier” [AA13]. The basic idea is that current worst-to-average-case reductions for the permanent are based on polynomial extrapolation, following Lipton’s proof [Lip91]. The set of low-degree polynomials is convex, and necessarily must be exponentially ill-conditioned (even for the subset of polynomials corresponding to valid permanent extrapolations). Thus polynomial extrapolation cannot be used to cross the finish line and prove the hardness of GPE±, as it will always introduce exponential relative error. For GPE±, this barrier sits at e−3⁢n⁢log⁡nsuperscript𝑒3𝑛𝑛e^{-3n\log n}italic_e start_POSTSUPERSCRIPT - 3 italic_n roman_log italic_n end_POSTSUPERSCRIPT [BFLL22]. There is also a closely related “noise barrier” of [BFLL22], which states that any proof of sampling hardness must not be invariant to adding constant noise rate to the experiment—and by convexity, polynomial interpolation does not cross this barrier. There are also barriers specific to particular experiments. For Random Circuit Sampling (RCS) over qubits, there are two additional barriers. One is the so-called “depth barrier” of Napp et al. [NLPD+22]. This paper gives a classical algorithm that approximately samples from the output distribution of shallow (i.e., sufficiently small constant) depth random quantum circuit sampling experiments. On the other hand, the existing techniques for proving hardness of computing output probabilities work with respect to circuits of any depth. Therefore, if we are to prove hardness of sampling, we need to find a proof technique that is sensitive to circuit depth and only works to prove hardness for sufficiently deep circuits. Another is the “worst-case barrier” which was identified by Krovi [Kro22]. The issue is that the desired additive robustness of computing random circuit output probabilities (2−nsuperscript2𝑛~{}2^{-n}2 start_POSTSUPERSCRIPT - italic_n end_POSTSUPERSCRIPT) is actually larger than the known worst-case hardness in additive terms (2−2⁢nsuperscript22𝑛~{}2^{-2n}2 start_POSTSUPERSCRIPT - 2 italic_n end_POSTSUPERSCRIPT), as this is derived from Fourier Sampling. Since polynomial interpolation is sensitive to noise in additive terms, it can’t be used to show hardness of sampling. For BosonSampling, there is another barrier we call the “Jerrum-Sinclair-Vigoda barrier,” which may be even more fundamental. It is inspired by a well-known efficient classical algorithm for multiplicatively estimating the permanent of a matrix with non-negative entries [JSV04]. This algorithm tells us that any technique used to prove the hardness of GPE± must fundamentally make use of the fact that matrices with i.i.d. 𝒩⁢(0,1)𝒩01{\mathcal{N}}(0,1)caligraphic_N ( 0 , 1 ) entries have negative as well as positive entries. All existing worst-to-average-case reductions for Gaussian permanents work equally well for non-negative permanents as well. Thus current proofs can’t possibly prove the GPE conjecture. In other words, to show hardness of sampling, we will need a proof which uses a special property of matrices with negative entries (like multiplicative hardness in the worst case) which does not hold for nonnegative matrices. Indeed we have also seen algorithmic attacks on GPE± which work for Gaussian matrices with positive means [EM18]—which make use of the fact such matrices have “less” cancellation than Gaussian permanents. Finally, we note there is a relativization barrier of Aaronson and Chen [AC17], which says any proof of quantum approximate sampling advantage (i.e. sampling to small ℓ1subscriptℓ1\ell_{1}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT error) must use non-relativizing techniques. However our work will focus on hardness of average-case exact sampling algorithms (i.e. sampling to small multiplicative error)—to which a relativization barrier does not apply as noted in [AC17]—see Discussion Sec. 1.3. 1.1 Our results In this work we introduce a new suite of tools which allow us to obtain an exponential improvement on the state-of-the-art robustness results for BosonSampling experiments. In particular we invent new techniques that overcome all of the barriers described above. While our work does not resolve the GPE conjecture, we show it allows us to prove the first non-trivial hardness of average-case sampling result for BosonSampling. For technical reasons all of our results will be proven for orthogonal BosonSampling, i.e. where the interferometer is a random orthogonal matrix, a case for which all existing arguments for BosonSampling hold equally well. We conjecture our results could also be extended to the complex case, and discuss some of the technical difficulties involved in doing so in E. Our first result is to show we can get within an nδsuperscript𝑛𝛿n^{\delta}italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT factor of proving hardness of sampling for BosonSampling, for any δ>0𝛿0\delta>0italic_δ > 0. This shows for the first time we can achieve a robustness whose leading order terms match those desired for sampling hardness: Theorem 1.1. For any δ>0𝛿0\delta>0italic_δ > 0, it is #⁢P#P\#\textsf{P}# P-hard to approximate the output probabilities of an n𝑛nitalic_n-photon O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )-mode orthogonal BosonSampling experiment to additive error e−n⁢log⁡n−n−O⁢(nδ)superscript𝑒𝑛𝑛𝑛𝑂superscript𝑛𝛿e^{-n\log n-n-O(n^{\delta})}italic_e start_POSTSUPERSCRIPT - italic_n roman_log italic_n - italic_n - italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT. This is nearly at the robustness needed for hardness of sampling—in particular if the nδsuperscript𝑛𝛿n^{\delta}italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT in the exponent could “merely” be improved to O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n ), this would imply hardness of sampling. This overcomes all proof barriers identified for BosonSampling, including the convexity and Jerrum-Sinclair-Vigoda barriers. In order to prove this result, we give a new worst-to-average-case reduction for BosonSampling which replaces polynomial extrapolation with polynomial coefficient extraction. This allows us to lessen the degree of the polynomial involved in the coefficient extraction argument and hence reduce the ill-conditionedness of the worst-to-average-case reduction. Crucially our proof derives the value of the worst case to relative error, and hence requires worst-case matrices with negative entries, thus surpassing the Jerrum-Sinclair-Vigoda barrier. We also show this idea can be ported to other quantum advantage experiments, like random circuit sampling: Corollary 1.2. For any δ>0𝛿0\delta>0italic_δ > 0, it is #⁢P#P\#\textsf{P}# P-hard to approximate the output probabilities of n𝑛nitalic_n-qubit random circuit sampling experiments of logarithmic depth to additive error 2−n−O⁢(nδ)superscript2𝑛𝑂superscript𝑛𝛿2^{-n-O(n^{\delta})}2 start_POSTSUPERSCRIPT - italic_n - italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT. Just as with BosonSampling, this exponentially improves over prior work [BFNV19, Mov23, BFLL22, KMM22, Kro22], and obtains hardness which is within an nδsuperscript𝑛𝛿n^{\delta}italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT factor of what is needed for hardness of sampling. For RCS this proof surpasses the worst-case barrier of Krovi [Kro22], as the worst-case value of the reduction is (to leading order) the same111The astute reader may notice there is a subleading reduction in the worst-case value—this is fixed in Lemma 1.3 which also applies to RCS. as the average-case value due to the dilution. It also surpasses the depth barrier of Napp et al. [NLPD+22], as the proof uses anticoncentration of RCS, which does not hold for general constant-depth RCS ensembles [DHB20a]. It thus clears all barriers for RCS as well. A closer examination of our first result, however, reveals it does not yet allow us to show any hardness of average-case sampling results. This is because the proof exhibits an exponential robustness loss in going from the average case to worst case via polynomial coefficient extraction (now reduced from eO⁢(n⁢log⁡n)superscript𝑒𝑂𝑛𝑛e^{O(n\log n)}italic_e start_POSTSUPERSCRIPT italic_O ( italic_n roman_log italic_n ) end_POSTSUPERSCRIPT to eO⁢(nδ)superscript𝑒𝑂superscript𝑛𝛿e^{O(n^{\delta})}italic_e start_POSTSUPERSCRIPT italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT) with no possible compensating exponential gain in the proof (for either BosonSampling or RCS). The only compensating factor in the proof is from the error in the Stockmeyer counting which is at most inverse-polynomial. Thus one cannot obtain hardness of sampling from this first argument. To address this, we develop a new worst-to-average-case reduction in which the exponential loss in robustness from coefficient extraction can be compensated by an exponential gain in robustness as well for the first time. This opens the possibility of showing an average-case sampling hardness result via Stockmeyer counting. In particular we show: Lemma 1.3. (Informal) It is #⁢𝖯#𝖯\#\mathsf{P}# sansserif_P-hard to compute output probabilities of real BosonSampling experiments to relative error ϵr⁢e⁢lsubscriptitalic-ϵ𝑟𝑒𝑙\epsilon_{rel}italic_ϵ start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT satisfying ϵr⁢e⁢l≤loss×v⁢a⁢lworsev⁢a⁢lavgsubscriptitalic-ϵ𝑟𝑒𝑙loss𝑣𝑎subscript𝑙worse𝑣𝑎subscript𝑙avg\epsilon_{rel}\leq\text{loss}\times\frac{val_{\text{worse}}}{val_{\text{avg}}}italic_ϵ start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT ≤ loss × divide start_ARG italic_v italic_a italic_l start_POSTSUBSCRIPT worse end_POSTSUBSCRIPT end_ARG start_ARG italic_v italic_a italic_l start_POSTSUBSCRIPT avg end_POSTSUBSCRIPT end_ARG where here v⁢a⁢lworse𝑣𝑎subscript𝑙worseval_{\text{worse}}italic_v italic_a italic_l start_POSTSUBSCRIPT worse end_POSTSUBSCRIPT is the value of the worst-case permanent we are computing, and v⁢a⁢lavg𝑣𝑎subscript𝑙avgval_{\text{avg}}italic_v italic_a italic_l start_POSTSUBSCRIPT avg end_POSTSUBSCRIPT is the value of the average-case permanent of the ensemble, and loss is the (exponential) loss of ill-conditionedness of polynomial coefficient extraction or extrapolation. To show hardness of average-case exact sampling, one needs ϵr⁢e⁢lsubscriptitalic-ϵ𝑟𝑒𝑙\epsilon_{rel}italic_ϵ start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT to be at most inverse polynomial—then this would imply that Stockmeyer’s algorithm could obtain this approximation, and hence place #⁢𝖯⊆𝖡𝖯𝖯𝖭𝖯#𝖯superscript𝖡𝖯𝖯𝖭𝖯\#\mathsf{P}\subseteq{\mathsf{BPP}}^{\mathsf{NP}}# sansserif_P ⊆ sansserif_BPP start_POSTSUPERSCRIPT sansserif_NP end_POSTSUPERSCRIPT. The key point of this equation is, for the first time, this exponential extrapolation is fighting against a compensating term—the ratio of worst to average-case values—which can be made exponential in n𝑛nitalic_n as well. For example, for a permanent of 𝒩⁢(0,1)𝒩01{\mathcal{N}}(0,1)caligraphic_N ( 0 , 1 ) matrices, the worst-case value (n!𝑛n!italic_n !) can be exponentially bigger than the average case value ( O⁢(n!)𝑂𝑛O(\sqrt{n!})italic_O ( square-root start_ARG italic_n ! end_ARG )), and we will show we can restrict our worst case to having large permanents while retaining hardness. Thus the fate of average-case sampling hardness hangs in the balance of a tug of war between two competing exponential terms. If we could simply reduce the coefficient extraction loss to a weaker exponential, or strengthen the worst to average-case ratio to a bigger exponential, this could potentially solve hardness of sampling. We note an analogous theorem holds for a real variant of RCS as well. Lemma 1.3 does not quite resolve the hardness of GPE±. If we engineer our worst case matrix to have a permanent of roughly n!𝑛n!italic_n ! (appropriately rescaled) and apply coefficient extraction, it gives us a robustness of e−1.5⁢n⁢log⁡nsuperscript𝑒1.5𝑛𝑛e^{-1.5n\log n}italic_e start_POSTSUPERSCRIPT - 1.5 italic_n roman_log italic_n end_POSTSUPERSCRIPT for standard BosonSampling, but now for a dense worst case, i.e. there is no “dilution” occurring in the argument. However, it does allow us to show, for the first time, a hardness of sampling result for random BosonSampling experiments: Theorem 1.4. There is no efficient classical algorithm which exactly samples from the output distribution of n𝑛nitalic_n-photon O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )-mode real BosonSampling experiments with probability more than 1−2−O⁢(n)1superscript2𝑂𝑛1-2^{-O(n)}1 - 2 start_POSTSUPERSCRIPT - italic_O ( italic_n ) end_POSTSUPERSCRIPT over the choice of experiment, assuming PH does not collapse and a slight generalization of permanent anticoncentration. Here by exact sampler we mean one which makes small relative error on each output probability of the experiment. The proof of this fact requires introducing new tools in worst-to-average-case reductions which go beyond total variation distance as a means to quantify when an average-case algorithm works. We note that this sampling result is weaker than what would be implied by a proof of the GPE conjecture in two ways. First, this result proves the impossibility of classically sampling from 1−1/2O⁢(n)11superscript2𝑂𝑛1-1/2^{O(n)}1 - 1 / 2 start_POSTSUPERSCRIPT italic_O ( italic_n ) end_POSTSUPERSCRIPT fraction of experiments, whereas a proof of the GPE conjecture would strengthen this to 1−1/poly⁢(n)11poly𝑛1-1/{\mathrm{poly}}(n)1 - 1 / roman_poly ( italic_n ) fraction of experiments. This is nontrivial, as our exponential function is larger than what we would need to say the algorithm computes the worst case directly222We emphasize that the input size for an n𝑛nitalic_n-photon experiment is much bigger than n𝑛nitalic_n (it is O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) entries, each of which must be specified to O~⁢(n)~𝑂𝑛\tilde{O}(n)over~ start_ARG italic_O end_ARG ( italic_n ) bits of precision to define the average-case exact sampling problem). (which is 1−2−O⁢(n3)1superscript2𝑂superscript𝑛31-2^{-O(n^{3})}1 - 2 start_POSTSUPERSCRIPT - italic_O ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT by Lemma 4.6). Second, our result works to rule out a classical algorithm that samples exactly (or multiplicatively close in every probability) from these experiments, rather than approximately in total variation distance. Third, we assume a slightly stronger version of anticoncentration conjecture than is standard in BosonSampling. Those caveats aside, the main point of our new result is that it shows for the first time that one can show a form of average-case sampling hardness, using polynomial coefficient extraction techniques combined with Stockmeyer counting. This had been open for all quantum supremacy proposals, as prior near-exact hardness results for computing output probabilities do not imply any average-case sampling hardness (even of exact sampling) due to the weakness of Stockmeyer counting. Interestingly this last result only holds for BosonSampling, as the state of average-case hardness for RCS is further from the target robustness than BosonSampling—see Discussion 1.3. 1.2 Proof techniques To explain our proof, it is helpful to briefly recall the average-case hardness proofs of [AA13] and its subsequent improvements [BFLL22, Kro23]. The basic idea is to use polynomial interpolation to show the squared permanent is hard to compute on average, following Lipton [Lip91]. Suppose we wish to compute the squared permanent of a worst-case matrix W∈{0,±1}n×n𝑊superscript0plus-or-minus1𝑛𝑛W\in\{0,\pm 1\}^{n\times n}italic_W ∈ { 0 , ± 1 } start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT using only the ability to compute most Gaussian permanents R𝑅Ritalic_R drawn from 𝒩⁢(0,1)n×n𝒩superscript01𝑛𝑛{\mathcal{N}}(0,1)^{n\times n}caligraphic_N ( 0 , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT. We define a univariate family of matrices interpolating between W𝑊Witalic_W and a single random choice of Gaussian matrix R𝑅Ritalic_R: A⁢(t)=(1−t)⁢R+t⁢W𝐴𝑡1𝑡𝑅𝑡𝑊A(t)=(1-t)R+tWitalic_A ( italic_t ) = ( 1 - italic_t ) italic_R + italic_t italic_W This family has three nice properties that enable the reduction: first |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is a low-degree polynomial in t𝑡titalic_t, second the marginal distribution on A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) is close to Gaussian on small values of t𝑡titalic_t, and third, |Per⁡(A⁢(1))|2=|Per⁡(W)|2superscriptPer𝐴12superscriptPer𝑊2|\operatorname{Per}(A(1))|^{2}=|\operatorname{Per}(W)|^{2}| roman_Per ( italic_A ( 1 ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = | roman_Per ( italic_W ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. This means one can compute |Per⁡(W)|2superscriptPer𝑊2|\operatorname{Per}(W)|^{2}| roman_Per ( italic_W ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT by computing |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT at many small values of t𝑡titalic_t, inferring the polynomial in t𝑡titalic_t, and extrapolating it to 1111. The robustness of this worst-to-average-case reduction to errors on the average-case points is the ill-conditionedness of the polynomial extrapolation step. This is controlled by the degree of the polynomial involved (d𝑑ditalic_d), and second, the distance of extrapolation ΔΔ\Deltaroman_Δ. If a degree d𝑑ditalic_d polynomial is evaluated to error ±ϵplus-or-minusitalic-ϵ\pm\epsilon± italic_ϵ at points t<1/Δ𝑡1Δt<1/\Deltaitalic_t < 1 / roman_Δ and extrapolated to t=1𝑡1t=1italic_t = 1, the error at 1111 blows up by roughly ϵ⁢Δditalic-ϵsuperscriptΔ𝑑\epsilon\Delta^{d}italic_ϵ roman_Δ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. In both the proofs of [BFLL22] and [Kro23] the main improvement was in reducing the distance of extrapolation, while keeping the same degree of polynomial (2⁢n2𝑛2n2 italic_n for a squared permanent). In particular in [BFLL22] the distance was reduced to Δ=O⁢(1/n2)Δ𝑂1superscript𝑛2\Delta=O(1/n^{2})roman_Δ = italic_O ( 1 / italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) by introducing a robust version of Berkelamp-Welch over the complex numbers 333We note similar results for BosonSampling could be obtained by the techniques of [KMM22].. In [Kro23] the distance was improved to Δ=O⁢(1/n)Δ𝑂1𝑛\Delta=O(1/n)roman_Δ = italic_O ( 1 / italic_n ) by combining this with a more sophisticated calculation of the total variation distance between A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) and Gaussian, which saves a factor of n2⁢n=e2⁢n⁢log⁡nsuperscript𝑛2𝑛superscript𝑒2𝑛𝑛n^{2n}=e^{2n\log n}italic_n start_POSTSUPERSCRIPT 2 italic_n end_POSTSUPERSCRIPT = italic_e start_POSTSUPERSCRIPT 2 italic_n roman_log italic_n end_POSTSUPERSCRIPT in the exponent. These yield the stated robustness values when suitably renormalized. 1.2.1 Coefficient extraction: a new way to encode the permanent A natural approach to try to improve the robustness of this argument is to reduce the degree of the polynomial involved. A simple observation is that for any ε>0𝜀0\varepsilon>0italic_ε > 0, it is #⁢𝖯#𝖯\#\mathsf{P}# sansserif_P-hard to compute the permanent of an nε×nεsuperscript𝑛𝜀superscript𝑛𝜀n^{\varepsilon}\times n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT matrix W𝑊Witalic_W as well—this is simply polynomially shrinking the input size. Therefore a natural way to improve the robustness is to try to make W𝑊Witalic_W smaller. Unfortunately this doesn’t yield much progress with polynomial extrapolation arguments. That’s because if we set W𝑊Witalic_W to have small support—say with only O⁢(nε)𝑂superscript𝑛𝜀O(n^{\varepsilon})italic_O ( italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ) nonzero entries—then Per⁡(W)=0Per𝑊0\operatorname{Per}(W)=0roman_Per ( italic_W ) = 0. Trivially, a matrix must have at least n𝑛nitalic_n non-zero entries for its permanent to be non-zero. This lower bounds how much one could gain by such arguments using extrapolation, and the best one can obtain by dilution is e−3⁢n⁢log⁡n−O⁢(n)superscript𝑒3𝑛𝑛𝑂𝑛e^{-3n\log n-O(n)}italic_e start_POSTSUPERSCRIPT - 3 italic_n roman_log italic_n - italic_O ( italic_n ) end_POSTSUPERSCRIPT robustness444This is obtained by setting W𝑊Witalic_W to be a tiny nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT dimension worst-case matrix in the upper left corner in direct sum with an identity on the remaining n−nε𝑛superscript𝑛𝜀n-n^{\varepsilon}italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT dimensions—which sits right at the convexity barrier. Our first step is to change the worst-to-average-case reduction from a problem about polynomial extrapolation to a problem about polynomial coefficient extraction. We consider a one-parameter family of matrices A⁢(t)=R+t⁢Wdilute𝐴𝑡𝑅𝑡subscript𝑊diluteA(t)=R+tW_{\text{dilute}}italic_A ( italic_t ) = italic_R + italic_t italic_W start_POSTSUBSCRIPT dilute end_POSTSUBSCRIPT and consider the case that Wdilutesubscript𝑊diluteW_{\text{dilute}}italic_W start_POSTSUBSCRIPT dilute end_POSTSUBSCRIPT consists of a tiny nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT-sized worst case matrix W′superscript𝑊′W^{\prime}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT in direct sum with the all 00’s matrix on the remaining n−nε𝑛superscript𝑛𝜀n-n^{\varepsilon}italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT dimensions. The key point of this construction is, even though the value of |Per⁡(A⁢(1))|2superscriptPer𝐴12|\operatorname{Per}(A(1))|^{2}| roman_Per ( italic_A ( 1 ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is not what we want (as A⁢(1)=R+Wdilute𝐴1𝑅subscript𝑊diluteA(1)=R+W_{\text{dilute}}italic_A ( 1 ) = italic_R + italic_W start_POSTSUBSCRIPT dilute end_POSTSUBSCRIPT), the coefficients of the polynomial |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT do encode information about Per⁡(W′)Persuperscript𝑊′\operatorname{Per}(W^{\prime})roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ). In particular, the degree of the polynomial |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is now n2⁢εsuperscript𝑛2𝜀n^{2\varepsilon}italic_n start_POSTSUPERSCRIPT 2 italic_ε end_POSTSUPERSCRIPT, and the top coefficient is |Per⁡(W′)|2⁢|Per⁡(RD)|2superscriptPersuperscript𝑊′2superscriptPersubscript𝑅𝐷2|\operatorname{Per}(W^{\prime})|^{2}|\operatorname{Per}(R_{D})|^{2}| roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT | roman_Per ( italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, where RDsubscript𝑅𝐷R_{D}italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT is the bottom righthand minor of R𝑅Ritalic_R of dimension n−nε𝑛superscript𝑛𝜀n-n^{\varepsilon}italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT (see Figure 1): |Per⁡(A⁢(t))|2=|Per⁡(W′)|2⁢|Per⁡(RD)|2⁢t2⁢nε+∑ℓ=0n2⁢ε−1cℓ⁢tℓsuperscriptPer𝐴𝑡2superscriptPersuperscript𝑊′2superscriptPersubscript𝑅𝐷2superscript𝑡2superscript𝑛𝜀superscriptsubscriptℓ0superscript𝑛2𝜀1subscript𝑐ℓsuperscript𝑡ℓ|\operatorname{Per}(A(t))|^{2}=|\operatorname{Per}(W^{\prime})|^{2}|% \operatorname{Per}(R_{D})|^{2}t^{2n^{\varepsilon}}+\displaystyle\sum_{\ell=0}^% {n^{2\varepsilon}-1}c_{\ell}t^{\ell}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = | roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT | roman_Per ( italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_t start_POSTSUPERSCRIPT 2 italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT roman_ℓ = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT 2 italic_ε end_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_t start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT where the cℓsubscript𝑐ℓc_{\ell}italic_c start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT are some other coefficients which depend (in some complicated manner) on the entries of R𝑅Ritalic_R and W𝑊Witalic_W. To see this, simply note that any term in the permanent which picks up all possible factors of t𝑡titalic_t must take all of its entries in the first nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT rows from the upper left submatrix. |Per(\Bigg{|}\operatorname{Per}\bigg{(}| roman_Per (R∼𝒩⁢(0,1)n×nsimilar-to𝑅𝒩superscript01𝑛𝑛R\sim{\mathcal{N}}(0,1)^{n\times n}italic_R ∼ caligraphic_N ( 0 , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT+++t𝑡titalic_t000000RCsubscript𝑅𝐶R_{C}italic_R start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPTRDsubscript𝑅𝐷R_{D}italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPTRAsubscript𝑅𝐴R_{A}italic_R start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPTRBsubscript𝑅𝐵R_{B}italic_R start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPTW′superscript𝑊′W^{\prime}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPTW′∈{0,±1}nε×nεsuperscript𝑊′superscript0plus-or-minus1superscript𝑛𝜀superscript𝑛𝜀W^{\prime}\in\{0,\pm 1\}^{n^{\varepsilon}\times n^{\varepsilon}}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ { 0 , ± 1 } start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT end_POSTSUPERSCRIPTWd⁢i⁢l⁢u⁢t⁢esubscript𝑊𝑑𝑖𝑙𝑢𝑡𝑒W_{{dilute}}italic_W start_POSTSUBSCRIPT italic_d italic_i italic_l italic_u italic_t italic_e end_POSTSUBSCRIPT)|\bigg{)}\Bigg{|}) | Figure 1: In Theorem 1.1, we extract the coefficient of the polynomial |Per⁡(R+t⁢Wd⁢i⁢l⁢u⁢t⁢e)|,Per𝑅𝑡subscript𝑊𝑑𝑖𝑙𝑢𝑡𝑒|\operatorname{Per}(R+tW_{dilute})|,| roman_Per ( italic_R + italic_t italic_W start_POSTSUBSCRIPT italic_d italic_i italic_l italic_u italic_t italic_e end_POSTSUBSCRIPT ) | , where R𝑅Ritalic_R is a matrix of standard normals and Wd⁢i⁢l⁢u⁢t⁢esubscript𝑊𝑑𝑖𝑙𝑢𝑡𝑒W_{dilute}italic_W start_POSTSUBSCRIPT italic_d italic_i italic_l italic_u italic_t italic_e end_POSTSUBSCRIPT has a worst-case matrix in its upper left block of size nε×nεsuperscript𝑛𝜀superscript𝑛𝜀n^{\varepsilon}\times n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT for any constant ε>0,𝜀0\varepsilon>0,italic_ε > 0 , with all other matrix entries being 0. The top coefficient of this polynomial is |Per⁡W′|⁢|Per⁡RD|,Persuperscript𝑊′Persubscript𝑅𝐷\left|\operatorname{Per}W^{\prime}||\operatorname{Per}R_{D}\right|,| roman_Per italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | | roman_Per italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT | , where RDsubscript𝑅𝐷R_{D}italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT is the complementary minor to W′.superscript𝑊′W^{\prime}.italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT . With this insight in hand, we can now give a new worst-to-average-case reduction for the permanent based on coefficient extraction: to compute |Per⁡(W′)|2superscriptPersuperscript𝑊′2|\operatorname{Per}(W^{\prime})|^{2}| roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for some worst-case matrix W′∈{0,±1}nε×nεsuperscript𝑊′superscript0plus-or-minus1superscript𝑛𝜀superscript𝑛𝜀W^{\prime}\in\{0,\pm 1\}^{n^{\varepsilon}\times n^{\varepsilon}}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ { 0 , ± 1 } start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT, pick many small values of t𝑡titalic_t (t=O⁢(1/nε)𝑡𝑂1superscript𝑛𝜀t=O(1/n^{\varepsilon})italic_t = italic_O ( 1 / italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ) suffices by prior arguments) and compute |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT using our average-case algorithm. Then ask the 𝖭𝖯𝖭𝖯{\mathsf{NP}}sansserif_NP oracle to give us a polynomial of degree 2⁢nε2superscript𝑛𝜀2n^{\varepsilon}2 italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT which approximately matches these values. Now look at the top coefficient of that polynomial, and divide by the value of |Per⁡(RD)|2superscriptPersubscript𝑅𝐷2|\operatorname{Per}(R_{D})|^{2}| roman_Per ( italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. Crucially, we can estimate the value of |Per⁡(RD)|2superscriptPersubscript𝑅𝐷2|\operatorname{Per}(R_{D})|^{2}| roman_Per ( italic_R start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT to small multiplicative error, as this is another average-case instance. As multiplicative error only adds under division, this now gives us a multiplicative estimate for |Per⁡(W′)|2superscriptPersuperscript𝑊′2|\operatorname{Per}(W^{\prime})|^{2}| roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. In other words, our algorithm translates relative error in the average case to relative error in the worst case. We show that the overall robustness of this algorithm is merely O⁢(nδ)𝑂superscript𝑛𝛿O(n^{\delta})italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ) far in the exponent from showing quantum advantage, for any δ>0𝛿0\delta>0italic_δ > 0 (Theorem 1.1). The key point is that our polynomial coefficient extraction step now merely depends on a polynomial of degree 2⁢nε2superscript𝑛𝜀2n^{\varepsilon}2 italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT rather than 2⁢n2𝑛2n2 italic_n, and as such its ill-conditionedness is exponentially improved. Moreover, we have crossed the Jerrum-Sinclair-Vigoda barrier for BosonSampling, as this proof requires that a multiplicative estimate to |Per⁡(W′)|2superscriptPersuperscript𝑊′2|\operatorname{Per}(W^{\prime})|^{2}| roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT remains #⁢𝖯#𝖯\#\mathsf{P}# sansserif_P-hard, which only holds for matrices with both positive and negative entries. In other words, this reduction fundamentally uses the “quantum” nature of the problem—namely the GapP-completeness of computing its output probabilities—which is at the core of the conjectured approximation resistance of average-case permanents. The corollary for RCS follows by a similar dilution argument—one simply picks a worst case random circuit which is a concatenation of an nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT qubit worst case instance with an n−nε𝑛superscript𝑛𝜀n-n^{\varepsilon}italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT-sized random instance, and applies prior worst-to-average-case reductions [Mov23, BFLL22, KMM22]. See Appendix B for details. 1.2.2 Making exponential gains against robustness loss via squared polynomials While this first result exponentially improves on prior work, it is natural to ask how much closer we are to proving the GPE conjecture, or more generally to establishing hardness of sampling. The above results are obtained by diluting the worst case instance size so that the extrapolation/coefficient extraction blowup is lessened. However, the amount of extrapolation blowup relative to the worst case instance size has not improved. At a deeper level, despite crossing all the barriers, the proof so far still doesn’t have any hope of showing hardness of sampling from Stockmeyer counting. This is because Stockmeyer counting gives 𝖡𝖯𝖯𝖭𝖯superscript𝖡𝖯𝖯𝖭𝖯{\mathsf{BPP}}^{\mathsf{NP}}sansserif_BPP start_POSTSUPERSCRIPT sansserif_NP end_POSTSUPERSCRIPT algorithm for approximating these squared permanents to inverse poly multiplicative error, but the worst-to-average-case reduction then blows up this error exponentially. There is no compensating factor in the reduction to “fight against” this exponential loss. In our next set of results, we extend the coefficient extraction technique to obtain a new worst-to-average-case reduction for the permanent that contains a term—in particular a worst to average-case value ratio—which fights against the extrapolation loss, and which can be pumped to be an exponentially large value. Thus the status of GPE hinges on tug of war between two competing exponential factors. Interestingly, this result will only hold for orthogonal BosonSampling, and the extension to complex unitary interferometers appears to be related to open problems in complex analysis (see Sec. 1.3). To do this, it is helpful to take a step back to examine what happens with dense worst case matrices with our new coefficient extraction approach. We apply two new modifications to coefficient extraction which improve the robustness of the dense case from e−4⁢n⁢log⁡n−O⁢(n)superscript𝑒4𝑛𝑛𝑂𝑛e^{-4n\log n-O(n)}italic_e start_POSTSUPERSCRIPT - 4 italic_n roman_log italic_n - italic_O ( italic_n ) end_POSTSUPERSCRIPT [Kro23] to e−1.5⁢n⁢log⁡n−O⁢(n)superscript𝑒1.5𝑛𝑛𝑂𝑛e^{-1.5n\log n-O(n)}italic_e start_POSTSUPERSCRIPT - 1.5 italic_n roman_log italic_n - italic_O ( italic_n ) end_POSTSUPERSCRIPT. While these modifications appear simple at first glance, we will see they introduce a term which we can use to combat extrapolation loss. This dense result may at first look like a step backwards, but we will late show this result is strong enough to imply a nontrivial hardness of sampling result. The first idea to improve robustness in the dense case is to simply use the fact that |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is the square of a polynomial to reduce the degree of coefficient extraction. Suppose our worst-case matrix W𝑊Witalic_W is dense and define A⁢(t):-R+t⁢W:-𝐴𝑡𝑅𝑡𝑊A(t)\coloneq R+tWitalic_A ( italic_t ) :- italic_R + italic_t italic_W as before. While |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is a degree 2⁢n2𝑛2n2 italic_n polynomial, trivially we have that |Per⁡(A⁢(t))|2=p⁢(t)2superscriptPer𝐴𝑡2𝑝superscript𝑡2|\operatorname{Per}(A(t))|^{2}=p(t)^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for some degree-n𝑛nitalic_n polynomial p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ). In our reduction, after (approximately) computing p⁢(t)2𝑝superscript𝑡2p(t)^{2}italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT at many values of t𝑡titalic_t using our average-case algorithm, we can ask the 𝖭𝖯𝖭𝖯{\mathsf{NP}}sansserif_NP oracle to give us the underlying degree n𝑛nitalic_n polynomial p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) which squares to the correct value (up to the error tolerance in the average case computation). For real-value matrices, p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) is real, so is uniquely defined up to a sign which we can resolve later in the proof. Again the highest coefficient of this polynomial (now the coefficient of tnsuperscript𝑡𝑛t^{n}italic_t start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT) contains the value of Per⁡(W)Per𝑊\operatorname{Per}(W)roman_Per ( italic_W ) that we wish to compute. One might a priori guess this simple change merely reduces the degree of extrapolation from 2⁢n2𝑛2n2 italic_n to n𝑛nitalic_n. Surprisingly, it has more benefit than that! In particular, suppose our average-case algorithm computes p⁢(t)2𝑝superscript𝑡2p(t)^{2}italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT to additive error ±γplus-or-minus𝛾\pm\gamma± italic_γ at the points t𝑡titalic_t near 00. How much error is induced on p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) itself? It turns out, p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) is estimated to less error than γ𝛾\gammaitalic_γ. Suppose our 𝖭𝖯𝖭𝖯{\mathsf{NP}}sansserif_NP oracle gives us a polynomial p~⁢(t)=p⁢(t)+e⁢(t)~𝑝𝑡𝑝𝑡𝑒𝑡\tilde{p}(t)=p(t)+e(t)over~ start_ARG italic_p end_ARG ( italic_t ) = italic_p ( italic_t ) + italic_e ( italic_t ) where e⁢(t)𝑒𝑡e(t)italic_e ( italic_t ) is some error polynomial. Then trivially we have p⁢(t)2±γ=(p⁢(t)+e⁢(t))2=p⁢(t)2+2⁢p⁢(t)⁢e⁢(t)+e⁢(t)2plus-or-minus𝑝superscript𝑡2𝛾superscript𝑝𝑡𝑒𝑡2𝑝superscript𝑡22𝑝𝑡𝑒𝑡𝑒superscript𝑡2p(t)^{2}\pm\gamma=(p(t)+e(t))^{2}=p(t)^{2}+2p(t)e(t)+e(t)^{2}italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ± italic_γ = ( italic_p ( italic_t ) + italic_e ( italic_t ) ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 2 italic_p ( italic_t ) italic_e ( italic_t ) + italic_e ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT As our error are vanishingly small in relative terms, the cross error term dominates, and we see that trivially |e⁢(t)|≤γp⁢(t)𝑒𝑡𝛾𝑝𝑡|e(t)|\leq\frac{\gamma}{p(t)}| italic_e ( italic_t ) | ≤ divide start_ARG italic_γ end_ARG start_ARG italic_p ( italic_t ) end_ARG at points t𝑡titalic_t near 00. In other words, we get to divide our error by the average-case value of the permanent, before we propagate the error through coefficient extraction. By assuming the Permanent Anticoncentration Conjecture 2.3, this value is n!𝑛\sqrt{n!}square-root start_ARG italic_n ! end_ARG so saves us an additional 0.5⁢n⁢log⁡n0.5𝑛𝑛0.5n\log n0.5 italic_n roman_log italic_n in the exponent beyond what we might have otherwise expected to gain in additive terms. This observation gets more interesting if we view it in relative terms. This correction factor can be seen as ensuring the relative error on p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) is the same (up to a constant factor of 2) as the relative error on p⁢(t)2𝑝superscript𝑡2p(t)^{2}italic_p ( italic_t ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, as relative error is preserved (up to constants) under taking powers. An observation is that this degree reduction via the square of a polynomial kept our error constant in relative terms on our underlying polynomial. On the other hand, polynomial coefficient extraction is naturally sensitive to error in additive terms. Our second observation is that we can use this mismatch to reduce the extrapolation error in relative terms, by an exponential amount. The basic idea is to now consider a worst case matrix with two components: first, a smaller and possibly negative-entry matrix W′superscript𝑊′W^{\prime}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT in the upper left hand corner of size nεsuperscript𝑛𝜀n^{\varepsilon}italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT, in direct sum with a larger matrix of all 1111’s of dimension n−nε𝑛superscript𝑛𝜀n-n^{\varepsilon}italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT (see Figure 2). |Per(\Bigg{|}\operatorname{Per}\bigg{(}| roman_Per (R∼𝒩⁢(0,1)n×nsimilar-to𝑅𝒩superscript01𝑛𝑛R\sim{\mathcal{N}}(0,1)^{n\times n}italic_R ∼ caligraphic_N ( 0 , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT+++t𝑡titalic_t0000 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 W′∈{0,±1}nε×nεsuperscript𝑊′superscript0plus-or-minus1superscript𝑛𝜀superscript𝑛𝜀W^{\prime}\in\{0,\pm 1\}^{n^{\varepsilon}\times n^{\varepsilon}}italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ { 0 , ± 1 } start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT end_POSTSUPERSCRIPTW𝑊Witalic_W)|\bigg{)}\Bigg{|}) | Figure 2: Polynomial |Per⁡(R+t⁢W)|,Per𝑅𝑡𝑊|\operatorname{Per}(R+tW)|,| roman_Per ( italic_R + italic_t italic_W ) | , whose top coefficient is |Per⁡W′|⁢(n−nε)!.Persuperscript𝑊′𝑛superscript𝑛𝜀|\operatorname{Per}W^{\prime}|(n-n^{\varepsilon})!.| roman_Per italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | ( italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ) ! . This is the ensemble under consideration in Thm. 4.5 where we coefficient-extract the unsquared permanent via the square method and use worst-case amplification by padding W𝑊Witalic_W with a matrix of 1111s. Interestingly, including this large-permanent sub matrix in our worst case actually improves our robustness in the worst-to-average-case reduction! This is because for this scheme, the top coefficient of the polynomial p⁢(t)=Per⁡(A⁢(t))𝑝𝑡Per𝐴𝑡p(t)=\operatorname{Per}(A(t))italic_p ( italic_t ) = roman_Per ( italic_A ( italic_t ) ) is equal to Per⁡(W′)⁢(n−nε)!Persuperscript𝑊′𝑛superscript𝑛𝜀\operatorname{Per}(W^{\prime})(n-n^{\varepsilon})!roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ( italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ) !, where this large multiplicative term is coming from the value of the permanent of the bottom right hand submatrix. Therefore, to obtain an constant multiplicative error estimate to Per⁡(W′)Persuperscript𝑊′\operatorname{Per}(W^{\prime})roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ), it suffices to estimate this top coefficient to additive error O⁢(Per⁡(W′)⁢(n−nε)!)𝑂Persuperscript𝑊′𝑛superscript𝑛𝜀O(\operatorname{Per}(W^{\prime})(n-n^{\varepsilon})!)italic_O ( roman_Per ( italic_W start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ( italic_n - italic_n start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ) ! ) In other words, the fact that this permanent of the all 1111s submatrix is big allows for more error tolerance in the reduction, overall improving the robustness. We show this trick can be generalized to the more general formula: See 1.3 In particular this worst-to-average-case reduction now has an exponential term—namely the value of this worst case permanent divided by the average case—fighting against the exponential loss of polynomial coefficient extraction. For BosonSampling, this ratio is roughly n!/n!=e0.5⁢n⁢log⁡n𝑛𝑛superscript𝑒0.5𝑛𝑛n!/\sqrt{n!}=e^{0.5n\log n}italic_n ! / square-root start_ARG italic_n ! end_ARG = italic_e start_POSTSUPERSCRIPT 0.5 italic_n roman_log italic_n end_POSTSUPERSCRIPT which fights against a coefficient extraction loss of en⁢log⁡nsuperscript𝑒𝑛𝑛e^{n\log n}italic_e start_POSTSUPERSCRIPT italic_n roman_log italic_n end_POSTSUPERSCRIPT, resulting in a net relative error of e−0.5⁢n⁢log⁡nsuperscript𝑒0.5𝑛𝑛e^{-0.5n\log n}italic_e start_POSTSUPERSCRIPT - 0.5 italic_n roman_log italic_n end_POSTSUPERSCRIPT needed in the average case to show hardness of sampling. To show hardness of sampling in the average case, this means we “merely” need to reduce the exponential loss of coefficient extraction to a weaker exponential, or increase the value of the worst-case matrix (now all 1111s) by an exponential factor. This is not an easy problem—these terms are interrelated, so say simply boosting the norm of the all 1111s matrix simultaneously improves the worst to average-case ratio and worsens the coefficient extraction loss, and does not show hardness of sampling. However, we now finally have a term fighting against coefficient extraction loss. We note a similar lemma can be shown for RCS as well—in particular for a real version of RCS with random orthogonal gates (see Section 3.3)—but does not yield any hardness of sampling results (see Discussion 1.3). 1.2.3 Extending our results to average-case sampling In the last part of our work, we apply this new worst-to-average-case reduction to obtain the first nontrivial hardness of average-case sampling for BosonSampling. This uses techniques specific to BosonSampling, which to the best of our knowledge do not carry over to other quantum advantage schemes. To show this, we consider our new worst-to-average-case reduction, whose relative error robustness is given by Lemma 1.3. To show an average-case hardness of sampling result via Stockmeyer, we need our relative error tolerance for #⁢𝖯#𝖯\#\mathsf{P}# sansserif_P-hardness to be inverse polynomial. Our compensating ratio of the worst to average-case is e0.5⁢n⁢log⁡nsuperscript𝑒0.5𝑛𝑛e^{0.5n\log n}italic_e start_POSTSUPERSCRIPT 0.5 italic_n roman_log italic_n end_POSTSUPERSCRIPT, so we can only afford a loss of e0.5⁢n⁢log⁡nsuperscript𝑒0.5𝑛𝑛e^{0.5n\log n}italic_e start_POSTSUPERSCRIPT 0.5 italic_n roman_log italic_n end_POSTSUPERSCRIPT from coefficient extraction. Unfortunately this is not enough of a loss budget to be able to do a standard worst-to-average-case reduction. This is because in these reductions, we compute values of |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for values of t𝑡titalic_t which are small enough so that A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) is distributed close in total variation distance to Gaussian, to ensure our average-case algorithm correctly computes A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) with high probability. To ensure closeness of total variation distance to constant error, t𝑡titalic_t must be O⁢(1/n)𝑂1𝑛O(1/n)italic_O ( 1 / italic_n )—this calculation (due to Krovi [Kro23]) is optimal. This sets the distance of extrapolation/coefficient extraction to be at least Δ=O⁢(n)Δ𝑂𝑛\Delta=O(n)roman_Δ = italic_O ( italic_n ), yielding a blowup of nn∼en⁢log⁡nsimilar-tosuperscript𝑛𝑛superscript𝑒𝑛𝑛~{}n^{n}\sim e^{n\log n}italic_n start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ∼ italic_e start_POSTSUPERSCRIPT italic_n roman_log italic_n end_POSTSUPERSCRIPT. There is no hope of closing this gap with a standard total variation distance approach. To get around this issue, our key idea is to go out of distribution. That is, what if we query points A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) which are far from Gaussian distributed? Clearly if our average-case algorithm could successfully compute the permanent of these matrices, then this would improve our robustness, as it would allow us to query points at much larger values of t𝑡titalic_t, and hence reduce our error blowup. For example, if we could successfully compute |Per⁡(A⁢(t))|2superscriptPer𝐴𝑡2|\operatorname{Per}(A(t))|^{2}| roman_Per ( italic_A ( italic_t ) ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for points t=O⁢(1/n)𝑡𝑂1𝑛t=O(1/\sqrt{n})italic_t = italic_O ( 1 / square-root start_ARG italic_n end_ARG ), our coefficient extraction loss would be halved in the exponent, and we could show hardness of average-case sampling! However, the issue is these matrices A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) at large values of t𝑡titalic_t are far in total variation distance from Gaussian, so there is no trivial guarantee our algorithm works here. In fact total variation distance arguments are useless here; the TV distance between A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) and Gaussian is of the form 1−δ1𝛿1-\delta1 - italic_δ for a small value of δ𝛿\deltaitalic_δ. Even if we assume our average-case algorithm works perfectly, a TV distance argument would only say it must work with probability at least δ𝛿\deltaitalic_δ on these points. This is insufficient for our polynomial coefficient extraction techniques. t𝑡titalic_t Figure 3: Lemma 4.3 shows that a function that computes permanents of 𝒩⁢(0,1)n×n𝒩superscript01𝑛𝑛{\mathcal{N}}(0,1)^{n\times n}caligraphic_N ( 0 , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT matrices with 1−exp⁡(−O⁢(n))1𝑂𝑛1-\exp(-O(n))1 - roman_exp ( - italic_O ( italic_n ) ) probability also computes permanents of 𝒩⁢(t,1)n×n𝒩superscript𝑡1𝑛𝑛{\mathcal{N}}(t,1)^{n\times n}caligraphic_N ( italic_t , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT matrices with 1−1/poly⁢(n)11poly𝑛1-1/{\mathrm{poly}}(n)1 - 1 / roman_poly ( italic_n ) probability for t=O⁢(1/n)𝑡𝑂1𝑛t=O(1/\sqrt{n})italic_t = italic_O ( 1 / square-root start_ARG italic_n end_ARG ). That is, an algorithm that works very often over a Gaussian distribution will also work reasonably often on a shifted Gaussian distribution. The figure depicts that events deep in the tail of one Gaussian are still tail events for a shifted Gaussian, with successful events colored blue and failure events colored orange. Instead, in our proof we go beyond total variation distance analysis to show that we can successfully query points A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) at high values of t𝑡titalic_t, so long as our average-case algorithm works with very high probability. The basic idea is this: suppose our average-case algorithm works near perfectly, say with probability 1−δ1𝛿1-\delta1 - italic_δ over the choice of Gaussian matrix. We want to show it also works if we query it on these points A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) which are far from Gaussian. A basic observation is that these A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) are also Gaussian distributed, but with a shifted mean. We prove a simple lemma, Lemma 4.3, showing that rare events under one Gaussian distribution remain rare under another Gaussian, so long as their rarity is less than e−d2superscript𝑒superscript𝑑2e^{-d^{2}}italic_e start_POSTSUPERSCRIPT - italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT where d𝑑ditalic_d is the distance between the means. Intuitively this is because if an event is extremely far from the mean of a Gaussian G1subscript𝐺1G_{1}italic_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (much further than the distance to the mean of G2subscript𝐺2G_{2}italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT) it is also far from the mean of G2subscript𝐺2G_{2}italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT as well, and hence rare under G2subscript𝐺2G_{2}italic_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (see Figure 3). We then apply this lemma to the event that the average-case algorithm fails under the standard Gaussian. If this is sufficiently rare for the average case, this is also rare for the distribution of A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ), and hence the algorithm works with high probability to compute A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) as well. There is a loss in this argument which forces δ𝛿\deltaitalic_δ to be exponentially small. However, the key point is that if our average-case algorithm works with extremely high probability, then it can also evaluate these points A⁢(t)𝐴𝑡A(t)italic_A ( italic_t ) at high values of t𝑡titalic_t, and hence lessen the coefficient extraction error in our reduction. We show this can be leveraged to show a nontrivial hardness of sampling result for an exact (i.e. relative error) average-case sampler. The proof follows the argument outlined above but requires several additional technical innovations. First, if you assume you have an average-case sampler that works with very high probability 1−δ1𝛿1-\delta1 - italic_δ over the choice of BosonSampling experiment, this doesn’t immediately imply (by Stockmeyer counting) a 𝖡𝖯𝖯𝖭𝖯superscript𝖡𝖯𝖯𝖭𝖯{\mathsf{BPP}}^{\mathsf{NP}}sansserif_BPP start_POSTSUPERSCRIPT sansserif_NP end_POSTSUPERSCRIPT algorithm for computing Gaussian permanents with probability 1−δ1𝛿1-\delta1 - italic_δ. The issue is that submatrices of Haar random orthogonal matrices have not been shown to be exponentially close to Gaussian in TV distance, but rather have only been shown to be inverse polynomially close [JM19]. Thus setting the sampler success probability to 1−δ1𝛿1-\delta1 - italic_δ where δ=2−O⁢(n)𝛿superscript2𝑂𝑛\delta=2^{-O(n)}italic_δ = 2 start_POSTSUPERSCRIPT - italic_O ( italic_n ) end_POSTSUPERSCRIPT for the sampler success does not automatically yield a correspondingly good algorithm for computing Gaussian permanents. To fix this we prove yet another “rare events lemma,” Proposition C.1, that allows us to transfer our high probability algorithm for Haar submatrices to Gaussian matrices, which may be of independent interest. Second, for our algorithm to work we require Per⁡(A⁢(t))Per𝐴𝑡\operatorname{Per}(A(t))roman_Per ( italic_A ( italic_t ) ) to anticoncentrate. This is not guaranteed by the standard Permanent Anticoncentration Conjecture 2.3 as these matrices are out of distribution. We instead formulate a more general permanent anticoncentration conjecture which conjectures that general shifted mean Gaussian permanents anticoncentrate: Conjecture 1.5 (Anticoncentration of gently perturbed Gaussian permanents). There exists a polynomial f𝑓fitalic_f such that for all n𝑛nitalic_n and ϵ>0,italic-ϵ0\epsilon>0,italic_ϵ > 0 , 𝐏R∼𝒩⁢(0,1)n×n⁢[|Per⁡(R+t⁢W)|<n!f⁢(n,1/ϵ)]<ϵ,subscript𝐏similar-to𝑅𝒩superscript01𝑛𝑛delimited-[]Per𝑅𝑡𝑊𝑛𝑓𝑛1italic-ϵitalic-ϵ{\mathbf{P}}_{R\sim{\mathcal{N}}(0,1)^{n\times n}}\left[\left|\operatorname{% Per}(R+tW)\right|<\frac{\sqrt{n!}}{f(n,1/\epsilon)}\right]<\epsilon,bold_P start_POSTSUBSCRIPT italic_R ∼ caligraphic_N ( 0 , 1 ) start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ | roman_Per ( italic_R + italic_t italic_W ) | < divide start_ARG square-root start_ARG italic_n ! end_ARG end_ARG start_ARG italic_f ( italic_n , 1 / italic_ϵ ) end_ARG ] < italic_ϵ , for arbitrary matrix W𝑊Witalic_W with entries bounded by 1111 and t=O⁢(1n).𝑡𝑂1𝑛t=O(\frac{1}{\sqrt{n}}).italic_t = italic_O ( divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_n end_ARG end_ARG ) . We note a special case of this conjecture has already been proven by Eldar and Mehraban [EM18] for 𝒩⁢(1/poly⁢log⁡n,1)𝒩1poly𝑛1{\mathcal{N}}(1/{\mathrm{poly}}\log n,1)caligraphic_N ( 1 / roman_poly roman_log italic_n , 1 ) matrices—and N⁢(0,1)𝑁01N(0,1)italic_N ( 0 , 1 ) matrices are the subject of standard anticoncentration—so our conjecture is in some sense interpolating between these proven statements and conjectures to matrices with entries like 𝒩⁢(1/n,1)𝒩1𝑛1{\mathcal{N}}(1/\sqrt{n},1)caligraphic_N ( 1 / square-root start_ARG italic_n end_ARG , 1 ). See Figure 4 for a schematic. 1.3 Discussion and open problems In this work we have shown the first non-trivial average-case exact sampling result for (orthogonal) BosonSampling. It is natural to ask if our techniques can be pushed further to prove the GPE conjecture and show hardness of BosonSampling in the general case. We note that further reductions in our coefficient extraction error could possibly yield intermediate results in this direction, in particular improving our average-case success probability of the sampler to be closer to 1−1/poly⁢(n)11poly𝑛1-1/{\mathrm{poly}}(n)1 - 1 / roman_poly ( italic_n ). In terms of pushing our results towards approximate average-case sampling, an important question is if our techniques relativize, as we know non-relativizing techniques will be required to show hardness of approximate sampling [AC17]. Interestingly Marshall, Aaronson and Djunko [MAD24] recently introduced new techniques that do not relativize. Of course the Permanent Anticoncentration Conjecture 2.3 remains open as well, and is assumed in our work. Another natural question is if we can show any hardness of sampling for RCS. Here the principal challenge is that the state-of-the-art of average-case hardness for RCS is substantially farther from the goal than for BosonSampling [BFNV19, Mov23, BFLL22, KMM22, Kro22]. While we show one can utilize the schemes of Lemma 1.3 for a real variant of RCS to obtain a worst to average-case ratio which fights against extrapolation loss (see Sec. 3.3), this gain is at most 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for RCS, while existing worst-to-average-case reductions have much larger robustness losses. We leave this an an open problem. We note a number of related works have studied the complexity of quantum advantage schemes under various forms of noise in the experiment, e.g. [ABOIN96, KK14, GD18, BFLL22, AGL+23, DNS+22, SYGY24, OLA+24, DHJB24, FGG+24, BBC+22, VNL+21] which can make the problems asymptotically easier in certain scenarios. In contrast our work is studying the complexity of near-noiseless variants of BosonSampling or RCS. Finally, it remains open if our proofs can be extended from real (i.e. orthogonal) BosonSampling to complex (i.e. unitary) BosonSampling. The part of our proof that breaks here is the statement that, if you have evaluations of the square of a polynomial |p⁢(t)|2superscript𝑝𝑡2|p(t)|^{2}| italic_p ( italic_t ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, that you can infer the underlying polynomial up to phase. While this is trivial in the real case (the phase is ±1plus-or-minus1\pm 1± 1, which is trivially disambiguated in the proof), in the complex case it is open if this approximately defines p⁢(t)𝑝𝑡p(t)italic_p ( italic_t ) up to a complex phase, and this appears to be an open problem in complex analysis [Her22]. In Appendix E, we explain in more detail the nature of the difficulty of extending the result to the complex setting."
https://arxiv.org/html/2411.04353v1,\adambrainstorming titlesOn the hardness of learning ground state entanglement of geometrically local Hamiltonians1D local gapless phases are classically hard to learn,"Characterizing the entanglement structure of ground states of local Hamiltonians is a fundamental problem in quantum information. In this work we study the computational complexity of this problem, given the Hamiltonian as input. Our main result is that to show it is cryptographically hard to determine if the ground state of a geometrically local, polynomially gapped Hamiltonian on qudits (d=O⁢(1)𝑑𝑂1d=O(1)italic_d = italic_O ( 1 )) has near-area law vs near-volume law entanglement. This improves prior work of Bouland et al. (arXiv:2311.12017) showing this for non-geometrically local Hamiltonians. In particular we show this problem is roughly factoring-hard in 1D, and LWE-hard in 2D. Our proof works by constructing a novel form of public-key pseudo-entanglement which is highly space-efficient, and combining this with a modification of Gottesman and Irani’s quantum Turing machine to Hamiltonian construction. Our work suggests that the problem of learning so-called “gapless” quantum phases of matter might be intractable.","Characterizing the entanglement structure of ground states of local Hamiltonians is a fundamental problem in quantum information. Many works have studied when the structure of local Hamiltonians forces the ground state to have simple entanglement structures such as an area law. For example, an area law for gapped 1D local Hamiltonians has been rigorously established [13], and much progress has been made towards a 2D area law as well e.g. [1]. This is closely connected to Hamiltonian complexity, as areas laws can enable efficient algorithms for learning and describing ground states, such as through matrix product states and PEPS, e.g. [20]. It is also closely connected to questions in condensed matter physics, where different ground state entanglement structures can be hallmarks of different quantum phases of matter, such as topological phases [27]. In this work we study the complexity of learning the ground state entanglement structure of a local Hamiltonian, given the Hamiltonian as input. This is known as the “Learning Ground State Entanglement Structure (LGSES)” problem [7]. Informally the LGSES problem captures the complexity of the job of a condensed matter physicist – as oftentimes one writes down a Hamiltonian and applies highly nontrivial techniques (Bethe ansatze, quantum Monte Carlo algorithms, etc.) to deduce properties of its low energy states. The difficulty of LGSES depends significantly on the assumptions made about the structure of the Hamiltonian. For example, if one assumes a constant spectral gap, then in many cases the area law forces the ground state to have a particularly simple structure, rendering the LGSES problem trivial. It has also recently been shown that with geometric locality and constant spectral gaps, one can efficiently learn properties of ground states, such as expectation values of local observables [14] if one is given labelled examples from members of a broader family444Their result also requires a certain smoothness condition on the Hamiltonians considered, see [14].. On the other hand, if the Hamiltonian has an inverse polynomial spectral gap, the problem can become much harder. For example, Bouland et al. [7] recently showed it is LWE-hard to learn if the ground state of a general local Hamiltonian has near 1D area law or near volume law entanglement. However, the Hamiltonians in their construction were not geometrically local, and hence not directly relevant to physics. With geometric locality, they were only able to obtain much weaker hardness results about detecting different variants of sub-volume law entanglement. A natural question is if it is hard to distinguish near area law vs. volume law entanglement in the geometrically local setting. Our results: In this work we show that LGSES is cryptographically hard even with geometrically local Hamiltonians, and even for determining if the ground state is near-area law vs. near volume law: We show this for 1D and 2D-local Hamiltonians on qudits where the local dimension d=O⁢(1)𝑑𝑂1d=O(1)italic_d = italic_O ( 1 ): Theorem 1.1 (Informal). It is hard for a classical computer to determine if a 1D local Hamiltonian on qudits has a ground state with 1D near area law vs. near volume law entanglement. Theorem 1.2 (Informal). It is hard for a quantum computer to determine if a 2D local Hamiltonian on qudits has a ground state with 2D near area law vs. near volume law entanglement. Here, near area law means that if ρ𝜌\rhoitalic_ρ is the reduced density matrix on a subset of qubits, then S⁢(ρ)≤|A|⁢polylog⁢(n)𝑆𝜌𝐴polylog𝑛S(\rho)\leq|A|\text{polylog}(n)italic_S ( italic_ρ ) ≤ | italic_A | polylog ( italic_n ) where A𝐴Aitalic_A is the area of the cut. The Hamiltonians have inverse polynomial spectral gaps. The first result is shown under the Decisional Composite Residuosity Assumption (DCRA), which is a standard classical hardness assumption based on discrete log/factoring. In particular we assume DCRA does not have a 2nϵsuperscript2superscript𝑛italic-ϵ2^{n^{\epsilon}}2 start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT italic_ϵ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT time algorithm for some value of ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0. The second result is shown assuming subexponential hardness of LWE. 1.1 Proof sketch We will describe the 1D proof, and later describe how to lift to 2D. Our proof uses on a new construction of public-key pseudo-entanglement. Here the idea is that one can construct ensembles of states for which it is difficult to estimate their entanglement, even given the description of the quantum circuit used to prepare the state. Such constructions imply hardness results for LGSES by passing the circuit ensembles through circuit to Hamiltonian constructions [11, 7]. The starting point of our work is to try to take the public-key pseudo-entanglement construction of [7] and pass them through a geometrically local circuit to Hamiltonian construction, in particular the 1D translation invariant construction of Gotteman and Irani [12]. The Gottesman-Irani construction, however, is formulated in a quantum Turing machine (QTM) model of computation, rather than the quantum circuit model. That is, give a QTM as input, it describes a Hamiltonian whose ground state on n𝑛nitalic_n qubits encodes the computation performed by that QTM on input 1nsuperscript1𝑛1^{n}1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Therefore, to apply this approach we first need to formulate a QTM variant of pseudo-entanglement, which causes several issues. First, we need to hard-code a cryptographic key into the construction. This is because the the public key enabling the preparation of the pseudo-entangled states must be provided as input to the QTM. This breaks the translation invariance of [12]. Second, it requires showing the cryptographic primitives used in [7] can be implemented in the QTM model, and not just the circuit model. Both of these changes require tedious modifications of the Gottesman-Irani construction, but are surmountable with sufficient attention to detail. However, the larger issue that we face in combining the constructions is the space complexity of our cryptographic primitives. In our setting our goal is not to show QMA-hardness of the ground state energy, but rather to show cryptographic hardness of learning the ground state entanglement. Therefore the key thing we wish to preserve in our circuit to QTM to Hamiltonian construction is the entanglement structure of the ground state. In turns out that for [12] to preserve entanglement structure, we need our pseudo-entanglement construction to run not only in polynomial time. but also in near linear space. This is because the space complexity of the QTM roughly equals the number of qudits in the chain, so a blowup say to O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) space effectively “dilutes” the entanglement in the ground state, as informally these O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ) e-bits of entanglement are then “spread out” amongst O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) qudits, meaning that states with high entanglement in the circuit are no longer highly entangled. We therefore can’t afford more than a logarithmic blowup in the space complexity of the algorithm. This is immediately a problem because the key sizes used in [7] are much larger than superlinear – the total key size is actually O⁢(n2⁢log⁡n)𝑂superscript𝑛2𝑛O(n^{2}\log n)italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n ). This key size is coming from the fact that public-key cryptographic primitives built from LWE typically have key sizes of O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) or larger – this is because the public key is usually a dense matrix A∈𝔽qn×n𝐴superscriptsubscript𝔽𝑞𝑛𝑛A\in\mathbb{F}_{q}^{n\times n}italic_A ∈ blackboard_F start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT. Therefore it seems extremely difficult to build public-key pseudo-entanglement with linear key size from LWE. There is also a second source of high space complexity in [7], coming from the use of n𝑛nitalic_n different pairwise-independent hash functions, which would itself contribute a quadratic sized key even if a different crypto primitive was slotted in place of LWE. To address this we create a new construction of pseudo-entanglement which has a much smaller public key size while still hiding a big entanglement gap. First, we relax the problem to consider only classical hardness. This enables cryptographic public-key constructions with near-linear key sizes in the input size – particularly a cryptographic object known as a lossy function [25] which allows one to “hash down” entanglement across a particular cut of the qubits [7]. This alone isn’t enough to fix the problem, because the prior construction had O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ) independent cryptographic keys plus O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ) hash function keys. This arises because the prior construction did a 1D “sweep” of the line, using lossy functions to “tamp down” entanglement across each cut of the line in the corresponding binary phase state. To fix this, we make a new construction which tamps down entanglement in a tree-like structure. First we cut down entanglement across the middle cut between the left n/2𝑛2n/2italic_n / 2 and right n/2𝑛2n/2italic_n / 2 qubits; then we cut down across the next cuts of size n/4𝑛4n/4italic_n / 4, etc. (see Figure 1). This still involves O⁢(n⁢log⁡n)𝑂𝑛𝑛O(n\log n)italic_O ( italic_n roman_log italic_n ) applications of lossy functions, so naively would not reduce the key size. The crucial insight is that, first, the keys can be the same across each level of the tree, and second, the key size at each level can be a decreasing function of n𝑛nitalic_n (as the security parameter coming from algorithmic tests of entanglement also shrinks with n𝑛nitalic_n). This allows us to obtain a total key size of O⁢(n⁢log⁡n)𝑂𝑛𝑛O(n\log n)italic_O ( italic_n roman_log italic_n ) across all of these lossy functions. Showing this works requires developing a new proof that tamping down entanglement across one cut doesn’t “blow up” your entanglement across another, which in [7] had followed from a simple property of 1D sweeps. It also requires further changes to the construction, as the classical lossy functions actually blow up the input size slightly, but crucially this blowup is tiny in the low-deoth tree, so does not result in much “dilution” of the entanglement. This allows us to remove the pairwise-independent hash functions used in prior work, which had served to avoid this blowup in input size. To lift this to 2D with LWE, to show that here the quadratic blowup in key size is acceptable – we use a larger key, and then make a ground state which is a superposition of the 1D states striped horizontally vs vertically. 1.2 Discussion and open problems Our work is the first to show it can be hard to learn the ground state entanglement structure of geometrically local Hamiltonians, even promised near-maximal gaps in entanglement structure. A number of open problems remain. First, can we show hardness of LGSES for translationally invariant Hamiltonians? Such a result would parallel the development QMA-hardness in Hamiltonian complexity [16, 22, 3, 12]. However, we believe this would require developing fundamentally new techniques. This is because in 1D translation-invariant constructions, the QTMs are not allowed to have a binary input – rather their input is written in unary, which allows one to show QMAEXPsubscriptQMAEXP\textsf{QMA}_{\textsf{EXP}}QMA start_POSTSUBSCRIPT EXP end_POSTSUBSCRIPT hardness. While a QTM can generate an instance of our public-key pseudo-entanglement from 1nsuperscript1𝑛1^{n}1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the algorithm will generate not only the public key (i.e. the description of how to prepare the state), but also the private key which allows one to distinguish the two ensembles. In our work, the ground state can be efficiently constructed from the Hamiltonian, so this means one can efficiently extract the private key from the ground state, breaking the security. As a result, one needs to go beyond pseudo-entanglement + circuit/QTM to Hamiltonian constructions if one wishes to show hardness of translationally invariant systems. In a similar spirit, there is the also the question of if we can reduce our local dimension, which has been done in the case of QMA, e.g. [15, 5], and if we can show the 1D case is hard based on post-quantum cryptography as well. Second, there is a question about how to interpret our result through the lens of condensed matter theory. As different entanglement structures can be hallmarks of different quantum phases of matter, our results could be interpreted as a statement about hardness of learning phases of matter. Our results are shown with inverse polynomial spectral gaps, so could be saying that it is hard to learn “gapless” phases of matter (where gap vanishes as system size grows), which stands in contrast to gapped phases which might be easier to learn [14]. Our result also complements recent work of Schuster Haferkamp and Huang [28], a corollary of which was that it can be hard to learn topological phases of matter. However we note our result is proven in a stronger public-key input model, as our input includes the recipe for preparing the state, whereas their corollary is in a private-key input model where one is only given copies of the state itself. 1.3 Outline of the paper We introduce the notations and relevant existing results in Section 2. In Section 3, we present two lossy function constructions based on DCRA and LWE respectively, which we use in Section 4 give two public-key pseudoentangled states constructions. The quantum Turing machines for these two constructions are given in Section 5. In Section 6, we present a general framework of encoding the running history of a QTM into a local Hamiltonian. Finally in Section 7, we combine all these techniques together and prove the hardness of LGSES for both 1D Hamiltonians and 2D Hamiltonians."
https://arxiv.org/html/2411.04115v1,Condensing Against Online Adversaries,"We investigate the task of deterministically condensing randomness from Online Non-Oblivious Symbol Fixing (oNOSF) sources, a natural model of defective random sources for which it is known that extraction is impossible [AORSV, EUROCRYPT’20]. A (g,ℓ)𝑔ℓ(g,\ell)( italic_g , roman_ℓ )-oNOSF source is a sequence of ℓℓ\ellroman_ℓ blocks 𝐗=(𝐗1,…,𝐗ℓ)∼({0,1}n)ℓ𝐗subscript𝐗1…subscript𝐗ℓsimilar-tosuperscriptsuperscript01𝑛ℓ\mathbf{X}=(\mathbf{X}_{1},\dots,\mathbf{X}_{\ell})\sim(\{0,1\}^{n})^{\ell}bold_X = ( bold_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_X start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) ∼ ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT, where at least g𝑔gitalic_g of the blocks are good (are independent and have some min-entropy), and the remaining bad blocks are controlled by an online adversary where each bad block can be arbitrarily correlated with any block that appears before it.The existence of condensers was recently studied in [CGR, FOCS’24]. They proved condensing impossibility results for various values of g𝑔gitalic_g and ℓℓ\ellroman_ℓ, and they showed the existence of condensers matching the impossibility results in the special case when n𝑛nitalic_n is extremely large compared to ℓℓ\ellroman_ℓ (i.e., the setting of few blocks of large length).In this work, we make significant progress on proving the existence of condensers with strong parameters in almost all parameter regimes, even when n𝑛nitalic_n is a large enough constant and ℓℓ\ellroman_ℓ is growing. This almost resolves the question of the existence of condensers for oNOSF sources, except when n𝑛nitalic_n is a small constant.As our next result, we construct the first explicit condensers for oNOSF sources and achieve parameters that match the existential results of [CGR, FOCS’24]. We also obtain a much improved construction for transforming low-entropy oNOSF sources (where the good blocks only have min-entropy, as opposed to being uniform) into uniform oNOSF sources.We find interesting connections and applications of our results on condensers to collective coin flipping and collective sampling, problems that are well-studied in fault-tolerant distributed computing. We use our condensers to provide very simple protocols for these problems.Finally, to understand the case of small n𝑛nitalic_n, we focus on n=1𝑛1n=1italic_n = 1 which corresponds to online non-oblivious bit-fixing (oNOBF) sources. We introduce and initiate a systematic study of a new, natural notion of the influence of Boolean functions, which we call online influence, and believe is of independent interest. Using tools from Boolean Fourier analysis, we establish tight bounds on the total online influence of Boolean functions, which imply extraction lower bounds. Several problems remain open regarding this new measure of influence; progress on these will lead to improved extractors and condensers for oNOBF sources or further strengthen our lower bounds.","Randomness is extremely useful in computation with wide-ranging applications in algorithm design, cryptography, distributed computing protocols, machine learning, error-correcting codes, and much more [motwani1995randomized, vadhan_pseudorandomness_2012]. Most of these applications require access to high quality randomness. However in a lot of settings, especially arising in practice, algorithms only have access to low quality source of randomness. This motivates the notion of condensers: functions that transform weak random sources into strong random sources that are of better quality. In this line of work, the standard way of measuring the amount of randomness is using min-entropy. Formally, for a source (distribution) 𝐗𝐗\mathbf{X}bold_X with support ΩΩ\Omegaroman_Ω, define its min-entropy as H∞⁢(𝐗)=minx∈Ω⁡log2⁡(1/Pr⁡[𝐗=x])subscript𝐻𝐗subscript𝑥Ωsubscript21Pr𝐗𝑥H_{\infty}(\mathbf{X})=\min_{x\in\Omega}\log_{2}(1/\Pr[\mathbf{X}=x])italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ( bold_X ) = roman_min start_POSTSUBSCRIPT italic_x ∈ roman_Ω end_POSTSUBSCRIPT roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 / roman_Pr [ bold_X = italic_x ] ). We will also need the notion of smooth min-entropy, which measures how close a distribution is to having high entropy. Formally, for a source 𝐗𝐗\mathbf{X}bold_X, its smooth min-entropy with parameter ε𝜀\varepsilonitalic_ε is defined as H∞ε⁢(𝐗)=max𝐘:|𝐗−𝐘|≤ε⁡{H∞⁢(𝐘)}superscriptsubscript𝐻𝜀𝐗subscript:𝐘𝐗𝐘𝜀subscript𝐻𝐘H_{\infty}^{\varepsilon}(\mathbf{X})=\max_{\mathbf{Y}:\left\lvert\mathbf{X}-% \mathbf{Y}\right\rvert\leq\varepsilon}\{H_{\infty}(\mathbf{Y})\}italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( bold_X ) = roman_max start_POSTSUBSCRIPT bold_Y : | bold_X - bold_Y | ≤ italic_ε end_POSTSUBSCRIPT { italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ( bold_Y ) }, where |⋅|⋅\left\lvert\cdot\right\rvert| ⋅ | denotes the statistical distance (Definition 3.1). With this, we are ready to formally define condensers: Definition 1.1. A function 𝖢𝗈𝗇𝖽:{0,1}n→{0,1}m:𝖢𝗈𝗇𝖽→superscript01𝑛superscript01𝑚\mathsf{Cond}:\{0,1\}^{n}\to\{0,1\}^{m}sansserif_Cond : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT is a (ki⁢n,ko⁢u⁢t,ε)subscript𝑘𝑖𝑛subscript𝑘𝑜𝑢𝑡𝜀(k_{in},k_{out},\varepsilon)( italic_k start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT , italic_k start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT , italic_ε )-condenser for a family of distributions 𝒳𝒳\mathcal{X}caligraphic_X if for all 𝐗∈𝒳𝐗𝒳\mathbf{X}\in\mathcal{X}bold_X ∈ caligraphic_X with 𝐗∼{0,1}nsimilar-to𝐗superscript01𝑛\mathbf{X}\sim\{0,1\}^{n}bold_X ∼ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and H∞⁢(𝐗)≥ki⁢nsubscript𝐻𝐗subscript𝑘𝑖𝑛H_{\infty}(\mathbf{X})\geq k_{in}italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ( bold_X ) ≥ italic_k start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT, we have that H∞ε⁢(𝐗)≥ko⁢u⁢tsuperscriptsubscript𝐻𝜀𝐗subscript𝑘𝑜𝑢𝑡H_{\infty}^{\varepsilon}(\mathbf{X})\geq k_{out}italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( bold_X ) ≥ italic_k start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT. We say ki⁢nnsubscript𝑘𝑖𝑛𝑛\frac{k_{in}}{n}divide start_ARG italic_k start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT end_ARG start_ARG italic_n end_ARG is the input entropy rate, ko⁢u⁢tmsubscript𝑘𝑜𝑢𝑡𝑚\frac{k_{out}}{m}divide start_ARG italic_k start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT end_ARG start_ARG italic_m end_ARG is the output entropy rate, and m−ko⁢u⁢t𝑚subscript𝑘𝑜𝑢𝑡m-k_{out}italic_m - italic_k start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT is the entropy gap of 𝖢𝗈𝗇𝖽𝖢𝗈𝗇𝖽\mathsf{Cond}sansserif_Cond. The task of the condenser is to make the output entropy rate as high as possible compared to the input entropy rate, or, in other words, to make the output distribution more “condensed”. Related to this, it is also desirable to have as small entropy gap as possible. Notice that if the entropy gap is 00, the output distribution is ε𝜀\varepsilonitalic_ε-close to the uniform distribution. Such condensers with entropy gap 00 are known as randomness extractors—a topic that has been extensively studied in theoretical computer science. When 𝒳𝒳\mathcal{X}caligraphic_X is the family of all distributions, it is folklore that no non-trivial condensing is possible.111Assuming m≤n𝑚𝑛m\leq nitalic_m ≤ italic_n (wlog this holds since |𝖢𝗈𝗇𝖽⁢({0,1}n)|≤2n𝖢𝗈𝗇𝖽superscript01𝑛superscript2𝑛\left\lvert\mathsf{Cond}(\{0,1\}^{n})\right\rvert\leq 2^{n}| sansserif_Cond ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) | ≤ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT), m−ko⁢u⁢t≥(n−ki⁢n)−log⁡(1/(1−ε))𝑚subscript𝑘𝑜𝑢𝑡𝑛subscript𝑘𝑖𝑛11𝜀m-k_{out}\geq(n-k_{in})-\log(1/(1-\varepsilon))italic_m - italic_k start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT ≥ ( italic_n - italic_k start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ) - roman_log ( 1 / ( 1 - italic_ε ) ) and hence the output entropy rate cannot be more than the input entropy rate without incurring extremely large error (>0.999absent0.999>0.999> 0.999). So, we additionally assume that 𝒳𝒳\mathcal{X}caligraphic_X is a structured family of sources.222A different route, that has been widely studied, is to assume access to a short independent seed. In this work, we will limit ourselves to the seedless setting. Since extractors are the highest quality condensers, a significant amount of work has focused on constructing extractors for interesting family of sources, such as: sources generated by small circuits, two independent sources, algebraically generated sources, sources generated by small space sources, and many more [tv00, chattopadhyay_explicit_2019, dgw09extractpolynomials, kamp_deterministic_2007]. However, for many natural family of sources, one can provably show that no extractor can exist. In such situations, one can still hope to show that high quality condensers exist. We note that condensers (and sources with high min-entropy rate) are very useful: the condensed distribution can be used to efficiently simulate randomized algorithms with small overhead, perform one-shot simulations for randomized protocols, cryptography and interactive proofs, and much more. [DPW14key] showed these condensers are equivalent to ‘unpredictability extractors’ that can simulate cryptographic protocols against biased distinguishers. For details on these applications and more, see [aggarwal_how_2020, doron_almost_2023, CGR_seedless_condensers]. In this work, we focus on one natural family of sources where it is known that extraction is impossible. The family we consider are known as online non-oblivious symbol fixing sources (oNOSF sources ).333These sources are in contrast to non-oblivious symbol fixing (NOSF) sources where bad blocks can be arbitrary functions of all the good blocks. These sources were introduced in [chor_bit_1985] with applications in leakage-resilient cryptography, and have been well-studied. Formally: Definition 1.2. A (g,ℓ,n,k)𝑔ℓ𝑛𝑘{\left(g,\ell,n,k\right)}( italic_g , roman_ℓ , italic_n , italic_k )-oNOSF source 𝐗=(𝐗1,…,𝐗ℓ)𝐗subscript𝐗1…subscript𝐗ℓ\mathbf{X}=(\mathbf{X}_{1},\dots,\mathbf{X}_{\ell})bold_X = ( bold_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , bold_X start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ) is such that each block 𝐗isubscript𝐗𝑖\mathbf{X}_{i}bold_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is over {0,1}nsuperscript01𝑛\{0,1\}^{n}{ 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, g𝑔gitalic_g of the blocks are are independent sources with min-entropy k𝑘kitalic_k (“good blocks”), and each “bad block” is an arbitrary function of the blocks with an index smaller than it. When k=n𝑘𝑛k=nitalic_k = italic_n, we will call such sources uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources. These sources are inspired by real-time randomness generation settings such as in blockchains. There, each subsequent block is random or controlled by an adversary. Since these sources are generated in real time, a bad block can only be a function of the blocks that have appeared so far, and it is reasonable to assume that the good blocks contain entropy and are independent. Further, there are natural cryptographic settings, such as creating a Common Reference String, that are widely used in various cryptographic protocols where oNOSF source sources naturally arise (see [aggarwal_how_2020] for a discussion). The remainder of our introduction is structured as follows. We give an overview of previous work in Section 1.1 before presenting our main existential and explicit condenser results in Section 1.2. In Section 1.3, we show how our results have implications for collective coin flipping and sampling protocols. Next, we introduce our notion of online influence and related results in Section 1.4. We end by defining a local version of oNOSF sources and give explicit extractors for them in Section 1.5. 1.1 Previous work The study of condensers for oNOSF sources was initiated by [aggarwal_how_2020].444In [aggarwal_how_2020], these sources were called SHELA (Somewhere Honest Entropic Look Ahead) sources. Their results include the following: • It is impossible to extract from uniform oNOSF sources (even when the fraction of good blocks is an arbitrary constant). • An explicit transformation from (g,ℓ,n,0.9⁢n)𝑔ℓ𝑛0.9𝑛{\left(g,\ell,n,0.9n\right)}( italic_g , roman_ℓ , italic_n , 0.9 italic_n )-oNOSF source into a source over ({0,1}O⁢(n))ℓ−1superscriptsuperscript01𝑂𝑛ℓ1(\{0,1\}^{O(n)})^{\ell-1}( { 0 , 1 } start_POSTSUPERSCRIPT italic_O ( italic_n ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ - 1 end_POSTSUPERSCRIPT where g−1𝑔1g-1italic_g - 1 of the blocks are uniform and independent. • An explicit transformation from (g,ℓ,n,0.1⁢n)𝑔ℓ𝑛0.1𝑛{\left(g,\ell,n,0.1n\right)}( italic_g , roman_ℓ , italic_n , 0.1 italic_n )-oNOSF source into a source over ({0,1}O⁢(n))100⁢ℓsuperscriptsuperscript01𝑂𝑛100ℓ(\{0,1\}^{O(n)})^{100\ell}( { 0 , 1 } start_POSTSUPERSCRIPT italic_O ( italic_n ) end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 100 roman_ℓ end_POSTSUPERSCRIPT where g−1𝑔1g-1italic_g - 1 of the blocks are uniform and independent. Even though the output entropy rate is only slightly more than the input-entropy rate in the second result and smaller in the third result, the fact that a lot of the blocks are truly uniform is very useful, and they find interesting cryptographic applications of these somewhere-extractors. oNOSF sources were further studied by [CGR_seedless_condensers], where they obtained the following results: • When n≥k≥ℓ𝑛𝑘ℓn\geq k\geq\ellitalic_n ≥ italic_k ≥ roman_ℓ, there exist functions that can transform a (g,ℓ,n,k)𝑔ℓ𝑛𝑘{\left(g,\ell,n,k\right)}( italic_g , roman_ℓ , italic_n , italic_k )-oNOSF source into a uniform (g−1,ℓ−1,O⁢(k/ℓ))𝑔1ℓ1𝑂𝑘ℓ{\left(g-1,\ell-1,O(k/\ell)\right)}( italic_g - 1 , roman_ℓ - 1 , italic_O ( italic_k / roman_ℓ ) )-oNOSF source (this function can be made explicit with slightly worse dependence on output length). • When n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT, there exists condenser 𝖢𝗈𝗇𝖽:({0,1}n)ℓ→{0,1}m=O⁢(n⋅ℓ/g):𝖢𝗈𝗇𝖽→superscriptsuperscript01𝑛ℓsuperscript01𝑚𝑂⋅𝑛ℓ𝑔\mathsf{Cond}:(\{0,1\}^{n})^{\ell}\to\{0,1\}^{m=O(n\cdot\ell/g)}sansserif_Cond : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m = italic_O ( italic_n ⋅ roman_ℓ / italic_g ) end_POSTSUPERSCRIPT such that for any uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF source 𝐗𝐗\mathbf{X}bold_X, H∞ε⁢(𝖢𝗈𝗇𝖽⁢(𝐗))≥1⌊ℓ/g⌋⋅m−O⁢(log⁡(n/ε))superscriptsubscript𝐻𝜀𝖢𝗈𝗇𝖽𝐗⋅1ℓ𝑔𝑚𝑂𝑛𝜀H_{\infty}^{\varepsilon}(\mathsf{Cond}(\mathbf{X}))\geq\frac{1}{\left\lfloor% \ell/g\right\rfloor}\cdot m-O(\log(n/\varepsilon))italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( sansserif_Cond ( bold_X ) ) ≥ divide start_ARG 1 end_ARG start_ARG ⌊ roman_ℓ / italic_g ⌋ end_ARG ⋅ italic_m - italic_O ( roman_log ( italic_n / italic_ε ) ). Their result is not explicit. • It is impossible to condense from uniform ⁢(g,ℓ,n)⁢-oNOSF sourcesuniform 𝑔ℓ𝑛-oNOSF sources\textrm{uniform }{\left(g,\ell,n\right)}\textrm{-oNOSF sources}uniform ( italic_g , roman_ℓ , italic_n ) -oNOSF sources with output entropy rate more than 1⌊ℓ/g⌋1ℓ𝑔\frac{1}{\left\lfloor\ell/g\right\rfloor}divide start_ARG 1 end_ARG start_ARG ⌊ roman_ℓ / italic_g ⌋ end_ARG. We also mention a related family of sources, namely adversarial Chor-Goldreich sources. uniform oNOSF sources can be seen as a special case of adversarial Chor-Goldreich sources where the good blocks are uniform. Constructing condensers where the output entropy rate is g/ℓ𝑔ℓg/\ellitalic_g / roman_ℓ for adversarial Chor-Goldreich sources is already a challenging task, although such condensers in various parameter regimes have been recently constructed [doron_almost_2023, GLZ_cg_condenser]. [DMOZ24condenseunpredictability] recently constructed condensers for a related more general model. 1.2 New condenser constructions Previous works only showed the existence of condensers for oNOSF sources when n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT. We vastly improve on this result in two ways. First, we show that for almost all values of n,ℓ𝑛ℓn,\ellitalic_n , roman_ℓ, even when n𝑛nitalic_n is a small constant, excellent condensers exist. Second, we provide explicit condensers for oNOSF sources when n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT. We also obtain much better transformation from low-entropy oNOSF sources to uniform oNOSF sources that work even when k≪ℓmuch-less-than𝑘ℓk\ll\ellitalic_k ≪ roman_ℓ. These results show condensers always exist, except when n𝑛nitalic_n is a very small constant (such as n=1𝑛1n=1italic_n = 1). To further our understanding of this case, we initiate the study of online influence of Boolean functions, a natural generalization of influence that captures the one-sided nature of our online adversary. We also discover surprising connections between condensers for oNOSF sources and protocols for natural problems in distributed computing, such as collective coin flipping and collective sampling. We now discuss our result in details below. 1.2.1 Existential condensers We show how to condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources for almost all settings of ℓℓ\ellroman_ℓ and n𝑛nitalic_n when g≥0.51⁢ℓ𝑔0.51ℓg\geq 0.51\ellitalic_g ≥ 0.51 roman_ℓ. In particular, we show: Theorem 1 (Informal version of Theorem 4.1). For all ℓ,εℓ𝜀\ell,\varepsilonroman_ℓ , italic_ε where ℓ≥O⁢(log⁡(1/ε))ℓ𝑂1𝜀\ell\geq O(\log(1/\varepsilon))roman_ℓ ≥ italic_O ( roman_log ( 1 / italic_ε ) ), and n=104𝑛superscript104n=10^{4}italic_n = 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT, there exists a condenser 𝖢𝗈𝗇𝖽:({0,1}n)ℓ→{0,1}m:𝖢𝗈𝗇𝖽→superscriptsuperscript01𝑛ℓsuperscript01𝑚\mathsf{Cond}:(\{0,1\}^{n})^{\ell}\to\{0,1\}^{m}sansserif_Cond : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that for any uniform (0.51⁢ℓ,ℓ,n)0.51ℓℓ𝑛{\left(0.51\ell,\ell,n\right)}( 0.51 roman_ℓ , roman_ℓ , italic_n )-oNOSF source 𝐗𝐗\mathbf{X}bold_X, we have H∞ε⁢(𝖢𝗈𝗇𝖽⁢(𝐗))≥0.99⁢msuperscriptsubscript𝐻𝜀𝖢𝗈𝗇𝖽𝐗0.99𝑚H_{\infty}^{\varepsilon}(\mathsf{Cond}(\mathbf{X}))\geq 0.99mitalic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( sansserif_Cond ( bold_X ) ) ≥ 0.99 italic_m where m=O⁢(ℓ+log⁡(1/ε))𝑚𝑂ℓ1𝜀m=O(\ell+\log(1/\varepsilon))italic_m = italic_O ( roman_ℓ + roman_log ( 1 / italic_ε ) ). Furthermore, when n=ω⁢(1)𝑛𝜔1n=\omega(1)italic_n = italic_ω ( 1 ), the output entropy rate becomes 1−o⁢(1)1𝑜11-o(1)1 - italic_o ( 1 ). This is tight since [CGR_seedless_condensers] showed it is impossible to condense uniform (0.5⁢ℓ,ℓ,n)0.5ℓℓ𝑛{\left(0.5\ell,\ell,n\right)}( 0.5 roman_ℓ , roman_ℓ , italic_n )-oNOSF sources beyond output entropy rate 0.50.50.50.5. Using our new results regarding transforming oNOSF sources to uniform oNOSF sources , we also obtain condensers for (0.51⁢ℓ,ℓ,n,k)0.51ℓℓ𝑛𝑘{\left(0.51\ell,\ell,n,k\right)}( 0.51 roman_ℓ , roman_ℓ , italic_n , italic_k )-oNOSF sources when n≥poly⁡(log⁡(ℓ))𝑛polyℓn\geq\operatorname{poly}(\log(\ell))italic_n ≥ roman_poly ( roman_log ( roman_ℓ ) ), Theorem 2. For all ℓ,n,εℓ𝑛𝜀\ell,n,\varepsilonroman_ℓ , italic_n , italic_ε where n=poly⁡(log⁡(ℓ/ε)),k=O⁢(log⁡(ℓ/ε))formulae-sequence𝑛polyℓ𝜀𝑘𝑂ℓ𝜀n=\operatorname{poly}(\log(\ell/\varepsilon)),k=O(\log(\ell/\varepsilon))italic_n = roman_poly ( roman_log ( roman_ℓ / italic_ε ) ) , italic_k = italic_O ( roman_log ( roman_ℓ / italic_ε ) ), there exists a condenser 𝖢𝗈𝗇𝖽:({0,1}n)ℓ→{0,1}m:𝖢𝗈𝗇𝖽→superscriptsuperscript01𝑛ℓsuperscript01𝑚\mathsf{Cond}:(\{0,1\}^{n})^{\ell}\to\{0,1\}^{m}sansserif_Cond : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that for any (0.51⁢ℓ,ℓ,n,k)0.51ℓℓ𝑛𝑘{\left(0.51\ell,\ell,n,k\right)}( 0.51 roman_ℓ , roman_ℓ , italic_n , italic_k )-oNOSF source 𝐗𝐗\mathbf{X}bold_X, we have H∞ε⁢(𝖢𝗈𝗇𝖽⁢(𝐗))≥m−O⁢(m/log⁡(m))−O⁢(log⁡(1/ε))superscriptsubscript𝐻𝜀𝖢𝗈𝗇𝖽𝐗𝑚𝑂𝑚𝑚𝑂1𝜀H_{\infty}^{\varepsilon}(\mathsf{Cond}(\mathbf{X}))\geq m-O(m/\log(m))-O(\log(% 1/\varepsilon))italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( sansserif_Cond ( bold_X ) ) ≥ italic_m - italic_O ( italic_m / roman_log ( italic_m ) ) - italic_O ( roman_log ( 1 / italic_ε ) ) where m=Ω⁢(k)𝑚Ω𝑘m=\Omega(k)italic_m = roman_Ω ( italic_k ). We can also extend our result to condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources for all g,ℓ𝑔ℓg,\ellitalic_g , roman_ℓ and constant n𝑛nitalic_n where the output entropy rate is 1/⌊ℓ/g⌋−0.0011ℓ𝑔0.0011/\left\lfloor\ell/g\right\rfloor-0.0011 / ⌊ roman_ℓ / italic_g ⌋ - 0.001. This is tight since [CGR_seedless_condensers] showed it is impossible to condense such sources beyond output entropy rate 1/⌊ℓ/g⌋1ℓ𝑔1/\left\lfloor\ell/g\right\rfloor1 / ⌊ roman_ℓ / italic_g ⌋. Previously, [CGR_seedless_condensers] showed how to existentially condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources when g≥0.51⁢ℓ𝑔0.51ℓg\geq 0.51\ellitalic_g ≥ 0.51 roman_ℓ, provided n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT. As n𝑛nitalic_n gets smaller, condensing becomes harder since a uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF source is also a uniform (g⋅n/1000,ℓ⋅n/1000,1000)⋅𝑔𝑛1000⋅ℓ𝑛10001000{\left(g\cdot n/1000,\ell\cdot n/1000,1000\right)}( italic_g ⋅ italic_n / 1000 , roman_ℓ ⋅ italic_n / 1000 , 1000 )-oNOSF source. Hence, we greatly improve the parameters while using different and much simpler techniques. 1.2.2 Explicit condensers We construct the first explicit condensers for oNOSF sources . Our explicit condenser construction achieves the same parameters as the existential condenser construction of [CGR_seedless_condensers]. We show how to explicitly condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources when n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT and g≥0.5⁢ℓ+1𝑔0.5ℓ1g\geq 0.5\ell+1italic_g ≥ 0.5 roman_ℓ + 1. We state the results for constant ℓℓ\ellroman_ℓ since that is cleaner: Theorem 3 (Informal version of Theorem 5.1). For all n,ε𝑛𝜀n,\varepsilonitalic_n , italic_ε and constant ℓℓ\ellroman_ℓ, there exists an explicit condenser 𝖢𝗈𝗇𝖽:({0,1}n)ℓ→{0,1}m:𝖢𝗈𝗇𝖽→superscriptsuperscript01𝑛ℓsuperscript01𝑚\mathsf{Cond}:(\{0,1\}^{n})^{\ell}\to\{0,1\}^{m}sansserif_Cond : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that for any uniform (0.5⁢ℓ+1,ℓ)0.5ℓ1ℓ{\left(0.5\ell+1,\ell\right)}( 0.5 roman_ℓ + 1 , roman_ℓ )-oNOSF source 𝐗𝐗\mathbf{X}bold_X, we have H∞ε⁢(𝖢𝗈𝗇𝖽⁢(𝐗))≥m−O⁢(log⁡(m/ε))superscriptsubscript𝐻𝜀𝖢𝗈𝗇𝖽𝐗𝑚𝑂𝑚𝜀H_{\infty}^{\varepsilon}(\mathsf{Cond}(\mathbf{X}))\geq m-O(\log(m/\varepsilon))italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( sansserif_Cond ( bold_X ) ) ≥ italic_m - italic_O ( roman_log ( italic_m / italic_ε ) ) where m=Ω⁢(n)𝑚Ω𝑛m=\Omega(n)italic_m = roman_Ω ( italic_n ). Just like earlier, since condensing when g=0.5⁢ℓ𝑔0.5ℓg=0.5\ellitalic_g = 0.5 roman_ℓ is impossible, this result is also tight. Using our new results regarding transforming oNOSF sources to uniform oNOSF sources , we also obtain explicit condensers for (0.51⁢ℓ,ℓ,n,k)0.51ℓℓ𝑛𝑘{\left(0.51\ell,\ell,n,k\right)}( 0.51 roman_ℓ , roman_ℓ , italic_n , italic_k )-oNOSF sources for the same parameter regime: Corollary 1.3 (Corollary 5.2, simplified). For all ℓ,n,εℓ𝑛𝜀\ell,n,\varepsilonroman_ℓ , italic_n , italic_ε with constant ℓℓ\ellroman_ℓ and n≥O⁢(log⁡(1/ε))𝑛𝑂1𝜀n\geq O(\log(1/\varepsilon))italic_n ≥ italic_O ( roman_log ( 1 / italic_ε ) ), there exists an explicit condenser 𝖢𝗈𝗇𝖽:({0,1}n)ℓ→{0,1}m:𝖢𝗈𝗇𝖽→superscriptsuperscript01𝑛ℓsuperscript01𝑚\mathsf{Cond}:(\{0,1\}^{n})^{\ell}\to\{0,1\}^{m}sansserif_Cond : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that for any (0.5⁢ℓ+2,ℓ,n,poly⁡(log⁡n))0.5ℓ2ℓ𝑛poly𝑛{\left(0.5\ell+2,\ell,n,\operatorname{poly}(\log n)\right)}( 0.5 roman_ℓ + 2 , roman_ℓ , italic_n , roman_poly ( roman_log italic_n ) )-oNOSF source 𝐗𝐗\mathbf{X}bold_X, we have H∞ε⁢(𝖢𝗈𝗇𝖽⁢(𝐗))≥m−O⁢(log⁡(m/ε))superscriptsubscript𝐻𝜀𝖢𝗈𝗇𝖽𝐗𝑚𝑂𝑚𝜀H_{\infty}^{\varepsilon}(\mathsf{Cond}(\mathbf{X}))\geq m-O(\log(m/\varepsilon))italic_H start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_ε end_POSTSUPERSCRIPT ( sansserif_Cond ( bold_X ) ) ≥ italic_m - italic_O ( roman_log ( italic_m / italic_ε ) ) where m=poly⁡(log⁡n)𝑚poly𝑛m=\operatorname{poly}(\log n)italic_m = roman_poly ( roman_log italic_n ). Similar to earlier, we can also extend our result to explicitly condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources in the same parameter regime so that the output entropy rate is 1/⌊ℓ/g⌋−o⁢(1)1ℓ𝑔𝑜11/\left\lfloor\ell/g\right\rfloor-o(1)1 / ⌊ roman_ℓ / italic_g ⌋ - italic_o ( 1 ). Just like earlier, this is tight as well. Previously, [CGR_seedless_condensers] showed how to existentially condense from uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources in this parameter regime. However, they relied on the existence of a very strong pseudorandom object: “output-light” low-error two-source extractors. Such extractors, even without the output-lightness requirement, are extremely hard to construct and it is a major open problem to obtain such extractors. We are able to make this condenser explicit by building up on their ideas, making interesting observations regarding oNOSF sources , and stitching them together so that the base pseudorandom object we rely on are seeded extractors that we know how to explicitly construct with near optimal parameters. 1.2.3 Transforming low-entropy oNOSF sources to uniform oNOSF sources We show how to existentially, as well as explicitly, with a slight loss in parameters, transform (g,ℓ,n,k)𝑔ℓ𝑛𝑘{\left(g,\ell,n,k\right)}( italic_g , roman_ℓ , italic_n , italic_k )-oNOSF sources into uniform (0.99⁢g,ℓ−1,n)0.99𝑔ℓ1𝑛{\left(0.99g,\ell-1,n\right)}( 0.99 italic_g , roman_ℓ - 1 , italic_n )-oNOSF sources. Formally, we show: Theorem 1.4 (Informal version of Theorem 6.1). For all ℓ,n,k,εℓ𝑛𝑘𝜀\ell,n,k,\varepsilonroman_ℓ , italic_n , italic_k , italic_ε where n=poly⁡(log⁡(ℓ)),k=O⁢(log⁡(ℓ/ε))formulae-sequence𝑛polyℓ𝑘𝑂ℓ𝜀n=\operatorname{poly}(\log(\ell)),k=O(\log(\ell/\varepsilon))italic_n = roman_poly ( roman_log ( roman_ℓ ) ) , italic_k = italic_O ( roman_log ( roman_ℓ / italic_ε ) ), there exists a function f𝑓fitalic_f such that f𝑓fitalic_f transforms (0.51⁢ℓ,ℓ,n,k)0.51ℓℓ𝑛𝑘{\left(0.51\ell,\ell,n,k\right)}( 0.51 roman_ℓ , roman_ℓ , italic_n , italic_k )-oNOSF sources into uniform (0.509⁢ℓ,ℓ,m)0.509ℓℓ𝑚{\left(0.509\ell,\ell,m\right)}( 0.509 roman_ℓ , roman_ℓ , italic_m )-oNOSF sources with error ε𝜀\varepsilonitalic_ε where m=O⁢(k)𝑚𝑂𝑘m=O(k)italic_m = italic_O ( italic_k ). Our construction can also be made explicit with slightly worse dependence on m𝑚mitalic_m and ε𝜀\varepsilonitalic_ε. See Corollary 6.4 for the full tradeoff. Previously, [CGR_seedless_condensers] provided such a transformation only for n≥k≥Ω⁢(ℓ)𝑛𝑘Ωℓn\geq k\geq\Omega(\ell)italic_n ≥ italic_k ≥ roman_Ω ( roman_ℓ ). Hence, our transformation makes a major improvement on their parameters. Such an improvement allows us to obtain better condensers for low-entropy oNOSF sources in the regime n=poly⁡(log⁡(ℓ/ε))𝑛polyℓ𝜀n=\operatorname{poly}(\log(\ell/\varepsilon))italic_n = roman_poly ( roman_log ( roman_ℓ / italic_ε ) ) (see 2). 1.3 Application to collective coin flipping and collective sampling Condensing from oNOSF sources can be viewed as a special case of coin flipping and collective sampling protocols in the full information model that arise in fault-tolerant distributed computing. 1.3.1 Background Say there are ℓℓ\ellroman_ℓ players who have a common broadcast channel and want to jointly perform a task such as collectively flipping a coin. Some b𝑏bitalic_b players out of them are “bad” and want to deter the task. We assume the bad players are computationally unbounded so cryptographic primitives are of no use. We further assume that each player has private access to uniform randomness. [ben-or_collective_1989] initiated the study of this model and aptly termed this task as “collective coin flipping.” The simplest way to collectively flip a coin would be for all the players to initially agree on a function f:{0,1}ℓ→{0,1}:𝑓→superscript01ℓ01f:\{0,1\}^{\ell}\to\{0,1\}italic_f : { 0 , 1 } start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 }, then synchronously broadcast one random bit risubscript𝑟𝑖r_{i}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and to finally agree on the output being f⁢(r1,…,rℓ)𝑓subscript𝑟1…subscript𝑟ℓf(r_{1},\dots,r_{\ell})italic_f ( italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_r start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ). However, synchronizing broadcasts is hard, and it could be that the bad players set their output as function of the bits of the good players. [kahn_influence_1988] showed that no function f𝑓fitalic_f can handle more than O⁢(ℓlog⁡ℓ)𝑂ℓℓO\left(\frac{\ell}{\log\ell}\right)italic_O ( divide start_ARG roman_ℓ end_ARG start_ARG roman_log roman_ℓ end_ARG ) corruptions. One way to allow for more corruptions (almost linear) amongst players is to consider “protocols” that allow more rounds of communication. In particular, a protocol can be thought of as a tree where each vertex represents a “round” where in every round the following happens: all good players sends their bits, then all bad players send their bits as a function of the bits of the good players, and they jointly compute a function of these bits. Depending on the outcome of the function, everyone branches on one branch in this tree. Furthermore, every leaf is labelled with final outcomes (say 00 or 1111) and, once you reach a leaf, that is the outcome that everybody agrees on. [ggl98] initiated the study of protocols where the outcomes are from a larger range and where the bad players are trying to minimize the largest probability of any outcome. They called this problem “collective sampling.” 1.3.2 Known results [ben-or_collective_1989] showed that for protocols with outcomes {0,1}01\{0,1\}{ 0 , 1 }, b𝑏bitalic_b bad players can always ensure some outcome occurs with probability at least 12+b2⁢ℓ12𝑏2ℓ\frac{1}{2}+\frac{b}{2\ell}divide start_ARG 1 end_ARG start_ARG 2 end_ARG + divide start_ARG italic_b end_ARG start_ARG 2 roman_ℓ end_ARG. [alonnoar93collective] first constructed a protocol that can handle O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ) corruptions. Follow-up works tried to reduce the number of rounds in this protocol where, in some settings, players were allowed to send more bits per round [russellzuckerman01, feige_noncryptographic_1999]. [ggl98] showed that for all collective sampling protocols and all outcomes, there exists a way for b𝑏bitalic_b bad players to coordinate and ensure that an outcome that happens without corruption with probability p𝑝pitalic_p, now happens with probability p1−(b/n)≥p⁢(1+bn⁢log⁡(1/p))superscript𝑝1𝑏𝑛𝑝1𝑏𝑛1𝑝p^{1-(b/n)}\geq p\left(1+\frac{b}{n}\log(1/p)\right)italic_p start_POSTSUPERSCRIPT 1 - ( italic_b / italic_n ) end_POSTSUPERSCRIPT ≥ italic_p ( 1 + divide start_ARG italic_b end_ARG start_ARG italic_n end_ARG roman_log ( 1 / italic_p ) ). For further results and bounds, see [dodis2006fault]. 1.3.3 Connection to oNOSF sources The problem of extracting or condensing from oNOSF sources can be seen as special cases or variants of collective coin flipping and collective sampling that provide very simple protocols. For instance, suppose one has an extractor or condenser f𝑓fitalic_f for uniform ⁢(g,ℓ,n)⁢-oNOSF sourcesuniform 𝑔ℓ𝑛-oNOSF sources\textrm{uniform }{\left(g,\ell,n\right)}\textrm{-oNOSF sources}uniform ( italic_g , roman_ℓ , italic_n ) -oNOSF sources. Then, consider a protocol where all ℓℓ\ellroman_ℓ players take turns and output n𝑛nitalic_n random bits. The agreed final outcome is f𝑓fitalic_f applied on these ℓ⁢nℓ𝑛\ell nroman_ℓ italic_n bits. This leads to protocols that are structurally much simpler since players don’t have to carefully compute whose turn is it to go in various rounds and can obliviously prepare for their turn. The above protocol can also be viewed as a relaxed version of a 1111-round protocol where instead of everyone providing their output asynchronously, they take turns and provide outputs one after another in a simple sequential manner. 1.3.4 Previous results interpreted in oNOSF source context Previous impossibility results can be interpreted in the context of extracting / condensing from uniform oNOSF sources . For instance, collective coin flipping impossibility results of [ben-or_collective_1989] imply extraction impossibility results for uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources when n=1𝑛1n=1italic_n = 1. In particular, they imply: Corollary 1.5. There does not exist an ε𝜀\varepsilonitalic_ε-extractor for uniform (g,ℓ,1)𝑔ℓ1{\left(g,\ell,1\right)}( italic_g , roman_ℓ , 1 )-oNOSF sources where ε=b2⁢ℓ𝜀𝑏2ℓ\varepsilon=\frac{b}{2\ell}italic_ε = divide start_ARG italic_b end_ARG start_ARG 2 roman_ℓ end_ARG. Similarly, we observe that the notion of collective sampling is equivalent to 00-error condensing. Hence, lower bounds of [ggl98] imply zero-error condensing lower bounds for uniform (g,ℓ,n)𝑔ℓ𝑛{\left(g,\ell,n\right)}( italic_g , roman_ℓ , italic_n )-oNOSF sources when n=1𝑛1n=1italic_n = 1. Formally: Corollary 1.6. There does not exist a condenser 𝖢𝗈𝗇𝖽:{0,1}ℓ→{0,1}m:𝖢𝗈𝗇𝖽→superscript01ℓsuperscript01𝑚\mathsf{Cond}:\{0,1\}^{\ell}\to\{0,1\}^{m}sansserif_Cond : { 0 , 1 } start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT for uniform (g,ℓ,1)𝑔ℓ1{\left(g,\ell,1\right)}( italic_g , roman_ℓ , 1 )-oNOSF sources that can guarantee output smooth min-entropy (with parameter ε=0𝜀0\varepsilon=0italic_ε = 0) more than k=gℓ⋅m𝑘⋅𝑔ℓ𝑚k=\frac{g}{\ell}\cdot mitalic_k = divide start_ARG italic_g end_ARG start_ARG roman_ℓ end_ARG ⋅ italic_m. 1.3.5 ε𝜀\varepsilonitalic_ε-collective sampling Since collective sampling lower bounds show that for any protocol, 00-error condensing beyond rate g/ℓ𝑔ℓg/\ellitalic_g / roman_ℓ is impossible, one can naturally ask whether condensing with small error ε𝜀\varepsilonitalic_ε is possible: We call this problem ε𝜀\varepsilonitalic_ε-collective sampling where the goal is to output a distribution which is ε𝜀\varepsilonitalic_ε-close to a distribution where every output has small probability. Interpreted this way, this is exactly what protocols arising out of our condensers for uniform oNOSF sources provide: Using 1, when each player has access to 104superscript10410^{4}10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT random bits, there exists a simple protocol that can handle 0.49⁢ℓ0.49ℓ0.49\ell0.49 roman_ℓ corrupt players such that the players can collectively sample a distribution over m=O⁢(ℓ)𝑚𝑂ℓm=O(\ell)italic_m = italic_O ( roman_ℓ ) bits which is 2−Ω⁢(ℓ)superscript2Ωℓ2^{-\Omega(\ell)}2 start_POSTSUPERSCRIPT - roman_Ω ( roman_ℓ ) end_POSTSUPERSCRIPT-close to having entropy 0.99⁢m0.99𝑚0.99m0.99 italic_m. As far as we are aware, such a protocol cannot be implied using any other previous protocol (a lot of previous protocols are obtained through leader election protocols which do not seem useful here since the leader has access to only constant number of bits). We similarly obtain explicit protocols using 3 for the case when each player has access to n≥2ω⁢(ℓ)𝑛superscript2𝜔ℓn\geq 2^{\omega(\ell)}italic_n ≥ 2 start_POSTSUPERSCRIPT italic_ω ( roman_ℓ ) end_POSTSUPERSCRIPT bits. 1.3.6 Collective coin flipping and sampling with weak random sources A natural extension to collective coin flipping and sampling in the full information model is when all players only have access to weak source of randomness (that are independent from each other) instead of true uniform randomness. This question was first studied by [gsv05]. [klrz08network] used network extractor protocol to transform weak random sources of each player into independent private random sources. This way, after using the network extraction protocol, players can follow the usual collective coin flipping / sampling protocol. [gsz21network] improved the network extraction protocol using two-source non-malleable extractors. Using our (g,ℓ,n,k)𝑔ℓ𝑛𝑘{\left(g,\ell,n,k\right)}( italic_g , roman_ℓ , italic_n , italic_k )-oNOSF source condensers, we obtain alternative, simple ε𝜀\varepsilonitalic_ε-collective sampling protocols in the setting where players have access to weak sources of randomness. We obtain such an existential protocol using 2, and explicit protocol using Corollary 1.3. 1.4 Online influence When n𝑛nitalic_n is a large enough constant, we showed that great condensers do exist for oNOSF sources . We now study the case of small n𝑛nitalic_n. In particular, we focus on the case of n=1𝑛1n=1italic_n = 1. We call such uniform (g,ℓ,1)𝑔ℓ1{\left(g,\ell,1\right)}( italic_g , roman_ℓ , 1 )-oNOSF sources as (g,ℓ)𝑔ℓ{\left(g,\ell\right)}( italic_g , roman_ℓ )-oNOBF sources; oNOBF stands for online non-oblivious bit-fixing sources. We ask what is the exact tradeoff between g𝑔gitalic_g, ℓℓ\ellroman_ℓ, and ε𝜀\varepsilonitalic_ε for extracting / condensing from oNOBF sources . Towards this, we introduce a new notion of influence for Boolean functions which we call online influence. Definition 1.7 (Online influence). For a function f:{0,1}ℓ→{0,1}:𝑓→superscript01ℓ01f:\{0,1\}^{\ell}\to\{0,1\}italic_f : { 0 , 1 } start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 }, the online influence of the i𝑖iitalic_i-th bit is 𝐨𝐈i⁡[f]=𝔼x∼𝐔i−1[|𝔼y∼𝐔ℓ−i[f⁢(x,1,y)]−𝔼y∼𝐔ℓ−i[f⁢(x,0,y)]|]subscript𝐨𝐈𝑖𝑓subscript𝔼similar-to𝑥subscript𝐔𝑖1subscript𝔼similar-to𝑦subscript𝐔ℓ𝑖𝑓𝑥1𝑦subscript𝔼similar-to𝑦subscript𝐔ℓ𝑖𝑓𝑥0𝑦\displaystyle\operatorname{\mathbf{oI}}_{i}[f]=\operatorname*{\mathbb{E}}_{x% \sim\mathbf{U}_{i-1}}\left[\left\lvert\operatorname*{\mathbb{E}}_{y\sim\mathbf% {U}_{\ell-i}}[f(x,1,y)]-\operatorname*{\mathbb{E}}_{y\sim\mathbf{U}_{\ell-i}}[% f(x,0,y)]\right\rvert\right]bold_oI start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT [ italic_f ] = blackboard_E start_POSTSUBSCRIPT italic_x ∼ bold_U start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ | blackboard_E start_POSTSUBSCRIPT italic_y ∼ bold_U start_POSTSUBSCRIPT roman_ℓ - italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_f ( italic_x , 1 , italic_y ) ] - blackboard_E start_POSTSUBSCRIPT italic_y ∼ bold_U start_POSTSUBSCRIPT roman_ℓ - italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_f ( italic_x , 0 , italic_y ) ] | ] and the total online influence is 𝐨𝐈⁡[f]𝐨𝐈𝑓\displaystyle\operatorname{\mathbf{oI}}[f]bold_oI [ italic_f ] =∑i=1ℓ𝐨𝐈i⁡[f].absentsuperscriptsubscript𝑖1ℓsubscript𝐨𝐈𝑖𝑓\displaystyle=\sum_{i=1}^{\ell}\operatorname{\mathbf{oI}}_{i}[f].= ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT bold_oI start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT [ italic_f ] . We first observe that for monotone functions, online influence equals the usual notion of influence (see Lemma 7.4 for a proof). Next, we show a Poincaré style inequality for total online influence: Theorem 4 (Theorem 7.5, restated). For any f:{0,1}ℓ→{0,1}:𝑓→superscript01ℓ01f:\{0,1\}^{\ell}\to\{0,1\}italic_f : { 0 , 1 } start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 }, we have Var(f)≤𝐨𝐈⁡[f]≤ℓ⁢Var(f)Var𝑓𝐨𝐈𝑓ℓVar𝑓\operatorname*{Var}(f)\leq\operatorname{\mathbf{oI}}[f]\leq\sqrt{\ell% \operatorname*{Var}(f)}roman_Var ( italic_f ) ≤ bold_oI [ italic_f ] ≤ square-root start_ARG roman_ℓ roman_Var ( italic_f ) end_ARG. These inequalities are tight, with tightness exhibited by PARITY and MAJORITY respectively (see Example 7.6 for more details). We then ask the natural question that for a function f𝑓fitalic_f, what is the maximum online influence out of all n𝑛nitalic_n bits? For the usual notion of influence, this question was resolved by the famous theorem of [kahn_influence_1988] who showed there always exists a bit with influence at least Var(f)⋅Ω⁢(log⁡ℓℓ)⋅Var𝑓Ωℓℓ\operatorname*{Var}(f)\cdot\Omega\left(\frac{\log\ell}{\ell}\right)roman_Var ( italic_f ) ⋅ roman_Ω ( divide start_ARG roman_log roman_ℓ end_ARG start_ARG roman_ℓ end_ARG ). We show that surprisingly, there exists a balanced function, namely the address function, where every bit has online influence at most O⁢(1ℓ)𝑂1ℓO\left(\frac{1}{\ell}\right)italic_O ( divide start_ARG 1 end_ARG start_ARG roman_ℓ end_ARG ) (see Lemma 7.12 for a proof). This provides a separation between the usual notion of influence and online influence. Additionally, in Lemma 7.13, we show that the address function is an extractor for uniform (ℓ−1,ℓ)ℓ1ℓ{\left(\ell-1,\ell\right)}( roman_ℓ - 1 , roman_ℓ )-oNOSF sources with error 1/ℓ1ℓ1/\ell1 / roman_ℓ . Lastly, we show that using this notion of online influence, we can obtain the following extraction lower bound: Theorem 1.8 (Informal version of Theorem 7.17). For ε<0.01𝜀0.01\varepsilon<0.01italic_ε < 0.01, there do not exist extractors for (0.98⁢ℓ,ℓ)0.98ℓℓ{\left(0.98\ell,\ell\right)}( 0.98 roman_ℓ , roman_ℓ )-oNOBF sources with error at most ε𝜀\varepsilonitalic_ε. A similar extraction lower bound was shown in [aggarwal_how_2020] using different techniques. 1.5 Extracting from local oNOSF sources A natural variation on our definition of oNOSF sources is to consider the case where the adversary cannot remember the value of every good block in the past; rather, it can only remember the value of the most recent s𝑠sitalic_s blocks. Arguably, this is a realistic assumption in the setting of many short blocks, where it could be difficult to introduce long range correlation."
https://arxiv.org/html/2411.03444v1,Algebraic metacomplexity and representation theory,"We prove that in the algebraic metacomplexity framework, the decomposition of metapolynomials into their isotypic components can be implemented efficiently, namely with only a quasipolynomial blowup in the circuit size. This means that many existing algebraic complexity lower bound proofs can be efficiently converted into isotypic lower bound proofs via highest weight metapolynomials, a notion studied in geometric complexity theory. In the context of algebraic natural proofs, our result means that without loss of generality algebraic natural proofs can be assumed to be isotypic. Our proof is built on the Poincaré–Birkhoff–Witt theorem for Lie algebras and on Gelfand–Tsetlin theory, for which we give the necessary comprehensive background.","Strong computational complexity lower bounds are often difficult to prove, for many different complexity measures. In most cases, the inability to prove lower bounds can be explained by barrier results such as the Relativization barrier due to Baker, Gill and Solovay [BGS75], the Algebrization barrier due to Aaronson and Wigderson [AW09] and the Natural Proofs barrier due to Razborov and Rudich [RR94]. Metacomplexity studies the complexity of computing various complexity measures, such as the minimum circuit complexity of a function. One eventual goal of the metacomplexity program is to understand mathematically why lower bounds are hard to prove. In this paper, we study metacomplexity in the algebraic circuit complexity setup from a representation-theoretic viewpoint. Algebraic complexity focuses on proving complexity lower bounds for various problems related to the computation of multivariate polynomials and rational functions. Prominent examples include the discrete Fourier transform, matrix multiplication, and solving systems of linear equations; see [BCS13]. In algebraic complexity, the main model of computation is the algebraic circuit, which is a labeled directed graph encoding an algorithm to evaluate a polynomial. Most polynomials require large algebraic circuits; however exhibiting explicit ones with such property is difficult. Valiant’s flagship conjecture [Val79], known as 𝖵𝖯≠𝖵𝖭𝖯𝖵𝖯𝖵𝖭𝖯\mathsf{VP}\neq\mathsf{VNP}sansserif_VP ≠ sansserif_VNP, states that the algebraic circuit complexity of the permanent polynomial 𝗉𝖾𝗋d⁢(x1,1,…,xd,d)=∑π∈𝔖d∏i=1dxi,π⁢(i)subscript𝗉𝖾𝗋𝑑subscript𝑥11…subscript𝑥𝑑𝑑subscript𝜋subscript𝔖𝑑superscriptsubscriptproduct𝑖1𝑑subscript𝑥𝑖𝜋𝑖\mathsf{per}_{d}(x_{1,1},\dots,x_{d,d})=\sum_{\pi\in\mathfrak{S}_{d}}\prod_{i=% 1}^{d}x_{i,\pi(i)}sansserif_per start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 , 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_d , italic_d end_POSTSUBSCRIPT ) = ∑ start_POSTSUBSCRIPT italic_π ∈ fraktur_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT end_POSTSUBSCRIPT ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i , italic_π ( italic_i ) end_POSTSUBSCRIPT is not polynomially bounded as a function of d𝑑ditalic_d; this conjecture is an algebraic analog of the 𝖯≠𝖭𝖯𝖯𝖭𝖯\mathsf{P}\neq\mathsf{NP}sansserif_P ≠ sansserif_NP conjecture: indeed, the permanent of the adjacency matrix of a bipartite graph counts the number of perfect matchings, which is a #⁢𝖯#𝖯\#\mathsf{P}# sansserif_P-hard problem. Since the superlinear algebraic lower bounds for general circuits demonstrated by Strassen [Str73] and Baur & Strassen [BS83], there have been no significant improvements in these lower bounds for more than four decades. This stagnation has prompted research into understanding the limitations of current proof techniques for establishing strong lower bounds for algebraic circuits, in order to guide us away from lower bound techniques that are inherently limited. Many current proof techniques in algebraic complexity theory are implicitly based on metapolynomials. Examples of such techniques are rank methods [LO15, LST21], methods based on geometric features [LMR13, GGIL22], and the geometric complexity program [MS01, Mul12]. We refer to Section 2.2 for a more extensive discussion. Informally, metapolynomials are polynomials whose variables are coefficients of polynomials. The concept dates back to resultants and invariants of forms [Cay45, Syl52], while the term “metapolynomial” was coined in [Reg02], and made popular in [GKSS17]. A classical example is the metapolynomial b2−4⁢a⁢csuperscript𝑏24𝑎𝑐b^{2}-4acitalic_b start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_a italic_c in the coefficients of a univariate degree 2222 polynomial a⁢x2+b⁢x+c𝑎superscript𝑥2𝑏𝑥𝑐ax^{2}+bx+citalic_a italic_x start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_b italic_x + italic_c, which vanishes exactly when the two roots of the polynomial coincide. In this paper, we study the algebraic circuit complexity of metapolynomials, and their representation theoretic structure. We prove that the search space for lower bounds proofs via metapolynomials can be drastically reduced to isotypic metapolynomials, or to highest weight vectors, with only a quasipolynomial circuit size blowup. This reduction is common in the geometric setting, see e.g., [AC07, BI11, BI13, AIR16, CIM17, BHIM22]; however the general circuit size blowup was unknown. Our method can be used to extract isotypic metapolynomials for example from rank-based lower bounds proofs, and the obtained metapolynomials give the same lower bounds. Generally, metapolynomials are not affected by barriers for rank methods [EGOW18, Gał17]. In fact, metapolynomials characterize border complexity classes in the sense of Section 2.4. Metapolynomials We work over the field ℂℂ\mathbb{C}blackboard_C of complex numbers, and the set {x1,x2,…}subscript𝑥1subscript𝑥2…\{x_{1},x_{2},\ldots\}{ italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … } of variables. For every sequence 𝒊𝒊\bm{i}bold_italic_i of nonnegative integers with ∑jij<∞subscript𝑗subscript𝑖𝑗\sum_{j}i_{j}<\infty∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT < ∞, a monomial x𝒊superscript𝑥𝒊x^{\bm{i}}italic_x start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT is the finite product of variables x1i1⁢x2i2⁢⋯superscriptsubscript𝑥1subscript𝑖1superscriptsubscript𝑥2subscript𝑖2⋯x_{1}^{i_{1}}x_{2}^{i_{2}}\cdotsitalic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⋯, and a polynomial f𝑓fitalic_f is a finite linear combination of monomials. For every monomial x𝒊=x1i1⁢x2i2⁢⋯superscript𝑥𝒊superscriptsubscript𝑥1subscript𝑖1superscriptsubscript𝑥2subscript𝑖2⋯x^{\bm{i}}=x_{1}^{i_{1}}x_{2}^{i_{2}}\cdotsitalic_x start_POSTSUPERSCRIPT bold_italic_i end_POSTSUPERSCRIPT = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⋯, define a metavariable c𝒊subscript𝑐𝒊c_{\bm{i}}italic_c start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT. A metavariable c𝒊subscript𝑐𝒊c_{{\bm{i}}}italic_c start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT has degree 1, and it has weight 𝒊𝒊\bm{i}bold_italic_i. Finite products of metavariables are called metamonomials, and finite linear combinations of metamonomials are called metapolynomials. The weight of a metamonomial is the sum of the weights of its metavariables. If every metamonomial in a metapolynomial ΔΔ\Deltaroman_Δ has the same weight, then ΔΔ\Deltaroman_Δ is called a weight metapolynomial (and the zero metapolynomial has every weight). For a fixed weight w𝑤witalic_w the metapolynomials of that weight form a vector space, the weight w𝑤witalic_w space. Every metapolynomial can be written as a unique sum of weight metapolynomials of different weights. A metapolynomial is called affine linear if all its metamonomials have degree at most 1, i.e., are just a metavariable or a constant. Every metapolynomial ΔΔ\Deltaroman_Δ can be evaluated at any polynomial f𝑓fitalic_f by assigning to each metavariable the coefficient of the corresponding monomial in f𝑓fitalic_f. For example, the discriminant of a degree two homogeneous polynomial in two variables c20⁢x02+c11⁢x0⁢x1+c02⁢x12subscript𝑐20superscriptsubscript𝑥02subscript𝑐11subscript𝑥0subscript𝑥1subscript𝑐02superscriptsubscript𝑥12c_{20}x_{0}^{2}+c_{11}x_{0}x_{1}+c_{02}x_{1}^{2}italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT is the metapolynomial Δ=c112−4⁢c20⁢c02Δsuperscriptsubscript𝑐1124subscript𝑐20subscript𝑐02\Delta=c_{11}^{2}-4c_{20}c_{02}roman_Δ = italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT. It is a classical fact that Δ⁢(f)=0Δ𝑓0\Delta(f)=0roman_Δ ( italic_f ) = 0 if and only if f=ℓ2𝑓superscriptℓ2f=\ell^{2}italic_f = roman_ℓ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for some homogeneous linear polynomial ℓ=α0⁢x0+α1⁢x1ℓsubscript𝛼0subscript𝑥0subscript𝛼1subscript𝑥1\ell=\alpha_{0}x_{0}+\alpha_{1}x_{1}roman_ℓ = italic_α start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. In principle, metapolynomials can involve metavariables that correspond to monomials of different degrees, but for our purposes it is sufficient to consider the case where all metavariables correspond to monomials of the same degree d𝑑ditalic_d, see 1.2. Every such metapolynomial can be decomposed uniquely as a sum of its homogeneous degree δ𝛿\deltaitalic_δ components, and we call a homogeneous degree δ𝛿\deltaitalic_δ metapolynomial a metapolynomial of format (δ,d,k)𝛿𝑑𝑘(\delta,d,k)( italic_δ , italic_d , italic_k ) if all its metavariables only involve the variables x1,…,xksubscript𝑥1…subscript𝑥𝑘x_{1},\ldots,x_{k}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Algebraic circuits In this paper, we are mostly interested in the algebraic circuit size of metapolynomials. Algebraic circuits for metapolynomials are defined in the same way as for usual polynomials, as follows. An algebraic circuit is a directed acyclic graph in which each vertex has indegree 00 or 2222. Every indegree 0 vertex is called input gate and it is labelled by an affine linear metapolynomial; every indegree 2 vertex is called a computation gate and it is labeled by either “+++” or “×\times×”; every edge is labeled by a complex number, which is assumed to be 1 if this scalar is omitted; there is exactly one vertex of outdegree 0. An algebraic circuit computes a metapolynomial at every vertex by induction over the directed acyclic graph structure (the labels on the edges rescale the computed values), i.e., if the values computed at the children of a gate v𝑣vitalic_v are Δ1subscriptΔ1\Delta_{1}roman_Δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and Δ2subscriptΔ2\Delta_{2}roman_Δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and the incoming edges to v𝑣vitalic_v are labelled with α1subscript𝛼1\alpha_{1}italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and α2subscript𝛼2\alpha_{2}italic_α start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, respectively, then the value computed at v𝑣vitalic_v is α1⁢Δ1+α2⁢Δ2subscript𝛼1subscriptΔ1subscript𝛼2subscriptΔ2\alpha_{1}\Delta_{1}+\alpha_{2}\Delta_{2}italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT roman_Δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + italic_α start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_Δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT or α1⁢α2⁢Δ1⁢Δ2subscript𝛼1subscript𝛼2subscriptΔ1subscriptΔ2\alpha_{1}\alpha_{2}\Delta_{1}\Delta_{2}italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_α start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT roman_Δ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT roman_Δ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, depending on whether v𝑣vitalic_v is labelled with a “+++” or a “×\times×”. An algebraic circuit computes the metapolynomial computed at its outdegree 0 vertex. The size of a circuit is the total number of its vertices. The algebraic circuit complexity of a metapolynomial is the minimum size of an algebraic circuit computing it. For example, Figure 1 shows that the algebraic circuit complexity of the discriminant is at most 6. Algebraic circuits for polynomials are defined analogously. c11subscript𝑐11c_{11}italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPTc20subscript𝑐20c_{20}italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPTc02subscript𝑐02c_{02}italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT×\times××\times×+++−44-4- 4 Figure 1: An algebraic circuit computing the discriminant Δ=c112−4⁢c20⁢c02Δsuperscriptsubscript𝑐1124subscript𝑐20subscript𝑐02\Delta=c_{11}^{2}-4c_{20}c_{02}roman_Δ = italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT. Representation Theory A partition λ=(λ1,λ2,…)𝜆subscript𝜆1subscript𝜆2…\lambda=(\lambda_{1},\lambda_{2},\ldots)italic_λ = ( italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … ) is a finite sequence of non-increasing positive natural numbers. Let ℓ⁢(λ)=max⁡{j∣λj≠0}ℓ𝜆conditional𝑗subscript𝜆𝑗0\ell(\lambda)=\max\{j\mid\lambda_{j}\neq 0\}roman_ℓ ( italic_λ ) = roman_max { italic_j ∣ italic_λ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ≠ 0 }. We define λj=0subscript𝜆𝑗0\lambda_{j}=0italic_λ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = 0 for all j>ℓ⁢(λ)𝑗ℓ𝜆j>\ell(\lambda)italic_j > roman_ℓ ( italic_λ ). Write |λ|:=∑jλjassign𝜆subscript𝑗subscript𝜆𝑗|\lambda|:=\sum_{j}\lambda_{j}| italic_λ | := ∑ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_λ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, and say that λ𝜆\lambdaitalic_λ is a partition of |λ|𝜆|\lambda|| italic_λ | of length ℓ⁢(λ)ℓ𝜆\ell(\lambda)roman_ℓ ( italic_λ ). In this case we write λ⊢|λ|proves𝜆𝜆\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}\,}{\scalebox{1.2}[0.7]{ $% \vdash$}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}\,}{\scalebox{0.5}{% \scalebox{1.2}[0.7]{$\vdash$}}\,}|\lambda|italic_λ ⊢ | italic_λ | or λ⊢ℓ⁢(λ)|λ|\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}_{\ell(\lambda)}\,}{\scalebox% {1.2}[0.7]{ $\vdash$}_{\ell(\lambda)}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$% \vdash$}}_{\ell(\lambda)}\,}{\scalebox{0.5}{\scalebox{1.2}[0.7]{$\vdash$}}_{% \ell(\lambda)}\,}|\lambda|italic_λ ⊢ start_POSTSUBSCRIPT roman_ℓ ( italic_λ ) end_POSTSUBSCRIPT | italic_λ | depending on whether the length is relevant. For example, λ=(4,2,2)𝜆422\lambda=(4,2,2)italic_λ = ( 4 , 2 , 2 ) is a partition of 8888 of length 3333, i.e., λ⊢3 8\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}_{3}\,}{\scalebox{1.2}[0.7]{ % $\vdash$}_{3}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}_{3}\,}{% \scalebox{0.5}{\scalebox{1.2}[0.7]{$\vdash$}}_{3}\,}8italic_λ ⊢ start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT 8. The Young diagram of a partition λ𝜆\lambdaitalic_λ is a top-left justified array of boxes with λjsubscript𝜆𝑗\lambda_{j}italic_λ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT many boxes in row j𝑗jitalic_j. For example, the Young diagram for (4,2,2)422(4,2,2)( 4 , 2 , 2 ) is \yng⁢(4,2,2)\yng422\yng(4,2,2)( 4 , 2 , 2 ). A Young tableau T𝑇Titalic_T is a filling of the boxes of a Young diagram with numbers. The partition λ𝜆\lambdaitalic_λ is called the shape of T𝑇Titalic_T. For example, \young⁢(1421,31,24)\young14213124\young(1421,31,24)( 1421 , 31 , 24 ) is a Young tableau of shape (4,2,2)422(4,2,2)( 4 , 2 , 2 ). A Young tableau is semistandard if the numbers within each row from left to right are non-decreasing, and the numbers within each column from top to bottom are strictly increasing, for example \young⁢(1122,23,44)\young11222344\young(1122,23,44)( 1122 , 23 , 44 ). For each partition λ𝜆\lambdaitalic_λ there exists a unique superstandard tableau, that is the tableau with only the number j𝑗jitalic_j in row j𝑗jitalic_j, e.g., \young⁢(1111,22,33)\young11112233\young(1111,22,33)( 1111 , 22 , 33 ). The group GLksubscriptGL𝑘\textnormal{GL}_{k}GL start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT acts on the space ℂ⁢[x1,…,xk]dℂsubscriptsubscript𝑥1…subscript𝑥𝑘𝑑\mathbb{C}[x_{1},\ldots,x_{k}]_{d}blackboard_C [ italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT of homogeneous polynomials of degree d𝑑ditalic_d on ℂksuperscriptℂ𝑘\mathbb{C}^{k}blackboard_C start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT by linear change of coordinates. This action induces, again by linear change of coordinates, an action on the space of metapolynomials with format (δ,d,k)𝛿𝑑𝑘(\delta,d,k)( italic_δ , italic_d , italic_k ) for every δ𝛿\deltaitalic_δ. For instance, the change of basis swapping the two coordinates on ℂ2superscriptℂ2\mathbb{C}^{2}blackboard_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, defines the change of basis on ℂ⁢[x0,x1]2ℂsubscriptsubscript𝑥0subscript𝑥12\mathbb{C}[x_{0},x_{1}]_{2}blackboard_C [ italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT obtained by exchanging x0subscript𝑥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and x1subscript𝑥1x_{1}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. This induces a linear change of coordinates on ℂ⁢[c20,c11,c02]ℂsubscript𝑐20subscript𝑐11subscript𝑐02\mathbb{C}[c_{20},c_{11},c_{02}]blackboard_C [ italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT ] which exchanges c20subscript𝑐20c_{20}italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT and c02subscript𝑐02c_{02}italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT and leaves c11subscript𝑐11c_{11}italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT fixed. The discriminant c112−4⁢c02⁢c20superscriptsubscript𝑐1124subscript𝑐02subscript𝑐20c_{11}^{2}-4c_{02}c_{20}italic_c start_POSTSUBSCRIPT 11 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 4 italic_c start_POSTSUBSCRIPT 02 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 20 end_POSTSUBSCRIPT is sent to itself by this change of coordinates. More precisely the group actions are defined as follows. For every homogeneous degree d𝑑ditalic_d polynomial f𝑓fitalic_f in k𝑘kitalic_k variables and every g∈GLk𝑔subscriptGL𝑘g\in\textnormal{GL}_{k}italic_g ∈ GL start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, the polynomial g⋅f⋅𝑔𝑓g\cdot fitalic_g ⋅ italic_f is defined by (g⋅f)⁢(x)=f⁢(g−1⁢x)⋅𝑔𝑓𝑥𝑓superscript𝑔1𝑥(g\cdot f)(x)=f(g^{-1}x)( italic_g ⋅ italic_f ) ( italic_x ) = italic_f ( italic_g start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_x ) for every x∈ℂk𝑥superscriptℂ𝑘x\in\mathbb{C}^{k}italic_x ∈ blackboard_C start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT. Similarly, for every format (δ,d,k)𝛿𝑑𝑘(\delta,d,k)( italic_δ , italic_d , italic_k ) metapolynomial ΔΔ\Deltaroman_Δ, the metapolynomial g⋅Δ⋅𝑔Δg\cdot\Deltaitalic_g ⋅ roman_Δ is defined by (g⋅Δ)⁢(f)=Δ⁢(g−1⋅f)⋅𝑔Δ𝑓Δ⋅superscript𝑔1𝑓(g\cdot\Delta)(f)=\Delta(g^{-1}\cdot f)( italic_g ⋅ roman_Δ ) ( italic_f ) = roman_Δ ( italic_g start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ⋅ italic_f ) for every homogeneous degree d𝑑ditalic_d polynomial f𝑓fitalic_f. The details about this action are provided in Section 4. The vector space of metapolynomials of format (δ,d,k)𝛿𝑑𝑘(\delta,d,k)( italic_δ , italic_d , italic_k ) is closed under this action of GLksubscriptGL𝑘\textnormal{GL}_{k}GL start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT, and it decomposes into a direct sum of subspaces which are also closed under the action of GLksubscriptGL𝑘\textnormal{GL}_{k}GL start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT: these subspaces are called isotypic components and they are in one to one correspondence with partitions λ⊢kδd\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}_{k}\,}{\scalebox{1.2}[0.7]{ % $\vdash$}_{k}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}_{k}\,}{% \scalebox{0.5}{\scalebox{1.2}[0.7]{$\vdash$}}_{k}\,}{\delta d}italic_λ ⊢ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_δ italic_d. The summand corresponding to the partition λ𝜆\lambdaitalic_λ is called the λ𝜆\lambdaitalic_λ-isotypic component. This is called the isotypic decomposition. Each λ𝜆\lambdaitalic_λ-isotypic component decomposes even further into a direct sum of subspaces with one summand for each semistandard tableau T𝑇Titalic_T of shape λ𝜆\lambdaitalic_λ. We call the component for T𝑇Titalic_T the T𝑇Titalic_T-isotypic component. If T𝑇Titalic_T is a superstandard tableau of shape λ𝜆\lambdaitalic_λ, then the corresponding T𝑇Titalic_T-isotypic component is called the highest weight metapolynomial vector space of weight λ𝜆\lambdaitalic_λ. Equivalently, a highest weight vector of weight λ𝜆\lambdaitalic_λ is a metapolynomial ΔΔ\Deltaroman_Δ with g⋅Δ=t1λ1⁢⋯⁢tkλk⁢Δ⋅𝑔Δsuperscriptsubscript𝑡1subscript𝜆1⋯superscriptsubscript𝑡𝑘subscript𝜆𝑘Δg\cdot\Delta=t_{1}^{\lambda_{1}}\cdots t_{k}^{\lambda_{k}}\Deltaitalic_g ⋅ roman_Δ = italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ⋯ italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_POSTSUPERSCRIPT roman_Δ, for every g∈GLk𝑔subscriptGL𝑘g\in\textnormal{GL}_{k}italic_g ∈ GL start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT upper triangular with t1,…,tksubscript𝑡1…subscript𝑡𝑘t_{1},\ldots,t_{k}italic_t start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_t start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT on the main diagonal. The λ𝜆\lambdaitalic_λ-isotypic component is known to be the linear span of the union of the orbits of all its highest weight vectors. For example (not easily verifiable by hand, see Example 5.4), the space of metapolynomials of format (δ,d,k)=(3,2,3)𝛿𝑑𝑘323(\delta,d,k)=(3,2,3)( italic_δ , italic_d , italic_k ) = ( 3 , 2 , 3 ) decomposes into three nonzero isotypic components, corresponding to partitions (6,0,0)600(6,0,0)( 6 , 0 , 0 ), (4,2,0)420(4,2,0)( 4 , 2 , 0 ) and (2,2,2)222(2,2,2)( 2 , 2 , 2 ) of δ⋅d=6⋅𝛿𝑑6\delta\cdot d=6italic_δ ⋅ italic_d = 6. The isotypic component (4,2,0)420(4,2,0)( 4 , 2 , 0 ) further decomposes into three T𝑇Titalic_T-isotypic components for the three semistandard tableaux of shape (4,2,0)420(4,2,0)( 4 , 2 , 0 ): \young⁢(1122,33)\young112233\young(1122,33)( 1122 , 33 ), \young⁢(1123,23)\young112323\young(1123,23)( 1123 , 23 ), \young⁢(1133,22)\young113322\young(1133,22)( 1133 , 22 ). The metapolynomial Δ=c2,0,0⁢c0,2,0⁢c0,0,2Δsubscript𝑐200subscript𝑐020subscript𝑐002\Delta=c_{2,0,0}c_{0,2,0}c_{0,0,2}roman_Δ = italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT can be written according to this decomposition as 60⁢Δ60Δ\displaystyle 60\,\Delta60 roman_Δ =\displaystyle== 2⁢(c1,0,12⁢c0,2,0+2⁢c1,1,0⁢c1,0,1⁢c0,1,1+c2,0,0⁢c0,1,12+c1,1,02⁢c0,0,2+2⁢c2,0,0⁢c0,2,0⁢c0,0,2)2superscriptsubscript𝑐1012subscript𝑐0202subscript𝑐110subscript𝑐101subscript𝑐011subscript𝑐200superscriptsubscript𝑐0112superscriptsubscript𝑐1102subscript𝑐0022subscript𝑐200subscript𝑐020subscript𝑐002\displaystyle 2\big{(}c_{1,0,1}^{2}c_{0,2,0}+2c_{1,1,0}c_{1,0,1}c_{0,1,1}+c_{2% ,0,0}c_{0,1,1}^{2}+c_{1,1,0}^{2}c_{0,0,2}+2c_{2,0,0}c_{0,2,0}c_{0,0,2}\big{)}2 ( italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT + 2 italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT + italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT + 2 italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT ) +\displaystyle++ [ 2(−c0,2,0c1,0,12−2c0,1,1c1,0,1c1,1,0+4c0,0,2c1,1,02−c0,1,12c2,0,0+8c0,0,2c0,2,0c2,0,0)\displaystyle\Big{[}\ 2\big{(}-c_{0,2,0}c_{1,0,1}^{2}-2c_{0,1,1}c_{1,0,1}c_{1,% 1,0}+4c_{0,0,2}c_{1,1,0}^{2}-c_{0,1,1}^{2}c_{2,0,0}+8c_{0,0,2}c_{0,2,0}c_{2,0,% 0}\big{)}[ 2 ( - italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 2 italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT + 4 italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT + 8 italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT ) +\displaystyle++ 00\displaystyle\phantom{\Big{[}\ }0 +\displaystyle++ 5(c0,2,0c1,0,12−c0,1,1c1,0,1c1,1,0−c0,0,2c1,1,02+c0,1,12c2,0,0+4c0,0,2c0,2,0c2,0,0)]\displaystyle\phantom{\Big{[}\ }5\big{(}c_{0,2,0}c_{1,0,1}^{2}-c_{0,1,1}c_{1,0% ,1}c_{1,1,0}-c_{0,0,2}c_{1,1,0}^{2}+c_{0,1,1}^{2}c_{2,0,0}+4c_{0,0,2}c_{0,2,0}% c_{2,0,0}\big{)}\ \Big{]}5 ( italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT + 4 italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT ) ] +\displaystyle++ 5⁢(−c1,0,12⁢c0,2,0+c1,1,0⁢c1,0,1⁢c0,1,1−c2,0,0⁢c0,1,12−c1,1,02⁢c0,0,2+4⁢c2,0,0⁢c0,2,0⁢c0,0,2),5superscriptsubscript𝑐1012subscript𝑐020subscript𝑐110subscript𝑐101subscript𝑐011subscript𝑐200superscriptsubscript𝑐0112superscriptsubscript𝑐1102subscript𝑐0024subscript𝑐200subscript𝑐020subscript𝑐002\displaystyle 5\big{(}-c_{1,0,1}^{2}c_{0,2,0}+c_{1,1,0}c_{1,0,1}c_{0,1,1}-c_{2% ,0,0}c_{0,1,1}^{2}-c_{1,1,0}^{2}c_{0,0,2}+4c_{2,0,0}c_{0,2,0}c_{0,0,2}\big{)},5 ( - italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT + italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 1 , 0 , 1 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT - italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 1 , 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_c start_POSTSUBSCRIPT 1 , 1 , 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT + 4 italic_c start_POSTSUBSCRIPT 2 , 0 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 2 , 0 end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT 0 , 0 , 2 end_POSTSUBSCRIPT ) , where the five summands from top to bottom are \young⁢(112233)\young112233\young(112233)( 112233 )-isotypic, \young⁢(1122,33)\young112233\young(1122,33)( 1122 , 33 )-isotypic, \young⁢(1123,23)\young112323\young(1123,23)( 1123 , 23 )-isotypic, \young⁢(1133,22)\young113322\young(1133,22)( 1133 , 22 )-isotypic, and \young⁢(11,22,33)\young112233\young(11,22,33)( 11 , 22 , 33 )-isotypic, respectively. The fifth summand is a highest weight vector, because \young⁢(11,22,33)\young112233\young(11,22,33)( 11 , 22 , 33 ) is superstandard. All summands have weight (2,2,2), because ΔΔ\Deltaroman_Δ has weight (2,2,2). Let ℂ⁢[x1,…,xk]dℂsubscriptsubscript𝑥1…subscript𝑥𝑘𝑑\mathbb{C}[x_{1},\ldots,x_{k}]_{d}blackboard_C [ italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT denote the space of homogeneous degree d𝑑ditalic_d polynomials in the variables x1,…,xksubscript𝑥1…subscript𝑥𝑘x_{1},\ldots,x_{k}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. Let ℕℕ\mathbb{N}blackboard_N denote the set of natural numbers including zero. Theorem 1.1 (Main theorem). Let Δ:ℂ⁢[x1,…,xk]d→ℂ:Δ→ℂsubscriptsubscript𝑥1…subscript𝑥𝑘𝑑ℂ\Delta\colon\mathbb{C}[x_{1},\dots,x_{k}]_{d}\to\mathbb{C}roman_Δ : blackboard_C [ italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ] start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT → blackboard_C be a metapolynomial of format (δ,d,k)𝛿𝑑𝑘(\delta,d,k)( italic_δ , italic_d , italic_k ) computed by an algebraic circuit of size s𝑠sitalic_s. Then 1. For every weight μ∈ℕk𝜇superscriptℕ𝑘\mu\in\mathbb{N}^{k}italic_μ ∈ blackboard_N start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT, |μ|=d⁢δ𝜇𝑑𝛿|\mu|=d\delta| italic_μ | = italic_d italic_δ, the projection of ΔΔ\Deltaroman_Δ onto the weight space of weight μ𝜇\muitalic_μ can be computed by a circuit of size O⁢(s⁢(δ⁢d)2⁢k3)𝑂𝑠superscript𝛿𝑑2superscript𝑘3O(s(\delta d)^{2k^{3}})italic_O ( italic_s ( italic_δ italic_d ) start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). 2. For every partition λ⊢d⁢δproves𝜆𝑑𝛿\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}\,}{\scalebox{1.2}[0.7]{ $% \vdash$}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}\,}{\scalebox{0.5}{% \scalebox{1.2}[0.7]{$\vdash$}}\,}d\deltaitalic_λ ⊢ italic_d italic_δ the projection of ΔΔ\Deltaroman_Δ onto the λ𝜆\lambdaitalic_λ-isotypic component can be computed by a circuit of size O⁢(s⁢k2⁢k2⁢(δ⁢d)2⁢k3)𝑂𝑠superscript𝑘2superscript𝑘2superscript𝛿𝑑2superscript𝑘3O(sk^{2k^{2}}(\delta d)^{2k^{3}})italic_O ( italic_s italic_k start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_δ italic_d ) start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). 3. For every partition λ⊢d⁢δproves𝜆𝑑𝛿\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}\,}{\scalebox{1.2}[0.7]{ $% \vdash$}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}\,}{\scalebox{0.5}{% \scalebox{1.2}[0.7]{$\vdash$}}\,}d\deltaitalic_λ ⊢ italic_d italic_δ the projection of ΔΔ\Deltaroman_Δ onto the highest weight space of weight λ𝜆\lambdaitalic_λ can be computed by a circuit of size O⁢(s⁢(k+1)2⁢k2⁢(δ⁢d)2⁢k3)𝑂𝑠superscript𝑘12superscript𝑘2superscript𝛿𝑑2superscript𝑘3O(s(k+1)^{2k^{2}}(\delta d)^{2k^{3}})italic_O ( italic_s ( italic_k + 1 ) start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_δ italic_d ) start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). 4. For every semistandard tableau T𝑇Titalic_T of shape λ⊢d⁢δproves𝜆𝑑𝛿\lambda\mathchoice{\scalebox{1.2}[0.7]{ $\vdash$}\,}{\scalebox{1.2}[0.7]{ $% \vdash$}\,}{\scalebox{0.7}{\scalebox{1.2}[0.7]{$\vdash$}}\,}{\scalebox{0.5}{% \scalebox{1.2}[0.7]{$\vdash$}}\,}d\deltaitalic_λ ⊢ italic_d italic_δ the projection of ΔΔ\Deltaroman_Δ onto the T𝑇Titalic_T-isotypic space can be computed by a circuit of size O⁢(s⁢k2⁢k2⁢(δ⁢d)2⁢k4)𝑂𝑠superscript𝑘2superscript𝑘2superscript𝛿𝑑2superscript𝑘4O(sk^{2k^{2}}(\delta d)^{2k^{4}})italic_O ( italic_s italic_k start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_δ italic_d ) start_POSTSUPERSCRIPT 2 italic_k start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). Remark 1.2. In general, algebraic complexity classes are defined for possibly non-homogeneous polynomials. In this paper, we assume that polynomials and metapolynomials are homogeneous. However, one can lift the results to the nonhomogeneous setting as follows. A polynomial f⁢(x1,…,xk)𝑓subscript𝑥1…subscript𝑥𝑘f(x_{1},\ldots,x_{k})italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) is called homogeneous if all its monomials have the same degree. For d≥deg⁡(f)𝑑degree𝑓d\geq\deg(f)italic_d ≥ roman_deg ( italic_f ), define the degree d𝑑ditalic_d homogenization f♯⁢d⁢(x0,x1,…,xk):=x0d⁢f⁢(x1/x0,…,xk/x0).assignsuperscript𝑓♯𝑑subscript𝑥0subscript𝑥1…subscript𝑥𝑘superscriptsubscript𝑥0𝑑𝑓subscript𝑥1subscript𝑥0…subscript𝑥𝑘subscript𝑥0f^{\sharp d}(x_{0},x_{1},\ldots,x_{k}):=x_{0}^{d}f(x_{1}/x_{0},\ldots,x_{k}/x_% {0}).italic_f start_POSTSUPERSCRIPT ♯ italic_d end_POSTSUPERSCRIPT ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) := italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT italic_f ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT / italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT / italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) . If f𝑓fitalic_f has an algebraic circuit of size s𝑠sitalic_s, then f♯⁢dsuperscript𝑓♯𝑑f^{\sharp d}italic_f start_POSTSUPERSCRIPT ♯ italic_d end_POSTSUPERSCRIPT has an algebraic circuit of size at most O⁢(s⁢d)𝑂𝑠𝑑O(sd)italic_O ( italic_s italic_d ): s⁢(d+1)𝑠𝑑1s(d+1)italic_s ( italic_d + 1 ) for extracting the homogeneous parts of f𝑓fitalic_f via interpolation, d𝑑ditalic_d operations to compute all values x0,x02,…,x0dsubscript𝑥0superscriptsubscript𝑥02…superscriptsubscript𝑥0𝑑x_{0},x_{0}^{2},\ldots,x_{0}^{d}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , … , italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, and another d+1𝑑1d+1italic_d + 1 for multiplying the homogeneous components with the correct powers of x0subscript𝑥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, and a final d𝑑ditalic_d for adding up the results. Given a metapolynomial ΔΔ\Deltaroman_Δ that does not involve x0subscript𝑥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, define Δ♯⁢dsuperscriptΔ♯𝑑\Delta^{\sharp d}roman_Δ start_POSTSUPERSCRIPT ♯ italic_d end_POSTSUPERSCRIPT by replacing every metavariable c𝒊subscript𝑐𝒊c_{\bm{i}}italic_c start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT with c𝒊+(d−|𝒊|,0,0,…)subscript𝑐𝒊𝑑𝒊00…c_{\bm{i}+(d-|\bm{i}|,0,0,\ldots)}italic_c start_POSTSUBSCRIPT bold_italic_i + ( italic_d - | bold_italic_i | , 0 , 0 , … ) end_POSTSUBSCRIPT, and setting every metavariable c𝒊subscript𝑐𝒊c_{\bm{i}}italic_c start_POSTSUBSCRIPT bold_italic_i end_POSTSUBSCRIPT with |𝒊|>d𝒊𝑑|\bm{i}|>d| bold_italic_i | > italic_d to zero. Clearly we have Δ♯⁢d⁢(f♯⁢d)=Δ⁢(f)superscriptΔ♯𝑑superscript𝑓♯𝑑Δ𝑓\Delta^{\sharp d}(f^{\sharp d})=\Delta(f)roman_Δ start_POSTSUPERSCRIPT ♯ italic_d end_POSTSUPERSCRIPT ( italic_f start_POSTSUPERSCRIPT ♯ italic_d end_POSTSUPERSCRIPT ) = roman_Δ ( italic_f ), provided that d≥deg⁡(f)𝑑degree𝑓d\geq\deg(f)italic_d ≥ roman_deg ( italic_f ). Hence, in this paper we can always assume that f𝑓fitalic_f is homogeneous. ∎ Organization of the paper In the first part of Section 2 we illustrate the motivations for studying the circuit complexity of the isotypic components and the highest weight vectors in the space of metapolynomials, in the context of algebraic complexity lower bounds and border complexity classes. In Section 2.5, based on Theorem 1.1 we prove that algebraic natural proofs can without loss of generality be assumed to be isotypic, see Theorem 2.4. Section 3 sketches the main ideas behind Theorem 1.1. In Section 4, we provide an introduction to Lie algebras, universal enveloping algebras, and their representation theory, on which the core of the proof is built. In Section 5.1, we explain the construction of the projection maps used in the proof of the main theorem; we describe the efficient circuit implementation in Section 5.2. In Appendix A, we prove the results of Section 2.5. In Appendix B, we show one part of the proof of the Poincaré–Birkhoff–Witt Theorem (Theorem 4.9); this proof is explicit and can be used to construct the projectors in Theorem 1.1."
https://arxiv.org/html/2411.04073v1,Rescheduling after vehicle failures in the multi-depot rural postman problem with rechargeable and reusable vehicles,"We present a centralized auction algorithm to solve the Multi-Depot Rural Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing on rescheduling arc routing after vehicle failures. The problem involves finding a heuristically obtained best feasible routes for multiple rechargeable and reusable vehicles with capacity constraints capable of performing multiple trips from multiple depots, with the possibility of vehicle failures. Our algorithm auctions the failed trips to active (non-failed) vehicles through local auctioning, modifying initial routes to handle dynamic vehicle failures efficiently. When a failure occurs, the algorithm searches for the best active vehicle to perform the failed trip and inserts the trip into that vehicle’s route, which avoids a complete rescheduling and reduces the computational effort. We compare the algorithm’s solutions against offline optimal solutions obtained from solving a Mixed Integer Linear Programming (MILP) formulation using the Gurobi solver; this formulation assumes that perfect information about the vehicle failures and failure times are given. We derived a set of 257 failure scenarios from arc routing instances in the literature and used them to perform a competitive analysis. For each scenario we used a simulated annealing algorithm to generate an initial set of routes and then used the centralized auction algorithm to reschedule after each vehicle failure. The results demonstrate that the centralized auction algorithm produces solutions that are, in some cases, near-optimal; moreover the execution time for the proposed approach is much more consistent and is, for some instances, orders of magnitude less than the execution time of the Gurobi solver. The theoretical analysis provides an upper bound for the competitive ratio and computational complexity of our algorithm, offering a formal performance guarantee in dynamic failure scenarios.","Unmanned battery-operated rechargeable vehicles are becoming more prevalent in real-world applications due to their cost-effectiveness and efficiency [1, 2]. However, these systems still face significant challenges. The failure rate for drones is approximately 1 in 1,000 flight hours, two orders of magnitude higher than commercial aviation’s 1 in 100,000 flight hours, and sophisticated Unmanned Aerial Vehicle (UAV) systems face an overall failure rate of 25% [3]. These failures can lead to significant delays and disruptions, underscoring the need for improved reliability in unmanned vehicle operations. Although many preventive maintenance approaches have been proposed to increase the reliability of unmanned vehicles [3, 4], any failure during a mission requires changing the mission plan to react to the loss of the vehicle. This paper, therefore, proposes an approach for effectively managing and mitigating the impact of vehicle failures on routing after they occur, specifically addressing the challenges of rerouting and task reallocation to ensure mission completion despite unexpected vehicle breakdowns. In the MD-RPP-RRV, the vehicles have limited capacity (operation time) but can be recharged and reused for multiple trips from multiple depots to traverse a subset of edges (required edges) in a weighted undirected connected graph, minimizing mission time. The maximum time taken by vehicles to traverse all required edges is referred to as mission time or maximum trip time. One of the key assumptions considered in our previous study [5] to solve the MD-RPP-RRV was that vehicles do not fail during their trips. In this study of the MD-RPP-RRV with vehicle failures, we relax that assumption and consider that multiple (but not all) vehicles might fail randomly during their trips. This study developed and evaluated a rescheduling approach that reacts to vehicle failures; it requires no information about the vehicle failures before the vehicles begin following their routes. Studying the MD-RPP-RRV with vehicle failures is crucial for addressing real-world challenges in applications like parcel delivery, infrastructure inspection, and surveillance, where unmanned vehicles may encounter failures during operation, necessitating the development of quick rerouting approaches for remaining active vehicles to ensure mission completion. The MD-RPP-RRV is NP-hard to solve [5] as it generalizes the RPP, which is proven to be NP-hard [6]. In its simplest case, with a single depot and single trip, the MD-RPP-RRV reduces to the RPP. Hence, solving the MD-RPP-RRV with vehicle failures poses significant computational challenges due to the additional complexities introduced by random vehicle failures. This paper proposes a centralized auction algorithm to address the MD-RPP-RRV with vehicle failures. We chose a centralized approach over decentralized methods due to its ability to maintain a global perspective, enabling quicker decision-making and more efficient task reallocation essential for handling multiple random vehicle failures dynamically. Our approach efficiently reassigns trips that a failed vehicle was supposed to complete (considered as tasks) to the remaining active vehicles (considered as agents) with the objective of minimizing the increase in mission time. To evaluate the performance of our proposed algorithm, we compared its solutions against offline optimal solutions obtained from solving the Mixed Integer Linear Programming (MILP) formulation using the Gurobi optimizer with vehicle failures known beforehand. We also empirically and theoretically analyzed the competitive ratio to assess the proposed algorithm’s solution quality relative to the offline optimal solution. The main contributions of this paper are the following: 1. A centralized auction algorithm that reformulates the MD-RPP-RRV as a variant of the Generalized Assignment Problem (GAP) [25]. This approach efficiently handles dynamic vehicle failures by reassigning tasks without complete rerouting, reducing computational complexity. Our method addresses a gap in existing auction approaches [34] by applying them to dynamic failures in arc routing problems, specifically the MD-RPP-RRV, which has not been previously explored in this context. This algorithm extends centralized auction methods [36, 37] to handle more complex task allocation scenarios in the MD-RPP-RRV context in the following ways: (a) Assigning multiple failed trips (tasks) to a single vehicle (agent). (b) Dynamically reallocating trips from failed vehicles to active ones during the mission, thereby adapting to changes in the available vehicle fleet size due to failures. This approach addresses limitations in existing methods that typically assign only one task per agent or assume a fixed number of agents throughout the mission. 2. Experimental results that describe the quality of the solutions that the approach generates and the execution time required. 3. A theoretical upper bound for the competitive ratio of our proposed centralized auction algorithm to solve the MD-RPP-RRV with vehicle failures. This analysis provides a formal performance guarantee for our algorithm in dynamic failure scenarios. The remainder of this paper is organized as follows: Section 2 presents a literature review of related works. Section 3 provides the assumptions and presents a MILP formulation for the MD-RPP-RRV with known vehicle failures and failure times. Section 4 describes the proposed centralized auction algorithm. Section 5 presents our experimental results. It details the testing of our proposed algorithm on failure scenarios created from benchmark instances. It also compares the quality of the solutions with offline optimal solutions that were obtained by solving the MILP formulation using the Gurobi solver. Section 6 concludes the paper."
https://arxiv.org/html/2411.03813v1,On the satisfiability of random3333-SAT formulaswithk𝑘kitalic_k-wise independent clauses,"The problem of identifying the satisfiability threshold of random 3333-SAT formulas has received a lot of attention during the last decades and has inspired the study of other threshold phenomena in random combinatorial structures. The classical assumption in this line of research is that, for a given set of n𝑛nitalic_n Boolean variables, each clause is drawn uniformly at random among all sets of three literals from these variables, independently from other clauses. Here, we keep the uniform distribution of each clause, but deviate significantly from the independence assumption and consider richer families of probability distributions. For integer parameters n𝑛nitalic_n, m𝑚mitalic_m, and k𝑘kitalic_k, we denote by ℱk⁢(n,m)subscriptℱ𝑘𝑛𝑚\mathcal{F}_{k}(n,m)caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) the family of probability distributions that produce formulas with m𝑚mitalic_m clauses, each selected uniformly at random from all sets of three literals from the n𝑛nitalic_n variables, so that the clauses are k𝑘kitalic_k-wise independent. Our aim is to make general statements about the satisfiability or unsatisfiability of formulas produced by distributions in ℱk⁢(n,m)subscriptℱ𝑘𝑛𝑚\mathcal{F}_{k}(n,m)caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) for different values of the parameters n𝑛nitalic_n, m𝑚mitalic_m, and k𝑘kitalic_k.Our technical results are as follows: First, all probability distributions in ℱ2⁢(n,m)subscriptℱ2𝑛𝑚\mathcal{F}_{2}(n,m)caligraphic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_n , italic_m ) with m∈Ω⁢(n3)𝑚Ωsuperscript𝑛3m\in\Omega(n^{3})italic_m ∈ roman_Ω ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) return unsatisfiable formulas with high probability. This result is tight. We show that there exists a probability distribution 𝒟∈ℱ3⁢(n,m)𝒟subscriptℱ3𝑛𝑚\mathcal{D}\in\mathcal{F}_{3}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_n , italic_m ) with m∈O⁢(n3)𝑚𝑂superscript𝑛3m\in O(n^{3})italic_m ∈ italic_O ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) so that a random formula drawn from 𝒟𝒟\mathcal{D}caligraphic_D is almost always satisfiable. In contrast, for m=Ω⁢(n2)𝑚Ωsuperscript𝑛2m=\Omega(n^{2})italic_m = roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), any probability distribution 𝒟∈ℱ4⁢(n,m)𝒟subscriptℱ4𝑛𝑚\mathcal{D}\in\mathcal{F}_{4}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_n , italic_m ) returns an unsatisfiable formula with high probability. This is our most surprising and technically involved result. Finally, for any integer k≥2𝑘2k\geq 2italic_k ≥ 2, any probability distribution 𝒟∈ℱk⁢(n,m)𝒟subscriptℱ𝑘𝑛𝑚\mathcal{D}\in\mathcal{F}_{k}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) with m=O⁢(n1−1/k)𝑚𝑂superscript𝑛11𝑘m=O(n^{1-1/k})italic_m = italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ) returns a satisfiable formula with high probability.","Satisfiability of propositional formulas (SAT) is one of the most renowned problems in theoretical computer science. It appeared in the first lists of NP-complete problems independently proposed by Cook and Levin, and is pivotal for many developments in modern complexity theory. Today, many lower bounds on the running time of algorithms rely on the Exponential Time Hypothesis for solving SAT [11, 18, 36, 37]. On the practical side, SAT solvers are frequently deployed in hardware circuit design, model checking, program verification, automated planning and scheduling, as well as in solving real-life instantiations of combinatorial optimization problems such as FCC spectrum auctions. Modern SAT solvers often find solutions to large industrial instances with thousands or even millions of variables despite the NP-hardness of the problem. However, there is still a large discrepancy between the performance of SAT solvers on those instances and theoretical average-case predictions, which have been studied in great depth under the line of research on random SAT. Random SAT. A j𝑗jitalic_j-CNF formula ϕitalic-ϕ\phiitalic_ϕ over n𝑛nitalic_n variables is composed of m𝑚mitalic_m OR-clauses, each containing exactly j𝑗jitalic_j literals of j𝑗jitalic_j different variables. In the most commonly studied random SAT model, a formula ϕitalic-ϕ\phiitalic_ϕ is generated uniformly at random from all possible j𝑗jitalic_j-CNF formulas over n𝑛nitalic_n variables and m𝑚mitalic_m clauses. The most prominent theoretical question related to random SAT is to identify the satisfiability threshold rjsubscript𝑟𝑗r_{j}italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT such that limn→∞𝐏𝐫⁡[ϕ⁢ is satisfiable]subscript→𝑛𝐏𝐫italic-ϕ is satisfiable\lim_{n\to\infty}\operatorname{\mathbf{Pr}}\mathchoice{\left[\phi\text{ is % satisfiable}\right]}{[\phi\text{ is satisfiable}]}{[\phi\text{ is satisfiable}% ]}{[\phi\text{ is satisfiable}]}roman_lim start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT bold_Pr [ italic_ϕ is satisfiable ] is equal to 00 when m/n>rj𝑚𝑛subscript𝑟𝑗m/n>r_{j}italic_m / italic_n > italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT, and equal to 1111 when m/n<rj𝑚𝑛subscript𝑟𝑗m/n<r_{j}italic_m / italic_n < italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT. It has been established [15] that 2222-SAT has r2=1subscript𝑟21r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1, and its phase transition window [10] is m∈[n−Θ⁢(n1/3),n+Θ⁢(n1/3)]𝑚𝑛Θsuperscript𝑛13𝑛Θsuperscript𝑛13m\in[n-\Theta(n^{1/3}),n+\Theta(n^{1/3})]italic_m ∈ [ italic_n - roman_Θ ( italic_n start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT ) , italic_n + roman_Θ ( italic_n start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT ) ]. For j≥3𝑗3j\geq 3italic_j ≥ 3, the asymptotic j𝑗jitalic_j-SAT threshold was shown to be 2j⁢log⁡2−12⁢(1+log⁡2)±oj⁢(1)plus-or-minussuperscript2𝑗21212subscript𝑜𝑗12^{j}\log 2-\frac{1}{2}(1+\log 2)\pm o_{j}(1)2 start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT roman_log 2 - divide start_ARG 1 end_ARG start_ARG 2 end_ARG ( 1 + roman_log 2 ) ± italic_o start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( 1 ) as j→∞→𝑗j\to\inftyitalic_j → ∞ [17] (improving previous results from [3]), while for large enough j𝑗jitalic_j the exact value of rjsubscript𝑟𝑗r_{j}italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT was determined in [20]. However, the question of identifying rjsubscript𝑟𝑗r_{j}italic_r start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT for small values of j𝑗jitalic_j remains open. In particular, random 3333-SAT has attracted a lot of attention. For the lower bound part, it has been shown in a series of papers [15, 12, 32, 1, 35, 39] that r3≥3.52subscript𝑟33.52r_{3}\geq 3.52italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ≥ 3.52 (the currently best known bound is due to [35, 39]). The upper bound part is studied by [27, 38, 21, 19]; the currently best known bound is r3<4.49subscript𝑟34.49r_{3}<4.49italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT < 4.49 due to [19]. The estimate r3≈4.26subscript𝑟34.26r_{3}\approx 4.26italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ≈ 4.26 was derived from numerical experiments [40] (see also [14, 41]). A more recent line of work [29, 30, 31, 42] extends the standard model of random j𝑗jitalic_j-SAT to non-uniform distributions. Their motivation comes from the empirical observation that, in practice, CNF formulas often have rather different frequencies/probabilities for the n𝑛nitalic_n variables to appear in each clause (following a power-law distribution instead of a uniform one). Namely, Friedrich and Rothenberger [31] proposed a non-uniform random model, where the literals {xi,xi¯}i∈[n]subscriptsubscript𝑥𝑖¯subscript𝑥𝑖𝑖delimited-[]𝑛\{x_{i},\overline{x_{i}}\}_{i\in[n]}{ italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , over¯ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG } start_POSTSUBSCRIPT italic_i ∈ [ italic_n ] end_POSTSUBSCRIPT are selected independently at random in each clause c𝑐citalic_c of the random j𝑗jitalic_j-CNF with 𝐏𝐫⁡[xi∈c]=𝐏𝐫⁡[xi¯∈c]=pi𝐏𝐫subscript𝑥𝑖𝑐𝐏𝐫¯subscript𝑥𝑖𝑐subscript𝑝𝑖\operatorname{\mathbf{Pr}}\mathchoice{\left[x_{i}\in c\right]}{[x_{i}\in c]}{[% x_{i}\in c]}{[x_{i}\in c]}=\operatorname{\mathbf{Pr}}\mathchoice{\left[% \overline{x_{i}}\in c\right]}{[\overline{x_{i}}\in c]}{[\overline{x_{i}}\in c]% }{[\overline{x_{i}}\in c]}=p_{i}bold_Pr [ italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_c ] = bold_Pr [ over¯ start_ARG italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ∈ italic_c ] = italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and where probabilities 𝐩=(pi)i∈[n]𝐩subscriptsubscript𝑝𝑖𝑖delimited-[]𝑛\mathbf{p}=(p_{i})_{i\in[n]}bold_p = ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i ∈ [ italic_n ] end_POSTSUBSCRIPT may vary across different variables. They find satisfiability threshold r2⁢(𝐩)subscript𝑟2𝐩r_{2}(\mathbf{p})italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( bold_p ) of non-uniform random 2222-SAT for certain regimes depending on 𝐩𝐩\mathbf{p}bold_p. However, the non-uniform model of [31] does not capture the community biases/correlations (i.e., the fact that certain variables are more likely to appear together in a clause), which are often observed in practice [6]. This leads us to the question of whether it is possible to relax the strong independence assumption in the existing random SAT literature. Relaxation of independence. We first observe that it does not make much sense to study distributions of SAT formulas with arbitrary correlations over the clauses. Indeed, by allowing correlation between several clauses, one may enforce that the random formula ϕitalic-ϕ\phiitalic_ϕ contains large fixed sub-formulas corresponding to NP-hard SAT variants. This would be at odds with our goal of studying average-case complexity. Therefore, we must keep a certain degree of independence in the distribution of instances. We propose to consider the relaxation of mutual independence over m𝑚mitalic_m clauses in a random formula ϕitalic-ϕ\phiitalic_ϕ to k𝑘kitalic_k-wise independence for a small constant k𝑘kitalic_k. To keep the new model tractable, we focus on 3333-SAT and uniform distribution of literals within each clause. I.e., we assume that (i) every 3333-OR-clause c𝑐citalic_c of a random 3333-CNF formula ϕitalic-ϕ\phiitalic_ϕ has three literals of three distinct variables drawn uniformly at random among all such triplets of literals and that (ii) given this marginal distribution of each clause c∼Funi.similar-to𝑐subscript𝐹uni.c\sim F_{\text{uni.}}italic_c ∼ italic_F start_POSTSUBSCRIPT uni. end_POSTSUBSCRIPT, the distribution 𝒟𝒟\mathcal{D}caligraphic_D over the clause set C𝐶Citalic_C in ϕitalic-ϕ\phiitalic_ϕ is only k𝑘kitalic_k-wise independent instead of the mutually independent distribution 𝒟Ind.=(Funi.)⊗msubscript𝒟Ind.superscriptsubscript𝐹uni.tensor-productabsent𝑚\mathcal{D}_{\text{Ind.}}=\left(F_{\text{uni.}}\right)^{\otimes m}caligraphic_D start_POSTSUBSCRIPT Ind. end_POSTSUBSCRIPT = ( italic_F start_POSTSUBSCRIPT uni. end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊗ italic_m end_POSTSUPERSCRIPT in the standard model. This is a natural generalization that has been considered in a number of different settings but, to the best of our knowledge, not in the context of random SAT. Note that the smaller k𝑘kitalic_k is, the bigger the set of possible distributions 𝒟𝒟\mathcal{D}caligraphic_D. Furthermore, for small values of k𝑘kitalic_k, a k𝑘kitalic_k-wise independent distribution 𝒟𝒟\mathcal{D}caligraphic_D can still capture a large class of dependencies among clauses but at the same time does not allow correlation between any k𝑘kitalic_k-tuples of clauses. In mathematical terms, the family of discrete k𝑘kitalic_k-wise independent distributions naturally appears when we map the set of distributions to the set of their low-degree moments. Specifically, if a distribution 𝒟𝒟\mathcal{D}caligraphic_D is supported on the n𝑛nitalic_n-dimensional binary cube111Similar moment functions can be defined for any distribution with discrete marginals. supp⁢(D)={−1,1}nsupp𝐷superscript11𝑛\texttt{supp}(D)=\{-1,1\}^{n}supp ( italic_D ) = { - 1 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, then all its moments of degree up to k𝑘kitalic_k can be described as μ⁢(D)=(𝐄⁡[∏i∈Sxi])|S|≤k𝜇𝐷subscript𝐄subscriptproduct𝑖𝑆subscript𝑥𝑖𝑆𝑘\mu(D)=(\operatorname{\mathbf{E}}\mathchoice{\left[\prod_{i\in S}x_{i}\right]}% {[\prod_{i\in S}x_{i}]}{[\prod_{i\in S}x_{i}]}{[\prod_{i\in S}x_{i}]})_{|S|% \leq k}italic_μ ( italic_D ) = ( bold_E [ ∏ start_POSTSUBSCRIPT italic_i ∈ italic_S end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ] ) start_POSTSUBSCRIPT | italic_S | ≤ italic_k end_POSTSUBSCRIPT. As low-degree moments (basically, the image of μ𝜇\muitalic_μ) are extremely important in statistical analysis, it is equally important to study the kernel of the aforementioned mapping, which exactly corresponds to the family of k𝑘kitalic_k-wise independent distributions. Let us provide additional justifications of our framework by discussing some of the theoretical work on random 3333SAT and on other settings with similar k𝑘kitalic_k-wise independence relaxation. Pseudo-randomness. Historically, the k𝑘kitalic_k-wise relaxation of independence has been actively used in the literature on derandomization and pseudo-randomness, as it allows to significantly reduce the amount of random bits needed to generate random objects. For example, Alon and Nussboim [5] consider random Erdős-Rényi graphs and examine the minimal degree k𝑘kitalic_k of independence needed to achieve a variety of graph properties and statistics (such as connectivity, existence of perfect matchings, existence of Hamiltonian cycles, clique and chromatic numbers, etc.) that match those in the mutually independent case. Benjamini et al. [9] consider similar questions for monotone boolean functions. The motivation in [5] comes from the fact that there are efficient constructions of k𝑘kitalic_k-wise independent distributions with “low degree of independence” (say k=O⁢(log⁡n)𝑘𝑂𝑛k=O(\log n)italic_k = italic_O ( roman_log italic_n )) that utilize only polylog⁢(n)polylog𝑛\text{polylog}(n)polylog ( italic_n ) random bits, i.e., much fewer than the polynomial number of random bits required to generate mutually independent distributions. While some of this motivation can be applied to our setting of random 3333-SAT, it is a conceptually different story. Indeed, the perspective of pseudo-random generation is through the lenses of “probability theory”, where one controls the distributions and can simply choose one that satisfies necessary conditions such as, e.g., (log⁡n)𝑛(\log n)( roman_log italic_n )-wise independence. On the other hand, our motivation stems from “statistics”, as our ideal model should have a reasonable fit to empirical observations. So, we would like to use as minimal assumptions as possible and study small (constant) degrees of independence. Refutability of 3333-SAT. While the research on lower bounds for random 3333-SAT often comes up with certain simple heuristics that efficiently find a satisfying assignment (see, e.g., the surveys by Achlioptas [2] and Flaxman [26]), it is extremely hard to find an efficient refutation of a unsatisfiable 3333-SAT formula. Indeed, the common approach to refute a given SAT formula is proof in resolution. Chvatal and Szemeredi [16] first showed that a random 3333-CNF formula with m=Θ⁢(n)𝑚Θ𝑛m=\Theta(n)italic_m = roman_Θ ( italic_n ) clauses (which is almost surely unsatisfiable) almost surely admits only exponential size proof in resolution. Later, Ben-Sasson and Wigderson [8] derived similar result for much larger m=O⁢(n3/2−ε)𝑚𝑂superscript𝑛32𝜀m=O(n^{3/2-\varepsilon})italic_m = italic_O ( italic_n start_POSTSUPERSCRIPT 3 / 2 - italic_ε end_POSTSUPERSCRIPT ). On the positive side, [28] gave the first polynomial time algorithm via spectral techniques that almost surely222Refutation in this case is an algorithm with one-sided error: it always refutes the formula correctly by producing certain certificates, or says that the formula might be correct. refutes a random 3333-SAT formula with m=n3/2+ε𝑚superscript𝑛32𝜀m=n^{3/2+\varepsilon}italic_m = italic_n start_POSTSUPERSCRIPT 3 / 2 + italic_ε end_POSTSUPERSCRIPT clauses. The best known bound on m𝑚mitalic_m is due to Feige and Ofek [25] who proved that, for a sufficiently large constant c𝑐citalic_c, random 3333-SAT formulas with m=c⋅n3/2𝑚⋅𝑐superscript𝑛32m=c\cdot n^{3/2}italic_m = italic_c ⋅ italic_n start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT clauses can be almost surely refuted in polynomial time using another spectral graph algorithm. We note that a similar situation (extremely high probability of unsatisfiability for a random formula and inability to efficiently confirm it) is unlikely to happen in our k𝑘kitalic_k-clause independent model for constant k𝑘kitalic_k. Indeed, the main proof approach for dealing with arbitrary k𝑘kitalic_k-wise independent distribution is to define a k𝑘kitalic_k-wise statistic, which differentiates any satisfiable formula from a typical unsatisfiable one. Testing k𝑘kitalic_k-wise independence. The property of k𝑘kitalic_k-wise independence of a distribution with n𝑛nitalic_n components can be tested using nO⁢(k)=p⁢o⁢l⁢y⁢(n)superscript𝑛𝑂𝑘𝑝𝑜𝑙𝑦𝑛n^{O(k)}=poly(n)italic_n start_POSTSUPERSCRIPT italic_O ( italic_k ) end_POSTSUPERSCRIPT = italic_p italic_o italic_l italic_y ( italic_n ) many samples in polynomial time, when k𝑘kitalic_k is a constant [4, 43]. This is a useful property to have, as it allows one to verify with only polynomially many instances of random 3333-SAT, whether these instances conform to k𝑘kitalic_k-wise independence or not. Robust mechanism design. A recent line of work in robust mechanism design also considers families of k𝑘kitalic_k-wise independent Bayesian priors in single and multi-unit auctions [13, 22, 33, 34]. Their motivation is similar to ours, as they also rely on the statistical point of view to justify the extension of the results for mutual independent priors typically assumed in Bayesian mechanism design to k𝑘kitalic_k-wise independent ones. 1.1 Problem formulation We consider random 3333-CNF formulas with n𝑛nitalic_n variables generated from a distribution 𝒟𝒟\mathcal{D}caligraphic_D over m𝑚mitalic_m clauses, where the mutual independence assumption over clauses is relaxed to k𝑘kitalic_k-wise independence. We use the term k𝑘kitalic_k-clause independence to refer to such distributions. We denote such families of distributions by ℱk⁢(n,m)subscriptℱ𝑘𝑛𝑚\mathcal{F}_{k}(n,m)caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ), where each 𝒟∈ℱk⁢(n,m)𝒟subscriptℱ𝑘𝑛𝑚\mathcal{D}\in\mathcal{F}_{k}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) has identical marginals uniformly distributed over all possible OR-clauses and those marginals are only assumed to be k𝑘kitalic_k-wise independent in 𝒟𝒟\mathcal{D}caligraphic_D. We would like to understand the following question for small values of k𝑘kitalic_k: How does the satisfiability threshold r3subscript𝑟3r_{3}italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT of random 3333-SAT formulas behave under any k𝑘kitalic_k-clause independent distribution 𝒟∈ℱk⁢(n,m)𝒟subscriptℱ𝑘𝑛𝑚\mathcal{D}\in\mathcal{F}_{k}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m )? As the distribution 𝒟𝒟\mathcal{D}caligraphic_D is not unique, there might be a large gap between lower and upper estimates of r3subscript𝑟3r_{3}italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT. To this end, we formally define the lower satisfiability threshold LSTk⁢(n)subscriptLST𝑘𝑛\texttt{LST}_{k}(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) as an upper bound on m𝑚mitalic_m, such that a random formula ϕitalic-ϕ\phiitalic_ϕ drawn from a distribution in ℱk⁢(n,m)subscriptℱ𝑘𝑛𝑚\mathcal{F}_{k}(n,m)caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) with m≤LSTk⁢(n)𝑚subscriptLST𝑘𝑛m\leq\texttt{LST}_{k}(n)italic_m ≤ LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) clauses has 𝐏𝐫⁡[ϕ⁢ is satisfiable]≥23𝐏𝐫italic-ϕ is satisfiable23\operatorname{\mathbf{Pr}}\mathchoice{\left[\phi\text{ is satisfiable}\right]}% {[\phi\text{ is satisfiable}]}{[\phi\text{ is satisfiable}]}{[\phi\text{ is % satisfiable}]}\geq\frac{2}{3}bold_Pr [ italic_ϕ is satisfiable ] ≥ divide start_ARG 2 end_ARG start_ARG 3 end_ARG. Similarly, the upper satisfiability threshold USTk⁢(n)subscriptUST𝑘𝑛\texttt{UST}_{k}(n)UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) is a lower bound on m𝑚mitalic_m, such that the random formula ϕitalic-ϕ\phiitalic_ϕ with m≥USTk⁢(n)𝑚subscriptUST𝑘𝑛m\geq\texttt{UST}_{k}(n)italic_m ≥ UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) clauses has 𝐏𝐫⁡[ϕ⁢ is satisfiable]≤13𝐏𝐫italic-ϕ is satisfiable13\operatorname{\mathbf{Pr}}\mathchoice{\left[\phi\text{ is satisfiable}\right]}% {[\phi\text{ is satisfiable}]}{[\phi\text{ is satisfiable}]}{[\phi\text{ is % satisfiable}]}\leq\frac{1}{3}bold_Pr [ italic_ϕ is satisfiable ] ≤ divide start_ARG 1 end_ARG start_ARG 3 end_ARG. What kind of bounds on upper USTk⁢(n)subscriptUST𝑘𝑛\texttt{UST}_{k}(n)UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) and lower LSTk⁢(n)subscriptLST𝑘𝑛\texttt{LST}_{k}(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) thresholds should we expect? Reasonable expectations. The condition 𝒟∈ℱk⁢(n,m)𝒟subscriptℱ𝑘𝑛𝑚\mathcal{D}\in\mathcal{F}_{k}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ) only says something about configurations of at most k𝑘kitalic_k clauses and does not put any other restrictions on the random formula ϕ∼𝒟similar-toitalic-ϕ𝒟\phi\sim\mathcal{D}italic_ϕ ∼ caligraphic_D. As the degree of independence k𝑘kitalic_k is a small constant, any argument that gives bounds on LSTksubscriptLST𝑘\texttt{LST}_{k}LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT or USTksubscriptUST𝑘\texttt{UST}_{k}UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT can only rely on statistics of at most a constant number of clauses. Hence, it is rather likely that bounds on LSTksubscriptLST𝑘\texttt{LST}_{k}LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and USTksubscriptUST𝑘\texttt{UST}_{k}UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT come together with efficient procedures of, respectively, finding a satisfying assignment for a random formula ϕitalic-ϕ\phiitalic_ϕ, or certifying that ϕitalic-ϕ\phiitalic_ϕ is not satisfiable. Hence, given the prior work on random 3333-SAT for 𝒟Ind.∈ℱk⁢(n,m)subscript𝒟Ind.subscriptℱ𝑘𝑛𝑚\mathcal{D}_{\text{Ind.}}\in\mathcal{F}_{k}(n,m)caligraphic_D start_POSTSUBSCRIPT Ind. end_POSTSUBSCRIPT ∈ caligraphic_F start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n , italic_m ), we get the following picture: Upper satisfiability threshold. The best known result for refuting 3333-CNF formulas efficiently is due to Feige and Ofek [25], who show how to do it only for a fairly large number of clauses m=c⋅n3/2𝑚⋅𝑐superscript𝑛32m=c\cdot n^{3/2}italic_m = italic_c ⋅ italic_n start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT. Furthermore, for any smaller number of clauses m=O⁢(n3/2−ε)𝑚𝑂superscript𝑛32𝜀m=O(n^{3/2-\varepsilon})italic_m = italic_O ( italic_n start_POSTSUPERSCRIPT 3 / 2 - italic_ε end_POSTSUPERSCRIPT ), a random 3333-CNF formula is likely to have only exponential in n𝑛nitalic_n proof size for any unsatisfiability proof in resolution [8]. Hence, it is out of reach to aim for a better bound on USTk⁢(n)subscriptUST𝑘𝑛\texttt{UST}_{k}(n)UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) than O⁢(n3/2)𝑂superscript𝑛32O(n^{3/2})italic_O ( italic_n start_POSTSUPERSCRIPT 3 / 2 end_POSTSUPERSCRIPT ) while relying only on k𝑘kitalic_k-wise independence for some constant k𝑘kitalic_k. In fact, the best known positive result on efficiently computable proofs of unsatisfiability in resolution is due to Beame et al. [7], who show that an ordered DLL algorithm executed on a random 3333-SAT instance with m=Ω⁢(n2/log⁡n)𝑚Ωsuperscript𝑛2𝑛m=\Omega(n^{2}/\log n)italic_m = roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / roman_log italic_n ) clauses terminates in polynomial time. Lower satisfiability threshold. As the proofs for the lower bounds on r3subscript𝑟3r_{3}italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT often establish simple procedures that find satisfying assignments with high probability, it is still possible that LSTk⁢(n)subscriptLST𝑘𝑛\texttt{LST}_{k}(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) is of similar order Θ⁢(n)Θ𝑛\Theta(n)roman_Θ ( italic_n ) as the lower bounds on r3subscript𝑟3r_{3}italic_r start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT for 𝒟Ind.subscript𝒟Ind.\mathcal{D}_{\text{Ind.}}caligraphic_D start_POSTSUBSCRIPT Ind. end_POSTSUBSCRIPT. Thus, the most ambitious result would be to show that LSTk⁢(n)≤ck⋅nsubscriptLST𝑘𝑛⋅subscript𝑐𝑘𝑛\texttt{LST}_{k}(n)\leq c_{k}\cdot nLST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) ≤ italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ⋅ italic_n for constant cksubscript𝑐𝑘c_{k}italic_c start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT that increases with k𝑘kitalic_k. A more modest goal is to aim for LSTk⁢(n)=o⁢(n)subscriptLST𝑘𝑛𝑜𝑛\texttt{LST}_{k}(n)=o(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) = italic_o ( italic_n ) for a constant k𝑘kitalic_k, where LSTk⁢(n)→Θ⁢(n)→subscriptLST𝑘𝑛Θ𝑛\texttt{LST}_{k}(n)\to\Theta(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) → roman_Θ ( italic_n ) as k→+∞→𝑘k\to+\inftyitalic_k → + ∞. 1.2 Our results We obtain the following bounds on the lower and upper satisfiability thresholds LSTk⁢(n)subscriptLST𝑘𝑛\texttt{LST}_{k}(n)LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) and USTk⁢(n)subscriptUST𝑘𝑛\texttt{UST}_{k}(n)UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) for various values of k𝑘kitalic_k. Lower satisfiability thresholds. We show (in Theorem 6.1) that LSTk⁢(n)≥Ω⁢(n1−1/k)subscriptLST𝑘𝑛Ωsuperscript𝑛11𝑘\texttt{LST}_{k}(n)\geq\Omega(n^{1-1/k})LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) ≥ roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ) for any k≥2𝑘2k\geq 2italic_k ≥ 2. I.e., any k𝑘kitalic_k-clause independent random formula is satisfiable with high probability if it contains at most O⁢(n1−1/k)𝑂superscript𝑛11𝑘O(n^{1-1/k})italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ) clauses. The argument is simple: for any k𝑘kitalic_k-clause independent distribution, we look at the 3333-uniform hypergraph that corresponds to the variables of a random formula ϕitalic-ϕ\phiitalic_ϕ produced according to this distribution, and argue that this graph does not have Berge-cycles, with high probability. We also provide an informal justification that this bound is asymptotically tight, i.e., that LSTk⁢(n)=O⁢(n1−1/k)subscriptLST𝑘𝑛𝑂superscript𝑛11𝑘\texttt{LST}_{k}(n)=O(n^{1-1/k})LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) = italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ). Specifically, we outline a plausible approach for constructing a k𝑘kitalic_k-clause independent distribution with m=O⁢(n1−1/k)𝑚𝑂superscript𝑛11𝑘m=O(n^{1-1/k})italic_m = italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ) clauses such that most of its formulas are unsatisfiable. Our approach is built upon existing constructions of dense hyper-graphs with large girth. It is interesting to note that, in both the proof of the LSTk⁢(n)=Ω⁢(n1−1/k)subscriptLST𝑘𝑛Ωsuperscript𝑛11𝑘\texttt{LST}_{k}(n)=\Omega(n^{1-1/k})LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) = roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ) result and the approach for showing that LSTk⁢(n)=O⁢(n1−1/k)subscriptLST𝑘𝑛𝑂superscript𝑛11𝑘\texttt{LST}_{k}(n)=O(n^{1-1/k})LST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) = italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 1 / italic_k end_POSTSUPERSCRIPT ), we only need to consider variables and can completely ignore the distribution over the literals. Upper satisfiability thresholds. We first consider small degrees of independence, i.e., k∈{2,3}𝑘23k\in\{2,3\}italic_k ∈ { 2 , 3 }. In both cases, we show that USTk⁢(n)=Θ⁢(n3)subscriptUST𝑘𝑛Θsuperscript𝑛3\texttt{UST}_{k}(n)=\Theta(n^{3})UST start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_n ) = roman_Θ ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ), meaning that one needs almost all possible clauses in a 3333-clause (as well as 2222-clause) independent formula to ensure that it is unsatisfiable (see Theorem 3.1 and Theorem 4.1). The most nontrivial part is to construct the distribution 𝒟∈ℱ3⁢(n,m)𝒟subscriptℱ3𝑛𝑚\mathcal{D}\in\mathcal{F}_{3}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_n , italic_m ) with m=Θ⁢(n3)𝑚Θsuperscript𝑛3m=\Theta(n^{3})italic_m = roman_Θ ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) and 𝐏𝐫⁡[ϕ⁢ is satisfiable]≥23𝐏𝐫italic-ϕ is satisfiable23\operatorname{\mathbf{Pr}}\mathchoice{\left[\phi\text{ is satisfiable}\right]}% {[\phi\text{ is satisfiable}]}{[\phi\text{ is satisfiable}]}{[\phi\text{ is % satisfiable}]}\geq\frac{2}{3}bold_Pr [ italic_ϕ is satisfiable ] ≥ divide start_ARG 2 end_ARG start_ARG 3 end_ARG. Our construction is based on “3333-XOR formulas” (i.e., OR-clauses that have either one or three literals that are satisfied by a randomly planted truth assignment), which aligns well with the intuition developed in previous work [24, 25]. The main technical difficulty is to ensure k𝑘kitalic_k-clause independence by adding a small fraction of unsatisfiable instances and checking all 3333-wise statistics. Our most exciting and technically involved result (see Theorem 5.1) is our proof that UST4⁢(n)=O⁢(n2)subscriptUST4𝑛𝑂superscript𝑛2\texttt{UST}_{4}(n)=O(n^{2})UST start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_n ) = italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), i.e., a random formula ϕ∼𝒟similar-toitalic-ϕ𝒟\phi\sim\mathcal{D}italic_ϕ ∼ caligraphic_D with m=O⁢(n2)𝑚𝑂superscript𝑛2m=O(n^{2})italic_m = italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) clauses is unsatisfiable with large probability for any 4444-clause independent distribution 𝒟∈ℱ4⁢(n,m)𝒟subscriptℱ4𝑛𝑚\mathcal{D}\in\mathcal{F}_{4}(n,m)caligraphic_D ∈ caligraphic_F start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_n , italic_m ). It is worth noting that such a bound is much harder to get under the 4444-wise independence assumption than in the case of a mutually independent distribution 𝒟Ind.subscript𝒟Ind.\mathcal{D}_{\text{Ind.}}caligraphic_D start_POSTSUBSCRIPT Ind. end_POSTSUBSCRIPT. Indeed, Feige and Ofek [25] describe a very simple refutation algorithm for m=Θ⁢(n2)𝑚Θsuperscript𝑛2m=\Theta(n^{2})italic_m = roman_Θ ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) that fixes a variable x𝑥xitalic_x and considers all clauses containing x𝑥xitalic_x or x¯¯𝑥\overline{x}over¯ start_ARG italic_x end_ARG (there will be Θ⁢(n)Θ𝑛\Theta(n)roman_Θ ( italic_n ) such clauses in expectation). Then, after deleting x𝑥xitalic_x (or x¯¯𝑥\overline{x}over¯ start_ARG italic_x end_ARG), one can reduce the problem to the refutation of the respective random 2222-CNF sub-instance, which can be easily verified in polynomial time and has a low satisfiability threshold of r2=1subscript𝑟21r_{2}=1italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 1. This simple approach obviously fails for 4444-clause independent distributions. We instead construct a bipartite multigraph G⁢(ϕ)𝐺italic-ϕG(\phi)italic_G ( italic_ϕ ) between pairs of distinct literals on one side and all singleton literals on the other, in which every OR-clause in ϕitalic-ϕ\phiitalic_ϕ corresponds to three different edges. We then carefully examine the statistic κ⁢(ϕ)𝜅italic-ϕ\kappa(\phi)italic_κ ( italic_ϕ ) that counts K2,2subscript𝐾22K_{2,2}italic_K start_POSTSUBSCRIPT 2 , 2 end_POSTSUBSCRIPT subgraphs in G⁢(ϕ)𝐺italic-ϕG(\phi)italic_G ( italic_ϕ ) for a random ϕ∼𝒟similar-toitalic-ϕ𝒟\phi\sim\mathcal{D}italic_ϕ ∼ caligraphic_D. We find that the expected value of κ⁢(ϕ)𝜅italic-ϕ\kappa(\phi)italic_κ ( italic_ϕ ) for random ϕitalic-ϕ\phiitalic_ϕ is only slightly larger than its absolute minimal value, while at the same time κ⁢(ϕ)𝜅italic-ϕ\kappa(\phi)italic_κ ( italic_ϕ ) is significantly larger than its expectation when ϕitalic-ϕ\phiitalic_ϕ is satisfiable. Our argument bears certain similarities with the argument in [25], which also looked at intersections of two literals between pairs of clauses but used the 3333-XOR principle and a differently constructed non-bipartite graph. 1.3 Roadmap The rest of the paper is structured as follows. We begin with preliminary definitions and notation in Section 2. Then, we warm up with our tight bounds on the upper satisfiability threshold UST2⁢(n)subscriptUST2𝑛\texttt{UST}_{2}(n)UST start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_n ) in Section 3. Our lower bound on UST3⁢(n)subscriptUST3𝑛\texttt{UST}_{3}(n)UST start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ( italic_n ) is proved in Section 4 while our upper bound on UST4⁢(n)subscriptUST4𝑛\texttt{UST}_{4}(n)UST start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ( italic_n ) follows in Section 5. Section 6 is devoted to the study of the lower satisfiability threshold."
https://arxiv.org/html/2411.02936v1,Deriving Nonuniform Lower Bounds from Uniform Nondeterministic Lower Bounds,"Proving complexity lower bounds remains a challenging task: currently, we only know how to prove conditional uniform (algorithm) lower bounds and nonuniform (circuit) lower bounds in restricted circuit models. About a decade ago, Williams (STOC 2010) showed how to derive nonuniform lower bounds from uniform upper bounds: roughly, by designing a fast algorithm for checking satisfiability of circuits, one gets a lower bound for this circuit class. Since then, a number of results of this kind have been proved. For example, Jahanjou et al. (ICALP 2015) and Carmosino et al. (ITCS 2016) proved that if \NSETH fails, then \E\NPsuperscript\E\NP\E^{\NP}start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT has circuit size ω⁢(n)𝜔𝑛\omega(n)italic_ω ( italic_n ). Just recently, it was shown how uniform lower bounds can be used to derive nonuniform lower bounds: Belova et al. (SODA 2024) showed that if for every ε>0𝜀0\varepsilon>0italic_ε > 0, \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), then, for any δ>0𝛿0\delta>0italic_δ > 0, there exists an explicit polynomial family of arithmetic circuit size Ω⁢(nδ)Ωsuperscript𝑛𝛿\Omega(n^{\delta})roman_Ω ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ); Williams (FOCS 2024) showed that if \NSETH is true, then Boolean Inner Product on n𝑛nitalic_n-bit vectors cannot be computed by \ETHR∘\ETHR\ETHR\ETHR\ETHR{}\circ\ETHR{}∘ circuits of size 2ε⁢nsuperscript2𝜀𝑛2^{\varepsilon n}2 start_POSTSUPERSCRIPT italic_ε italic_n end_POSTSUPERSCRIPT, for some ε>0𝜀0\varepsilon>0italic_ε > 0. In this paper, we continue developing this line of research and show that nondeterministic uniform lower bounds imply nonuniform lower bounds for various types of objects that are notoriously hard to analyze: circuits, matrix rigidity, and tensor rank. Specifically, we prove the following three results.If \NSETH is true, then there exists a monotone Boolean function family in \co\NP of monotone circuit size 2Ω⁢(n/log⁡n)superscript2Ω𝑛𝑛2^{\Omega(n/\log n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n / roman_log italic_n ) end_POSTSUPERSCRIPT. Combining this with the result above, we get win-win circuit lower bounds: either \E\NPsuperscript\E\NP\E^{\NP{}}start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT requires circuits of size w⁢(n)𝑤𝑛w(n)italic_w ( italic_n ) or \coNP\coNP\coNP requires monotone circuits of size 2Ω⁢(n/log⁡n)superscript2Ω𝑛𝑛2^{\Omega(n/\log n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n / roman_log italic_n ) end_POSTSUPERSCRIPT.If \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0, then for all δ>0𝛿0\delta>0italic_δ > 0 and infinitely many k𝑘kitalic_k, there is an explicit 2logO⁢(1)⁡ksuperscript2superscript𝑂1𝑘2^{\log^{O(1)}k}2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT family of k×k𝑘𝑘k\times kitalic_k × italic_k matrices, containing at least one matrix of k1/2−δsuperscript𝑘12𝛿k^{1/2-\delta}italic_k start_POSTSUPERSCRIPT 1 / 2 - italic_δ end_POSTSUPERSCRIPT rigidity k2−δsuperscript𝑘2𝛿k^{2-\delta}italic_k start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT.If \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0, then, for all δ>0𝛿0\delta>0italic_δ > 0, some Δ>0Δ0\Delta>0roman_Δ > 0, and infinitely many k𝑘kitalic_k, there are two explicit 2logO⁢(1)⁡ksuperscript2superscript𝑂1𝑘2^{\log^{O(1)}k}2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT families of k×k𝑘𝑘k\times kitalic_k × italic_k matrices and k×k×k𝑘𝑘𝑘k\times k\times kitalic_k × italic_k × italic_k tensors such that either some matrix has k1−δsuperscript𝑘1𝛿k^{1-\delta}italic_k start_POSTSUPERSCRIPT 1 - italic_δ end_POSTSUPERSCRIPT rigidity k2−δsuperscript𝑘2𝛿k^{2-\delta}italic_k start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT or some tensor has rank k1+Δsuperscript𝑘1Δk^{1+\Delta}italic_k start_POSTSUPERSCRIPT 1 + roman_Δ end_POSTSUPERSCRIPT.","1 Complexity Lower Bounds Finding the minimum time required to solve a given computational problem is a central question in computational complexity. Answering such a question for a particular problem involves proving a complexity lower bound, that is, showing that no fast algorithm can solve this problem. While the Time Hierarchy Theorem [HS65, HS66] guarantees that there are problems in ¶ that cannot be solved in time O⁢(nk)𝑂superscript𝑛𝑘O(n^{k})italic_O ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ), for any k>1𝑘1k>1italic_k > 1, we have no superlinear lower bounds for specific problems. For example, for \SAT, one of the most important \NP-complete problems, we have no algorithms working significantly faster than a brute force approach and at the same time have no methods of excluding a possibility that it can be solved in linear time. 1.1 Conditional Lower Bounds As unconditional complexity lower bounds remain elusive, the classical complexity theory allows one to prove conditional lower bounds of the following form: if a problem A𝐴Aitalic_A cannot be solved in polynomial time, then B𝐵Bitalic_B cannot be solved in polynomial time too. Such results are proved via reductions that are essentially algorithms: one shows how to transform an instance of A𝐴Aitalic_A into an instance of B𝐵Bitalic_B. Nowadays, hundreds of such reductions between various \NP-hard problems are known. For instance, if \SAT cannot be solved in polynomial time, then the Hamiltonian Cycle problem also cannot be solved in polynomial time. In a recently emerged area of fine-grained complexity, one aims to construct tighter reductions between problems showing that even a tiny improvement of an algorithm for one of them automatically leads to improved algorithms for the other one. For example, as proved by Williams [Wil05], if \SAT cannot be solved in time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0, then the Orthogonal Vectors problem cannot be solved in time O⁢(n2−ε)𝑂superscript𝑛2𝜀O(n^{2-\varepsilon})italic_O ( italic_n start_POSTSUPERSCRIPT 2 - italic_ε end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0. Again, many reductions of this form have been developed in recent years. We refer the reader to a recent survey by Vassilevska Williams [Vas18]. 1.2 Circuit Lower Bounds One of the reasons why proving complexity lower bounds is challenging is that an algorithm (viewed as a Turing machine or a RAM machine) is a relatively complex object: it has a memory, may contain loops, function calls (that may in turn be recursive). A related computational model of Boolean circuits has a much simpler structure (a straight-line program) and the same time is powerful enough to model algorithms: if a problem can be solved by algorithms in time T⁢(n)𝑇𝑛T(n)italic_T ( italic_n ), then it can also be solved by circuits in time O⁢(T⁢(n)⁢log⁡T⁢(n))𝑂𝑇𝑛𝑇𝑛O(T(n)\log T(n))italic_O ( italic_T ( italic_n ) roman_log italic_T ( italic_n ) ) [PF79]. It turns out that proving circuit lower bounds is also challenging: while it is not difficult to show that almost all Boolean functions can be computed by circuits of exponential size only (this was proved by Shannon [Sha49] back in 1949), for no function from \NP, we can currently exclude a possibility that it can be computed by circuits of linear size [LY22, FGHK16]. Strong lower bounds are only known for restricted models such as monotone circuits, constant-depth circuits, and formulas. Various such unconditional lower bounds can be found in the book by Jukna [Juk12]. An important difference between algorithms and circuits is that algorithms is a uniform model of computation (an algorithm is a program that needs to process instances of all possible lengths), whereas circuits are nonuniform: when saying that a problem can be solved by circuits, one usually means that there is an infinite collection of circuits, one circuit for every possible input length, and different circuits in this collection can, in principle, implement different programs. This makes the circuit model strictly more powerful than algorithms: on the one hand, every problem solved by algorithms can be solved by circuits of roughly the same size; on the other hand, it is not difficult to come up with a problem of small circuit size that cannot be solved by algorithms. 1.3 Connections Between Lower and Upper Bounds Intuitively, it seems that proving complexity upper bounds should be easier than proving lower bounds. This intuition is well supported by a much higher number of results on algorithms compared to the number of results on lower bounds. Indeed, to prove an upper bound on the complexity of a problem, one designs an algorithm for the problem and analyzes it. Whereas to prove a complexity lower bound, one needs to reason about a wide range of fast algorithms (or small circuits) and to argue that none of them is able to solve the problem at hand. Perhaps surprisingly, the tasks of proving lower and upper complexity bounds are connected to each other. A classical example is Karp–Lipton theorem [KL80] stating that if ¶ = \NP, then \EXP requires circuits of size Ω⁢(2n/n)Ωsuperscript2𝑛𝑛\Omega(2^{n}/n)roman_Ω ( 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT / italic_n ). More recently, Williams [Wil13] established a deep connection between upper bound for Circuit Sat and circuit lower bounds. Extending his results, Jahanjou, Miles and Viola [JMV18] proved that if \NSETH is false (meaning that \UNSAT can be solved fast with nondeterminism), then \E\NP\E{}^{\NP{}}start_FLOATSUPERSCRIPT end_FLOATSUPERSCRIPT requires series-parallel Boolean circuits of size ω⁢(n)𝜔𝑛\omega(n)italic_ω ( italic_n ). Such results show how to derive nonuniform lower bounds (that is, circuit lower bounds) from uniform upper bounds (algorithm upper bounds). Even though one can simulate an algorithm using circuits with slight overhead, the converse is not true as there are undecidable languages of low circuit complexity. Until recently, it was unknown how one can get nonuniform lower bounds from uniform lower bounds. In 2024, [BKM+24] proved that if \MAX-k𝑘kitalic_k-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ) for any ε>0𝜀0\varepsilon>0italic_ε > 0, then for any δ>0𝛿0\delta>0italic_δ > 0, there exists an explicit polynomial family that cannot be computed by arithmetic circuits of size O⁢(nδ)𝑂superscript𝑛𝛿O(n^{\delta})italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ). Also, Williams [Wil24] proved that if \NSETH holds, then Boolean Inner Product on n𝑛nitalic_n-bit vectors cannot be computed by \ETHR∘\ETHR\ETHR\ETHR\ETHR{}\circ\ETHR{}∘ circuits of size 2ε⁢nsuperscript2𝜀𝑛2^{\varepsilon n}2 start_POSTSUPERSCRIPT italic_ε italic_n end_POSTSUPERSCRIPT, for some ε>0𝜀0\varepsilon>0italic_ε > 0. Combined with the result above, it immediately leads to win-win circuit lower bounds: if \NSETH fails, we have a lower bound for series-parallel circuits, otherwise we have a lower bound for \ETHR∘\ETHR\ETHR\ETHR\ETHR{}\circ\ETHR{}∘ circuits. 1.4 Our Contribution In this paper, we derive a number of nonuniform lower bounds from uniform nondeterministic lower bounds. Our lower bounds apply for various objects that are notoriously hard to analyze: circuits, matrix rigidity, and tensor rank. For circuits, we get a win-win situation similar to the one by Williams. Below, we give formal statements of the lower bounds for the three types of objects followed by a discussion of known bounds for these objects. Our first result says that if \UNSAT cannot be solved fast nondeterministically, then one can prove much stronger (than known) monotone circuit lower bounds. Theorem 1. If \NSETH is true, then there exists a monotone Boolean function family in \coNP\coNP\coNP of monotone circuit size 2Ω⁢(n/log⁡n)superscript2Ω𝑛𝑛2^{\Omega(n/\log n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n / roman_log italic_n ) end_POSTSUPERSCRIPT. Combining this with circuit lower bounds from the negation of \NSETH due to [JMV18, CGI+16], leads to win-win circuit lower bounds. It should be noted that proving any of these two circuit lower bounds is a challenging long-standing open problem. Corollary 1. At least one of the following two circuit lower bounds holds: 1. \E\NPsuperscript\E\NP\E^{\NP}start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT requires series-parallel circuits of size ω⁢(n)𝜔𝑛\omega(n)italic_ω ( italic_n ); 2. There is an explicit function f∈\coNP𝑓\coNPf\in\coNPitalic_f ∈ that requires monotone circuits of size 2Ω⁢(n/log⁡n)superscript2Ω𝑛𝑛2^{\Omega(n/\log n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n / roman_log italic_n ) end_POSTSUPERSCRIPT. Our second result says that if \MAX-3-\SAT cannot be solved fast co-nondeterministically, then there exists small explicit families of rigid matrices. Theorem 2. If \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0, then, for all δ>0𝛿0\delta>0italic_δ > 0, there is a generator g:{0,1}logO⁢(1)⁡k→𝔽k×k:𝑔→superscript01superscript𝑂1𝑘superscript𝔽𝑘𝑘g\colon\{0,1\}^{\log^{O(1)}k}\to\mathbb{F}^{k\times k}italic_g : { 0 , 1 } start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT → blackboard_F start_POSTSUPERSCRIPT italic_k × italic_k end_POSTSUPERSCRIPT computable in time polynomial in k𝑘kitalic_k such that, for infinitely many k𝑘kitalic_k, there exist a seed s𝑠sitalic_s for which g⁢(s)𝑔𝑠g(s)italic_g ( italic_s ) has k12−δsuperscript𝑘12𝛿k^{\frac{1}{2}-\delta}italic_k start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG - italic_δ end_POSTSUPERSCRIPT-rigidity k2−δsuperscript𝑘2𝛿k^{2-\delta}italic_k start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT. Our third result extends the second result by including high-rank tensors. Theorem 3. If \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ) for any ε>0𝜀0\varepsilon>0italic_ε > 0, then for all δ>0𝛿0\delta>0italic_δ > 0 and some Δ>0Δ0\Delta>0roman_Δ > 0 there are two generators g1:{0,1}logO⁢(1)⁡k→𝔽k×k:subscript𝑔1→superscript01superscript𝑂1𝑘superscript𝔽𝑘𝑘g_{1}\colon\{0,1\}^{\log^{O(1)}k}\to\mathbb{F}^{k\times k}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT : { 0 , 1 } start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT → blackboard_F start_POSTSUPERSCRIPT italic_k × italic_k end_POSTSUPERSCRIPT and g2:{0,1}logO⁢(1)⁡k→𝔽k×k×k:subscript𝑔2→superscript01superscript𝑂1𝑘superscript𝔽𝑘𝑘𝑘g_{2}\colon\{0,1\}^{\log^{O(1)}k}\to\mathbb{F}^{k\times k\times k}italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : { 0 , 1 } start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT → blackboard_F start_POSTSUPERSCRIPT italic_k × italic_k × italic_k end_POSTSUPERSCRIPT computable in time polynomial in k𝑘kitalic_k such that, for infinitely many k𝑘kitalic_k, at least one of the following is satisfied: • g1⁢(s)subscript𝑔1𝑠g_{1}(s)italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_s ) has k1−δsuperscript𝑘1𝛿k^{1-\delta}italic_k start_POSTSUPERSCRIPT 1 - italic_δ end_POSTSUPERSCRIPT-rigidity k2−δsuperscript𝑘2𝛿k^{2-\delta}italic_k start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT, for some s𝑠sitalic_s; • rank⁡(g2⁢(s))ranksubscript𝑔2𝑠\operatorname{rank}(g_{2}(s))roman_rank ( italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_s ) ) is at least k1+Δsuperscript𝑘1Δk^{1+\Delta}italic_k start_POSTSUPERSCRIPT 1 + roman_Δ end_POSTSUPERSCRIPT, for some s𝑠sitalic_s. It is worth noting that [BKM+24] showed circuit lower bounds under the same assumption: if \MAX-k𝑘kitalic_k-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ) for any ε>0𝜀0\varepsilon>0italic_ε > 0, then for any δ>0𝛿0\delta>0italic_δ > 0, there exists an explicit polynomial family that cannot be computed by arithmetic circuits of size O⁢(nδ)𝑂superscript𝑛𝛿O(n^{\delta})italic_O ( italic_n start_POSTSUPERSCRIPT italic_δ end_POSTSUPERSCRIPT ). The best known lower bounds for the size of depth-three circuits computing an explicit Boolean function is 2Ω⁢(n)superscript2Ω𝑛2^{\Omega(\sqrt{n})}2 start_POSTSUPERSCRIPT roman_Ω ( square-root start_ARG italic_n end_ARG ) end_POSTSUPERSCRIPT [Hås89, PPSZ05]. Proving a 2ω⁢(n)superscript2𝜔𝑛2^{\omega(\sqrt{n})}2 start_POSTSUPERSCRIPT italic_ω ( square-root start_ARG italic_n end_ARG ) end_POSTSUPERSCRIPT lower bound for this restricted circuit model remains a challenging open problem and it is known that a lower bound as strong as 2ω⁢(n/log⁡log⁡n)superscript2𝜔𝑛𝑛2^{\omega(n/\log\log n)}2 start_POSTSUPERSCRIPT italic_ω ( italic_n / roman_log roman_log italic_n ) end_POSTSUPERSCRIPT would give an w⁢(n)𝑤𝑛w(n)italic_w ( italic_n ) lower bound for unrestricted circuits via Valiant’s reduction [Val77]. One way of proving better depth-three circuit lower bounds is via canonical circuits introduced by Goldreich and Wigderson [GW20]. They are closely related to rigid matrices: if T𝑇Titalic_T is an n×n𝑛𝑛n\times nitalic_n × italic_n matrix of r𝑟ritalic_r-rigidity r3superscript𝑟3r^{3}italic_r start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, then the corresponding bilinear function requires canonical circuits of size 2Ω⁢(r)superscript2Ω𝑟2^{\Omega(r)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_r ) end_POSTSUPERSCRIPT [GW20]. Goldreich and Tal [GT18] showed that a random Toeplitz matrix has r𝑟ritalic_r-rigidity n3r2⁢log⁡nsuperscript𝑛3superscript𝑟2𝑛\frac{n^{3}}{r^{2}\log n}divide start_ARG italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_ARG start_ARG italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n end_ARG, which implies a 2Ω⁢(n3/5)superscript2Ωsuperscript𝑛352^{\Omega(n^{3/5})}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 3 / 5 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT lower bound on canonical depth-three circuits for an explicit function. Thus, by substituting n2/3−δsuperscript𝑛23𝛿n^{2/3-\delta}italic_n start_POSTSUPERSCRIPT 2 / 3 - italic_δ end_POSTSUPERSCRIPT-rigidity for some δ>0𝛿0\delta>0italic_δ > 0 in our trade off Theorem 3, we derive the following result: Corollary 2. If \MAX-3-\SAT cannot be solved in co-nondeterministic time O⁢(2(1−ε)⁢n)𝑂superscript21𝜀𝑛O(2^{(1-\varepsilon)n})italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT ), for any ε>0𝜀0\varepsilon>0italic_ε > 0, then, for any δ>0𝛿0\delta>0italic_δ > 0 and for infinitely many n𝑛nitalic_n, one can construct an explicit family of 2logO⁢(1)⁡nsuperscript2superscript𝑂1𝑛2^{\log^{O(1)}n}2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT functions such that at least one of them is either bilinear and requires canonical circuits of size 2Ω⁢(n2/3−δ)superscript2Ωsuperscript𝑛23𝛿2^{\Omega(n^{2/3-\delta})}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 / 3 - italic_δ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT or trilinear and requires arithmetic circuits of size Ω⁢(n1.25)Ωsuperscript𝑛1.25\Omega(n^{1.25})roman_Ω ( italic_n start_POSTSUPERSCRIPT 1.25 end_POSTSUPERSCRIPT ). This conditionally improves the recent result of Goldreich [Gol22], who presented an O⁢(1)𝑂1O(1)italic_O ( 1 )-linear function that requires canonical depth-two circuits of size 2Ω⁢(n1−ε)superscript2Ωsuperscript𝑛1𝜀2^{\Omega(n^{1-\varepsilon})}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 - italic_ε end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT, for every ε>0𝜀0\varepsilon>0italic_ε > 0. Moreover, every bilinear function can be computed by canonical circuits of size 2O⁢(n2/3)superscript2𝑂superscript𝑛232^{O(n^{2/3})}2 start_POSTSUPERSCRIPT italic_O ( italic_n start_POSTSUPERSCRIPT 2 / 3 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT, so the lower bound is almost optimal and conditionally addresses Open Problem 6.5 from [GT18]. 1.4.1 Monotone Functions For monotone \NP-problems (like Clique, Matching, Hamiltonian Cycle), it is natural to ask what is their monotone circuit size. A celebrated result by Razborov [Raz85] is a lower bound nΩ⁢(log⁡n)superscript𝑛Ω𝑛n^{\Omega(\log n)}italic_n start_POSTSUPERSCRIPT roman_Ω ( roman_log italic_n ) end_POSTSUPERSCRIPT on monotone circuit size. Subsequently, Andreev [And85] proved a 2n1/8−o⁢(1)superscript2superscript𝑛18𝑜12^{n^{1/8-o(1)}}2 start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT 1 / 8 - italic_o ( 1 ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT lower bound for another explicit monotone function. Following the work of [AB87, And87, Juk99, HR00], in 2020, Cavalar, Kumar and Rossman [CKR22] achieved the best known lower bound of 2n1/2−o⁢(1)superscript2superscript𝑛12𝑜12^{n^{1/2-o(1)}}2 start_POSTSUPERSCRIPT italic_n start_POSTSUPERSCRIPT 1 / 2 - italic_o ( 1 ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT. Proving a 2ω⁢(n1/2)superscript2𝜔superscript𝑛122^{\omega(n^{1/2})}2 start_POSTSUPERSCRIPT italic_ω ( italic_n start_POSTSUPERSCRIPT 1 / 2 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT lower bound remains a challenging open problem (whereas a lower bound 2Ω⁢(n)superscript2Ω𝑛2^{\Omega(n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n ) end_POSTSUPERSCRIPT was recently proved by Pitassi and Robere [PR17] for monotone formulas). Our Theorem 1 establishes a stronger lower bound under an assumption that \NSETH holds. 1.4.2 Matrix Rigidity A matrix M𝑀Mitalic_M over a field 𝔽𝔽\mathbb{F}blackboard_F has r-rigidity s if for any matrices R,S𝑅𝑆R,Sitalic_R , italic_S over a field 𝔽𝔽\mathbb{F}blackboard_F such that M=R+S𝑀𝑅𝑆M=R+Sitalic_M = italic_R + italic_S and rank⁡(R)≤rrank𝑅𝑟\operatorname{rank}(R)\leq rroman_rank ( italic_R ) ≤ italic_r we have that S𝑆Sitalic_S has at least s𝑠sitalic_s nonzero entries. That is, one needs to change at least s𝑠sitalic_s elements in M𝑀Mitalic_M to change its rank down to at most r𝑟ritalic_r. The concept of rigidity was introduced by Valiant [Val77] and Grigoriev [Gri80]. It has striking connections to areas such as computational complexity [Lok09, AW17, AC19, GKW21], communication complexity [Wun12], data structure lower bounds [DGW19, RR20], and error-correcting codes [Dvi11]. Valiant [Val77] proved that if a matrix M𝑀Mitalic_M has ε⁢n𝜀𝑛\varepsilon nitalic_ε italic_n-rigidity n1+δsuperscript𝑛1𝛿n^{1+\delta}italic_n start_POSTSUPERSCRIPT 1 + italic_δ end_POSTSUPERSCRIPT for some ε,δ>0𝜀𝛿0\varepsilon,\delta>0italic_ε , italic_δ > 0, then the bilinear form of M𝑀Mitalic_M cannot be computed by arithmetic circuits of size O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ) and depth O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n ). Following Razborov [Raz89], Wunderlich [Wun12] proved that the existence of strongly-explicit matrices with 2(log⁡log⁡n)ω⁢(1)superscript2superscript𝑛𝜔12^{(\log\log n)^{\omega(1)}}2 start_POSTSUPERSCRIPT ( roman_log roman_log italic_n ) start_POSTSUPERSCRIPT italic_ω ( 1 ) end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT-rigidity δ⁢n2𝛿superscript𝑛2\delta n^{2}italic_δ italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, for some δ>0𝛿0\delta>0italic_δ > 0, implies the existence of a language that does not belong to the communication complexity analog of \PH\PH\PH. Although it is known [Val77] that for any r𝑟ritalic_r almost every n×n𝑛𝑛n\times nitalic_n × italic_n matrix has r𝑟ritalic_r-rigidity Ω⁢((n−r)2log⁡n)Ωsuperscript𝑛𝑟2𝑛\Omega(\frac{(n-r)^{2}}{\log n})roman_Ω ( divide start_ARG ( italic_n - italic_r ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG roman_log italic_n end_ARG ) over algebraically closed fields, obtaining an explicit constructions of rigid matrices remains a long-standing open question. Many works have aimed at finding explicit or semi-explicit rigid matrices [Fri93, PV91, SSS97, AW17, DE19, AC19, DL20, VK22, BGKM23, BHPT24]. We are interested in constructing small explicit111Matrix or family of matrices is called explicit if it is polynomial time constructible. families of rigid matrices, since they can be used to prove arithmetic circuits lower bounds [Val77]. The best known polynomial-time constructible matrices have r𝑟ritalic_r-rigidity n2r⁢log⁡(n/r)superscript𝑛2𝑟𝑛𝑟\frac{n^{2}}{r}\log(n/r)divide start_ARG italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG italic_r end_ARG roman_log ( italic_n / italic_r ) for any r𝑟ritalic_r, which was proved by Shokrollahi, Spielman and Stemann [SSS97]. Goldreich and Tal [GT18] proved that a random n×n𝑛𝑛n\times nitalic_n × italic_n Toeplitz matrix over 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT (i.e., a matrix of the form Ai,j=ai−jsubscript𝐴𝑖𝑗subscript𝑎𝑖𝑗A_{i,j}=a_{i-j}italic_A start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = italic_a start_POSTSUBSCRIPT italic_i - italic_j end_POSTSUBSCRIPT for some random bits a−(n−1),…,an−1subscript𝑎𝑛1…subscript𝑎𝑛1a_{-(n-1)},\ldots,a_{n-1}italic_a start_POSTSUBSCRIPT - ( italic_n - 1 ) end_POSTSUBSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_n - 1 end_POSTSUBSCRIPT) has r𝑟ritalic_r-rigidity n3r2⁢log⁡nsuperscript𝑛3superscript𝑟2𝑛\frac{n^{3}}{r^{2}\log n}divide start_ARG italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT end_ARG start_ARG italic_r start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n end_ARG for r≥n𝑟𝑛r\geq\sqrt{n}italic_r ≥ square-root start_ARG italic_n end_ARG. However, the size of that family is exponential in n𝑛nitalic_n. Our Theorem 2 demonstrates that, under the assumption that \MAX-3333-\SAT is hard, for any δ>0𝛿0\delta>0italic_δ > 0, for infinitely many n𝑛nitalic_n one can construct a 2logO⁢(1)⁡nsuperscript2superscript𝑂1𝑛2^{\log^{O(1)}n}2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT-sized family of n×n𝑛𝑛n\times nitalic_n × italic_n matrices with at least one having n1/2−δsuperscript𝑛12𝛿n^{1/2-\delta}italic_n start_POSTSUPERSCRIPT 1 / 2 - italic_δ end_POSTSUPERSCRIPT-rigidity n2−δsuperscript𝑛2𝛿n^{2-\delta}italic_n start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT. This result is still far from the regime where circuit lower bounds can be derived via Valiant’s result, but it strictly improves the polynomial-time construction [SSS97] for any r<n𝑟𝑛r<\sqrt{n}italic_r < square-root start_ARG italic_n end_ARG and improves the result of Goldreich and Tal [GT18] by substantially reducing the family size while maintaining the same rigidity for r≈n𝑟𝑛r\approx\sqrt{n}italic_r ≈ square-root start_ARG italic_n end_ARG. An open question remains as to whether explicit constructions of rigid matrices exist in the class ¶\NPsuperscript¶\NP\P^{\NP{}}¶ start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT [Ram20]. The construction provided by Goldreich and Tal [GT18] lies in \E\NPsuperscript\E\NP\E^{\NP{}}start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT. Alman and Chen [AC19] demonstrated that there exists a constant δ>0𝛿0\delta>0italic_δ > 0 such that, for any ε>0𝜀0\varepsilon>0italic_ε > 0, one can construct n×n𝑛𝑛n\times nitalic_n × italic_n matrices with 2(log⁡n)1/4−εsuperscript2superscript𝑛14𝜀2^{(\log n)^{1/4-\varepsilon}}2 start_POSTSUPERSCRIPT ( roman_log italic_n ) start_POSTSUPERSCRIPT 1 / 4 - italic_ε end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT-rigidity δ⁢n2𝛿superscript𝑛2\delta n^{2}italic_δ italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT in ¶\NPsuperscript¶\NP\P^{\NP}¶ start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT. Our construction, in the class \DTIME⁢[2logO⁢(1)⁡n]\NP\DTIMEsuperscriptdelimited-[]superscript2superscript𝑂1𝑛\NP\DTIME[2^{\log^{O(1)}n}]^{\NP}[ 2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ] start_POSTSUPERSCRIPT end_POSTSUPERSCRIPT, produces matrices with n12−δsuperscript𝑛12𝛿n^{\frac{1}{2}-\delta}italic_n start_POSTSUPERSCRIPT divide start_ARG 1 end_ARG start_ARG 2 end_ARG - italic_δ end_POSTSUPERSCRIPT-rigidity n2−δsuperscript𝑛2𝛿n^{2-\delta}italic_n start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT for any δ>0𝛿0\delta>0italic_δ > 0, under the condition that \MAX-3-\SAT is hard. 1.4.3 Tensor Rank and Arithmetic Circuits Proving arithmetic circuit lower bounds is another important challenge of complexity theory. An arithmetic circuit over a field 𝔽𝔽\mathbb{F}blackboard_F uses as inputs formal variables and field elements and computes in every gate either a sum or a product. As proved by Strassen [Str73, Str75] and Baur and Strassen [BS83], it is known that computing ∑i=1nxinsuperscriptsubscript𝑖1𝑛superscriptsubscript𝑥𝑖𝑛\sum_{i=1}^{n}x_{i}^{n}∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT requires arithmetic circuits of size Ω⁢(n⁢log⁡n)Ω𝑛𝑛\Omega(n\log n)roman_Ω ( italic_n roman_log italic_n ), provided n𝑛nitalic_n does not divide the characteristic of 𝔽𝔽\mathbb{F}blackboard_F. Raz [Raz03] further established that arithmetic circuits with bounded coefficients require Ω⁢(n2⁢log⁡n)Ωsuperscript𝑛2𝑛\Omega(n^{2}\log n)roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT roman_log italic_n ) gates to perform matrix multiplication over ℝℝ\mathbb{R}blackboard_R or ℂℂ\mathbb{C}blackboard_C, following the work in [RS03]. However, no superlinear lower bounds are known for polynomials of constant degree. For constant-depth arithmetic circuits over fields of characteristic 2222, exponential lower bounds are known [Raz87, Smo87]. For other finite characteristics, exponential lower bounds are known only for depth 3333 [GK98, GR98]. For characteristic 00, the best lower bound for depth 3333 is Ω⁢(n2−ε)Ωsuperscript𝑛2𝜀\Omega(n^{2-\varepsilon})roman_Ω ( italic_n start_POSTSUPERSCRIPT 2 - italic_ε end_POSTSUPERSCRIPT ) [SW99]. Matrix multiplication is one of the fundamental problems whose arithmetic circuit size is of great interest. While many highly nontrivial algorithms for it are known (starting from Strassen [Str69]), we still do not have superlinear lower bounds on its arithmetic circuit complexity. Proving such lower bounds is closely related to the problem of determining the rank of tensors. A d𝑑ditalic_d-dimensional tensor is said to have rank q𝑞qitalic_q if it can be expressed as a sum of q𝑞qitalic_q rank-one tensors. Here, a rank-one d𝑑ditalic_d-dimensional tensor is a tensor of the form u1⊗⋯⊗udtensor-productsubscript𝑢1⋯subscript𝑢𝑑u_{1}\otimes\dots\otimes u_{d}italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊗ ⋯ ⊗ italic_u start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT, where ⊗tensor-product\otimes⊗ stands for a tensor product. By a multiplication tensor, we mean a tensor of size n2×n2×n2superscript𝑛2superscript𝑛2superscript𝑛2n^{2}\times n^{2}\times n^{2}italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT × italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (formally defined in Section 2.4). Establishing an upper bound for the rank of the multiplication tensor provides a means of proving upper bounds for matrix multiplication via the laser method [Str86]. Moreover, proving a lower bound for the tensor rank would yield superlinear lower bounds for arithmetic circuits computing the polynomial defined by that tensor. Therefore, proving lower bounds on the tensor rank provides a path to proving lower bounds on arithmetic circuits. For the rank of the matrix multiplication tensor, Bshouty [Bsh89] and Bläser [Blä99] proved a lower bound 2.5⁢n2−Θ⁢(n)2.5superscript𝑛2Θ𝑛2.5n^{2}-\Theta(n)2.5 italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - roman_Θ ( italic_n ). Subsequently, Shpilka [Shp03] improved the bound to 3⁢n2−o⁢(n2)3superscript𝑛2𝑜superscript𝑛23n^{2}-o(n^{2})3 italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_o ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) over 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The bound 3⁢n2−o⁢(n)3superscript𝑛2𝑜𝑛3n^{2}-o(n)3 italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_o ( italic_n ) was later achieved by Landsberg [Lan14] over arbitrary fields and further slightly improved by Massarenti and Raviolo [MR13, MR14]. Alexeev, Forbes and Tsimerman [AFT11] constructed explicit d𝑑ditalic_d-dimensional tensors with rank 2⁢n⌊d2⌋+n−Θ⁢(d⁢log⁡n)2superscript𝑛𝑑2𝑛Θ𝑑𝑛2n^{\left\lfloor\frac{d}{2}\right\rfloor}+n-\Theta(d\log n)2 italic_n start_POSTSUPERSCRIPT ⌊ divide start_ARG italic_d end_ARG start_ARG 2 end_ARG ⌋ end_POSTSUPERSCRIPT + italic_n - roman_Θ ( italic_d roman_log italic_n ), thus improving the lower bounds on high-dimensional tensors. Nevertheless, superlinear size lower bounds for constant-degree polynomials remain unknown. Additionally, Håstad [Hås90] established that determining the rank of a d𝑑ditalic_d-dimensional tensor is \NP-hard for any d≥3𝑑3d\geq 3italic_d ≥ 3. Consequently, a major open problem is to construct an explicit family of d𝑑ditalic_d-dimensional tensors with rank at least n⌊d2⌋+εsuperscript𝑛𝑑2𝜀n^{\left\lfloor\frac{d}{2}\right\rfloor+\varepsilon}italic_n start_POSTSUPERSCRIPT ⌊ divide start_ARG italic_d end_ARG start_ARG 2 end_ARG ⌋ + italic_ε end_POSTSUPERSCRIPT for some ε>0𝜀0\varepsilon>0italic_ε > 0 and d≥3𝑑3d\geq 3italic_d ≥ 3. Our Theorem 3 shows that, under an assumption that \MAX-3-\SAT cannot be solved fast co-nondeterministically, one gets an explicit 2logO⁢(1)⁡nsuperscript2superscript𝑂1𝑛2^{\log^{O(1)}n}2 start_POSTSUPERSCRIPT roman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT-size family of n×n𝑛𝑛n\times nitalic_n × italic_n-matrices and n×n×n𝑛𝑛𝑛n\times n\times nitalic_n × italic_n × italic_n-tensors, such that for any δ>0𝛿0\delta>0italic_δ > 0 and some Δ>0Δ0\Delta>0roman_Δ > 0 at least one of the matrices has n1−δsuperscript𝑛1𝛿n^{1-\delta}italic_n start_POSTSUPERSCRIPT 1 - italic_δ end_POSTSUPERSCRIPT-rigidity n2−δsuperscript𝑛2𝛿n^{2-\delta}italic_n start_POSTSUPERSCRIPT 2 - italic_δ end_POSTSUPERSCRIPT or one of the tensors has rank n1+Δsuperscript𝑛1Δn^{1+\Delta}italic_n start_POSTSUPERSCRIPT 1 + roman_Δ end_POSTSUPERSCRIPT. Furthermore, we establish a trade-off between matrix rigidity and tensor rank, see Theorem 9. Other results for proving lower bounds on tensor rank under certain assumptions are known. Nederlof [Ned20] proved that, if for any ε>0𝜀0\varepsilon>0italic_ε > 0, the bipartite TSP problem cannot be solved in time 2(1−ε)⁢nsuperscript21𝜀𝑛2^{(1-\varepsilon)n}2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT, then the matrix multiplication tensor has superlinear rank. Additionally, Björklund and Kaski [BK24] recently proved that if, for any ε>0𝜀0\varepsilon>0italic_ε > 0, there exists a k𝑘kitalic_k such that the k𝑘kitalic_k-Set Cover problem cannot be solved in time O⁢(2(1−ε)⁢n⁢|ℱ|)𝑂superscript21𝜀𝑛ℱO(2^{(1-\varepsilon)n}|\mathcal{F}|)italic_O ( 2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT | caligraphic_F | ), then there is an explicit tensor with superlinear rank, where ℱℱ\mathcal{F}caligraphic_F is a family of subsets of [n]delimited-[]𝑛[n][ italic_n ], each of size at most k𝑘kitalic_k. Pratt [Pra24] improved this result, showing that under the same conjecture there exists an explicit tensor of shape n×n×n𝑛𝑛𝑛n\times n\times nitalic_n × italic_n × italic_n and rank at least n1.08superscript𝑛1.08n^{1.08}italic_n start_POSTSUPERSCRIPT 1.08 end_POSTSUPERSCRIPT. [BCH+24] showed that if for every ε>0𝜀0\varepsilon>0italic_ε > 0 Chromatic Number problem cannot be solved in time 2(1−ε)⁢nsuperscript21𝜀𝑛2^{(1-\varepsilon)n}2 start_POSTSUPERSCRIPT ( 1 - italic_ε ) italic_n end_POSTSUPERSCRIPT, then there exists an explicit tensor of superlinear rank. 1.5 Structure of the Paper The paper is organized as follows. In Section 2, we introduce the notation used throughout the paper and provide the necessary background information. In Section 3, we introduce the main ideas of each result. In Section 4, we establish the win-win circuit lower bound. In Section 5, we construct rigid matrices conditioned that \MAX-3-\SAT cannot be solved fast co-nondeterministically. In Section 6, we construct either three-dimensional tensors with high rank or matrices with high rigidity under the same assumption. In Section 7 we discuss future directions and open problems."
https://arxiv.org/html/2411.03230v1,Fermionic Independent Set and Laplacian of an independence complex are QMA-hard,"The Independent Set is a well known NP-hard optimization problem. In this work, we define a fermionic generalization of the Independent Set problem and prove that the optimization problem is QMA-hard in a k𝑘kitalic_k-particle subspace using perturbative gadgets. We discuss how the Fermionic Independent Set is related to the problem of computing the minimum eigenvalue of the kthsuperscript𝑘thk^{\text{th}}italic_k start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT-Laplacian of an independence complex of a vertex weighted graph. Consequently, we use the same perturbative gadget to prove QMA-hardness of the later problem resolving an open conjecture from [1] and give the first example of a natural topological data analysis problem that is QMA-hard.","Quantum Merlin Arthur (QMA) is the complexity class of decision problems for which a ‘yes’ solution can be efficiently verified using a quantum computer. The k𝑘kitalic_k-Local Hamiltonian problem [2, 3, 4] was the first non-trivial problem shown to be QMA-complete. Since then numerous other problems have been proven QMA-complete, mostly arising in quantum computing and information science [5]. While the k𝑘kitalic_k-Local Hamiltonian problem serves as a fundamental QMA-complete problem, analogous to k𝑘kitalic_k-SAT’s role in NP-completeness, the majority of NP-complete problems are constrained combinatorial optimization problems such as Minimum Vertex Cover, Maximum Independent Set, and Longest Path [6]. Such constrained optimization problems had a great impact on the development of classical algorithms, and hardness results. By studying quantum generalizations of such constrained optimization problems, we can explore new quantum algorithms and hardness results for quantum problems that are currently lacking. This kind of motivation inspired a previous work [7] which studies quantum generalizations of classical constrained problems with Vertex Cover as a driving example. Following this motivation, we define a fermionic generalization of the Independent Set and study its computational complexity. We prove that the Fermionic Independent Set is QMA-hard when restricted to a k𝑘kitalic_k-particle subspace. When problems without an obvious quantum connection are shown to be related QMA, it can offer new insights into the structure of QMA and as well as the problem at hand. One such problem in Homology is to determine the existence of a k𝑘kitalic_k-dimensional hole in a topological space. When the space is represented by the clique complex of a graph, this problem is of practical interest in Topological Data Analysis (TDA) which uses topological features such as holes to characterize and study data. TDA has found a broad range of applications from computational neuroscience [8] to cosmology [9]. Recently, there has been a significant progress towards understanding the computational complexity of determining the existence of a hole by relating it to quantum complexity classes. This connection was possible because of a correspondence between the combinatorial Laplacian of a clique complex whose null space captures the holes and a supersymmetric Hamiltonian [10]. The question of whether the clique complex has a k𝑘kitalic_k-dimensional hole or not is equivalent to whether the supersymmetric Hamiltonian has a zero energy ground state or not in the k𝑘kitalic_k-particle subspace. In this work, we prove that computing the minimum eigenvalue of the kthsuperscript𝑘thk^{\text{th}}italic_k start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT-Laplacian of a clique complex is QMA-hard resolving an open conjecture from [1] in the affirmative. Our result is proved for the Laplacian operator of the independence complex and holds true for the clique complex as well since the clique complex of a graph is same as the independence complex of the complement graph. A novelty of our work lies in the simplicity of our proof techniques based on perturbative gadgets compared to highly specialized homological proof techniques of previous works [11, 1]. Although the Fermionic Independent Set and the minimum eigenvalue problem of the Laplacian of an independence complex might seem unrelated at first, when expressed as constrained optimization problems they differ only slightly in their objective functions. The similarity between the problems is also reflected in the fact that we use the same perturbative gadget to prove QMA-hardness of both the problems. We consequently establish the first QMA-hardness result of a natural TDA problem. 1.1 Related Work Crichigno and Kohler [11] proved that the problem of deciding whether the minimum eigenvalue of the kthsuperscript𝑘thk^{\text{th}}italic_k start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT-Lapalacian is equal to 00 or >0absent0>0> 0 is QMA1-hard where QMA1 is the complexity class QMA with perfect completeness. But the corresponding QMA1-hard supersymmetric Hamiltonians that they construct can have exponentially small gap above the zero energy ground space. This was later improved by King and Kohler [1] where they constructed QMA1-hard supersymmetric Hamiltonians corresponding to clique complexes of vertex weighted graphs with inverse polynomial gap above the zero energy ground space, thereby placing them in QMA. The authors conjectured in [1] that there are supersymmetric Hamiltonians corresponding to clique complexes which are QMA-hard, meaning estimating the minimum eigenvalue of the Laplacian operator even when it is nonzero is QMA-hard, rather than just QMA1-hard. 1.2 Notation and organization The notation [n]delimited-[]𝑛[n][ italic_n ] denotes the set of integers {1,2,…,n}12…𝑛\{1,2,...,n\}{ 1 , 2 , … , italic_n }. A graph is denoted by G𝐺Gitalic_G, G⁢([n],E)𝐺delimited-[]𝑛𝐸G([n],E)italic_G ( [ italic_n ] , italic_E ) where vertices are labeled by elements from [n]delimited-[]𝑛[n][ italic_n ] and set E𝐸Eitalic_E denotes the edges between the vertices. An edge between vertices i𝑖iitalic_i and j𝑗jitalic_j is represent by i⁢j𝑖𝑗ijitalic_i italic_j. Hamiltonians are denoted by H𝐻Hitalic_H and V𝑉Vitalic_V with various subscripts, and projectors are denoted by P𝑃Pitalic_P and ΠΠ\Piroman_Π with various subscripts. Hilbert spaces are denoted by ℋℋ\mathcal{H}caligraphic_H with various subscripts. The notation ρ𝜌\rhoitalic_ρ denotes a density operator and the notation Tr⁢[A]Trdelimited-[]𝐴\mathrm{Tr}[A]roman_Tr [ italic_A ] denotes the matrix trace of an operator A𝐴Aitalic_A. Positive semi-definiteness of an operator A𝐴Aitalic_A is denoted by A⪰0succeeds-or-equals𝐴0A\succeq 0italic_A ⪰ 0. Fermionic creation and annihilation operators are denoted by a†superscript𝑎†a^{\dagger}italic_a start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT, a𝑎aitalic_a. Pauli matrices X𝑋Xitalic_X, Y𝑌Yitalic_Y, and Z𝑍Zitalic_Z are defined as follows X=[0110],Y=[0−ii0],andZ=[100−1].formulae-sequence𝑋matrix0110formulae-sequence𝑌matrix0𝑖𝑖0and𝑍matrix1001\displaystyle X=\begin{bmatrix}0&1\\ 1&0\end{bmatrix},\,\,\,\,\,\,Y=\begin{bmatrix}0&-i\\ i&0\end{bmatrix},\,\text{and}\,\,\,\,\,\,Z=\begin{bmatrix}1&0\\ 0&-1\end{bmatrix}.italic_X = [ start_ARG start_ROW start_CELL 0 end_CELL start_CELL 1 end_CELL end_ROW start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ] , italic_Y = [ start_ARG start_ROW start_CELL 0 end_CELL start_CELL - italic_i end_CELL end_ROW start_ROW start_CELL italic_i end_CELL start_CELL 0 end_CELL end_ROW end_ARG ] , and italic_Z = [ start_ARG start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL - 1 end_CELL end_ROW end_ARG ] . In section 2, we define the Fermionic Independent Set problem and the minimum eigenvalue problem of the Laplacian of an independence complex of a vertex weighted graph. We briefly the similarities and the differences between the two problems. In appendix A, we recall some theorems behind perturbative gadgets necessary for our work. In section 3, we give a proof of QMA-hardness of Fermionic Independent Set problem when restricted to a k𝑘kitalic_k-particle subspace. In section 4, we extend the QMA-hardness proof to minimum eigenvalue problem of the kthsuperscript𝑘thk^{\text{th}}italic_k start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT-Laplacian of an independence complex."
https://arxiv.org/html/2411.03103v1,Benign landscape for Burer-Monteiro factorizations of MaxCut-type semidefinite programs,"We consider MaxCut-type semidefinite programs (SDP) which admit a low rank solution. To numerically leverage the low rank hypothesis, a standard algorithmic approach is the Burer-Monteiro factorization, which allows to significantly reduce the dimensionality of the problem at the cost of its convexity. We give a sharp condition on the conditioning of the Laplacian matrix associated with the SDP under which any second-order critical point of the non-convex problem is a global minimizer. By applying our theorem, we improve on recent results about the correctness of the Burer-Monteiro approach on ℤ2subscriptℤ2\mathbb{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-synchronization problems.","1.1 Presentation of the problem Semidefinite programs (SDP) are optimization tools that allow the solving and modeling of a variety of problems across applied sciences. A number of problems admits a SDP formulation in combinatorial optimization [Goemans and Williamson, 1995], machine learning and data sciences [Lanckriet et al., 2004], statistics and signal processing [Candès, Strohmer, and Voroninski, 2013]. In this paper, we are interested in so-called MaxCut-type SDPs: minX∈𝕊n×n𝑋superscript𝕊𝑛𝑛min\displaystyle\underset{X\in\mathbb{S}^{n\times n}}{\mbox{min}}start_UNDERACCENT italic_X ∈ blackboard_S start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT end_UNDERACCENT start_ARG min end_ARG −⟨C,X⟩𝐶𝑋\displaystyle-\left\langle C,X\right\rangle- ⟨ italic_C , italic_X ⟩ (SDP) s.t. X⪰0succeeds-or-equals𝑋0\displaystyle X\succeq 0italic_X ⪰ 0 diag⁢(X)=𝟏n,diag𝑋subscript1𝑛\displaystyle\mathrm{diag}(X)=\operatorname{\mathbf{1}}_{n},roman_diag ( italic_X ) = bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , where the operator diag:ℝn×n→ℝn:diag→superscriptℝ𝑛𝑛superscriptℝ𝑛\operatorname{diag}:\mathbb{R}^{n\times n}\to\mathbb{R}^{n}roman_diag : blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT extracts the diagonal of a square matrix, 𝟏n=(1⁢…⁢1)T∈ℝnsubscript1𝑛superscript1…1𝑇superscriptℝ𝑛\operatorname{\mathbf{1}}_{n}=(1\dots 1)^{T}\in\mathbb{R}^{n}bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( 1 … 1 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and the symmetric matrix C∈ℝn×n𝐶superscriptℝ𝑛𝑛C\in\mathbb{R}^{n\times n}italic_C ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT is called the cost matrix. SDP of this form are especially known to provide precise convex relaxations of MaxCut problems from graph optimization [Goemans and Williamson, 1995]. They can also model problems such as group synchronization, phase retrieval and the Kuramoto model, for particular choices of the cost matrix C𝐶Citalic_C. Several general methods exist to numerically solve problem (SDP), but they scale poorly with n𝑛nitalic_n. For instance, interior-point solvers require O⁢(n3)𝑂superscript𝑛3O(n^{3})italic_O ( italic_n start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) computations per iteration and O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to store the variable [Benson, Ye, and Zhang, 2000]. To reduce the computational complexity of solvers, one must exploit the specific properties of the problem at hand, if any. For instance, it may be known in advance that the solution to (SDP) is low-rank: [Pataki, 1998] guarantees that there exists a solution with rank bounded by 2⁢n+O⁢(1)2𝑛𝑂1\sqrt{2n}+O(1)square-root start_ARG 2 italic_n end_ARG + italic_O ( 1 ) and, when (SDP) is the relaxation of a combinatorial problem, the optimal rank is often much less (see for instance [Candès, Strohmer, and Voroninski, 2013] for a theoretical justification in a particular case, [Journée, Bach, Absil, and Sepulchre, 2010] for a numerical investigation). In this case, it is possible to tackle the problem using its so-called Burer-Monteiro factorization. The principle is to factor the variable as X=V⁢VT𝑋𝑉superscript𝑉𝑇X=VV^{T}italic_X = italic_V italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT, for V∈ℝn×p𝑉superscriptℝ𝑛𝑝V\in\mathbb{R}^{n\times p}italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_p end_POSTSUPERSCRIPT, where p∈ℕ𝑝ℕp\in\mathbb{N}italic_p ∈ blackboard_N is larger or equal to the rank of the sought solution, and much smaller than n𝑛nitalic_n. Then, one optimizes over V𝑉Vitalic_V, instead of directly over X𝑋Xitalic_X. minV∈ℝn×p𝑉superscriptℝ𝑛𝑝min\displaystyle\underset{V\in\mathbb{R}^{n\times p}}{\mbox{min}}start_UNDERACCENT italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_p end_POSTSUPERSCRIPT end_UNDERACCENT start_ARG min end_ARG −⟨C,V⁢VT⟩𝐶𝑉superscript𝑉𝑇\displaystyle-\left\langle C,VV^{T}\right\rangle- ⟨ italic_C , italic_V italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⟩ (Burer-Monteiro) s.t. diag⁡(V⁢VT)=𝟏n.diag𝑉superscript𝑉𝑇subscript1𝑛\displaystyle\operatorname{diag}(VV^{T})=\operatorname{\mathbf{1}}_{n}.roman_diag ( italic_V italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) = bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT . The factorized problem reduces the number of variables to n⁢p𝑛𝑝npitalic_n italic_p instead of the O⁢(n2)𝑂superscript𝑛2O(n^{2})italic_O ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) variables of the initial problem which is computationally advantageous when p≪nmuch-less-than𝑝𝑛p\ll nitalic_p ≪ italic_n. However, the convexity is lost, so standard solvers are not guaranteed to reach the solution. Still, in practice, solvers oftentimes converge to a global solution V∈ℝn×p𝑉superscriptℝ𝑛𝑝V\in\mathbb{R}^{n\times p}italic_V ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_p end_POSTSUPERSCRIPT of the factorized problem, for which X=V⁢VT𝑋𝑉superscript𝑉𝑇X=VV^{T}italic_X = italic_V italic_V start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT solves the initial problem. 1.2 Prior work and our contribution The main explanation proposed in the literature for the success of standard algorithms at solving (Burer-Monteiro) has been the benign non-convexity of the optimization landscape: it may be that all second-order critical points of (Burer-Monteiro) are global minimizers. Since standard algorithms typically find a second-order critical point [Lee, Panageas, Piliouras, Simchowitz, Jordan, and Recht, 2019], they consequently find a global minimizer. Literature suggests that, the greater p𝑝pitalic_p is, the more likely it is that the landscape is benign. More precisely, when p≥2⁢n+O⁢(1)𝑝2𝑛𝑂1p\geq\sqrt{2n}+O(1)italic_p ≥ square-root start_ARG 2 italic_n end_ARG + italic_O ( 1 ), the landscape of the factorized problem is benign for almost all cost matrices C𝐶Citalic_C [Boumal, Voroninski, and Bandeira, 2020]. This property is even true for all cost matrices if p>n2𝑝𝑛2p>\frac{n}{2}italic_p > divide start_ARG italic_n end_ARG start_ARG 2 end_ARG [Boumal, Voroninski, and Bandeira, 2020, Cor. 5.11], while it can fail for a zero Lebesgue measure subset of cost matrices if 2⁢n+O⁢(1)≤p≤n22𝑛𝑂1𝑝𝑛2\sqrt{2n}+O(1)\leq p\leq\frac{n}{2}square-root start_ARG 2 italic_n end_ARG + italic_O ( 1 ) ≤ italic_p ≤ divide start_ARG italic_n end_ARG start_ARG 2 end_ARG [O’Carroll, Srinivas, and Vijayaraghavan, 2022]. However, when p≤2⁢n+O⁢(1)𝑝2𝑛𝑂1p\leq\sqrt{2n}+O(1)italic_p ≤ square-root start_ARG 2 italic_n end_ARG + italic_O ( 1 ), there is a subset of cost matrices C𝐶Citalic_C of positive Lebesgue measure for which (Burer-Monteiro) admits non-optimal critical points [Waldspurger and Waters, 2020] (with a gap to the optimal value scaling in O⁢(1/p)𝑂1𝑝O(1/p)italic_O ( 1 / italic_p ) [Mei, Misiakiewicz, Montanari, and Oliveira, 2017], but strictly positive). Nonetheless, in practice, standard algorithms seem to find a solution of (Burer-Monteiro) below the threshold 2⁢n2𝑛\sqrt{2n}square-root start_ARG 2 italic_n end_ARG, suggesting that, maybe, the set of cost matrices with a non-optimal critical point is small, and “typical” cost matrices do not belong to it. Therefore, researchers have tried to find properties on C𝐶Citalic_C guaranteeing that C𝐶Citalic_C is not in this bad set, focusing for the moment on the setting where the minimizer of (SDP) has rank 1111. The articles [McRae and Boumal, 2024] and [McRae, Abdalla, Bandeira, and Boumal, 2024] discuss matrices C𝐶Citalic_C with a specific structure, motivated by synchronization problems. They prove that the landscape of (Burer-Monteiro) is benign under conditions which involve eigenvalues of the subcomponents of C𝐶Citalic_C. [Ling, 2023] considers general matrices C𝐶Citalic_C and shows that the landscape is benign if the condition number of the associated Laplacian matrix is smaller than p−12𝑝12\frac{p-1}{2}divide start_ARG italic_p - 1 end_ARG start_ARG 2 end_ARG. For important instances of (SDP) (mainly ℤ2subscriptℤ2\mathbb{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-synchronization with additive Gaussian noise and multiplicative Bernoulli noise), these recent results show that standard algorithms, applied to (Burer-Monteiro), retrieve the rank 1111 solution under close to optimal conditions. Main result Our main result is a sufficient condition on the condition number of a certain matrix related to (SDP) which ensures that the landscape of (Burer-Monteiro) is benign. This tightens the result of [Ling, 2023]: we show that if the condition number of the Laplacian matrix associated with C𝐶Citalic_C is less than p𝑝pitalic_p (instead of p−12𝑝12\frac{p-1}{2}divide start_ARG italic_p - 1 end_ARG start_ARG 2 end_ARG in [Ling, 2023]), then the landscape of (Burer-Monteiro) is benign. Furthermore, we show that this bound is essentially optimal. Finally, by applying our theorem to ℤ2subscriptℤ2\mathbb{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-synchronization, we also improve on the applications of [McRae, Abdalla, Bandeira, and Boumal, 2024] and [Ling, 2023]. 1.3 Structure of the paper In section 2, we present our main result and, in section 3, its application to ℤ2subscriptℤ2\mathbb{Z}_{2}blackboard_Z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-synchronization with additive Gaussian noise and Bernoulli noise. In section 4 we provide the proof of the main theorem, without the technical details that we leave for the appendix. 1.4 Notation Throughout this paper, 𝕊n×nsuperscript𝕊𝑛𝑛\mathbb{S}^{n\times n}blackboard_S start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT is the set of symmetric n×n𝑛𝑛n\times nitalic_n × italic_n matrices. We write X⪰0succeeds-or-equals𝑋0X\succeq 0italic_X ⪰ 0 if X𝑋Xitalic_X is a positive semidefinite matrix. For a matrix X∈ℝn×n𝑋superscriptℝ𝑛𝑛X\in\mathbb{R}^{n\times n}italic_X ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT, when it makes sense, λ1⁢(X)≤λ2⁢(X)≤⋯≤λn⁢(X)subscript𝜆1𝑋subscript𝜆2𝑋⋯subscript𝜆𝑛𝑋\lambda_{1}(X)\leq\lambda_{2}(X)\leq\dots\leq\lambda_{n}(X)italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_X ) ≤ italic_λ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_X ) ≤ ⋯ ≤ italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_X ) are the eigenvalues of X𝑋Xitalic_X in ascending order. For matrices X,Y∈ℝn×m𝑋𝑌superscriptℝ𝑛𝑚X,Y\in\mathbb{R}^{n\times m}italic_X , italic_Y ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_m end_POSTSUPERSCRIPT, ⟨X,Y⟩=Tr⁡(XT⁢Y)𝑋𝑌Trsuperscript𝑋𝑇𝑌\left\langle X,Y\right\rangle=\operatorname{Tr}(X^{T}Y)⟨ italic_X , italic_Y ⟩ = roman_Tr ( italic_X start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_Y ) is the standard inner product on ℝn×msuperscriptℝ𝑛𝑚\mathbb{R}^{n\times m}blackboard_R start_POSTSUPERSCRIPT italic_n × italic_m end_POSTSUPERSCRIPT, X⊙Ydirect-product𝑋𝑌X\odot Yitalic_X ⊙ italic_Y is the entry-wise or Hadamard product, ∥X∥F=⟨X,X⟩subscriptdelimited-∥∥𝑋𝐹𝑋𝑋\left\lVert X\right\rVert_{F}=\sqrt{\left\langle X,X\right\rangle}∥ italic_X ∥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT = square-root start_ARG ⟨ italic_X , italic_X ⟩ end_ARG is the Frobenius norm on ℝn×msuperscriptℝ𝑛𝑚\mathbb{R}^{n\times m}blackboard_R start_POSTSUPERSCRIPT italic_n × italic_m end_POSTSUPERSCRIPT, Xi:∈ℝmsubscript𝑋:𝑖absentsuperscriptℝ𝑚X_{i:}\in\mathbb{R}^{m}italic_X start_POSTSUBSCRIPT italic_i : end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT is the i𝑖iitalic_i-th row of X𝑋Xitalic_X and X:j∈ℝnsubscript𝑋:absent𝑗superscriptℝ𝑛X_{:j}\in\mathbb{R}^{n}italic_X start_POSTSUBSCRIPT : italic_j end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is the j𝑗jitalic_j-th column of X𝑋Xitalic_X. For X∈ℝn×m𝑋superscriptℝ𝑛𝑚X\in\mathbb{R}^{n\times m}italic_X ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_m end_POSTSUPERSCRIPT, ∥X∥delimited-∥∥𝑋\left\lVert X\right\rVert∥ italic_X ∥ is the spectral or ℓ2subscriptℓ2\ell_{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT operator norm of X𝑋Xitalic_X and ∥X∥∞subscriptdelimited-∥∥𝑋\left\lVert X\right\rVert_{\infty}∥ italic_X ∥ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT is the ℓ∞subscriptℓ\ell_{\infty}roman_ℓ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT-norm of X𝑋Xitalic_X i.e. the maximum entry in absolute value. The operator ddiag:ℝn×n→𝕊n×n:ddiag→superscriptℝ𝑛𝑛superscript𝕊𝑛𝑛\operatorname{ddiag}:\mathbb{R}^{n\times n}\to\mathbb{S}^{n\times n}roman_ddiag : blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT → blackboard_S start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT zeroes out all the non diagonal entries of a matrix and for any vector x∈ℝn𝑥superscriptℝ𝑛x\in\mathbb{R}^{n}italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, diag⁡(x)∈𝕊n×ndiag𝑥superscript𝕊𝑛𝑛\operatorname{diag}(x)\in\mathbb{S}^{n\times n}roman_diag ( italic_x ) ∈ blackboard_S start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT is the diagonal matrix with the coordinates of x𝑥xitalic_x on the diagonal. For any x,y∈ℝ𝑥𝑦ℝx,y\in\mathbb{R}italic_x , italic_y ∈ blackboard_R the notation x≲yless-than-or-similar-to𝑥𝑦x\lesssim yitalic_x ≲ italic_y means that there exists a constant C>0𝐶0C>0italic_C > 0 that does not depend on any parameter, such that x≤C⁢y𝑥𝐶𝑦x\leq Cyitalic_x ≤ italic_C italic_y. For any vector x∈ℝn𝑥superscriptℝ𝑛x\in\mathbb{R}^{n}italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, ∥x∥delimited-∥∥𝑥\left\lVert x\right\rVert∥ italic_x ∥ is the Euclidean norm of x𝑥xitalic_x, 𝟏n=(1⁢…⁢1)T∈ℝnsubscript1𝑛superscript1…1𝑇superscriptℝ𝑛\operatorname{\mathbf{1}}_{n}=(1\dots 1)^{T}\in\mathbb{R}^{n}bold_1 start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( 1 … 1 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT."
https://arxiv.org/html/2411.03096v1,On the Complexity of Pure-State Consistency of Local Density Matrices,"In this work we investigate the computational complexity of the pure consistency of local density matrices (𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM) and pure N𝑁Nitalic_N-representability (𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability) problems. In these problems the input is a set of reduced density matrices and the task is to determine whether there exists a global pure state consistent with these reduced density matrices. While mixed 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM, i.e. where the global state can be mixed, was proven to be 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-complete by Broadbent and Grilo [JoC 2022], almost nothing was known about the complexity of the pure version. Before our work the best upper and lower bounds were 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) and 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA. Our contribution to the understanding of these problems is twofold.Firstly, we define a pure state analogue of the complexity class 𝖰𝖬𝖠+limit-from𝖰𝖬𝖠\mathsf{QMA}{+}sansserif_QMA + of Aharanov and Regev [FOCS 2003], which we call 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA. We prove that both 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability and 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM are complete for this new class. Along the way we supplement Broadbent and Grilo by proving hardness for 2-qubit reduced density matrices and showing that mixed N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒N\mathchar 45\relax\mathsf{Representability}italic_N - sansserif_Representability is 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA complete.Secondly, we improve the upper bound on 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. Using methods from algebraic geometry, we prove that 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⊆𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PureSuperQMA}\subseteq\mathsf{PSPACE}sansserif_PureSuperQMA ⊆ sansserif_PSPACE. Our methods, and the 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound, are also valid for 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM with exponential or even perfect precision, hence 𝗉𝗋𝖾𝖼𝗂𝗌𝖾−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝗉𝗋𝖾𝖼𝗂𝗌𝖾𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{precise\mathchar 45\relax PureCLDM}sansserif_precise - sansserif_PureCLDM is not 𝗉𝗋𝖾𝖼𝗂𝗌𝖾−𝖰𝖬𝖠⁢(𝟤)=𝖭𝖤𝖷𝖯𝗉𝗋𝖾𝖼𝗂𝗌𝖾𝖰𝖬𝖠2𝖭𝖤𝖷𝖯\mathsf{precise\mathchar 45\relax QMA(2)}=\mathsf{NEXP}sansserif_precise - sansserif_QMA ( sansserif_2 ) = sansserif_NEXP-complete, unless 𝖯𝖲𝖯𝖠𝖢𝖤=𝖭𝖤𝖷𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖤𝖷𝖯\mathsf{PSPACE}=\mathsf{NEXP}sansserif_PSPACE = sansserif_NEXP. We view this as evidence for a negative answer to the longstanding open question whether 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM is 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-complete.","“Are these local density matrices consistent with some global state?” This problem, known as the consistency of local density matrices problem (𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM) or quantum marginal problem, and as the N𝑁Nitalic_N-representability problem (N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒N\mathchar 45\relax\mathsf{Representability}italic_N - sansserif_Representability) when dealing with indistinguishable particles, is of fundamental importance to quantum physics. In fact, it was already recognized as an important question in the sixties [Col63]. At that time, the hope was that the ground state energy of quantum systems could be found using reduced density matrices. This hope was supported by the fact that Hamiltonians showing up in nature are all local. One requirement would be that it is possible to check that alleged reduced density matrices are indeed consistent with a valid global quantum state, hence the interest in the 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM problem. Over the years it became apparent that this hope would not materialize, especially when Kitaev proved that computing ground state energies of local Hamiltonians is 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard [KSV02]. Also the 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM problem itself was proven to be hard. First by Liu, who proved that the (mixed state) 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM problem is contained in 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA and 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-complete under Turing reductions [Liu06] and later, together with Christandl and Verstraete, proved that the N𝑁Nitalic_N-representability problem is also 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-complete under Turing reductions [LCV07]. This was improved by Broadbent and Grilo who showed that the mixed 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM is also 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard under Karp reductions, establishing it as 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA complete [BG22]. While the complexity of the mixed 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM and mixed N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒N\mathchar 45\relax\mathsf{Representability}italic_N - sansserif_Representability is quite well understood, our understanding of the pure versions, 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM and 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability, is limited. In these pure versions, one imposes the additional restriction that the consistent state should be pure. This restriction is quite natural as an (isolated) quantum system whose state is known exactly will be in a pure state [NC10]. Whereas mixed 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM is contained in 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA, it is unknown whether a similar containment holds for 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. Instead, Liu, Christandl and Verstraete prove a 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) upper bound to the fermionic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability. They leave completeness as an open problem, one that remains open to this day. A similar upper bound for the bosonic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability was proven in [WMN10]. However, as the best known upper bound to 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) is 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP, these results do not narrow down the complexity of 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability much. Our results In this work we investigate the complexity of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM and 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability and give evidence towards a negative answer to the longstanding open question whether they are 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-complete. Definition 1.1 (k−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝑘𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬k\mathchar 45\relax\mathsf{PureCLDM}italic_k - sansserif_PureCLDM, informal). We are given pairs (ρm,Cm),…,(ρm,Cm)subscript𝜌𝑚subscript𝐶𝑚…subscript𝜌𝑚subscript𝐶𝑚(\rho_{m},C_{m}),\dots,(\rho_{m},C_{m})( italic_ρ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ) , … , ( italic_ρ start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_C start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ), where the ρisubscript𝜌𝑖\rho_{i}italic_ρ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are reduced density matrices and Ci⊆[n]subscript𝐶𝑖delimited-[]𝑛C_{i}\subseteq[n]italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⊆ [ italic_n ] with |Ci|≤ksubscript𝐶𝑖𝑘\lvert C_{i}\rvert\leq k| italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | ≤ italic_k for all i𝑖iitalic_i. Additionally, we are given parameters α𝛼\alphaitalic_α and β𝛽\betaitalic_β with β−α≥1/poly⁡(n)𝛽𝛼1poly𝑛\beta-\alpha\geq 1/\operatorname{poly}(n)italic_β - italic_α ≥ 1 / roman_poly ( italic_n ). Decide whether: • YES: there exists a consistent pure state, that is, a state |ψ⟩delimited-|⟩𝜓\lvert\psi\rangle| italic_ψ ⟩ such that ∥TrCi¯(|ψ⟩⟨ψ|)−ρi∥≤α\lVert\operatorname{Tr}_{\overline{C_{i}}}(\lvert\psi\rangle\langle\psi\rvert)% -\rho_{i}\rVert\leq\alpha∥ roman_Tr start_POSTSUBSCRIPT over¯ start_ARG italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG end_POSTSUBSCRIPT ( | italic_ψ ⟩ ⟨ italic_ψ | ) - italic_ρ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ ≤ italic_α for all i∈[m]𝑖delimited-[]𝑚i\in[m]italic_i ∈ [ italic_m ]. • NO: all pure states are “far from” consistent, that is, for all |ψ⟩delimited-|⟩𝜓\lvert\psi\rangle| italic_ψ ⟩, there is an i∈[m]𝑖delimited-[]𝑚i\in[m]italic_i ∈ [ italic_m ] with ∥TrCi¯(|ψ⟩⟨ψ|)−ρi∥≥β\lVert\operatorname{Tr}_{\overline{C_{i}}}(\lvert\psi\rangle\langle\psi\rvert)% -\rho_{i}\rVert\geq\beta∥ roman_Tr start_POSTSUBSCRIPT over¯ start_ARG italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG end_POSTSUBSCRIPT ( | italic_ψ ⟩ ⟨ italic_ψ | ) - italic_ρ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ ≥ italic_β We begin our study of the complexity of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM by defining a new complexity class, which we call 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA, inspired by the class 𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{SuperQMA}sansserif_SuperQMA222𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{SuperQMA}sansserif_SuperQMA was called 𝖰𝖬𝖠+limit-from𝖰𝖬𝖠\mathsf{QMA}{+}sansserif_QMA + in [AR03], but recently 𝖰𝖬𝖠+superscript𝖰𝖬𝖠\mathsf{QMA}^{+}sansserif_QMA start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT has been used to refer to 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA with proofs with nonnegative amplitudes [JW23, BFM24]. As 𝖰𝖬𝖠+limit-from𝖰𝖬𝖠\mathsf{QMA}{+}sansserif_QMA + is sometimes referred to as 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA with a super-verifier, we use 𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{SuperQMA}sansserif_SuperQMA. from [AR03]. Definition 1.2 (𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA, informal). A promise problem A𝐴Aitalic_A is in 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(m,ε,δ)𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝑚𝜀𝛿\mathsf{PureSuperQMA}(m,\varepsilon,\delta)sansserif_PureSuperQMA ( italic_m , italic_ε , italic_δ ) if there exist m𝑚mitalic_m constraints 𝒱={(Vx,i,rx,i,sx,i)}i∈[m]𝒱subscriptsubscript𝑉𝑥𝑖subscript𝑟𝑥𝑖subscript𝑠𝑥𝑖𝑖delimited-[]𝑚\mathcal{V}=\{(V_{x,i},r_{x,i},s_{x,i})\}_{i\in[m]}caligraphic_V = { ( italic_V start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT ) } start_POSTSUBSCRIPT italic_i ∈ [ italic_m ] end_POSTSUBSCRIPT such that: • ∀x∈Ayes∃|ψ⟩:Pri(|p(Vx,i,ψ)−rx,i|≤sx,i)=1\forall x\in A_{\textup{yes}}\;\exists\lvert\psi\rangle\colon\Pr_{i}(\lvert p(% V_{x,i},\psi)-r_{x,i}\rvert\leq s_{x,i})=1∀ italic_x ∈ italic_A start_POSTSUBSCRIPT yes end_POSTSUBSCRIPT ∃ | italic_ψ ⟩ : roman_Pr start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( | italic_p ( italic_V start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT , italic_ψ ) - italic_r start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT | ≤ italic_s start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT ) = 1, that is, the Vx,isubscript𝑉𝑥𝑖V_{x,i}italic_V start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT accept |ψ⟩delimited-|⟩𝜓\lvert\psi\rangle| italic_ψ ⟩ with acceptance probability at most sx,isubscript𝑠𝑥𝑖s_{x,i}italic_s start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT away from rx,isubscript𝑟𝑥𝑖r_{x,i}italic_r start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT. • ∀x∈Ano∀|ψ⟩:Pri(|p(Vx,i,ψ)−rx,i|≤sx,i+ε)≤1−δ\forall x\in A_{\textup{no}}\;\forall\lvert\psi\rangle\colon\Pr_{i}(\lvert p(V% _{x,i},\psi)-r_{x,i}\rvert\leq s_{x,i}+\varepsilon)\leq 1-\delta∀ italic_x ∈ italic_A start_POSTSUBSCRIPT no end_POSTSUBSCRIPT ∀ | italic_ψ ⟩ : roman_Pr start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( | italic_p ( italic_V start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT , italic_ψ ) - italic_r start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT | ≤ italic_s start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT + italic_ε ) ≤ 1 - italic_δ, that is, at least a δ𝛿\deltaitalic_δ fraction of the Vx,isubscript𝑉𝑥𝑖V_{x,i}italic_V start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT accept |ψ⟩delimited-|⟩𝜓\lvert\psi\rangle| italic_ψ ⟩ with probability more than sx,i+εsubscript𝑠𝑥𝑖𝜀s_{x,i}+\varepsilonitalic_s start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT + italic_ε away from rx,isubscript𝑟𝑥𝑖r_{x,i}italic_r start_POSTSUBSCRIPT italic_x , italic_i end_POSTSUBSCRIPT. We denote the union of 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(m,ε,δ)𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝑚𝜀𝛿\mathsf{PureSuperQMA}(m,\varepsilon,\delta)sansserif_PureSuperQMA ( italic_m , italic_ε , italic_δ ) where m𝑚mitalic_m is polynomial and ε𝜀\varepsilonitalic_ε and δ𝛿\deltaitalic_δ are inverse polynomial as 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(poly,1/poly,1/poly)-:𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠-:𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠poly1poly1poly𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}(\operatorname{poly},1/\operatorname{poly},1/% \operatorname{poly})\eqcolon\mathsf{PureSuperQMA}sansserif_PureSuperQMA ( roman_poly , 1 / roman_poly , 1 / roman_poly ) -: sansserif_PureSuperQMA. We prove that by varying the parameters of 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA one gets a range of complexity classes going all the way up to 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP: Proposition 1.3. 𝖰𝖬𝖠⊆𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⊆𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(exp,1/poly,1/poly)⊆𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠1poly1poly𝖰𝖬𝖠2\mathsf{QMA}\subseteq\mathsf{PureSuperQMA}\subseteq\mathsf{PureSuperQMA}(\exp,% 1/\operatorname{poly},1/\operatorname{poly})\subseteq\mathsf{QMA}(2)sansserif_QMA ⊆ sansserif_PureSuperQMA ⊆ sansserif_PureSuperQMA ( roman_exp , 1 / roman_poly , 1 / roman_poly ) ⊆ sansserif_QMA ( 2 ). Proposition 1.4. 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(exp,1/exp,1/exp)=𝖭𝖤𝖷𝖯𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠11𝖭𝖤𝖷𝖯\mathsf{PureSuperQMA}(\exp,1/\exp,1/\exp)=\mathsf{NEXP}sansserif_PureSuperQMA ( roman_exp , 1 / roman_exp , 1 / roman_exp ) = sansserif_NEXP Next, we give a “normal form” for 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA. We show that the complexity does not change if we restrict ourselves to constraints (Vi,ri,si)subscript𝑉𝑖subscript𝑟𝑖subscript𝑠𝑖(V_{i},r_{i},s_{i})( italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) with ri=12subscript𝑟𝑖12r_{i}=\frac{1}{2}italic_r start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG 2 end_ARG and si=0subscript𝑠𝑖0s_{i}=0italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 0. We use this to prove our first main result, which is that 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA captures the complexity of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. In fact, we are able to show hardness even for k−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬1𝑘subscript𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬1k\mathchar 45\relax\mathsf{PureCLDM}_{1}italic_k - sansserif_PureCLDM start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, which is k−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝑘𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬k\mathchar 45\relax\mathsf{PureCLDM}italic_k - sansserif_PureCLDM with “exact consistency” (α=0𝛼0\alpha=0italic_α = 0). Theorem 1.5. k−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬1𝑘subscript𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬1k\mathchar 45\relax\mathsf{PureCLDM}_{1}italic_k - sansserif_PureCLDM start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-complete for all k≥2𝑘2k\geq 2italic_k ≥ 2. We also show completeness for both fermionic and bosonic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability. Theorem 1.6. Fermionic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒1𝖯𝗎𝗋𝖾𝑁subscript𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒1\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}_{1}sansserif_Pure - italic_N - sansserif_Representability start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-complete. Theorem 1.7. Bosonic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒1𝖯𝗎𝗋𝖾𝑁subscript𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒1\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}_{1}sansserif_Pure - italic_N - sansserif_Representability start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-complete. Combining Propositions 1.3 and 1.5 we conclude that 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA can only be 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-complete if a polynomial number of constraints give the same power as exponentially many constraints. Corollary 1.8. If 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(poly,1/poly,1/poly)⊊𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(exp,1/poly,1/poly)𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠poly1poly1poly𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠1poly1poly\mathsf{PureSuperQMA}(\operatorname{poly},1/\operatorname{poly},1/% \operatorname{poly})\subsetneq\mathsf{PureSuperQMA}(\exp,1/\operatorname{poly}% ,1/\operatorname{poly})sansserif_PureSuperQMA ( roman_poly , 1 / roman_poly , 1 / roman_poly ) ⊊ sansserif_PureSuperQMA ( roman_exp , 1 / roman_poly , 1 / roman_poly ), then 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM is not 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-hard. Along the way to Theorem 1.5, we show that the k−𝖢𝖫𝖣𝖬𝑘𝖢𝖫𝖣𝖬k\mathchar 45\relax\mathsf{CLDM}italic_k - sansserif_CLDM problem is already 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard for k≥2𝑘2k\geq 2italic_k ≥ 2. This improves upon the results by Broadbent and Grilo [BG22] who show hardness for k≥5𝑘5k\geq 5italic_k ≥ 5. We also resolve one of their open questions by showing that the (mixed) fermionic and bosonic N𝑁Nitalic_N-representability problems are 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard, already for 2222-particle reduced density matrices. Having proven Theorem 1.5, we address the relation between 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA and other complexity classes. Our second main result sharpens the upper bound on the complexity of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM from 𝖰𝖬𝖠⁢(2)⊆𝖭𝖤𝖷𝖯𝖰𝖬𝖠2𝖭𝖤𝖷𝖯\mathsf{QMA}(2)\subseteq\mathsf{NEXP}sansserif_QMA ( 2 ) ⊆ sansserif_NEXP to 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE. Theorem 1.9. 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⊆𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PureSuperQMA}\subseteq\mathsf{PSPACE}sansserif_PureSuperQMA ⊆ sansserif_PSPACE. What does this mean for 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )? Of course showing that 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM is 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-hard would imply 𝖰𝖬𝖠⁢(2)⊆𝖯𝖲𝖯𝖠𝖢𝖤𝖰𝖬𝖠2𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{QMA}(2)\subseteq\mathsf{PSPACE}sansserif_QMA ( 2 ) ⊆ sansserif_PSPACE but there is a catch. To prove Theorem 1.9 we use methods from algebraic geometry that also work for 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA with exponential precision and even with perfect precision. This allows us to obtain the following corollary which can be interpreted as evidence that 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM is not 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-hard. Corollary 1.10. If 𝗉𝗋𝖾𝖼𝗂𝗌𝖾−𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝗉𝗋𝖾𝖼𝗂𝗌𝖾𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{precise\mathchar 45\relax PureCLDM}sansserif_precise - sansserif_PureCLDM is 𝖰𝖬𝖠⁢(2)𝖾𝗑𝗉𝖰𝖬𝖠subscript2𝖾𝗑𝗉\mathsf{QMA}(2)_{\mathsf{exp}}sansserif_QMA ( 2 ) start_POSTSUBSCRIPT sansserif_exp end_POSTSUBSCRIPT-hard, then 𝖯𝖲𝖯𝖠𝖢𝖤=𝖭𝖤𝖷𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖤𝖷𝖯\mathsf{PSPACE}=\mathsf{NEXP}sansserif_PSPACE = sansserif_NEXP. This means that, assuming 𝖯𝖲𝖯𝖠𝖢𝖤≠𝖭𝖤𝖷𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖤𝖷𝖯\mathsf{PSPACE}\neq\mathsf{NEXP}sansserif_PSPACE ≠ sansserif_NEXP, any 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-hardness proof for 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM must fail for their precise versions. To prove Theorem 1.9 we rely results by Grigoriev and Pasechnik [GP05] that can solve certain large polynomials in exponential time. We modify their algorithm to work in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE and get the following result which is worth stating in its own right. Theorem 1.11 (informal). Let p:ℝn→ℝ:𝑝→superscriptℝ𝑛ℝp\colon\mathbb{R}^{n}\to\mathbb{R}italic_p : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → blackboard_R and Q:ℝN→ℝn:𝑄→superscriptℝ𝑁superscriptℝ𝑛Q\colon\mathbb{R}^{N}\to\mathbb{R}^{n}italic_Q : blackboard_R start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT be polynomials where the degree of Q𝑄Qitalic_Q is at most 2 and N=2n𝑁superscript2𝑛N=2^{n}italic_N = 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Assume that the zeros of p⁢(Q⁢(X))𝑝𝑄𝑋p(Q(X))italic_p ( italic_Q ( italic_X ) ) are bounded. Then there exists a 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE algorithm for determining whether p⁢(Q⁢(X))=0𝑝𝑄𝑋0p(Q(X))=0italic_p ( italic_Q ( italic_X ) ) = 0 has a solution. We also show that approximate solutions to p⁢(Q⁢(X))𝑝𝑄𝑋p(Q(X))italic_p ( italic_Q ( italic_X ) ) can be computed in (function) 𝖭𝖢⁢(poly)𝖭𝖢poly\mathsf{NC}(\operatorname{poly})sansserif_NC ( roman_poly ). Hence an approximately consistent state for a given 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM instance can be computed in 𝖭𝖢⁢(poly)𝖭𝖢poly\mathsf{NC}(\operatorname{poly})sansserif_NC ( roman_poly ), if this exists. Finally, we showcase the applicability Theorem 1.11 by giving some applications. In the first of these applications we improve upon a result by Shi and Wu. In [SW15] they give a 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE algorithm for optimizing the energy of “decomposable” Hamiltonians over separable states. Using our framework we are able to reprove this fact, and even get a better runtime dependence on the error. As a second application, we show that deciding if there exists a unique333We say a state |ϕ⟩delimited-|⟩italic-ϕ\lvert\phi\rangle| italic_ϕ ⟩ is the unique state consistent with some local density matrices if any state that is orthogonal to |ϕ⟩delimited-|⟩italic-ϕ\lvert\phi\rangle| italic_ϕ ⟩ is far from consistent. pure state that is consistent with given local density matrices is also in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE. In other words, we can decide in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE whether the local density matrices fully describe the physics of the system. As a final application, we show how to decide a variant of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM, where the input only specifies the spectrum of the local density matrices. This version is sometimes referred to as the quantum marginal problem, although others use that name for our 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. Proof techniques We now sketch the proofs of our main theorems, organized by topic. 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-hardness. The proof of the 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-completeness of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM closely follows Broadbent and Grilo’s proof of the 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hardness of the mixed 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM problem but with several key changes. Before we elaborate on those, let us sketch the original proof. Starting with an arbitrary 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-verifier V𝑉Vitalic_V, one can use Kitaev’s circuit-to-Hamiltonian construction to obtain a Hamiltonian whose low energy states include the history state of the computation. One would like to construct local density matrices that are consistent with a global state (the history state) if and only if the original computation was accepting. However, one obstacle is the dependence of the history state on the witness (or proof) state. To circumvent this problem, Broadbent and Grilo use s𝑠sitalic_s-simulatable codes from [GSY19]. These are codes whose codewords are s𝑠sitalic_s-simulatable, that is, their reduced density matrices on at most s𝑠sitalic_s qubits can be efficiently computed by a classical algorithm, just like their evolution under local unitaries. They now consider a different verification circuit V′superscript𝑉′V^{\prime}italic_V start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT that implements the original circuit V𝑉Vitalic_V on data encoded with such an s𝑠sitalic_s-simulatable code, starting from a similarly encoded proof state. From the properties of the code, it follows that the reduced density matrices of the history state corresponding to V′superscript𝑉′V^{\prime}italic_V start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT can be efficiently constructed. As the final step of the proof, it is shown that these reduced density matrices indeed are consistent if and only if the original computation was accepting. To adapt this approach to our needs we make several important changes. 1. To make sure that the proof is indeed encoded correctly, Broadbent and Grilo add a step to their protocol enforcing this, which essentially boils down to decoding and immediately encoding again. To make sure that the reduced density matrices can also be computed during this process, they ask for the proof as encrypted by a one-time pad, together with the keys. This one-time pad is then undone only after checking the encoding. It is this one-time padding that makes the consistent state a mixed state, which we want to avoid. To do so we reduce the number of possible one-time pad keys and do a separate check for each key. We do this by using the same key for the one-time pad encryption of every qubit. This means that individual proof qubits are still in a maximally mixed state, but there are only 4444 different keys. We abstract this change away into a modified super-verifier that has an accepting proof with maximally mixed 1111-local density matrices (see Section 3.1.2). 2. We use the 2222-local circuit-to-Hamiltonian construction of [KKR06] instead of Kitaev’s original 5555-local construction [KSV02]. This is so we can easily extend to the N𝑁Nitalic_N-representability problem, which is ordinarily defined with 2222-particle density matrices. Using this different construction causes some technical issues. To resolve these we introduce an “Extraction Lemma”, which allows extracting 1111-local density matrices at certain time steps from the 2222-local density matrices of the history state (see Section 3.1.2). 3. We need to check the proof against multiple constraints. For each constraint, we apply its circuit, decode the output qubit, encode the output qubit, and finally undo the circuit (see Section 3.1.3). The output probability can be extract from the time step between decoding and encoding. 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound. The main obstacle to prove the 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound is that the purity constraint is not a convex constraint. This prevents convex optimization approaches from being used, which are the standard for proving containment in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE. We take a wholly different approach: we convert a 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA instance into a system of polynomials and use methods from algebraic geometry to solve these. We begin by writing Pr(Vi accepts |ψ⟩)−12\Pr(V_{i}\text{ accepts }\lvert\psi\rangle)-\frac{1}{2}roman_Pr ( italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT accepts | italic_ψ ⟩ ) - divide start_ARG 1 end_ARG start_ARG 2 end_ARG as a real multivariate polynomial. The real and complex parts of every coefficient of the proof state will be represented by separate variables. This yields for every constraint Visubscript𝑉𝑖V_{i}italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, a polynomial Qi:ℝ2⁢N→ℝ:subscript𝑄𝑖→superscriptℝ2𝑁ℝQ_{i}\colon\mathbb{R}^{2N}\to\mathbb{R}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT 2 italic_N end_POSTSUPERSCRIPT → blackboard_R, where N=2n𝑁superscript2𝑛N=2^{n}italic_N = 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is the dimension of the proof state. These Qisubscript𝑄𝑖Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are polynomials in exponentially many variables, which might seem bad as it is 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP-hard to determine if a general polynomial in exponentially many variables of degree ≥4absent4\geq 4≥ 4 has a zero.444The statement for degree d≥4𝑑4d\geq 4italic_d ≥ 4 follows because linear programming over 0−1010\mathchar 45\relax 10 - 1 with exponentially many variables is 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP-hard. Restriction to 0−1010\mathchar 45\relax 10 - 1 can be enforced by the quartic polynomial equality ∑i(xi2−1)2=0subscript𝑖superscriptsuperscriptsubscript𝑥𝑖2120\sum_{i}(x_{i}^{2}-1)^{2}=0∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - 1 ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0. It is also 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP hard to determine if a system of degree 3333 polynomials has a zero. To see this we use 𝖰𝖬𝖠⁢(2)𝖾𝗑𝗉=𝖭𝖤𝖷𝖯𝖰𝖬𝖠subscript2𝖾𝗑𝗉𝖭𝖤𝖷𝖯\mathsf{QMA}(2)_{\mathsf{exp}}=\mathsf{NEXP}sansserif_QMA ( 2 ) start_POSTSUBSCRIPT sansserif_exp end_POSTSUBSCRIPT = sansserif_NEXP. The acceptance probability ⟨ψ|Πa⁢c⁢c|ψ⟩\langle\psi\rvert\Pi_{acc}\lvert\psi\rangle⟨ italic_ψ | roman_Π start_POSTSUBSCRIPT italic_a italic_c italic_c end_POSTSUBSCRIPT | italic_ψ ⟩ is a quadratic polynomial and the restriction to separable proofs can be enforced using the degree 3333 polynomial ⟨ψ|(|ϕ1⟩⊗|ϕ2⟩)−1=0\langle\psi\rvert(\lvert\phi_{1}\rangle\otimes\lvert\phi_{2}\rangle)-1=0⟨ italic_ψ | ( | italic_ϕ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⟩ ⊗ | italic_ϕ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ⟩ ) - 1 = 0. However, and this turns out to be crucial, the Qisubscript𝑄𝑖Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT have a degree of a most 2222. We combine the Qisubscript𝑄𝑖Q_{i}italic_Q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by taking another specially constructed polynomial p𝑝pitalic_p, this one with polynomially many variables and degree d=poly⁡(n)𝑑poly𝑛d=\operatorname{poly}(n)italic_d = roman_poly ( italic_n ), and considering p⁢(Q⁢(X))=0𝑝𝑄𝑋0p(Q(X))=0italic_p ( italic_Q ( italic_X ) ) = 0. We ensure that this latter equation will have a solution iff the 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA verifier accepts. To solve this system, we use results by Grigoriev and Pasechnik [GP05]. To our knowledge, this is the first time these techniques are used in a quantum context. Because the techniques are quite general and powerful we hope they will find more use there. Grigoriev and Pasechnik exhibit an algorithm for solving such systems p⁢(Q⁢(X))=0𝑝𝑄𝑋0p(Q(X))=0italic_p ( italic_Q ( italic_X ) ) = 0 with quadratic Q𝑄Qitalic_Q in exponential time. We will refer to such polynomials as GP systems. We modify their algorithm to get an efficient parallel algorithm, that is, an 𝖭𝖢⁢(poly)=𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖢poly𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{NC}(\operatorname{poly})=\mathsf{PSPACE}sansserif_NC ( roman_poly ) = sansserif_PSPACE algorithm for deciding if there is a zero. Broadly, their original algorithm consists of two steps. First, they show how such a system p⁢(Q⁢(X))=0𝑝𝑄𝑋0p(Q(X))=0italic_p ( italic_Q ( italic_X ) ) = 0 can be reduced to a set of (exponentially many) different polynomial systems, each consisting of polynomially many equations in only polynomially many variables. These smaller systems are called “pieces”. They prove that solutions to the original system, at least one in every connected component, can be recovered from the solutions of the pieces. The pieces could be solved using standard methods in exponential time or 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE, but there is a catch: for the reduction of the number of variables, Grigoriev and Pasechnik rely on three key assumptions. These are almost always555They are generically true. Informally, this means that there is some polynomial that is 0 iff they do not hold. satisfied, but can fail for certain degenerate cases. To circumvent this issue, they consider small perturbations of the original system and show that for sufficiently small values of these perturbations all assumptions are satisfied. Next, they show that the solutions to the original system are exactly equal to the limits of solutions of the perturbed system as the perturbations go to 00. The second part of their work is concerned with the computation of these limits. To get an efficient parallel algorithm, we mostly leave the first step as it is, but compute the limits differently. Whereas Grigoriev and Pasechnik consider the solutions of the perturbed systems as Puiseux series in the (infinitesimal) perturbations, we consider the perturbations as variables and the zeros as a set-valued function of these variables. We show that in this perspective the zeros of the original system are still equal to the limits of the solutions of the perturbed system. Our new perspective allows us to write the limit of the set of solutions as the set of points satisfying some formula in the first-order theory of the reals. A 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE algorithm for deciding the first-order theory of the reals (we use [Ren92-2]) can now be used to determine, for each piece, whether the corresponding solution set is empty. Doing these checks for all of the exponentially many pieces in parallel results in a 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE algorithm for deciding if p⁢(Q⁢(X))𝑝𝑄𝑋p(Q(X))italic_p ( italic_Q ( italic_X ) ) has any solutions. The approximation algorithm follows by using an algorithm to find approximate solutions to first-order theory of the reals formulas [Ren92-4]. We cannot directly use this to extract the entire solution though, as the number of entries is too big. Instead, we isolate a solution using a univariate encoding and extract all entries in parallel. With this setup, the three applications that we exhibit follow straightforwardly. We describe how to write them as GP systems, which can then be solved in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE. Related work The computational complexity of (mixed) 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM and N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒N\mathchar 45\relax\mathsf{Representability}italic_N - sansserif_Representability has previously been studied by Liu, Broadbent and Grilo, as mentioned before. Liu [Liu06] proves that (mixed) 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM is contained in 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA and hard under Turing reductions. Similar results for N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒N\mathchar 45\relax\mathsf{Representability}italic_N - sansserif_Representability are proven in [LCV07]. This was improved by Broadbent and Grilo who proved (among other results regarding zero-knowledge proof systems) that (mixed) 𝖢𝖫𝖣𝖬𝖢𝖫𝖣𝖬\mathsf{CLDM}sansserif_CLDM is also 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard under Karp reductions, thereby fully resolving its complexity [BG22]. Both Liu, and Broadbent and Grilo do not intensively study 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM, although [LCV07] does show containment of fermionic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability in 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ), leaving hardness as an open question. A similar containment for bosonic 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability was shown in [WMN10]. That does not mean that 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM and 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability have not been studied before. There is a large body of work focussing on finding necessary and/or sufficient conditions for reduced density matrices to be consistent with a global state. Among these works is [Kly04], which focuses on the case where the reduced density matrices are non-overlapping. The paper establishes conditions that are necessary and sufficient for the existence of a consistent pure state in this case. Mazziotti [Maz16] derives necessary conditions for a two-fermion density matrix to have a consist global N𝑁Nitalic_N-fermion pure state. [YSWNG21] rewrite 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM as an optimization problem over separable state. They then apply the method of symmetric extensions to this notoriously hard problem to describe 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM as a hierarchy of SDP’s. That is, they describe SDP’s depending on a parameter N𝑁Nitalic_N such that any “No” instance will be discovered by the SDP for sufficiently large N𝑁Nitalic_N. They do not, however, prove any upper bounds on the size of N𝑁Nitalic_N required. In [BFLMW24], the authors consider 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA with an internally separable proof. They prove that when this proof is mixed, the class is contained in 𝖤𝖷𝖯𝖤𝖷𝖯\mathsf{EXP}sansserif_EXP, whereas it is equal to 𝖭𝖤𝖷𝖯𝖭𝖤𝖷𝖯\mathsf{NEXP}sansserif_NEXP if the proof is pure. This provides the, to our knowledge first, instance where pure proofs are provably stronger than mixed proofs, modulo standard complexity theoretic assumptions. An algorithm for solving polynomial systems more general than those considered in Theorem 1.11 is given in [Gri13]. It shows that a system of k𝑘kitalic_k polynomials of degree d𝑑ditalic_d in n𝑛nitalic_n variables can be solved in time poly⁡(nd3⁢k)polysuperscript𝑛superscript𝑑3𝑘\operatorname{poly}\left(n^{d^{3k}}\right)roman_poly ( italic_n start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT 3 italic_k end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). One downside to this algorithm is that it finds solution over the complex numbers instead of the reals. This makes it hard to constrain the norm of variables, as the complex conjugate is not a polynomial. Discussion and open questions Our work sheds some more light on the complexity of 𝖯𝗎𝗋𝖾−N−𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒𝖯𝗎𝗋𝖾𝑁𝖱𝖾𝗉𝗋𝖾𝗌𝖾𝗇𝗍𝖺𝖻𝗂𝗅𝗂𝗍𝗒\mathsf{Pure}\mathchar 45\relax N\mathchar 45\relax\mathsf{Representability}sansserif_Pure - italic_N - sansserif_Representability and 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. However, the story is far from complete as the relation between 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA and 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA or 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE remains poorly understood. We conjecture Conjecture 1.12. 𝖰𝖬𝖠⊊𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⊊𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖰𝖬𝖠2\mathsf{QMA}\subsetneq\mathsf{PureSuperQMA}\subsetneq\mathsf{QMA}(2)sansserif_QMA ⊊ sansserif_PureSuperQMA ⊊ sansserif_QMA ( 2 ). We give some evidence that 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA differs from 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ). Indeed, we prove that their precise versions are equal only if 𝖯𝖲𝖯𝖠𝖢𝖤=𝖭𝖤𝖷𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖤𝖷𝖯\mathsf{PSPACE}=\mathsf{NEXP}sansserif_PSPACE = sansserif_NEXP. However, this does not necessarily carry over from the precise setting to the “standard” setting. It would therefore be nice to see more evidence that 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⊊𝖰𝖬𝖠⁢(2)𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖰𝖬𝖠2\mathsf{PureSuperQMA}\subsetneq\mathsf{QMA}(2)sansserif_PureSuperQMA ⊊ sansserif_QMA ( 2 ), such as an oracle separation. Of course, separating 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA from 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) relative to an oracle is at least as hard as separating 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA from 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) in this way, something that has been eluding researchers to this date. Perhaps, however, the new perspective offered by 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA can lead to new insights. Recently, it has been suggested that purity testing is at the heart of 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )’s power[BFLMW24]. While we provide evidence that 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM is not 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )-hard, that does not mean the end for this suggestion. One way to formalize the idea that 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 )’s power derives from purity would be to prove that 𝖰𝖬𝖠⁢(2)=𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠⁢(exp,1/poly,1/poly)𝖰𝖬𝖠2𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠1poly1poly\mathsf{QMA}(2)=\mathsf{PureSuperQMA}(\exp,1/\operatorname{poly},1/% \operatorname{poly})sansserif_QMA ( 2 ) = sansserif_PureSuperQMA ( roman_exp , 1 / roman_poly , 1 / roman_poly ). Note that our results do not provide evidence against this equality, as the 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound crucially relies on there being only polynomially many constraints. Lastly, it would be nice to see if the GP system framework used for our 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound can find other uses. An approach one could take here is to try to use it for a 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE or 𝖤𝖷𝖯𝖤𝖷𝖯\mathsf{EXP}sansserif_EXP upper bound on 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ). There are two main obstacles here. Firstly, any such approach needs to make essential use of the promise gap in order to work for 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) but not for 𝖰𝖬𝖠⁢(2)𝖾𝗑𝗉𝖰𝖬𝖠subscript2𝖾𝗑𝗉\mathsf{QMA}(2)_{\mathsf{exp}}sansserif_QMA ( 2 ) start_POSTSUBSCRIPT sansserif_exp end_POSTSUBSCRIPT (assuming 𝖯𝖲𝖯𝖠𝖢𝖤≠𝖭𝖤𝖷𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖭𝖤𝖷𝖯\mathsf{PSPACE}\neq\mathsf{NEXP}sansserif_PSPACE ≠ sansserif_NEXP). Secondly, naively converting a 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) instance into polynomials yields degree 3, for which the techniques from [GP05] no longer work. One potential way around this is to use the fact that [GP05] can find a point in every connected component of the solutions. Perhaps it is possible to write a 𝖰𝖬𝖠⁢(2)𝖰𝖬𝖠2\mathsf{QMA}(2)sansserif_QMA ( 2 ) instance as degree-2 polynomials in such a way that, although invalid solutions666I.e. solutions that do not have the required tensor product structure. may exist, these will not be in the same connected component as the valid solutions. In this case, a valid solution would always be found if one exists. Organization The paper consists of three main parts. In the first part, we formally define 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA and prove some of its properties. The second part is devoted to proving the 𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠𝖯𝗎𝗋𝖾𝖲𝗎𝗉𝖾𝗋𝖰𝖬𝖠\mathsf{PureSuperQMA}sansserif_PureSuperQMA-completeness of 𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬𝖯𝗎𝗋𝖾𝖢𝖫𝖣𝖬\mathsf{PureCLDM}sansserif_PureCLDM. The completeness of the bosonic and fermionic N𝑁Nitalic_N-representability problems are at the end of this section. The last section deals with the 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE upper bound. We will spend particular effort covering the methods from [GP05] here, hoping that this paves the way to their further use. We conclude the section by giving some applications."
https://arxiv.org/html/2411.03006v1,Neural Networks and (Virtual) Extended Formulations,"Neural networks with piecewise linear activation functions, such as rectified linear units (ReLU) or maxout, are among the most fundamental models in modern machine learning. We make a step towards proving lower bounds on the size of such neural networks by linking their representative capabilities to the notion of the extension complexity xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ) of a polytope P𝑃Pitalic_P, a well-studied quantity in combinatorial optimization and polyhedral geometry. To this end, we propose the notion of virtual extension complexity vxc⁡(P)=min⁡{xc⁡(Q)+xc⁡(R)∣P+Q=R}vxc𝑃xc𝑄conditionalxc𝑅𝑃𝑄𝑅\operatorname{vxc}(P)=\min\{\operatorname{xc}(Q)+\operatorname{xc}(R)\mid P+Q=R\}roman_vxc ( italic_P ) = roman_min { roman_xc ( italic_Q ) + roman_xc ( italic_R ) ∣ italic_P + italic_Q = italic_R }. This generalizes xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ) and describes the number of inequalities needed to represent the linear optimization problem over P𝑃Pitalic_P as a difference of two linear programs. We prove that vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ) is a lower bound on the size of a neural network that optimizes over P𝑃Pitalic_P. While it remains open to derive strong lower bounds on virtual extension complexity, we show that powerful results on the ordinary extension complexity can be converted into lower bounds for monotone neural networks, that is, neural networks with only nonnegative weights. Furthermore, we show that one can efficiently optimize over a polytope P𝑃Pitalic_P using a small virtual extended formulation. We therefore believe that virtual extension complexity deserves to be studied independently from neural networks, just like the ordinary extension complexity. As a first step in this direction, we derive an example showing that extension complexity can go down under Minkowski sum.","While machine learning is nowadays driven by rapid empirical progress, our work focuses on the theoretical understanding of the underlying models and methods. A crucial building block are feedforward neural networks. These are directed, acyclic graphs in which each vertex (neuron) defines a simple computation, usually a linear transformation composed with a scalar-valued, continuous and piecewise linear (CPWL) activation function. While a standard choice for the activation function is the rectified linear unit (ReLU) x↦max⁡{0,x}maps-to𝑥0𝑥x\mapsto\max\{0,x\}italic_x ↦ roman_max { 0 , italic_x }, in this paper we focus on the more general maxout networks. These allow to compute the maximum of constantly many linear functions at each neuron. As a result, the entire network computes a (potentially complex) CPWL function. One of the big challenges in the theoretical analysis of neural networks is to understand how many neurons one requires to exactly or approximately represent a given (CPWL) function. To the best of our knowledge, it is an open question whether there exists a family of CPWL functions, which we can evaluate in polynomial time, but which cannot be represented by polynomial-size neural networks. The piecewise linear nature of the studied networks suggests to tackle such questions by means of polyhedral geometry, see, e.g., the recent survey [25]. In fact, a similar problem to the question above used to be open for a long time in the context of linear programming, until Rothvoß [37] resolved it affirmatively: does there exist a polytope P𝑃Pitalic_P over which we can optimize in polynomial time, but any linear programming formulation must have exponential size? This question can be formalized with the notion of extension complexity xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ), which describes the minimal number of facets of any polytope Q𝑄Qitalic_Q that projects onto P𝑃Pitalic_P. In this case, we call Q𝑄Qitalic_Q an extended formulation of P𝑃Pitalic_P. Rothvoß [37] proved that the matching polytope has exponential extension complexity even though Edmonds’ algorithm [11] can be used to find the maximum weight matching or minimum weight perfect matching in polynomial time. Additionally, it was also proven that a couple of polytopes associated with NP-hard optimization problems like the travelling salesperson problem have exponential extension complexity [14]. There is a direct translation between polytopes (as feasible sets of linear programs) and CPWL functions (represented by neural networks) through the notion of the support function fP⁢(c)=maxx∈P⁡c⊤⁢xsubscript𝑓𝑃𝑐subscript𝑥𝑃superscript𝑐top𝑥f_{P}(c)=\max_{x\in P}c^{\top}xitalic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_c ) = roman_max start_POSTSUBSCRIPT italic_x ∈ italic_P end_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_x of a polytope P𝑃Pitalic_P. This (convex) CPWL function, which has one linear region for each vertex of P𝑃Pitalic_P, uniquely determines P𝑃Pitalic_P via convex duality. Computing fP⁢(c)subscript𝑓𝑃𝑐f_{P}(c)italic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ( italic_c ) means determining the objective value when optimizing over P𝑃Pitalic_P in c𝑐citalic_c-direction. Each CPWL function fPsubscript𝑓𝑃f_{P}italic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT can be represented by a neural network [1], though the required number of neurons can be large. To quantify this, we define the neural network complexity nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ) as the minimum number of neurons to represent fPsubscript𝑓𝑃f_{P}italic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT by a maxout neural network. 1.1 Our Contributions The aim of this paper is to connect the world of extended formulations with the study of neural networks. A “dream result” in this direction would be to bound xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ) polynomially in nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ). Then the breakthrough results on extension complexity would directly imply strong lower bounds on the size of neural networks. It turns out, however, that there is one feature of neural networks that seems to make the “dream result” difficult to obtain: namely the ability to use subtraction. To remedy this, we propose the notion of virtual extension complexity vxc⁡(P)=min⁡{xc⁡(Q)+xc⁡(R)∣Q and R are polytopes with ⁢P+Q=R},vxc𝑃xc𝑄conditionalxc𝑅Q and R are polytopes with 𝑃𝑄𝑅\operatorname{vxc}(P)=\min\{\operatorname{xc}(Q)+\operatorname{xc}(R)\mid\text% {$Q$ and $R$ are polytopes with }P+Q=R\}\ ,roman_vxc ( italic_P ) = roman_min { roman_xc ( italic_Q ) + roman_xc ( italic_R ) ∣ italic_Q and italic_R are polytopes with italic_P + italic_Q = italic_R } , where P+Q={p+q∣p∈P,q∈Q}𝑃𝑄conditional-set𝑝𝑞formulae-sequence𝑝𝑃𝑞𝑄P+Q=\{p+q\mid p\in P,q\in Q\}italic_P + italic_Q = { italic_p + italic_q ∣ italic_p ∈ italic_P , italic_q ∈ italic_Q } is the Minkowski sum. In this definition, P𝑃Pitalic_P is a (formal) Minkowski difference of two polytopes Q𝑄Qitalic_Q and R𝑅Ritalic_R. Note that this is not the same as R+(−1)⋅Q𝑅⋅1𝑄R+(-1)\cdot Qitalic_R + ( - 1 ) ⋅ italic_Q but rather the inverse operation of Minkowski addition. The name virtual extension complexity is derived from virtual polytopes [33], a framework for the algebraic study of formal Minkowski differences of polytopes. Observe that vxc⁡(P)≤xc⁡(P)vxc𝑃xc𝑃\operatorname{vxc}(P)\leq\operatorname{xc}(P)roman_vxc ( italic_P ) ≤ roman_xc ( italic_P ) because we can always choose Q={0}𝑄0Q=\{0\}italic_Q = { 0 } with xc⁡({0})=0xc00\operatorname{xc}(\{0\})=0roman_xc ( { 0 } ) = 0. In that sense, virtual extension complexity is really a strengthening of the ordinary extension complexity. In Section 3, we deduce that vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ) is indeed a lower bound for nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ), up to a constant factor. This leaves the open question to find ways to lower-bound vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ) in order to achieve the original goal to lower-bound nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ). A consequence of the discussion above is that, if one removes the ability to subtract within neural networks, we do indeed obtain our “dream result”, namely lower bounds through xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ). The resulting model is the one of monotone neural networks, which are neural networks with only nonnegative weights. In analogy to nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ), we define the monotone neural network complexity mnnc⁡(P)mnnc𝑃\operatorname{mnnc}(P)roman_mnnc ( italic_P ) as the minimum number of neurons to represent fPsubscript𝑓𝑃f_{P}italic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT by a monotone maxout neural network. In Section 4, we show how lower bounds on xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ) imply lower bounds on exact and approximate representations of monotone neural networks. Studying monotone neural networks is justified both from a theoretical and a practical perspective. From the theoretical perspective, it is a natural approach in complexity theory to prove lower bounds first for monotone models of computation, to first circumvent some additional challenges of the general case; see, e.g., [42]. From the practical perspective, it is always a good idea to incorporate prior knowledge about a problem into a machine learning algorithm to solve that problem. If one knows that the target function should be a monotone function, then it might be a good idea to constrain each unit of the neural network to compute a monotone function—this exactly corresponds to nonnegative weights. See [29] and the references therein for recent studies of monotone neural networks in the machine learning community. Summarizing, in this paper, we discuss four ways to represent a polytope or its support function through (virtual) extended formulations and (monotone) neural networks. Figure 1 shows what we know about how the associated complexity measures xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ), vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ), nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ), and mnnc⁡(P)mnnc𝑃\operatorname{mnnc}(P)roman_mnnc ( italic_P ) relate to each other. xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P )mnnc⁡(P)mnnc𝑃\operatorname{mnnc}(P)roman_mnnc ( italic_P )vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P )nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P )?? Figure 1: Relations between complexity measures for a polytope P𝑃Pitalic_P. A directed arc means that the tail can be polynomially bounded by the head. It remains an open question whether xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ) and nnc⁡(P)nnc𝑃\operatorname{nnc}(P)roman_nnc ( italic_P ) can be related this way. We conclude with some insights for vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ) and its relation to xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ). Observe that P+Q=R𝑃𝑄𝑅P+Q=Ritalic_P + italic_Q = italic_R is equivalent to fP=fR−fQsubscript𝑓𝑃subscript𝑓𝑅subscript𝑓𝑄f_{P}=f_{R}-f_{Q}italic_f start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT - italic_f start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT pointwise. Therefore, intuitively, in order to optimize over P𝑃Pitalic_P, one only needs to optimize over R𝑅Ritalic_R and Q𝑄Qitalic_Q and subtract the results. We make this intuition formal in Section 5.1, implying that small extended formulations for Q𝑄Qitalic_Q and R𝑅Ritalic_R are sufficient to optimize efficiently over P𝑃Pitalic_P. Furthermore, in Section 5.2, we provide a class of examples with P+Q=R𝑃𝑄𝑅P+Q=Ritalic_P + italic_Q = italic_R demonstrating that xc⁡(R)xc𝑅\operatorname{xc}(R)roman_xc ( italic_R ) can be much smaller than xc⁡(P)xc𝑃\operatorname{xc}(P)roman_xc ( italic_P ). This gives important insights on how extension complexity behaves under Minkowski sum and implies that we really need to look at both xc⁡(Q)xc𝑄\operatorname{xc}(Q)roman_xc ( italic_Q ) and xc⁡(R)xc𝑅\operatorname{xc}(R)roman_xc ( italic_R ) in order to lower-bound vxc⁡(P)vxc𝑃\operatorname{vxc}(P)roman_vxc ( italic_P ). 1.2 Further Related Work In this paper we aim to prove lower bounds on neural networks representing combinatorial optimization problems. Complementing upper bounds can be found in [22] for minimum spanning trees and maximum flows. Furthermore, in [23], similar upper bounds for the knapsack problem are given, even though they are different in flavor because some integrality assumptions are made. Concerning the general expressivity of (piecewise linear) neural networks, the celebrated universal approximation theorems state that a single layer of neurons is sufficient to approximate any continuous function on a bounded domain; see [10] for the original version for sigmoid activation functions and [27] for a version that encompasses ReLU. However, such shallow neural networks usually require a large number of neurons. A sequence of results demonstrates that deeper networks sometimes require exponentially fewer neurons to represent the same functions; see, e.g., [1, 12]. In terms of exact representation, it is known that a function can be represented if and only if it is CPWL [1], and it is still an open question whether constant depth is sufficient to do so [21, 20]. Interestingly, also for this question, monotone networks seem to be more amenable for proving lower bounds than their non-monotone counterparts [41]. Furthermore, the related question of how to efficiently write a non-convex CPWL function as a difference of two convex ones received quite some attention recently [5, 40]. We would like to emphasize that we view neural networks as a model of real-valued computation, as opposed to binary models of computation like Boolean circuits and Turing machines. In fact, if one restricts the inputs of a neural network to be binary, it is not too difficult to simulate AND-, OR-, and NOT-gates [32]. Thus, in such a binary model, every problem in P can be solved with polynomial-size neural networks. However, such networks would usually be very sensitive to single bits in the input and therefore cannot naturally be transformed into exact or approximate neural networks in the real-valued model. See also the discussion in [22] for more details. The more useful connection to circuit complexity is through arithmetic [38], and in particular tropical circuits [26], which are also real-valued models of computation. Again we refer to [22] for a more detailed discussion of how these models relate to neural networks. In fact, the extension complexity has been related before to Boolean and arithmetic circuits, see [13, 24]. This is also related to Goemans’ proof that the permutahedron has extension complexity 𝒪⁢(n⁢log⁡n)𝒪𝑛𝑛\mathcal{O}(n\log n)caligraphic_O ( italic_n roman_log italic_n ) [16], as this goes via sorting networks, which can be seen as a very specific version of a piecewise-linear arithmetic circuit."
https://arxiv.org/html/2411.02819v1,Coboundary expansion of coset complexes,"Coboundary expansion is a high dimensional generalization of the Cheeger constant to simplicial complexes. Originally, this notion was motivated by the fact that it implies topological expansion, but nowadays a significant part of the motivation stems from its deep connection to problems in theoretical computer science such as agreement expansion in the low soundness regime. In this paper, we prove coboundary expansion with non-Abelian coefficients for the coset complex construction of Kaufman and Oppenheim. Our proof uses a novel global argument, as opposed to the local-to-global arguments that are used to prove cosystolic expansion.","In this paper we show that the coset complexes that were introduced by [KO18] (or in fact a variant of those) are coboundary expanders over the symmetric group. In addition to the importance of the coboundary expansion result per se, our work suggests that the recent result of [BMV24] that construct PCPs over some variants of the Ramanujan complexes, could potentially be implemented also over the coset complexes to yield efficient PCPs over the coset complexes, i.e., efficient PCPs over elementary high dimensional expanders. 1.1 Our contribution In this paper, we will show that for every finite group ΛΛ\Lambdaroman_Λ, a slight variation of the Kaufman-Oppenheim complexes give examples of bounded degree 1111-coboundary expanders over ΛΛ\Lambdaroman_Λ. More explicitly, for n≥3𝑛3n\geq 3italic_n ≥ 3 and p𝑝pitalic_p prime, we construct an infinite family of n𝑛nitalic_n-dimensional coset complexes {Xn,p(s)}s>3⁢nsubscriptsuperscriptsubscript𝑋𝑛𝑝𝑠𝑠3𝑛\{X_{n,p}^{(s)}\}_{s>3n}{ italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_s > 3 italic_n end_POSTSUBSCRIPT modelled over the family of groups {SLn+1⁡(𝔽p⁢[t]/⟨ts⟩)}s>3⁢nsubscriptsubscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡delimited-⟨⟩superscript𝑡𝑠𝑠3𝑛\{\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t]/\langle t^{s}\rangle)\}_{s>3n}{ roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] / ⟨ italic_t start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ⟩ ) } start_POSTSUBSCRIPT italic_s > 3 italic_n end_POSTSUBSCRIPT using a slight variation of the construction in [KO18]. For this construction, our main result in this paper is the following: Theorem 1.1 (Main Theorem - informal, see formal Theorem 6.2). Let n≥3𝑛3n\geq 3italic_n ≥ 3 and ΛΛ\Lambdaroman_Λ a finite group. For every prime p𝑝pitalic_p that is large enough with respect to n𝑛nitalic_n and |Λ|Λ|\Lambda|| roman_Λ |, the family {Xn,p(s)}s>3⁢nsubscriptsuperscriptsubscript𝑋𝑛𝑝𝑠𝑠3𝑛\{X_{n,p}^{(s)}\}_{s>3n}{ italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT } start_POSTSUBSCRIPT italic_s > 3 italic_n end_POSTSUBSCRIPT has uniformly bounded degree and (uniformly) 1111-coboundary expansion over ΛΛ\Lambdaroman_Λ. The main difficulty in the proof of our main Theorem is showing vanishing of cohomology with respect to a non-Abelian group ΛΛ\Lambdaroman_Λ - this is due to the fact that cosystolic expansion for such groups is known via a combination of previous work. Thus, once we prove vanishing of cohomology the previous known cosystolic result for coset complexes could be upgraded to a coboundary expansion result. We note that vanishing of cohomology with finite coefficients is inherently a global property and cannot be attained via local to global considerations. This is the main challenge we are facing, as most developed techniques within high dimensional expansion are of local to global nature, but a local to global argument can not imply vanishing of cohomology when working with finite coefficients. We note that our proof of this result is fairly elementary and self-contained - we only use some external results regarding the presentation of SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) and some of its subgroups in terms of generators and relations. Notably, unlike similar results obtained in [BLM24, DDL24] (for a completely different family of complexes), we do not use any sophisticated tools from the theory of algebraic groups nor do we need the strong results of the congruence subgroup property and the strong approximation theorem. 1.2 Significance of coboundary expansion over the symmetric group within CS In the following, we discuss the notions of coboundary expansion, cosystolic expansion and agreement expansion and their relation to PCP construction. Coboundary expansion. Coboundary expansion is a topological notion of high dimensional expansion that was introduced by Gromov [Gro10] and independently by Linial and Meshulam [LM06]. Gromov has studied this notion since he has shown that coboundary expansion over 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of a simplicial complex implies the topological overlapping property of the complex. Gromov knew how to prove this topological expansion property for complexes with small diameter, but his main interest was to obtain it for complexes with unbounded diameter, such as the Ramanujan complexes defined in [LSV05a, LSV05b] 111When we refer to Ramanujan complexes below, any quotient of an affine A~nsubscript~𝐴𝑛\widetilde{A}_{n}over~ start_ARG italic_A end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT building with sufficiently large injectivity radius can be used. since he wanted to show the existence of bounded degree complexes with the topological overlapping property. This question of Gromov was resolved by [KKL14, EK24] using a relaxed notion to coboundary expansion called cosystolic expansion. Cosystolic expansion. Cosystolic expansion is the requirement that an approximate cocycle (i.e., a cochain whose coboundary is small) is close to a genuine cocycle. Coboundary expansion is equivalent to cosystolic expansion plus additional requirement of vanishing of the relevant cohomologies. Importantly, cosystolic expansion is a global testability question that could be deduced by local to global means (see [KKL14, EK24] that have shown cosystolic expansion with 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT coefficients). However, in contrast to cosystolic expansion, coboundary expansion is a global property that can not be deduced by local to global means. The techniques to get cosystolic expansion with 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT coefficients by local to global means were also pivotal in obtaining good LTCS and good qLDPCs [EKZ20, DEL+22, PK22]. Coset complexes. The Ramanujan complexes were shown to be bounded degree cosystolic expanders, but their construction was rather involved. This raised the question of the existence of bounded degree cosystolic expanders with an elementary construction. The first construction of bounded degree spectral high dimensional expanders was given in [KO18] using the idea of coset complexes. This idea was generalized in [KO23, OP22, dPVB24] to other similar constructions of bounded degree spectral high dimensional expanders. It was later shown in [KO21], that the complexes constructed in [KO18] are also give rise bounded degree cosystolic expanders over 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT in dimension 2 (it is conjectured that this result can be generalized to higher dimensions). These construction remain one of the main sources of examples for HDX’s (e.g., see [DLYZ23]). Agreement expansion in the high and low soundness regimes. In another line of work within CS [DK17] have studied the notion of agreement expansion and have shown that high dimensional spectral expanders are agreement expanders in the high soundness regime; Agreement expansion in the high soundness regime asks roughly for the following: Given a binary assignment to the vertices of each k face in a complex of dimension n>k𝑛𝑘n>kitalic_n > italic_k such that almost all k-assignments are agreeing on their intersections, is it the case that there exists a global binary function on all the vertices of the complex whose restriction to the different k-faces agrees with most assignments to the k-faces. This question is related to PCPs and is called agreement expansion in the high soundness regime. However for PCPs constructions one needs a stronger requirement called agreement expansion in the low soundless regime. Agreement expansion in the low soundless regime roughly requires that if 1 percent of the intersection of the k-faces are agreeing then there exists a global function that is consistent with a constant fraction of the k-sets. In [DK17] it was shown that spectral high dimensional expansion is sufficient for agreement expansion in the high soundness regime and they have conjectured that it should imply also the low soundness case. So the state of things until recently has been that agreement expansion in the high soundness case is implied by spectral high dimensional expansion and robustness of codes and topological overlapping property are implied by cosystolic expansion (i.e. by topological expansion) or similar variants (see also [FK24]). List agreement expansion and the bridge between spectral and topological high dimensional expansion. The work of [GK23] has recently defined a stronger version of the agreement expansion that also needs topological expansion in additional to spectral high dimensional expansion. They have defined the notion of list agreement expansion ; in which the agreement expansion question in the high soundness regime is changed so that the input on each k-face is a list of l𝑙litalic_l different assignments to the k-face (and not only one) and the question is the following : if a typical pair of k-faces that intersect are agreeing on their whole list then there exist l𝑙litalic_l-global functions that are consistent with most assignments of l𝑙litalic_l-lists on k𝑘kitalic_k-faces. In [GK23] it was also shown that if the complex is both a spectral high dimensional expander and a coboundary expander over the symmetric group then it has the list-agreement expansion property in the high soundness regime. Then the following question arises: what is the relation between agreement expansion in the low soundness regime, that is useful towards PCP construction and the list-agreement expansion in the high soundness regime? Reduction from agreement with low soundness to list agreement with high soundness. In two independent works [BM24] and [DD24b] have shown that there is a reduction from agreement expansion in the low soundness regime to list agreement expansion in the high soundness. Namely one can solve low soundness agreement by translating it to high soundness agreement on lists (with additional requirement that the coboundary expansion constant in links is independent of the complex dimension). As was explained, high soundness agreement on lists can be solved by coboundary expansion of the complex and by spectral expansion of it. The Path towards PCP construction. After those works that have shown a reduction from agreement expansion in the low soundness to list agreement expansion in the high soundness regime, the main challenge towards obtaining bounded degree complexes that supports agreement expansion in the low soundness regime has been in coming up with a bounded degree complexes that are coboundary expanders over the symmetric group. [BLM24, DDL24] have shown the existence of such complexes based on an earlier work of [CL24]. Thus, these works have shown the existence of bounded degree complexes that support agreement expansion in the low soundness regime. All these efforts have culminated in the [BMV24] that showed that a complex which supports agreement expansion in the low soundness regime gives rise to an efficient PCP by routing through it existing local PCP. On the implications of our work. Based on the previous discussion, the main global challenge to get a PCP from a complex with expanding links is in proving the global property that this complex is a coboundary expander over the symmetric group. The main difficulty is that coboundary expansion of the complex is a property that can not be implied by local to global means that are abundant in the high dimensional expansion literature. We see the significance of our results in three key aspects: First, proving coboundary expansion of the coset complex over the symmetric group. Second, solving the main global challenge towards constructing PCPs based on the coset complex (although the local problem of providing coboundary expansion constants of the links that are independent of the degree is still open). Third, we provide a novel global technique for proving vanishing of the first cohomology over the symmetric group (in contrast to other techniques for establishing spectral expansion or cosystolic expansion that are of local nature). We believe that our work can be generalized to the other constructions of spectral expanders using coset complexes in [OP22]. 1.3 Comparison to similar results It is intriguing to compare our proof of the vanishing of cohomology with recent results in [BLM24, DDL24]. Given a finite group ΛΛ\Lambdaroman_Λ both our work and [BLM24, DDL24] construct a family of high-dimensional expanders with trivial 1-cohomology relative to ΛΛ\Lambdaroman_Λ-coefficients, following a similar outline. The approach begins with an ”algebraic” simplicial complex that has trivial 1-cohomology with respect to ΛΛ\Lambdaroman_Λ, and then passes to a family of high-dimensional expanders by taking quotients via congruence subgroups, which also have trivial 1-cohomology with ΛΛ\Lambdaroman_Λ-coefficients. Despite this shared framework, the methods and challenges in the proofs differ significantly. In [BLM24, DDL24], the initial complex is a contractible symplectic C~nsubscript~𝐶𝑛\widetilde{C}_{n}over~ start_ARG italic_C end_ARG start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT-building, which has trivial cohomology for any group. The difficulty lies in proving that the congruence subgroups exhibit trivial 1-cohomology with respect to ΛΛ\Lambdaroman_Λ, requiring deep results from group theory, such as the congruence subgroup property and the strong approximation theorem. In contrast, our work begins with a coset complex over SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ). For n≥3𝑛3n\geq 3italic_n ≥ 3, the explicit description of the congruence subgroups, which follows from the fact that SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) has the same presentation as a Steinberg group, makes the vanishing of 1-cohomology for congruence subgroups with ΛΛ\Lambdaroman_Λ-coefficients almost trivial when p>|Λ|𝑝Λp>|\Lambda|italic_p > | roman_Λ |. This is a straightforward argument requiring no deep theoretical results. Most of our effort focuses on proving that the coset complex over SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) has trivial 1-cohomology with respect to ΛΛ\Lambdaroman_Λ (unlike the work in [BLM24, DDL24], the coset complex in our case is not simply connected). 1.4 Proof overview In order to show that a family of complexes {X(s)}superscript𝑋𝑠\{X^{(s)}\}{ italic_X start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT } has 1111-coboundary expansion over a group ΛΛ\Lambdaroman_Λ, one needs to show two things: First, that the family has 1111-cosystolic expansion over ΛΛ\Lambdaroman_Λ. Second, that for every s𝑠sitalic_s, H1⁢(X(s),Λ)=0superscript𝐻1superscript𝑋𝑠Λ0H^{1}(X^{(s)},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT , roman_Λ ) = 0. In [KO21] it was shown that the Kaufman-Oppenheim complexes (with large enough prime p𝑝pitalic_p) have 1111-cosystolic expansion over 𝔽2subscript𝔽2\mathbb{F}_{2}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The new results of Dikstein and Dinur in [DD24a, DD24b] show that the same proof given in [KO21] actually show that the Kaufman-Oppenheim complexes have 1111-cosystolic expansion over any group ΛΛ\Lambdaroman_Λ (see a more detailed explanation of this point in Section 2.5 below). Thus we are left to show a vanishing of cohomology result for the coset complexes in our construction. This is done via the following steps: Vanishing of cohomology for a quotient. Let X𝑋Xitalic_X be a simplicial complex and N𝑁Nitalic_N a group acting simplicially on X𝑋Xitalic_X. The quotient complex, denoted N\X\𝑁𝑋N\backslash Xitalic_N \ italic_X, is defined via identifying all the vertices of X𝑋Xitalic_X that are in the same orbit of N𝑁Nitalic_N. Under some mild conditions on X𝑋Xitalic_X and on the action of N𝑁Nitalic_N, the following result holds for every group ΛΛ\Lambdaroman_Λ: If both H1⁢(X,Λ)=0superscript𝐻1𝑋Λ0H^{1}(X,\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X , roman_Λ ) = 0 and H1⁢(N,Λ)=0superscript𝐻1𝑁Λ0H^{1}(N,\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_N , roman_Λ ) = 0, then H1⁢(N\X,Λ)=0superscript𝐻1\𝑁𝑋Λ0H^{1}(N\backslash X,\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_N \ italic_X , roman_Λ ) = 0 (see exact formulation in Theorem 3.1 below). Passing to the coset complex of SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ). It was already observed in [KO23] that the Kaufman-Oppenheim coset complexes over the family of groups {SLn+1⁡(𝔽p⁢[t]/⟨ts⟩)}s>3⁢nsubscriptsubscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡delimited-⟨⟩superscript𝑡𝑠𝑠3𝑛\{\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t]/\langle t^{s}\rangle)\}_{s>3n}{ roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] / ⟨ italic_t start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ⟩ ) } start_POSTSUBSCRIPT italic_s > 3 italic_n end_POSTSUBSCRIPT are actually all quotients of a coset complex modelled over SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ). Namely, for any n,p𝑛𝑝n,pitalic_n , italic_p, there are coset complexes Xn,psubscript𝑋𝑛𝑝X_{n,p}italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT modelled over SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) and normal subgroups Γn,ps◁SLn+1⁡(𝔽p⁢[t])◁superscriptsubscriptΓ𝑛𝑝𝑠subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\Gamma_{n,p}^{s}\triangleleft\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_Γ start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ◁ roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) such that for any s>3⁢n𝑠3𝑛s>3nitalic_s > 3 italic_n, Xn,p(s)=Γn,ps\Xn,psuperscriptsubscript𝑋𝑛𝑝𝑠\superscriptsubscriptΓ𝑛𝑝𝑠subscript𝑋𝑛𝑝X_{n,p}^{(s)}=\Gamma_{n,p}^{s}\backslash X_{n,p}italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT = roman_Γ start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT \ italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT. We will see that if ΛΛ\Lambdaroman_Λ is a group that has no non-trivial element of order p𝑝pitalic_p, then H1⁢(Γn,ps,Λ)=0superscript𝐻1superscriptsubscriptΓ𝑛𝑝𝑠Λ0H^{1}(\Gamma_{n,p}^{s},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( roman_Γ start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT , roman_Λ ) = 0 for every s𝑠sitalic_s. In particular, if ΛΛ\Lambdaroman_Λ is finite and p>|Λ|𝑝Λp>|\Lambda|italic_p > | roman_Λ |, then H1⁢(Γn,ps,Λ)=0superscript𝐻1superscriptsubscriptΓ𝑛𝑝𝑠Λ0H^{1}(\Gamma_{n,p}^{s},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( roman_Γ start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT , roman_Λ ) = 0 for every s𝑠sitalic_s. By the discussion above, if we can show that for such p>|Λ|𝑝Λp>|\Lambda|italic_p > | roman_Λ |, it also holds that H1⁢(Xn,p,Λ)=0superscript𝐻1subscript𝑋𝑛𝑝Λ0H^{1}(X_{n,p},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT , roman_Λ ) = 0, then it will follow that H1⁢(Xn,p(s),Λ)=0superscript𝐻1superscriptsubscript𝑋𝑛𝑝𝑠Λ0H^{1}(X_{n,p}^{(s)},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_s ) end_POSTSUPERSCRIPT , roman_Λ ) = 0 for every s>3⁢n𝑠3𝑛s>3nitalic_s > 3 italic_n. Vanishing of cohomology for Xn,psubscript𝑋𝑛𝑝X_{n,p}italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT. Fix n≥3𝑛3n\geq 3italic_n ≥ 3 and p𝑝pitalic_p an odd prime. To avoid cumbersome notation, we will denote X=Xn,p𝑋subscript𝑋𝑛𝑝X=X_{n,p}italic_X = italic_X start_POSTSUBSCRIPT italic_n , italic_p end_POSTSUBSCRIPT. By the previous paragraph, we need to show that for any finite group ΛΛ\Lambdaroman_Λ, if p>|Λ|𝑝Λp>|\Lambda|italic_p > | roman_Λ |, then H1⁢(X,Λ)=0superscript𝐻1𝑋Λ0H^{1}(X,\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X , roman_Λ ) = 0. Had we known that X𝑋Xitalic_X is simply connected, then we would be done, since for every simply connected complexes, the 1111-cohomology vanishes with respect to any group ΛΛ\Lambdaroman_Λ. However, X𝑋Xitalic_X is a coset complex and there is a characterization of simple connectedness for coset complexes (see [AH93] and further discussion below) that X𝑋Xitalic_X does not meet. Fortunately, the universal cover of X𝑋Xitalic_X, denoted X~~𝑋\widetilde{X}over~ start_ARG italic_X end_ARG, has an explicit description as a coset complex. Namely, there is an explicit abstract group Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG and a simply connected coset complex X~~𝑋\widetilde{X}over~ start_ARG italic_X end_ARG modelled over Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG such that Γ~→SLn+1⁡(𝔽p⁢[t])→~ΓsubscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\widetilde{\Gamma}\rightarrow\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])over~ start_ARG roman_Γ end_ARG → roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) is a surjective homomorphism that induces a covering map X~→X→~𝑋𝑋\widetilde{X}\rightarrow Xover~ start_ARG italic_X end_ARG → italic_X. The group Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG is given in terms of generators and relations such that the generators can be identified with a generating set of SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) and the set of relations of Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG is a partial set of the relations in a finite presentation of SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ). We will refer to the relations in the presentation of SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) that do not appear in the presentation of Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG as the “missing relations”. Adding relations to Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG and considering the coset complex with the added relations is equivalent to passing to a quotient of X~~𝑋\widetilde{X}over~ start_ARG italic_X end_ARG by the normal subgroup generated by the added relations. The crux of our proof is that we can add the missing relations to Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG in an iterative process, such that the normal group that we divide by has no ΛΛ\Lambdaroman_Λ 1111-cohomology. Thus, we start with H1⁢(X~,Λ)=0superscript𝐻1~𝑋Λ0H^{1}(\widetilde{X},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( over~ start_ARG italic_X end_ARG , roman_Λ ) = 0 (since X~~𝑋\widetilde{X}over~ start_ARG italic_X end_ARG is simply connected) and pass in a sequence of quotients X0=X~,X1=N0\X0,…,Xm=Nm−1\Xm−1formulae-sequencesubscript𝑋0~𝑋formulae-sequencesubscript𝑋1\subscript𝑁0subscript𝑋0…subscript𝑋𝑚\subscript𝑁𝑚1subscript𝑋𝑚1X_{0}=\widetilde{X},X_{1}=N_{0}\backslash X_{0},...,X_{m}=N_{m-1}\backslash X_% {m-1}italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = over~ start_ARG italic_X end_ARG , italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_N start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT \ italic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = italic_N start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT \ italic_X start_POSTSUBSCRIPT italic_m - 1 end_POSTSUBSCRIPT such that Xm=Xsubscript𝑋𝑚𝑋X_{m}=Xitalic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = italic_X and in each step H1⁢(Ni,Λ)=0superscript𝐻1subscript𝑁𝑖Λ0H^{1}(N_{i},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , roman_Λ ) = 0 and thus H1⁢(Xi+1,Λ)=0superscript𝐻1subscript𝑋𝑖1Λ0H^{1}(X_{i+1},\Lambda)=0italic_H start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT ( italic_X start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT , roman_Λ ) = 0 by the discussion above. This result builds on identifying the relations in SLn+1⁡(𝔽p⁢[t])subscriptSL𝑛1subscript𝔽𝑝delimited-[]𝑡\operatorname{SL}_{n+1}(\mathbb{F}_{p}[t])roman_SL start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT [ italic_t ] ) as pairs of roots in the root system Ansubscript𝐴𝑛A_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT and establishing a combinatorial propagation result in the chambers of Ansubscript𝐴𝑛A_{n}italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT (passing from the relations in Γ~~Γ\widetilde{\Gamma}over~ start_ARG roman_Γ end_ARG to the missing relations)."
https://arxiv.org/html/2411.02702v1,Corners in Quasirandom Groups via Sparse Mixing,"We improve the best known upper bounds on the density of corner-free sets over quasirandom groups from inverse poly-logarithmic to quasi-polynomial. We make similarly substantial improvements to the best known lower bounds on the communication complexity of a large class of permutation functions in the 3-player Number-on-Forehead model. Underpinning both results is a general combinatorial theorem that extends the recent work of Kelley, Lovett, and Meka (STOC’24), itself a development of ideas from the breakthrough result of Kelley and Meka on three-term arithmetic progressions (FOCS’23).","In the early 1980s, Chandra, Furst, and Lipton introduced the Number-on-Forehead (NOF) model of communication complexity [14] to better capture interaction with shared information. The k𝑘kitalic_k-NOF model is defined by k𝑘kitalic_k players communicating over a shared channel in order to compute a function f:({0,1}n)k→{0,1}:𝑓→superscriptsuperscript01𝑛𝑘01f:(\{0,1\}^{n})^{k}\to\{0,1\}italic_f : ( { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT → { 0 , 1 }. Each player can see the k−1𝑘1k-1italic_k - 1 inputs of every other player, but they cannot see their own. Albeit perhaps unintuitive at first glance, the model has a number of strikingly powerful and surprising connections to other areas of theoretical computer science and combinatorics. For example, lower bounds for k=ω⁢(log⁡n)𝑘𝜔𝑛k=\omega(\log n)italic_k = italic_ω ( roman_log italic_n ) players would imply breakthrough circuit lower bounds [13, 42, 44, 9], and the communication complexity of several natural functions is known to be equivalent to central problems in Ramsey theory [14, 51, 39]. Unfortunately, our understanding of this model is severely lacking. Only in the past year have researchers discovered explicit functions witnessing strong separations between randomized and deterministic 3-NOF communication complexity [31], despite the fact that optimal separations were long known to exist non-explicitly [5]. More precisely, Kelley, Lovett, and Meka exhibited an explicit 3-player function which has a constant cost randomized protocol, but requires Ω⁢(n1/3)Ωsuperscript𝑛13\Omega(n^{1/3})roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / 3 end_POSTSUPERSCRIPT ) bits of communication to compute deterministically. Their primary technical tool is a combinatorial adaptation of ideas from the recent breakthrough of Kelley and Meka on three-term arithmetic progressions (3APs) [32]. One of the most well-studied functions in the NOF setting is Exactly-N, where each player receives a number in [N]≔{1,2,…,N}≔delimited-[]𝑁12…𝑁[N]\coloneqq\{1,2,\dots,N\}[ italic_N ] ≔ { 1 , 2 , … , italic_N }, and they wish to determine if their numbers sum to N𝑁Nitalic_N. Introduced by [14], they showed that the 3-NOF complexity of Exactly-N is at most O⁢(log⁡N)𝑂𝑁O(\sqrt{\log N})italic_O ( square-root start_ARG roman_log italic_N end_ARG ) using the Behrend construction of 3-AP free sets [6]. In fact, they observed a near equivalence between Exactly-N (for three players) and the size of sets S⊂[N]2𝑆superscriptdelimited-[]𝑁2S\subset[N]^{2}italic_S ⊂ [ italic_N ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT without corners: three points (x,y),(x+z,y),(x,y+z)∈[N]2𝑥𝑦𝑥𝑧𝑦𝑥𝑦𝑧superscriptdelimited-[]𝑁2(x,y),(x+z,y),(x,y+z)\in[N]^{2}( italic_x , italic_y ) , ( italic_x + italic_z , italic_y ) , ( italic_x , italic_y + italic_z ) ∈ [ italic_N ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT with z≠0𝑧0z\neq 0italic_z ≠ 0. The first nontrivial bounds on the size of such sets were proven earlier by Ajtai and Szemerédi [2], but the quantitative behavior was poor, since the proof relied on Szemerédi’s regularity lemma [52]. The strongest bound to date is due to Shkredov [50], who showed any corner-free set of size δ⁢N2𝛿superscript𝑁2\delta N^{2}italic_δ italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT must satisfy δ≤O⁢(1(log⁡log⁡N)c)𝛿𝑂1superscript𝑁𝑐\delta\leq O\left(\frac{1}{(\log\log N)^{c}}\right)italic_δ ≤ italic_O ( divide start_ARG 1 end_ARG start_ARG ( roman_log roman_log italic_N ) start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT end_ARG ) for some absolute constant c>0𝑐0c>0italic_c > 0 (see also [49] and the exposition by Green over finite fields [23, 24]). Using the connection shown by [14], this implies that the complexity of Exactly-N is at least Ω⁢(log⁡log⁡log⁡N)Ω𝑁\Omega(\log\log\log N)roman_Ω ( roman_log roman_log roman_log italic_N ). Unfortunately, the techniques developed in [31] do not suffice to improve this lower bound, since they only apply to much denser functions. Concretely, the number of solutions of Exactly-N (that is, triples x,y,z∈[N]𝑥𝑦𝑧delimited-[]𝑁x,y,z\in[N]italic_x , italic_y , italic_z ∈ [ italic_N ] that satisfy x+y+z=N𝑥𝑦𝑧𝑁x+y+z=Nitalic_x + italic_y + italic_z = italic_N) is at most N2superscript𝑁2N^{2}italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, whereas the function exhibited by [31] to have strong lower bounds for deterministic NOF communication has N3−csuperscript𝑁3𝑐N^{3-c}italic_N start_POSTSUPERSCRIPT 3 - italic_c end_POSTSUPERSCRIPT solutions for some small constant c>0𝑐0c>0italic_c > 0; their technique is restricted to such functions. Observe that corners may be viewed as a multidimensional generalization of arithmetic progressions. In fact, upper bounds on corner-free sets easily imply upper bounds on 3AP-free sets (see e.g. [55, Section 2.4]). Given their tight relationship, many researchers have suspected that the recent techniques of Kelley and Meka [32] used to improve bounds for 3AP-free sets will be amenable to usage in the case of corners (see e.g. [40] and [43, Section 1.2]). While there is some preliminary evidence that this direction is viable [30, 41], such strong bounds remain currently beyond reach. 1.1 Our results A common strategy in additive combinatorics when working over the integers is to prove a similar result in some model setting, such as finite fields, then port the result back to the integers using standard machinery. One interesting setting is quasirandom groups. For now, one can think of a quasirandom group as a finite group G𝐺Gitalic_G enjoying the property that any two large sets A,B⊂G𝐴𝐵𝐺A,B\subset Gitalic_A , italic_B ⊂ italic_G “mix” under convolutions. In other words, if we take random samples a∈A𝑎𝐴a\in Aitalic_a ∈ italic_A and b∈B𝑏𝐵b\in Bitalic_b ∈ italic_B, then the distribution of a⁢b𝑎𝑏abitalic_a italic_b is close to the uniform distribution over G𝐺Gitalic_G. A classic example of a quasirandom group is G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\mathrm{SL}_{2}(\mathbb{F}_{p})italic_G = roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ), the set of 2×2222\times 22 × 2 matrices over the finite field 𝔽psubscript𝔽𝑝\mathbb{F}_{p}blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT for p𝑝pitalic_p prime with determinant 1. The Exactly-N problem naturally generalizes to any finite group G𝐺Gitalic_G [8], where the players receive inputs x,y,z∈G𝑥𝑦𝑧𝐺x,y,z\in Gitalic_x , italic_y , italic_z ∈ italic_G and accept if and only if their inputs satisfy x⁢y⁢z=1G𝑥𝑦𝑧subscript1𝐺xyz=1_{G}italic_x italic_y italic_z = 1 start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. Note that over any group, Exactly-N has a constant cost randomized protocol by reducing to equality. We obtain the following lower bound for computing Exactly-N over G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\mathrm{SL}_{2}(\mathbb{F}_{p})italic_G = roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) by either deterministic or even non-deterministic protocols. Theorem 1.1 (Special case of Theorem 4.3). Any non-deterministic 3-NOF protocol computing Exactly-N over G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\mathrm{SL}_{2}(\mathbb{F}_{p})italic_G = roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) for prime p𝑝pitalic_p requires Ω⁢(log1/4⁡|G|)Ωsuperscript14𝐺\Omega(\log^{1/4}|G|)roman_Ω ( roman_log start_POSTSUPERSCRIPT 1 / 4 end_POSTSUPERSCRIPT | italic_G | ) bits of communication. Similar to the abelian case, there exists an intimate connection between Exactly-N over a group G𝐺Gitalic_G and corner-free sets in G×G𝐺𝐺G\times Gitalic_G × italic_G. However, there is a slight subtlety here, as corners generalize to the non-abelian setting in two non-equivalent ways. One option is triples of the form {(x,y),(z⁢x,y),(x,z⁢y)}𝑥𝑦𝑧𝑥𝑦𝑥𝑧𝑦\{(x,y),(zx,y),(x,zy)\}{ ( italic_x , italic_y ) , ( italic_z italic_x , italic_y ) , ( italic_x , italic_z italic_y ) } for z≠1G𝑧subscript1𝐺z\neq 1_{G}italic_z ≠ 1 start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, often referred to as naïve corners. In this setting, Austin [4] proved that for G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\mathrm{SL}_{2}(\mathbb{F}_{p})italic_G = roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ), any subset of G×G𝐺𝐺G\times Gitalic_G × italic_G without naïve corners has size |G|2−εsuperscript𝐺2𝜀|G|^{2-\varepsilon}| italic_G | start_POSTSUPERSCRIPT 2 - italic_ε end_POSTSUPERSCRIPT for some small constant ε>0𝜀0\varepsilon>0italic_ε > 0. Alternatively, one can consider triples of the form {(x,y),(x⁢z,y),(x,z⁢y)}𝑥𝑦𝑥𝑧𝑦𝑥𝑧𝑦\{(x,y),(xz,y),(x,zy)\}{ ( italic_x , italic_y ) , ( italic_x italic_z , italic_y ) , ( italic_x , italic_z italic_y ) } for z≠1G𝑧subscript1𝐺z\neq 1_{G}italic_z ≠ 1 start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, sometimes called BMZ corners after the first researchers to study them [11]. This formulation is less understood, and it corresponds to the three-player Exactly-N function over general groups (see e.g. [54, Lemma 21]). We will focus our attention on this latter generalization, and henceforth refer to them simply as corners. Austin also showed that corner-free sets over SL2⁢(𝔽p)subscriptSL2subscript𝔽𝑝\mathrm{SL}_{2}(\mathbb{F}_{p})roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) have density at most δ≤O⁢(1/logc⁡|G|)𝛿𝑂1superscript𝑐𝐺\delta\leq O(1/\log^{c}|G|)italic_δ ≤ italic_O ( 1 / roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT | italic_G | ) for some absolute constant c>0𝑐0c>0italic_c > 0 (see [54, Section 5] for a nice exposition). We are able to substantially improve this bound. Theorem 1.2 (Special case of Corollary 4.10). Let G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\mathrm{SL}_{2}(\mathbb{F}_{p})italic_G = roman_SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) for prime p𝑝pitalic_p. Then, any corner-free subset of G×G𝐺𝐺G\times Gitalic_G × italic_G has size at most δ⁢|G|2𝛿superscript𝐺2\delta|G|^{2}italic_δ | italic_G | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for δ≤exp⁡(−Ω⁢(log1/4⁡|G|)).𝛿Ωsuperscript14𝐺\delta\leq\exp{\left(-\Omega\left(\log^{1/4}|G|\right)\right)}.italic_δ ≤ roman_exp ( - roman_Ω ( roman_log start_POSTSUPERSCRIPT 1 / 4 end_POSTSUPERSCRIPT | italic_G | ) ) . We emphasize that Theorems 1.1 and 1.2 are only special cases of more general theorems, and we direct readers to Sections 4.1 and 4.2, respectively, for details. Both of our results are consequences of a general combinatorial theorem which may be of independent interest. Before stating it, we require some definitions. A set S⊂[N]3𝑆superscriptdelimited-[]𝑁3S\subset[N]^{3}italic_S ⊂ [ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT is called a permutation function111Such sets are called 2-dimensional permutations in [34, 37], and extend graph functions studied in [5, 51]. if for any fixing of two coordinates of some a∈[N]3𝑎superscriptdelimited-[]𝑁3a\in[N]^{3}italic_a ∈ [ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, there is precisely one choice of the other coordinate such that a∈S𝑎𝑆a\in Sitalic_a ∈ italic_S. For example, S={(x,y,z):x⁢y⁢z=1G}⊂G3𝑆conditional-set𝑥𝑦𝑧𝑥𝑦𝑧subscript1𝐺superscript𝐺3S=\{(x,y,z):xyz=1_{G}\}\subset G^{3}italic_S = { ( italic_x , italic_y , italic_z ) : italic_x italic_y italic_z = 1 start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT } ⊂ italic_G start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT is an example of a permutation function (identifying [N]delimited-[]𝑁[N][ italic_N ] with G𝐺Gitalic_G). Given a permutation function S⊂[N]3𝑆superscriptdelimited-[]𝑁3S\subset[N]^{3}italic_S ⊂ [ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT and a subset A⊂S𝐴𝑆A\subset Sitalic_A ⊂ italic_S, we denote by AX⁢Y,AX⁢Z,AY⁢Z⊂[N]2subscript𝐴𝑋𝑌subscript𝐴𝑋𝑍subscript𝐴𝑌𝑍superscriptdelimited-[]𝑁2A_{XY},A_{XZ},A_{YZ}\subset[N]^{2}italic_A start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT italic_X italic_Z end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT italic_Y italic_Z end_POSTSUBSCRIPT ⊂ [ italic_N ] start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT the projections of A𝐴Aitalic_A to the X⁢Y,X⁢Z,Y⁢Z𝑋𝑌𝑋𝑍𝑌𝑍XY,XZ,YZitalic_X italic_Y , italic_X italic_Z , italic_Y italic_Z-faces of [N]3superscriptdelimited-[]𝑁3[N]^{3}[ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, respectively. Theorem 1.3 (Informal special case of Theorem 2.4). Let d≥1𝑑1d\geq 1italic_d ≥ 1. Suppose S⊂[N]3𝑆superscriptdelimited-[]𝑁3S\subset[N]^{3}italic_S ⊂ [ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT is a permutation function and A⊂S𝐴𝑆A\subset Sitalic_A ⊂ italic_S is a set of size |A|≥2−d⁢|S|𝐴superscript2𝑑𝑆|A|\geq 2^{-d}|S|| italic_A | ≥ 2 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT | italic_S |. If S𝑆Sitalic_S is sufficiently pseudorandom (in the sense of Definition 2.1), then |{(x,y,z)∈[N]3:(x,y)∈AX⁢Y,(x,z)∈AX⁢Z,(y,z)∈AY⁢Z}|≥2−O⁢(d3)⁢N3.conditional-set𝑥𝑦𝑧superscriptdelimited-[]𝑁3formulae-sequence𝑥𝑦subscript𝐴𝑋𝑌formulae-sequence𝑥𝑧subscript𝐴𝑋𝑍𝑦𝑧subscript𝐴𝑌𝑍superscript2𝑂superscript𝑑3superscript𝑁3\left|\left\{(x,y,z)\in[N]^{3}:(x,y)\in A_{XY},(x,z)\in A_{XZ},(y,z)\in A_{YZ}% \right\}\right|\geq 2^{-O(d^{3})}N^{3}.| { ( italic_x , italic_y , italic_z ) ∈ [ italic_N ] start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT : ( italic_x , italic_y ) ∈ italic_A start_POSTSUBSCRIPT italic_X italic_Y end_POSTSUBSCRIPT , ( italic_x , italic_z ) ∈ italic_A start_POSTSUBSCRIPT italic_X italic_Z end_POSTSUBSCRIPT , ( italic_y , italic_z ) ∈ italic_A start_POSTSUBSCRIPT italic_Y italic_Z end_POSTSUBSCRIPT } | ≥ 2 start_POSTSUPERSCRIPT - italic_O ( italic_d start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT italic_N start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT . For now, the reader can think of the pseudorandomness condition as saying that the density of S𝑆Sitalic_S stays roughly the same whenever you restrict to some large cube. Theorem 1.3 should be compared with [31, Lemma 2.10], where they refer to the quantity on the left-hand side of the above inequality as the “cylinder intersection closure of A𝐴Aitalic_A.” The two results can be viewed as similar statements in two extreme regimes for the set S𝑆Sitalic_S. Our theorem holds when S𝑆Sitalic_S is permutation function, so it must necessarily be sparse (of size |S|=N2𝑆superscript𝑁2|S|=N^{2}| italic_S | = italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT), whereas their result holds in the dense case where S𝑆Sitalic_S has size roughly N3−csuperscript𝑁3𝑐N^{3-c}italic_N start_POSTSUPERSCRIPT 3 - italic_c end_POSTSUPERSCRIPT for some small enough constant c>0𝑐0c>0italic_c > 0. We briefly note that our pseudorandomness notion differs from theirs to better reflect an alternative regime of interest. 1.2 Future work We conclude by noting a few directions for future work. The results of [31] hold for sufficiently dense functions, while our results apply only to permutation functions which are sparse. It would be interesting to see if these results can be unified in a theorem which works in all density regimes. Another natural open question is to extend Theorem 1.2 to give quasi-polynomial bounds for corner-free sets over the integers or 𝔽2nsuperscriptsubscript𝔽2𝑛\mathbb{F}_{2}^{n}blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Over the integers, there are constructions of corner-free sets of size 2−Ω⁢(log⁡N)⁢N2superscript2Ω𝑁superscript𝑁22^{-\Omega(\sqrt{\log N})}N^{2}2 start_POSTSUPERSCRIPT - roman_Ω ( square-root start_ARG roman_log italic_N end_ARG ) end_POSTSUPERSCRIPT italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT [6] (see also the recent improvements [38, 25, 29]). Thus, such an extension would be optimal in the “shape” of the bound. While we are optimistic that the techniques present here may be useful in these settings, we are not able to directly apply Theorem 1.3, since the corresponding ambient set (see Section 4.2 for more details) S≔{(x,y,x+y)∈(ℤ/N⁢ℤ)3:x,y∈ℤ/N⁢ℤ}≔𝑆conditional-set𝑥𝑦𝑥𝑦superscriptℤ𝑁ℤ3𝑥𝑦ℤ𝑁ℤS\coloneqq\{(x,y,x+y)\in(\mathbb{Z}/N\mathbb{Z})^{3}:x,y\in\mathbb{Z}/N\mathbb% {Z}\}italic_S ≔ { ( italic_x , italic_y , italic_x + italic_y ) ∈ ( blackboard_Z / italic_N blackboard_Z ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT : italic_x , italic_y ∈ blackboard_Z / italic_N blackboard_Z } is not sufficiently pseudorandom (in the sense of Definition 2.1). For instance, if X,Y={1,…,N/4}𝑋𝑌1…𝑁4X,Y=\{1,\dots,N/4\}italic_X , italic_Y = { 1 , … , italic_N / 4 } and Z={3⁢N/4,…,N−1}𝑍3𝑁4…𝑁1Z=\{3N/4,\dots,N-1\}italic_Z = { 3 italic_N / 4 , … , italic_N - 1 }, then the cube X×Y×Z𝑋𝑌𝑍X\times Y\times Zitalic_X × italic_Y × italic_Z is dense in (ℤ/N⁢ℤ)3superscriptℤ𝑁ℤ3(\mathbb{Z}/N\mathbb{Z})^{3}( blackboard_Z / italic_N blackboard_Z ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT but contains no points in S𝑆Sitalic_S. Similar obstructions also exist if we replace ℤ/N⁢ℤℤ𝑁ℤ\mathbb{Z}/N\mathbb{Z}blackboard_Z / italic_N blackboard_Z with other abelian groups. Along similar lines, we note the bound in Theorem 1.2 appears to essentially be the quantitative limit of our techniques. However, it remains plausible that the strong structure imbued by quasirandomness guarantees that the largest corner-free sets over G=SL2⁢(𝔽p)𝐺subscriptSL2subscript𝔽𝑝G=\textrm{SL}_{2}(\mathbb{F}_{p})italic_G = SL start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( blackboard_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ) have size |G|2−εsuperscript𝐺2𝜀|G|^{2-\varepsilon}| italic_G | start_POSTSUPERSCRIPT 2 - italic_ε end_POSTSUPERSCRIPT for some small constant ε>0𝜀0\varepsilon>0italic_ε > 0. Such bounds would imply optimal separations between randomized and deterministic 3-NOF protocols. It would also be interesting to extend our NOF lower bounds to more than 3 players. Paper organization. We provide a detailed proof overview of our main theorem in Section 2 with proofs of the main technical lemmas deferred to Sections 5, 6, and 7. Section 3 contains a review of preliminary definitions and facts. Section 4 contains applications to lower bounds in the NOF model of communication, corners in quasirandom groups, and insights about the triangle removal lemma, respectively. Acknowledgments. We thank Russell Impagliazzo and David Zuckerman for helpful conversations, and Ilya Shkredov for answering a question about the current state-of-the-art. MJ would like to thank Sarah Peluse for her encouragement and collaboration on this question, as well as Amey Bhangale and Surya Teja Gavva for their collaboration on this question at the Simons Institue for the Theory of Computing."
https://arxiv.org/html/2411.02554v1,Quantum-Computable One-Way Functionswithout One-Way Functions,"We construct a classical oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP but quantum-computable quantum-secure trapdoor one-way functions exist. This is a substantial strengthening of the result of Kretschmer, Qian, Sinha, and Tal (STOC 2023), which only achieved single-copy pseudorandom quantum states relative to an oracle that collapses 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP to 𝖯𝖯\mathsf{P}sansserif_P. For example, our result implies multi-copy pseudorandom states and pseudorandom unitaries, but also classical-communication public-key encryption, signatures, and oblivious transfer schemes relative to an oracle on which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP. Hence, in our new relativized world, classical computers live in “Algorithmica” whereas quantum computers live in “Cryptomania,” using the language of Impagliazzo’s worlds.Our proof relies on a new distributional block-insensitivity lemma for 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuits, wherein a single block is resampled from an arbitrary distribution.","What cryptography would survive in the event of someone or some organization discovering a practical algorithm to solve 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP-complete problems? Unfortunately, almost all computationally-secure classical cryptography relies on the existence of one-way functions [IL89, Gol90]. Thus, their security certainly requires at least 𝖯≠𝖭𝖯𝖯𝖭𝖯\mathsf{P}\neq\mathsf{NP}sansserif_P ≠ sansserif_NP. Recent works have hinted that quantum analogues of many important cryptographic tasks may not be subject to this barrier. A series of black-box separations established that pseudorandom quantum states—a quantum counterpart to classical pseudorandom generators—can exist relative to oracles that make 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP [KQST23], 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA [Kre21], and more powerful complexity classes [LMW24] computationally easy. Combined with parallel efforts to build cryptosystems from pseudorandom states [AQY22, MY22, AGQY22, ALY24, BBO+24, CGG24], we now know that useful computationally-secure quantum cryptography could conceivably exist in a world where 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP. Upon closer inspection, the cryptographic protocols realized in these oracle separations all require quantum communication, or even long-term quantum memory, in addition to fault-tolerant quantum computation. So, these oracle separations are hardly a satisfactory replacement for the classical cryptography that we currently use. For example, it is possible that we find efficient algorithms for problems like breaking SHA-3 and learning with errors before we have quantum internet or reliable quantum storage. Even outside of this nightmare scenario, quantum communication is not always desirable. Besides the obvious challenges of engineering a robust quantum channel, there are other theoretical and practical limitations to protocols that use quantum communication. Certain scenarios require broadcasting, which is impossible quantumly due to the no-broadcasting theorem [BCF+96]. For a concrete example, public-key encryptions and digital signatures with public key infrastructure (PKI) have been essential for securing digital communications. While quantum versions of public-key encryptions from one-way functions [BGHD+23, Col23, KMNY24, MW24] and digital signatures without one-way functions [GC01, MY22] have been explored, these schemes all make use of an uncloneable quantum public key, besides only satisfying weak security requirements such as one-time security. This unclonability is undesirable from the PKI perspective because it prevents the PKI from distributing the public key: once the copies that the PKI holds are exhausted, new users would be unable to obtain public keys and take part in the protocols. Altogether, these limitations of quantum communication in cryptography give rise to the following natural question: What quantum cryptography with classical communication is still possible if 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP? 1.1 Main Result Consider a quantum-computable one-way function (OWF), which is like an ordinary one-way function except that instead of mandating an efficient classical evaluation algorithm, we permit (pseudo-deterministic) quantum algorithms as well. Security must hold against both classical and quantum adversaries. It is clear that this is a weakening of traditional (quantum-secure) one-way functions. Since the only difference is in permitting evaluation by a quantum computer, one might be optimistic that this object is not so different from one-way functions, perhaps by employing some clever dequantizations. After all, a 𝖡𝖯𝖯𝖡𝖯𝖯\mathsf{BPP}sansserif_BPP-computable pseudo-deterministic one-way function can be derandomized through standard black-box techniques.111In particular, a 𝖡𝖯𝖯𝖡𝖯𝖯\mathsf{BPP}sansserif_BPP-computable OWF f⁢(x;r)𝑓𝑥𝑟f(x;r)italic_f ( italic_x ; italic_r ) gives a distributional OWF f′⁢(x,r):=f⁢(x;r)assignsuperscript𝑓′𝑥𝑟𝑓𝑥𝑟f^{\prime}(x,r):=f(x;r)italic_f start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ( italic_x , italic_r ) := italic_f ( italic_x ; italic_r ), which can then be used to construct a standard OWF [IL89]. In this work, we show, surprisingly, that quantum-computable OWFs can exist in an oracle world where 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP, and therefore dequantizing a quantum-computable OWF is impossible in a black-box fashion. In fact, our main theorem is a significant strengthening of this, where we construct quantum-computable trapdoor one-way functions that are consistent with 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP. Theorem 1 (Theorem 32, informal). There exists a classical oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP and a quantum-computable trapdoor one-way function exists. Furthermore, the trapdoor one-way function has pseudorandom public keys. By invoking known post-quantum fully black-box reductions, we obtain that relative to the same classical oracle as Theorem 1, the following classical-communication cryptographic schemes also exist: • Public-key encryptions with semantic security. (Corollary 39) • Public-key signatures with existential unforgeable security. ([Son14, Section 5.1]) • Oblivious transfer protocols with simulation security. (Corollary 39) Therefore, it appears that in this oracular world, classical computers live in “Algorithmica” while quantum computers live in “Cryptomania” [Imp95], even without the need of any long-term quantum memory or quantum communication! As a corollary, all of these cryptographic schemes are separated from 𝖯≠𝖭𝖯𝖯𝖭𝖯\mathsf{P}\neq\mathsf{NP}sansserif_P ≠ sansserif_NP (thus OWFs) as well. Note that prior to our work, even mildly quantum variants of these were not known to be separated from OWFs (e.g., public-key encryption with quantum ciphertext, or quantum signatures with standard security). Implications for Quantum Pseudorandomness. Recall that the previous oracle separations of comparable nature are instantiations of pseudorandom quantum states relative to oracles that make classical cryptography easy [Kre21, KQST23, LMW24]. Our result is strictly stronger, then, because quantum-computable one-way functions are also sufficient to construct pseudorandom states since these reductions to one-way functions are fully-black-box [JLS18, BS19, AGQY22]. Specifically, one can use the now standard binary phase construction: |ψk⟩≔12n⁢∑x∈{0,1}n(−1)fk⁢(x)⁢|x⟩,≔ketsubscript𝜓𝑘1superscript2𝑛subscript𝑥superscript01𝑛superscript1subscript𝑓𝑘𝑥ket𝑥\ket{\psi_{k}}\coloneqq\frac{1}{\sqrt{2^{n}}}\sum_{x\in\{0,1\}^{n}}(-1)^{f_{k}% (x)}\ket{x},| start_ARG italic_ψ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG ⟩ ≔ divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG end_ARG ∑ start_POSTSUBSCRIPT italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( - 1 ) start_POSTSUPERSCRIPT italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) end_POSTSUPERSCRIPT | start_ARG italic_x end_ARG ⟩ , where {fk}subscript𝑓𝑘\{f_{k}\}{ italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } is a keyed family of pseudorandom functions constructed from the one-way functions [Zha21]. This directly answers an open problem from [KQST23]: Corollary 2. There exists a classical oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP and many-copy-secure pseudorandom states exist. For comparison, [KQST23] only achieved single-copy-secure pseudorandom states. Following more recent advances, one can build even more versatile quantum pseudorandomness primitives from one-way functions, including pseudorandom states of arbitrary polynomial length [BS20] and even pseudorandom unitaries [MPSY24, CBB+24, MH24]. As a corollary, these also exist relative to our oracle as well. 1.2 Technical Overview Warmup: Separating Quantum-Computable PRFs. We first show how to construct an oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP and quantum-computable pseudorandom functions (PRFs) exist. The analysis in this special case is conceptually simpler, though still rich enough to capture most of the important ideas needed to generalize to trapdoor one-way functions. The main idea behind this oracle separation is to construct a random oracle in a special encoding that is only accessible by 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP but not 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH. This encoding technique was previously seen in the work of Aaronson, Ingram, and Kretschmer [AIK22], although similar ideas have also appeared in even earlier works [BM99, ABDK16]. Then intuitively, the quantum-computable pseudorandom functions can simply be constructed by direct evaluation of this quantum-computable random oracle. We now explain the oracle construction in more detail. Similar to the oracle used in [KQST23], our oracle 𝒪𝒪\mathcal{O}caligraphic_O can be thought of as a pair of oracles (A,B)𝐴𝐵(A,B)( italic_A , italic_B ). The oracle A𝐴Aitalic_A encodes the 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP-accessible random oracle, and the addition of auxiliary oracle B𝐵Bitalic_B has the effect of making 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP. Morally speaking, B𝐵Bitalic_B behaves as if it were an oracle for 𝖯𝖧Asuperscript𝖯𝖧𝐴\mathsf{PH}^{A}sansserif_PH start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT. Thus, showing the security of the quantum-computable PRFs relative to 𝒪𝒪\mathcal{O}caligraphic_O amounts to proving security against polynomial-time quantum adversaries that can query any 𝖯𝖧Asuperscript𝖯𝖧𝐴\mathsf{PH}^{A}sansserif_PH start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT language. For brevity, we’ll call these 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT (oracular) adversaries in this exposition. The key difference between our oracle construction and that of [KQST23] is in how we build A𝐴Aitalic_A. In [KQST23], A𝐴Aitalic_A is simply a random oracle, whereas in this warmup, A𝐴Aitalic_A is an encoding of a uniformly random oracle. As with many of the oracles constructed in [AIK22], we encode each bit of the oracle using the Forrelation problem [Aar10, RT19]. Recall that Forrelation (in its broadest sense) is the following task: given query access to a pair of functions f,g:{0,1}ℓ→{0,1}:𝑓𝑔→superscript01ℓ01f,g:\{0,1\}^{\ell}\to\{0,1\}italic_f , italic_g : { 0 , 1 } start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT → { 0 , 1 }, distinguish between (NO) f𝑓fitalic_f and g𝑔gitalic_g are independent uniformly random functions, or (YES) f𝑓fitalic_f and g𝑔gitalic_g are individually random, but sampled in such a way that f𝑓fitalic_f is noticeably correlated with the Boolean Fourier transform of g𝑔gitalic_g (i.e., f𝑓fitalic_f and g𝑔gitalic_g are “Forrelated”). In contrast to [KQST23], whose analysis required a carefully-crafted version of Forrelation, we only require black-box use of one key fact from [RT19]: that these two distributions are efficiently distinguishable by 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP algorithms, but not by 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH algorithms. Letting L𝐿Litalic_L be the random oracle, our strategy for encoding L𝐿Litalic_L is to hide each bit of its output behind an instance of Forrelation. That is, for each x∈{0,1}∗𝑥superscript01x\in\{0,1\}^{*}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT, we add a region of A𝐴Aitalic_A that encodes a pair of uniformly random Boolean functions if L⁢(x)=0𝐿𝑥0L(x)=0italic_L ( italic_x ) = 0, or otherwise a pair of Forrelated functions if L⁢(x)=1𝐿𝑥1L(x)=1italic_L ( italic_x ) = 1. It is straightforward to show that oracle access to A𝐴Aitalic_A enables a quantum algorithm to recover any bit of L𝐿Litalic_L. The candidate quantum-computable PRF family {fk}subscript𝑓𝑘\{f_{k}\}{ italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } is the natural choice defined by fk(x)≔L(k||x)f_{k}(x)\coloneqq L(k||x)italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) ≔ italic_L ( italic_k | | italic_x ). The main technical difficulty is to formalize the intuition that this encoding is secure enough against 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH that distinguishing the PRFs from random remains hard even against 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT adversaries. We expect this to be the case because to 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH, the oracle A𝐴Aitalic_A looks completely random and independent of L𝐿Litalic_L, and therefore a 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT adversary should not have much more power than a 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP adversary. To make this argument rigorous, we have to prove that a 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT adversary, given oracle access to an auxiliary function hℎhitalic_h, cannot distinguish whether hℎhitalic_h is uniformly random or whether hℎhitalic_h is one of the pseudorandom functions fksubscript𝑓𝑘f_{k}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT. We establish this by observing that it suffices to show the following: if the adversary is given a uniformly random hℎhitalic_h, then the adversary is unlikely to detect a change to the oracle A𝐴Aitalic_A so as to make it consistent with h=fkℎsubscript𝑓𝑘h=f_{k}italic_h = italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT for a random key k𝑘kitalic_k. For the PRF family {fk}k∈{0,1}nsubscriptsubscript𝑓𝑘𝑘superscript01𝑛\{f_{k}\}_{k\in\{0,1\}^{n}}{ italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT of functions fk:{0,1}n→{0,1}:subscript𝑓𝑘→superscript01𝑛01f_{k}:\{0,1\}^{n}\to\{0,1\}italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → { 0 , 1 }, we can view the part of A𝐴Aitalic_A encoding these functions as a 2n×2nsuperscript2𝑛superscript2𝑛2^{n}\times 2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT × 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT matrix of Forrelation instances. In this matrix, the rows are indexed by keys k∈{0,1}n𝑘superscript01𝑛k\in\{0,1\}^{n}italic_k ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the columns by inputs x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, and the corresponding Forrelation instance is Forrelated if fk⁢(x)=1subscript𝑓𝑘𝑥1f_{k}(x)=1italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) = 1, or uniform otherwise. Given h:{0,1}n→{0,1}:ℎ→superscript01𝑛01h:\{0,1\}^{n}\to\{0,1\}italic_h : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → { 0 , 1 }, the goal of the adversary is to determine whether there is a row of the matrix whose pattern of Forrelated/uniform instances is consistent with hℎhitalic_h. See Figure 1 for an example. h=ℎabsenth=italic_h = 0 1 0 1 ⇓⇓\Downarrow⇓ Uniform Forrelated Uniform Uniform Forrelated Uniform Forrelated Forrelated Forrelated Uniform Forrelated Uniform Uniform Uniform Forrelated Forrelated vs. Uniform Forrelated Uniform Uniform Uniform Forrelated Uniform Forrelated Forrelated Uniform Forrelated Uniform Uniform Uniform Forrelated Forrelated Figure 1: An example of the distinguishing task for our quantum-computable PRFs with n=2𝑛2n=2italic_n = 2. The goal is to decide (left) whether the Forrelation instances in the matrix are all randomly assigned to either uniform or Forrelated, or (right) whether the pattern of 0s/1s in hℎhitalic_h matches the pattern of uniform/Forrelated in one of the rows. Our security proof proceeds in a similar fashion to the 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT lower bound for the so-called OR∘ForrelationORForrelation\textsc{OR}\circ\textsc{Forrelation}OR ∘ Forrelation problem that was considered in prior works [AIK22, KQST23]. In OR∘ForrelationORForrelation\textsc{OR}\circ\textsc{Forrelation}OR ∘ Forrelation, we are given a list of instances of the Forrelation problem, and must decide whether they are all uniform (NO), or whether a single one of the instances is Forrelated (YES). Using the well-known correspondence between 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH query algorithms and 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuits [FSS84], the 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT lower bound for OR∘ForrelationORForrelation\textsc{OR}\circ\textsc{Forrelation}OR ∘ Forrelation reduces to a certain type of sensitivity concentration result for 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuits. The key step [AIK22, Lemma 45] shows that for most uniformly random M×N𝑀𝑁M\times Nitalic_M × italic_N Boolean matrices, an 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuit is unlikely to notice the change if we uniformly swap out one of the rows for fresh random bits. We show that security of our PRF ensemble also reduces to a comparable statement about the sensitivity of 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuits, but under a distribution of Boolean matrices that is not uniform. Instead, we have to consider matrices like those sampled in Figure 1, where the blocks are a random pattern of uniform or Forrelated. For this purpose, we are able to show the following main technical lemma, which informally states the following. Consider a quasi-polynomial-size 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuit that takes K𝐾Kitalic_K blocks of bits, where each block is sampled independently from an arbitrary distribution 𝒟𝒟\mathcal{D}caligraphic_D. Then for sufficiently large K𝐾Kitalic_K, it is hard for it to notice if any block is resampled from the same distribution 𝒟𝒟\mathcal{D}caligraphic_D. More formally, Lemma 3 (Lemma 15, restated). Let f:{0,1}K⁢M→{0,1}:𝑓→superscript01𝐾𝑀01f:\{0,1\}^{KM}\to\{0,1\}italic_f : { 0 , 1 } start_POSTSUPERSCRIPT italic_K italic_M end_POSTSUPERSCRIPT → { 0 , 1 } be an 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuit of size s𝑠sitalic_s and depth d𝑑ditalic_d. Let 𝒟𝒟\mathcal{D}caligraphic_D be a distribution over {0,1}Msuperscript01𝑀\{0,1\}^{M}{ 0 , 1 } start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT. Let x∼𝒟Ksimilar-to𝑥superscript𝒟𝐾x\sim\mathcal{D}^{K}italic_x ∼ caligraphic_D start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT be an input to f𝑓fitalic_f, viewed as a K×M𝐾𝑀K\times Mitalic_K × italic_M matrix. Let y𝑦yitalic_y be sampled depending on x𝑥xitalic_x as follows: uniformly select one of the rows of x𝑥xitalic_x, resample that row from 𝒟𝒟\mathcal{D}caligraphic_D, and leave the other rows of x𝑥xitalic_x unchanged. Then for any p>0𝑝0p>0italic_p > 0: Prx∼𝒟K⁡[Pry⁡[f⁢(x)≠f⁢(y)]≥p]≤4⁢Kp⋅2−p⁢KO⁢(log⁡s)d−1.subscriptPrsimilar-to𝑥superscript𝒟𝐾subscriptPr𝑦𝑓𝑥𝑓𝑦𝑝⋅4𝐾𝑝superscript2𝑝𝐾𝑂superscript𝑠𝑑1\Pr_{x\sim\mathcal{D}^{K}}\left[\Pr_{y}\left[f(x)\neq f(y)\right]\geq p\right]% \leq\frac{4K}{p}\cdot 2^{-\frac{pK}{O(\log s)^{d-1}}}.roman_Pr start_POSTSUBSCRIPT italic_x ∼ caligraphic_D start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ roman_Pr start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT [ italic_f ( italic_x ) ≠ italic_f ( italic_y ) ] ≥ italic_p ] ≤ divide start_ARG 4 italic_K end_ARG start_ARG italic_p end_ARG ⋅ 2 start_POSTSUPERSCRIPT - divide start_ARG italic_p italic_K end_ARG start_ARG italic_O ( roman_log italic_s ) start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT end_ARG end_POSTSUPERSCRIPT . Notably, this holds for any distribution 𝒟𝒟\mathcal{D}caligraphic_D, and not merely the distribution of randomly chosen uniform/Forrelated blocks. Previously, Lemma 3 was only known to hold in the special case where 𝒟𝒟\mathcal{D}caligraphic_D is the uniform distribution [AIK22, Lemma 45]. The proof of this lemma involves a careful construction of a related 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuit from f𝑓fitalic_f, whose sensitivity corresponds to the probability of f𝑓fitalic_f noticing the block being resampled. This then allows us to relate this to known sensitivity bounds on 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT circuits [AIK22]. We refer interested readers to Lemma 15 for the details. Generalization to Trapdoor Functions. Since Lemma 3 morally lets us resample an arbitrary block that can be arbitrarily distributed, we can in fact prove that the distinguishing task in Figure 1 is hard for any distribution of functions instead of just uniform. A natural idea then is to use Forrelation to encode a more structured oracle that allows us to construct more structured cryptographic primitives. However, we also cannot introduce more structure than what Lemma 3 allows us to handle. For example, to get quantum-computable oblivious transfer protocols, a natural idea would be to encode random trapdoored permutations or something similar instead. However, unlike a random function, a random permutation is already problematic since each entry in a random permutation is weakly correlated with the other entries. On the other hand, Lemma 3 only works with product distributions. Inspired by this example, we instead start with random functions and only introduce just enough structure to have a trapdoor. Specifically, to obtain an oracle relative to which some form of quantum-computable trapdoor one-way functions exist but 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP, we utilize a similar Forrelation encoding, but the oracle A𝐴Aitalic_A is no longer random. Instead, A𝐴Aitalic_A encodes a triple of functions G,F,I𝐺𝐹𝐼G,F,Iitalic_G , italic_F , italic_I where • G⁢(t⁢d)𝐺𝑡𝑑G(td)italic_G ( italic_t italic_d ) is a random function mapping a trapdoor t⁢d𝑡𝑑tditalic_t italic_d to its public key p⁢k𝑝𝑘pkitalic_p italic_k; • F⁢(p⁢k,x)𝐹𝑝𝑘𝑥F(pk,x)italic_F ( italic_p italic_k , italic_x ) is also a random function mapping a public key p⁢k𝑝𝑘pkitalic_p italic_k and input x𝑥xitalic_x to an output y𝑦yitalic_y; • Finally, I⁢(t⁢d,y)𝐼𝑡𝑑𝑦I(td,y)italic_I ( italic_t italic_d , italic_y ) is the only “structured” function that inverts an image y𝑦yitalic_y of F⁢(G⁢(t⁢d),⋅)𝐹𝐺𝑡𝑑⋅F(G(td),\cdot)italic_F ( italic_G ( italic_t italic_d ) , ⋅ ) using the trapdoor t⁢d𝑡𝑑tditalic_t italic_d. Then the quantum-computable trapdoor one-way function construction is simply evaluating these three functions G,F,I𝐺𝐹𝐼G,F,Iitalic_G , italic_F , italic_I by a 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP algorithm that queries the Forrelation encodings in A𝐴Aitalic_A. For security, we want to show that a 𝖡𝖰𝖯𝖯𝖧superscript𝖡𝖰𝖯𝖯𝖧\mathsf{BQP^{PH}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_PH end_POSTSUPERSCRIPT adversary, given p⁢k=G⁢(t⁢d)𝑝𝑘𝐺𝑡𝑑pk=G(td)italic_p italic_k = italic_G ( italic_t italic_d ) and y=F⁢(p⁢k,x)𝑦𝐹𝑝𝑘𝑥y=F(pk,x)italic_y = italic_F ( italic_p italic_k , italic_x ) for random trapdoor t⁢d𝑡𝑑tditalic_t italic_d and input x𝑥xitalic_x, cannot find a preimage x′superscript𝑥′x^{\prime}italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT such that F⁢(p⁢k,x′)=y𝐹𝑝𝑘superscript𝑥′𝑦F(pk,x^{\prime})=yitalic_F ( italic_p italic_k , italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) = italic_y. Proving this is more challenging than before since the encoded oracle here is more sophisticated than simply a random function. However, notice that the previous security proof for the PRF reduces to a resampling indistinguishability task (Figure 1). We can similarly reduce security to resampling indistinguishability with some additional steps: 1. Starting with the real experiment (G,F,I)𝐺𝐹𝐼(G,F,I)( italic_G , italic_F , italic_I ), we first argue that G𝐺Gitalic_G and I𝐼Iitalic_I do not help the adversary in inverting y𝑦yitalic_y as follows. (a) First, resample G⁢(t⁢d)=p⁢k∗𝐺𝑡𝑑𝑝superscript𝑘G(td)=pk^{*}italic_G ( italic_t italic_d ) = italic_p italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT and set I⁢(t⁢d,⋅)𝐼𝑡𝑑⋅I(td,\cdot)italic_I ( italic_t italic_d , ⋅ ) to be the inversion table for F⁢(p⁢k∗,⋅)𝐹𝑝superscript𝑘⋅F(pk^{*},\cdot)italic_F ( italic_p italic_k start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT , ⋅ ) instead: this is indistinguishable since we are resampling one of exponentially many blocks of (G,I)𝐺𝐼(G,I)( italic_G , italic_I ). (b) Next, we want to claim that I𝐼Iitalic_I no longer contains the inversion table for F⁢(p⁢k,⋅)𝐹𝑝𝑘⋅F(pk,\cdot)italic_F ( italic_p italic_k , ⋅ ). The idea is to argue that t⁢d𝑡𝑑tditalic_t italic_d was the only trapdoor that inverts F⁢(p⁢k,⋅)𝐹𝑝𝑘⋅F(pk,\cdot)italic_F ( italic_p italic_k , ⋅ ) and after resampling it, there is no trapdoor left to invert F⁢(p⁢k,⋅)𝐹𝑝𝑘⋅F(pk,\cdot)italic_F ( italic_p italic_k , ⋅ ) with overwhelming probability. For this to hold, it suffices to take G𝐺Gitalic_G to be length expanding enough so that it is injective with overwhelming probability. 2. After the first step, F⁢(p⁢k,⋅)𝐹𝑝𝑘⋅F(pk,\cdot)italic_F ( italic_p italic_k , ⋅ ) is essentially a random function independent of the rest of the oracle, which includes I𝐼Iitalic_I, G𝐺Gitalic_G, and the rest of F𝐹Fitalic_F. Therefore, we can prove it is one-way using the same approach as before. Morally, we next resample F⁢(p⁢k,x)𝐹𝑝𝑘𝑥F(pk,x)italic_F ( italic_p italic_k , italic_x ) indistinguishably so that y𝑦yitalic_y is no longer in the image of F⁢(p⁢k,⋅)𝐹𝑝𝑘⋅F(pk,\cdot)italic_F ( italic_p italic_k , ⋅ ), making inversion impossible. Beyond Trapdoor Functions. Observe that this proof sketch actually establishes something stronger. Specifically, the two steps above prove that our trapdoor function construction satisfies two additional properties, which are respectively: (a) the public keys are pseudorandom and (b) the function is one-way under a truly random public key. These properties allow us to construct what is called a fakeable public-key encryption (PKE) scheme [GKM+00] which is “essentially equivalent” to semi-honest oblivious transfer. On a high level, a fakeable public-key primitive has a “fake mode” of sampling the public key such that security holds even if given the randomness for fakely sampling the public key. In our case, the fake mode sampling would simply be outputting the input randomness as is. Finally, we briefly comment on adapting constructions for trapdoor one-way functions with pseudorandom public keys to the quantum-computable setting, such as constructing fully-secure oblivious transfer from a semi-honest protocol. Building cryptography out of quantum-computable primitives requires additional care, because it is not always possible to mindlessly substitute a classical primitive with a quantum-computable counterpart. For example, consider the scenario where we wish to prove that a one-way function was computed correctly in zero-knowledge.222This is not a contrived example: many oblivious transfer protocol constructions do make use of such functionality. Classically, this could be done just by the assumption that one-way functions exist because the statement above is in 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP. However, if we wish to instead prove that a quantum-computable one-way function was computed correctly in zero-knowledge, then this would appear to be a 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA statement, so the construction breaks down. We resolve this by observing that as long as we have a post-quantum fully black-box reduction [RTV04] then substituting with a quantum-computable primitive works. 1.3 Discussion Explaining Quantum-Classical Separations. There are two high-level reasons why quantum cryptographic primitives are harder to break than classical ones, even if they inherently can only be computationally secure.333We focus on separations of these strictly-computational primitives, unlike statistical-computational separations such as QKD [BB84] vs. classical key exchange. The first is purely complexity-theoretic: because the challenger is quantum rather than classical, adversaries require stronger computational power to detect patterns produced by the challenger. For example, whereas inverting a one-way function is a canonical example of an 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP problem, inverting a quantum-computable one-way function is a 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA problem. The containment 𝖭𝖯⊆𝖰𝖢𝖬𝖠𝖭𝖯𝖰𝖢𝖬𝖠\mathsf{NP}\subseteq\mathsf{QCMA}sansserif_NP ⊆ sansserif_QCMA is believed to be strict, and this distinction alone allows for the possibility that quantum cryptography could be beyond the grasp of 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP algorithms. The second reason is information-theoretic: the challenges themselves could be complex and highly-entangled quantum states, rather than classical bit strings that can be readily copied. So, we cannot even express the security games as problems within our usual mathematical framework of complexity classes like 𝖯𝖯\mathsf{P}sansserif_P, 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP, 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP, or 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA: these classes are only equipped to operate on classical inputs! While some recent efforts have been made to define complexity classes that accept quantum inputs (e.g. 𝗎𝗇𝗂𝗍𝖺𝗋𝗒𝖡𝖰𝖯𝗎𝗇𝗂𝗍𝖺𝗋𝗒𝖡𝖰𝖯\mathsf{unitaryBQP}sansserif_unitaryBQP [BEM+23]), the connections between these “𝗎𝗇𝗂𝗍𝖺𝗋𝗒𝗎𝗇𝗂𝗍𝖺𝗋𝗒\mathsf{unitary}sansserif_unitary” complexity classes and their classical-input counterparts remain unclear. We point out this distinction because to date, the existing oracle separations between pseudorandom states and classical cryptography [Kre21, KQST23, LMW24] have widely been understood as arising from the second feature. Our Theorem 1 is the first that clearly makes use of the first feature exclusively, because quantum-computable one-way functions output classical security challenges. For comparison, recall: • [Kre21] constructs a quantum oracle relative to which 𝖡𝖰𝖯=𝖰𝖬𝖠𝖡𝖰𝖯𝖰𝖬𝖠\mathsf{BQP}=\mathsf{QMA}sansserif_BQP = sansserif_QMA and pseudorandom states exist. The proof makes crucial use of the quantum-challenge nature of pseudorandom states. One way to see this is the fact that quantum-computable one-way functions do not exist relative to this oracle. • [KQST23] constructs an oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP and single-copy pseudorandom states exist. Here, it is not so clear whether the quantumness of the pseudorandom states is essential for this separation, as quantum-computable one-way functions may or may not exist relative to this oracle. (We discuss this further in the related work section.) • [LMW24] (implicitly444Take a random language L𝐿Litalic_L, and let the oracle 𝒪𝒪\mathcal{O}caligraphic_O be any 𝖯𝖲𝖯𝖠𝖢𝖤Lsuperscript𝖯𝖲𝖯𝖠𝖢𝖤𝐿\mathsf{PSPACE}^{L}sansserif_PSPACE start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT-complete language. Then clearly 𝖯𝒪=𝖯𝖲𝖯𝖠𝖢𝖤𝒪superscript𝖯𝒪superscript𝖯𝖲𝖯𝖠𝖢𝖤𝒪\mathsf{P}^{\mathcal{O}}=\mathsf{PSPACE}^{\mathcal{O}}sansserif_P start_POSTSUPERSCRIPT caligraphic_O end_POSTSUPERSCRIPT = sansserif_PSPACE start_POSTSUPERSCRIPT caligraphic_O end_POSTSUPERSCRIPT. [LMW24] construct a single-copy pseudorandom state ensemble using queries to L𝐿Litalic_L (which can certainly be simulated using queries to 𝒪𝒪\mathcal{O}caligraphic_O) whose parallel-query security holds relative to any oracle 𝒪𝒪\mathcal{O}caligraphic_O. ) constructs a classical oracle relative to which 𝖯=𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{P}=\mathsf{PSPACE}sansserif_P = sansserif_PSPACE and single-copy pseudorandom states cannot be broken by efficient parallel-query adversaries. But 𝖯=𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{P}=\mathsf{PSPACE}sansserif_P = sansserif_PSPACE implies (for example) that any one-round classical-communication falsifiable protocol can be broken by an efficient parallel-query adversary, because the optimal adversary strategy can be simulated in 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE. This certainly implies that quantum-computable one-way functions do not exist relative to this oracle. So, the security of the pseudorandom state ensemble here also relies on its use of quantum challenges. Thus, our work is the only one to use the first feature alone, hinting at the possibility of quantum advantage for computing a one-way function. For this reason, a worthwhile direction for future research complementing ours is to give stronger evidence that the second feature (the use of quantum states in computationally-secure cryptography) directly enables separations from classical cryptography. All of the existing separations in this regard have caveats: [Kre21] uses a quantum oracle, [KQST23] might not rely on the use of quantum challenges at all, and [LMW24] only obtains security against parallel-query adversaries. For this purpose, we reiterate the following open problem that was raised in earlier works [Kre21, KQST23]: Problem 4. Construct a classical oracle relative to which 𝖯=𝖰𝖬𝖠𝖯𝖰𝖬𝖠\mathsf{P}=\mathsf{QMA}sansserif_P = sansserif_QMA (or at least 𝖡𝖰𝖯=𝖰𝖢𝖬𝖠𝖡𝖰𝖯𝖰𝖢𝖬𝖠\mathsf{BQP}=\mathsf{QCMA}sansserif_BQP = sansserif_QCMA) and pseudorandom states (or at least quantum commitments) exist. The main appeal of 4 is that it would answer this conceptual question about the role of quantum challenges in cryptography, without necessarily requiring a resolution to the long-standing unitary synthesis problem in quantum query complexity [AK07, Aar16, LMW24]. Related Work. Compared to [KQST23], who gave a black-box construction of single-copy-secure pseudorandom states relative to an oracle that makes 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP, our work has some advantages. As noted before, our result is strictly stronger, because one can additionally build quantum-computable (trapdoor) one-way functions relative to our oracle. These imply single-copy pseudorandom states but are not necessary for them [Kre21]. Also, our proof is somewhat simpler, because we do not require a special version of the Forrelation problem; hardness against 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT and easiness for quantum algorithms are sufficient for the construction to work. One difference, however, is that our oracle is more structured. Both our oracle and [KQST23]’s take the form 𝒪=(A,B)𝒪𝐴𝐵\mathcal{O}=(A,B)caligraphic_O = ( italic_A , italic_B ), where in both cases B𝐵Bitalic_B is constructed from A𝐴Aitalic_A in an identical fashion. But, whereas [KQST23] takes A𝐴Aitalic_A to be a random oracle, we do not. The Aaronson–Ambainis conjecture [AA14] provides some evidence that this difference is necessary: if the Aaronson–Ambainis conjecture is true, then any pseudo-deterministic quantum algorithm querying the random oracle can be query-efficiently simulated by a classical algorithm as well. Thus, intuitively, a random oracle does not assist in building a quantum-computable one-way function that is not also classically-computable. Our main theorem also improves upon the separation in [AIK22, Theorem 4], which shows that there is an oracle relative to which 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP but 𝖡𝖰𝖯≠𝖰𝖢𝖬𝖠𝖡𝖰𝖯𝖰𝖢𝖬𝖠\mathsf{BQP}\neq\mathsf{QCMA}sansserif_BQP ≠ sansserif_QCMA. The same complexity class separations hold relative to our oracle, because quantum-computable one-way functions cannot exist if 𝖡𝖰𝖯=𝖰𝖢𝖬𝖠𝖡𝖰𝖯𝖰𝖢𝖬𝖠\mathsf{BQP}=\mathsf{QCMA}sansserif_BQP = sansserif_QCMA. Starting with the work of Ananth, Gulati, Qian, and Yuen [AGQY22], there have been a few works [ALY24, BBO+24, CGG24] aiming to construct classical-communication quantum cryptography without using a one-way function. One might intuitively believe that these constructions do not rely on one-way functions because they are based on logarithmic-output-length pseudorandom states, which seem weaker. Nevertheless, our work is the first to black-box separate these logarithmic-output-length pseudorandom states from one-way functions, as they can be black-box constructed from quantum-computable pseudorandom functions [BS20]. Furthermore, we separate a stronger object, a (pseudo-deterministic) trapdoor one-way function. Pseudorandom state-based constructions are also messier and less elegant due to the use of tomography. Another recent line of works aim to investigate the (im)possibility of constructing quantum public-key encryption (PKE) schemes from one-way functions [ACC+22, BGHD+23, Col23, BGVV24, KMNY24, LLLL24, MW24]. Specifically, it is shown that they can be constructed from OWFs if the public key is allowed to be an uncloneable quantum state. We do consider the stronger notion of quantum-computable classical-communication PKE, but the construction essentially assumes quantum-computable trapdoor OWFs. This assumption (as we have shown) is incomparable to OWFs. Future Directions. One open question is to strengthen our separation to separate quantum-computable collision resistance, quantum-computable one-way permutations, or quantum-computable indistinguishability obfuscation and quantum-computable OWFs from 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP as well. Our oracle construction could be straightforwardly adapted to those settings by replacing the Forrelation-encoded random oracle with a Forrelation encoding of any oracle that instantiates these primitives. However, proving security of these primitives relative to such oracles remains a challenge. It seems one would need a stronger 𝖠𝖢𝟢superscript𝖠𝖢0\mathsf{AC^{0}}sansserif_AC start_POSTSUPERSCRIPT sansserif_0 end_POSTSUPERSCRIPT sensitivity bound (like Lemma 3) capable of handling a more complicated resampling procedure, e.g. where multiple rows may be updated in a correlated fashion. While our work, along with earlier oracle separations, only studies separations between abstract cryptographic primitives, these also reveal a potential pathway towards finding cryptographically-useful concrete assumptions beneath one-way functions. Specifically, this work shows that if we consider a candidate one-way function that we only know how to evaluate with quantum computers, then its security could resist even the proof of 𝖯=𝖭𝖯𝖯𝖭𝖯\mathsf{P}=\mathsf{NP}sansserif_P = sansserif_NP. Unlike the work of [KQST23], however, it is unclear how to heuristically instantiate our oracle, because we do not know of any candidates for non-oracular problems in 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP that are hard for 𝖯𝖧𝖯𝖧\mathsf{PH}sansserif_PH [Aar18]. However, the recent work of Khurana and Tomer [KT24] constructs quantum cryptography from #⁢𝖯#𝖯\mathsf{\#P}# sansserif_P-hardness and quantum advantage conjectures, and our work hints that quantum-computable classical cryptography could be realized from similar assumptions as well. We leave as a future research direction to investigate concrete quantum-computable classical cryptography instantiations. Finally, we note that our technical contributions may prove useful towards resolving a certain open problem about oracle separations of complexity classes. Aaronson [Aar10] raised the question of whether there exists an oracle relative to which 𝖭𝖯⊆𝖡𝖰𝖯𝖭𝖯𝖡𝖰𝖯\mathsf{NP}\subseteq\mathsf{BQP}sansserif_NP ⊆ sansserif_BQP but 𝖯𝖧⊄𝖡𝖰𝖯not-subset-of𝖯𝖧𝖡𝖰𝖯\mathsf{PH}\not\subset\mathsf{BQP}sansserif_PH ⊄ sansserif_BQP. Later work by Aaronson, Ingram, and Kretschmer [AIK22] conjectured the possibility of a more granular separation, namely: an oracle relative to which Σk𝖯⊆𝖡𝖰𝖯superscriptsubscriptsans-serif-Σ𝑘𝖯𝖡𝖰𝖯\mathsf{\Sigma}_{k}^{\mathsf{P}}\subseteq\mathsf{BQP}sansserif_Σ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT start_POSTSUPERSCRIPT sansserif_P end_POSTSUPERSCRIPT ⊆ sansserif_BQP but Σk+1𝖯⊄𝖡𝖰𝖯not-subset-ofsuperscriptsubscriptsans-serif-Σ𝑘1𝖯𝖡𝖰𝖯\mathsf{\Sigma}_{k+1}^{\mathsf{P}}\not\subset\mathsf{BQP}sansserif_Σ start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT sansserif_P end_POSTSUPERSCRIPT ⊄ sansserif_BQP, for any desired k∈ℕ𝑘ℕk\in\mathbb{N}italic_k ∈ blackboard_N. Moreover, they gave a candidate construction of such an oracle, and sketched a possible route towards showing that this oracle satisfies the desired properties [AIK22, Section 6.2]. We remark that Lemma 3 is precisely one of the steps in their proposed sketch, although it does not seem to be sufficient on its own to achieve the separation."
https://arxiv.org/html/2411.02535v1,Polynomial-Time Classical Simulation of Noisy Circuits with Naturally Fault-Tolerant Gates,"We construct a polynomial-time classical algorithm that samples from the output distribution of low-depth noisy Clifford circuits with any product-state inputs and final single-qubit measurements in any basis. This class of circuits includes Clifford-magic circuits and Conjugated-Clifford circuits, which are important candidates for demonstrating quantum advantage using non-universal gates. Additionally, our results generalize a simulation algorithm for IQP circuits [RWL24] to the case of IQP circuits augmented with CNOT gates, which is another class of non-universal circuits that are relevant to current experiments. Importantly, our results do not require randomness assumptions over the circuit families considered (such as anticoncentration properties) and instead hold for every circuit in each class. This allows us to place tight limitations on the robustness of these circuits to noise. In particular, we show that there is no quantum advantage at large depths with realistically noisy Clifford circuits, even with perfect magic state inputs, or IQP circuits with CNOT gates, even with arbitrary diagonal non-Clifford gates. The key insight behind the algorithm is that interspersed noise causes a decay of long-range entanglement, and at depths beyond a critical threshold, the noise builds up to an extent that most correlations can be classically simulated. To prove our results, we merge techniques from percolation theory with tools from Pauli path analysis.","A first step towards understanding the power of quantum computation is to determine the conditions under which it is possible to perform a quantum computation that cannot be classically simulated or, in other words, to demonstrate “quantum advantage”. Although there is robust theoretical evidence that this is true for large-scale fault-tolerant quantum computers, this becomes a subtle question when restricted to near-term quantum hardware. These devices are noisy and may lack capabilities that are required for fault tolerance such as the ability to perform intermediate measurements or reset qubits during a computation. To address these questions, a line of research has considered the task of sampling from the output distribution of (random) quantum circuits as a way to demonstrate quantum advantage [TD04]. This is relevant to near-term hardware because even very restricted models of quantum computation can be used to demonstrate such quantum advantages, and the advantage is not contrived in that it tolerates a constant amount of total error [BJS10, BMS16, AA13, GWD17, HKS+17]. Adding realistic noise with constant rate complicates this picture however, since the fidelity with which the targeted task can be performed on a noisy quantum device diminishes exponentially with the system size. An important line of research is therefore to study the computational power of quantum computations with quantitatively realistic noise assumptions [ABOIN96, FT16, BMS17, AGL+23, CCHL22]. Obtaining a precise understanding of the computational power of noisy restricted models of computation can thus yield new insights into whether or not quantum computers can retain robustness to noise and elucidate the ingredients that are necessary for quantum advantage. In this work, we consider noisy quantum circuits with gate sets that are naturally fault-tolerant. These include Clifford circuits with state preparation and measurement in arbitrary product bases, and IQP circuits augmented with CNOT gates. In particular, this allows for magic state inputs in the case of Clifford circuits and arbitrary diagonal non-Clifford gates in the case of IQP+CNOT circuits. The circuit classes we consider do not allow for intermediate measurement and classical feed-forward and are therefore not universal for quantum computation. At the same time, they constitute circuits which are readily implementable in early fault-tolerant quantum devices which can implement non-universal gate sets [BEG+24, EK09], making them good candidates for demonstration of quantum advantage. In particular, these circuit classes include Clifford-magic, conjugated Clifford circuits and hypercube block IQP circuits, which have all been proven to be hard to approximately sample from in the nearly noiseless case assuming certain complexity-theoretic conjectures [YJS19, BFK18, HKB+24]. Thus, it is important to understand the noise and depth regimes in which these circuits maintain their computational power. Providing a lower bound on computational power, Fujii and Tamate have constructed a family of low-depth Clifford-magic circuits for which they give complexity-theoretic evidence that exact simulation is classically intractable even in the presence of sufficiently weak, constant-strength local noise [FT16]. A common way to upper bound the computational power of a class of noisy quantum circuits is to construct a classical simulation algorithm that approximately samples from its output distribution, assuming a general noise model. If the runtime of this algorithm is polynomial, then this circuit class cannot be used to demonstrate quantum advantage. There is a rich landscape of existing work that deals with this task. However, a common proof technique in prior work relies on the randomness of the quantum circuits considered [AGL+23, BMS17, TTT21, GD18, MAG+24, SYGY24, FRD+23]. They show that typical noisy quantum circuits can be simulated. However, such techniques cannot exclude the possibility of a worst-case circuit which is cleverly designed to maintain robustness to noise (e.g. [ABOIN96, FT16]), which is precisely the goal of near-term fault-tolerance. For worst-case noisy circuits, the strongest upper bound on computational complexity is due to Aharonov et al. [ABOIN96], who showed that the output distribution of any noisy quantum circuit converges to uniform after circuit depth which is logarithmic in system size, and is thus trivially simulatable. The same work [ABOIN96] also demonstrates a lower bound on the computational complexity of general quantum circuits by proving that noisy quantum circuits can solve problems in Q⁢N⁢C1𝑄𝑁superscript𝐶1QNC^{1}italic_Q italic_N italic_C start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT (decision problems solvable by noiseless logarithmic depth quantum circuits) with a quasipolynomial overhead in system size. At the same time, Shor’s factoring algorithm can be implemented using log-depth quantum circuits [CW00]. Together, these results provide some evidence that it is difficult in general to classically simulate noisy quantum circuits at logarithmic depths. This suggests to start by understanding the classical simulatability of restricted families of noisy quantum circuits that correspond to the limitations of near-term hardware, such as 2⁢D2𝐷2D2 italic_D-local or non-universal circuits. In this work, we develop a classical simulation algorithm for noisy Clifford and IQP + CNOT circuits with any product-state input and final single-qubit measurements in any basis. Applied to geometrically local circuits, our algorithm is efficient at low circuit depths above a constant threshold that depends on the noise rate (we assume single-qubit depolarizing channels after every circuit layer), and is efficient for all circuits in this class. Importantly, our results hold even if the magic input states are perfect. Our results thus provide strong evidence that in order to achieve quantum advantage with realistically noisy circuits an additional ingredient is required such as non-Clifford mid-circuit gates, intermediate measurement, or a supply of fresh qubits. Our techniques improve upon the simulation methods of [BMS17, GD18, AGL+23], which require at least logarithmic circuit depth and only work for typical circuit instances, although we assume a restricted circuit model. The only prior work achieving both properties (worst-case and constant-depth simulability) is Ref. [RWL24], which restricts to purely diagonal IQP circuits. 1.1 Overview of Results We summarize our main result informally in the following theorem. Theorem 1 (Informal). There exists an efficient randomized classical algorithm that approximately samples from the output distribution of a noisy quantum circuit C𝐶Citalic_C with circuit-level local noise rate γ𝛾\gammaitalic_γ in the following cases, 1. C𝐶Citalic_C is a geometrically local Clifford-Magic, Conjugated Clifford, or IQP+CNOT circuit and d≥Ω⁢(γ−1⁢log⁡γ−1)𝑑Ωsuperscript𝛾1superscript𝛾1d\geq\Omega(\gamma^{-1}\log\gamma^{-1})italic_d ≥ roman_Ω ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) 2. C𝐶Citalic_C is a Clifford-Magic, Conjugated Clifford, or IQP+CNOT circuit and d≥Ω⁢(γ−1⁢log⁡n)𝑑Ωsuperscript𝛾1𝑛d\geq\Omega(\gamma^{-1}\log n)italic_d ≥ roman_Ω ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_n ) . Figure 1: Overview of the simulation algorithm. (a) Depolarizing errors are sampled and propagated to the beginning of the circuit. |A⟩ket𝐴\ket{A}| start_ARG italic_A end_ARG ⟩ represents a single-qubit magic-state but can be any single-qubit state. (b) The circuit can now equivalently be represented as one error channel followed by the original noiseless circuit. (c) We prove that this input error channel has the effect of depolarizing many of the input qubits and so it remains to simulate the lightcones of qubits that are not depolarized. When these lightcones intersect they must be simulated together but can otherwise be simulated independently. Any measurements that are not in the lightcone of a depolarized qubit can be simulated by a random coin flip. At a high-level, the algorithm works by first propagating errors to the beginning of the circuit. This reformulates the noisy circuit as one layer of noise followed by the ideal circuit, which is pictured in Fig. 1b. Note that it is especially easy to propagate errors since the circuit is Clifford and the errors are Pauli operators. The focus of much of the technical work is to show that this propagated error channel effectively depolarizes many of the input qubits, which is pictured in Fig. 1c. In the geometrically local case, after a critical depth threshold of O⁢(γ−1⁢log⁡γ−1)𝑂superscript𝛾1superscript𝛾1O(\gamma^{-1}\log\gamma^{-1})italic_O ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ), enough qubits get depolarized that a percolation effect occurs, and one can independently simulate the non-depolarized input qubits with intersecting lightcones. We expect at most O⁢(log⁡n⁢d)𝑂𝑛𝑑O(\log nd)italic_O ( roman_log italic_n italic_d ) non-depolarized qubits to have intersecting lightcones and so at most O⁢(\poly⁢(d)⁢log⁡n⁢d)𝑂\poly𝑑𝑛𝑑O(\poly(d)\log nd)italic_O ( ( italic_d ) roman_log italic_n italic_d ) qubits must be simulated together at once (since geometric locality restricts each lightcone to be of size \poly⁢(d)\poly𝑑\poly(d)( italic_d )). Although this is efficient when d𝑑ditalic_d is constant, we can simulate these lightcones even more efficiently by representing the input in the Pauli basis. This representation is sparse at high depths because many Pauli operators are annihilated by the propagated error channel. In fact, at O⁢(γ−1⁢log⁡n)𝑂superscript𝛾1𝑛O(\gamma^{-1}\log n)italic_O ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_n )-depth the Pauli decomposition is so sparse that it is even efficient to do this simulation on all n𝑛nitalic_n qubits. This is why our algorithm also works when there is all-to-all connectivity and no lightcones, although this requires the larger depth. To prove that this algorithm is efficient, our analysis merges tools from Pauli path enumeration [BMS17, GD18, AGL+23] and techniques from percolation theory [RWL24, Oh24]. Our algorithm has many desirable properties: (1) it does not require assumptions on the output distribution or distribution from which the circuit is sampled. In particular, in contrast to the results of [BMS17, GD18, AGL+23] it does not require that the output distributions have the anticoncentration property (see [HE23] for details on this property). (2) It performs exact sampling with random runtime which is polynomial in expectation (and this can be modified to give the more common approximate sampler with worst-case polynomial runtime). (3) Only the depth threshold but not the runtime depends on the noise strength. Our tools also turn out to be useful for bounding anticoncentration, which may be of independent interest. In fact, we are able to show that any Clifford circuit acting on a random input bit string anticoncentrates in O⁢(γ−1⁢log⁡n)𝑂superscript𝛾1𝑛O(\gamma^{-1}\log n)italic_O ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_n ) depth, which is proved in Appendix D. This additionally implies that noisy Haar random circuits anticoncentrate in O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n )-depth for any architecture, which was only previously known for 1⁢D1𝐷1D1 italic_D and all-to-all connectivity [DHB22, DNS+22]. 1.2 Discussion and Future Work Our work is among the first classical simulatability results for noisy quantum circuits that apply to worst-case circuits, albeit with restrictions on connectivity and gate sets. This is accomplished by removing the need for the anticoncentration property in our analysis. This not only allows for classical simulatability beyond average case, but also shows that our algorithm works even when the circuit output distribution is bounded away from uniform (the distributions we can simulate may be peaked). Peaked circuits have recently been proposed as a potential candidate for quantum advantage [AZ24] and are by definition not amenable to simulation techniques relying on anticoncentration. Our methods do not have the same fundamental restrictions and so it is plausible that similar techniques may be useful in this case 111Note that it is known that constant-depth peaked circuits can be simulated in quasipolynomial time [BGL23] but it is an open question whether they are simulatable at O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n )-depth.. If we consider the weaker task of classically simulating random instead of worst-case Clifford circuits, we conjecture that our critical depth threshold for classical simulatability can be lowered significantly. In particular, one would expect random Clifford circuits to spread noise in a manner that causes a larger fraction of qubits to be effectively depolarized. For example, [QSFK+24] construct a family of noisy random Clifford circuits which converge to the maximally mixed state at O⁢(log⁡log⁡n)𝑂𝑛O(\log\log n)italic_O ( roman_log roman_log italic_n ) depth - that is, all qubits are depolarized at sublogarithmic depth. Since our algorithm becomes efficient at low depths, long before all qubits are depolarized, we anticipate simulatability for random Clifford circuits at much shorter depths than our worst-case bounds suggest. Although our results assume Clifford gates, we believe that this is largely a consequence of the analysis since the underlying properties that make the algorithm work are actually quite broad. Thus, it is hoped that our methods may be applicable to a larger class of worst-case circuits. For instance, one of our key techniques is motivated by the general property of unitarity. By using a careful counting argument in place of assuming anticoncentration as done in prior work [BMS17, GD18, AGL+23] , we are able to tightly upper bound the contributions of high-weight Pauli paths. In this analysis, we use unitarity to argue that not all high-weight Pauli operators can be mapped by the circuit to low-weight operators since this is a strictly smaller space and thus violates unitarity. This suggests that high-weight Pauli operators maintain their approximate weight throughout the circuit and thus are evenly suppressed by errors at various timesteps, which turns out to be crucial for the analysis. Since this is largely a consequence of unitarity, we believe similar arguments may prove fruitful for circuit classes beyond Clifford circuits. Another ingredient in our simulation result that may apply more generally is the existence of a constant depth threshold for noise percolation. In recent prior work, noise percolation was shown to exist in noisy IQP circuits [RWL24] also resulting in classical simulation. For these IQP circuits, the analysis relies on the special property that the noise operators commute with the gate-set, which may give reason to believe that this percolation is unique to IQP circuits. Instead, our result shows that this phenomenon is actually quite general in that it also arises in Clifford circuits. Since noisy Clifford circuits exhibit many general features of noisy quantum dynamics [LCF18, CBQA20, LCF19, GKH+21, NBFG23], this provides evidence that this entanglement breakdown may occur in even broader classes of noisy circuits such as Haar random circuits. This would give a simulatability result that improves the depth restriction of [AGL+23]. Thus, we believe that our algorithm may have broad applications to simulating other circuit classes at constant depth. We also conjecture that the depth threshold for classical simulatability in the geometrically local case corresponds directly to a phase transition in computational complexity. That is, it may be possible to construct hard-to-sample quantum circuits at depths right below the threshold (at least for exact sampling). For example, [RWL24] construct IQP circuits which are hard to sample up until depths that asymptotically match their depth threshold for efficient classical simulatability. We leave it to future work to check whether similar techniques will allow us to prove hardness for noisy geometrically local Clifford-Magic or IQP+CNOT circuits as well. Such results could have important consequences for demonstrating near-term quantum advantage. Our results may also provide avenues to classically simulate real quantum experiments. For example, going beyond geometric locality, can we use percolation to prove a sublogarithmic depth threshold for classical simulatability on partially constrained architectures, such as the hypercube connectivity of [HKB+24]? Note that the IQP+CNOT circuits of [HKB+24] require O⁢(log⁡n)𝑂𝑛O(\log n)italic_O ( roman_log italic_n ) depth. Our algorithm for the all-to-all connectivity case shows that these circuits will be classically simulatable if they are scaled past a O⁢(γ−1⁢log⁡n)𝑂superscript𝛾1𝑛O(\gamma^{-1}\log n)italic_O ( italic_γ start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT roman_log italic_n ) depth (for noise strength γ𝛾\gammaitalic_γ). It would be of practical interest to see if this bound can be improved by considering the locality structure of the hypercube. Similarly, removing the depolarizing noise assumption, it may be possible using our techniques to understand the onset of classical simulatability for more realistic noise models such as non-unital [Got16, FGG+23, MAG+24]? Paper Outline In Section 2 we give the preliminaries and notation. In Section 3 we describe the algorithm. In Section 4, we describe how these results directly apply to IQP+CNOT circuits and to conjugated Clifford circuits."
https://arxiv.org/html/2411.02392v1,One-Way Functions and Polynomial Time Dimension,"This work solves an open problem regarding the rate of time-bounded Kolmogorov complexity and polynomial-time dimension, conditioned on a hardness assumption. Hitchcock and Vinodchandran in 2004 [HV04] show that the polynomial-time dimension of infinite sequences (denoted cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT) defined using betting algorithms called s𝑠sitalic_s-gales, is greater than or equal to the asymptotic lower rate of polynomial-time Kolmogorov complexity (denoted 𝒦polysubscript𝒦poly\mathcal{K}_{\text{poly}}caligraphic_K start_POSTSUBSCRIPT poly end_POSTSUBSCRIPT). They asked ([HV04], see also Stull [Stu20]) whether the converse relationship, cdimP≤𝒦polysubscriptcdimPsubscript𝒦poly{\mathrm{cdim}}_{\mathrm{P}}\leq\mathcal{K}_{\text{poly}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ≤ caligraphic_K start_POSTSUBSCRIPT poly end_POSTSUBSCRIPT also holds. This question has thus far resisted resolution. The corresponding unbounded notions, namely, the constructive dimension and the asymptotic lower rate of unbounded Kolmogorov complexity are equal for every sequence. Analogous notions are equal even at finite-state level [BHV05]. In view of these results, it is reasonable to conjecture that the polynomial-time quantities are identical for every sequence and set of sequences.However, under a plausible assumption which underlies modern cryptography - namely the existence of one-way functions, we refute the conjecture thereby giving a negative answer to the open question posed by Hitchcock and Vinodchandran [HV04] and Stull [Stu20].We show the following, conditioned on the existence of one-way functions:There are sets ℱℱ\mathcal{F}caligraphic_F of infinite sequences whose polytime dimension strictly exceeds 𝒦poly⁢(ℱ)subscript𝒦polyℱ\mathcal{K}_{\text{poly}}(\mathcal{F})caligraphic_K start_POSTSUBSCRIPT poly end_POSTSUBSCRIPT ( caligraphic_F ), that is cdimP⁢(ℱ)>𝒦poly⁢(ℱ)subscriptcdimPℱsubscript𝒦polyℱ{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})>\mathcal{K}_{{\mathrm{poly}}}(% \mathcal{F})roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) > caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ).We establish a stronger version of this result, that there are individual sequences X𝑋Xitalic_X whose poly-time dimension strictly exceeds 𝒦poly⁢(X)subscript𝒦poly𝑋\mathcal{K}_{\text{poly}}(X)caligraphic_K start_POSTSUBSCRIPT poly end_POSTSUBSCRIPT ( italic_X ), that is cdimP⁢(X)>𝒦poly⁢(X)subscriptcdimP𝑋subscript𝒦poly𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)>\mathcal{K}_{{\mathrm{poly}}}(X)roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) > caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ).Further, we show that the gap between these quantities can be made as large as possible (i.e. close to 1).We also establish similar bounds for strong poly-time dimension (denoted cDimPsubscriptcDimP{{\mathrm{cDim}}}_{\mathrm{P}}roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT) versus asymptotic upper Kolmogorov complexity rates (denoted 𝒦polystrsubscriptsuperscript𝒦strpoly\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT).Thus, if one-way functions exist, there are infinite sequences whose prefixes are output by short polynomial time algorithms, but polytime betting algorithms are unable to capitalize on this to succeed over them.Our proof techniques involve explicit constructions by concatenating the outputs of pseudorandom generators to form sequences whose prefixes are output by short polynomial time algorithms, but resist betting by polytime s𝑠sitalic_s-gales. Our proof uses several new constructions and arguments involving probabilistic tools such as the Borel-Cantelli Lemma and the Kolmogorov inequality for martingales. This work shows that the question of non-robustness of polynomial-time information density notions, which is prima facie different, is intimately related to questions which are of current interest in cryptography and meta-complexity.","1.1 Context and Motivation Problems related to the minimum circuit-size (MCSP) and minimum time-bounded Kolmogorov complexity (MKt⁢PsuperscriptMK𝑡P\mathrm{MK}^{t}\mathrm{P}roman_MK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT roman_P) have been extensively studied in recent years. Kabanets and Cai [KC00] established that if one-way functions exist, then MCSP is NP-hard, using the framework of natural proofs. This result establishes a connection between cryptographic primitives and hardness of decision problems, leading to the establishment of meta-complexity, the study of the complexity of computing various computational complexity measures. By using the notion of average-case meta-complexity, strong converses have been established, which show that average-case hardness, hardness of approximation, or the average-case hardness of “gap” versions of related meta-complexity problems suffice to establish the existence of important cryptographic primitives such as one-way functions, and pseudorandom functions, often yielding explicit constructions [IRS22]. In this work, we initiate another related line of investigation - namely the connection between cryptographic primitives and the robustness of complexity notions of infinite sequences. We provide a negative resolution to an open question by Hitchcock, Vinodchandran and Stull [HV04, HV06, Stu20] by showing that polynomial-time dimension is not robust, assuming the existence of one-way functions. Polynomial-time dimension quantifies the asymptotic rate of information in an infinite sequence of bits. There are several approaches towards defining polynomial time dimension. The first approach analyzes the asymptotic compressibility of the finite prefixes of the given infinite sequence. The polynomial-time bounded Kolmogorov Complexity of a string x𝑥xitalic_x is the length of the shortest program that can output x𝑥xitalic_x in at most polynomial number of time steps. In the compressibility approach, the polynomial time density of information is defined in terms of the polynomial-time bounded Kolmogorov Complexity of the prefixes of the string, denoted 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT. In the predictability approach, polynomial-time dimension, denoted cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT, is defined in terms of polynomial-time betting algorithms called s𝑠sitalic_s-gales, as they attempt to profit by placing successive bets on the bits in the sequence 111The formal equivalence between polynomial time predictors with log-loss functions and polynomial time s𝑠sitalic_s-gales was established by Hitchcock [Hit03b]. The bets placed by the gale on each bit reflects its confidence of prediction on that bit appearing. The unbounded analogue of time-bounded dimension is known to be robust - markedly different approaches to its definition, via predictors, via unbounded time s𝑠sitalic_s-gales, and via unbounded Kolmogorov complexity rates are known to be equivalent [May02] [Lut03a]. At the other extreme, finite-state analogues of these notions are also known to be robust - there are equivalent characterizations of dimension at finite-state level, using diverse characterizations such as block entropy rates, information-lossless finite-state compressors, and finite-state s𝑠sitalic_s-gales ([DLLM04, BHV05]). However, the robustness of dimension at the important “intermediate” resource-bounded level of polynomial time dimension, has been open for a long time. The robustness question is the following: 1. For every infinite sequence X𝑋Xitalic_X, does the polynomial-time dimension of X𝑋Xitalic_X, cdimP⁢(X)subscriptcdimP𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) as measured by s𝑠sitalic_s-gales equal 𝒦poly⁢(X)subscript𝒦poly𝑋\mathcal{K}_{{\mathrm{poly}}}(X)caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X )? 2. For every set ℱℱ\mathcal{F}caligraphic_F of infinite sequences, does the polynomial-time dimension of ℱℱ\mathcal{F}caligraphic_F, cdimP⁢(ℱ)subscriptcdimPℱ{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) equal 𝒦poly⁢(ℱ)subscript𝒦polyℱ\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F )? In other words, if infinitely many prefixes of sequences have short polynomial-time programs, then can polynomial-time s𝑠sitalic_s-gales bet and win on them? Hitchcock and Vinodchandran [HV04] show that the polynomial-dimension of every sequence is at least the asymptotic lower density of the Kolmogorov complexity of its prefixes. Given the evidence of robustness at other levels, and the fact that the inequality holds in one direction, it is natural to conjecture that the opposite inequality holds as well. This would establish the robustness of polynomial time-bounded dimension. Surprisingly, we show that under the plausible assumption that one-way functions exist, the converse inequality does not hold either for sequences or for sets. Thus polynomial time-bounded dimension is non-robust if one-way functions exist. Further, we show that strong polynomial time-bounded dimension is also non-robust. The reason why one-way functions imply non-robustness is quite fundamental. The existence of one-way functions is equivalent to that of pseudorandom generators [HILL99]. This implies the existence of ensembles generated by polynomial time algorithms from short seeds which are, crucially, hard to distinguish from uniform randoms using any probabilistic polynomial time algorithm. The outputs of a pseudorandom generator are highly compressible using its seeds, unlike true randoms. The main insight of our results is that if polynomial-time dimension is robust, then there are predictors, or s𝑠sitalic_s-gales, that succeed on a sequence of pseudorandom generator outputs. We then modify these s𝑠sitalic_s-gales to obtain probabilistic algorithms to distinguish pseudorandom outputs from uniform randoms. Thus robustness of polynomial-time dimension contradicts the existence of one-way functions. The notion of meta-complexity - the complexity of computing various complexity measures - has been shown to have close connections to cryptographic notions. Our work broadens the scope of this connection, showing that other foundational questions in Kolmogorov complexity which seemingly bear only a tangential relation to hardness, also have provably close connections to cryptographic primitives, while showing an unexpected resolution to a long-standing open problem. 1.2 One-way functions, meta-complexity and time bounded Kolmogorov complexity One-way functions [DH76, Gol01, Lev03] are functions on finite strings that are easy to compute but are hard to invert, except possibly on a negligible fraction of the input strings of a given length. The concept of a one-way function is central in cryptography, since the existence of such functions are both necessary and sufficient for the existence of essential cryptographic primitives like pseudorandom generators [HILL99], digital signatures [Rom90], private key encryption [HILL99] [GM84], authentication schemes [FS90] and commitment schemes [Nao91]. In their seminal paper, Håstad, Impagliazzo, Levin and Luby [HILL99] show that one-way functions exist if and only if pseudorandom generators exist (see also [MP23, Gol08, Gol01]). Several recent advancements in meta-complexity reveal intriguing connections between one-way functions and the computational hardness of various problems in complexity. Kabanets and Cai [KC00] showed that if one-way functions exist, then Minimum Circuit Size Problem (MCSP) is NP-hard. Liu and Pass [LP20, LP21] established the first natural computational problem characterizing cryptographic primitives using time bounded Kolmogorov complexity Ktsubscript𝐾𝑡K_{t}italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT. The t𝑡titalic_t-time bounded Kolmogorov complexity Kt⁢(x)subscript𝐾𝑡𝑥K_{t}(x)italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) [Kol65, LV08] of a string x𝑥xitalic_x is the length of the shortest program ΠΠ\Piroman_Π which outputs x𝑥xitalic_x in at most t𝑡titalic_t time steps when fed to a fixed universal Turing machine 𝒰𝒰\mathcal{U}caligraphic_U. In [LP20], Liu and Pass proved that one-way functions exist if and only if the t𝑡titalic_t-time bounded Kolmogorov complexity problem MKt⁢PsuperscriptMK𝑡P\mathrm{MK}^{t}\mathrm{P}roman_MK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT roman_P, is mildly hard on average. In a follow-up work [LP21] they define a problem that is NPNP{\mathrm{NP}}roman_NP-complete under randomized reductions (the t𝑡titalic_t-time bounded conditional Kolmogorov complexity problem McKt⁢PsuperscriptMcK𝑡P\mathrm{McK}^{t}\mathrm{P}roman_McK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT roman_P) whose mild average case hardness is equivalent to existence of one-way functions. Allender, Cheraghchi, Myrisiotis, Tirumala and Volkovich [ACM+21] showed similar results in the setting of KTKT\mathrm{KT}roman_KT complexity. They proved that average case hardness for a polynomial fraction of instances of McKTPMcKTP\mathrm{McKTP}roman_McKTP (an analogue of McKt⁢PsuperscriptMcK𝑡P\mathrm{McK}^{t}\mathrm{P}roman_McK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT roman_P for KTKT\mathrm{KT}roman_KT-complexity) implies the existence of one-way functions. In the converse direction, they showed that if one-way functions exist then McKTPMcKTP\mathrm{McKTP}roman_McKTP is hard-on-average on an exponential fraction of its instances. Considerable research has been devoted to understanding whether fundamental properties of unbounded Kolmogorov complexity survive in the time bounded setting. One of the important properties that was studied in this context is the symmetry of information of Kolmogorov complexity [LV08, SUV22, DH10, Nie09]. Longpré and Mocas [LM93] (also Longpré and Watanabe [LW92]) showed that if one-way functions exist then symmetry of information does not hold for time bounded Kolmogorov complexity. In [Hir22] and [GK22], symmetry of information for polynomial time bounded probabilistic Kolmogorov complexity pKtsuperscriptpK𝑡\mathrm{pK}^{t}roman_pK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT (see [GKLO22, LO22]) was derived from the stronger assumption DistNP⊆AvgBPPDistNPAvgBPP\mathrm{DistNP}\subseteq\mathrm{AvgBPP}roman_DistNP ⊆ roman_AvgBPP. A recent work [HIL+23] gave a complete characterization of one-way functions in terms of the average case failure of symmetry of information (and related properties like the conditional coding theorem) for pKtsuperscriptpK𝑡\mathrm{pK}^{t}roman_pK start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT. Along similar lines, we investigate whether the characterization of constructive dimension in terms of Kolmogorov complexity [Lut03a, May02] survives in the time bounded setting. We show that if one-way functions exist then polynomial time bounded Kolmogorov complexity does not yield a characterization of polynomial time dimension of infinite sequences, thereby refuting an open question posed by Hitchcock and Vinodchandran in [HV04] and by Stull in [Stu20]. In the following sub-section we give an informal account of constructive dimension and its history. 1.3 Constructive Dimension Constructive dimension was introduced by Lutz [Lut03a, Lut03b] as a complexity-theoretic formulation of the classical Hausdorff dimension [Hau19]. It is a quantification of the density of information present in an infinite sequence. Constructive dimension was originally defined in [Lut03a] in terms of unfair betting strategies over infinite sequences called s𝑠sitalic_s-gales. Resource bounded dimension is the analogue of constructive dimension, where a resource bound, either of time or of space used in computation of the betting strategy is imposed. Resource bounded dimension is an effective tool that has yielded several interesting results in the study of complexity classes [Lut03a, AHLM07, HLM05, May08, Stu20]. An important paradigm that is useful in the study of constructive dimension and measure is that of compressibility [DH10, Nie09]. Lutz [Lut03b] and Mayordomo [May02] gave an equivalent characterization of constructive dimension of infinite sequences in terms of the Kolmogorov complexity of its prefixes. These equivalent characterizations offer multiple viewpoints that are useful under different contexts for studying constructive dimension. Furthermore, these characterizations establish the robustness of constructive dimension as a mathematical concept. One of our main results is that if one-way functions exist, then these characterizations of polynomial time dimension- one in terms of polynomial-time computable s𝑠sitalic_s-gales and the other in terms of density of polynomial-time bounded Kolmogorov complexity are not equivalent. We now give an informal account of the definition of constructive dimension using s𝑠sitalic_s-gales from [Lut03a]. s𝑠sitalic_s-gales are betting strategies on infinite sequences. The betting game on an infinite binary sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT can be understood as follows. The player starts with an initial capital of d⁢(λ)=1𝑑𝜆1d(\lambda)=1italic_d ( italic_λ ) = 1 on the empty string. Here d𝑑ditalic_d is the betting function (capital) of the s𝑠sitalic_s-gale. At the n𝑛nitalic_nth stage, having accumulated a capital d⁢(x1⁢x2⁢…⁢xn)𝑑subscript𝑥1subscript𝑥2…subscript𝑥𝑛d(x_{1}x_{2}\dots x_{n})italic_d ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT … italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) on the first n𝑛nitalic_n bits of the sequence, the player is allowed to place an amount as a “bet” on the next bit xn+1subscript𝑥𝑛1x_{n+1}italic_x start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT of the sequence. The rule of the game is that the expected value of capital received by the player after the bet is 2ssuperscript2𝑠2^{s}2 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT times the capital they started with, that is 2s.d⁢(w)=d⁢(w⁢0)+d⁢(w⁢1)formulae-sequencesuperscript2𝑠𝑑𝑤𝑑𝑤0𝑑𝑤12^{s}.d(w)=d(w0)+d(w1)2 start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT . italic_d ( italic_w ) = italic_d ( italic_w 0 ) + italic_d ( italic_w 1 ), for any finite string w∈Σ∗𝑤superscriptΣw\in\Sigma^{*}italic_w ∈ roman_Σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT. The player d𝑑ditalic_d succeeds on the sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT if they can secure an arbitrary amount of capital over the course of betting on the infinite sequence, more precisely if lim supn→∞d⁢(x1⁢x2⁢…⁢xn)=∞subscriptlimit-supremum→𝑛𝑑subscript𝑥1subscript𝑥2…subscript𝑥𝑛\limsup_{n\to\infty}d(x_{1}x_{2}\dots x_{n})=\inftylim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_d ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT … italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = ∞. When s=1𝑠1s=1italic_s = 1, the average capital after the bet on w⁢0𝑤0w0italic_w 0 or w⁢1𝑤1w1italic_w 1 is equal to the previous capital d⁢(w)𝑑𝑤d(w)italic_d ( italic_w ) (when s=1𝑠1s=1italic_s = 1, such s𝑠sitalic_s-gales are referred to as martingales). Therefore, the betting strategy is fair. When s<1𝑠1s<1italic_s < 1, the average capital after the bet is strictly less than the previous capital d⁢(w)𝑑𝑤d(w)italic_d ( italic_w ). Therefore, such betting strategies are inherently unfair to the player. When s=1𝑠1s=1italic_s = 1, the player can bet “evenly” on the next bit if they are unsure. But as s𝑠sitalic_s decreases, the setting becomes more unfavorable and the player needs to bet more aggressively, or “predict” the bits more efficiently to keep increasing their capital. In simple terms, the Constructive Dimension of a set ℱ∈Σ∞ℱsuperscriptΣ\mathcal{F}\in\Sigma^{\infty}caligraphic_F ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is the least value of s𝑠sitalic_s (or the infimum over s𝑠sitalic_s) for which there exists a lower-semi computable s𝑠sitalic_s-gale that can win on all X∈ℱ𝑋ℱX\in\mathcal{F}italic_X ∈ caligraphic_F. Lower semi-computability is a weak notion of computability where the bets of the s𝑠sitalic_s-gale can be computably enumerated from below, with no resource bounds put on the computation. Definition 1 ([Lut03a, Lut03b]). The constructive dimension of ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is defined as cdim⁢(ℱ)=inf{s∣∃ a lower semi-computable ⁢s⁢-gale ⁢d⁢ such that d succeeds on all ⁢X∈ℱ}.cdimℱinfimumconditional-set𝑠 a lower semi-computable 𝑠-gale 𝑑 such that d succeeds on all 𝑋ℱ\mathrm{cdim}(\mathcal{F})=\inf\{s\mid\exists\text{ a lower semi-computable }s% \text{-gale }d\text{ such that d succeeds on all }X\in\mathcal{F}\}.roman_cdim ( caligraphic_F ) = roman_inf { italic_s ∣ ∃ a lower semi-computable italic_s -gale italic_d such that d succeeds on all italic_X ∈ caligraphic_F } . The constructive dimension of an individual sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is defined as cdim⁢(X)=cdim⁢({X})cdim𝑋cdim𝑋\mathrm{cdim}(X)=\mathrm{cdim}(\{X\})roman_cdim ( italic_X ) = roman_cdim ( { italic_X } ). Mayordomo [May02] and Lutz [Lut03b] showed that constructive dimension of X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT has an equivalent characterization in terms of the rate of information of the prefixes of X𝑋Xitalic_X. The Kolmogorov Complexity of a finite string x𝑥xitalic_x, denoted by K⁢(x)𝐾𝑥K(x)italic_K ( italic_x ), is the length of the shortest program that produces the string as the output. Any string x𝑥xitalic_x can be produced by a program that trivially outputs the string x𝑥xitalic_x, and therefore the Kolmogorov complexity of a string x𝑥xitalic_x is less than or equal to its length, up to an additive constant. However, if the string has lesser amount of information, there may be programs of shorter length that outputs it. For instance, if all the even bits of the string are 00, the program needs to encode only the bits at the odd indices to produce the string. Therefore, its Kolmogorov complexity is at most half its length, up to additive constants. The quantity K⁢(x)/n𝐾𝑥𝑛K(x)/nitalic_K ( italic_x ) / italic_n is the rate of information in a finite string x𝑥xitalic_x. To define rate of information for an infinite string X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, we consider the n𝑛nitalic_n-length prefixes of X𝑋Xitalic_X, denoted X↾n↾𝑋𝑛X\upharpoonright nitalic_X ↾ italic_n, and take the Kolmogorov complexity K⁢(X↾n)𝐾↾𝑋𝑛K(X\upharpoonright n)italic_K ( italic_X ↾ italic_n ). The quantity lim infn→∞K⁢(X↾n)nsubscriptlimit-infimum→𝑛𝐾↾𝑋𝑛𝑛\liminf_{n\rightarrow\infty}\frac{K(X\upharpoonright n)}{n}lim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG denotes the asymptotic lower bound of rate of information over all the finite prefixes of X𝑋Xitalic_X. For a set ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, let 𝒦⁢(ℱ)𝒦ℱ\mathcal{K}(\mathcal{F})caligraphic_K ( caligraphic_F ) denote the supremum of this quantity over all X∈ℱ𝑋ℱX\in\mathcal{F}italic_X ∈ caligraphic_F. Definition 2 ([May02, HV04, HV06]). For any ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, 𝒦⁢(ℱ)=supX∈ℱlim infn→∞K⁢(X↾n)n.𝒦ℱsubscriptsupremum𝑋ℱsubscriptlimit-infimum→𝑛𝐾↾𝑋𝑛𝑛\mathcal{K}(\mathcal{F})=\sup\limits_{X\in\mathcal{F}}\liminf\limits_{n% \rightarrow\infty}\frac{K(X\upharpoonright n)}{n}.caligraphic_K ( caligraphic_F ) = roman_sup start_POSTSUBSCRIPT italic_X ∈ caligraphic_F end_POSTSUBSCRIPT lim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG . Mayordomo [May02] and Lutz [Lut03b] gave the following equivalent characterization of constructive dimension in terms of Kolmogorov complexity. Theorem 1 (Mayordomo [May02] and Lutz [Lut03b]). For every ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, cdim⁢(ℱ)=𝒦⁢(ℱ).cdimℱ𝒦ℱ\mathrm{cdim}(\mathcal{F})=\mathcal{K}(\mathcal{F}).roman_cdim ( caligraphic_F ) = caligraphic_K ( caligraphic_F ) . 1.4 Polynomial-time Dimension Resource bounded dimension is defined by placing resource bounds on the computation of the s𝑠sitalic_s-gale. Analogously, resource bounded Kolmogorov complexity is defined by placing resource bounds on the programs that can print a string. PSPACEPSPACE{\rm PSPACE}roman_PSPACE analogues of cdimcdim\mathrm{cdim}roman_cdim and 𝒦𝒦\mathcal{K}caligraphic_K are defined by restricting the s𝑠sitalic_s-gales in the definition of cdimcdim\mathrm{cdim}roman_cdim to be polynomial space computable and by using polynomial space bounded Kolmogorov complexity in the definition of 𝒦𝒦\mathcal{K}caligraphic_K. Hitchcock and Vinodchandran [HV04, HV06] showed that these notions of resource bounded dimension coincide in the PSPACEPSPACE{\rm PSPACE}roman_PSPACE setting. Theorem 2 ([HV04, HV06]). For every ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, cdimPSPACE⁢(ℱ)=𝒦PSPACE⁢(ℱ)subscriptcdimPSPACEℱsubscript𝒦PSPACEℱ\mathrm{cdim}_{{\rm PSPACE}}(\mathcal{F})=\mathcal{K}_{{\rm PSPACE}}(\mathcal{% F})roman_cdim start_POSTSUBSCRIPT roman_PSPACE end_POSTSUBSCRIPT ( caligraphic_F ) = caligraphic_K start_POSTSUBSCRIPT roman_PSPACE end_POSTSUBSCRIPT ( caligraphic_F ). The Polynomial time dimension quantifies the rate of information in an infinite sequence, measured with respect to polynomial time bounded computation. It is formulated using polynomial time s𝑠sitalic_s-gales. An s𝑠sitalic_s-gale d𝑑ditalic_d wins on an infinite sequence if X𝑋Xitalic_X lim supn→∞d⁢(X↾n)=∞subscriptlimit-supremum→𝑛𝑑↾𝑋𝑛\limsup_{n\to\infty}d(X\upharpoonright n)=\inftylim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_d ( italic_X ↾ italic_n ) = ∞. d𝑑ditalic_d is said to be polynomial-time computable if for some p⁢(n)∈poly⁢(n)𝑝𝑛poly𝑛p(n)\in{\mathrm{poly}}(n)italic_p ( italic_n ) ∈ roman_poly ( italic_n ), d𝑑ditalic_d takes at most p⁢(n)𝑝𝑛p(n)italic_p ( italic_n ) time to compute d⁢(w)𝑑𝑤d(w)italic_d ( italic_w ), where n𝑛nitalic_n is the length of w𝑤witalic_w. Definition 3 (Polynomial-time dimension [Lut03a]). The polynomial-time dimension of ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is defined as cdimP⁢(ℱ)=inf{s∣∃ a polynomial-time ⁢s⁢-gale ⁢d⁢ such that d succeeds on all ⁢X∈ℱ}.subscriptcdimPℱinfimumconditional-set𝑠 a polynomial-time 𝑠-gale 𝑑 such that d succeeds on all 𝑋ℱ\displaystyle{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})=\inf\{s\mid\exists\text% { a polynomial-time }s\text{-gale }d\text{ such that d succeeds on all }X\in% \mathcal{F}\}.roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) = roman_inf { italic_s ∣ ∃ a polynomial-time italic_s -gale italic_d such that d succeeds on all italic_X ∈ caligraphic_F } . For a sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, define cdimP⁢(X)=cdimP⁢({X})subscriptcdimP𝑋subscriptcdimP𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)={\mathrm{cdim}}_{\mathrm{P}}(\{X\})roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( { italic_X } ). That is cdimP⁢(X)subscriptcdimP𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) is the “lowest” s𝑠sitalic_s for which there exists a polynomial time s𝑠sitalic_s-gale d𝑑ditalic_d that succeeds on X𝑋Xitalic_X. On the other hand, we can use time bounded Kolmogorov complexity to define a polynomial time analogue of 𝒦𝒦\mathcal{K}caligraphic_K. The run time of the shortest program of size K⁢(x)𝐾𝑥K(x)italic_K ( italic_x ) that produces a string x𝑥xitalic_x can be very large relative to the length of x𝑥xitalic_x. For a given time bound t⁢(n)𝑡𝑛t(n)italic_t ( italic_n ), the t𝑡titalic_t-time bounded Kolmogorov complexity Kt⁢(x)subscript𝐾𝑡𝑥K_{t}(x)italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_x ) of a string x𝑥xitalic_x is the length of the shortest program that generates x𝑥xitalic_x in at most t⁢(|x|)𝑡𝑥t(\lvert x\rvert)italic_t ( | italic_x | ) time steps (see [LV08]). In this paper we are mostly concerned with the polynomial time bounded Kolmogorov complexity of strings x∈Σ∗𝑥superscriptΣx\in\Sigma^{*}italic_x ∈ roman_Σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT, that is Kp⁢(n)⁢(x)subscript𝐾𝑝𝑛𝑥K_{p(n)}(x)italic_K start_POSTSUBSCRIPT italic_p ( italic_n ) end_POSTSUBSCRIPT ( italic_x ) for some polynomial p𝑝pitalic_p where n𝑛nitalic_n is the length of x𝑥xitalic_x. For a given time bound t⁢(n)𝑡𝑛t(n)italic_t ( italic_n ), the quantity lim infn→∞Kt⁢(X↾n)/nsubscriptlimit-infimum→𝑛subscript𝐾𝑡↾𝑋𝑛𝑛\liminf_{n\rightarrow\infty}K_{t}(X\upharpoonright n)/nlim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) / italic_n gives the t𝑡titalic_t-time bounded rate of information in an infinite string X𝑋Xitalic_X. The polynomial time analogue of 𝒦𝒦\mathcal{K}caligraphic_K (Definition 4) is the infimum of this quantity over all polynomial time bounds t𝑡titalic_t. Definition 4 ([HV04, HV06]). For any ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, 𝒦poly⁢(ℱ)=inft∈polysupX∈ℱlim infn→∞Kt⁢(X↾n)n.subscript𝒦polyℱsubscriptinfimum𝑡polysubscriptsupremum𝑋ℱsubscriptlimit-infimum→𝑛subscript𝐾𝑡↾𝑋𝑛𝑛\displaystyle\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})=\inf\limits_{t\in{% \mathrm{poly}}}\sup\limits_{X\in\mathcal{F}}\liminf\limits_{n\rightarrow\infty% }\frac{K_{t}(X\upharpoonright n)}{n}.caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) = roman_inf start_POSTSUBSCRIPT italic_t ∈ roman_poly end_POSTSUBSCRIPT roman_sup start_POSTSUBSCRIPT italic_X ∈ caligraphic_F end_POSTSUBSCRIPT lim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG . This leads to the question: Are the notions of polynomial time dimension formulated using s𝑠sitalic_s-gales (cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT) and time bounded Kolmogorov complexity (𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT) equivalent?. Hitchcock and Vinodchandran [HV06] showed that cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT is always greater than or equal to 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT222See Section 8 for alternate proofs of Theorems 3 and 4.. Theorem 3 ([HV04, HV06]). For every ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, 𝒦poly⁢(ℱ)≤cdimP⁢(ℱ)subscript𝒦polyℱsubscriptcdimPℱ\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})\leq{\mathrm{cdim}}_{\mathrm{P}}(% \mathcal{F})caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) ≤ roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ). López and Mayordomo in [LVM05] showed a characterization of polynomial time dimension in terms of compression schemes that do not start from the scratch. But the question whether the above notions of polynomial time dimensions defined using polynomial time s𝑠sitalic_s-gales and polynomial time bounded Kolmogorov complexity are equivalent remained elusive. Hitchcock and Vinodchandran [HV04, HV06] and later Stull in [Stu20] posed the following open question: Question 1 ([HV04, HV06, Stu20]). Is it true that, for every sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT cdimP⁢(X)=𝒦poly⁢(X)⁢?subscriptcdimP𝑋subscript𝒦poly𝑋?\displaystyle{\mathrm{cdim}}_{\mathrm{P}}(X)=\mathcal{K}_{{\mathrm{poly}}}(X)\;?roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) ? A analogous question can be asked for sets of sequences, ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. Question 2 ([HV04, HV06, Stu20]). Is it true that, for every ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT cdimP⁢(ℱ)=𝒦poly⁢(ℱ)⁢?subscriptcdimPℱsubscript𝒦polyℱ?\displaystyle{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})=\mathcal{K}_{{\mathrm{% poly}}}(\mathcal{F})\;?roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) ? Note that an affirmative answer to Question 2 trivially implies an affirmative answer to Question 1. However, a positive answer to Question 1 does not necessarily imply a positive answer to Question 2. For an arbitrary set ℱℱ\mathcal{F}caligraphic_F, assume that cdimP⁢(X)=𝒦poly⁢(X)subscriptcdimP𝑋subscript𝒦poly𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)=\mathcal{K}_{{\mathrm{poly}}}(X)roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) for every X∈ℱ𝑋ℱX\in\mathcal{F}italic_X ∈ caligraphic_F. Then, for any s>𝒦poly⁢(ℱ)𝑠subscript𝒦polyℱs>\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})italic_s > caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) and X∈ℱ𝑋ℱX\in\mathcal{F}italic_X ∈ caligraphic_F, there exists a polytime s𝑠sitalic_s-gale that wins on the point X𝑋Xitalic_X. However, there need not exist a single s𝑠sitalic_s-gale that wins on every point in ℱℱ\mathcal{F}caligraphic_F. Polynomial-time strong dimension is a dual notion of polynomial time dimension [AHLM07, Stu20]. As in the case of polynomial time dimension, there exist two notions, one defined using s𝑠sitalic_s-gales and the other defined in terms of time bounded Kolmogorov complexity. An s𝑠sitalic_s-gale d𝑑ditalic_d strongly succeeds on an infinite sequence X𝑋Xitalic_X if lim infn→∞d⁢(X1⁢X2⁢…⁢Xn)=∞subscriptlimit-infimum→𝑛𝑑subscript𝑋1subscript𝑋2…subscript𝑋𝑛\liminf\limits_{n\to\infty}d(X_{1}X_{2}\dots X_{n})=\inftylim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_d ( italic_X start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT … italic_X start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = ∞. Definition 5 (Polynomial-time strong dimension [AHLM07, Stu20]). The polynomial-time dimension of ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT is defined as cDimP⁢(ℱ)=inf{s∣∃ a polynomial-time ⁢s⁢-gale ⁢d⁢ such that d strongly succeeds on all ⁢X∈ℱ}.subscriptcDimPℱinfimumconditional-set𝑠 a polynomial-time 𝑠-gale 𝑑 such that d strongly succeeds on all 𝑋ℱ\displaystyle{{\mathrm{cDim}}}_{\mathrm{P}}(\mathcal{F})=\inf\{s\mid\exists% \text{ a polynomial-time }s\text{-gale }d\text{ such that d strongly succeeds % on all }X\in\mathcal{F}\}.roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) = roman_inf { italic_s ∣ ∃ a polynomial-time italic_s -gale italic_d such that d strongly succeeds on all italic_X ∈ caligraphic_F } . For a sequence X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, define cDimP⁢(X)=cDimP⁢({X})subscriptcDimP𝑋subscriptcDimP𝑋{{\mathrm{cDim}}}_{\mathrm{P}}(X)={{\mathrm{cDim}}}_{\mathrm{P}}(\{X\})roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( { italic_X } ). The strong dimension analogue of 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT is defined by replacing the lim inflimit-infimum\liminflim inf in the definition of 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT with lim suplimit-supremum\limsuplim sup. Definition 6 ([HV04, HV06]). For any ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, 𝒦polystr⁢(ℱ)=inft∈polysupX∈ℱlim supn→∞Kt⁢(X↾n)n.subscriptsuperscript𝒦strpolyℱsubscriptinfimum𝑡polysubscriptsupremum𝑋ℱsubscriptlimit-supremum→𝑛subscript𝐾𝑡↾𝑋𝑛𝑛\displaystyle\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}(\mathcal{F})=\inf% \limits_{t\in{\mathrm{poly}}}\sup\limits_{X\in\mathcal{F}}\limsup\limits_{n% \rightarrow\infty}\frac{K_{t}(X\upharpoonright n)}{n}.caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) = roman_inf start_POSTSUBSCRIPT italic_t ∈ roman_poly end_POSTSUBSCRIPT roman_sup start_POSTSUBSCRIPT italic_X ∈ caligraphic_F end_POSTSUBSCRIPT lim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG . Similar to the conclusion of Theorem 3, cDimPsubscriptcDimP{{\mathrm{cDim}}}_{\mathrm{P}}roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT is always greater than or equal to 𝒦polystrsubscriptsuperscript𝒦strpoly\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT. Theorem 4 ([HV04, HV06]). For every ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, 𝒦polystr⁢(ℱ)≤cDimP⁢(ℱ)subscriptsuperscript𝒦strpolyℱsubscriptcDimPℱ\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}(\mathcal{F})\leq{{\mathrm{cDim}}}% _{\mathrm{P}}(\mathcal{F})caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) ≤ roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ). Stull in [Stu20] posed the following question: Are the notions of polynomial time strong dimension formulated using s𝑠sitalic_s-gales (cDimPsubscriptcDimP{{\mathrm{cDim}}}_{\mathrm{P}}roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT) and time bounded Kolmogorov complexity (𝒦polystrsubscriptsuperscript𝒦strpoly\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT) equivalent?. 1.5 Our Results We show that if one-way functions exist then equality does not hold in Question 2. In order to show this, we prove the contrapositive of the statement. Theorem 5. If for all ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, cdimP⁢(ℱ)=𝒦poly⁢(ℱ),subscriptcdimPℱsubscript𝒦polyℱ{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})=\mathcal{K}_{{\mathrm{poly}}}(% \mathcal{F}),roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) , then one-way functions do not exist. We then show the stronger result that if one-way functions exist then Question 1 has a negative answer, by proving the following contrapositive statement. Theorem 6. If for all X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, cdimP⁢(X)=𝒦poly⁢(X),subscriptcdimP𝑋subscript𝒦poly𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)=\mathcal{K}_{{\mathrm{poly}}}(X),roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) , then one-way functions do not exist. Conditioned on the existence of one-way functions, we demonstrate the existence of sets ℱℱ\mathcal{F}caligraphic_F and sequences X𝑋Xitalic_X such that 𝒦poly⁢(ℱ)<cdimP⁢(ℱ)subscript𝒦polyℱsubscriptcdimPℱ\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})<{\mathrm{cdim}}_{\mathrm{P}}(% \mathcal{F})caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ) < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) and 𝒦poly⁢(X)<cdimP⁢(X)subscript𝒦poly𝑋subscriptcdimP𝑋\mathcal{K}_{{\mathrm{poly}}}(X)<{\mathrm{cdim}}_{\mathrm{P}}(X)caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ). In the last section of the paper we demonstrate how the proof of Theorem 6 can be extended to show that if one-way functions exist, then the distance between these quantities can be arbitrarily close to the maximum possible value of 1111. An analogous theorem for sets follows from Theorem 7. Theorem 7. If one-way functions exist then for any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, there exists X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT such that, cdimP⁢(X)−𝒦poly⁢(X)≥1−ϵ.subscriptcdimP𝑋subscript𝒦poly𝑋1italic-ϵ\displaystyle{\mathrm{cdim}}_{\mathrm{P}}(X)-\mathcal{K}_{{\mathrm{poly}}}(X)% \geq 1-\epsilon.roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) - caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) ≥ 1 - italic_ϵ . For polynomial time strong dimension, we show that if one-way functions exist, then there exist sequences for which the gap between 𝒦polystrsubscriptsuperscript𝒦strpoly\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT and cDimPsubscriptcDimP{{\mathrm{cDim}}}_{\mathrm{P}}roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT is arbitrarily close to 1111. An analogous theorem for sets follows from Theorem 8. Theorem 8. If one-way functions exist then for any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, there exists X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT such that, cDimP⁢(X)−𝒦polystr⁢(X)≥1−ϵ.subscriptcDimP𝑋subscriptsuperscript𝒦strpoly𝑋1italic-ϵ\displaystyle{{\mathrm{cDim}}}_{\mathrm{P}}(X)-\mathcal{K}^{\mathrm{str}}_{{% \mathrm{poly}}}(X)\geq 1-\epsilon.roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) - caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) ≥ 1 - italic_ϵ . Therefore, we show that if one-way functions exist, the answers to both parts of Open Question 3.71 from [Stu20] are negative. 1.6 Proof Outline In this section we give an informal account of the proofs of the main results from section 1.5. The full proofs are given in section 4 and Section 5. One-way functions and polynomial time dimension of sets We first show that if one-way functions exist, then there exist sets of sequences ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT such that the cdimP⁢(ℱ)subscriptcdimPℱ{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) is strictly greater than 𝒦poly⁢(ℱ)subscript𝒦polyℱ\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F})caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ). This proves Theorem 5 thereby refuting Question 2. See 5 We start with the assumption that one-way functions exist. This implies the existence of pseudorandom generators {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT mapping strings of length s⁢n𝑠𝑛snitalic_s italic_n to strings of length n𝑛nitalic_n for every s<1𝑠1s<1italic_s < 1. Let t⁢(n)∈poly⁢(n)𝑡𝑛poly𝑛t(n)\in{\mathrm{poly}}(n)italic_t ( italic_n ) ∈ roman_poly ( italic_n ) be the running time complexity of Gnsubscript𝐺𝑛G_{n}italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. To prove Theorem 5, we only need to consider the case when s=2−m𝑠superscript2𝑚s=2^{-m}italic_s = 2 start_POSTSUPERSCRIPT - italic_m end_POSTSUPERSCRIPT for some m>1𝑚1m>1italic_m > 1. Now, we consider the set ℱssubscriptℱ𝑠\mathcal{F}_{s}caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT which consists of all infinite sequences X𝑋Xitalic_X such that Kt⁢(X↾n)≤s⁢nsubscript𝐾𝑡↾𝑋𝑛𝑠𝑛K_{t}(X\upharpoonright n)\leq snitalic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) ≤ italic_s italic_n for infinitely many n𝑛nitalic_n. Here X↾n↾𝑋𝑛X\upharpoonright nitalic_X ↾ italic_n denotes the first n𝑛nitalic_n bits of X𝑋Xitalic_X. Therefore, the limit inferior of density of information Kt⁢(X↾n)/nsubscript𝐾𝑡↾𝑋𝑛𝑛K_{t}(X\upharpoonright n)/nitalic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) / italic_n for any such sequence is less than or equal to s𝑠sitalic_s. It follows from the definition of 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT for sets, that 𝒦poly⁢(ℱs)≤ssubscript𝒦polysubscriptℱ𝑠𝑠\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F}_{s})\leq scaligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) ≤ italic_s. In order to prove Theorem 5, assume the hypothesis that for all ℱ⊆Σ∞ℱsuperscriptΣ\mathcal{F}\subseteq\Sigma^{\infty}caligraphic_F ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, cdimP⁢(ℱ)=𝒦poly⁢(ℱ)subscriptcdimPℱsubscript𝒦polyℱ{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F})=\mathcal{K}_{{\mathrm{poly}}}(% \mathcal{F})roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F ), which in particular implies that cdimP⁢(ℱs)=𝒦poly⁢(ℱs)≤ssubscriptcdimPsubscriptℱ𝑠subscript𝒦polysubscriptℱ𝑠𝑠{\mathrm{cdim}}_{\mathrm{P}}(\mathcal{F}_{s})=\mathcal{K}_{{\mathrm{poly}}}(% \mathcal{F}_{s})\leq sroman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) ≤ italic_s. From this, we show that for every s′∈(s,1/2)superscript𝑠′𝑠12s^{\prime}\in(s,1/2)italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ ( italic_s , 1 / 2 ) such that 2s′superscript2superscript𝑠′2^{s^{\prime}}2 start_POSTSUPERSCRIPT italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT is rational, there exists an exact computable polynomial time s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT that succeeds on all sequences X𝑋Xitalic_X such that Kt⁢(X↾n)≤s⁢nsubscript𝐾𝑡↾𝑋𝑛𝑠𝑛K_{t}(X\upharpoonright n)\leq snitalic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) ≤ italic_s italic_n. In the rest of the proof, we modify this gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and construct a distinguisher algorithm A𝐴Aitalic_A which can distinguish between the outputs of the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT and uniform random strings with non-negligible probability for infinitely many input lengths n𝑛nitalic_n. Now we are faced with a technical hurdle. Pseudorandom generators are defined as mapping between finite strings. On the other hand, polynomial time dimension is defined over infinite sequences. To connect these notions, we first extend the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT to a mapping between infinite sequences, g:Σ∞→Σ∞:𝑔→superscriptΣsuperscriptΣg:\Sigma^{\infty}\to\Sigma^{\infty}italic_g : roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT → roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. The mapping g𝑔gitalic_g is constructed as follows. We first define mappings gksubscript𝑔𝑘g_{k}italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT from ΣksuperscriptΣ𝑘\Sigma^{k}roman_Σ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT to Σ∗superscriptΣ\Sigma^{*}roman_Σ start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT and g𝑔gitalic_g is defined to be the limit of the mappings gksubscript𝑔𝑘g_{k}italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT as k→∞→𝑘k\to\inftyitalic_k → ∞. On an input w∈Σk𝑤superscriptΣ𝑘w\in\Sigma^{k}italic_w ∈ roman_Σ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT, gksubscript𝑔𝑘g_{k}italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT first divides w𝑤witalic_w into blocks xnsubscript𝑥𝑛x_{n}italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of size s⁢.2n𝑠superscript.2𝑛s.2^{n}italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for every n≤log⁡(k/s)𝑛𝑘𝑠n\leq\log(k/s)italic_n ≤ roman_log ( italic_k / italic_s ). Then, for every block xnsubscript𝑥𝑛x_{n}italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT in w𝑤witalic_w, g𝑔gitalic_g applies the function Gnsubscript𝐺𝑛G_{n}italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT to obtain an output block ynsubscript𝑦𝑛y_{n}italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of length 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Now gk⁢(w)subscript𝑔𝑘𝑤g_{k}(w)italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_w ) is defined as the concatenation of blocks ynsubscript𝑦𝑛y_{n}italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT for each n∈ℕ𝑛ℕn\in\mathbb{N}italic_n ∈ blackboard_N. The mappings gksubscript𝑔𝑘g_{k}italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT preserves the prefix ordering among strings (i.e. if w′⊑wsquare-image-of-or-equalssuperscript𝑤′𝑤w^{\prime}\sqsubseteq witalic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ⊑ italic_w then g|w′|⁢(w′)⊑g|w|⁢(w)square-image-of-or-equalssubscript𝑔superscript𝑤′superscript𝑤′subscript𝑔𝑤𝑤g_{\lvert w^{\prime}\rvert}(w^{\prime})\sqsubseteq g_{\lvert w\rvert}(w)italic_g start_POSTSUBSCRIPT | italic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT | end_POSTSUBSCRIPT ( italic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ⊑ italic_g start_POSTSUBSCRIPT | italic_w | end_POSTSUBSCRIPT ( italic_w )). Now, for any X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT we define g⁢(X)=limk→∞gk⁢(X↾k)𝑔𝑋subscript→𝑘subscript𝑔𝑘↾𝑋𝑘g(X)=\lim_{k\to\infty}g_{k}(X\upharpoonright k)italic_g ( italic_X ) = roman_lim start_POSTSUBSCRIPT italic_k → ∞ end_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_X ↾ italic_k ) (see the precise definition in section 3). We abuse the notation and use g𝑔gitalic_g instead of gksubscript𝑔𝑘g_{k}italic_g start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT when the context is clear. Figure 1 gives a detailed illustration of the construction of g𝑔gitalic_g. Figure 1: Illustration of the construction of g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ). The first 2msuperscript2𝑚2^{m}2 start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT bits of the g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ) are 0. Thereafter, for every for every n>m𝑛𝑚n>mitalic_n > italic_m, the block X⁢[s⁢.2n−1,s⁢.2n−1]𝑋𝑠superscript.2𝑛1𝑠superscript.2𝑛1X[s.2^{{n-1}},s.2^{n}-1]italic_X [ italic_s .2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT , italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT - 1 ] is mapped to G2n−1⁢(X⁢[s⁢.2n−1,s⁢.2n−1])subscript𝐺superscript2𝑛1𝑋𝑠superscript.2𝑛1𝑠superscript.2𝑛1G_{2^{n-1}}(X[s.2^{{n-1}},s.2^{n}-1])italic_G start_POSTSUBSCRIPT 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( italic_X [ italic_s .2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT , italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT - 1 ] ) in the output string g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ). Let g⁢(Σ∞)𝑔superscriptΣg(\Sigma^{\infty})italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ) denote the set {g⁢(X):X∈Σ∞}conditional-set𝑔𝑋𝑋superscriptΣ\{g(X):X\in\Sigma^{\infty}\}{ italic_g ( italic_X ) : italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT }. Now we analyze the density of information of the sequences in g⁢(Σ∞)𝑔superscriptΣg(\Sigma^{\infty})italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ). An important observation is that for any y∈Σn𝑦superscriptΣ𝑛y\in\Sigma^{n}italic_y ∈ roman_Σ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT such that y=Gn⁢(x)𝑦subscript𝐺𝑛𝑥y=G_{n}(x)italic_y = italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ), y𝑦yitalic_y has a short description in terms of x𝑥xitalic_x and the description of the algorithm computing the PRG Gnsubscript𝐺𝑛G_{n}italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. Therefore, it follows that Kt⁢(y)≲|x|+O⁢(1)≤s⁢n+O⁢(1)less-than-or-similar-tosubscript𝐾𝑡𝑦𝑥𝑂1𝑠𝑛𝑂1K_{t}(y)\lesssim\lvert x\rvert+O(1)\leq sn+O(1)italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_y ) ≲ | italic_x | + italic_O ( 1 ) ≤ italic_s italic_n + italic_O ( 1 ). Now, if Y=g⁢(X)𝑌𝑔𝑋Y=g(X)italic_Y = italic_g ( italic_X ) for some X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, it follows that the first 2msuperscript2𝑚2^{m}2 start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT bits of Y𝑌Yitalic_Y has a short description in terms of the first s⁢.2m𝑠superscript.2𝑚s.2^{m}italic_s .2 start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT bits of X𝑋Xitalic_X along with the description of the algorithm which computes the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT. Therefore we obtain that for infinitely many n∈ℕ𝑛ℕn\in\mathbb{N}italic_n ∈ blackboard_N, Kt⁢(Y↾2n)≲s⁢.2n+O⁢(1)less-than-or-similar-tosubscript𝐾𝑡↾𝑌superscript2𝑛𝑠superscript.2𝑛𝑂1K_{t}(Y\upharpoonright 2^{n})\lesssim s.2^{n}+O(1)italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) ≲ italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT + italic_O ( 1 ). This implies that lim infn→∞Kt⁢(Y↾n)/n≤ssubscriptlimit-infimum→𝑛subscript𝐾𝑡↾𝑌𝑛𝑛𝑠\liminf_{n\to\infty}K_{t}(Y\upharpoonright n)/n\leq slim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Y ↾ italic_n ) / italic_n ≤ italic_s and hence Y∈ℱs𝑌subscriptℱ𝑠Y\in\mathcal{F}_{s}italic_Y ∈ caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT. Hence, it follows that g⁢(Σ∞)⊆ℱs𝑔superscriptΣsubscriptℱ𝑠g(\Sigma^{\infty})\subseteq\mathcal{F}_{s}italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ) ⊆ caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT. Therefore the s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT succeeds on every sequence in the set g⁢(Σ∞)𝑔superscriptΣg(\Sigma^{\infty})italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ). Using standard techniques on gales, we transform d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT into a polynomial time martingale d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG that gains a significant amount of money over blocks of length 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT for infinitely many n𝑛nitalic_n. More precisely, for some s~∈(2⁢s′,1)~𝑠2superscript𝑠′1\tilde{s}\in(2s^{\prime},1)over~ start_ARG italic_s end_ARG ∈ ( 2 italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , 1 ), for all Y∈g⁢(Σ∞)𝑌𝑔superscriptΣY\in g(\Sigma^{\infty})italic_Y ∈ italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ), there exist infinitely many n𝑛nitalic_n such that d~⁢(Y↾2n+1)>2(1−s~)⁢2n⁢d~⁢(Y↾2n).~𝑑↾𝑌superscript2𝑛1superscript21~𝑠superscript2𝑛~𝑑↾𝑌superscript2𝑛\displaystyle\tilde{d}(Y\upharpoonright 2^{n+1})>2^{(1-\tilde{s})2^{n}}\tilde{% d}(Y\upharpoonright 2^{n}).over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) . (1) We now design a probabilistic distinguisher algorithm A𝐴Aitalic_A that breaks the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT. We describe the behavior of A𝐴Aitalic_A on inputs of length 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Let y𝑦yitalic_y be an input of size 2nsuperscript2𝑛2^{n}2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. The distinguisher randomly chooses s⁢.2n𝑠superscript.2𝑛s.2^{n}italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bits x′superscript𝑥′x^{\prime}italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and takes y′=g⁢(x′)superscript𝑦′𝑔superscript𝑥′y^{\prime}=g(x^{\prime})italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_g ( italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ). Now A𝐴Aitalic_A outputs 1111 if and only if: d~⁢(y′⁢y)>2(1−s~)⁢2n⁢d~⁢(y)~𝑑superscript𝑦′𝑦superscript21~𝑠superscript2𝑛~𝑑𝑦\displaystyle\tilde{d}(y^{\prime}y)>2^{(1-\tilde{s})2^{n}}\tilde{d}(y)over~ start_ARG italic_d end_ARG ( italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT italic_y ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_y ) Otherwise A𝐴Aitalic_A outputs 00. Here A𝐴Aitalic_A evaluates d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG on the string y′⁢ysuperscript𝑦′𝑦y^{\prime}yitalic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT italic_y instead of y⁢y′𝑦superscript𝑦′yy^{\prime}italic_y italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT because the construction of y′⁢ysuperscript𝑦′𝑦y^{\prime}yitalic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT italic_y is consistent with the structure of the mapping g𝑔gitalic_g. Since d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG is polynomial time computable, A𝐴Aitalic_A is a polynomial time algorithm. We have shown that d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG satisfies the condition (1) over Y∈g⁢(Σ∞)𝑌𝑔superscriptΣY\in g(\Sigma^{\infty})italic_Y ∈ italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ) for infinitely many n𝑛nitalic_n. But the fraction of strings of a particular length n𝑛nitalic_n satisfying (1) may in fact be negligible. In order to overcome this difficulty, we use an argument involving the Borel Cantelli Lemma to show that there exist infinitely many n∈ℕ𝑛ℕn\in\mathbb{N}italic_n ∈ blackboard_N, such that over at least a 1/n21superscript𝑛21/n^{2}1 / italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT fraction of strings w∈Σs⁢.2n𝑤superscriptΣ𝑠superscript.2𝑛w\in\Sigma^{s.2^{n}}italic_w ∈ roman_Σ start_POSTSUPERSCRIPT italic_s .2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT, d~(g(w))>2(1−s~)⁢2nd~(g(w)↾2n−1)).\displaystyle\tilde{d}(g(w))>2^{(1-\tilde{s})2^{n}}\tilde{d}(g(w)% \upharpoonright 2^{n-1})).over~ start_ARG italic_d end_ARG ( italic_g ( italic_w ) ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_g ( italic_w ) ↾ 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ) ) . Letting N=2n𝑁superscript2𝑛N=2^{n}italic_N = 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, from the above it follows that for infinitely many N∈ℕ𝑁ℕN\in\mathbb{N}italic_N ∈ blackboard_N, Prx∈Σs.N⁢[A⁢(g⁢(x))=1]≥1N2.subscriptPr𝑥superscriptΣformulae-sequence𝑠𝑁delimited-[]𝐴𝑔𝑥11superscript𝑁2\displaystyle\mathrm{Pr}_{x\in\Sigma^{s.N}}[A(g(x))=1]\geq\frac{1}{N^{2}}.roman_Pr start_POSTSUBSCRIPT italic_x ∈ roman_Σ start_POSTSUPERSCRIPT italic_s . italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_g ( italic_x ) ) = 1 ] ≥ divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG . On the other hand, for uniformly random inputs, the Kolmogorov inequality for martingales implies that the probability that condition (1) holds is exponentially low. For all n∈ℕ𝑛ℕn\in\mathbb{N}italic_n ∈ blackboard_N, taking N=2n𝑁superscript2𝑛N=2^{n}italic_N = 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we have Pry∈ΣN⁢[A⁢(y)=1]<12N.(1−s~).subscriptPr𝑦superscriptΣ𝑁delimited-[]𝐴𝑦11superscript2formulae-sequence𝑁1~𝑠\displaystyle\mathrm{Pr}_{y\in\Sigma^{N}}[A(y)=1]<\frac{1}{2^{N.(1-\tilde{s})}}.roman_Pr start_POSTSUBSCRIPT italic_y ∈ roman_Σ start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_y ) = 1 ] < divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_N . ( 1 - over~ start_ARG italic_s end_ARG ) end_POSTSUPERSCRIPT end_ARG . (2) Therefore there exist infinitely many N∈ℕ𝑁ℕN\in\mathbb{N}italic_N ∈ blackboard_N such that, Prx∈Σs.N⁢[A⁢(g⁢(x))=1]−Pry∈ΣN⁢[A⁢(y)=1]≥1N2−12N.(1−s′)>1NcsubscriptPr𝑥superscriptΣformulae-sequence𝑠𝑁delimited-[]𝐴𝑔𝑥1subscriptPr𝑦superscriptΣ𝑁delimited-[]𝐴𝑦11superscript𝑁21superscript2formulae-sequence𝑁1superscript𝑠′1superscript𝑁𝑐\displaystyle\mathrm{Pr}_{x\in\Sigma^{s.N}}[A(g(x))=1]-\mathrm{Pr}_{y\in\Sigma% ^{N}}[A(y)=1]\geq\frac{1}{N^{2}}-\frac{1}{2^{N.(1-s^{\prime})}}>\frac{1}{N^{c}}roman_Pr start_POSTSUBSCRIPT italic_x ∈ roman_Σ start_POSTSUPERSCRIPT italic_s . italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_g ( italic_x ) ) = 1 ] - roman_Pr start_POSTSUBSCRIPT italic_y ∈ roman_Σ start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_y ) = 1 ] ≥ divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG - divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_N . ( 1 - italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT end_ARG > divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT end_ARG (3) for some large enough c>0𝑐0c>0italic_c > 0. Therefore the algorithm A𝐴Aitalic_A is a distinguisher for the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT. Thus, we obtain a contradiction. Therefore, under the assumption that one-way functions exist, it must be the case that 𝒦poly⁢(ℱs)<cdimP⁢(ℱs)subscript𝒦polysubscriptℱ𝑠subscriptcdimPsubscriptℱ𝑠\mathcal{K}_{{\mathrm{poly}}}(\mathcal{F}_{s})<{\mathrm{cdim}}_{\mathrm{P}}(% \mathcal{F}_{s})caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( caligraphic_F start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ) which proves Theorem 5. Figure 2 gives an illustration of the implications used in the proof of Theorem 5. Figure 2: Block diagram illustrating outline of proof of Theorem 5. One-way functions and polynomial time dimension of sequences We show the stronger claim that if one-way functions exist, then cdimP⁢(X)=𝒦poly⁢(X)subscriptcdimP𝑋subscript𝒦poly𝑋{\mathrm{cdim}}_{\mathrm{P}}(X)=\mathcal{K}_{{\mathrm{poly}}}(X)roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) = caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) does not hold for all sequences X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. See 6 We start with the assumption that one-way functions exist. This implies the existence of pseudorandom generators {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT mapping strings of length s⁢n𝑠𝑛snitalic_s italic_n to strings of length n𝑛nitalic_n for every s<1𝑠1s<1italic_s < 1. Let t⁢(n)∈poly⁢(n)𝑡𝑛poly𝑛t(n)\in{\mathrm{poly}}(n)italic_t ( italic_n ) ∈ roman_poly ( italic_n ) be the running time of Gnsubscript𝐺𝑛G_{n}italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT. To prove Theorem 6, we only need to consider the case when s=2−m𝑠superscript2𝑚s=2^{-m}italic_s = 2 start_POSTSUPERSCRIPT - italic_m end_POSTSUPERSCRIPT for some m>1𝑚1m>1italic_m > 1. Many elements in the proof of Theorem 6 are similar to those in the proof of Theorem 5. Consider the mapping g𝑔gitalic_g from the proof of Theorem 5. From section 1.6, we obtain that lim infn→∞Kt⁢(Y↾n)/n≤ssubscriptlimit-infimum→𝑛subscript𝐾𝑡↾𝑌𝑛𝑛𝑠\liminf_{n\to\infty}K_{t}(Y\upharpoonright n)/n\leq slim inf start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Y ↾ italic_n ) / italic_n ≤ italic_s for every Y∈g⁢(Σ∞)𝑌𝑔superscriptΣY\in g(\Sigma^{\infty})italic_Y ∈ italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ). By the assumption, for any X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT and s′>ssuperscript𝑠′𝑠s^{\prime}>sitalic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT > italic_s, there is a polynomial time computable s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale dX′subscriptsuperscript𝑑′𝑋d^{\prime}_{X}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT that succeeds on g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ). The major technical obstacle here is that we do not have a single s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT that succeeds on g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ) for all X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT. We overcome this difficulty using a gale combination technique we construct a single polynomial time s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT that succeeds on g⁢(X)𝑔𝑋g(X)italic_g ( italic_X ) for every X∈𝒮𝑋𝒮X\in\mathcal{S}italic_X ∈ caligraphic_S some 𝒮⊆Σ∞𝒮superscriptΣ\mathcal{S}\subseteq\Sigma^{\infty}caligraphic_S ⊆ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT satisfying μ⁢(𝒮)>0𝜇𝒮0\mu(\mathcal{S})>0italic_μ ( caligraphic_S ) > 0. The rest of the proof is similar to that of Theorem 5. We convert the s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT-gale d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT into a polynomial time martingale d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG such that for some s~<1~𝑠1\tilde{s}<1over~ start_ARG italic_s end_ARG < 1 and every Y𝑌Yitalic_Y in g⁢(𝒮)𝑔𝒮g(\mathcal{S})italic_g ( caligraphic_S ), there exist infinitely many n≥0𝑛0n\geq 0italic_n ≥ 0 such that d~⁢(Y↾2n+1)>2(1−s~)⁢2n⁢d~⁢(Y↾2n).~𝑑↾𝑌superscript2𝑛1superscript21~𝑠superscript2𝑛~𝑑↾𝑌superscript2𝑛\displaystyle\tilde{d}(Y\upharpoonright 2^{n+1})>2^{(1-\tilde{s})2^{n}}\tilde{% d}(Y\upharpoonright 2^{n}).over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) . We use the same distinguisher algorithm A𝐴Aitalic_A from section 1.6. The analysis of the algorithm is similar to that in the proof of Theorem 5. Finally, we obtain that there exist infinitely many N∈ℕ𝑁ℕN\in\mathbb{N}italic_N ∈ blackboard_N such that, Prx∈Σs.N⁢[A⁢(g⁢(x))=1]−Pry∈ΣN⁢[A⁢(y)=1]≥1NcsubscriptPr𝑥superscriptΣformulae-sequence𝑠𝑁delimited-[]𝐴𝑔𝑥1subscriptPr𝑦superscriptΣ𝑁delimited-[]𝐴𝑦11superscript𝑁𝑐\displaystyle\mathrm{Pr}_{x\in\Sigma^{s.N}}[A(g(x))=1]-\mathrm{Pr}_{y\in\Sigma% ^{N}}[A(y)=1]\geq\frac{1}{N^{c}}roman_Pr start_POSTSUBSCRIPT italic_x ∈ roman_Σ start_POSTSUPERSCRIPT italic_s . italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_g ( italic_x ) ) = 1 ] - roman_Pr start_POSTSUBSCRIPT italic_y ∈ roman_Σ start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_A ( italic_y ) = 1 ] ≥ divide start_ARG 1 end_ARG start_ARG italic_N start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT end_ARG (4) for some large enough c>0𝑐0c>0italic_c > 0. The algorithm A𝐴Aitalic_A is a distinguisher for the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT. Thus, we obtain a contradiction. Therefore, under the assumption that one-way functions exist, there exists sequences X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT such that 𝒦poly⁢(X)<cdimP⁢(X)subscript𝒦poly𝑋subscriptcdimP𝑋\mathcal{K}_{{\mathrm{poly}}}(X)<{\mathrm{cdim}}_{\mathrm{P}}(X)caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) which proves Theorem 5. Gap between 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT and cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT The techniques in the proof of Theorem 6 yields the following gaps between cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT and 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT. Theorem 9. If one-way functions exist then for any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, there exists X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT such that, cdimP⁢(X)−𝒦poly⁢(X)≥1/2−ϵsubscriptcdimP𝑋subscript𝒦poly𝑋12italic-ϵ{\mathrm{cdim}}_{\mathrm{P}}(X)-\mathcal{K}_{{\mathrm{poly}}}(X)\geq 1/2-\epsilonroman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) - caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) ≥ 1 / 2 - italic_ϵ. In this section, we demonstrate how this gap can be increased to 1−ϵ1italic-ϵ1-\epsilon1 - italic_ϵ for any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0. See 7 Therefore, if one-way functions exist then the gap between Kpolysubscript𝐾polyK_{{\mathrm{poly}}}italic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT dimension and cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT can be as close as required to the maximum gap of 1111. Below we give an outline of the proof of Theorem 7. While constructing the martingale d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG in the proof of Theorem 6, we used the assumption that s′<1/2superscript𝑠′12s^{\prime}<1/2italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT < 1 / 2. This is important because in order to obtain the condition d~⁢(Y↾2n+1)>2(1−s~)⁢2n⁢d~⁢(Y↾2n)~𝑑↾𝑌superscript2𝑛1superscript21~𝑠superscript2𝑛~𝑑↾𝑌superscript2𝑛\tilde{d}(Y\upharpoonright 2^{n+1})>2^{(1-\tilde{s})2^{n}}\tilde{d}(Y% \upharpoonright 2^{n})over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n + 1 end_POSTSUPERSCRIPT ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) for infinitely many n𝑛nitalic_n over any Y∈g⁢(𝒮)𝑌𝑔𝒮Y\in g(\mathcal{S})italic_Y ∈ italic_g ( caligraphic_S ), we require s~>2⁢s′~𝑠2superscript𝑠′\tilde{s}>2s^{\prime}over~ start_ARG italic_s end_ARG > 2 italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT (see Lemma 4 for the formal proof). The major tool we need to overcome this hurdle is a generalization of the construction of martingale d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG to every s′<1superscript𝑠′1s^{\prime}<1italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT < 1 (see Lemma 11). We transform d′superscript𝑑′d^{\prime}italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT into a polynomial time martingale d~~𝑑\tilde{d}over~ start_ARG italic_d end_ARG satisfying the following property: let s~~𝑠\tilde{s}over~ start_ARG italic_s end_ARG and s′′superscript𝑠′′s^{\prime\prime}italic_s start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT be such that s~>s′′>s′~𝑠superscript𝑠′′superscript𝑠′\tilde{s}>s^{\prime\prime}>s^{\prime}over~ start_ARG italic_s end_ARG > italic_s start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT > italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Then for any Y∈g⁢(𝒮)𝑌𝑔𝒮Y\in g(\mathcal{S})italic_Y ∈ italic_g ( caligraphic_S ) there exist infinitely many n𝑛nitalic_n satisfying either of the following conditions: 1. d~⁢(Y↾2n)>2(1−s~)⁢2n−1⁢d~⁢(Y↾2n−1)~𝑑↾𝑌superscript2𝑛superscript21~𝑠superscript2𝑛1~𝑑↾𝑌superscript2𝑛1\tilde{d}(Y\upharpoonright 2^{n})>2^{(1-\tilde{s})2^{n-1}}\tilde{d}(Y% \upharpoonright 2^{n-1})over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) > 2 start_POSTSUPERSCRIPT ( 1 - over~ start_ARG italic_s end_ARG ) 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ). 2. There exists ℓℓ\ellroman_ℓ satisfying ((s~−s′′)/s′′)⋅2n−1≤ℓ≤2n−1⋅~𝑠superscript𝑠′′superscript𝑠′′superscript2𝑛1ℓsuperscript2𝑛1((\tilde{s}-s^{\prime\prime})/s^{\prime\prime})\cdot 2^{n-1}\leq\ell\leq 2^{n-1}( ( over~ start_ARG italic_s end_ARG - italic_s start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT ) / italic_s start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT ) ⋅ 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ≤ roman_ℓ ≤ 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT such that d~⁢(Y↾2n−1+ℓ)>2(1−s′′)⁢(2n−1+ℓ)~𝑑↾𝑌superscript2𝑛1ℓsuperscript21superscript𝑠′′superscript2𝑛1ℓ\tilde{d}(Y\upharpoonright 2^{n-1}+\ell)>2^{(1-s^{\prime\prime})(2^{n-1}+\ell)}over~ start_ARG italic_d end_ARG ( italic_Y ↾ 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT + roman_ℓ ) > 2 start_POSTSUPERSCRIPT ( 1 - italic_s start_POSTSUPERSCRIPT ′ ′ end_POSTSUPERSCRIPT ) ( 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT + roman_ℓ ) end_POSTSUPERSCRIPT. We need the second condition above to handle the case when s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT may be between 1/2121/21 / 2 and 1111. Finally, we modify Algorithm A from the proof of Theorem 6 to incorporate the second condition above. We adapt the analysis of the algorithm and the arguments involving the Borel Cantelli lemma appropriately to show that A𝐴Aitalic_A is a distinguisher for the PRG {Gn}n∈ℕsubscriptsubscript𝐺𝑛𝑛ℕ\{G_{n}\}_{n\in\mathbb{N}}{ italic_G start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n ∈ blackboard_N end_POSTSUBSCRIPT. One way functions and polynomial time strong dimension In this section we show that under the existence of one-way functions, there exist sets for which polynomial time strong dimension defined using s𝑠sitalic_s-gales is strictly greater than the analogous notion defined using time bounded Kolmogorov complexity. These results provide a negative answer to the open question posed by Stull in [Stu20] under the assumption that one-way functions exist. We accomplish this by constructing sets and sequences exhibiting a gap arbitrarily close to 1111 between these quantities. See 8 Below, we give a summary of the proof of Theorem 8. To deal with strong dimension, we require a few new technical tools. First we show the following: if Y=g⁢(X)𝑌𝑔𝑋Y=g(X)italic_Y = italic_g ( italic_X ) for some X∈Σ∞𝑋superscriptΣX\in\Sigma^{\infty}italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT, for every i>0𝑖0i>0italic_i > 0, Kt⁢(Y↾i)≲(2⁢s).i+O⁢(1)formulae-sequenceless-than-or-similar-tosubscript𝐾𝑡↾𝑌𝑖2𝑠𝑖𝑂1K_{t}(Y\upharpoonright i)\lesssim(2s).i+O(1)italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Y ↾ italic_i ) ≲ ( 2 italic_s ) . italic_i + italic_O ( 1 ). This implies that lim supn→∞Kt⁢(Y↾n)/n≤2⁢ssubscriptlimit-supremum→𝑛subscript𝐾𝑡↾𝑌𝑛𝑛2𝑠\limsup_{n\to\infty}K_{t}(Y\upharpoonright n)/n\leq 2slim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_Y ↾ italic_n ) / italic_n ≤ 2 italic_s for every Y∈g⁢(Σ∞)𝑌𝑔superscriptΣY\in g(\Sigma^{\infty})italic_Y ∈ italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ). Let s=2−m𝑠superscript2𝑚s=2^{-m}italic_s = 2 start_POSTSUPERSCRIPT - italic_m end_POSTSUPERSCRIPT for some m>1𝑚1m>1italic_m > 1. We have s<1/2𝑠12s<1/2italic_s < 1 / 2 and therefore 2⁢s<12𝑠12s<12 italic_s < 1. Consider the set ℱ2⁢s′={X∈Σ∞:lim supn→∞Ktg⁢(X↾n)n≤2⁢s}subscriptsuperscriptℱ′2𝑠conditional-set𝑋superscriptΣsubscriptlimit-supremum→𝑛subscript𝐾subscript𝑡𝑔↾𝑋𝑛𝑛2𝑠\mathcal{F}^{\prime}_{2s}=\{X\in\Sigma^{\infty}:\limsup_{n\rightarrow\infty}% \frac{K_{t_{g}}({X}\upharpoonright n)}{n}\leq 2s\}caligraphic_F start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 italic_s end_POSTSUBSCRIPT = { italic_X ∈ roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT : lim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K start_POSTSUBSCRIPT italic_t start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG ≤ 2 italic_s }. From the above observation, it follows that g⁢(Σ∞)⊆ℱ2⁢s′𝑔superscriptΣsubscriptsuperscriptℱ′2𝑠g(\Sigma^{\infty})\subseteq\mathcal{F}^{\prime}_{2s}italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ) ⊆ caligraphic_F start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 italic_s end_POSTSUBSCRIPT. For any X∈ℱ2⁢s′𝑋subscriptsuperscriptℱ′2𝑠X\in\mathcal{F}^{\prime}_{2s}italic_X ∈ caligraphic_F start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 italic_s end_POSTSUBSCRIPT, 𝒦polystr⁢(X)=inft∈p⁢o⁢l⁢ylim supn→∞Kt⁢(X↾n)n≤2⁢s.subscriptsuperscript𝒦strpoly𝑋subscriptinfimum𝑡𝑝𝑜𝑙𝑦subscriptlimit-supremum→𝑛subscript𝐾𝑡↾𝑋𝑛𝑛2𝑠\displaystyle\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}(X)=\inf_{t\in poly}% \limsup_{n\rightarrow\infty}\frac{K_{t}(X\upharpoonright n)}{n}\leq 2s.caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT ( italic_X ) = roman_inf start_POSTSUBSCRIPT italic_t ∈ italic_p italic_o italic_l italic_y end_POSTSUBSCRIPT lim sup start_POSTSUBSCRIPT italic_n → ∞ end_POSTSUBSCRIPT divide start_ARG italic_K start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_X ↾ italic_n ) end_ARG start_ARG italic_n end_ARG ≤ 2 italic_s . We argue that there does exist any s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT satisfying 2⁢s<s′<12𝑠superscript𝑠′12s<s^{\prime}<12 italic_s < italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT < 1 and 2s′∈ℚsuperscript2superscript𝑠′ℚ2^{s^{\prime}}\in\mathbb{Q}2 start_POSTSUPERSCRIPT italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ∈ blackboard_Q such that cdimP⁢(X)<s′subscriptcdimP𝑋superscript𝑠′{\mathrm{cdim}}_{\mathrm{P}}({X})<s^{\prime}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT ( italic_X ) < italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT for every X∈g⁢(Σ∞)𝑋𝑔superscriptΣX\in g(\Sigma^{\infty})italic_X ∈ italic_g ( roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT ). This is accomplished using similar arguments as in the proof of Theorem 6 and Theorem 7. Since s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT need not be below half, the distinguisher algorithm checks the same condition in the proof of Theorem 7. Now, Theorem 8 follows from the observation that by taking m𝑚mitalic_m large enough and choosing an appropriate s′superscript𝑠′s^{\prime}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, the quantity s′−2⁢s=s′−2−m−1superscript𝑠′2𝑠superscript𝑠′superscript2𝑚1s^{\prime}-2s=s^{\prime}-2^{-{m-1}}italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - 2 italic_s = italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - 2 start_POSTSUPERSCRIPT - italic_m - 1 end_POSTSUPERSCRIPT can be made arbitrarily close to 1111. 1.7 Open Problems Our results highlight several potential directions for future research. It is open whether weaker hardness assumptions like P≠NPPNP{\mathrm{P}}\neq{\mathrm{NP}}roman_P ≠ roman_NP, DistNP⊈AvgPnot-subset-of-or-equalsDistNPAvgP\mathrm{DistNP}\not\subseteq\mathrm{AvgP}roman_DistNP ⊈ roman_AvgP and DistNP⊈AvgBPPnot-subset-of-or-equalsDistNPAvgBPP\mathrm{DistNP}\not\subseteq\mathrm{AvgBPP}roman_DistNP ⊈ roman_AvgBPP imply the separation of polynomial time dimension defined using time bounded s𝑠sitalic_s-gales and time bounded Kolmogorov complexity in appropriate settings. The relationship between time bounded symmetry of information, coding theorems and the existence of one-way functions were investigated in several works [LW92, LM93, HIL+23, GKLO22]. The relationships between time bounded dimension relative dimension or mutual dimension [CL18, Stu22, LL18] and existence of cryptographic primitives like one-way functions also remain unexplored. 1.8 Organization of the article The rest of the paper is organized as follows. In section 2, we introduce the basic notation and definitions. In section 3, we give the formal construction of the mapping g:Σ∞→Σ∞:𝑔→superscriptΣsuperscriptΣg:\Sigma^{\infty}\to\Sigma^{\infty}italic_g : roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT → roman_Σ start_POSTSUPERSCRIPT ∞ end_POSTSUPERSCRIPT outlined in the introduction. In section 4, we give a proof of Theorem 5 which proves that if one-way functions exist then there exists subsets of the Cantor space such that 𝒦poly<cdimPsubscript𝒦polysubscriptcdimP\mathcal{K}_{{\mathrm{poly}}}<{\mathrm{cdim}}_{\mathrm{P}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT. In section 5, we give a proof of Theorem 6 which proves that if one-way functions exist then there exists sequences in the Cantor space such that 𝒦poly<cdimPsubscript𝒦polysubscriptcdimP\mathcal{K}_{{\mathrm{poly}}}<{\mathrm{cdim}}_{\mathrm{P}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT < roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT. In section 6, we prove Theorems 11 and 7 thereby establishing optimal gaps between 𝒦polysubscript𝒦poly\mathcal{K}_{{\mathrm{poly}}}caligraphic_K start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT and cdimPsubscriptcdimP{\mathrm{cdim}}_{\mathrm{P}}roman_cdim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT for sets and sequences. In section 7 we establish the non-equivalence of 𝒦polystrsubscriptsuperscript𝒦strpoly\mathcal{K}^{\mathrm{str}}_{{\mathrm{poly}}}caligraphic_K start_POSTSUPERSCRIPT roman_str end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_poly end_POSTSUBSCRIPT and cDimPsubscriptcDimP{{\mathrm{cDim}}}_{\mathrm{P}}roman_cDim start_POSTSUBSCRIPT roman_P end_POSTSUBSCRIPT. In section 8 we give the proofs of certain technical lemmas used in proving the main results."
https://arxiv.org/html/2411.02251v1,Parks: A Doubly Infinite Family of NP-Complete Puzzles and Generalizations of A002464,"The Parks Puzzle is a paper-and-pencil puzzle game that is classically played on a square grid with different colored regions (the parks). The player needs to place a certain number of “trees” in each row, column, and park such that none are adjacent, even diagonally. We define a doubly-infinite family of such puzzles, the (c,r)𝑐𝑟(c,r)( italic_c , italic_r )-tree Parks puzzles, where there need be c𝑐citalic_c trees per column and r𝑟ritalic_r per row. We then prove that for each c𝑐citalic_c and r𝑟ritalic_r the set of (c,r)𝑐𝑟(c,r)( italic_c , italic_r )-tree puzzles is NP-complete. For each c𝑐citalic_c and r𝑟ritalic_r, there is a sequence of possible board sizes m×n𝑚𝑛m\times nitalic_m × italic_n, and the number of possible puzzle solutions for these board sizes is a doubly-infinite generalization of OEIS sequence A002464, which itself describes the case c=r=1𝑐𝑟1c=r=1italic_c = italic_r = 1. This connects the Parks puzzle to chess-based puzzle problems, as the sequence describes the number of ways to place non-attacking kings on a chessboard so that there is exactly one in each column and row (i.e. to place non-attacking dragon kings in shogi). These findings add yet another puzzle to the set of chess puzzles and expands the list of known NP-complete problems described.","The P versus NP problem is a major open problem in computer science, and one of the seven Millennium Problems posed by the Clay Mathematical Institute in the year 2000, with a $1,000,000 prize for a solution. As of this writing, only one of the seven Millennium Problems has been solved [1, 2, 3]. Despite decades of research into computational complexity, the current state of the theoretical understanding leaves much to be desired. For a detailed exposition on the P vs. NP problem itself, as well as its place in computer science research, see [4, 5, 6]. The problem of determining the complexity class of a computational problem is an important aspect of the study of complexity classes, of which P and NP have taken center stage due to the practical outcomes associated with their study. The study of the P and NP complexity classes is a very mature field. The study of puzzles in NP is also quite mature, with several decades worth of work related to identifying NP-complete puzzles, developing strategies for proving reductions, and advancing algorithmic techniques to create practical solvers for these puzzles [7, 8]. A large number of common puzzles such as Minesweeper [9], Sudoku [10], Kakuro [11] and Yosenabe [12] have been proven NP-complete. A relatively large number of lesser known puzzles have also been shown to be NP-complete, such as Light Up, Numberlink, and KPlumber [13]. In 2012, Andrea Sabbatini released a cell phone app called “100 Logic Games - Time Killers” that contains 100 different types of puzzles, most of which have been proven to be NP-complete already: Tents [14], Nurikabe [15], Skyscrapers [16], Battleships [17], Hitori, and Kakuro just to name a few; see [7] for a list of many such and more. Yet the authors are not aware of a rigorous proof of the NP-completeness of the Parks puzzle, at least not in its full generality (the senior thesis of the third author contains a proof in a particular case [18]). The Parks Puzzle is a logic puzzle akin to Sudoku that has not to our knowledge been rigorously shown to be NP-complete, at least not in its full generalization. This puzzle challenges players to determine the placement of a certain number of trees in a grid, adhering to simple rules: place exactly c𝑐citalic_c trees in each column, exactly r𝑟ritalic_r in each row, and exactly r𝑟ritalic_r in each park, making sure no two trees are adjacent, not even diagonally (see Figures 1, 2, 3, and 4; the “parks” are recognized by their own distinct colors). This puzzle is growing in popularity via several mobile apps made by Andrea Sabbatini [19, 20, 21, 22], yet the analysis of its difficulty and fascinating underlying combinatorics remains unstudied. We start by defining the Parks puzzles and giving a few examples in Section II. Notice that in so doing we are presenting a more general version of the puzzle than those in the aforementioned apps111The mobile apps listed above generalize the puzzle a bit less, with (t,t)𝑡𝑡(t,t)( italic_t , italic_t )-tree puzzles where we must place t𝑡titalic_t trees in each column, row, and park.. This generalization presents new possibilities for creating interesting puzzles, and has wider mathematical and computer science implications. Then we review a bit of background on the P vs. NP Millennium Prize Problem and the 3-SAT logic problem; for a thorough understanding of the first problem, we refer the reader to [4] or [5]. Next, we prove Parks is in NP (Section IV), present a proof of the NP-completeness of the (1,1)11(1,1)( 1 , 1 )-tree puzzle in Section V, and finally a proof of the NP-completeness of the general (c,r)𝑐𝑟(c,r)( italic_c , italic_r )-tree puzzle in Section VI. The proofs of Sections V and VI are reductions from 3-SAT. This shows that while the puzzle is easy to describe and every puzzle in the aforementioned mobile apps is solvable without the need for guessing, since there is a unique solution (as claimed in the apps), there is probably222This is assuming P≠N⁢P𝑃𝑁𝑃P\neq NPitalic_P ≠ italic_N italic_P. no algorithm possible for a classical computer that would solve an arbitrary-sized puzzle without essentially some amount of brute-force guessing. Next, we dive into the combinatorics underlying the puzzle, namely the number of puzzles of a given size and the number of possible solutions, primarily focusing on the latter. It turns out that the smallest size (c,r)𝑐𝑟(c,r)( italic_c , italic_r )-tree puzzle is 4⁢c×4⁢r4𝑐4𝑟4c\times 4r4 italic_c × 4 italic_r (Theorem 3), and there are exactly 2 tree configurations possible for that size. Thus, for the construction of non-trivial puzzles it would seem prudent to choose larger puzzles. For any pair of c𝑐citalic_c and r𝑟ritalic_r there is a sequence of relevant board sizes and the number of (c,r)𝑐𝑟(c,r)( italic_c , italic_r )-tree configurations for these board sizes could be a new OEIS sequence, except for the case of c=r=1𝑐𝑟1c=r=1italic_c = italic_r = 1, which is OEIS sequence A002464 and counts the number of tree arrangements for the basic (1,1)11(1,1)( 1 , 1 )-tree puzzle. Thus we relate the ever-developing study of complexity theory to combinatorics in a new way and open the door to interesting combinatorial questions related to a doubly-infinite family of NP-complete puzzles."
https://arxiv.org/html/2411.01630v1,"Optimal Inapproximability of Promise Equationsover Finite Groups††thanks:This work was supported by UKRI EP/X024431/1. For the purpose of Open Access, the authors have applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission. All data is provided in full in the results section of this paper.","A celebrated result of Håstad established that, for any constant ε>0𝜀0\varepsilon>0italic_ε > 0, it is NP-hard to find an assignment satisfying a (1/|𝒢|+ε)1𝒢𝜀(1/|\mathscr{G}|+\varepsilon)( 1 / | script_G | + italic_ε )-fraction of the constraints of a given 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instance over an Abelian group 𝒢𝒢\mathscr{G}script_G even if one is promised that an assignment satisfying a (1−ε)1𝜀(1-\varepsilon)( 1 - italic_ε )-fraction of the constraints exists. Engebretsen, Holmerin, and Russell showed the same result for 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instances over any finite (not necessarily Abelian) group. In other words, for almost-satisfiable instances of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN the random assignment achieves an optimal approximation guarantee. We prove that the random assignment algorithm is still best possible under a stronger promise that the 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instance is almost satisfiable over an arbitrarily more restrictive group.","The PCP theorem [AS98, ALM+98, Din07] is one of the jewels of computational complexity and theoretical computer science more broadly [AB09]. One of its equivalent statements is as follows: The maximum number of simultaneously satisfiable constraints of a Constraint Satisfaction Problem, or CSP for short, is NP-hard to approximate within some constant factor. That is, while NP-hardness of CSPs means that it is NP-hard to distinguish instances that are satisfiable from those that are unsatisfiable, the PCP theorem shows that there is an absolute constant α<1𝛼1\alpha<1italic_α < 1 such that it is NP-hard to distinguish satisfiable CSP instances from those in which strictly fewer than an α𝛼\alphaitalic_α-fraction of the constraints can be simultaneously satisfied. Thus it is NP-hard to find an assignment that satisfies an α𝛼\alphaitalic_α-fraction of the constraints even if one is promised that a satisfying assignment exists. For some CSPs, as we shall see shortly, the optimal value of α𝛼\alphaitalic_α is known. A classic example of a CSP is 3-SAT, the satisfiability problem of CNF-formulas in which each clause contains 3 literals. The random assignment gives a method to find an assignment that satisfies a 7/8787/87 / 8-fraction of the clauses. Håstad famously showed that this is optimal in the following sense: For any constant ε>0𝜀0\varepsilon>0italic_ε > 0, it is NP-hard to find an assignment satisfying a (7/8+ε)78𝜀(7/8+\varepsilon)( 7 / 8 + italic_ε )-fraction of the clauses of a 3-SAT instance even if one is promised that a satisfying assignment exists [Hås01]. Another classic CSP is 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN, the problem of solving linear equations in 3 variables over the Boolean domain {0,1}01\{0,1\}{ 0 , 1 }. If all equations can be satisfied simultaneously then a satisfying assignment can be found in polynomial time by Gaussian elimination. What can be done if no satisfying assignment exists? As for 3-SAT, the random assignment gives a method to find a somewhat satisfying assignment, namely one that satisfies a 1/2121/21 / 2-fraction of the constraints. As it turns out, this is best possible even for instances of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN that are almost satisfiable. In detail, Håstad showed that for any constant ε>0𝜀0\varepsilon>0italic_ε > 0, it is NP-hard to find an assignment satisfying a (1/2+ε)12𝜀(1/2+\varepsilon)( 1 / 2 + italic_ε )-fraction of the constraints of a 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instance even if one is promised that an assignment satisfying a (1−ε)1𝜀(1-\varepsilon)( 1 - italic_ε )-fraction of the constraints exists. In fact, Håstad established optimal inapproximability results for 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over any finite Abelian group, not just {0,1}01\{0,1\}{ 0 , 1 }. This result was later extended by Engebretsen, Holmerin, and Russell to all finite groups [EHR04]. Since these foundational works, Guruswami and Raghavendra [GR09] showed NP-hardness of finding a barely satisfying assignment for a 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instance over the reals (and thus also over the integers) even if a nearly satisfying assignment is promised to exist over the integers. The same result was later established for 2−LIN2LIN\operatorname{2-LIN}2 - roman_LIN for large enough cyclic groups [OWZ15]. Khot and Moshkovitz [KM13] studied inapproximability of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over the reals. In this work, we strengthen the optimal inapproximability results for 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over finite groups by establishing NP-hardness of beating the random assignment threshold even if the instance is almost satisfiable in an arbitrarily more restrictive setting. Formally, this is captured by fixing (not one but) two groups and a homomorphism between them, following the framework of promise CSPs [AGH17, BBKO21]. In detail, (decision) promise CSPs [BBKO21] can be seen as a qualitative form of approximation: Each constraint comes in two forms, a strong one and a weak one. The promise is that there is a solution satisfying all constraints in the strong form while the (potentially easier) goal is to find a solution satisfying all constraints in the weak form. An example of a strong vs. weak constraint on the same, say Boolean, domain is 1111-in-3333 vs NAE, where the former is {(0,0,1),(0,1,0),(1,0,0)}001010100\{(0,0,1),(0,1,0),(1,0,0)\}{ ( 0 , 0 , 1 ) , ( 0 , 1 , 0 ) , ( 1 , 0 , 0 ) } and the latter is {(0,0,1),(0,1,0),(1,0,0),(1,1,0),(1,0,1),(0,1,1)}001010100110101011\{(0,0,1),(0,1,0),(1,0,0),(1,1,0),(1,0,1),(0,1,1)\}{ ( 0 , 0 , 1 ) , ( 0 , 1 , 0 ) , ( 1 , 0 , 0 ) , ( 1 , 1 , 0 ) , ( 1 , 0 , 1 ) , ( 0 , 1 , 1 ) }. NAE is weaker as the relation contains more tuples. While these two constraint relations capture the well-known NP-hard problems of 1-in-3-SAT and Not-All-Equal-SAT respectively [Sch78], finding an NAE-assignment turns out to be doable in polynomial time under the promise that a 1-in-3-assignment exists [BG21]! For constraints on different domains, the notion of strong vs. weak constraint is captured by a homomorphism between the (sets of all) constraint relations; in the example above, the homomorphism is just the identity function. The exact solvability of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN in the promise setting was resolved in [LŽ24]. Recent work of Barto et al. [BBK+24] considered (quantitative) approximation of promise CSPs. In the context of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN, here are two simple examples captured by this framework. First, let 𝒢𝒢\mathscr{G}script_G be a group and ℋℋ\mathscr{H}script_H be a subgroup of 𝒢𝒢\mathscr{G}script_G. Given an almost-satisfiable system over the subgroup ℋℋ\mathscr{H}script_H, maximise the number of satisfied equations over 𝒢𝒢\mathscr{G}script_G. Our results imply that beating the random assignment over ℋℋ\mathscr{H}script_H is NP-hard. In the second example, consider a group 𝒢𝒢\mathscr{G}script_G, a normal subgroup ℋℋ\mathscr{H}script_H, and an almost-satisfiable system over 𝒢𝒢\mathscr{G}script_G. The goal this time is to maximise the number of satisfied equations in the system over the quotient 𝒢/ℋ𝒢ℋ\mathscr{G}/\mathscr{H}script_G / script_H. Our results show that doing better than the random assignment over 𝒢/ℋ𝒢ℋ\mathscr{G}/\mathscr{H}script_G / script_H is NP-hard. More generally, going beyond subgroups and quotients of a given group, we fix two groups 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and a group homomorphism φ𝜑\varphiitalic_φ from a subgroup ℋ1subscriptℋ1\mathscr{H}_{1}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT of 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to a subgroup ℋ2subscriptℋ2\mathscr{H}_{2}script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT with the property that φ𝜑\varphiitalic_φ extend to a group homomorphism from 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Given an almost-satisfiable system of equations over 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT with constants in ℋ1subscriptℋ1\mathscr{H}_{1}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, the goal is to maximise the number of satisfied equations over 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT where the constants are interpreted in ℋ2subscriptℋ2\mathscr{H}_{2}script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT via φ𝜑\varphiitalic_φ. Our main result establishes that doing better than the random assignment over ℋ2subscriptℋ2\mathscr{H}_{2}script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is NP-hard, cf. Theorem 1.3. Thus we give an optimal inapproximability result for a natural and fundamental fragment of promise CSPs, systems of linear equations. The general approach for establishing inapproximability of systems of equations, going back to [Hås01, EHR04], can be seen as a reduction from another CSP that is hard to approximate. In this reduction, one initially transforms an instance of the original CSP to a system of equations of the form x⁢y⁢z=1𝑥𝑦𝑧1xyz=1italic_x italic_y italic_z = 1. To guarantee the soundness of this reduction, one needs to show that any assignment that beats the random assignment in the target system of equations can be transformed into a “good” assignment of the original instance. To do this it is necessary to rule out vacuous assignments (e.g., the assignment that sends all variables to the group identity) through a procedure called folding, which introduces constants in the system of equations. Afterwards, the soundness bounds are shown by performing Fourier analysis on certain functions derived from the system. Our proof follows this general approach. The main obstacle to applying the techniques of [EHR04] directly is the fact that in our setting the constants lie in a proper subgroup of the ambient group, which precludes us from applying classical folding over groups. Instead, we use a weaker notion of folding. This, however, implies that in the soundness analysis we have to take care of functions whose Fourier expansion has non-zero value for the trivial term. To tackle this issue, we consider the behaviour of irreducible group representations when they are restricted to the subgroup of constants via Frobenius Reciprocity. Before formal description of our results, we mention other related work. First, extending the work from [Hås01], Austrin, Brown-Cohen, and Håstad established optimal inapproximability of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over Abelian groups with a universal factor graph [ABCH23]. Similarly, Bhangale and Stankovic established optimal inapproximability of 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over non-Abelian groups with a universal factor graph [BS23]. Second, unlike over Abelian groups, for 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN over non-Abelian groups finding a satisfying assignment is NP-hard even under the promise that one exists. There is a folklore randomised algorithm for satisfiable 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN instances over non-Abelian groups (whose approximation factor depends on the group 𝒢𝒢\mathscr{G}script_G and is 1/|𝒢|1𝒢1/|\mathscr{G}|1 / | script_G | if 𝒢𝒢\mathscr{G}script_G is a so-called perfect group but can beat the naive random assignment for non-perfect groups). Bhangale and Khot showed that this algorithm is optimal [BK21]. Third, going beyond 3−LIN3LIN\operatorname{3-LIN}3 - roman_LIN, building on a long line of work Chan established optimal (up to a constant factor) NP-hardness for CSPs [Cha16]. There are other works on various inapproximability notions for CSPs, e.g., [AH13, KTW14a, KTW14b]. Finally, we mention that Khot’s influential Unique Games Conjecture [Kho02] postulates, in one of its equivalent forms, NP-hardness of finding a barely satisfying solution to a 2−LIN2LIN\operatorname{2-LIN}2 - roman_LIN instance given that an almost-satisfying assignment exists (for a large enough domain size). 1.1 Preliminaries and notation We use ⟦⋅⟧delimited-⟦⟧⋅\llbracket\cdot\rrbracket⟦ ⋅ ⟧ to denote the Iverson bracket; i.e., ⟦P⟧delimited-⟦⟧𝑃\llbracket P\rrbracket⟦ italic_P ⟧ is 1 if P𝑃Pitalic_P is true and 00 otherwise. As usual, [n]delimited-[]𝑛[n][ italic_n ] denotes the set {1,2,…,n}12…𝑛\{1,2,\ldots,n\}{ 1 , 2 , … , italic_n }. We consider matrices whose sets of indices are arbitrary finite sets. Given two finite sets N𝑁Nitalic_N and M𝑀Mitalic_M, an N×M𝑁𝑀N\times Mitalic_N × italic_M complex matrix A𝐴Aitalic_A consists of a family of complex numbers Ai,jsubscript𝐴𝑖𝑗A_{i,j}italic_A start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT indexed by pairs i∈N𝑖𝑁i\in Nitalic_i ∈ italic_N, j∈M𝑗𝑀j\in Mitalic_j ∈ italic_M. Algebraic notions such as matrix product, trace, and transpose are defined in the natural way. Given an N1×N2subscript𝑁1subscript𝑁2N_{1}\times N_{2}italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT complex matrix A𝐴Aitalic_A, and an M1×M2subscript𝑀1subscript𝑀2M_{1}\times M_{2}italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT complex matrix B𝐵Bitalic_B, the tensor product A⊗Btensor-product𝐴𝐵A\otimes Bitalic_A ⊗ italic_B is an (N1×M1)×(N2×M2)subscript𝑁1subscript𝑀1subscript𝑁2subscript𝑀2(N_{1}\times M_{1})\times(N_{2}\times M_{2})( italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) × ( italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT × italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) matrix, where (A⊗B)(i,s)⁢(j,t)=Ai,j⁢Bs,tsubscripttensor-product𝐴𝐵𝑖𝑠𝑗𝑡subscript𝐴𝑖𝑗subscript𝐵𝑠𝑡(A\otimes B)_{(i,s)(j,t)}=A_{i,j}B_{s,t}( italic_A ⊗ italic_B ) start_POSTSUBSCRIPT ( italic_i , italic_s ) ( italic_j , italic_t ) end_POSTSUBSCRIPT = italic_A start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT for each i∈N1,j∈N2,s∈M1,t∈M2formulae-sequence𝑖subscript𝑁1formulae-sequence𝑗subscript𝑁2formulae-sequence𝑠subscript𝑀1𝑡subscript𝑀2i\in N_{1},j\in N_{2},s\in M_{1},t\in M_{2}italic_i ∈ italic_N start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_j ∈ italic_N start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_s ∈ italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_t ∈ italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The group of invertible N×N𝑁𝑁N\times Nitalic_N × italic_N complex matrices (equipped with matrix multiplication and matrix inversion) is denoted by GL⁢(N)GL𝑁\mathrm{GL}(N)roman_GL ( italic_N ), and the set of N×M𝑁𝑀N\times Mitalic_N × italic_M complex matrices is denoted by ℂN×Msuperscriptℂ𝑁𝑀\mathbb{C}^{N\times M}blackboard_C start_POSTSUPERSCRIPT italic_N × italic_M end_POSTSUPERSCRIPT. A subset ℋ⊆𝒢ℋ𝒢\mathscr{H}\subseteq\mathscr{G}script_H ⊆ script_G of a group 𝒢𝒢\mathscr{G}script_G is called a subgroup of 𝒢𝒢\mathscr{G}script_G, denoted by ℋ≤𝒢ℋ𝒢\mathscr{H}\leq\mathscr{G}script_H ≤ script_G, if ℋℋ\mathscr{H}script_H equipped with the group operation of 𝒢𝒢\mathscr{G}script_G forms a group. Given a group 𝒢𝒢\mathscr{G}script_G, a subgroup ℋℋ\mathscr{H}script_H of 𝒢𝒢\mathscr{G}script_G, and an element g∈𝒢𝑔𝒢g\in\mathscr{G}italic_g ∈ script_G, the right coset of ℋℋ\mathscr{H}script_H in 𝒢𝒢\mathscr{G}script_G by g𝑔gitalic_g is the set ℋ⁢g:={h⁢g∣h∈ℋ}assignℋ𝑔conditional-setℎ𝑔ℎℋ\mathscr{H}g:=\{hg\mid h\in\mathscr{H}\}script_H italic_g := { italic_h italic_g ∣ italic_h ∈ script_H }. The set of right cosets of ℋℋ\mathscr{H}script_H in 𝒢𝒢\mathscr{G}script_G is denoted by ℋ\𝒢\ℋ𝒢\mathscr{H}\backslash\mathscr{G}script_H \ script_G. Let N𝑁Nitalic_N be a finite set. The Nthsuperscript𝑁thN^{\text{th}}italic_N start_POSTSUPERSCRIPT th end_POSTSUPERSCRIPT direct power of 𝒢𝒢\mathscr{G}script_G, denoted by 𝒢Nsuperscript𝒢𝑁\mathscr{G}^{N}script_G start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT, is the group whose elements are N𝑁Nitalic_N-tuples 𝐠∈𝒢N𝐠superscript𝒢𝑁\mathbf{g}\in\mathscr{G}^{N}bold_g ∈ script_G start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT of elements from 𝒢𝒢\mathscr{G}script_G, and where the group operation is taken component-wise, i.e., 𝐠⋅𝐡⁢(n)=𝐠⁢(n)⋅𝐡⁢(n)⋅𝐠𝐡𝑛⋅𝐠𝑛𝐡𝑛\mathbf{g}\cdot\mathbf{h}(n)=\mathbf{g}(n)\cdot\mathbf{h}(n)bold_g ⋅ bold_h ( italic_n ) = bold_g ( italic_n ) ⋅ bold_h ( italic_n ) for each n∈N𝑛𝑁n\in Nitalic_n ∈ italic_N. If ℋ≤𝒢ℋ𝒢\mathscr{H}\leq\mathscr{G}script_H ≤ script_G, we define (h⋅𝐠)⁢(n)=h⋅𝐠⁢(n)⋅ℎ𝐠𝑛⋅ℎ𝐠𝑛(h\cdot\mathbf{g})(n)=h\cdot\mathbf{g}(n)( italic_h ⋅ bold_g ) ( italic_n ) = italic_h ⋅ bold_g ( italic_n ) for each h∈ℋℎℋh\in\mathscr{H}italic_h ∈ script_H and 𝐠∈𝒢N𝐠superscript𝒢𝑁\mathbf{g}\in\mathscr{G}^{N}bold_g ∈ script_G start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT. With this notation, the notion of coset extends to include the right cosets of ℋℋ\mathscr{H}script_H in 𝒢Nsuperscript𝒢𝑁\mathscr{G}^{N}script_G start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT in a natural way. A homomorphism from a group 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to a group 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is a map φ:𝒢1→𝒢2:𝜑→subscript𝒢1subscript𝒢2\varphi:\mathscr{G}_{1}\to\mathscr{G}_{2}italic_φ : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT which satisfies that φ⁢(g⋅h)=φ⁢(g)⋅φ⁢(h)𝜑⋅𝑔ℎ⋅𝜑𝑔𝜑ℎ\varphi(g\cdot h)=\varphi(g)\cdot\varphi(h)italic_φ ( italic_g ⋅ italic_h ) = italic_φ ( italic_g ) ⋅ italic_φ ( italic_h ) for every g,h∈𝒢1𝑔ℎsubscript𝒢1g,h\in\mathscr{G}_{1}italic_g , italic_h ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. The domain and image of φ𝜑\varphiitalic_φ are denoted Dom⁢(φ)Dom𝜑\textnormal{Dom}(\varphi)Dom ( italic_φ ) and Im⁢(φ)Im𝜑\textnormal{Im}(\varphi)Im ( italic_φ ) respectively. Let N𝑁Nitalic_N be a finite set, 𝒢isubscript𝒢𝑖\mathscr{G}_{i}script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT groups, i∈[2]𝑖delimited-[]2i\in[2]italic_i ∈ [ 2 ], ℋi≤𝒢isubscriptℋ𝑖subscript𝒢𝑖\mathscr{H}_{i}\leq\mathscr{G}_{i}script_H start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≤ script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, and φ:ℋ1→ℋ2:𝜑→subscriptℋ1subscriptℋ2\varphi:\mathscr{H}_{1}\to\mathscr{H}_{2}italic_φ : script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT → script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT be a homomorphism. We say that a function f:𝒢1N→𝒢2:𝑓→superscriptsubscript𝒢1𝑁subscript𝒢2f:\mathscr{G}_{1}^{N}\to\mathscr{G}_{2}italic_f : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is folded over φ𝜑\varphiitalic_φ if f⁢(h⁢𝐠)=φ⁢(h)⁢f⁢(𝐠)𝑓ℎ𝐠𝜑ℎ𝑓𝐠f(h\mathbf{g})=\varphi(h)f(\mathbf{g})italic_f ( italic_h bold_g ) = italic_φ ( italic_h ) italic_f ( bold_g ) for all h∈ℋ1ℎsubscriptℋ1h\in\mathscr{H}_{1}italic_h ∈ script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝐠∈𝒢1N𝐠superscriptsubscript𝒢1𝑁\mathbf{g}\in\mathscr{G}_{1}^{N}bold_g ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT. Given an arbitrary function f:𝒢1N→𝒢2:𝑓→superscriptsubscript𝒢1𝑁subscript𝒢2f:\mathscr{G}_{1}^{N}\to\mathscr{G}_{2}italic_f : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and a homomorphism between subgroups, there is a natural way to construct a folded function that resembles f𝑓fitalic_f. Fix an arbitrary representative from each right coset of ℋ1subscriptℋ1\mathscr{H}_{1}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT in 𝒢1Nsuperscriptsubscript𝒢1𝑁\mathscr{G}_{1}^{N}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT. For each 𝐠∈𝒢N𝐠superscript𝒢𝑁\mathbf{g}\in\mathscr{G}^{N}bold_g ∈ script_G start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT, denote by 𝐠†superscript𝐠†\mathbf{g}^{\dagger}bold_g start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT the representative of ℋ1⁢𝐠subscriptℋ1𝐠\mathscr{H}_{1}\mathbf{g}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_g, and let h𝐠∈ℋ1subscriptℎ𝐠subscriptℋ1h_{\mathbf{g}}\in\mathscr{H}_{1}italic_h start_POSTSUBSCRIPT bold_g end_POSTSUBSCRIPT ∈ script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT be such that 𝐠†=h𝐠⁢𝐠superscript𝐠†subscriptℎ𝐠𝐠\mathbf{g}^{\dagger}=h_{\mathbf{g}}\mathbf{g}bold_g start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT = italic_h start_POSTSUBSCRIPT bold_g end_POSTSUBSCRIPT bold_g. Then the folding of f𝑓fitalic_f over φ𝜑\varphiitalic_φ (with respect to this choice of representatives) is the map fφ:𝒢1N→𝒢2:subscript𝑓𝜑→superscriptsubscript𝒢1𝑁subscript𝒢2f_{\varphi}:\mathscr{G}_{1}^{N}\to\mathscr{G}_{2}italic_f start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT given by fφ⁢(𝐠)=φ⁢(h𝐠−1)⁢f⁢(𝐠†)subscript𝑓𝜑𝐠𝜑superscriptsubscriptℎ𝐠1𝑓superscript𝐠†f_{\varphi}(\mathbf{g})=\varphi(h_{\mathbf{g}}^{-1})f(\mathbf{g}^{\dagger})italic_f start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT ( bold_g ) = italic_φ ( italic_h start_POSTSUBSCRIPT bold_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) italic_f ( bold_g start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ). Fix a pair of disjoint finite sets D𝐷Ditalic_D, E𝐸Eitalic_E, called the label sets, and a subset Π⊆EDΠsuperscript𝐸𝐷\Pi\subseteq E^{D}roman_Π ⊆ italic_E start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT of labeling functions. An instance of the Label Cover problem is a bipartite graph with vertex set U⊔Vsquare-union𝑈𝑉U\sqcup Vitalic_U ⊔ italic_V and a labeling function πu⁢v∈Πsubscript𝜋𝑢𝑣Π\pi_{uv}\in\Piitalic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ∈ roman_Π for each edge {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v } in the graph. The task is to decide whether there is a pair of assignments hD:U→D:subscriptℎ𝐷→𝑈𝐷h_{D}:U\to Ditalic_h start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT : italic_U → italic_D, hE:V→E:subscriptℎ𝐸→𝑉𝐸h_{E}:V\to Eitalic_h start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT : italic_V → italic_E that satisfies all the constraints, i.e., such that πu⁢v⁢(hD⁢(u))=hE⁢(v)subscript𝜋𝑢𝑣subscriptℎ𝐷𝑢subscriptℎ𝐸𝑣\pi_{uv}(h_{D}(u))=h_{E}(v)italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ( italic_h start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_u ) ) = italic_h start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_v ) for each edge {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v }. Given additionally a pair of rational constants 0<s≤c≤10𝑠𝑐10<s\leq c\leq 10 < italic_s ≤ italic_c ≤ 1, the gap version of this problem, known as the Gap Label Cover problem with completeness c𝑐citalic_c and soundness s𝑠sitalic_s and denoted GLCD,E⁢(c,s)subscriptGLC𝐷𝐸𝑐𝑠\mathrm{GLC}_{D,E}(c,s)roman_GLC start_POSTSUBSCRIPT italic_D , italic_E end_POSTSUBSCRIPT ( italic_c , italic_s ), is the problem of distinguishing instances where a c𝑐citalic_c-fraction of the constraints can be satisfied from instances where not even an s𝑠sitalic_s-fraction of the constraints can be satisfied. The hardness of Gap Label Cover with perfect completeness stated below is a consequence of the PCP theorem [ALM+98, AS98] and the Parallel Repetition Theorem [Raz98]. Theorem 1.1. For every α>0𝛼0\alpha>0italic_α > 0 there exist finite sets D𝐷Ditalic_D, E𝐸Eitalic_E such that GLCD,E⁢(1,α)subscriptGLC𝐷𝐸1𝛼\mathrm{GLC}_{D,E}(1,\alpha)roman_GLC start_POSTSUBSCRIPT italic_D , italic_E end_POSTSUBSCRIPT ( 1 , italic_α ) is NP-hard. Fourier Analysis We follow closely [Ter99] for our main definitions and preliminary results. A representation of a group 𝒢𝒢\mathscr{G}script_G is a group homomorphism γ:𝒢→GL⁢(Nγ):𝛾→𝒢GLsubscript𝑁𝛾\gamma:\mathscr{G}\to\mathrm{GL}(N_{\gamma})italic_γ : script_G → roman_GL ( italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT ) for some finite set Nγsubscript𝑁𝛾N_{\gamma}italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT. We call |Nγ|subscript𝑁𝛾|N_{\gamma}|| italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT | the dimension of γ𝛾\gammaitalic_γ and write dimγ=|Nγ|subscriptdimension𝛾subscript𝑁𝛾\dim_{\gamma}=|N_{\gamma}|roman_dim start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT = | italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT |. Given a pair of indices i,j∈Nγ2𝑖𝑗superscriptsubscript𝑁𝛾2i,j\in N_{\gamma}^{2}italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, γi,jsubscript𝛾𝑖𝑗\gamma_{i,j}italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT denotes the (i,j)𝑖𝑗(i,j)( italic_i , italic_j )-th entry of γ𝛾\gammaitalic_γ. The character of a representation γ𝛾\gammaitalic_γ, denoted by χγsubscript𝜒𝛾\chi_{\gamma}italic_χ start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT, is its trace. The trivial representation, denoted 1111, maps all group elements to the number one (i.e., the one-dimensional identity matrix). A representation γ𝛾\gammaitalic_γ is said to be unitary if its image contains only unitary matrices. We say that two representations α𝛼\alphaitalic_α and β𝛽\betaitalic_β of some group 𝒢𝒢\mathscr{G}script_G are equivalent, written α≃βsimilar-to-or-equals𝛼𝛽\alpha\simeq\betaitalic_α ≃ italic_β, if there is an invertible Nβ×Nαsubscript𝑁𝛽subscript𝑁𝛼N_{\beta}\times N_{\alpha}italic_N start_POSTSUBSCRIPT italic_β end_POSTSUBSCRIPT × italic_N start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT complex matrix T𝑇Titalic_T such that α⁢(g)=T−1⁢β⁢(g)⁢T𝛼𝑔superscript𝑇1𝛽𝑔𝑇\alpha(g)=T^{-1}\beta(g)Titalic_α ( italic_g ) = italic_T start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_β ( italic_g ) italic_T for all g∈𝒢𝑔𝒢g\in\mathscr{G}italic_g ∈ script_G. In particular, dimα=dimβsubscriptdimension𝛼subscriptdimension𝛽\dim_{\alpha}=\dim_{\beta}roman_dim start_POSTSUBSCRIPT italic_α end_POSTSUBSCRIPT = roman_dim start_POSTSUBSCRIPT italic_β end_POSTSUBSCRIPT. Similarly, the representation β𝛽\betaitalic_β is said to be a sub-representation of α𝛼\alphaitalic_α if there is an invertible matrix T𝑇Titalic_T, such that T−1⁢α⁢(g)⁢Tsuperscript𝑇1𝛼𝑔𝑇T^{-1}\alpha(g)Titalic_T start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_α ( italic_g ) italic_T can be written as (β⁢(g)∗0∗)matrix𝛽𝑔0\begin{pmatrix}\beta(g)&*\\ 0&*\end{pmatrix}( start_ARG start_ROW start_CELL italic_β ( italic_g ) end_CELL start_CELL ∗ end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL ∗ end_CELL end_ROW end_ARG ) for all g∈𝒢𝑔𝒢g\in\mathscr{G}italic_g ∈ script_G. The representation β𝛽\betaitalic_β is said to be irreducible if all its sub-representations are equivalent to itself. If β𝛽\betaitalic_β is irreducible, its multiplicity in α𝛼\alphaitalic_α is the non-negative integer n𝑛nitalic_n satisfying that α𝛼\alphaitalic_α is equivalent to a block diagonal representation with two diagonal blocks α1,α2subscript𝛼1subscript𝛼2\alpha_{1},\alpha_{2}italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_α start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, where (1) α1subscript𝛼1\alpha_{1}italic_α start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is another block-diagonal representation consisting of n𝑛nitalic_n diagonal blocks equal to β𝛽\betaitalic_β, and (2) α2subscript𝛼2\alpha_{2}italic_α start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT does not have β𝛽\betaitalic_β as a sub-representation. Given a group 𝒢𝒢\mathscr{G}script_G, we use 𝒢^^𝒢\widehat{\mathscr{G}}over^ start_ARG script_G end_ARG to denote some arbitrary and fixed complete set of inequivalent irreducible unitary representations of 𝒢𝒢\mathscr{G}script_G; such a set exists by, e.g., [Ter99, Proposition 1]. The space ℒ2⁢(𝒢)superscriptℒ2𝒢\mathcal{L}^{2}(\mathscr{G})caligraphic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( script_G ) is the vector space of complex-valued functions over 𝒢𝒢\mathscr{G}script_G, equipped with the following inner product:111Note the additional normalising factor of 1|𝒢|1𝒢\frac{1}{|\mathscr{G}|}divide start_ARG 1 end_ARG start_ARG | script_G | end_ARG compared to [Ter99]. ⟨F,H⟩=1|𝒢|⁢∑g∈𝒢F⁢(g)⁢H⁢(g)¯.𝐹𝐻1𝒢subscript𝑔𝒢𝐹𝑔¯𝐻𝑔\langle F,H\rangle=\frac{1}{|\mathscr{G}|}\sum_{g\in\mathscr{G}}F(g)\overline{% H(g)}.⟨ italic_F , italic_H ⟩ = divide start_ARG 1 end_ARG start_ARG | script_G | end_ARG ∑ start_POSTSUBSCRIPT italic_g ∈ script_G end_POSTSUBSCRIPT italic_F ( italic_g ) over¯ start_ARG italic_H ( italic_g ) end_ARG . Let 𝒢𝒢\mathscr{G}script_G be a group, and let F:𝒢→ℂ:𝐹→𝒢ℂF:\mathscr{G}\rightarrow\mathbb{C}italic_F : script_G → blackboard_C be a complex-valued function. Given γ∈𝒢^𝛾^𝒢\gamma\in\widehat{\mathscr{G}}italic_γ ∈ over^ start_ARG script_G end_ARG and i,j∈Nγ𝑖𝑗subscript𝑁𝛾i,j\in N_{\gamma}italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT, the Fourier coefficient F^⁢(γi,j)^𝐹subscript𝛾𝑖𝑗\widehat{F}(\gamma_{i,j})over^ start_ARG italic_F end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) is defined as the product ⟨F,γi,j⟩𝐹subscript𝛾𝑖𝑗\langle F,\gamma_{i,j}\rangle⟨ italic_F , italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ⟩. The matrix entries of the representations γ∈𝒢^𝛾^𝒢\gamma\in\widehat{\mathscr{G}}italic_γ ∈ over^ start_ARG script_G end_ARG form an orthogonal basis of ℒ2⁢(𝒢)superscriptℒ2𝒢\mathcal{L}^{2}(\mathscr{G})caligraphic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( script_G ), and allow us to perform Fourier analysis on this space, as stated in the following theorem [Ter99, Theorem 2]. Theorem 1.2. Let 𝒢𝒢\mathscr{G}script_G be a finite group. Then the set {γi,j∣γ∈𝒢^,i,j∈Nγ}conditional-setsubscript𝛾𝑖𝑗formulae-sequence𝛾^𝒢𝑖𝑗subscript𝑁𝛾\{\gamma_{i,j}\mid\gamma\in\widehat{\mathscr{G}},\ i,j\in N_{\gamma}\}{ italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ∣ italic_γ ∈ over^ start_ARG script_G end_ARG , italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT } is an orthogonal basis of ℒ2⁢(𝒢)superscriptℒ2𝒢\mathcal{L}^{2}(\mathscr{G})caligraphic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( script_G ), and dimγ∥γi,j∥2=1subscriptdimension𝛾superscriptdelimited-∥∥subscript𝛾𝑖𝑗21\dim_{\gamma}\lVert\gamma_{i,j}\rVert^{2}=1roman_dim start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT ∥ italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 1 for all γi,jsubscript𝛾𝑖𝑗\gamma_{i,j}italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT. Moreover, the following hold: 1. Plancherel’s Theorem: Given F∈ℒ2⁢(𝒢)𝐹superscriptℒ2𝒢F\in\mathcal{L}^{2}(\mathscr{G})italic_F ∈ caligraphic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( script_G ), ∥F∥2=∑γ∈𝒢^,i,j∈Nγdimγ|F^⁢(γi,j)|2.superscriptdelimited-∥∥𝐹2subscriptformulae-sequence𝛾^𝒢𝑖𝑗subscript𝑁𝛾subscriptdimension𝛾superscript^𝐹subscript𝛾𝑖𝑗2\lVert F\rVert^{2}=\sum_{\gamma\in\widehat{\mathscr{G}},i,j\in N_{\gamma}}\dim% _{\gamma}|\widehat{F}(\gamma_{i,j})|^{2}.∥ italic_F ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = ∑ start_POSTSUBSCRIPT italic_γ ∈ over^ start_ARG script_G end_ARG , italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT | over^ start_ARG italic_F end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT . 2. Fourier Inversion: Given F∈ℒ2⁢(𝒢)𝐹superscriptℒ2𝒢F\in\mathcal{L}^{2}(\mathscr{G})italic_F ∈ caligraphic_L start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ( script_G ), F⁢(g)=∑γ∈𝒢^,i,j∈NγdimγF^⁢(γi,j)⁢γi,j⁢(g) for all ⁢g∈𝒢.formulae-sequence𝐹𝑔subscriptformulae-sequence𝛾^𝒢𝑖𝑗subscript𝑁𝛾subscriptdimension𝛾^𝐹subscript𝛾𝑖𝑗subscript𝛾𝑖𝑗𝑔 for all 𝑔𝒢F(g)=\sum_{\gamma\in\widehat{\mathscr{G}},i,j\in N_{\gamma}}\dim_{\gamma}% \widehat{F}(\gamma_{i,j})\gamma_{i,j}(g)\qquad\text{ for all }g\in\mathscr{G}.italic_F ( italic_g ) = ∑ start_POSTSUBSCRIPT italic_γ ∈ over^ start_ARG script_G end_ARG , italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT over^ start_ARG italic_F end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ( italic_g ) for all italic_g ∈ script_G . We also consider Fourier transforms of matrix-valued functions F:𝒢→ℂNF×NF:𝐹→𝒢superscriptℂsubscript𝑁𝐹subscript𝑁𝐹F:\mathscr{G}\rightarrow\mathbb{C}^{N_{F}\times N_{F}}italic_F : script_G → blackboard_C start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT × italic_N start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. Given γ∈𝒢^𝛾^𝒢\gamma\in\widehat{\mathscr{G}}italic_γ ∈ over^ start_ARG script_G end_ARG and indices i,j∈Nγ𝑖𝑗subscript𝑁𝛾i,j\in N_{\gamma}italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_γ end_POSTSUBSCRIPT, we define the NF×NFsubscript𝑁𝐹subscript𝑁𝐹N_{F}\times N_{F}italic_N start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT × italic_N start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT matrix F^⁢(γi,j)^𝐹subscript𝛾𝑖𝑗\widehat{F}(\gamma_{i,j})over^ start_ARG italic_F end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) as the one whose (s,t)𝑠𝑡(s,t)( italic_s , italic_t )-th entry is Fs,t^⁢(γi,j)^subscript𝐹𝑠𝑡subscript𝛾𝑖𝑗\widehat{F_{s,t}}(\gamma_{i,j})over^ start_ARG italic_F start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) for each s,t∈NF𝑠𝑡subscript𝑁𝐹s,t\in N_{F}italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT. In other words, F^⁢(γi,j)=1|𝒢|⁢∑g∈𝒢F⁢(g)⁢γi,j⁢(g)¯.^𝐹subscript𝛾𝑖𝑗1𝒢subscript𝑔𝒢𝐹𝑔¯subscript𝛾𝑖𝑗𝑔\widehat{F}(\gamma_{i,j})=\frac{1}{|\mathscr{G}|}\sum_{g\in\mathscr{G}}F(g)% \overline{\gamma_{i,j}(g)}.over^ start_ARG italic_F end_ARG ( italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) = divide start_ARG 1 end_ARG start_ARG | script_G | end_ARG ∑ start_POSTSUBSCRIPT italic_g ∈ script_G end_POSTSUBSCRIPT italic_F ( italic_g ) over¯ start_ARG italic_γ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ( italic_g ) end_ARG . Let N𝑁Nitalic_N be a finite set. Given a pair of functions function F,H:𝒢→ℂN×N:𝐹𝐻→𝒢superscriptℂ𝑁𝑁F,H:\mathscr{G}\to\mathbb{C}^{N\times N}italic_F , italic_H : script_G → blackboard_C start_POSTSUPERSCRIPT italic_N × italic_N end_POSTSUPERSCRIPT, we define their convolution F∗H𝐹𝐻F*Hitalic_F ∗ italic_H by (F∗H)⁢(g):=1|𝒢|⁢∑h∈𝒢F⁢(h)⁢H⁢(h−1⁢g).assign𝐹𝐻𝑔1𝒢subscriptℎ𝒢𝐹ℎ𝐻superscriptℎ1𝑔(F*H)(g):=\frac{1}{|\mathscr{G}|}\sum_{h\in\mathscr{G}}F(h)H(h^{-1}g).( italic_F ∗ italic_H ) ( italic_g ) := divide start_ARG 1 end_ARG start_ARG | script_G | end_ARG ∑ start_POSTSUBSCRIPT italic_h ∈ script_G end_POSTSUBSCRIPT italic_F ( italic_h ) italic_H ( italic_h start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_g ) . We will also need to perform Fourier analysis over powers of the form 𝒢Dsuperscript𝒢𝐷\mathscr{G}^{D}script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT for a given group 𝒢𝒢\mathscr{G}script_G and finite set D𝐷Ditalic_D. It is possible to identify 𝒢D^^superscript𝒢𝐷\widehat{\mathscr{G}^{D}}over^ start_ARG script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG with (𝒢^)Dsuperscript^𝒢𝐷(\widehat{\mathscr{G}})^{D}( over^ start_ARG script_G end_ARG ) start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT [Ter99]. This way, an element ρ∈𝒢D^𝜌^superscript𝒢𝐷\rho\in\widehat{\mathscr{G}^{D}}italic_ρ ∈ over^ start_ARG script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG is given by a tuple (ρd)d∈Dsubscriptsuperscript𝜌𝑑𝑑𝐷(\rho^{d})_{d\in D}( italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_d ∈ italic_D end_POSTSUBSCRIPT where ρd∈𝒢^superscript𝜌𝑑^𝒢\rho^{d}\in\widehat{\mathscr{G}}italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ∈ over^ start_ARG script_G end_ARG for each d∈D𝑑𝐷d\in Ditalic_d ∈ italic_D in such a way that ρ⁢(𝐠)=⨂d∈Dρd⁢(𝐠⁢(d))𝜌𝐠subscripttensor-product𝑑𝐷superscript𝜌𝑑𝐠𝑑\rho(\mathbf{g})=\bigotimes_{d\in D}\rho^{d}(\mathbf{g}(d))italic_ρ ( bold_g ) = ⨂ start_POSTSUBSCRIPT italic_d ∈ italic_D end_POSTSUBSCRIPT italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ( bold_g ( italic_d ) ) for all 𝐠∈𝒢D𝐠superscript𝒢𝐷\mathbf{g}\in\mathscr{G}^{D}bold_g ∈ script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT. Observe we use superscripts for the “components” of the representation ρ𝜌\rhoitalic_ρ on the power group 𝒢Dsuperscript𝒢𝐷\mathscr{G}^{D}script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT, rather than subscripts, which we utilise to denote matrix entries. The degree of ρ𝜌\rhoitalic_ρ, written |ρ|𝜌|\rho|| italic_ρ |, is the number of indices d∈D𝑑𝐷d\in Ditalic_d ∈ italic_D for which ρdsuperscript𝜌𝑑\rho^{d}italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT is non-trivial.222This quantity is called “weight” in [EHR04, BS23]. 1.2 Results Let 𝒢1,𝒢2subscript𝒢1subscript𝒢2\mathscr{G}_{1},\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT be two groups and φ𝜑\varphiitalic_φ a group homomorphism with domain Dom⁢(φ)≤𝒢1Dom𝜑subscript𝒢1\textnormal{Dom}(\varphi)\leq\mathscr{G}_{1}Dom ( italic_φ ) ≤ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and image Im⁢(φ)≤𝒢2Im𝜑subscript𝒢2\textnormal{Im}(\varphi)\leq\mathscr{G}_{2}Im ( italic_φ ) ≤ script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT that extends to a full homomorphism from 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. We shall refer to triples (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ) of this kind as templates. Further, let 0<s≤c≤10𝑠𝑐10<s\leq c\leq 10 < italic_s ≤ italic_c ≤ 1 be rational constants. We consider the problem 3−LIN⁡(𝒢1,𝒢2,φ,c,s)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑠\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,s)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_s ) which asks, given a weighted system of linear equations with exactly three variables in each equation and constants in Dom⁢(φ)Dom𝜑\textnormal{Dom}(\varphi)Dom ( italic_φ ) that is c𝑐citalic_c-satisfiable in 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, to decide whether there exists an s𝑠sitalic_s-approximation in 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, where the constants are interpreted through φ𝜑\varphiitalic_φ. To be more precise, an instance to 3−LIN⁡(𝒢1,𝒢2,φ,c,s)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑠\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,s)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_s ) over a set of variables X𝑋Xitalic_X is a weighted systems of linear equations where each equation is of the form xi⁢yj⁢zk=gsuperscript𝑥𝑖superscript𝑦𝑗superscript𝑧𝑘𝑔x^{i}y^{j}z^{k}=gitalic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_z start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_g for some x,y,z∈X𝑥𝑦𝑧𝑋x,y,z\in Xitalic_x , italic_y , italic_z ∈ italic_X, g∈Dom⁢(φ)𝑔Dom𝜑g\in\textnormal{Dom}(\varphi)italic_g ∈ Dom ( italic_φ ), i,j,k∈{−1,1}𝑖𝑗𝑘11i,j,k\in\{-1,1\}italic_i , italic_j , italic_k ∈ { - 1 , 1 }, and each equation has a non-negative rational weight. Without loss of generality, we assume that the weights are normalised, i.e., sum up to 1. For t∈[2]𝑡delimited-[]2t\in[2]italic_t ∈ [ 2 ], an assignment f:X→𝒢t:𝑓→𝑋subscript𝒢𝑡f:X\to\mathscr{G}_{t}italic_f : italic_X → script_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT satisfies an equation xi⁢yj⁢zk=gsuperscript𝑥𝑖superscript𝑦𝑗superscript𝑧𝑘𝑔x^{i}y^{j}z^{k}=gitalic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT italic_y start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_z start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_g in 𝒢tsubscript𝒢𝑡\mathscr{G}_{t}script_G start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT if f⁢(x)i⁢f⁢(y)j⁢f⁢(z)k=g𝑓superscript𝑥𝑖𝑓superscript𝑦𝑗𝑓superscript𝑧𝑘𝑔f(x)^{i}f(y)^{j}f(z)^{k}=gitalic_f ( italic_x ) start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT italic_f ( italic_y ) start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_f ( italic_z ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_g for t=1𝑡1t=1italic_t = 1, and f⁢(x)i⁢f⁢(y)j⁢f⁢(z)k=φ⁢(g)𝑓superscript𝑥𝑖𝑓superscript𝑦𝑗𝑓superscript𝑧𝑘𝜑𝑔f(x)^{i}f(y)^{j}f(z)^{k}=\varphi(g)italic_f ( italic_x ) start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT italic_f ( italic_y ) start_POSTSUPERSCRIPT italic_j end_POSTSUPERSCRIPT italic_f ( italic_z ) start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_φ ( italic_g ) for t=2𝑡2t=2italic_t = 2. The task then is to accept if there is an assignment that satisfies a c𝑐citalic_c-fraction (i.e., a fraction of total weight c𝑐citalic_c) of equations in 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and to reject if there is no assignment that satisfies an s𝑠sitalic_s-fraction of the equations in 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. It is easy to verify that, if (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ) is a template and s≤c𝑠𝑐s\leq citalic_s ≤ italic_c, then the sets of accept and reject instances are, in fact, disjoint.3333−LIN3LIN\operatorname{3-LIN}3 - roman_LIN can be alternatively phrased as a promise constraint satisfaction problem, cf. Section 4 for details. 3−LIN⁡(𝒢1,𝒢2,φ,c,s)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑠\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,s)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_s ) is trivially tractable when Im⁢(φ)={1}Im𝜑1\textnormal{Im}(\varphi)=\{1\}Im ( italic_φ ) = { 1 }, so we focus on the case where |Im⁢(φ)|≥2Im𝜑2|\textnormal{Im}(\varphi)|\geq 2| Im ( italic_φ ) | ≥ 2. The main result of this paper is that 3−LIN⁡(𝒢1,𝒢2,φ,1−ϵ,1/|Im⁢(φ)|+δ)3LINsubscript𝒢1subscript𝒢2𝜑1italic-ϵ1Im𝜑𝛿\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,1-\epsilon,1/|% \textnormal{Im}(\varphi)|+\delta)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , 1 - italic_ϵ , 1 / | Im ( italic_φ ) | + italic_δ ) in NP-hard for all ϵ,δ>0italic-ϵ𝛿0\epsilon,\delta>0italic_ϵ , italic_δ > 0 for which the problem is well-defined. This is achieved by a reduction from the Gap Label Cover problem with perfect completeness and soundness α=δ2/(4⁢κ⁢|𝒢1|κ⁢|𝒢2|4)𝛼superscript𝛿24𝜅superscriptsubscript𝒢1𝜅superscriptsubscript𝒢24\alpha=\delta^{2}/(4\kappa|\mathscr{G}_{1}|^{\kappa}|\mathscr{G}_{2}|^{4})italic_α = italic_δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ( 4 italic_κ | script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_κ end_POSTSUPERSCRIPT | script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ), where κ=⌈(log2⁡δ−2)/(log2⁡(1−ϵ))⌉𝜅subscript2𝛿2subscript21italic-ϵ\kappa=\lceil(\log_{2}\delta-2)/(\log_{2}(1-\epsilon))\rceilitalic_κ = ⌈ ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_δ - 2 ) / ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_ϵ ) ) ⌉. Theorem 1.3 (Main). Let ϵ,δitalic-ϵ𝛿\epsilon,\deltaitalic_ϵ , italic_δ be positive constants satisfying 1−ϵ≥1/|Im⁢(φ)|+δ1italic-ϵ1Im𝜑𝛿1-\epsilon\geq 1/|\textnormal{Im}(\varphi)|+\delta1 - italic_ϵ ≥ 1 / | Im ( italic_φ ) | + italic_δ. Then, 3−LIN⁡(𝒢1,𝒢2,φ,1−ϵ,1/|Im⁢(φ)|+δ)3LINsubscript𝒢1subscript𝒢2𝜑1italic-ϵ1Im𝜑𝛿\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,1-\epsilon,1/|% \textnormal{Im}(\varphi)|+\delta)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , 1 - italic_ϵ , 1 / | Im ( italic_φ ) | + italic_δ ) is NP-hard. The hardness result in Theorem 1.3 is tight for many, but perhaps surprisingly not all, templates. We call a template (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ) cubic if for every h∈Im⁢(φ)ℎIm𝜑h\in\textnormal{Im}(\varphi)italic_h ∈ Im ( italic_φ ) there is an element g∈𝒢2𝑔subscript𝒢2g\in\mathscr{G}_{2}italic_g ∈ script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT satisfying g3=hsuperscript𝑔3ℎg^{3}=hitalic_g start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT = italic_h. Theorem 1.3 is tight for cubic templates. Indeed, for these templates, the random assignment over Im⁢(φ)Im𝜑\textnormal{Im}(\varphi)Im ( italic_φ ) achieves a 1/|Im⁢(φ)|1Im𝜑1/|\textnormal{Im}(\varphi)|1 / | Im ( italic_φ ) | expected fraction of satisfied equations (and this can be derandomised, e.g., by the method of conditional expectations). Theorem 1.4. Let (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ) be a cubic template and 0<s≤c<10𝑠𝑐10<s\leq c<10 < italic_s ≤ italic_c < 1. Then, 3−LIN⁡(𝒢1,𝒢2,φ,c,s)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑠\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,s)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_s ) is tractable if s≤1/|Im⁢(φ)|𝑠1Im𝜑s\leq 1/|\textnormal{Im}(\varphi)|italic_s ≤ 1 / | Im ( italic_φ ) | and NP-hard otherwise. Let us now turn to non-cubic templates. An equation is unsatisfiable if it is of the form x3=hsuperscript𝑥3ℎx^{3}=hitalic_x start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT = italic_h or x−3=hsuperscript𝑥3ℎx^{-3}=hitalic_x start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT = italic_h for some h∈Dom⁢(φ)ℎDom𝜑h\in\textnormal{Dom}(\varphi)italic_h ∈ Dom ( italic_φ ) such that g3≠φ⁢(h)superscript𝑔3𝜑ℎg^{3}\neq\varphi(h)italic_g start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ≠ italic_φ ( italic_h ) for all g∈𝒢2𝑔subscript𝒢2g\in\mathscr{G}_{2}italic_g ∈ script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Note that a template has unsatisfiable equations if and only if it is non-cubic. Note that the naive random assignment cannot achieve a positive approximation factor in systems of equations over non-cubic templates since the system could consist exclusively of unsatisfiable equations. However, there is a simple algorithm for 3−LIN⁡(𝒢1,𝒢2,φ,c,c/|Im⁢(φ)|)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑐Im𝜑\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,c/|\textnormal{% Im}(\varphi)|)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_c / | Im ( italic_φ ) | ) that works even for non-cubic templates, which we describe next. Given a weighted system of equations over (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ), consider its set of unsatisfiable equations. Since φ𝜑\varphiitalic_φ extends to a full homomorphism, if the total weight of the set of unsatisfiable equations is more than 1−c1𝑐1-c1 - italic_c, then the instance cannot be c𝑐citalic_c-satisfiable in 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, hence, reject. Otherwise, the random assignment over Im⁢(φ)Im𝜑\textnormal{Im}(\varphi)Im ( italic_φ ) satisfies at least a 1/|Im⁢(φ)|1Im𝜑1/|\textnormal{Im}(\varphi)|1 / | Im ( italic_φ ) |-fraction of the satisfiable equations over 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, which is at least a c/|Im⁢(φ)|𝑐Im𝜑c/|\textnormal{Im}(\varphi)|italic_c / | Im ( italic_φ ) |-fraction of the entire system. It is a simple corollary of Theorem 1.3 that this algorithm is optimal for non-cubic groups, leading to the following result. Details are deferred to Appendix A. Theorem 1.5. Let (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ) be a non-cubic template and 0<s≤c<10𝑠𝑐10<s\leq c<10 < italic_s ≤ italic_c < 1. Then, 3−LIN⁡(𝒢1,𝒢2,φ,c,s)3LINsubscript𝒢1subscript𝒢2𝜑𝑐𝑠\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,c,s)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , italic_c , italic_s ) is tractable if s/c≤1/|Im⁢(φ)|𝑠𝑐1Im𝜑s/c\leq 1/|\textnormal{Im}(\varphi)|italic_s / italic_c ≤ 1 / | Im ( italic_φ ) | and NP-hard otherwise. The structure of the paper is as follows. The rest of this section gives a sketch of the main proof: In Section 1.3 we present the reduction from Gap Label Cover to 3−LIN⁡(𝒢1,𝒢2,φ,1−ϵ,1/|Im⁢(φ)|+δ)3LINsubscript𝒢1subscript𝒢2𝜑1italic-ϵ1Im𝜑𝛿\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,1-\epsilon,1/|% \textnormal{Im}(\varphi)|+\delta)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , 1 - italic_ϵ , 1 / | Im ( italic_φ ) | + italic_δ ), and in Section 1.4 we give an overview of the techniques used in the analysis of this reduction and of the main challenges that arise in extending previous work to the promise setting. The rest of the paper then gives all technical details. In Section 2 we set the notation and present the necessary technical background on Fourier analysis over non-Abelian groups. Section 3 is dedicated to the proof of the main result, with the completeness analysis in Section 3.1 and the soundness analysis in Section 3.2. Finally, in Section 4 we relate our results to a recent theory of Barto et al. [BBK+24], who developed a systematic approach to study (in)approximability of promise CSPs, which includes approximability of promise linear equations, from the viewpoint of universal algebra. In particular, we show that the proof of Theorem 1.3 implies that the collection of symmetries444called the valued minion of plurimorphisms in [BBK+24]. of 3−LIN⁡(𝒢1,𝒢2,φ,1−ϵ,1/|Im⁢(φ)|+δ)3LINsubscript𝒢1subscript𝒢2𝜑1italic-ϵ1Im𝜑𝛿\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},\varphi,1-\epsilon,1/|% \textnormal{Im}(\varphi)|+\delta)start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ , 1 - italic_ϵ , 1 / | Im ( italic_φ ) | + italic_δ ) can be mapped homomorphically to the collection of symmetries of Gap Label Cover, a condition that, based on the algebraic theory from [BBK+24], is known to guarantee NP-hardness of the former problem. 1.3 Reduction For the rest of the section we outline the proof of our main result, Theorem 1.3. From now on we fix a template (𝒢1,𝒢2,φ)subscript𝒢1subscript𝒢2𝜑(\mathscr{G}_{1},\mathscr{G}_{2},\varphi)( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_φ ), and positive constants δ,ϵ>0𝛿italic-ϵ0\delta,\epsilon>0italic_δ , italic_ϵ > 0 with 1/|Im⁢(φ)|+δ≤1−ϵ1Im𝜑𝛿1italic-ϵ1/|\textnormal{Im}(\varphi)|+\delta\leq 1-\epsilon1 / | Im ( italic_φ ) | + italic_δ ≤ 1 - italic_ϵ. We define ℋ1=Dom⁢(φ)≤𝒢1subscriptℋ1Dom𝜑subscript𝒢1\mathscr{H}_{1}=\textnormal{Dom}(\varphi)\leq\mathscr{G}_{1}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = Dom ( italic_φ ) ≤ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and ℋ2=Im⁢(φ)≤𝒢2subscriptℋ2Im𝜑subscript𝒢2\mathscr{H}_{2}=\textnormal{Im}(\varphi)\leq\mathscr{G}_{2}script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = Im ( italic_φ ) ≤ script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Our proof follows from a reduction from GLCD,E⁢(1,α)subscriptGLC𝐷𝐸1𝛼\mathrm{GLC}_{D,E}(1,\alpha)roman_GLC start_POSTSUBSCRIPT italic_D , italic_E end_POSTSUBSCRIPT ( 1 , italic_α ) where α=δ2/(4⁢κ⁢|𝒢1|κ⁢|𝒢2|4)𝛼superscript𝛿24𝜅superscriptsubscript𝒢1𝜅superscriptsubscript𝒢24\alpha=\delta^{2}/(4\kappa|\mathscr{G}_{1}|^{\kappa}|\mathscr{G}_{2}|^{4})italic_α = italic_δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ( 4 italic_κ | script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_κ end_POSTSUPERSCRIPT | script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ), κ=⌈(log2⁡δ−2)/(log2⁡(1−ϵ))⌉𝜅subscript2𝛿2subscript21italic-ϵ\kappa=\lceil(\log_{2}\delta-2)/(\log_{2}(1-\epsilon))\rceilitalic_κ = ⌈ ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_δ - 2 ) / ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_ϵ ) ) ⌉, and D,E𝐷𝐸D,Eitalic_D , italic_E are chosen to be large enough so that GLCD,E⁢(1,α)subscriptGLC𝐷𝐸1𝛼\mathrm{GLC}_{D,E}(1,\alpha)roman_GLC start_POSTSUBSCRIPT italic_D , italic_E end_POSTSUBSCRIPT ( 1 , italic_α ) is NP-hard by the PCP theorem [ALM+98, AS98, Raz98] (cf. Theorem 1.1). This reduction constructs an instance ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT of 3−LIN(𝒢1,𝒢2,\operatorname{3-LIN}(\mathscr{G}_{1},\mathscr{G}_{2},start_OPFUNCTION 3 - roman_LIN end_OPFUNCTION ( script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , φ,1−ϵ,1/|ℋ2|+δ)\varphi,1-\epsilon,1/|\mathscr{H}_{2}|+\delta)italic_φ , 1 - italic_ϵ , 1 / | script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | + italic_δ ) for any given instance ΣΣ\Sigmaroman_Σ of Gap Label Cover as described below. Let U⊔Vsquare-union𝑈𝑉U\sqcup Vitalic_U ⊔ italic_V be the underlying vertex set of ΣΣ\Sigmaroman_Σ, D,E𝐷𝐸D,Eitalic_D , italic_E be the disjoint sets of labels, and πu⁢vsubscript𝜋𝑢𝑣\pi_{uv}italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT be the labeling functions. We fix representatives from each right coset in ℋ1\𝒢1D\subscriptℋ1superscriptsubscript𝒢1𝐷\mathscr{H}_{1}\backslash\mathscr{G}_{1}^{D}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT and ℋ1\𝒢1E\subscriptℋ1superscriptsubscript𝒢1𝐸\mathscr{H}_{1}\backslash\mathscr{G}_{1}^{E}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT \ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT. Given a tuple 𝐱𝐱{\mathbf{x}}bold_x in either 𝒢1Dsuperscriptsubscript𝒢1𝐷\mathscr{G}_{1}^{D}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT or 𝒢1Esuperscriptsubscript𝒢1𝐸\mathscr{G}_{1}^{E}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT we write 𝐱†superscript𝐱†\mathbf{x}^{\dagger}bold_x start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT for the representative of the coset ℋ1⁢𝐱subscriptℋ1𝐱\mathscr{H}_{1}\mathbf{x}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT bold_x. Let X={u𝐛|u∈U,𝐛∈𝒢1D}⊔{v𝐚|v∈V,𝐚∈𝒢1E}𝑋square-unionconditional-setsubscript𝑢𝐛formulae-sequence𝑢𝑈𝐛superscriptsubscript𝒢1𝐷conditional-setsubscript𝑣𝐚formulae-sequence𝑣𝑉𝐚superscriptsubscript𝒢1𝐸X=\{u_{\mathbf{b}}\,|u\in U,{\mathbf{b}}\in\mathscr{G}_{1}^{D}\}\sqcup\{v_{% \mathbf{a}}\,|v\in V,{\mathbf{a}}\in\mathscr{G}_{1}^{E}\}italic_X = { italic_u start_POSTSUBSCRIPT bold_b end_POSTSUBSCRIPT | italic_u ∈ italic_U , bold_b ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT } ⊔ { italic_v start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT | italic_v ∈ italic_V , bold_a ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT }. Then ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT is the weighted system of equations over X𝑋Xitalic_X that contains the equation v𝐚†⁢u𝐛s1s1⁢u𝐜s2s2=g𝐚subscript𝑣superscript𝐚†superscriptsubscript𝑢superscript𝐛subscript𝑠1subscript𝑠1superscriptsubscript𝑢superscript𝐜subscript𝑠2subscript𝑠2subscript𝑔𝐚v_{{\mathbf{a}}^{\dagger}}u_{{\mathbf{b}}^{s_{1}}}^{s_{1}}u_{{\mathbf{c}}^{s_{% 2}}}^{s_{2}}=g_{{\mathbf{a}}}italic_v start_POSTSUBSCRIPT bold_a start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_u start_POSTSUBSCRIPT bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_u start_POSTSUBSCRIPT bold_c start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT (1) for each edge {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v } of ΣΣ\Sigmaroman_Σ, 𝐚∈𝒢1E𝐚superscriptsubscript𝒢1𝐸{\mathbf{a}}\in\mathscr{G}_{1}^{E}bold_a ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT, 𝐛∈𝒢1D𝐛superscriptsubscript𝒢1𝐷{\mathbf{b}}\in\mathscr{G}_{1}^{D}bold_b ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT, s1,s2∈{−1,1}subscript𝑠1subscript𝑠211s_{1},s_{2}\in\{-1,1\}italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∈ { - 1 , 1 }, where 𝐜𝐜{\mathbf{c}}bold_c stands for 𝐛−1⁢(𝐚∘πu⁢v)−1⁢𝝂superscript𝐛1superscript𝐚subscript𝜋𝑢𝑣1𝝂{\mathbf{b}}^{-1}({\mathbf{a}}\circ\pi_{uv})^{-1}\bm{\nu}bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν and 𝝂∈𝒢1D𝝂superscriptsubscript𝒢1𝐷\bm{\nu}\in\mathscr{G}_{1}^{D}bold_italic_ν ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT is a small perturbation factor. The element g𝐚subscript𝑔𝐚g_{\mathbf{a}}italic_g start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT is chosen so that 𝐚†=g𝐚⁢𝐚superscript𝐚†subscript𝑔𝐚𝐚{\mathbf{a}}^{\dagger}=g_{\mathbf{a}}{\mathbf{a}}bold_a start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT bold_a. The weight of this equation in ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT is the joint probability of the independent events described in Figure 1. (1)The edge {u,v} is chosen uniformly at random among all edges of Σ.(2)The elements 𝐚 and 𝐛 are chosen uniformly at random from 𝒢1E and 𝒢1D respectively.(3)The element 𝝂∈𝒢1D is chosen so that for each d∈D, independently, 𝝂⁢(d)=1𝒢1 withprobability 1−ϵ, and 𝝂⁢(d) is selected uniformly at random from 𝒢1 with probability ϵ.(4)The signs s1,s2 are chosen uniformly at random from {−1,1}.(1)The edge {u,v} is chosen uniformly at random among all edges of Σ.missing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression(2)The elements 𝐚 and 𝐛 are chosen uniformly at random from 𝒢1E and 𝒢1D respectively.missing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression(3)The element 𝝂∈𝒢1D is chosen so that for each d∈D, independently, 𝝂⁢(d)=1𝒢1 withmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpressionprobability 1−ϵ, and 𝝂⁢(d) is selected uniformly at random from 𝒢1 with probability ϵ.missing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression(4)The signs s1,s2 are chosen uniformly at random from {−1,1}.missing-subexpressionmissing-subexpressionmissing-subexpressionmissing-subexpression\displaystyle\boxed{\begin{array}[]{llllll}\mbox{($1$)}&\text{The edge $\{u,v\}$ is chosen uniformly at random among all edges of $\Sigma$.}\\[5% .0pt] \mbox{($2$)}&\text{The elements ${\mathbf{a}}$ and ${\mathbf{b}}$ are chosen % uniformly at random from $\mathscr{G}_{1}^{E}$ and $\mathscr{G}_{1}^{D}$ % respectively.}\\[5.0pt] \mbox{($3$)}&\text{The element $\bm{\nu}\in\mathscr{G}_{1}^{D}$ is chosen so % that for each $d\in D$, independently, $\bm{\nu}(d)=1_{\mathscr{G}_{1}}$ with}\\ &\text{probability $1-\epsilon$, and $\bm{\nu}(d)$ is selected uniformly at % random from $\mathscr{G}_{1}$ with probability $\epsilon$.}\\[5.0pt] \mbox{($4$)}&\text{The signs $s_{1},s_{2}$ are chosen uniformly at random from $\{-1,1\}$.}\end{array}}start_ARRAY start_ROW start_CELL ( 1 ) end_CELL start_CELL The edge { italic_u , italic_v } is chosen uniformly at random among all edges of roman_Σ . end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ( 2 ) end_CELL start_CELL The elements bold_a and bold_b are chosen uniformly at random from script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT and script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT respectively. end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ( 3 ) end_CELL start_CELL The element bold_italic_ν ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT is chosen so that for each italic_d ∈ italic_D , independently, bold_italic_ν ( italic_d ) = 1 start_POSTSUBSCRIPT script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT with end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL end_CELL start_CELL probability 1 - italic_ϵ , and bold_italic_ν ( italic_d ) is selected uniformly at random from script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT with probability italic_ϵ . end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL ( 4 ) end_CELL start_CELL The signs italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are chosen uniformly at random from { - 1 , 1 } . end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL start_CELL end_CELL end_ROW end_ARRAY Figure 1: The sampling procedure for ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT. Let us describe assignments of ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT over 𝒢isubscript𝒢𝑖\mathscr{G}_{i}script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for i=1,2𝑖12i=1,2italic_i = 1 , 2. Formally, an assignment of ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT over 𝒢isubscript𝒢𝑖\mathscr{G}_{i}script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is a map h:X→𝒢i:ℎ→𝑋subscript𝒢𝑖h:X\rightarrow\mathscr{G}_{i}italic_h : italic_X → script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Such an assignment can be described by two families of maps A=(Av)v∈V𝐴subscriptsubscript𝐴𝑣𝑣𝑉A=(A_{v})_{v\in V}italic_A = ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_v ∈ italic_V end_POSTSUBSCRIPT from 𝒢1Esubscriptsuperscript𝒢𝐸1\mathscr{G}^{E}_{1}script_G start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to 𝒢isubscript𝒢𝑖\mathscr{G}_{i}script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and B=(Bu)u∈U𝐵subscriptsubscript𝐵𝑢𝑢𝑈B=(B_{u})_{u\in U}italic_B = ( italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_u ∈ italic_U end_POSTSUBSCRIPT from 𝒢1Dsuperscriptsubscript𝒢1𝐷\mathscr{G}_{1}^{D}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT to 𝒢isubscript𝒢𝑖\mathscr{G}_{i}script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT by letting Av⁢(𝐚)=h⁢(v𝐚)subscript𝐴𝑣𝐚ℎsubscript𝑣𝐚A_{v}({\mathbf{a}})=h(v_{{\mathbf{a}}})italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( bold_a ) = italic_h ( italic_v start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT ) for all v∈V,𝐚∈𝒢1Eformulae-sequence𝑣𝑉𝐚superscriptsubscript𝒢1𝐸v\in V,{\mathbf{a}}\in\mathscr{G}_{1}^{E}italic_v ∈ italic_V , bold_a ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT, and Bu⁢(𝐛)=h⁢(u𝐛)=subscript𝐵𝑢𝐛ℎsubscript𝑢𝐛absentB_{u}({\mathbf{b}})=h(u_{{\mathbf{b}}})=italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b ) = italic_h ( italic_u start_POSTSUBSCRIPT bold_b end_POSTSUBSCRIPT ) = for all u∈U,𝐛∈𝒢1Dformulae-sequence𝑢𝑈𝐛superscriptsubscript𝒢1𝐷u\in U,{\mathbf{b}}\in\mathscr{G}_{1}^{D}italic_u ∈ italic_U , bold_b ∈ script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT. It will be more convenient to talk about the pair (A,B)𝐴𝐵(A,B)( italic_A , italic_B ) rather than the map hℎhitalic_h itself, so we will write ΦΣ𝒢i⁢(A,B)subscriptsuperscriptΦsubscript𝒢𝑖Σ𝐴𝐵\Phi^{\mathscr{G}_{i}}_{\Sigma}(A,B)roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ) to refer to the proportion of equations satisfied by the assignment hℎhitalic_h. Let us give a more useful expression for ΦΣ𝒢i⁢(A,B)subscriptsuperscriptΦsubscript𝒢𝑖Σ𝐴𝐵\Phi^{\mathscr{G}_{i}}_{\Sigma}(A,B)roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ). When i=1𝑖1i=1italic_i = 1, we can write ΦΣ𝒢1(A,B)=𝔼u⁢v,𝐚,𝐛,𝝂,s1,s2[⟦Av(𝐚†)Bu(𝐛s1)s1Bu((𝐛−1(𝐚∘πu⁢v)−1𝝂)s2)s2=g𝐚⟧],\Phi^{\mathscr{G}_{1}}_{\Sigma}(A,B)=\mathbb{E}_{\begin{subarray}{c}uv,{% \mathbf{a}},{\mathbf{b}},\\ \bm{\nu},s_{1},s_{2}\end{subarray}}\left[\llbracket A_{v}({\mathbf{a}}^{% \dagger})B_{u}({\mathbf{b}}^{s_{1}})^{s_{1}}B_{u}(({\mathbf{b}}^{-1}({\mathbf{% a}}\circ\pi_{uv})^{-1}\bm{\nu})^{s_{2}})^{s_{2}}=g_{{\mathbf{a}}}\rrbracket% \right],roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ) = blackboard_E start_POSTSUBSCRIPT start_ARG start_ROW start_CELL italic_u italic_v , bold_a , bold_b , end_CELL end_ROW start_ROW start_CELL bold_italic_ν , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_POSTSUBSCRIPT [ ⟦ italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( bold_a start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ) italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = italic_g start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT ⟧ ] , where the expectation is taken over the probabilities described in Figure 1, and we use u⁢v𝑢𝑣uvitalic_u italic_v as a shorthand for an edge {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v }. Folding the assignments Avsubscript𝐴𝑣A_{v}italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT over the identity on ℋ1subscriptℋ1\mathscr{H}_{1}script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and using the fact that (Av)idℋ1⁢(𝐚)=g𝐚−1⁢Av⁢(𝐚†)subscriptsubscript𝐴𝑣subscriptidsubscriptℋ1𝐚superscriptsubscript𝑔𝐚1subscript𝐴𝑣superscript𝐚†(A_{v})_{\mathrm{id}_{\mathscr{H}_{1}}}({\mathbf{a}})=g_{{\mathbf{a}}}^{-1}A_{% v}({\mathbf{a}}^{\dagger})( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT roman_id start_POSTSUBSCRIPT script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_a ) = italic_g start_POSTSUBSCRIPT bold_a end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( bold_a start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ), we obtain ΦΣ𝒢1(A,B)=𝔼u⁢v,𝐚,𝐛,𝝂,s1,s2[⟦(Av)idℋ1(𝐚)Bu(𝐛s1)s1Bu((𝐛−1(𝐚∘πu⁢v)−1𝝂)s2)s2=1𝒢1⟧].\Phi^{\mathscr{G}_{1}}_{\Sigma}(A,B)=\mathbb{E}_{\begin{subarray}{c}uv,{% \mathbf{a}},{\mathbf{b}},\\ \bm{\nu},s_{1},s_{2}\end{subarray}}\left[\llbracket(A_{v})_{\mathrm{id}_{% \mathscr{H}_{1}}}({\mathbf{a}})B_{u}({\mathbf{b}}^{s_{1}})^{s_{1}}B_{u}(({% \mathbf{b}}^{-1}({\mathbf{a}}\circ\pi_{uv})^{-1}\bm{\nu})^{s_{2}})^{s_{2}}=1_{% \mathscr{G}_{1}}\rrbracket\right].roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ) = blackboard_E start_POSTSUBSCRIPT start_ARG start_ROW start_CELL italic_u italic_v , bold_a , bold_b , end_CELL end_ROW start_ROW start_CELL bold_italic_ν , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_POSTSUBSCRIPT [ ⟦ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT roman_id start_POSTSUBSCRIPT script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( bold_a ) italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = 1 start_POSTSUBSCRIPT script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⟧ ] . (2) Analogously, when i=2𝑖2i=2italic_i = 2 and Av,Busubscript𝐴𝑣subscript𝐵𝑢A_{v},B_{u}italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT are families of maps to 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, we obtain a similar expression for ΦΣ𝒢2⁢(A,B)subscriptsuperscriptΦsubscript𝒢2Σ𝐴𝐵\Phi^{\mathscr{G}_{2}}_{\Sigma}(A,B)roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ): ΦΣ𝒢2(A,B)=𝔼u⁢v,𝐚,𝐛,𝝂,s1,s2[⟦(Av)φ(𝐚)Bu(𝐛s1)s1Bu((𝐛−1(𝐚∘πu⁢v)−1𝝂)s2)s2=1𝒢2⟧].\Phi^{\mathscr{G}_{2}}_{\Sigma}(A,B)=\mathbb{E}_{\begin{subarray}{c}uv,{% \mathbf{a}},{\mathbf{b}},\\ \bm{\nu},s_{1},s_{2}\end{subarray}}\left[\llbracket(A_{v})_{\varphi}({\mathbf{% a}})B_{u}({\mathbf{b}}^{s_{1}})^{s_{1}}B_{u}(({\mathbf{b}}^{-1}({\mathbf{a}}% \circ\pi_{uv})^{-1}\bm{\nu})^{s_{2}})^{s_{2}}=1_{\mathscr{G}_{2}}\rrbracket% \right].roman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ) = blackboard_E start_POSTSUBSCRIPT start_ARG start_ROW start_CELL italic_u italic_v , bold_a , bold_b , end_CELL end_ROW start_ROW start_CELL bold_italic_ν , italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_POSTSUBSCRIPT [ ⟦ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT ( bold_a ) italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT = 1 start_POSTSUBSCRIPT script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⟧ ] . (3) That is, a pair of assignments (A,B)𝐴𝐵(A,B)( italic_A , italic_B ) satisfies an equation in ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT if and only if the corresponding pair of assignments obtained by folding A𝐴Aitalic_A (over idℋ1subscriptidsubscriptℋ1\mathrm{id}_{\mathscr{H}_{1}}roman_id start_POSTSUBSCRIPT script_H start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT and φ𝜑\varphiitalic_φ respectively) maps the equation to the group identity (respectively, in 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT and 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT). Thus, folding allows us to focus exclusively on the identity terms in these expectations, which will be useful in the analysis of the reduction. Theorem 1.3 follows from our completeness and soundness bounds for ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT, stated in the next results, using the fact that by Theorem 1.1, there are finite sets D,E𝐷𝐸D,Eitalic_D , italic_E such that GLCD,E⁢(1,α)subscriptGLC𝐷𝐸1𝛼\mathrm{GLC}_{D,E}(1,\alpha)roman_GLC start_POSTSUBSCRIPT italic_D , italic_E end_POSTSUBSCRIPT ( 1 , italic_α ) is NP-hard for the value of α𝛼\alphaitalic_α chosen in Theorem 1.7 below. The proofs of the completeness and soundness bounds can be found in Section 3.1 and Section 3.2 respectively. Theorem 1.6 (Completeness). Let ΣΣ\Sigmaroman_Σ be a Gap Label Cover instance and ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT be the system defined in (1). Suppose that ΣΣ\Sigmaroman_Σ is 1111-satisfiable. Then ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT is (1−ϵ)1italic-ϵ(1-\epsilon)( 1 - italic_ϵ )-satisfiable in 𝒢1subscript𝒢1\mathscr{G}_{1}script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Theorem 1.7 (Soundness). Let ΣΣ\Sigmaroman_Σ be a Gap Label Cover instance and ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT be the system defined in (1). Suppose that ΦΣsubscriptΦΣ\Phi_{\Sigma}roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT is (1/|ℋ2|+δ)1subscriptℋ2𝛿(1/|\mathscr{H}_{2}|+\delta)( 1 / | script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | + italic_δ )-satisfiable in 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Then ΣΣ\Sigmaroman_Σ is α𝛼\alphaitalic_α-satisfiable, where α=δ2/(4⁢κ⁢|𝒢1|κ⁢|𝒢2|4)𝛼superscript𝛿24𝜅superscriptsubscript𝒢1𝜅superscriptsubscript𝒢24\alpha=\delta^{2}/(4\kappa|\mathscr{G}_{1}|^{\kappa}|\mathscr{G}_{2}|^{4})italic_α = italic_δ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ( 4 italic_κ | script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT italic_κ end_POSTSUPERSCRIPT | script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) and κ=⌈(log2δ−2)/(log2(1−ϵ)⌉\kappa=\lceil(\log_{2}\delta-2)/(\log_{2}(1-\epsilon)\rceilitalic_κ = ⌈ ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_δ - 2 ) / ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_ϵ ) ⌉. 1.4 Proof Outline The main difficulty in proving the correctness of our reduction lies in showing the soundness bound (Theorem 1.7). The completeness result (Theorem 1.6) is relatively straightforward and follows as in [EHR04]. In summary, suppose the Gap Label Cover instance ΣΣ\Sigmaroman_Σ is satisfied by a pair of assignments hD:U→D:subscriptℎ𝐷→𝑈𝐷h_{D}:U\rightarrow Ditalic_h start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT : italic_U → italic_D, hE:V→E:subscriptℎ𝐸→𝑉𝐸h_{E}:V\rightarrow Eitalic_h start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT : italic_V → italic_E. Then we find families A,B𝐴𝐵A,Bitalic_A , italic_B such that ΦΣ𝒢1⁢(A,B)≥1−ϵsubscriptsuperscriptΦsubscript𝒢1Σ𝐴𝐵1italic-ϵ\Phi^{\mathscr{G}_{1}}_{\Sigma}(A,B)\geq 1-\epsilonroman_Φ start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT ( italic_A , italic_B ) ≥ 1 - italic_ϵ by letting Avsubscript𝐴𝑣A_{v}italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT be the hE⁢(v)subscriptℎ𝐸𝑣h_{E}(v)italic_h start_POSTSUBSCRIPT italic_E end_POSTSUBSCRIPT ( italic_v )-th projection and Busubscript𝐵𝑢B_{u}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT be the hD⁢(u)subscriptℎ𝐷𝑢h_{D}(u)italic_h start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_u )-th projection for each v∈V,u∈Uformulae-sequence𝑣𝑉𝑢𝑈v\in V,u\in Uitalic_v ∈ italic_V , italic_u ∈ italic_U. As usual, the noise introduced by the perturbation factor 𝝂𝝂\bm{\nu}bold_italic_ν is what forces us to give up perfect completeness. The idea behind our soundness analysis has appeared many times in the literature (e.g., [Hås01, EHR04, BK21]), but the approach taken in [EHR04] is the most similar to ours. Suppose that there are assignments A,B𝐴𝐵A,Bitalic_A , italic_B, satisfying ΦΣ𝒢2⁢(A,B)≥1|ℋ2|+δ.superscriptsubscriptΦΣsubscript𝒢2𝐴𝐵1subscriptℋ2𝛿\Phi_{\Sigma}^{\mathscr{G}_{2}}(A,B)\geq\frac{1}{|\mathscr{H}_{2}|}+\delta.roman_Φ start_POSTSUBSCRIPT roman_Σ end_POSTSUBSCRIPT start_POSTSUPERSCRIPT script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ( italic_A , italic_B ) ≥ divide start_ARG 1 end_ARG start_ARG | script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | end_ARG + italic_δ . (4) In view of (3), this inequality can be understood as a lower bound for the the success probability of the following 3333-query dictatorship test: Sample all parameters according to the distribution shown in Figure 1, and then query the values (Av)φ⁢(𝐚)subscriptsubscript𝐴𝑣𝜑𝐚(A_{v})_{\varphi}({\mathbf{a}})( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT ( bold_a ), Bu⁢(𝐛s1)s1subscript𝐵𝑢superscriptsuperscript𝐛subscript𝑠1subscript𝑠1B_{u}({\mathbf{b}}^{s_{1}})^{s_{1}}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT, and Bu⁢((𝐛−1⁢(𝐚∘πu⁢v)−1⁢𝝂)s2)s2subscript𝐵𝑢superscriptsuperscriptsuperscript𝐛1superscript𝐚subscript𝜋𝑢𝑣1𝝂subscript𝑠2subscript𝑠2B_{u}(({\mathbf{b}}^{-1}({\mathbf{a}}\circ\pi_{uv})^{-1}\bm{\nu})^{s_{2}})^{s_% {2}}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. The test is passed if the product of the three values is the group identity, and failed otherwise. The soundness proof consists in showing that (4) implies that the functions (Av)φ:𝒢1E→𝒢2:subscriptsubscript𝐴𝑣𝜑→superscriptsubscript𝒢1𝐸subscript𝒢2(A_{v})_{\varphi}:\mathscr{G}_{1}^{E}\rightarrow\mathscr{G}_{2}( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT and Bu:𝒢1D→𝒢2:subscript𝐵𝑢→superscriptsubscript𝒢1𝐷subscript𝒢2B_{u}:\mathscr{G}_{1}^{D}\rightarrow\mathscr{G}_{2}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT are “close” to dictators (i.e., projections) for each v∈V𝑣𝑉v\in Vitalic_v ∈ italic_V, u∈U𝑢𝑈u\in Uitalic_u ∈ italic_U. Then, this fact allows us to find a good solution to the starting Gap Label Cover instance ΣΣ\Sigmaroman_Σ. Indeed, suppose that for each v∈V𝑣𝑉v\in Vitalic_v ∈ italic_V the map (Av)φsubscriptsubscript𝐴𝑣𝜑(A_{v})_{\varphi}( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT is the projection on the evsubscript𝑒𝑣e_{v}italic_e start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT-th coordinate, and for each u∈U𝑢𝑈u\in Uitalic_u ∈ italic_U, the map Busubscript𝐵𝑢B_{u}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT is the projection on the dusubscript𝑑𝑢d_{u}italic_d start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT-th coordinate. Then the assignment mapping v𝑣vitalic_v to evsubscript𝑒𝑣e_{v}italic_e start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT and u𝑢uitalic_u to dusubscript𝑑𝑢d_{u}italic_d start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT for each v∈V,u∈Uformulae-sequence𝑣𝑉𝑢𝑈v\in V,u\in Uitalic_v ∈ italic_V , italic_u ∈ italic_U is a good solution for ΣΣ\Sigmaroman_Σ. However, it is not clear how to extend this simple idea to the case where the maps (Av)φ,Busubscriptsubscript𝐴𝑣𝜑subscript𝐵𝑢(A_{v})_{\varphi},B_{u}( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT , italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT are not projections. In order to find a good solution for ΣΣ\Sigmaroman_Σ in this general case, we first find suitable maps γ1,γ2:𝒢2→ℂ:subscript𝛾1subscript𝛾2→subscript𝒢2ℂ\gamma_{1},\gamma_{2}:\mathscr{G}_{2}\rightarrow\mathbb{C}italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT → blackboard_C and analyse γ1∘(Av)φsubscript𝛾1subscriptsubscript𝐴𝑣𝜑\gamma_{1}\circ(A_{v})_{\varphi}italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∘ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT, γ2∘Busubscript𝛾2subscript𝐵𝑢\gamma_{2}\circ B_{u}italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∘ italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT. Now, using the fact that (Av)φsubscriptsubscript𝐴𝑣𝜑(A_{v})_{\varphi}( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT and Busubscript𝐵𝑢B_{u}italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT are close to projections, we can prove that choosing the labels e,d𝑒𝑑e,ditalic_e , italic_d for the vertices v,u𝑣𝑢v,uitalic_v , italic_u according to the “low-degree influence” of the e𝑒eitalic_e-th coordinate in γ1∘(Av)φsubscript𝛾1subscriptsubscript𝐴𝑣𝜑\gamma_{1}\circ(A_{v})_{\varphi}italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∘ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT and the d𝑑ditalic_d-th coordinate in γ2∘Busubscript𝛾2subscript𝐵𝑢\gamma_{2}\circ B_{u}italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ∘ italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT yields a good randomised assignment of ΣΣ\Sigmaroman_Σ. This overview so far also applies to the soundness analysis of [EHR04]. Let us give more detail and highlight the main differences that sets our work apart. The first important difference has to do with the choice of γ1,γ2subscript𝛾1subscript𝛾2\gamma_{1},\gamma_{2}italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. We define γ1=ωx,ysubscript𝛾1subscript𝜔𝑥𝑦\gamma_{1}=\omega_{x,y}italic_γ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_ω start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT, and γ2=ωy,zsubscript𝛾2subscript𝜔𝑦𝑧\gamma_{2}=\omega_{y,z}italic_γ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = italic_ω start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT, where ω𝜔\omegaitalic_ω is some irreducible representation of 𝒢2subscript𝒢2\mathscr{G}_{2}script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT, and x,y,z𝑥𝑦𝑧x,y,zitalic_x , italic_y , italic_z are suitable indices in Nωsubscript𝑁𝜔N_{\omega}italic_N start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT. In [EHR04], the representation ω𝜔\omegaitalic_ω is a non-trivial representation chosen so that |𝔼⁢[χω⁢((Av)φ⁢(𝐚)⁢Bu⁢(𝐛s1)s1⁢Bu⁢((𝐛−1⁢(𝐚∘π)−1⁢𝝂)s2)s2)]|≥dimωδ.𝔼delimited-[]subscript𝜒𝜔subscriptsubscript𝐴𝑣𝜑𝐚subscript𝐵𝑢superscriptsuperscript𝐛subscript𝑠1subscript𝑠1subscript𝐵𝑢superscriptsuperscriptsuperscript𝐛1superscript𝐚𝜋1𝝂subscript𝑠2subscript𝑠2subscriptdimension𝜔𝛿\left|\mathbb{E}\left[\chi_{\omega}\left((A_{v})_{\varphi}({\mathbf{a}})B_{u}(% {\mathbf{b}}^{s_{1}})^{s_{1}}B_{u}(({\mathbf{b}}^{-1}({\mathbf{a}}\circ\pi)^{-% 1}\bm{\nu})^{s_{2}})^{s_{2}}\right)\right]\right|\geq\dim_{\omega}\delta.| blackboard_E [ italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT ( ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT ( bold_a ) italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) ] | ≥ roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_δ . Here the expectation is taken over the probability space described in Figure 1, and the dependence of π𝜋\piitalic_π on the edge {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v } is left implicit. In our case, rather than using the Fourier characters for choosing ω𝜔\omegaitalic_ω, we consider “penalized characters” χω~~subscript𝜒𝜔\widetilde{\chi_{\omega}}over~ start_ARG italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT end_ARG. We define χω~:𝒢2→ℂ:~subscript𝜒𝜔→subscript𝒢2ℂ\widetilde{\chi_{\omega}}:\mathscr{G}_{2}\rightarrow\mathbb{C}over~ start_ARG italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT end_ARG : script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT → blackboard_C as the map χω−ηωsubscript𝜒𝜔subscript𝜂𝜔\chi_{\omega}-\eta_{\omega}italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT - italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT, where the penalty ηωsubscript𝜂𝜔\eta_{\omega}italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT is the multiplicity of the trivial representation in the restriction ω|ℋ2evaluated-at𝜔subscriptℋ2\omega|_{\mathscr{H}_{2}}italic_ω | start_POSTSUBSCRIPT script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT. This way, we pick ω∈𝒢2^𝜔^subscript𝒢2\omega\in\widehat{\mathscr{G}_{2}}italic_ω ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG so that the previous inequality holds after replacing χωsubscript𝜒𝜔\chi_{\omega}italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT with χω~~subscript𝜒𝜔\widetilde{\chi_{\omega}}over~ start_ARG italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT end_ARG. Equivalently, we find ω𝜔\omegaitalic_ω satisfying |𝔼⁢[χω⁢((Av)φ⁢(𝐚)⁢Bu⁢(𝐛s1)s1⁢Bu⁢((𝐛−1⁢(𝐚∘π)−1⁢𝝂)s2)s2)]|≥dimωδ+ηω.𝔼delimited-[]subscript𝜒𝜔subscriptsubscript𝐴𝑣𝜑𝐚subscript𝐵𝑢superscriptsuperscript𝐛subscript𝑠1subscript𝑠1subscript𝐵𝑢superscriptsuperscriptsuperscript𝐛1superscript𝐚𝜋1𝝂subscript𝑠2subscript𝑠2subscriptdimension𝜔𝛿subscript𝜂𝜔\left|\mathbb{E}\left[\chi_{\omega}\left((A_{v})_{\varphi}({\mathbf{a}})B_{u}(% {\mathbf{b}}^{s_{1}})^{s_{1}}B_{u}(({\mathbf{b}}^{-1}({\mathbf{a}}\circ\pi)^{-% 1}\bm{\nu})^{s_{2}})^{s_{2}}\right)\right]\right|\geq\dim_{\omega}\delta+\eta_% {\omega}.| blackboard_E [ italic_χ start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT ( ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT ( bold_a ) italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ( bold_b start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) ] | ≥ roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_δ + italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT . (5) The fact that such ω𝜔\omegaitalic_ω exists is a consequence of (4) together with ∑ω∈𝒢2^dimωηω=|𝒢2|/|ℋ2|subscript𝜔^subscript𝒢2subscriptdimension𝜔subscript𝜂𝜔subscript𝒢2subscriptℋ2\sum_{\omega\in\widehat{\mathscr{G}_{2}}}\dim_{\omega}\eta_{\omega}=|\mathscr{% G}_{2}|/|\mathscr{H}_{2}|∑ start_POSTSUBSCRIPT italic_ω ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT = | script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | / | script_H start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT |, which follows from the Frobenius Reciprocity Theorem, as shown in Lemma 2.11. This additional factor of ηωsubscript𝜂𝜔\eta_{\omega}italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT is crucial to our soundness analysis, as we will see. Define the map 𝒜=ω∘(Av)φ𝒜𝜔subscriptsubscript𝐴𝑣𝜑\mathcal{A}=\omega\circ(A_{v})_{\varphi}caligraphic_A = italic_ω ∘ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT and the map ℬ:𝒢1D→𝒢2:ℬ→superscriptsubscript𝒢1𝐷subscript𝒢2\mathcal{B}:\mathscr{G}_{1}^{D}\rightarrow\mathscr{G}_{2}caligraphic_B : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT given by ℬ⁢(𝐛)=𝔼s∈{−1,1}⁢ω∘Bu⁢(𝐛s)sℬ𝐛subscript𝔼𝑠11𝜔subscript𝐵𝑢superscriptsuperscript𝐛𝑠𝑠\mathcal{B}({\mathbf{b}})=\mathbb{E}_{s\in\{-1,1\}}\omega\circ B_{u}({\mathbf{% b}}^{s})^{s}caligraphic_B ( bold_b ) = blackboard_E start_POSTSUBSCRIPT italic_s ∈ { - 1 , 1 } end_POSTSUBSCRIPT italic_ω ∘ italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( bold_b start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT, where s∈{−1,1}𝑠11s\in\{-1,1\}italic_s ∈ { - 1 , 1 } is distributed uniformly.555Observe that the maps 𝒜𝒜\mathcal{A}caligraphic_A and ℬℬ\mathcal{B}caligraphic_B depend on the hidden parameters v𝑣vitalic_v and u𝑢uitalic_u respectively. To show the soundness bound we consider the Fourier expansions of 𝒜𝒜\mathcal{A}caligraphic_A and ℬ∗ℬℬℬ\mathcal{B}*\mathcal{B}caligraphic_B ∗ caligraphic_B in the expression |tr⁢𝔼⁢[𝒜⁢(𝐚)⁢(ℬ∗ℬ)⁢((𝐚∘π)−1⁢𝝂)]|,tr𝔼delimited-[]𝒜𝐚ℬℬsuperscript𝐚𝜋1𝝂\left|\mathrm{tr}\,\mathbb{E}\left[\mathcal{A}({\mathbf{a}})(\mathcal{B}*% \mathcal{B})(({\mathbf{a}}\circ\pi)^{-1}\bm{\nu})\right]\right|,| roman_tr blackboard_E [ caligraphic_A ( bold_a ) ( caligraphic_B ∗ caligraphic_B ) ( ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) ] | , which is just a rearrangement of the left-hand-side in the previous inequality. More precisely, we look at the equivalent expression |tr⁢𝔼⁢[(∑τ∈𝒢E^,s,t∈Nτdimτ𝒜^⁢(τs,t)⁢τs,t⁢(𝐚))⁢(∑ρ∈𝒢D^,i,j∈Nρdimρ(ℬ∗ℬ)^⁢(ρi,j)⁢ρi,j⁢((𝐚∘π)−1⁢𝝂))]|.tr𝔼delimited-[]subscriptformulae-sequence𝜏^superscript𝒢𝐸𝑠𝑡subscript𝑁𝜏subscriptdimension𝜏^𝒜subscript𝜏𝑠𝑡subscript𝜏𝑠𝑡𝐚subscriptformulae-sequence𝜌^superscript𝒢𝐷𝑖𝑗subscript𝑁𝜌subscriptdimension𝜌^ℬℬsubscript𝜌𝑖𝑗subscript𝜌𝑖𝑗superscript𝐚𝜋1𝝂\left|\mathrm{tr}\,\mathbb{E}\left[\left(\sum_{\tau\in\widehat{\mathscr{G}^{E}% },s,t\in N_{\tau}}\dim_{\tau}\widehat{\mathcal{A}}(\tau_{s,t})\tau_{s,t}({% \mathbf{a}})\right)\left(\sum_{\rho\in\widehat{\mathscr{G}^{D}},i,j\in N_{\rho% }}\dim_{\rho}\widehat{(\mathcal{B}*\mathcal{B})}(\rho_{i,j})\rho_{i,j}(({% \mathbf{a}}\circ\pi)^{-1}\bm{\nu})\right)\right]\right|.| roman_tr blackboard_E [ ( ∑ start_POSTSUBSCRIPT italic_τ ∈ over^ start_ARG script_G start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT end_ARG , italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT over^ start_ARG caligraphic_A end_ARG ( italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ) italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ( bold_a ) ) ( ∑ start_POSTSUBSCRIPT italic_ρ ∈ over^ start_ARG script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG , italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT over^ start_ARG ( caligraphic_B ∗ caligraphic_B ) end_ARG ( italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ( ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) ) ] | . (6) Our goal is to find a bound κ𝜅\kappaitalic_κ, independent of |D|,|E|𝐷𝐸|D|,|E|| italic_D | , | italic_E |, satisfying that the contribution to this expression of non-trivial representations τ,ρ𝜏𝜌\tau,\rhoitalic_τ , italic_ρ of degree less than κ𝜅\kappaitalic_κ is at least dimωδ/2subscriptdimension𝜔𝛿2\dim_{\omega}\delta/2roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_δ / 2. This is achieved by controlling the contribution of the trivial term and the contribution of high-degree terms, as indicated by Lemma 3.1 and Lemma 3.2 respectively. The second main difference of our soundness analysis compared to [EHR04] is our handling of the trivial term. In Lemma 3.1 we prove that |tr⁢𝔼⁢[𝒜^⁢(1)⁢(∑ρ∈𝒢D^,s,t∈Nρdimρ(ℬ∗ℬ)^⁢(ρi,j)⁢ρi,j⁢((𝐚∘π)−1⁢𝝂))]|≤ηω.tr𝔼delimited-[]^𝒜1subscriptformulae-sequence𝜌^superscript𝒢𝐷𝑠𝑡subscript𝑁𝜌subscriptdimension𝜌^ℬℬsubscript𝜌𝑖𝑗subscript𝜌𝑖𝑗superscript𝐚𝜋1𝝂subscript𝜂𝜔\left|\mathrm{tr}\,\mathbb{E}\left[\widehat{\mathcal{A}}(1)\left(\sum_{\rho\in% \widehat{\mathscr{G}^{D}},s,t\in N_{\rho}}\dim_{\rho}\widehat{(\mathcal{B}*% \mathcal{B})}(\rho_{i,j})\rho_{i,j}(({\mathbf{a}}\circ\pi)^{-1}\bm{\nu})\right% )\right]\right|\leq\eta_{\omega}.| roman_tr blackboard_E [ over^ start_ARG caligraphic_A end_ARG ( 1 ) ( ∑ start_POSTSUBSCRIPT italic_ρ ∈ over^ start_ARG script_G start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG , italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT over^ start_ARG ( caligraphic_B ∗ caligraphic_B ) end_ARG ( italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ( ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) ) ] | ≤ italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT . In the non-promise setting, this bound is not necessary. Roughly, under the stronger notion of folding used in [EHR04], it is possible to show that 𝒜^⁢(1)^𝒜1\widehat{\mathcal{A}}(1)over^ start_ARG caligraphic_A end_ARG ( 1 ) vanishes. Our weaker notion of folding does not allow us to prove the same result, but we are still able to leverage folding to obtain the above bound. This mismatch with [EHR04] is the reason why the extra ηωsubscript𝜂𝜔\eta_{\omega}italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT term was required in (5). The key insight in the proof of Lemma 3.1 is that if F:𝒢1E→𝒢2:𝐹→superscriptsubscript𝒢1𝐸subscript𝒢2F:\mathscr{G}_{1}^{E}\rightarrow\mathscr{G}_{2}italic_F : script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT → script_G start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is folded over φ𝜑\varphiitalic_φ, then the trace of (ω∘F)^⁢(1)^𝜔𝐹1\widehat{(\omega\circ F)}(1)over^ start_ARG ( italic_ω ∘ italic_F ) end_ARG ( 1 ) is at most ηωsubscript𝜂𝜔\eta_{\omega}italic_η start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT in absolute value. Our analysis of high-degree terms is in the same spirit as previous works that show hardness of approximation in the imperfect completeness setting. In Lemma 3.2 we prove that |tr𝔼[(∑τ∈𝒢1E^,τ≠1∑s,t∈Nτdimτ𝒜^(τs,t)τs,t(𝐚))×\displaystyle\left|\mathrm{tr}\,\mathbb{E}\left[\left(\sum_{\tau\in\widehat{% \mathscr{G}_{1}^{E}},\tau\neq 1}\sum_{s,t\in N_{\tau}}\dim_{\tau}\widehat{% \mathcal{A}}(\tau_{s,t})\tau_{s,t}({\mathbf{a}})\right)\times\right.\right.| roman_tr blackboard_E [ ( ∑ start_POSTSUBSCRIPT italic_τ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT end_ARG , italic_τ ≠ 1 end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT over^ start_ARG caligraphic_A end_ARG ( italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ) italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ( bold_a ) ) × (∑ρ∈𝒢1D^,|ρ|≥κ∑i,j∈Nρdimρ(ℬ∗ℬ)^(ρi,j)ρi,j((𝐚∘π)−1𝝂))]|≤(dimωδ)/2\displaystyle\left.\left.\left(\sum_{\rho\in\widehat{\mathscr{G}_{1}^{D}},|% \rho|\geq\kappa}\sum_{i,j\in N_{\rho}}\dim_{\rho}\widehat{(\mathcal{B}*% \mathcal{B})}(\rho_{i,j})\rho_{i,j}(({\mathbf{a}}\circ\pi)^{-1}\bm{\nu})\right% )\right]\right|\leq(\dim_{\omega}\delta)/2( ∑ start_POSTSUBSCRIPT italic_ρ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG , | italic_ρ | ≥ italic_κ end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT over^ start_ARG ( caligraphic_B ∗ caligraphic_B ) end_ARG ( italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ( ( bold_a ∘ italic_π ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT bold_italic_ν ) ) ] | ≤ ( roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_δ ) / 2 for all κ≥(log2⁡δ−2)/log2⁡(1−ϵ)𝜅subscript2𝛿2subscript21italic-ϵ\kappa\geq(\log_{2}\delta-2)/\log_{2}(1-\epsilon)italic_κ ≥ ( roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_δ - 2 ) / roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( 1 - italic_ϵ ). The essential idea is that the “noise vector” 𝝂𝝂\bm{\nu}bold_italic_ν has a smoothing effect that limits the contribution of high-degree terms in (6). Finally, having established that the contribution of non-trivial terms of degree less than κ𝜅\kappaitalic_κ in (6) is at least dimωδ/2subscriptdimension𝜔𝛿2\dim_{\omega}\delta/2roman_dim start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT italic_δ / 2, in Lemma 3.3 we give a good randomised strategy to solve ΣΣ\Sigmaroman_Σ. This strategy assigns the label e∈E𝑒𝐸e\in Eitalic_e ∈ italic_E to v∈V𝑣𝑉v\in Vitalic_v ∈ italic_V and the label d∈D𝑑𝐷d\in Ditalic_d ∈ italic_D to u∈U𝑢𝑈u\in Uitalic_u ∈ italic_U with probabilities Pr⁡(v↦e)=∑τ∈𝒢1E^,τe≠1∑s,t∈Nτdimτ|𝒜x,y^⁢(τs,t)|2|τ|Prmaps-to𝑣𝑒subscriptformulae-sequence𝜏^superscriptsubscript𝒢1𝐸superscript𝜏𝑒1subscript𝑠𝑡subscript𝑁𝜏subscriptdimension𝜏superscript^subscript𝒜𝑥𝑦subscript𝜏𝑠𝑡2𝜏\Pr(v\mapsto e)\ =\sum_{\tau\in\widehat{\mathscr{G}_{1}^{E}},\tau^{e}\neq 1}% \sum_{s,t\in N_{\tau}}\dim_{\tau}\frac{\left|\widehat{\mathcal{A}_{x,y}}(\tau_% {s,t})\right|^{2}}{|\tau|}roman_Pr ( italic_v ↦ italic_e ) = ∑ start_POSTSUBSCRIPT italic_τ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT end_ARG , italic_τ start_POSTSUPERSCRIPT italic_e end_POSTSUPERSCRIPT ≠ 1 end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT divide start_ARG | over^ start_ARG caligraphic_A start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT end_ARG ( italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG | italic_τ | end_ARG and Pr⁡(u↦d)=∑ρ∈𝒢1D^,ρd≠1∑i,j∈Nρdimρ|ℬy,z^⁢(ρi,j)|2|ρ|,Prmaps-to𝑢𝑑subscriptformulae-sequence𝜌^superscriptsubscript𝒢1𝐷superscript𝜌𝑑1subscript𝑖𝑗subscript𝑁𝜌subscriptdimension𝜌superscript^subscriptℬ𝑦𝑧subscript𝜌𝑖𝑗2𝜌\Pr(u\mapsto d)\ =\sum_{\rho\in\widehat{\mathscr{G}_{1}^{D}},\rho^{d}\neq 1}% \sum_{i,j\in N_{\rho}}\dim_{\rho}\frac{\left|\widehat{\mathcal{B}_{y,z}}(\rho_% {i,j})\right|^{2}}{|\rho|},roman_Pr ( italic_u ↦ italic_d ) = ∑ start_POSTSUBSCRIPT italic_ρ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG , italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ≠ 1 end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_dim start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT divide start_ARG | over^ start_ARG caligraphic_B start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT end_ARG ( italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG | italic_ρ | end_ARG , where x,y,z∈Nω𝑥𝑦𝑧subscript𝑁𝜔x,y,z\in N_{\omega}italic_x , italic_y , italic_z ∈ italic_N start_POSTSUBSCRIPT italic_ω end_POSTSUBSCRIPT are suitable indices found in Lemma 3.3. These probabilities are supposed to capture the influence of the e𝑒eitalic_e-th and d𝑑ditalic_d-th coordinates on 𝒜x,y=ωx,y∘(Av)φsubscript𝒜𝑥𝑦subscript𝜔𝑥𝑦subscriptsubscript𝐴𝑣𝜑\mathcal{A}_{x,y}=\omega_{x,y}\circ(A_{v})_{\varphi}caligraphic_A start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT = italic_ω start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT ∘ ( italic_A start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT and ℬy,z=ωy,z∘𝔼s⁢Bu⁢(⋅s)ssubscriptℬ𝑦𝑧subscript𝜔𝑦𝑧subscript𝔼𝑠subscript𝐵𝑢superscriptsuperscript⋅𝑠𝑠\mathcal{B}_{y,z}=\omega_{y,z}\circ\mathbb{E}_{s}B_{u}(\ \cdot^{s})^{s}caligraphic_B start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT = italic_ω start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT ∘ blackboard_E start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ( ⋅ start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT respectively (compare with the notion of influence in [BK21, AM09]). This turns out to be a good randomised assignment for ΣΣ\Sigmaroman_Σ. That is, 𝔼u⁢v⁢[∑d∈DPr⁡(v↦πu⁢v⁢(d))⁢Pr⁡(u↦d)]≥α,subscript𝔼𝑢𝑣delimited-[]subscript𝑑𝐷Prmaps-to𝑣subscript𝜋𝑢𝑣𝑑Prmaps-to𝑢𝑑𝛼\mathbb{E}_{uv}\left[\sum_{d\in D}\Pr(v\mapsto\pi_{uv}(d))\Pr(u\mapsto d)% \right]\geq\alpha,blackboard_E start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT [ ∑ start_POSTSUBSCRIPT italic_d ∈ italic_D end_POSTSUBSCRIPT roman_Pr ( italic_v ↦ italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ( italic_d ) ) roman_Pr ( italic_u ↦ italic_d ) ] ≥ italic_α , (7) where the expectation is taken uniformly over the edges {u,v}𝑢𝑣\{u,v\}{ italic_u , italic_v } of ΣΣ\Sigmaroman_Σ, and α𝛼\alphaitalic_α is the soundness constant appearing in Theorem 1.7. We are being informal with the usage of the word “probability” here: the quantities Pr⁡(v↦e)Prmaps-to𝑣𝑒\Pr(v\mapsto e)roman_Pr ( italic_v ↦ italic_e ) and Pr⁡(u↦d)Prmaps-to𝑢𝑑\Pr(u\mapsto d)roman_Pr ( italic_u ↦ italic_d ) may add up to less than 1111, but this is easily fixed by normalising, or by letting our strategy default to the uniform assignment with some positive probability. Let us give some more detail. More precisely, Lemma 3.3 shows that truncating our assignment probabilities to terms of degree less than κ𝜅\kappaitalic_κ is enough to satisfy this last inequality. Let ℓ≥0ℓ0\ell\geq 0roman_ℓ ≥ 0. The probabilities Pr<ℓ⁡(v↦e)superscriptPrabsentℓmaps-to𝑣𝑒\Pr^{<\ell}(v\mapsto e)roman_Pr start_POSTSUPERSCRIPT < roman_ℓ end_POSTSUPERSCRIPT ( italic_v ↦ italic_e ), Pr<ℓ⁡(u↦d)superscriptPrabsentℓmaps-to𝑢𝑑\Pr^{<\ell}(u\mapsto d)roman_Pr start_POSTSUPERSCRIPT < roman_ℓ end_POSTSUPERSCRIPT ( italic_u ↦ italic_d ) are defined the same way as Pr⁡(v↦e)Prmaps-to𝑣𝑒\Pr(v\mapsto e)roman_Pr ( italic_v ↦ italic_e ) and Pr⁡(u↦d)Prmaps-to𝑢𝑑\Pr(u\mapsto d)roman_Pr ( italic_u ↦ italic_d ) but considering only representations τ,ρ𝜏𝜌\tau,\rhoitalic_τ , italic_ρ of degree less than ℓℓ\ellroman_ℓ. These modified probabilities can be understood as the “low-degree influences” of each coordinate in 𝒜x,ysubscript𝒜𝑥𝑦\mathcal{A}_{x,y}caligraphic_A start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT and ℬy,zsubscriptℬ𝑦𝑧\mathcal{B}_{y,z}caligraphic_B start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT. With this notation, in Lemma 3.3 we prove that (7) holds after replacing each assignment probability PrPr\Prroman_Pr with its truncated variant Pr<κsuperscriptPrabsent𝜅\Pr^{<\kappa}roman_Pr start_POSTSUPERSCRIPT < italic_κ end_POSTSUPERSCRIPT. In other words, we prove that 𝔼u⁢v⁢[∑d∈D∑ρ∈𝒢1D^,ρd≠1|ρ|<κ,i,j∈Nρ∑τ∈𝒢1E^,τπu⁢v⁢(d)≠1|τ|<κ,s,t∈Nτdimτ|𝒜x,y^⁢(τs,t)|2|τ|⁢dimρ|ℬy,z^⁢(ρi,j)|2|ρ|]≥α.subscript𝔼𝑢𝑣delimited-[]subscript𝑑𝐷subscriptformulae-sequence𝜌^superscriptsubscript𝒢1𝐷superscript𝜌𝑑1formulae-sequence𝜌𝜅𝑖𝑗subscript𝑁𝜌subscriptformulae-sequence𝜏^superscriptsubscript𝒢1𝐸superscript𝜏subscript𝜋𝑢𝑣𝑑1formulae-sequence𝜏𝜅𝑠𝑡subscript𝑁𝜏subscriptdimension𝜏superscript^subscript𝒜𝑥𝑦subscript𝜏𝑠𝑡2𝜏subscriptdimension𝜌superscript^subscriptℬ𝑦𝑧subscript𝜌𝑖𝑗2𝜌𝛼\mathbb{E}_{uv}\left[\sum_{d\in D}\sum_{\begin{subarray}{c}\rho\in\widehat{% \mathscr{G}_{1}^{D}},\rho^{d}\neq 1\\ |\rho|<\kappa,\,i,j\in N_{\rho}\end{subarray}}\sum_{\begin{subarray}{c}\tau\in% \widehat{\mathscr{G}_{1}^{E}},\tau^{\pi_{uv}(d)}\neq 1\\ |\tau|<\kappa,\,s,t\in N_{\tau}\end{subarray}}\frac{\dim_{\tau}\left|\widehat{% \mathcal{A}_{x,y}}(\tau_{s,t})\right|^{2}}{|\tau|}\frac{\dim_{\rho}\left|% \widehat{\mathcal{B}_{y,z}}(\rho_{i,j})\right|^{2}}{|\rho|}\right]\geq\alpha.blackboard_E start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT [ ∑ start_POSTSUBSCRIPT italic_d ∈ italic_D end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT start_ARG start_ROW start_CELL italic_ρ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT end_ARG , italic_ρ start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ≠ 1 end_CELL end_ROW start_ROW start_CELL | italic_ρ | < italic_κ , italic_i , italic_j ∈ italic_N start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT start_ARG start_ROW start_CELL italic_τ ∈ over^ start_ARG script_G start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_E end_POSTSUPERSCRIPT end_ARG , italic_τ start_POSTSUPERSCRIPT italic_π start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT ( italic_d ) end_POSTSUPERSCRIPT ≠ 1 end_CELL end_ROW start_ROW start_CELL | italic_τ | < italic_κ , italic_s , italic_t ∈ italic_N start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT end_CELL end_ROW end_ARG end_POSTSUBSCRIPT divide start_ARG roman_dim start_POSTSUBSCRIPT italic_τ end_POSTSUBSCRIPT | over^ start_ARG caligraphic_A start_POSTSUBSCRIPT italic_x , italic_y end_POSTSUBSCRIPT end_ARG ( italic_τ start_POSTSUBSCRIPT italic_s , italic_t end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG | italic_τ | end_ARG divide start_ARG roman_dim start_POSTSUBSCRIPT italic_ρ end_POSTSUBSCRIPT | over^ start_ARG caligraphic_B start_POSTSUBSCRIPT italic_y , italic_z end_POSTSUBSCRIPT end_ARG ( italic_ρ start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG start_ARG | italic_ρ | end_ARG ] ≥ italic_α . This shows that our proposed strategy produces a good randomised assignment for ΣΣ\Sigmaroman_Σ and completes the soundness proof."
https://arxiv.org/html/2411.02148v1,Optimality of Frequency Moment Estimation,"Estimating the second frequency moment of a stream up to (1±ε)plus-or-minus1𝜀(1\pm\varepsilon)( 1 ± italic_ε ) multiplicative error requires at most O⁢(log⁡n/ε2)𝑂𝑛superscript𝜀2O(\log n/\varepsilon^{2})italic_O ( roman_log italic_n / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) bits of space, due to a seminal result of Alon, Matias, and Szegedy. It is also known that at least Ω⁢(log⁡n+1/ε2)Ω𝑛1superscript𝜀2\Omega(\log n+1/\varepsilon^{2})roman_Ω ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) space is needed. We prove an optimal lower bound of Ω⁢(log⁡(n⁢ε2)/ε2)Ω𝑛superscript𝜀2superscript𝜀2\Omega\left(\log\left(n\varepsilon^{2}\right)/\varepsilon^{2}\right)roman_Ω ( roman_log ( italic_n italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) for all ε=Ω⁢(1/n)𝜀Ω1𝑛\varepsilon=\Omega(1/\sqrt{n})italic_ε = roman_Ω ( 1 / square-root start_ARG italic_n end_ARG ). Note that when ε>n−1/2+c𝜀superscript𝑛12𝑐\varepsilon>n^{-1/2+c}italic_ε > italic_n start_POSTSUPERSCRIPT - 1 / 2 + italic_c end_POSTSUPERSCRIPT, where c>0𝑐0c>0italic_c > 0, our lower bound matches the classic upper bound of AMS. For smaller values of ε𝜀\varepsilonitalic_ε we also introduce a revised algorithm that improves the classic AMS bound and matches our lower bound. Our lower bound holds also for the more general problem of p𝑝pitalic_p-th frequency moment estimation for the range of p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ], giving a tight bound in the only remaining range to settle the optimal space complexity of estimating frequency moments.","An extensive body of literature is devoted to the streaming model of computation, which is important for the analysis of massive datasets and in network traffic monitoring. A central problem in this model is the frequency moment estimation problem: Elements from a universe U𝑈Uitalic_U are given to the algorithm one-by-one, defining a vector of frequencies — that is, fx∈ℕsubscript𝑓𝑥ℕf_{x}\in\mathbb{N}italic_f start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ∈ blackboard_N is the number of times the element x∈U𝑥𝑈x\in Uitalic_x ∈ italic_U appeared in the stream; Finally, the algorithm has to return, with good probability, a (1±ε)plus-or-minus1𝜀(1\pm\varepsilon)( 1 ± italic_ε )-estimation of Fp:=∑x∈Ufxpassignsubscript𝐹𝑝subscript𝑥𝑈superscriptsubscript𝑓𝑥𝑝F_{p}:=\sum_{x\in U}f_{x}^{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT := ∑ start_POSTSUBSCRIPT italic_x ∈ italic_U end_POSTSUBSCRIPT italic_f start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT — the p𝑝pitalic_p-th frequency moment of the stream. We generally denote the length of the stream by n𝑛nitalic_n and assume that |U|=poly⁢(n)𝑈poly𝑛|U|=\text{poly}(n)| italic_U | = poly ( italic_n ). The main complexity parameter studied in this model is how much space is needed for the algorithm to succeed. The study of both the streaming model and of frequency moment estimation in it was initiated in the seminal 1996 work of Alon, Matias, and Szegedy [AMS96]. The case of p=2𝑝2p=2italic_p = 2, or second moment estimation, is of particular importance. It is often called the repeat rate or surprise index, and is used in various tasks such as database query optimization [AGMS99], network traffic anomaly detection [KSZC03], approximate histogram maintenance [GGI+02] and more. Other moments of particular interest are p=1𝑝1p=1italic_p = 1, corresponding to the approximate counting problem [Mor78, NY22], and p=0𝑝0p=0italic_p = 0, corresponding to the distinct elements problem [FM85, IW03, KNW10b]. Among these special cases, only the space complexity of the first remains not fully understood. The original algorithm for F2subscript𝐹2F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-estimation given by Alon, Matias, and Szegedy uses O⁢(log⁡n/ε2)𝑂𝑛superscript𝜀2O(\log n/\varepsilon^{2})italic_O ( roman_log italic_n / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) bits of space; while the highest known lower bound due to Woodruff in 2004 [Woo04] is Ω⁢(log⁡n+1/ε2)Ω𝑛1superscript𝜀2\Omega(\log n+1/\varepsilon^{2})roman_Ω ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) — leaving up to a quadratic gap between the upper and lower bounds for certain choices of ε𝜀\varepsilonitalic_ε. While Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation for p≤2𝑝2p\leq 2italic_p ≤ 2 uses amount of space that is only logarithmic in the length of the stream, it was shown that for p>2𝑝2p>2italic_p > 2 at least Ω⁢(n1−2/p/poly⁢(ε))Ωsuperscript𝑛12𝑝poly𝜀\Omega(n^{1-2/p}/\text{poly}(\varepsilon))roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 - 2 / italic_p end_POSTSUPERSCRIPT / poly ( italic_ε ) ) space is needed [BYJKS04, CKS03b] — which is polynomial in the stream’s length. A long list of works [IW05, BGKS06, MW10, AKO11, BO10, And17, Gan11b, WZ12, Gan11a, LW13] resulted in a nearly-tight bound of Θ~⁢(n1−2/p/ε2)~Θsuperscript𝑛12𝑝superscript𝜀2\tilde{\Theta}\left(n^{1-2/p}/\varepsilon^{2}\right)over~ start_ARG roman_Θ end_ARG ( italic_n start_POSTSUPERSCRIPT 1 - 2 / italic_p end_POSTSUPERSCRIPT / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) for Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation for every p>2𝑝2p>2italic_p > 2 (not necessarily an integer) and ε𝜀\varepsilonitalic_ε, for some ranges of parameters the bounds are tight — in others there is a gap between the bounds that is poly-logarithmic in the bound itself. For p≤2𝑝2p\leq 2italic_p ≤ 2 the space complexity is not as well understood. Woodruff [Woo04] showed a lower bound of Ω⁢(log⁡n+1/ε2)Ω𝑛1superscript𝜀2\Omega(\log n+1/\varepsilon^{2})roman_Ω ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) for every p≠1𝑝1p\neq 1italic_p ≠ 1, this is optimal in terms of ε𝜀\varepsilonitalic_ε alone and is also known to be optimal for the distinct elements problem (that is, p=0𝑝0p=0italic_p = 0). For the special case of approximate counting (that is, p=1𝑝1p=1italic_p = 1), a tight bound of Θ⁢(log⁡log⁡n+log⁡ε−1)Θ𝑛superscript𝜀1\Theta(\log\log n+\log\varepsilon^{-1})roman_Θ ( roman_log roman_log italic_n + roman_log italic_ε start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) is known [NY22]. For the range of p∈[0,1)𝑝01p\in[0,1)italic_p ∈ [ 0 , 1 ), the upper bound of AMS was improved by Jayaram and Woodruff who presented a nearly-tight O~⁢(log⁡n+1/ε2)~𝑂𝑛1superscript𝜀2\tilde{O}\left(\log n+1/\varepsilon^{2}\right)over~ start_ARG italic_O end_ARG ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) bound in that range [JW19]. This leaves p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ] as the last remaining range within no nearly-tight bounds are known. For certain generalizations more is known: When the stream is randomly shuffled and given in random order, then in the range p∈(1,2)𝑝12p\in(1,2)italic_p ∈ ( 1 , 2 ) (excluding p=2𝑝2p=2italic_p = 2) [BVWY18] showed an improved upper bound of O~⁢(log⁡n+1/ε2)~𝑂𝑛1superscript𝜀2\tilde{O}\left(\log n+1/\varepsilon^{2}\right)over~ start_ARG italic_O end_ARG ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ). When updates are allowed in the stream, that is, elements can also be deleted and not only added to it, then [KNW10a] showed that Θ⁢(log⁡n/ε2)Θ𝑛superscript𝜀2\Theta(\log n/\varepsilon^{2})roman_Θ ( roman_log italic_n / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) is optimal for p≤2𝑝2p\leq 2italic_p ≤ 2. In this work, we settle the space complexity of frequency moment estimation in the entire remaining range of p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ], including the special case of second frequency moment estimation. For p=2𝑝2p=2italic_p = 2, we show that the AMS bound is essentially tight. Theorem. Let 𝒜𝒜\mathcal{A}caligraphic_A be a streaming algorithm that gives an (1±ε)plus-or-minus1𝜀\left(1\pm\varepsilon\right)( 1 ± italic_ε ) multiplicative approximation to the F2subscript𝐹2F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of its input stream and succeeds with probability ≥2/3absent23\geq 2/3≥ 2 / 3, for some ε=Ω⁢(1/n)𝜀Ω1𝑛\varepsilon=\Omega(1/\sqrt{n})italic_ε = roman_Ω ( 1 / square-root start_ARG italic_n end_ARG ). Then, the space used by 𝒜𝒜\mathcal{A}caligraphic_A is Ω⁢(log⁡(ε2⁢n)/ε2)Ωsuperscript𝜀2𝑛superscript𝜀2\Omega\left(\log\left(\varepsilon^{2}n\right)/\varepsilon^{2}\right)roman_Ω ( roman_log ( italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n ) / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ). Note that the range ε<1/n𝜀1𝑛\varepsilon<1/\sqrt{n}italic_ε < 1 / square-root start_ARG italic_n end_ARG is less interesting as O⁢(min⁡{n⁢log⁡n,|U|})𝑂𝑛𝑛𝑈O\left(\min\{n\log n,|U|\}\right)italic_O ( roman_min { italic_n roman_log italic_n , | italic_U | } ) space suffices for exactly maintaining the vector of frequencies. We observe that in the range where ε𝜀\varepsilonitalic_ε is very close to 1/n1𝑛1/\sqrt{n}1 / square-root start_ARG italic_n end_ARG our lower bound is (slightly) lower than the AMS upper bound, we show that this is inherent by introducing a modification of the AMS algorithm that matches our lower bound in this range. Theorem. For ε=Ω⁢(1/n)𝜀Ω1𝑛\varepsilon=\Omega(1/\sqrt{n})italic_ε = roman_Ω ( 1 / square-root start_ARG italic_n end_ARG ), we can get a (1±ε)plus-or-minus1𝜀(1\pm\varepsilon)( 1 ± italic_ε )-approximation of the F2subscript𝐹2F_{2}italic_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT of a stream of length n𝑛nitalic_n using O⁢(log⁡(ε2⁢n)/ε2)𝑂superscript𝜀2𝑛superscript𝜀2O\left(\log\left(\varepsilon^{2}n\right)/\varepsilon^{2}\right)italic_O ( roman_log ( italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n ) / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) space with success probability >2/3absent23>2/3> 2 / 3. 0≤p<10𝑝10\leq p<10 ≤ italic_p < 1 p=1𝑝1p=1italic_p = 1 1<p≤21𝑝21<p\leq 21 < italic_p ≤ 2 p>2𝑝2p>2italic_p > 2 Θ~⁢(log⁡n+1/ε2)~Θ𝑛1superscript𝜀2\tilde{\Theta}(\log n+1/\varepsilon^{2})over~ start_ARG roman_Θ end_ARG ( roman_log italic_n + 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) Θ⁢(log⁡log⁡n+log⁡ε−1)Θ𝑛superscript𝜀1\Theta(\log\log n+\log\varepsilon^{-1})roman_Θ ( roman_log roman_log italic_n + roman_log italic_ε start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) Θ⁢(log⁡n/ε2)Θ𝑛superscript𝜀2\Theta(\log n/\varepsilon^{2})roman_Θ ( roman_log italic_n / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) Θ~⁢(n1−2/p/ε2)~Θsuperscript𝑛12𝑝superscript𝜀2\tilde{\Theta}(n^{1-2/p}/\varepsilon^{2})over~ start_ARG roman_Θ end_ARG ( italic_n start_POSTSUPERSCRIPT 1 - 2 / italic_p end_POSTSUPERSCRIPT / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) Figure 1: Space complexity of Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation. We also extend our lower bound to the range p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ], which settles the space complexity of Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation for all values of p𝑝pitalic_p. See Figure 1 for a summary of the space complexity of Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation for all p≥0𝑝0p\geq 0italic_p ≥ 0. Theorem. Fix p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ]. Let 𝒜𝒜\mathcal{A}caligraphic_A be a streaming algorithm that gives an (1±ε)plus-or-minus1𝜀\left(1\pm\varepsilon\right)( 1 ± italic_ε ) approximation to the Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT of its input stream, for some ε∈(Ω⁢(n−1/p),4−1/(p−1))𝜀Ωsuperscript𝑛1𝑝superscript41𝑝1\varepsilon\in\left(\Omega\left(n^{-1/p}\right),{4^{-1/(p-1)}}\right)italic_ε ∈ ( roman_Ω ( italic_n start_POSTSUPERSCRIPT - 1 / italic_p end_POSTSUPERSCRIPT ) , 4 start_POSTSUPERSCRIPT - 1 / ( italic_p - 1 ) end_POSTSUPERSCRIPT ), and succeeds with probability ≥2/3absent23\geq 2/3≥ 2 / 3. Then, the space used by 𝒜𝒜\mathcal{A}caligraphic_A is Ω⁢(log⁡(ε1/p⁢n)/ε2)Ωsuperscript𝜀1𝑝𝑛superscript𝜀2\Omega\left(\log\left(\varepsilon^{1/p}n\right)/\varepsilon^{2}\right)roman_Ω ( roman_log ( italic_ε start_POSTSUPERSCRIPT 1 / italic_p end_POSTSUPERSCRIPT italic_n ) / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ). Most of the lower bounds for streaming problems are based on reductions from communication complexity. In [JW19], a natural barrier to prove a better than Ω~⁢(1/ε2)~Ω1superscript𝜀2\tilde{\Omega}(1/\varepsilon^{2})over~ start_ARG roman_Ω end_ARG ( 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) lower bound was shown: Even in a very strong model of communication, O⁢(1/ε2⋅(log⁡log⁡n+log⁡d+log⁡ε−1))𝑂⋅1superscript𝜀2𝑛𝑑superscript𝜀1O\left(1/\varepsilon^{2}\cdot\left(\log\log n+\log d+\log\varepsilon^{-1}% \right)\right)italic_O ( 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⋅ ( roman_log roman_log italic_n + roman_log italic_d + roman_log italic_ε start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) ) bits of communication suffice for the players to correctly produce a Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT estimation, where d𝑑ditalic_d is the diameter of the communication graph. This means that problems who reduce to Fpsubscript𝐹𝑝F_{p}italic_F start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT-estimation have a too low communication complexity to improve the existing lower bounds. To overcome this natural barrier, we present a new type of a direct sum theorem that takes place at the level of the streaming algorithm rather than the level of the communication model — informally, we pack many instances of problems with communication complexity Θ⁢(1/ε2)Θ1superscript𝜀2\Theta(1/\varepsilon^{2})roman_Θ ( 1 / italic_ε start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) into a single stream, and then directly show that a successful streaming algorithm must solve them all. In Section 2 we give a detailed high-level overview of our proofs. The lower bound is presented in Section 4 and Section 5, and then extended from p=2𝑝2p=2italic_p = 2 to p∈(1,2]𝑝12p\in(1,2]italic_p ∈ ( 1 , 2 ] in Section 5.3. The improved upper bound is presented in Section 6. We conclude and present remaining open problems in Section 7."
https://arxiv.org/html/2411.02087v2,"An Exponential Separation Between Quantum and Quantum-Inspired
Classical Algorithms for Machine Learning","Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task.In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms. We prove the separation for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.","Demonstrating an exponential quantum advantage for a relevant machine learning task has been an important research goal since the promising quantum algorithm by Harrow, Hassidim and Lloyd [12] for solving linear systems. Ignoring a few details, the HHL algorithm (and later improvements [4, 9]) generates a quantum state ∑i=1nxi⁢|i⟩superscriptsubscript𝑖1𝑛subscript𝑥𝑖ket𝑖\sum_{i=1}^{n}x_{i}|i\rangle∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_i ⟩ corresponding to the solution x=M−1⁢y𝑥superscript𝑀1𝑦x=M^{-1}yitalic_x = italic_M start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_y to an n×n𝑛𝑛n\times nitalic_n × italic_n linear system of equations M⁢x=y𝑀𝑥𝑦Mx=yitalic_M italic_x = italic_y in just poly⁡(ln⁡n)poly𝑛\operatorname{poly}(\ln n)roman_poly ( roman_ln italic_n ) time. At first sight, this seems exponentially faster than any classic algorithm, which probably has to read the entire input matrix M𝑀Mitalic_M to solve the same problem. However, as pointed out e.g. by Aaronson [1], the analysis of the HHL algorithm assumes the input matrix is given in a carefully chosen input format. Taking this state preparation into consideration, it was initially unclear how the performance could be compared to a classical algorithm and whether any quantum advantage remained. The shortcoming of the HHL algorithm regarding state preparation was later addressed in seminal work by Kerenedis and Prakash [14], who gave an end-to-end analysis (i.e. including state preparation) that can be directly compared to a classical algorithm. Concretely, their framework assumes that the input matrices and vectors to a linear algebraic machine learning problem are given as simple classical data structures, but with quantum access to the memory representations. At the time, their new quantum algorithm (for recommender systems) was exponentially faster than the best classical counterpart (which is given the same classical data structures as input). Their work sparked a fruitful line of research, yielding exponential speedups for a host of important machine learning tasks, including solving linear systems [6], linear regression [6], PCA [6], recommender systems [14], supervised clustering [15] and Hamiltonian simulation [10]. Despite the exponential speedups over classical algorithms, a lower bound for classical algorithms ruling out a similar improvement via new algorithmic ideas remained illusive. It turned out that this was for good reasons: In breakthrough work by Tang [20], it was demonstrated that on all inputs where the recommender systems algorithm by Kerenedis and Prakash yielded an exponential speedup, a similar speedup could be obtained via a classical algorithmic approach that she dubbed quantum-inspired classical (QIC) algorithms. Since then, almost all the initially exponential speedups from quantum algorithms have been reduced to mere polynomial speedups through the development of new efficient QIC algorithms, see e.g. [5, 7, 19]. The disheartening state-of-affairs is thus that only a few machine learning problems remain where there is still an exponential gap between quantum and QIC algorithms. Based on Tang’s work, it remains entirely plausible that new QIC algorithms may close these gaps as well. Our Contribution. In this work, we present the first provable exponential separation between quantum and quantum-inspired classical algorithms for a central machine learning problem. Concretely, we prove a lower bound for any QIC algorithm for solving linear systems with sparse rows and columns. The lower bound is exponentially higher than known quantum upper bounds [6] when the matrix is well-conditioned, thus establishing the separation. 1.1 Quantum-Inspired Classical Algorithms In the following, we formally introduce QIC algorithms, the linear system problem, our lower bound statement and previous work on proving separations between quantum and QIC algorithms. As mentioned earlier, the work by Kerenidis and Prakash [14] gave a rigorous framework for directly comparing a quantum algorithm for a machine learning task with a classical counterpart. Taking state preparation into account, they define a natural input format for matrices and vectors in linear algebraic problems. At a high level, they assume the input is presented as a classical binary tree based data structure over the entries of the rows and columns of a matrix. They then built their quantum recommender system algorithm assuming quantum access to the memory representation of this classical data structure. Follow-up works have used essentially the same input representation or equivalent formulations. In many cases, for sufficiently well-conditioned matrices, the obtained quantum algorithms run in just poly⁡(ln⁡n)poly𝑛\operatorname{poly}(\ln n)roman_poly ( roman_ln italic_n ) time. Now to prove a separation between quantum and classical algorithms, any fair comparison should use the same input representation. Given the simplicity of the data structure by Kerenidis and Prakash for representing the input, it seemed reasonable to conjecture that any classical algorithm for e.g. recommender systems would need polynomial time even when given this data structure. This intuition was however proven false by Tang [20]. Her key insight was that the classical data structure allows efficient classical (i.e. poly⁡(ln⁡n)poly𝑛\operatorname{poly}(\ln n)roman_poly ( roman_ln italic_n ) time) ℓ22superscriptsubscriptℓ22\ell_{2}^{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT sampling (formally defined below) from the rows and columns of the input, as well as efficient reading of individual entries. Exploiting this sampling access, she gave a classical algorithm for recommender systems that runs in just poly⁡(ln⁡n)poly𝑛\operatorname{poly}(\ln n)roman_poly ( roman_ln italic_n ) time on all matrices where the quantum algorithm by Kerenidis and Prakash does. She referred to such classical algorithms with ℓ22superscriptsubscriptℓ22\ell_{2}^{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT sampling access to input matrices and vectors as quantum-inspired classical algorithms. This sampling access has since then proved extremely useful in other machine learning tasks, see e.g. [5, 7, 19]. Tang [20] summarized the above discussion as follows: “when quantum machine learning algorithms are compared to classical machine learning algorithms in the context of finding speedups, any state preparation assumptions in the quantum machine learning model should be matched with ℓ22superscriptsubscriptℓ22\ell_{2}^{2}roman_ℓ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT-norm sampling assumptions in the classical machine learning model’’. Using the notation of Mande and Shao [17], QIC algorithms formally have the following access to the input: Definition 1 (Query Access). For a vector v∈ℝn𝑣superscriptℝ𝑛v\in\mathbb{R}^{n}italic_v ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we have Q⁢(v)𝑄𝑣Q(v)italic_Q ( italic_v ), query access to v𝑣vitalic_v, if for all i𝑖iitalic_i, we can query visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. Likewise for a matrix M∈ℝm×n𝑀superscriptℝ𝑚𝑛M\in\mathbb{R}^{m\times n}italic_M ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_n end_POSTSUPERSCRIPT, we have query access to M𝑀Mitalic_M if for all (i,j)∈[m]×[n]𝑖𝑗delimited-[]𝑚delimited-[]𝑛(i,j)\in[m]\times[n]( italic_i , italic_j ) ∈ [ italic_m ] × [ italic_n ], we can query Mi,jsubscript𝑀𝑖𝑗M_{i,j}italic_M start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT. Definition 2 (Sampling and Query Access to a Vector). For a vector v∈ℝn𝑣superscriptℝ𝑛v\in\mathbb{R}^{n}italic_v ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we have S⁢Q⁢(v)𝑆𝑄𝑣SQ(v)italic_S italic_Q ( italic_v ), sampling and query access to v𝑣vitalic_v, if we can • Query for entries of v𝑣vitalic_v as in Q⁢(v)𝑄𝑣Q(v)italic_Q ( italic_v ). • Obtain independent samples of indices i∈[n]𝑖delimited-[]𝑛i\in[n]italic_i ∈ [ italic_n ], each distributed as ℙ⁢[i]=vi2/‖v‖2ℙdelimited-[]𝑖superscriptsubscript𝑣𝑖2superscriptnorm𝑣2\mathbb{P}[i]=v_{i}^{2}/\|v\|^{2}blackboard_P [ italic_i ] = italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ∥ italic_v ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. • Query for ‖v‖norm𝑣\|v\|∥ italic_v ∥. Definition 3 (Sampling and Query Access to a Matrix). For a matrix M∈ℝm×n𝑀superscriptℝ𝑚𝑛M\in\mathbb{R}^{m\times n}italic_M ∈ blackboard_R start_POSTSUPERSCRIPT italic_m × italic_n end_POSTSUPERSCRIPT, we have S⁢Q⁢(M)𝑆𝑄𝑀SQ(M)italic_S italic_Q ( italic_M ) if we have S⁢Q⁢(Mi,⋆)𝑆𝑄subscript𝑀𝑖⋆SQ(M_{i,\star})italic_S italic_Q ( italic_M start_POSTSUBSCRIPT italic_i , ⋆ end_POSTSUBSCRIPT ), S⁢Q⁢(M⋆,j)𝑆𝑄subscript𝑀⋆𝑗SQ(M_{\star,j})italic_S italic_Q ( italic_M start_POSTSUBSCRIPT ⋆ , italic_j end_POSTSUBSCRIPT ), S⁢Q⁢(r)𝑆𝑄𝑟SQ(r)italic_S italic_Q ( italic_r ) and S⁢Q⁢(c)𝑆𝑄𝑐SQ(c)italic_S italic_Q ( italic_c ) for all i∈m𝑖𝑚i\in mitalic_i ∈ italic_m and j∈n𝑗𝑛j\in nitalic_j ∈ italic_n where r⁢(M)=(‖M1,⋆‖,…,‖Mm,⋆‖)𝑟𝑀normsubscript𝑀1⋆…normsubscript𝑀𝑚⋆r(M)=(\|M_{1,\star}\|,\dots,\|M_{m,\star}\|)italic_r ( italic_M ) = ( ∥ italic_M start_POSTSUBSCRIPT 1 , ⋆ end_POSTSUBSCRIPT ∥ , … , ∥ italic_M start_POSTSUBSCRIPT italic_m , ⋆ end_POSTSUBSCRIPT ∥ ) and c⁢(M)=(‖M⋆,1‖,…,‖M⋆,n‖)𝑐𝑀normsubscript𝑀⋆1…normsubscript𝑀⋆𝑛c(M)=(\|M_{\star,1}\|,\dots,\|M_{\star,n}\|)italic_c ( italic_M ) = ( ∥ italic_M start_POSTSUBSCRIPT ⋆ , 1 end_POSTSUBSCRIPT ∥ , … , ∥ italic_M start_POSTSUBSCRIPT ⋆ , italic_n end_POSTSUBSCRIPT ∥ ). Here Mi,⋆subscript𝑀𝑖⋆M_{i,\star}italic_M start_POSTSUBSCRIPT italic_i , ⋆ end_POSTSUBSCRIPT is the i𝑖iitalic_i’th row of M𝑀Mitalic_M, M⋆,jsubscript𝑀⋆𝑗M_{\star,j}italic_M start_POSTSUBSCRIPT ⋆ , italic_j end_POSTSUBSCRIPT is the j𝑗jitalic_j’th column, r⁢(M)𝑟𝑀r(M)italic_r ( italic_M ) is the vector of row-norms and c⁢(M)𝑐𝑀c(M)italic_c ( italic_M ) is the vector of column-norms of M𝑀Mitalic_M. With the input representation defined, we proceed to present the problem of solving a linear system via a QIC algorithm. Here one again needs to be careful for a fair comparison between quantum and QIC algorithms. Concretely, the known quantum algorithms for solving a linear system M⁢x=y𝑀𝑥𝑦Mx=yitalic_M italic_x = italic_y do not output the full solution x𝑥xitalic_x (which would take linear time), but instead a quantum state ∑ix~i⁢|i⟩subscript𝑖subscript~𝑥𝑖ket𝑖\sum_{i}\tilde{x}_{i}|i\rangle∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_i ⟩ for a x~~𝑥\tilde{x}over~ start_ARG italic_x end_ARG approximating the solution x𝑥xitalic_x. Taking measurements on such a state allows one to sample an index i𝑖iitalic_i with probability x~i2/‖x~‖2superscriptsubscript~𝑥𝑖2superscriptnorm~𝑥2\tilde{x}_{i}^{2}/\|\tilde{x}\|^{2}over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ∥ over~ start_ARG italic_x end_ARG ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT. With this in mind, the classical analog of solving a linear system is as follows. Problem 1 (Linear Systems). Given S⁢Q⁢(M)𝑆𝑄𝑀SQ(M)italic_S italic_Q ( italic_M ) and S⁢Q⁢(y)𝑆𝑄𝑦SQ(y)italic_S italic_Q ( italic_y ) for a symmetric and real matrix M∈ℝn×n𝑀superscriptℝ𝑛𝑛M\in\mathbb{R}^{n\times n}italic_M ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT of full rank, a vector y∈ℝn𝑦superscriptℝ𝑛y\in\mathbb{R}^{n}italic_y ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and precision ε>0𝜀0\varepsilon>0italic_ε > 0, the Linear Systems problem is to support sampling an index i𝑖iitalic_i with probability x~i2/‖x~‖2superscriptsubscript~𝑥𝑖2superscriptnorm~𝑥2\tilde{x}_{i}^{2}/\|\tilde{x}\|^{2}over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ∥ over~ start_ARG italic_x end_ARG ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT from a vector x~~𝑥\tilde{x}over~ start_ARG italic_x end_ARG satisfying that ‖x~−x‖≤ε⁢‖x‖norm~𝑥𝑥𝜀norm𝑥\|\tilde{x}-x\|\leq\varepsilon\|x\|∥ over~ start_ARG italic_x end_ARG - italic_x ∥ ≤ italic_ε ∥ italic_x ∥ where x=M−1⁢y𝑥superscript𝑀1𝑦x=M^{-1}yitalic_x = italic_M start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_y is the solution to the linear system of equations M⁢x=y𝑀𝑥𝑦Mx=yitalic_M italic_x = italic_y. The query complexity of a QIC algorithm for solving a linear system, is the number of queries to S⁢Q⁢(M)𝑆𝑄𝑀SQ(M)italic_S italic_Q ( italic_M ) and S⁢Q⁢(y)𝑆𝑄𝑦SQ(y)italic_S italic_Q ( italic_y ) necessary to sample one index i𝑖iitalic_i from x~~𝑥\tilde{x}over~ start_ARG italic_x end_ARG. We remark that the known QIC algorithms furthermore output the value x~isubscript~𝑥𝑖\tilde{x}_{i}over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT upon sampling i𝑖iitalic_i. Since we aim to prove a lower bound, our results are only stronger if we prove it for merely sampling i𝑖iitalic_i. Quantum Benchmark. To prove our exponential separation, we first present the state-of-the-art performance of quantum algorithms for linear systems. Here we focus on the case where the input matrix M𝑀Mitalic_M has sparse rows and columns, i.e. every row and column has at most s𝑠sitalic_s non-zero entries. The running time of the best known quantum algorithm depends on the condition number of M𝑀Mitalic_M, defined as κ=σmax/σmin.𝜅subscript𝜎subscript𝜎\kappa=\sigma_{\max}/\sigma_{\min}.italic_κ = italic_σ start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT / italic_σ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT . Here σmaxsubscript𝜎\sigma_{\max}italic_σ start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the largest singular value of M𝑀Mitalic_M and σminsubscript𝜎\sigma_{\min}italic_σ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT is the smallest singular value. Note that for real symmetric M𝑀Mitalic_M of full rank, all eigenvalues λ1≥⋯≥λnsubscript𝜆1⋯subscript𝜆𝑛\lambda_{1}\geq\cdots\geq\lambda_{n}italic_λ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≥ ⋯ ≥ italic_λ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT of M𝑀Mitalic_M are real and non-zero, and the singular values σmax=σ1≥⋯≥σn=σmin>0subscript𝜎subscript𝜎1⋯subscript𝜎𝑛subscript𝜎0\sigma_{\max}=\sigma_{1}\geq\cdots\geq\sigma_{n}=\sigma_{\min}>0italic_σ start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT = italic_σ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≥ ⋯ ≥ italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = italic_σ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT > 0 are the absolute values of the eigenvalues {|λi|}i=1nsuperscriptsubscriptsubscript𝜆𝑖𝑖1𝑛\{|\lambda_{i}|\}_{i=1}^{n}{ | italic_λ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT in sorted order. Given a precision ε>0𝜀0\varepsilon>0italic_ε > 0, matrix M𝑀Mitalic_M and vector y𝑦yitalic_y as input (in the classical data structure format), the quantum algorithm by Chakraborty, Gilyén and Jeffery [6] runs in time poly⁡(s,κ,ln⁡(1/ε),ln⁡n)poly𝑠𝜅1𝜀𝑛\displaystyle\operatorname{poly}(s,\kappa,\ln(1/\varepsilon),\ln n)roman_poly ( italic_s , italic_κ , roman_ln ( 1 / italic_ε ) , roman_ln italic_n ) (1) to produce a quantum state ∑ix~i⁢|i⟩subscript𝑖subscript~𝑥𝑖ket𝑖\sum_{i}\tilde{x}_{i}|i\rangle∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT over~ start_ARG italic_x end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_i ⟩ for a x~~𝑥\tilde{x}over~ start_ARG italic_x end_ARG with ‖x~−x‖≤ε⁢‖x‖norm~𝑥𝑥𝜀norm𝑥\|\tilde{x}-x\|\leq\varepsilon\|x\|∥ over~ start_ARG italic_x end_ARG - italic_x ∥ ≤ italic_ε ∥ italic_x ∥ with x=M−1⁢y𝑥superscript𝑀1𝑦x=M^{-1}yitalic_x = italic_M start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT italic_y. We remark that to derive (1) from [6], one invokes their Lemma 11 (originating in [11]) to obtain a block-encoding of a sparse matrix and then invoke their Theorem 30. See also the recent work [16]. QIC Benchmark. The best QIC algorithm [19] for sparse linear systems instead has a query complexity (and running time) of poly⁡(s,κF,ln⁡(1/ε),ln⁡n),poly𝑠subscript𝜅𝐹1𝜀𝑛\displaystyle\operatorname{poly}(s,\kappa_{F},\ln(1/\varepsilon),\ln n),roman_poly ( italic_s , italic_κ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT , roman_ln ( 1 / italic_ε ) , roman_ln italic_n ) , (2) where κF=‖M‖F/σmin=∑iσi2σmin.subscript𝜅𝐹subscriptnorm𝑀𝐹subscript𝜎subscript𝑖superscriptsubscript𝜎𝑖2subscript𝜎\kappa_{F}=\|M\|_{F}/\sigma_{\min}=\frac{\sqrt{\sum_{i}\sigma_{i}^{2}}}{\sigma% _{\min}}.italic_κ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT = ∥ italic_M ∥ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT / italic_σ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT = divide start_ARG square-root start_ARG ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG end_ARG start_ARG italic_σ start_POSTSUBSCRIPT roman_min end_POSTSUBSCRIPT end_ARG . Since κFsubscript𝜅𝐹\kappa_{F}italic_κ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT may be larger than κ𝜅\kappaitalic_κ by as much as a n𝑛\sqrt{n}square-root start_ARG italic_n end_ARG factor, there are thus matrices with κ,s=poly⁡(ln⁡n)𝜅𝑠poly𝑛\kappa,s=\operatorname{poly}(\ln n)italic_κ , italic_s = roman_poly ( roman_ln italic_n ) where there is an exponential gap between (1) and (2). However, proving that a QIC algorithm with a performance matching (1) cannot be developed has so far remained out of reach. Our Result. We show the following strong lower bound for QIC algorithms Theorem 1. There is a constant c>0𝑐0c>0italic_c > 0, such that for n≥c𝑛𝑐n\geq citalic_n ≥ italic_c and any precision ε≤(c⁢ln2.5⁡n)−1𝜀superscript𝑐superscript2.5𝑛1\varepsilon\leq(c\ln^{2.5}n)^{-1}italic_ε ≤ ( italic_c roman_ln start_POSTSUPERSCRIPT 2.5 end_POSTSUPERSCRIPT italic_n ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT, it holds that for any QIC algorithm 𝒜𝒜\mathcal{A}caligraphic_A for linear systems, there exists a full rank n×n𝑛𝑛n\times nitalic_n × italic_n symmetric real matrix M𝑀Mitalic_M with condition number κ≤c⁢ln2⁡n𝜅𝑐superscript2𝑛\kappa\leq c\ln^{2}nitalic_κ ≤ italic_c roman_ln start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_n and 4444-sparse rows and columns, such that 𝒜𝒜\mathcal{A}caligraphic_A must make Ω⁢(n1/12)Ωsuperscript𝑛112\Omega(n^{1/12})roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / 12 end_POSTSUPERSCRIPT ) queries to S⁢Q⁢(M)𝑆𝑄𝑀SQ(M)italic_S italic_Q ( italic_M ) on the linear system M⁢x=e1𝑀𝑥subscript𝑒1Mx=e_{1}italic_M italic_x = italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Observe that the complexity of the best quantum algorithm (1) for this setting of s,κ𝑠𝜅s,\kappaitalic_s , italic_κ and ε𝜀\varepsilonitalic_ε is just poly⁡(ln⁡n)poly𝑛\operatorname{poly}(\ln n)roman_poly ( roman_ln italic_n ), hence the claimed exponential separation. Furthermore, the matrix M𝑀Mitalic_M is extremely sparse, with only s=4𝑠4s=4italic_s = 4 non-zeroes per row and column, and the vector y𝑦yitalic_y in the linear system M⁢x=y𝑀𝑥𝑦Mx=yitalic_M italic_x = italic_y is simply the first standard unit vector e1subscript𝑒1e_{1}italic_e start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Previous Separations. Finally, let us mention recent work by Mande and Shao [17] that also focuses on separating quantum and QIC algorithms. Using reductions from number-in-hand multiparty communication complexity [18], they prove a number of lower bounds for QIC algorithms for linear regression, supervised clustering, PCA, recommender systems and Hamiltonian simulation. Their lower bounds are of the form Ω~⁢(κF2)~Ωsuperscriptsubscript𝜅𝐹2\tilde{\Omega}(\kappa_{F}^{2})over~ start_ARG roman_Ω end_ARG ( italic_κ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ), but only for problems where the best known quantum algorithms are no better than O~⁢(κF)~𝑂subscript𝜅𝐹\tilde{O}(\kappa_{F})over~ start_ARG italic_O end_ARG ( italic_κ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ), thus establishing quadratic separations compared to our exponential separation. Let us also remark that our lower bound proof takes a completely different approach, instead reducing from a problem of random walks by Childs et al. [8]."
https://arxiv.org/html/2411.01992v1,"Ask, and it shall be given: Turing completeness of prompting","Since the success of GPT, large language models (LLMs) have been revolutionizing machine learning and have initiated the so-called LLM prompting paradigm. In the era of LLMs, people train a single general-purpose LLM and provide the LLM with different prompts to perform different tasks. However, such empirical success largely lacks theoretical understanding. Here, we present the first theoretical study on the LLM prompting paradigm to the best of our knowledge. In this work, we show that prompting is in fact Turing-complete: there exists a finite-size Transformer such that for any computable function, there exists a corresponding prompt following which the Transformer computes the function. Furthermore, we show that even though we use only a single finite-size Transformer, it can still achieve nearly the same complexity bounds as that of the class of all unbounded-size Transformers. Overall, our result reveals that prompting can enable a single finite-size Transformer to be efficiently universal, which establishes a theoretical underpinning for prompt engineering in practice.","The mainstream architecture of large language models (LLMs; e.g., OpenAI, 2024; Anthropic, 2024; Meta, 2024; Google, 2024) is Transformers (Vaswani et al., 2017). There has been a series of theoretical studies on Transformers under realistic abstractions (Pérez et al., 2019; Bhattamishra et al., 2020; Hahn, 2020; Pérez et al., 2021; Hao et al., 2022; Liu et al., 2023a; Chiang et al., 2023; Merrill & Sabharwal, 2023; Roberts, 2023; Merrill & Sabharwal, 2024a; b; Hou et al., 2024; Li et al., 2024). For example, Pérez et al. (2021) have shown that the class of all Transformers with hardmaxhardmax\operatorname{hardmax}roman_hardmax attention is Turing-complete: for any computable function φ∈𝖳𝖨𝖬𝖤1⁢(t⁢(n))𝜑subscript𝖳𝖨𝖬𝖤1𝑡𝑛\varphi\in\mathsf{TIME}_{1}(t(n))italic_φ ∈ sansserif_TIME start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_t ( italic_n ) ), there exists a Transformer that computes φ𝜑\varphiitalic_φ using O⁢(t⁢(n))O𝑡𝑛\mathrm{O}(t(n))roman_O ( italic_t ( italic_n ) ) chain-of-thought (CoT; Wei et al., 2022b) steps and O⁢(log⁡(n+t⁢(n)))O𝑛𝑡𝑛\mathrm{O}(\log(n+t(n)))roman_O ( roman_log ( italic_n + italic_t ( italic_n ) ) ) precision on length-n𝑛nitalic_n inputs; Merrill & Sabharwal (2024a) have later improved the CoT complexity to O⁢(t⁢(n))O𝑡𝑛\mathrm{O}(t(n))roman_O ( italic_t ( italic_n ) ) for 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) functions. These works have finely characterized the capacities and limits of Transformers under the classic one-model-one-task paradigm. Nevertheless, existing theoretical studies fail to align with the LLM prompting practice, i.e., the one-model-many-tasks paradigm. In the era of LLMs, people train a single general-purpose LLM and provide the LLM with different prompts to perform different tasks. Since the success of GPT (Brown et al., 2020), the LLM prompting paradigm has revolutionized machine learning (Liu et al., 2023b). For example, a bonus capability arising from prompting is zero-shot learning (Wei et al., 2022a): when provided with suitable prompts, LLMs can even perform novel tasks that are not present in their training corpora. Such empirical success calls for a theoretical understanding of the LLM prompting paradigm: Fundamentally, how powerful is the LLM prompting paradigm? We answer this call and present the first theory on the LLM prompting paradigm to the best of our knowledge. In this work, we show that prompting is in fact Turing-complete: there exists a finite-size Transformer such that for any computable function, there exists a corresponding prompt following which the Transformer computes the function. Furthermore, we show that prompting is not only universal but also efficiently universal: even though we only use a single finite-size Transformer, it can still achieve nearly the same complexity bounds as that of the class of all unbounded-size Transformers. Main contributions. Our main contributions are informally stated as follows: • Expressive power. We show that prompting is Turing-complete: there exists a finite-size Transformer ΓΓ\varGammaroman_Γ such that for any computable function φ𝜑\varphiitalic_φ, there exists a finite prompt 𝝅φsubscript𝝅𝜑\boldsymbol{\pi}_{\varphi}bold_italic_π start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT such that for any input 𝒙𝒙\boldsymbol{x}bold_italic_x, the Transformer ΓΓ\varGammaroman_Γ computes φ⁢(𝒙)𝜑𝒙\varphi(\boldsymbol{x})italic_φ ( bold_italic_x ) following the prompt 𝝅φsubscript𝝅𝜑\boldsymbol{\pi}_{\varphi}bold_italic_π start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT. Importantly, our constructed Transformer ΓΓ\varGammaroman_Γ is independent of the function φ𝜑\varphiitalic_φ, the prompt 𝝅φsubscript𝝅𝜑\boldsymbol{\pi}_{\varphi}bold_italic_π start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT is independent of the input 𝒙𝒙\boldsymbol{x}bold_italic_x, and the input 𝒙𝒙\boldsymbol{x}bold_italic_x can be arbitrarily long. • CoT complexity. Our ΓΓ\varGammaroman_Γ can compute any 𝖳𝖨𝖬𝖤2⁢(t⁢(n))subscript𝖳𝖨𝖬𝖤2𝑡𝑛\mathsf{TIME}_{2}(t(n))sansserif_TIME start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_t ( italic_n ) ) function within O⁢(t⁢(n))O𝑡𝑛\mathrm{O}(t(n))roman_O ( italic_t ( italic_n ) ) CoT steps and can compute any 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) function within O⁢(t⁢(n)⁢log⁡t⁢(n))O𝑡𝑛𝑡𝑛\mathrm{O}(t(n)\log t(n))roman_O ( italic_t ( italic_n ) roman_log italic_t ( italic_n ) ) CoT steps for any length-n𝑛nitalic_n input. Notably, our result shows that even a single Transformer can still achieve nearly the same CoT complexity as the class of all Transformers does. • Precision complexity. Our constructed ΓΓ\varGammaroman_Γ can compute any 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) function within O⁢(log⁡(n+t⁢(n)))O𝑛𝑡𝑛\mathrm{O}(\log(n+t(n)))roman_O ( roman_log ( italic_n + italic_t ( italic_n ) ) ) bits of precision for any length-n𝑛nitalic_n input. Notably, our result shows that even a single Transformer can still achieve the same precision complexity as the class of all Transformers does. In particular, ΓΓ\varGammaroman_Γ can decide any 𝖯𝖯\mathsf{P}sansserif_P language within log-precision. 1.1 Related work Existing theoretical studies on Transformers fall under the classic one-model-one-task paradigm: they need to construct different Transformers for different tasks. There are two lines of related work: (i) when at most O⁢(1)O1\mathrm{O}(1)roman_O ( 1 ) CoT steps are allowed, it has been shown that Transformers are capable but far from Turing-complete (Hahn, 2020; Hao et al., 2022; Liu et al., 2023a; Chiang et al., 2023; Merrill & Sabharwal, 2023; 2024b); (ii) when more CoT steps are allowed, it has been shown that the expressive power of Transformers increases with the number of CoT steps (Pérez et al., 2019; Bhattamishra et al., 2020; Pérez et al., 2021; Roberts, 2023; Merrill & Sabharwal, 2024a; Hou et al., 2024; Li et al., 2024). Besides that, there have recently been studies on the learnability (Malach, 2023; Grau-Moya et al., 2024) and the in-context learning capability (Akyürek et al., 2022; von Oswald et al., 2023; Zhang et al., 2024; Ahn et al., 2024; Vladymyrov et al., 2024). Nevertheless, no existing work studies the LLM prompting paradigm (i.e., the one-model-many-tasks paradigm). Our work is the first to bridge this gap to the best of our knowledge. 1.2 Technical overview A core step of our proof is to construct a new model of computation (called 2222-PTMs) that can be easily encoded into a prompt using a finite alphabet. Furthermore, we show that 2222-PTMs are not only Turing-complete but also nearly as efficient as Turing machines. Theorem (informal version of Theorem 4.1). Any 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) function can be computed by a 2222-PTM within O⁢(t⁢(n)⁢log⁡t⁢(n))O𝑡𝑛𝑡𝑛\mathrm{O}(t(n)\log t(n))roman_O ( italic_t ( italic_n ) roman_log italic_t ( italic_n ) ) steps. ∎ Given any computable function φ𝜑\varphiitalic_φ, we encode its 2222-PTM into a prompt 𝝅φsubscript𝝅𝜑\boldsymbol{\pi}_{\varphi}bold_italic_π start_POSTSUBSCRIPT italic_φ end_POSTSUBSCRIPT. Then, it remains to construct a Transformer ΓΓ\varGammaroman_Γ that can execute 2222-PTMs. Since it is known that Transformers without CoTs are not universal (Hahn, 2020), the Transformer ΓΓ\varGammaroman_Γ needs to use CoT steps to execute 2222-PTMs. Specifically, we use CoT steps to record the execution steps of the 2222-PTM so that the Transformer can restore the state of the 2222-PTM at any step. This establishes the CoT complexity of ΓΓ\varGammaroman_Γ. Corollary (informal version of Corollary 4.5). Our constructed ΓΓ\varGammaroman_Γ can compute any 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) function within O⁢(t⁢(n)⁢log⁡t⁢(n))O𝑡𝑛𝑡𝑛\mathrm{O}(t(n)\log t(n))roman_O ( italic_t ( italic_n ) roman_log italic_t ( italic_n ) ) CoT steps. To incorporate input 𝒙𝒙\boldsymbol{x}bold_italic_x into computation, we use O⁢(|𝒙|)O𝒙\mathrm{O}(|\boldsymbol{x}|)roman_O ( | bold_italic_x | ) CoT steps to emulate an imaginary process of writing the input 𝒙𝒙\boldsymbol{x}bold_italic_x onto a tape of the 2222-PTM. This implies the precision complexity of ΓΓ\varGammaroman_Γ. Corollary (informal version of Corollary 4.7). Our constructed ΓΓ\varGammaroman_Γ can compute any 𝖳𝖨𝖬𝖤⁢(t⁢(n))𝖳𝖨𝖬𝖤𝑡𝑛\mathsf{TIME}(t(n))sansserif_TIME ( italic_t ( italic_n ) ) function within O⁢(log⁡(n+t⁢(n)))O𝑛𝑡𝑛\mathrm{O}(\log(n+t(n)))roman_O ( roman_log ( italic_n + italic_t ( italic_n ) ) ) bits of precision. Finally, we construct a decoder-only Transformer that achieves the desiderata above by leveraging ReLU activation, layer normalization, and causal attention."
https://arxiv.org/html/2411.01718v1,Toward Separating QMA from QCMA with a Classical Oracle,"QMA is the class of languages that can be decided by an efficient quantum verifier given a quantum witness, whereas QCMA is the class of such languages where the efficient quantum verifier only is given a classical witness. A challenging fundamental goal in quantum query complexity is to find a classical oracle separation for these classes. In this work, we offer a new approach towards proving such a separation that is qualitatively different than prior work, and show that our approach is sound assuming a natural statistical conjecture which may have other applications to quantum query complexity lower bounds.","Do quantum witnesses offer more power than classical witnesses? Slightly more precisely, there are two natural ways to generalize 𝖭𝖯𝖭𝖯{\sf NP}sansserif_NP from the classical setting to the quantum setting: 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA (for Quantum Merlin-Arthur) is the set of languages decidable by efficient quantum algorithms with quantum witnesses, whereas 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA (for Quantum Classical Merlin-Arthur) is the set of languages decidable by efficient quantum algorithms with classical witnesses. A long-standing fundamental question, first raised by [AN02], is whether or not these two generalizations of 𝖭𝖯𝖭𝖯{\sf NP}sansserif_NP are the same. As an unconditional separation between 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA and 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA is out of reach given the state of complexity theory, the community has focused on proving oracle separations. The first such separation [AK07] gives a quantum oracle; that is, an oracle that implements a unitary operation and which can be queried on quantum states. A major open question has been whether there is a classical oracle separation; that is, an oracle that implements a classical function, but is accessible in superposition. Classical oracle separations are considered more standard in the community. An early candidate classical oracle separation was given by [Lut11], but no proof was given. More recently, there have been several results making progress towards this goal by proving separations under different restrictions on how the oracle is accessed. [FK18] show a separation assuming the classical oracle is an “in-place permutation oracle”, a non-standard modeling where the oracle irreversibly permutes the input state. [NN23] show a separation, assuming the witness is required to be independent of certain choices made in constructing the oracle. A very recent line of work has used quantum advantage relative to unstructured oracles [YZ22] to separate 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA from 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA: [Liu23, LLPY24] give a separation assuming the verifier can only make classical oracle queries, and more recently [BDK24] give a separation which allows the verifier quantum queries, but assumes the adaptivity of the queries is sub-logarithmic. A standard classical oracle separation that makes no constraints on how the oracle is accessed or how the witness is created still remains open. The central challenge in separating 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA from 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA relative to a classical oracle seems to be the following. Consider a language in 𝖰𝖬𝖠∖𝖰𝖢𝖬𝖠𝖰𝖬𝖠𝖰𝖢𝖬𝖠{\sf QMA}\setminus{\sf QCMA}sansserif_QMA ∖ sansserif_QCMA, and consider measuring the 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA witness in the computational basis. The resulting classical string must not be accepted by the 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA verifier, since otherwise we would then have a classical witness for the language, putting it in 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA. Therefore, in some sense, the 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA verifier needs to verify that the witness is in superposition. In order to allow for such verification using only a classical oracle, existing approaches require highly structured oracles. But then to actually prove the language is outside of 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA, we need a quantum query complexity lower-bound, and unfortunately the techniques we have are often not amenable to highly structured oracles. Additionally, any witness would naturally be treated as a form of oracle-dependent advice about the oracle, and most quantum query complexity techniques are not very good at distinguishing between quantum advice and classical advice. In other words, if a typical technique succeeded at proving a language is outside of 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA, then if it cannot distinguish quantum vs classical advice, it would likely also show that the language is outside 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA as well, thus failing to give a separation. Our Work. We give a new approach for separating 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA from 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA relative to a classical oracle. Like prior work, we are unable to prove our oracle separation unconditionally. However, our separation appears much less structured than the prior work (though this is an intuitive statement rather than a formal one), and appears much more amenable to existing quantum query complexity techniques. In particular, we prove under a natural conjecture about k𝑘kitalic_k-wise independent distributions that our separation indeed works. We believe our work adds to the evidence that 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA and 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA are indeed distinct relative to classical oracles, and may offer a new path toward a proof. 1.1 Our Separating Oracles Our basic idea is the following. An instance in our language will correspond to a subset S⊆[N]𝑆delimited-[]𝑁S\subseteq[N]italic_S ⊆ [ italic_N ] where N𝑁Nitalic_N is exponentially-sized. S𝑆Sitalic_S will be chosen to only contain a negligible fraction of [N]delimited-[]𝑁[N][ italic_N ], but still be super-polynomial sized. We will provide a classical oracle (accessible in superposition) that decides membership in S𝑆Sitalic_S. We will often simply call this oracle S𝑆Sitalic_S. Next, we choose a random state |ψ⟩=∑y∈Sαy⁢|y⟩ket𝜓subscript𝑦𝑆subscript𝛼𝑦ket𝑦|\psi\rangle=\sum_{y\in S}\alpha_{y}|y\rangle| italic_ψ ⟩ = ∑ start_POSTSUBSCRIPT italic_y ∈ italic_S end_POSTSUBSCRIPT italic_α start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT | italic_y ⟩ with support on the set S𝑆Sitalic_S. The state |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ will be our witness state for the 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA instance. An incomplete verification for |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ proceeds by simply checking that |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ has support contained in S𝑆Sitalic_S. Essentially, |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ is acting as a 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA witness that S𝑆Sitalic_S is non-empty. But there is also a simple 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA witness for this fact: any classical value y∈S𝑦𝑆y\in Sitalic_y ∈ italic_S. We will instead attempt to turn |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ into a witness that S𝑆Sitalic_S is super-polynomial sized. To do so, we will add a second oracle U𝑈Uitalic_U which essentially attests to |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ being a superposition over super-polynomially-many points. Intuitively, we want to show that U𝑈Uitalic_U can distinguish between |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ and any state whose support is only polynomial-sized. To construct U𝑈Uitalic_U, let |ψ^⟩ket^𝜓|\hat{\psi}\rangle| over^ start_ARG italic_ψ end_ARG ⟩ denote the quantum Fourier transform (QFT) of |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩. We observe that if |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ has support on a single point y𝑦yitalic_y, then |ψ^⟩ket^𝜓|\hat{\psi}\rangle| over^ start_ARG italic_ψ end_ARG ⟩ will have uniform amplitude on all points in [N]delimited-[]𝑁[N][ italic_N ] (though with complex phases on these points). On the other hand, for random |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ with support on the large set S𝑆Sitalic_S, the amplitudes on different points will vary. Concretely, while the expected squared-amplitude on any point z∈[N]𝑧delimited-[]𝑁z\in[N]italic_z ∈ [ italic_N ] is 1/N1𝑁1/N1 / italic_N, there is a reasonable chance that it could be, say, smaller than 1/2⁢N12𝑁1/2N1 / 2 italic_N or larger than 2/N2𝑁2/N2 / italic_N. We will choose U𝑈Uitalic_U to be a subset of [N]delimited-[]𝑁[N][ italic_N ] consisting of points where |ψ^⟩ket^𝜓|\hat{\psi}\rangle| over^ start_ARG italic_ψ end_ARG ⟩ has squared-amplitude somewhat larger than 1/N1𝑁1/N1 / italic_N. We can then have, say, the total squared-amplitude of |ψ^⟩ket^𝜓|\hat{\psi}\rangle| over^ start_ARG italic_ψ end_ARG ⟩ on points in U𝑈Uitalic_U be roughly 3/4343/43 / 4 while |U|/N𝑈𝑁|U|/N| italic_U | / italic_N is only roughly 1/2121/21 / 2. In this case, the QFT of a classical string y𝑦yitalic_y will have squared-amplitude on U𝑈Uitalic_U of only 1/2121/21 / 2. Thus, U𝑈Uitalic_U enables distinguishing |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ from a classical input. We will therefore give out an oracle for deciding membership in U𝑈Uitalic_U. The verifier will first confirm that |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ has support only on S𝑆Sitalic_S using the oracle for S𝑆Sitalic_S. Then it will compute |ψ^⟩ket^𝜓|\hat{\psi}\rangle| over^ start_ARG italic_ψ end_ARG ⟩ via the QFT, and check that the support is in U𝑈Uitalic_U. Overall the verifier accepts with probability 3/4343/43 / 4. Instances not in the language will consist of S,U𝑆𝑈S,Uitalic_S , italic_U pairs where S𝑆Sitalic_S is very small but non-empty. We show that, for a certain way of choosing U𝑈Uitalic_U, that there is no 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA witness in the case of such small S𝑆Sitalic_S. Thus, our language is in 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA relative to the oracles for S,U𝑆𝑈S,Uitalic_S , italic_U. 1.2 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA hardness We now need a way to argue that our language does not have 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA witnesses. While we showed that a classical string y∈S𝑦𝑆y\in Sitalic_y ∈ italic_S cannot serve as a witness, this alone does not preclude some more clever way of attesting to S𝑆Sitalic_S being large. In particular, the witness w𝑤witalic_w could contain several points in S𝑆Sitalic_S. Worse, perhaps queries to U𝑈Uitalic_U may reveal a significant amount of information about S𝑆Sitalic_S, which may help deciding if S𝑆Sitalic_S is large or small. We make progress toward showing 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA hardness of our oracle problem, as we now describe. Consider a hypothetical 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA verifier V𝑉Vitalic_V which is given a classical witness w𝑤witalic_w and makes quantum queries to S,U𝑆𝑈S,Uitalic_S , italic_U, and accepts in the case S𝑆Sitalic_S is large. We want to show that we can replace S𝑆Sitalic_S with a small set S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, and V𝑉Vitalic_V will still accept with too-high a probability, meaning it incorrectly claims that (S′,U)superscript𝑆′𝑈(S^{\prime},U)( italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_U ) is in the language, despite S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT being small. Toward that end, we will choose S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT to be all points in S𝑆Sitalic_S that are also “heavy” among the queries V𝑉Vitalic_V makes to S𝑆Sitalic_S. That is, points y∈S𝑦𝑆y\in Sitalic_y ∈ italic_S such that the query amplitude in V𝑉Vitalic_V’s quantum queries to S𝑆Sitalic_S is above some inverse-polynomial threshold. As the total query amplitude of all points is just the number of queries of V𝑉Vitalic_V and hence polynomial, the number of heavy y𝑦yitalic_y is polynomial. Hence, S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is small. We can also construct S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT efficiently: for each heavy y𝑦yitalic_y, running V𝑉Vitalic_V and measuring a random query will have an inverse polynomial chance of producing y𝑦yitalic_y. By repeating this process a polynomial number of times, we can collect all heavy queries. But why should S𝑆Sitalic_S and S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT be indistinguishable to V𝑉Vitalic_V? By standard quantum query analysis, if V𝑉Vitalic_V can distinguish S𝑆Sitalic_S from S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, then it’s queries must place significant amplitude on S∖S′𝑆superscript𝑆′S\setminus S^{\prime}italic_S ∖ italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. By measuring a random query, we therefore obtain with significant probability a y∈S∖S′𝑦𝑆superscript𝑆′y\in S\setminus S^{\prime}italic_y ∈ italic_S ∖ italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. But since y𝑦yitalic_y is not heavy, repeating this process many times will produce many different y𝑦yitalic_y. This means that if V𝑉Vitalic_V can distinguish S𝑆Sitalic_S from S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, it must actually be able to generate essentially arbitrarily large (polynomial) numbers of y∈S𝑦𝑆y\in Sitalic_y ∈ italic_S. Denote the number of y𝑦yitalic_y by L𝐿Litalic_L. V𝑉Vitalic_V that do not query U𝑈Uitalic_U. Let us first assume that V𝑉Vitalic_V makes no queries to U𝑈Uitalic_U. In this case, we can argue that any distinguishing V𝑉Vitalic_V actually violates known query complexity results for multiple Grover search. In particular, [HM23] show that an algorithm making polynomially-many queries to a random sparse S𝑆Sitalic_S cannot produce L𝐿Litalic_L points in S𝑆Sitalic_S except with probability bounded by 2−Lsuperscript2𝐿2^{-L}2 start_POSTSUPERSCRIPT - italic_L end_POSTSUPERSCRIPT (see Lemma 2.6 for precise statement). Now, this result assumes no advice is provided about S𝑆Sitalic_S, but the witness w𝑤witalic_w counts as advice. Fortunately, we can handle the advice using the strong exponential lower bound provided by [HM23]. Consider running the process above with a random w′superscript𝑤′w^{\prime}italic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT instead of w𝑤witalic_w. In the event w′=wsuperscript𝑤′𝑤w^{\prime}=witalic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_w, the process will produce L𝐿Litalic_L points in S𝑆Sitalic_S. Moreover, w′=wsuperscript𝑤′𝑤w^{\prime}=witalic_w start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_w with probability 2−|w|superscript2𝑤2^{-|w|}2 start_POSTSUPERSCRIPT - | italic_w | end_POSTSUPERSCRIPT. By setting L≫|w|much-greater-than𝐿𝑤L\gg|w|italic_L ≫ | italic_w | (recall that we can make L𝐿Litalic_L an arbitrarily large polynomial), we therefore obtain an algorithm with no advice which produces L𝐿Litalic_L points in S𝑆Sitalic_S with probability 2−|w|≫2−Lmuch-greater-thansuperscript2𝑤superscript2𝐿2^{-|w|}\gg 2^{-L}2 start_POSTSUPERSCRIPT - | italic_w | end_POSTSUPERSCRIPT ≫ 2 start_POSTSUPERSCRIPT - italic_L end_POSTSUPERSCRIPT, contradicting the hardness of multiple Grover search. Remark 1.1. The above strategy inherently uses the fact that w𝑤witalic_w is classical. If V𝑉Vitalic_V had a quantum witness/advice, running it even once and measuring a random query to find a y∈S𝑦𝑆y\in Sitalic_y ∈ italic_S would potentially destroy the witness, meaning further runs of V𝑉Vitalic_V are not guaranteed to produce any points in S𝑆Sitalic_S. This is the key place in the proof where we distinguish between classical and quantum witnesses, hopefully indicating a promising route toward proving a separation between 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA and 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA. k𝑘kitalic_k-wise independent U𝑈Uitalic_U. The above strategy does not work for handling queries to U𝑈Uitalic_U. The problem is that U𝑈Uitalic_U takes potentially N𝑁Nitalic_N bits (which is exponential) to describe, meaning treating U𝑈Uitalic_U as advice would require setting L≫Nmuch-greater-than𝐿𝑁L\gg Nitalic_L ≫ italic_N, at which point the bounds from [HM23] do not apply. We will for now assume that U𝑈Uitalic_U is k𝑘kitalic_k-wise independent for a super-polynomial k𝑘kitalic_k, and return to justifying this assumption later. We will assume such k𝑘kitalic_k-wise independence holds even conditioned on S𝑆Sitalic_S (but not conditioned on |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩, whose correlation with U𝑈Uitalic_U is crucial for the correctness of our 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA verifier). A result of [Zha12] (formally described in Lemma 2.5) shows that a k𝑘kitalic_k-wise independent U𝑈Uitalic_U is actually perfectly indistinguishable from a uniform U𝑈Uitalic_U, for all quantum query algorithms making at most k/2𝑘2k/2italic_k / 2 queries. Since k𝑘kitalic_k is super-polynomial, we thus obtain perfect indistinguishability against all polynomial-query algorithms, including our process above for generating points in S𝑆Sitalic_S. Consequently, the process above succeeds in generating L𝐿Litalic_L points in S𝑆Sitalic_S even if U𝑈Uitalic_U is replaced by a uniformly random U𝑈Uitalic_U independent of S𝑆Sitalic_S. But such a uniform U𝑈Uitalic_U can be simulated without knowledge of S𝑆Sitalic_S at all, and hence the lower-bound of [HM23] actually applies to algorithms making queries to uniform U𝑈Uitalic_U. Thus under the assumption that U𝑈Uitalic_U is k𝑘kitalic_k-wise independent, we can justify 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA hardness. Our U𝑈Uitalic_U are “close” to k𝑘kitalic_k-wise independent. We show that, by choosing U𝑈Uitalic_U carefully in a probabilistic way, U𝑈Uitalic_U is “close” to k𝑘kitalic_k-wise independent, even conditioned on S𝑆Sitalic_S. By “close”, we concretely mean that for every subset T⊆[N]𝑇delimited-[]𝑁T\subseteq[N]italic_T ⊆ [ italic_N ] of size at most k𝑘kitalic_k, that 2−|T|≤Pr⁡[T∩U=∅]≤(1+ϵ)×2−|T|superscript2𝑇Pr𝑇𝑈1italic-ϵsuperscript2𝑇2^{-|T|}\leq\Pr[T\cap U=\emptyset]\leq(1+\epsilon)\times 2^{-|T|}2 start_POSTSUPERSCRIPT - | italic_T | end_POSTSUPERSCRIPT ≤ roman_Pr [ italic_T ∩ italic_U = ∅ ] ≤ ( 1 + italic_ϵ ) × 2 start_POSTSUPERSCRIPT - | italic_T | end_POSTSUPERSCRIPT, for some very small ϵitalic-ϵ\epsilonitalic_ϵ which depends on k,|S|,N𝑘𝑆𝑁k,|S|,Nitalic_k , | italic_S | , italic_N. Note that true k𝑘kitalic_k-wise independence is equivalent to Pr⁡[T∩U=∅]=2−|T|Pr𝑇𝑈superscript2𝑇\Pr[T\cap U=\emptyset]=2^{-|T|}roman_Pr [ italic_T ∩ italic_U = ∅ ] = 2 start_POSTSUPERSCRIPT - | italic_T | end_POSTSUPERSCRIPT for all T𝑇Titalic_T of size at most k𝑘kitalic_k. Is this “close” enough? Unfortunately, we do not know how to prove that U𝑈Uitalic_U which are close to k𝑘kitalic_k-wise independent are sufficient to make our approach work. The issue is that [Zha12] only applies to perfect k𝑘kitalic_k-wise independence, and there are counterexamples that show that the result does not hold when replaced with some approximate notions of k𝑘kitalic_k-wise independence. The good news is that our notion of closeness is quite different from the usual notion of “biased” or “almost” k𝑘kitalic_k-wise independence used in the literature. Specifically, those notions allow for an additive error in any of the marginal probabilities, whereas we impose a strong multiplicative error bound. This gives us hope that our distribution of U𝑈Uitalic_U, despite not being truly k𝑘kitalic_k-wise independent, may still be close enough to get a separation. We make progress toward justifying this claim. We make a conjecture that any distribution over U𝑈Uitalic_U which is “close” to k𝑘kitalic_k-wise independent (in our sense) can be turned into a distribution U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT that is truly k𝑘kitalic_k-wise independent. Importantly, U𝑈Uitalic_U and U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT will agree on almost all points. More precisely, for any z𝑧zitalic_z, the probability that U𝑈Uitalic_U and U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT differ on z𝑧zitalic_z is negligible. See Conjecture 3.2 for the formal statement of this conjecture. Observe that this conjecture is simply a statement about distributions, and has nothing on the surface to do with quantum query complexity. Under this conjecture, we complete the full oracle separation between 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA and 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA. Instead of giving out the oracle U𝑈Uitalic_U, we simply give out the oracle U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, and prove 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA hardness following the above approach. Our statistical conjecture is then used to show that replacing U𝑈Uitalic_U with U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT does not break our 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA verifier. Concretely, by standard query complexity arguments, we show that if our verifier works on U𝑈Uitalic_U, then it must also work (with negligibly larger error) on U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Remark 1.2. Our statistical conjecture gives one way to prove an oracle separation between 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA and 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA following our approach. Our conjecture could of course turn out to be false. Even in this case, our oracles still seem likely to give a separation, and there may be many other paths toward proving it. Perhaps if the general conjecture is false, our particular U𝑈Uitalic_U can still be converted into U′superscript𝑈′U^{\prime}italic_U start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT as needed. Or maybe being “close” to k𝑘kitalic_k-wise independent is directly sufficient for a separation and can be proven via quantum query complexity arguments. Possibly there is a different distribution over |ψ⟩ket𝜓|\psi\rangle| italic_ψ ⟩ and associated U𝑈Uitalic_U where U𝑈Uitalic_U actually is perfectly k𝑘kitalic_k-wise independent. Thus, independent of our particular statistical conjecture, we believe our new approach at a separation gives a promising new approach toward separating 𝖰𝖬𝖠𝖰𝖬𝖠{\sf QMA}sansserif_QMA from 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠{\sf QCMA}sansserif_QCMA relative to classical oracles."
https://arxiv.org/html/2411.01663v1,Unlocking the Theory Behind Scaling 1-Bit Neural Networks,"Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an impressive combination of efficiency and performance that rivals traditional LLMs. Research by WMD+ [91], MWM+ [70] indicates that the performance of these 1-bit LLMs progressively improves as the number of parameters increases, hinting at the potential existence of a Scaling Law for 1-bit Neural Networks. In this paper, we present the first theoretical result that rigorously establishes this scaling law for 1-bit models. We prove that, despite the constraint of weights restricted to {−1,+1}11\{-1,+1\}{ - 1 , + 1 }, the dynamics of model training inevitably align with kernel behavior as the network width grows. This theoretical breakthrough guarantees convergence of the 1-bit model to an arbitrarily small loss as width increases. Furthermore, we introduce the concept of the generalization difference, defined as the gap between the outputs of 1-bit networks and their full-precision counterparts, and demonstrate that this difference maintains a negligible level as network width scales. Building on the work of KMH+ [51], we conclude by examining how the training loss scales as a power-law function of the model size, dataset size, and computational resources utilized for training. Our findings underscore the promising potential of scaling 1-bit neural networks, suggesting that int1 could become the standard in future neural network precision.","Large-scale neural networks, particularly Large Language Models (LLMs) [20, 106] and Large Multimodel Models (LMMs) [97, 87], are becoming increasingly relevant to our day-to-day lives, finding a huge variety of applications in both the workplace and at home [55, 98]. However, it is expensive to deploy and run these models due to their substantial computational requirements, large memory footprints, and energy consumption [86, 5, 103]. This is especially true for resource-constrained environments, such as mobile devices, edge computing, or companies with limited infrastructure [47, 69, 24]. To make these models more efficient and accessible, quantization techniques are used, which reduce the precision of the model’s parameters (such as weights and activations) from floating-point numbers to lower-bit representations (e.g., 8-bit or even lower) [72, 30, 33, 66, 2]. Quantization reduces the memory and computational costs of inference, enabling faster processing with less energy, while maintaining a comparable level of performance. This optimization allows language models to be more practical, scalable, and sustainable for widespread use across various platforms [21, 60, 35]. In particular, quantization techniques could be primarily divided into two methods: Post-Training Quantization (PTQ) [67, 94, 83] and Quantization-Aware Training (QAT) [62, 91, 70]. PTQ methods, including uniform and non-uniform quantization, conveniently convert pre-trained model weights and activations to lower-bit representations post-training. However, this leads to accuracy loss, especially in lower precision, as the model is not optimized for these quantized representations and significant shifts in weight distribution occur [73]. The alternative, Quantization-Aware Training (QAT), incorporates quantization during training, allowing the model to fine-tune and adapt its parameters to the quantized representation, compensating for quantization errors. Therefore, compared to PTQ, QAT maintains higher accuracy and robustness even in lower precision. Recent studies [61, 91, 70, 107] have shown that 1111-bit LLMs, most of which have matrix weights in the range of {−1,+1}11\{-1,+1\}{ - 1 , + 1 }, can be trained from scratch to deliver performance that rivals that of standard LLMs. These models exhibit remarkable efficiency, particularly in terms of scaling laws. Experimental results indicate that the performance of the 1111-bit model improves as the number of parameters increases, a principle that mirrors the training approach utilized in standard LLMs [51]. Despite the demonstrated efficiency of quantization methods, our understanding of the training mechanism for quantization remains limited. Specifically, it remains unclear how and why the 1111-bit QAT enhances learning capability as the number of neurons in the model is scaled up. In addition, we are also concerned about whether the quantization method damages the generalization ability compared to full precision networks. In this study, we initially apply the Neural Tangent Kernel (NTK) framework to delve into the optimization and generalization issues associated with a two-layer linear network operating in 1-bit (int1) precision, as detailed in Section 4. We introduce a 1-bit quantization method to the hidden-layer weights W∈ℝd×m𝑊superscriptℝ𝑑𝑚W\in\mathbb{R}^{d\times m}italic_W ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_m end_POSTSUPERSCRIPT of the conventional NTK linear network, where d𝑑ditalic_d represents the input dimension and m𝑚mitalic_m indicates the model’s width. Our analysis reveals that the training dynamics of the 1-bit model approximate kernel behavior as the model width m𝑚mitalic_m expands. This key finding paves the way for an established relationship between the theoretically guaranteed loss and the model width, endowing the model with robust learning capabilities akin to kernel regression. Ultimately, the model achieves an insignificantly small training loss, contingent on setting a sufficiently large model width, selecting an appropriate learning rate, and allowing an adequate training duration. Moreover, Section 5 provides a theoretical confirmation that, within the scaling trend, the disparities in predictions of the 1-bit model from those of the original linear network on identical inputs maintain a negligible value. We assess the error between our 1-bit linear and standard linear networks on both the training and test datasets. Our theorem demonstrates that for any input from these datasets, the absolute error between the two network predictions can be denoted as ϵquant≤O⁢(κ⁢d⁢log⁡(m⁢d/δ))subscriptitalic-ϵquant𝑂𝜅𝑑𝑚𝑑𝛿\epsilon_{\rm quant}\leq O(\kappa d\log(md/\delta))italic_ϵ start_POSTSUBSCRIPT roman_quant end_POSTSUBSCRIPT ≤ italic_O ( italic_κ italic_d roman_log ( italic_m italic_d / italic_δ ) ) for scale coefficient κ≤1𝜅1\kappa\leq 1italic_κ ≤ 1, model width m𝑚mitalic_m, dimension d𝑑ditalic_d and failure probability δ∈(0,0.1)𝛿00.1\delta\in(0,0.1)italic_δ ∈ ( 0 , 0.1 ). This indicates that the output behavior of the 1-bit linear model increasingly aligns with that of the standard linear model. The observed similarity on the test dataset validates the generalization similarity, suggesting the feasibility of approximating training neural networks with int1 precision equivalent to full precision. Finally, in Section 6, we verify our theoretical results by implementing training models to learn complicated functions to compare the difference between 1111-bit networks and full precision networks. Firstly, we choose a combination of difficult functions across the exponential function, trigonometric function, logarithmic function, the Lambert W function, the Gamma function, and their combination. Therefore, we sample random data points and split train and test datasets. We next compare how the training loss decreases as the model width m𝑚mitalic_m scales up. Besides, as shown in Section 6.3, in the trend of a growing number of parameters, the error of predictions both on training and test input likewise converge as the power-law in 1111-bit networks optimization. In particular, we visualize some 1111-dimension function to see how the differences of outputs are. We demonstrate the results complying with our theoretical guarantee with a negligible error."
https://arxiv.org/html/2411.01452v1,Rapidly mixing loop representation quantum Monte Carlo for Heisenberg models on star-like bipartite graphs,"Quantum Monte Carlo (QMC) methods have proven invaluable in condensed matter physics, particularly for studying ground states and thermal equilibrium properties of quantum Hamiltonians without a sign problem. Over the past decade, significant progress has also been made on their rigorous convergence analysis. Heisenberg antiferromagnets (AFM) with bipartite interaction graphs are a popular target of computational QMC studies due to their physical importance, but despite the apparent empirical efficiency of these simulations it remains an open question whether efficient classical approximation of the ground energy is possible in general. In this work we introduce a ground state variant of the stochastic series expansion QMC method, and for the special class of AFM on interaction graphs with an O⁢(1)𝑂1O(1)italic_O ( 1 )-bipartite component (star-like), we prove rapid mixing of the associated QMC Markov chain (polynomial time in the number of qubits) by using Jerrum and Sinclair’s method of canonical paths. This is the first Markov chain analysis of a practical class of QMC algorithms with the loop representation of Heisenberg models. Our findings contribute to the broader effort to resolve the computational complexity of Heisenberg AFM on general bipartite interaction graphs.","The Heisenberg Hamiltonian couples neighboring spin-1/2 degrees of freedom arranged on fixed spatial sites by the exchange interaction of the form ±σ→i⋅σ→j=±(Xi⁢Xj+Yi⁢Yj+Zi⁢Zj)plus-or-minus⋅subscript→𝜎𝑖subscript→𝜎𝑗plus-or-minussubscript𝑋𝑖subscript𝑋𝑗subscript𝑌𝑖subscript𝑌𝑗subscript𝑍𝑖subscript𝑍𝑗\pm\vec{\sigma}_{i}\cdot\vec{\sigma}_{j}=\pm(X_{i}X_{j}+Y_{i}Y_{j}+Z_{i}Z_{j})± over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT = ± ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), which models the effective energetic tendencies of neighboring electron spins in molecular orbitals within a solid (i,j𝑖𝑗i,jitalic_i , italic_j refer to neighboring sites, and σ→=(X,Y,Z)→𝜎𝑋𝑌𝑍\vec{\sigma}=(X,Y,Z)over→ start_ARG italic_σ end_ARG = ( italic_X , italic_Y , italic_Z ) is a vector of Pauli matrices). The coupling −σ→i⋅σ→j⋅subscript→𝜎𝑖subscript→𝜎𝑗-\vec{\sigma}_{i}\cdot\vec{\sigma}_{j}- over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT in a Hamiltonian is called ferromagnetic (FM) because it energetically favors alignment of spins, while the coupling +σ→i⋅σ→j⋅subscript→𝜎𝑖subscript→𝜎𝑗+\vec{\sigma}_{i}\cdot\vec{\sigma}_{j}+ over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT favors anti-alignment and is called antiferromanetic (AFM). Exact solutions for Heisenberg models are known only for a few cases [30, 4, 51, 33] so approximate or computational solutions are needed to study the model in more complicated geometries such as 2D lattices and beyond. Quantum Monte Carlo (QMC) methods seek computational solutions by reducing the approximation of equilibrium observables in certain quantum spin systems to the problem of sampling classical configurations from a weighted probability distribution. QMC methods use a Markov chain to sample from the target distribution, and Monte Carlo estimation to approximate observables of interest. An important condition for the efficient application of QMC is that the model should not have a sign problem [31, 34] , meaning that there should be some choice of local basis in which all of the off-diagonal Hamiltonian matrix elements are real and non-positive. In both Suzuki’s original formulation of QMC [53, 52] and more modern QMC treatments for spin systems [45], this condition ensures that the paths contributing to the path integral for the ground state all have non-negative weights. More generally, the absence of a sign problem reduces the computational complexity of estimating equilibrium observables [13] and such models without a sign problem are now commonly called “stoquastic” in the context of Hamiltonian complexity [10, 9, 7]. Ferromagnetic Heisenberg models are always stoquastic (the interaction −(Xi⁢Xj+Yi⁢Yj+Zi⁢Zj)subscript𝑋𝑖subscript𝑋𝑗subscript𝑌𝑖subscript𝑌𝑗subscript𝑍𝑖subscript𝑍𝑗-(X_{i}X_{j}+Y_{i}Y_{j}+Z_{i}Z_{j})- ( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) has all real and non-positive matrix elements in the Z𝑍Zitalic_Z-basis). For the antiferromagnetic interaction (Xi⁢Xj+Yi⁢Yj+Zi⁢Zj)subscript𝑋𝑖subscript𝑋𝑗subscript𝑌𝑖subscript𝑌𝑗subscript𝑍𝑖subscript𝑍𝑗(X_{i}X_{j}+Y_{i}Y_{j}+Z_{i}Z_{j})( italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT + italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), the desired property of off-diagonal matrix elements in the Z𝑍Zitalic_Z-basis can be obtained by a local unitary transformation [34], (Z⊗I)⁢σ→i⋅σ→j⁢(Z⊗I)=(Zi⁢Zj−Xi⁢Xj−Yi⁢Yj)⋅tensor-product𝑍𝐼subscript→𝜎𝑖subscript→𝜎𝑗tensor-product𝑍𝐼subscript𝑍𝑖subscript𝑍𝑗subscript𝑋𝑖subscript𝑋𝑗subscript𝑌𝑖subscript𝑌𝑗(Z\otimes I)\vec{\sigma}_{i}\cdot\vec{\sigma}_{j}(Z\otimes I)=(Z_{i}Z_{j}-X_{i% }X_{j}-Y_{i}Y_{j})( italic_Z ⊗ italic_I ) over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ over→ start_ARG italic_σ end_ARG start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_Z ⊗ italic_I ) = ( italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ), but applying this transformation to successfully render the entire model stoquastic requires that the underlying interactions are bipartite in the graph-theoretic sense (i.e., vertices are two-colorable). Hamiltonian Complexity. Computing the ground state energy of an AFM Heisenberg model on general graphs up to an inverse polynomial precision is known to be QMA-complete, and is essentially regarded as the quantum analog of the classical MaxCut problem [17, 3], thus called QuantumMaxCut in the approximation algorithm community. In contrast, the same problem for bipartite graphs is contained in the more limited complexity class StoqMA [13] because it is stoquastic as described above. While classical MaxCut is trivial to solve on bipartite graphs, the complexity of QuantumMaxCut for bipartite graphs is unknown and is explicitly raised as an open problem in [16]. Currenlty, the only proven fact is the containment in StoqMA [38], so the possibility is wide open from containment in P to being StoqMA-complete. Classical ground state approximations to the QuantumMaxCut problem on general graphs have been obtained in special cases by semidefinite programming (SDP) heierarchies, generalizing the Goemans-Williamson algorithm for classical MaxCut [26, 57, 66, 27]. These SDP methods are not explicitly affected by the sign problem, but bipartite graphs (including the star-like graphs we consider) have been an important source of tractable examples for these algorithms. QMC and related methods have been used for proving polynomial-time simulability of a variety of stoquastic systems without NP-hardness obstructions, including 1D spin systems at constant temperature [11], ferromagnetic Ising models on general interaction graphs [6], high-temperature quantum Ising spin glasses on bounded-degree graphs [12], as well as a landmark result by Bravyi and Gosset establishing ground state and thermal state simulation for XY ferromagnets on arbitrary interaction graphs [8]. We note that this latter result includes X⁢X𝑋𝑋XXitalic_X italic_X and Y⁢Y𝑌𝑌YYitalic_Y italic_Y interactions as long as they are stoquastic (thus somewhat extending the notion of “ferromagnetic”) and also local Z𝑍Zitalic_Z fields, but not Z⁢Z𝑍𝑍ZZitalic_Z italic_Z interactions. Another related result is a deterministic quasipolynomial-time simulation of XXZ models with tunable X⁢X,Y⁢Y,𝑋𝑋𝑌𝑌XX,YY,italic_X italic_X , italic_Y italic_Y , and Z⁢Z𝑍𝑍ZZitalic_Z italic_Z interactions as long as the Z⁢Z𝑍𝑍ZZitalic_Z italic_Z term dominates the other two in a ferromagnetic way [20]. Based on the empirical evidence provided by decades of computational studies [45], it is fairly plausible that QMC algorithms can approximate ground states of bipartite QuantumMaxCut models on a wide range of interaction graphs in classical polynomial time, but there has been no rigorous proof for efficient convergence of QMC for any bipartite AFM models to date. Our work thus provides a first step along a reasonable approach to putting bipartite cases of QuantumMaxCut in BPP. Markov chains and Mixing Times. To obtain a polynomial-time simulation by QMC, the mixing time of Markov chain that drives the QMC method must scale polynomially with the system size [28]. The mixing time of a Markov chain characterizes the number of classical updates which suffice to produce each approximate sample from the target distribution - a Markov chain which equilibrates in a time that scales logarithmically in the size of its state space (i.e. polynomially in the number of spins or particles for a quantum system) is called rapidly mixing. A general technique for analyzing the mixing time is to bound it in terms of reciprocal of the spectral gap of the Markov chain transition matrix. To bound the spectral gap of the QMC dynamics for O⁢(1)𝑂1O(1)italic_O ( 1 )-bipartite graphs, we use the method of canonical paths due to Jerrum and Sinclair [22, 50]. In this method the Markov chain state space is viewed as a combinatorial graph, with vertices representing states of the Markov chain and edges representing transitions between states. The task of showing rapid-mixing is then essentially to show that this combinatorial graph is an expander. The canonical path method does this by showing the existence of a routing of the probability flow through the state space graph that delivers the necessary stationary probability to every vertex without overloading any particular edges. We apply the method of canonical paths in a relatively straightforward way (inspired by the textbook example of “left-to-right bit fixing paths”) - most of our technical effort is devoted to developing the QMC representation that is simple enough to analyze yet close enough to the practical method, and proving geometric and topological facts about the state space so that these straightforward canonical paths suffice to show rapid mixing. The success of this approach highlights the opportunity to apply more sophisticated Markov chain analysis techniques to the interdisciplinary open problem of simulating bipartite AFM by rigorously efficient QMC. Figure 1: a) The “Heisenberg star”, or star graph with N−1𝑁1N-1italic_N - 1 qubits interacting antiferromagnetically with a single central qubit, is the archetypical example of the bipartite AFM we analyze. b) More generally we allow a constant number of qubits M=O⁢(1)𝑀𝑂1M=O(1)italic_M = italic_O ( 1 ) to interact antiferromagnetically with N−M𝑁𝑀N-Mitalic_N - italic_M qubits. Our analysis also extends to include staggered local fields and ferromagnetic interactions within each bipartite component. O⁢(1)𝑂1O(1)italic_O ( 1 )-bipartite (star-like) Heisenberg Models. Throughout this work we consider Heisenberg Hamiltonians defined on a bipartite interaction graph 𝒜∪ℬ𝒜ℬ\mathcal{A}\cup\mathcal{B}caligraphic_A ∪ caligraphic_B with N=|𝒜|+|ℬ|𝑁𝒜ℬN=|\mathcal{A}|+|\mathcal{B}|italic_N = | caligraphic_A | + | caligraphic_B | qubits, in which one component has a fixed size |𝒜|=O⁢(1)𝒜𝑂1|\mathcal{A}|=O(1)| caligraphic_A | = italic_O ( 1 ) and the other component has size |ℬ|=O⁢(N)ℬ𝑂𝑁|\mathcal{B}|=O(N)| caligraphic_B | = italic_O ( italic_N ). For any pair of qubits define the 2-local projection operator hi⁢j=(𝟙−Xi⁢Xj−Yi⁢Yj−Zi⁢Zj)/4.subscriptℎ𝑖𝑗1subscript𝑋𝑖subscript𝑋𝑗subscript𝑌𝑖subscript𝑌𝑗subscript𝑍𝑖subscript𝑍𝑗4h_{ij}=(\mathbbm{1}-X_{i}X_{j}-Y_{i}Y_{j}-Z_{i}Z_{j})/4.italic_h start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = ( blackboard_1 - italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) / 4 . (1) Then the Heisenberg AFM Hamiltonian with weights wi⁢j≥0subscript𝑤𝑖𝑗0w_{ij}\geq 0italic_w start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ≥ 0 is HAFM=−∑i∈𝒜,j∈ℬwi⁢j⁢hi⁢j,subscript𝐻AFMsubscriptformulae-sequence𝑖𝒜𝑗ℬsubscript𝑤𝑖𝑗subscriptℎ𝑖𝑗H_{\textrm{AFM}}=-\sum_{i\in\mathcal{A},j\in\mathcal{B}}w_{ij}h_{ij},italic_H start_POSTSUBSCRIPT AFM end_POSTSUBSCRIPT = - ∑ start_POSTSUBSCRIPT italic_i ∈ caligraphic_A , italic_j ∈ caligraphic_B end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , (2) which we will explain in more detail in section 2. Although the AFM terms are the primary interest in this work, our analysis also extends (without much additional complication) to including ferromagnetic terms acting within 𝒜𝒜\mathcal{A}caligraphic_A or within ℬℬ\mathcal{B}caligraphic_B, and 1-local X𝑋Xitalic_X terms with their signs staggered to enhance the antiferromagnetic order. HFMsubscript𝐻FM\displaystyle H_{\textrm{FM}}italic_H start_POSTSUBSCRIPT FM end_POSTSUBSCRIPT =−∑(i,j)∈𝒜⁢ or ⁢(i,j)∈ℬJi⁢j⁢(𝟙−hi⁢j)absentsubscript𝑖𝑗𝒜 or 𝑖𝑗ℬsubscript𝐽𝑖𝑗1subscriptℎ𝑖𝑗\displaystyle=-\sum_{(i,j)\in\mathcal{A}\textrm{ or }(i,j)\in\mathcal{B}}J_{ij% }(\mathbbm{1}-h_{ij})= - ∑ start_POSTSUBSCRIPT ( italic_i , italic_j ) ∈ caligraphic_A or ( italic_i , italic_j ) ∈ caligraphic_B end_POSTSUBSCRIPT italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ( blackboard_1 - italic_h start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT ) (3) HXsubscript𝐻𝑋\displaystyle H_{X}italic_H start_POSTSUBSCRIPT italic_X end_POSTSUBSCRIPT =12⁢∑i∈Agi⁢(𝟙−Xi)−12⁢∑j∈Bgj⁢(𝟙−Xj)absent12subscript𝑖𝐴subscript𝑔𝑖1subscript𝑋𝑖12subscript𝑗𝐵subscript𝑔𝑗1subscript𝑋𝑗\displaystyle=\frac{1}{2}\sum_{i\in A}g_{i}(\mathbbm{1}-X_{i})-\frac{1}{2}\sum% _{j\in B}g_{j}(\mathbbm{1}-X_{j})= divide start_ARG 1 end_ARG start_ARG 2 end_ARG ∑ start_POSTSUBSCRIPT italic_i ∈ italic_A end_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( blackboard_1 - italic_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - divide start_ARG 1 end_ARG start_ARG 2 end_ARG ∑ start_POSTSUBSCRIPT italic_j ∈ italic_B end_POSTSUBSCRIPT italic_g start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( blackboard_1 - italic_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) (4) where Ji⁢j,gisubscript𝐽𝑖𝑗subscript𝑔𝑖J_{ij},g_{i}italic_J start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT are positive weights. The most general Hamiltonian we consider is H=HAFM+HFM+HX𝐻subscript𝐻AFMsubscript𝐻FMsubscript𝐻XH=H_{\textrm{AFM}}+H_{\textrm{FM}}+H_{\textrm{X}}italic_H = italic_H start_POSTSUBSCRIPT AFM end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT FM end_POSTSUBSCRIPT + italic_H start_POSTSUBSCRIPT X end_POSTSUBSCRIPT (5) for O⁢(1)𝑂1O(1)italic_O ( 1 )-bipartite graphs, as indicated in Figure 1. Our main result is a proof of poly⁢(N)poly𝑁\textrm{poly}(N)poly ( italic_N ) time rapid mixing for the QMC Markov chain dynamics of Section 3 applied to these models, which allows for approximating the expectation of local observables and approximately sampling from the ground state in the Z𝑍Zitalic_Z basis. Since our results pertain to a QMC method that estimates the ground state energy of (5), we emphasize that the ground state energy of these O⁢(1)𝑂1O(1)italic_O ( 1 )-bipartite models can always be found in poly⁢(N)poly𝑁\textrm{poly}(N)poly ( italic_N ) time by the Lieb-Mattis theorem (see Appendix A). Our motivation here is not just to find some polynomial time algorithm for approximating these ground states, but to show that a popular and practical QMC algorithm also yields a rigorously efficient classical approximation algorithm for estimating ground state observables for these systems. The fact that the QMC algorithm is operated in a general way and does not make use of the Lieb-Mattis theorem to reduce the dimensionality brings hope for proving efficiency for more general cases in future work. Another perspective is that our main result lower bounds the spectral gap of the dynamical generator of a kinetic loop model that has not been previously analyzed. This loop model equilibrium distribution simulates the Heisenberg AFM ground state and thus yields an efficient algorithm for the problem of approximating the ground energy. Loop representation of QMC for Heisenberg models. Following the discussion of stoquastic complexity, a central goal of computational QMC studies is to design Markov chains for which the state space, stationary distribution, and update rules lead to rapid mixing. Despite progress in the rigorous analysis of QMC methods, bipartite Heisenberg models with AFM terms have resisted such analysis to date. A high-level reason for this is that the form of the Heisenberg interaction leads to QMC configurations with many combinatorial constraints when using the most basic type of QMC [53]. Such constraints not only brings difficulties for the rigorous analysis of the Markov chain mixing time, but also results in impractical long mixing times. To resolve this issue, modern QMC methods used in computational studies of Heisenberg models involve non-local cluster updates (analogous to Swendson-Wang updates [54] for classical Ising models, instead of single-site Glauber dynamics) achieving practically fast mixing time. Our approach is based on a state-of-the-art QMC used in computational condensed matter physics, called the stochastic series expansion (SSE) method [47]. This method is especially optimized for Heisenberg interactions, where it has been applied in thermal and ground state simulations with over 106superscript10610^{6}10 start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT qubits [58]. In the simplified version of this method which we introduce and analyze, the stationary distribution over configurations of clusters (which are conventionally called “loops” even when they can be open strings) takes a simplified purely geometric form, proportional to 2#⁢ of loopssuperscript2# of loops2^{\#\textrm{ of loops}}2 start_POSTSUPERSCRIPT # of loops end_POSTSUPERSCRIPT. Only by focusing on such practically fast QMC methods and appropriately simplifying them was it possible to rigorously prove rapid-mixing as we present here. Figure 2: An example configuration from the SPE Markov chain we analyze. The loop configuration (top) is an example of a configuration with 2⁢B=82𝐵82B=82 italic_B = 8 operators and 6 line segments (“loops”) for a Heisenberg model on a 4-arm star graph (bottom). The QMC we analyze closely follows the standard SSE algorithm, except for one difference that is significant for the analysis: instead of using the Taylor series for tr⁢[e−β⁢H]trdelimited-[]superscript𝑒𝛽𝐻\textrm{tr}[e^{-\beta H}]tr [ italic_e start_POSTSUPERSCRIPT - italic_β italic_H end_POSTSUPERSCRIPT ] as is done in standard SSE, we use a fixed large positive integer power of the Hamiltonian (−H)Lsuperscript𝐻𝐿(-H)^{L}( - italic_H ) start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT applied to the trial state |+N⟩ketsuperscript𝑁|+^{N}\rangle| + start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT ⟩ to project onto the low energy subspace. As we discuss later on, although physical intuition may indicate that this is not much of a difference, this in fact turns out to be crucial for our proof to work because of topological reasons. The idea of applying (−H)Lsuperscript𝐻𝐿(-H)^{L}( - italic_H ) start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT to obtain the ground state has been done in many QMC methods [46], but in our QMC, we use the z𝑧zitalic_z-basis unlike [46] and then switch to the loop representation. We term this modified version of SSE as Stochastic Power Expansion (SPE) QMC for convenience, as both the open boundary condition and the loop representation are essential for our analysis. Figure 2 illustrates a typical SPE (SSE) configuration for the Heisenberg AFM on the star graph. We briefly overview the method here; see Section 3 for a full derivation and explanation. • For a general bipartite AFM, the SSE representation augments the interaction graph 𝒢𝒢\mathcal{G}caligraphic_G with an “imaginary time direction” {1,…,2⁢B}1…2𝐵\{1,...,2B\}{ 1 , … , 2 italic_B } and considers configurations consisting of an assignment of a “bridge” (corresponding to an edge in 𝒢𝒢\mathcal{G}caligraphic_G i.e. a local AFM term, dotted in the figure) to each “(imaginary) time slice” j∈{1,…,2⁢B}𝑗1…2𝐵j\in\{1,...,2B\}italic_j ∈ { 1 , … , 2 italic_B }. • One samples from this set of bridge configurations by a Markov chain that switches a randomly chosen bridge at each step. The Markov chain satisfies detailed balance and converges to the stationary distribution where probabilities are proportional to 2#⁢ of loopssuperscript2# of loops2^{\#\textrm{ of loops}}2 start_POSTSUPERSCRIPT # of loops end_POSTSUPERSCRIPT. The loops (which can be closed or open strings, shown in distinct colors for visual clarity in Figure 2) are defined via the bridge configuration. • The loop structure of a configuration will in general undergo non-local changes when a single bridge is changed, which complicates the analysis but is essential for the efficiency of the method in practice. This paper is structured as follows. In section 2, we introduce the notations as well as all possible forms of the Hamiltonians that we consider in this work. In section 3, we derive the configuration space and the probability distribution that our QMC method will be sampling from. This derivation shows how the seemingly nonquantum yet topological configurations that we sample are related to the Heisenberg model. Section 4 is devoted to introducing the canonical path method, the mathematical technique we use for proving rapid mixing. We also go through the basics of Markov Chain Monte Carlo methods in general, and also precisely define the QMC sampling algorithm based on the framework. We then move on to the main proof in section 5, where we cover all cases that we can prove rapid-mixing. Finally, in section 6, we discuss the implications of our result as well as relations with various concepts in condensed matter physics and also comment on open problems. We advice readers who are only interested in the core idea of the algorithm to see the simplest configuration space we consider in eq. 26 and the probability distribution over it that is explained thereafter. This should be enough to understand the QMC procedure explained in section 4.2, and also understand our proof in the simplest case which is explained in the first few subsections of section 5."
https://arxiv.org/html/2411.00976v1,Low-degree approximation of QAC0circuits,"QAC0 is the class of constant-depth quantum circuits with polynomially many ancillary qubits, where Toffoli gates on arbitrarily many qubits are allowed. In this work, we show that the parity function cannot be computed in QAC0, resolving a long-standing open problem in quantum circuit complexity more than twenty years old. As a result, this proves 𝐐𝐀𝐂0⫋𝐐𝐀𝐂wf0superscript𝐐𝐀𝐂0superscriptsubscript𝐐𝐀𝐂wf0{\bf QAC}^{0}\subsetneqq{\bf QAC}_{\rm wf}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⫋ bold_QAC start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. We also show that any QAC circuit of depth d𝑑ditalic_d that approximately computes parity on n𝑛nitalic_n bits requires 2Ω~⁢(n1/d)superscript2~Ωsuperscript𝑛1𝑑2^{\widetilde{\Omega}(n^{1/d})}2 start_POSTSUPERSCRIPT over~ start_ARG roman_Ω end_ARG ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT ancillary qubits, which is close to tight. This implies a similar lower bound on approximately preparing cat states using QAC circuits. Finally, we prove a quantum analog of the Linial-Mansour-Nisan theorem for 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. This implies that, for any QAC0 circuit U𝑈Uitalic_U with a=poly⁢(n)𝑎poly𝑛a={\rm poly}(n)italic_a = roman_poly ( italic_n ) ancillary qubits, and for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, the correlation between Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ) and the parity function is bounded by 1/2+2−Ω~⁢(n1/d)12superscript2~Ωsuperscript𝑛1𝑑{1}/{2}+2^{-\widetilde{\Omega}(n^{1/d})}1 / 2 + 2 start_POSTSUPERSCRIPT - over~ start_ARG roman_Ω end_ARG ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT, where Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ) denotes the output of measuring the output qubit of U⁢|x,0a⟩𝑈ket𝑥superscript0𝑎U\ket{x,0^{a}}italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩. All the above consequences rely on the following technical result. If U𝑈Uitalic_U is a 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit with a=poly⁢(n)𝑎poly𝑛a={\rm poly}(n)italic_a = roman_poly ( italic_n ) ancillary qubits, then there is a distribution 𝒟𝒟\mathcal{D}caligraphic_D of bounded polynomials of degree polylog(n)𝑛(n)( italic_n ) such that with high probability, a random polynomial from 𝒟𝒟\mathcal{D}caligraphic_D approximates the function ⟨x,0a|⁢U†⁢Zn+1⁢U⁢|x,0a⟩bra𝑥superscript0𝑎superscript𝑈†subscript𝑍𝑛1𝑈ket𝑥superscript0𝑎\bra{x,0^{a}}U^{\dagger}Z_{n+1}U\ket{x,0^{a}}⟨ start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ for a large fraction of x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. This result is analogous to the Razborov-Smolensky result on the approximation of AC0 circuits by random low-degree polynomials.","Classically, 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits are circuits of constant depth and polynomial size, with unbounded fan-in AND, OR and NOT gates (the NOT gates only at the input layer). The complexity class 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT defined by these circuits is used in theoretical computer science to understand the computational power of circuits with limited depth. One of the main motivations for studying 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is that it is a good “toy model” for studying larger classes of circuits. It is known that if any NP problems cannot be solved by circuits of polynomial size [1], then NP ≠\neq≠ P. Thus proving circuit lower bounds is a potential way for proving NP ≠\neq≠ P. Solving this problem for general circuits is remarkably challenging. Hence, a natural way to make progress towards this goal is to first try to prove that NP problems cannot be solved by polynomial-size circuits chosen from a restricted family. The 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits are a particularly interesting and well-studied family. In some celebrated works [10, 3] it was shown that 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT cannot compute the parity function. Later, more precise characterisations of the relationship between parity and 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT were discovered, e.g., see [15, 19, 21, 13]. Analogously, in the quantum case, Moore in 1999 first introduced the concept of quantum 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit [16]. There are two versions of quantum 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. One is known as 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, which is the class of polynomial-size quantum circuits of constant depth made up of arbitrary single-qubit gates and arbitrary-width Toffoli gates. Another generalisation of 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is called 𝐐𝐀𝐂wf0subscriptsuperscript𝐐𝐀𝐂0wf{\bf QAC}^{0}_{\rm wf}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT, which further includes unbounded fanout gates. Here the subscript “wf” means “with fanout”. It is straightforward to see that 𝐐𝐀𝐂wf0subscriptsuperscript𝐐𝐀𝐂0wf{\bf QAC}^{0}_{\rm wf}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT includes 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, and was proved in [4] that 𝐐𝐀𝐂wf0subscriptsuperscript𝐐𝐀𝐂0wf{\bf QAC}^{0}_{\rm wf}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT is much more powerful than 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. However, in sharp contrast, it is still unknown if 𝐀𝐂0⊂𝐐𝐀𝐂0superscript𝐀𝐂0superscript𝐐𝐀𝐂0{\bf AC}^{0}\subset{\bf QAC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⊂ bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT and if 𝐐𝐀𝐂0=𝐐𝐀𝐂wf0superscript𝐐𝐀𝐂0subscriptsuperscript𝐐𝐀𝐂0wf{\bf QAC}^{0}={\bf QAC}^{0}_{\rm wf}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT = bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT, see [16, 4]. Note that arbitrary fan-out is allowed in the 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit. If 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT can also do fanout, then it can compute the parity function and so is a larger class than 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. In this case, 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT turns out to be a very powerful class, as it would be able to do many other things, like performing the MODq gates for all q𝑞qitalic_q, modular addition gates, and the quantum Fourier transform [16, 4, 11]. Conversely, if 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT cannot compute parity, then we would immediately obtain 𝐐𝐀𝐂0⫋𝐐𝐀𝐂wf0superscript𝐐𝐀𝐂0subscriptsuperscript𝐐𝐀𝐂0wf{\bf QAC}^{0}\subsetneqq{\bf QAC}^{0}_{\rm wf}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⫋ bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT. This would also show that fanout cannot be computed in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, highlighting an important difference between 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT and 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT.111Here we cannot claim that 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT does not include 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, unless we can find a decision problem (Boolean function) that is in 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, but not in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. “Compute fanout” is not a decision problem, so we do not seem to automatically obtain this consequence. The 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits also have a close connection to the cat (GHZ) state 12⁢(|0n⟩+|1n⟩)12ketsuperscript0𝑛ketsuperscript1𝑛\frac{1}{\sqrt{2}}(\ket{0^{n}}+\ket{1^{n}})divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 end_ARG end_ARG ( | start_ARG 0 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ + | start_ARG 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ ), a quantum state which plays a fundamental role in the understanding of entanglement. In [16, 11], it was shown that the ability to form a cat state of n𝑛nitalic_n qubits is equivalent to the ability to construct an n𝑛nitalic_n-ary parity gate in constant depth. This result was extended to approximate constructions in [20], in which it was shown that approximating a cat state in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is equivalent to approximating the parity function in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. It is easy to show via a lightcone argument [23] that cat states cannot be prepared by a fixed constant-depth quantum circuit using bounded fan-in gates, i.e., cat states cannot be created in 𝐐𝐍𝐂0superscript𝐐𝐍𝐂0{\bf QNC}^{0}bold_QNC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT (although they can be prepared by interleaving low-depth quantum circuits with classical computations [7]). But until now, it has not been known if cat states can be prepared by 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits. As we can see, all the above open problems boil down to one particular open problem: is parity in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT? Although this is completely solved for the classical class 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, and special cases of the quantum problem have been solved, e.g., see [4, 20, 18, 8, 17, 2] (see Section 1.4), the main open problem has remained open for more than 20 years, and it is widely believed that the answer is “no”. In this work, we resolve this open problem and show that parity is not in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. 1.1 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits and the parity problem A 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit is a quantum circuit consisting of arbitrary single-qubit gates and arbitrary-width Toffoli gates (also known as arbitrary-width CCNOT gates) acting as follows Toffolin:|x1,…,xn,b⟩→|x1,…,xn,b⊕⋀i=1nxi⟩.{\rm Toffoli}_{n}:\leavevmode\nobreak\ \leavevmode\nobreak\ \ket{x_{1},\ldots,% x_{n},b}\rightarrow\ket{x_{1},\ldots,x_{n},b\oplus\bigwedge_{i=1}^{n}x_{i}}.roman_Toffoli start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_b end_ARG ⟩ → | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_b ⊕ ⋀ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ⟩ . (1.1) For any subset S⊆[n]𝑆delimited-[]𝑛S\subseteq[n]italic_S ⊆ [ italic_n ], the controlled-Z gate specified by S𝑆Sitalic_S is, denoted as CZSsubscriptCZ𝑆{\rm CZ}_{S}roman_CZ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT, CZS:|x1,…,xn⟩→(−1)∏i∈Sxi|x1,…,xn⟩.{\rm CZ}_{S}:\leavevmode\nobreak\ \leavevmode\nobreak\ \ket{x_{1},\ldots,x_{n}% }\rightarrow(-1)^{\prod_{i\in S}x_{i}}\ket{x_{1},\ldots,x_{n}}.roman_CZ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT : | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG ⟩ → ( - 1 ) start_POSTSUPERSCRIPT ∏ start_POSTSUBSCRIPT italic_i ∈ italic_S end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG ⟩ . (1.2) In this work, when S𝑆Sitalic_S is not specified, we will simply call it the CC..CZ gate. The Toffoli gate ToffolinsubscriptToffoli𝑛{\rm Toffoli}_{n}roman_Toffoli start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is equivalent to the CZ[n+1]subscriptCZdelimited-[]𝑛1{\rm CZ}_{[n+1]}roman_CZ start_POSTSUBSCRIPT [ italic_n + 1 ] end_POSTSUBSCRIPT gate up to conjugation by Hadamard gate, namely Toffolin=(In⊗H)⁢CZ[n+1]⁢(In⊗H)subscriptToffoli𝑛tensor-productsuperscript𝐼𝑛𝐻subscriptCZdelimited-[]𝑛1tensor-productsuperscript𝐼𝑛𝐻{\rm Toffoli}_{n}=(I^{n}\otimes H){\rm CZ}_{[n+1]}(I^{n}\otimes H)roman_Toffoli start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ⊗ italic_H ) roman_CZ start_POSTSUBSCRIPT [ italic_n + 1 ] end_POSTSUBSCRIPT ( italic_I start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ⊗ italic_H ). One advantage of CC..CZ gates over Toffoli gates in terms of simplicity is that there is no need to introduce an ancillary qubit to define them. So a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d can be written as CZ(d)⁢Ud⁢⋯⁢CZ(1)⁢U1superscriptCZ𝑑subscript𝑈𝑑⋯superscriptCZ1subscript𝑈1{\rm CZ}^{(d)}U_{d}\cdots{\rm CZ}^{(1)}U_{1}roman_CZ start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT italic_U start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ⋯ roman_CZ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, where U1,…,Udsubscript𝑈1…subscript𝑈𝑑U_{1},\ldots,U_{d}italic_U start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_U start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT are tensor products of single qubit gates and CZ(1),…,CZ(d)superscriptCZ1…superscriptCZ𝑑{\rm CZ}^{(1)},\ldots,{\rm CZ}^{(d)}roman_CZ start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , roman_CZ start_POSTSUPERSCRIPT ( italic_d ) end_POSTSUPERSCRIPT are tensor products of CC..CZ gates. At each layer, all CC..CZ gates act on different qubits. The size of the circuit is the total number of CC..CZ gates; this would not change significantly if we also counted single-qubit gates. The complexity class 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is the class of languages that are recognised by 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits with depth O⁢(1)𝑂1O(1)italic_O ( 1 ), polynomial size, and using polynomially many ancillas. (Note that here, we define the family of “𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits” to allow for arbitrary depth, an arbitrary number of ancillas, etc, as our results apply in a more general setting – but when we use the term “𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit” we mean a circuit that corresponds to the complexity class 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT.) The parity function Parityn:{0,1}n→{0,1}:subscriptParity𝑛→superscript01𝑛01{\rm Parity}_{n}:\{0,1\}^{n}\rightarrow\{0,1\}roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → { 0 , 1 } is defined as Parityn⁢(x1,…,xn)=⨁i=1nxi.subscriptParity𝑛subscript𝑥1…subscript𝑥𝑛superscriptsubscriptdirect-sum𝑖1𝑛subscript𝑥𝑖{\rm Parity}_{n}(x_{1},\ldots,x_{n})=\bigoplus_{i=1}^{n}x_{i}.roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = ⨁ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . (1.3) On a quantum circuit, it is implemented as UParityn:|x1,…,xn,b⟩→|x1,…,xn,b⊕⨁i=1nxi⟩U_{{\rm Parity}_{n}}:\leavevmode\nobreak\ \leavevmode\nobreak\ \ket{x_{1},% \ldots,x_{n},b}\rightarrow\ket{x_{1},\ldots,x_{n},b\oplus\bigoplus_{i=1}^{n}x_% {i}}italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT : | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_b end_ARG ⟩ → | start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_b ⊕ ⨁ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ⟩ (1.4) with the introduction of an ancillary qubit. To implement the parity function by a quantum circuit, we usually need to introduce some ancillary qubits. So for a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit, we will always use n𝑛nitalic_n to denote the number of system qubits and a𝑎aitalic_a to denote the number of ancillary qubits. Definition 1.1 ((ε,η)𝜀𝜂(\varepsilon,\eta)( italic_ε , italic_η ) approximation of parity function). Let U𝑈Uitalic_U be a circuit on n+a𝑛𝑎n+aitalic_n + italic_a qubits. We say U𝑈Uitalic_U (ε,η)𝜀𝜂(\varepsilon,\eta)( italic_ε , italic_η ) approximates the parity function if for at least a (1−ε)1𝜀(1-\varepsilon)( 1 - italic_ε ) fraction of x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, with probability at least 1−η1𝜂1-\eta1 - italic_η, the result of measuring a given output qubit (say, the (n+1)𝑛1(n+1)( italic_n + 1 )-th qubit) of U⁢|x,0a⟩𝑈ket𝑥superscript0𝑎U\ket{x,0^{a}}italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ is Parityn⁢(x)subscriptParity𝑛𝑥{\rm Parity}_{n}(x)roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ). The main open problem proposed in [16, 8] can be described as follows. Problem 1.2 (Is parity in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT?). Let ε∈[0,1),η∈[0,1/2]formulae-sequence𝜀01𝜂012\varepsilon\in[0,1),\eta\in[0,1/2]italic_ε ∈ [ 0 , 1 ) , italic_η ∈ [ 0 , 1 / 2 ]. Is computing an (ε,η)𝜀𝜂(\varepsilon,\eta)( italic_ε , italic_η ) approximation of the parity function in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT? The definition of Problem 1.2 here is weaker than the one proposed in [16]. In that case, ε=η=0𝜀𝜂0\varepsilon=\eta=0italic_ε = italic_η = 0. That is, the parity function is computed cleanly. This is also the case studied in [8, 4, 18]. The problem here is also weaker than the statement given in [20], in which it is required that ε=0𝜀0\varepsilon=0italic_ε = 0. Classically, if C⁢(x)𝐶𝑥C(x)italic_C ( italic_x ) is the Boolean function computed by a polynomial-size 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit, then it was proved in several celebrated works [15, 19, 21] that Prx∈{0,1}n⁡[C⁢(x)=Parityn⁢(x)]≤12+on⁢(1).subscriptPr𝑥superscript01𝑛𝐶𝑥subscriptParity𝑛𝑥12subscript𝑜𝑛1\Pr_{x\in\{0,1\}^{n}}[C(x)={\rm Parity}_{n}(x)]\leq\frac{1}{2}+o_{n}(1).roman_Pr start_POSTSUBSCRIPT italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_C ( italic_x ) = roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) ] ≤ divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( 1 ) . (1.5) The on⁢(1)subscript𝑜𝑛1o_{n}(1)italic_o start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( 1 ) is a function depending on n𝑛nitalic_n, which is o⁢(1/n)𝑜1𝑛o(1/\sqrt{n})italic_o ( 1 / square-root start_ARG italic_n end_ARG ) in [19, 21] and is o⁢(2−n1/d)𝑜superscript2superscript𝑛1𝑑o(2^{-n^{1/d}})italic_o ( 2 start_POSTSUPERSCRIPT - italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ) in [15]. Equation (1.5) shows the average-case hardness of computing parity by 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. In the quantum case, we can study the following problem similarly. Problem 1.3 (Average case hardness). Let U𝑈Uitalic_U be a 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit with a=poly⁢(n)𝑎poly𝑛a={\rm poly}(n)italic_a = roman_poly ( italic_n ) ancillary qubits. For any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, let Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ) be the output of measuring the (n+1)𝑛1(n+1)( italic_n + 1 )-th qubit of U⁢|x,0a⟩𝑈ket𝑥superscript0𝑎U\ket{x,0^{a}}italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩, then can we find an upper bound on the following probability Pr⁡[Q⁢(x)=Parityn⁢(x)]⁢?Pr𝑄𝑥subscriptParity𝑛𝑥?\Pr[Q(x)={\rm Parity}_{n}(x)]?roman_Pr [ italic_Q ( italic_x ) = roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) ] ? (1.6) Here the probability is taken over all x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and the randomness of Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ). In [20], the author proved that when the depth d=2𝑑2d=2italic_d = 2, then no matter how large the number of ancilla qubits a𝑎aitalic_a is, the probability in Equation (1.6) is at most 12+o⁢(2−n)12𝑜superscript2𝑛\frac{1}{2}+o(2^{-n})divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_o ( 2 start_POSTSUPERSCRIPT - italic_n end_POSTSUPERSCRIPT ). In [17], the authors showed that for any d𝑑ditalic_d, if a<12⁢n1/d𝑎12superscript𝑛1𝑑a<\frac{1}{2}n^{1/d}italic_a < divide start_ARG 1 end_ARG start_ARG 2 end_ARG italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT, then the probability in (1.6) is smaller than 12+o⁢(2−n1/d)12𝑜superscript2superscript𝑛1𝑑\frac{1}{2}+o(2^{-n^{1/d}})divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_o ( 2 start_POSTSUPERSCRIPT - italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). Recently, in [2], the authors proved a similar result but only required a=O~⁢(n1+3−d)𝑎~𝑂superscript𝑛1superscript3𝑑a=\widetilde{O}(n^{1+3^{-d}})italic_a = over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1 + 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). Thus, all these results leave open the possibility that the parity function can be computed with high probability by a 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit with, for example, O⁢(n1.1)𝑂superscript𝑛1.1O(n^{1.1})italic_O ( italic_n start_POSTSUPERSCRIPT 1.1 end_POSTSUPERSCRIPT ) ancilla qubits. A closely relevant problem is the preparation of cat states by low depth quantum circuits. A cat state on n𝑛nitalic_n qubits is a state of the form |CATn⟩:=12⁢(|0n⟩+|1n⟩)assignketsubscriptCAT𝑛12ketsuperscript0𝑛ketsuperscript1𝑛\ket{{\rm CAT}_{n}}:=\frac{1}{\sqrt{2}}(\ket{0^{n}}+\ket{1^{n}})| start_ARG roman_CAT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_ARG ⟩ := divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 end_ARG end_ARG ( | start_ARG 0 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ + | start_ARG 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ ). A more general family of states are called n𝑛nitalic_n-nekomata states, defined as |ν⟩:=12⁢(|0n⟩⁢|ϕ0⟩+|1n⟩⁢|ϕ1⟩)assignket𝜈12ketsuperscript0𝑛ketsubscriptitalic-ϕ0ketsuperscript1𝑛ketsubscriptitalic-ϕ1\ket{\nu}:=\frac{1}{\sqrt{2}}(\ket{0^{n}}\ket{\phi_{0}}+\ket{1^{n}}\ket{\phi_{% 1}})| start_ARG italic_ν end_ARG ⟩ := divide start_ARG 1 end_ARG start_ARG square-root start_ARG 2 end_ARG end_ARG ( | start_ARG 0 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ | start_ARG italic_ϕ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ⟩ + | start_ARG 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ | start_ARG italic_ϕ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG ⟩ ), where |ϕ0⟩,|ϕ1⟩ketsubscriptitalic-ϕ0ketsubscriptitalic-ϕ1\ket{\phi_{0}},\ket{\phi_{1}}| start_ARG italic_ϕ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_ARG ⟩ , | start_ARG italic_ϕ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG ⟩ can be arbitrary states on any number of qubits. In [20], the following problem was proposed. Problem 1.4 (Can nekomata states be constructed in 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT?). Let η∈[0,1)𝜂01\eta\in[0,1)italic_η ∈ [ 0 , 1 ) and let |ν⟩ket𝜈\ket{\nu}| start_ARG italic_ν end_ARG ⟩ be any n𝑛nitalic_n-nekomata state. Is it possible to construct a 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit U𝑈Uitalic_U such that the fidelity of U⁢|0n+a⟩𝑈ketsuperscript0𝑛𝑎U\ket{0^{n+a}}italic_U | start_ARG 0 start_POSTSUPERSCRIPT italic_n + italic_a end_POSTSUPERSCRIPT end_ARG ⟩ and |ν⟩ket𝜈\ket{\nu}| start_ARG italic_ν end_ARG ⟩ is at least 1−η1𝜂1-\eta1 - italic_η? It was also proved in [20, Theorem 3.1] that Problem 1.2 and Problem 1.4 are equivalent. In this work, we provide essentially complete answers to the above three problems. 1.2 Main results For Problem 1.2, our result is as follows. Theorem 1.5 (Parity is not in QAC0). Assume that η∈[0,1/2],ε∈[0,1)formulae-sequence𝜂012𝜀01\eta\in[0,1/2],\varepsilon\in[0,1)italic_η ∈ [ 0 , 1 / 2 ] , italic_ε ∈ [ 0 , 1 ) satisfying that (1−η)⁢(1−ε)>1/2+2−Ω⁢(n1/d/log⁡n)1𝜂1𝜀12superscript2Ωsuperscript𝑛1𝑑𝑛(1-\eta)(1-\varepsilon)>{1}/{2}+2^{-\Omega({n^{1/d}}/{\log n})}( 1 - italic_η ) ( 1 - italic_ε ) > 1 / 2 + 2 start_POSTSUPERSCRIPT - roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / roman_log italic_n ) end_POSTSUPERSCRIPT. Then any QAC0 circuit of depth d𝑑ditalic_d cannot (ε,η)𝜀𝜂(\varepsilon,\eta)( italic_ε , italic_η )-approximate the parity function. As a direct application, we have the following result. Corollary 1.6. 𝐐𝐀𝐂0⫋𝐐𝐀𝐂wf0superscript𝐐𝐀𝐂0superscriptsubscript𝐐𝐀𝐂wf0{\bf QAC}^{0}\subsetneqq{\bf QAC}_{\rm wf}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT ⫋ bold_QAC start_POSTSUBSCRIPT roman_wf end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. We also have the following more concrete characterisation of the number of ancillary qubits to compute parity. Theorem 1.7 (Computing parity by QAC require exponentially many ancillas). Assume that η∈[0,1/2],ε∈[0,1)formulae-sequence𝜂012𝜀01\eta\in[0,1/2],\varepsilon\in[0,1)italic_η ∈ [ 0 , 1 / 2 ] , italic_ε ∈ [ 0 , 1 ) such that (1−η)⁢(1−ε)>1/21𝜂1𝜀12(1-\eta)(1-\varepsilon)>1/2( 1 - italic_η ) ( 1 - italic_ε ) > 1 / 2. Then any 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d that (ε,η)𝜀𝜂(\varepsilon,\eta)( italic_ε , italic_η ) approximates the n𝑛nitalic_n-bit parity function requires 2Ω⁢(n1/d/c⁢log⁡n)superscript2Ωsuperscript𝑛1𝑑𝑐𝑛2^{\Omega(n^{1/d}/{c\log n})}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / italic_c roman_log italic_n ) end_POSTSUPERSCRIPT ancillary qubits, where c=−log⁡((1−η)⁢(1−ε)−1/2)𝑐1𝜂1𝜀12c=-\log((1-\eta)(1-\varepsilon)-1/2)italic_c = - roman_log ( ( 1 - italic_η ) ( 1 - italic_ε ) - 1 / 2 ). This is close to tight, as Rosenthal showed that there is a constant-depth 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit computing parity with high probability, using exp⁡(poly⁢(n1/d)⁢log⁡(n/η))polysuperscript𝑛1𝑑𝑛𝜂\exp({\rm poly}(n^{1/d})\log(n/\eta))roman_exp ( roman_poly ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) roman_log ( italic_n / italic_η ) ) many ancillary qubits [20]. As a direct application of Theorem 1.7 and [20, Theorem 3.1], we have the following result towards Problem 1.4.222[20, Theorem 3.1] states that if there is a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d, size s𝑠sitalic_s using a𝑎aitalic_a ancillary qubits that prepares a nekomata state with fidelity 1−η1𝜂1-\eta1 - italic_η, then there is a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth 4⁢d+34𝑑34d+34 italic_d + 3, size O⁢(n+s)𝑂𝑛𝑠O(n+s)italic_O ( italic_n + italic_s ) using a𝑎aitalic_a ancillary qubits that (0,O⁢(η))0𝑂𝜂(0,O(\eta))( 0 , italic_O ( italic_η ) ) approximates the parity function. From the proof of this theorem, O⁢(η)=72⁢η𝑂𝜂72𝜂O(\eta)=72\etaitalic_O ( italic_η ) = 72 italic_η. So when using Theorem 1.7, c𝑐citalic_c becomes −log⁡(1/2−72⁢η)1272𝜂-\log(1/2-72\eta)- roman_log ( 1 / 2 - 72 italic_η ) assuming η<1/144𝜂1144\eta<1/144italic_η < 1 / 144. Corollary 1.8 (Preparing nekomata states by 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits requires exponentially many ancillas). Assume that η∈[0,1/144)𝜂01144\eta\in[0,1/144)italic_η ∈ [ 0 , 1 / 144 ). Then any 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d that prepares a n𝑛nitalic_n-nekomata state with fidelity at least 1−η1𝜂1-\eta1 - italic_η requires 2Ω⁢(n1/d/c⁢log⁡n)superscript2Ωsuperscript𝑛1𝑑𝑐𝑛2^{\Omega(n^{1/d}/c\log n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / italic_c roman_log italic_n ) end_POSTSUPERSCRIPT ancillary qubits, where c=−log⁡(1/2−72⁢η)𝑐1272𝜂c=-\log(1/2-72\eta)italic_c = - roman_log ( 1 / 2 - 72 italic_η ). For Problem 1.3, our main result is as follows. Theorem 1.9 (Average case hardness of computing parity by QAC). Let U𝑈Uitalic_U be a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit with depth d𝑑ditalic_d, size s𝑠sitalic_s and a𝑎aitalic_a ancillary qubits. For any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, let Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ) be the output of measuring the (n+1)𝑛1(n+1)( italic_n + 1 )-th qubit of U⁢|x,0a⟩𝑈ket𝑥superscript0𝑎U\ket{x,0^{a}}italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩. Then Pr⁡[Q⁢(x)=Parityn⁢(x)]≤12+s⋅2−Ω⁢(n~/log⁡n~),Pr𝑄𝑥subscriptParity𝑛𝑥12⋅𝑠superscript2Ω~𝑛~𝑛\Pr\Big{[}Q(x)={\rm Parity}_{n}(x)\Big{]}\leq\frac{1}{2}+\sqrt{s}\cdot 2^{-% \Omega(\tilde{n}/\log\tilde{n})},roman_Pr [ italic_Q ( italic_x ) = roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) ] ≤ divide start_ARG 1 end_ARG start_ARG 2 end_ARG + square-root start_ARG italic_s end_ARG ⋅ 2 start_POSTSUPERSCRIPT - roman_Ω ( over~ start_ARG italic_n end_ARG / roman_log over~ start_ARG italic_n end_ARG ) end_POSTSUPERSCRIPT , (1.7) where n~=n1/dlog⁡(n+a)~𝑛superscript𝑛1𝑑𝑛𝑎\tilde{n}=\frac{n^{1/d}}{\log(n+a)}over~ start_ARG italic_n end_ARG = divide start_ARG italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT end_ARG start_ARG roman_log ( italic_n + italic_a ) end_ARG and the probability is taken over all x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and the randomness of Q⁢(x)𝑄𝑥Q(x)italic_Q ( italic_x ). In particular, for 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits, we have Pr⁡[Q⁢(x)=Parityn⁢(x)]≤12+2−Ω⁢(n1/d/log⁡n).Pr𝑄𝑥subscriptParity𝑛𝑥12superscript2Ωsuperscript𝑛1𝑑𝑛\Pr\Big{[}Q(x)={\rm Parity}_{n}(x)\Big{]}\leq\frac{1}{2}+2^{-\Omega({n^{1/d}}/% {\log n})}.roman_Pr [ italic_Q ( italic_x ) = roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) ] ≤ divide start_ARG 1 end_ARG start_ARG 2 end_ARG + 2 start_POSTSUPERSCRIPT - roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / roman_log italic_n ) end_POSTSUPERSCRIPT . (1.8) Theorem 1.9 follows from a quantum analog of the LMN theorem [15], which we now state. Theorem 1.10 (Fourier spectrum of 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits). Let U𝑈Uitalic_U be a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d and size s𝑠sitalic_s, acting on n+a𝑛𝑎n+aitalic_n + italic_a qubits. Let δ∈(0,1]𝛿01\delta\in(0,1]italic_δ ∈ ( 0 , 1 ] and k=(O⁢((log⁡(n+a))⁢(log⁡s/δ)⁢(log⁡log⁡s/δ)))d.𝑘superscript𝑂𝑛𝑎𝑠𝛿𝑠𝛿𝑑k=\Big{(}O\big{(}(\log(n+a))(\log s/\delta)(\log\log s/\delta)\big{)}\Big{)}^{% d}.italic_k = ( italic_O ( ( roman_log ( italic_n + italic_a ) ) ( roman_log italic_s / italic_δ ) ( roman_log roman_log italic_s / italic_δ ) ) ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT . (1.9) Then for the function f⁢(x):=⟨x,0a|⁢U†⁢Zn+1⁢U⁢|x,0a⟩assign𝑓𝑥bra𝑥superscript0𝑎superscript𝑈†subscript𝑍𝑛1𝑈ket𝑥superscript0𝑎f(x):=\bra{x,0^{a}}U^{\dagger}Z_{n+1}U\ket{x,0^{a}}italic_f ( italic_x ) := ⟨ start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ (1.10) from {0,1}nsuperscript01𝑛\{0,1\}^{n}{ 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT to [−1,1]11[-1,1][ - 1 , 1 ], we have ∑|S|>kf^⁢(S)2≤δ.subscript𝑆𝑘^𝑓superscript𝑆2𝛿\sum_{|S|>k}\widehat{f}(S)^{2}\leq\delta.∑ start_POSTSUBSCRIPT | italic_S | > italic_k end_POSTSUBSCRIPT over^ start_ARG italic_f end_ARG ( italic_S ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≤ italic_δ . (1.11) In the above, f^⁢(S)^𝑓𝑆\widehat{f}(S)over^ start_ARG italic_f end_ARG ( italic_S ) are the Fourier coefficients of the real-valued Boolean function f⁢(x)𝑓𝑥f(x)italic_f ( italic_x ). For 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits, k=poly⁢(log⁡n)𝑘poly𝑛k={\rm poly}(\log n)italic_k = roman_poly ( roman_log italic_n ) in (1.9). So Theorem 1.10 shows that the Fourier coefficients of the real-valued Boolean function f⁢(x)𝑓𝑥f(x)italic_f ( italic_x ) defined by a 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit are concentrated on the low-degree parts. Consequently, the function f⁢(x)𝑓𝑥f(x)italic_f ( italic_x ) can be learned using quasipolynomially many samples, which coincides with the LMN theorem [15] for 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. 1.3 Technical overview Before starting the technical parts, we briefly recall some notation relating to Pauli matrices. In this work, Pauli matrices are denoted as I,X,Y,Z𝐼𝑋𝑌𝑍I,X,Y,Zitalic_I , italic_X , italic_Y , italic_Z. They are defined as I=(1001),X=(0110),Y=(0−ii0),Z=(100−1).formulae-sequence𝐼matrix1001formulae-sequence𝑋matrix0110formulae-sequence𝑌matrix0𝑖𝑖0𝑍matrix1001I=\begin{pmatrix}1&0\\ 0&1\end{pmatrix},\quad X=\begin{pmatrix}0&1\\ 1&0\end{pmatrix},\quad Y=\begin{pmatrix}0&-i\\ i&0\end{pmatrix},\quad Z=\begin{pmatrix}1&0\\ 0&-1\end{pmatrix}.italic_I = ( start_ARG start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL 1 end_CELL end_ROW end_ARG ) , italic_X = ( start_ARG start_ROW start_CELL 0 end_CELL start_CELL 1 end_CELL end_ROW start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW end_ARG ) , italic_Y = ( start_ARG start_ROW start_CELL 0 end_CELL start_CELL - italic_i end_CELL end_ROW start_ROW start_CELL italic_i end_CELL start_CELL 0 end_CELL end_ROW end_ARG ) , italic_Z = ( start_ARG start_ROW start_CELL 1 end_CELL start_CELL 0 end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL - 1 end_CELL end_ROW end_ARG ) . When a Pauli matrix, say Z𝑍Zitalic_Z, is acting on the i𝑖iitalic_i-th qubit of n𝑛nitalic_n qubits, then we sometimes simply write it as Zisubscript𝑍𝑖Z_{i}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, which represents Zi⊗I[n]\{i}tensor-productsubscript𝑍𝑖subscript𝐼\delimited-[]𝑛𝑖Z_{i}\otimes I_{[n]\backslash\{i\}}italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⊗ italic_I start_POSTSUBSCRIPT [ italic_n ] \ { italic_i } end_POSTSUBSCRIPT. For any operator A𝐴Aitalic_A acting on n𝑛nitalic_n qubits, it has a Pauli decomposition A=∑PαP⁢σP𝐴subscript𝑃subscript𝛼𝑃subscript𝜎𝑃A=\sum_{P}\alpha_{P}\sigma_{P}italic_A = ∑ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT italic_α start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT, where σP∈{I,X,Y,Z}⊗nsubscript𝜎𝑃superscript𝐼𝑋𝑌𝑍tensor-productabsent𝑛\sigma_{P}\in\{I,X,Y,Z\}^{\otimes n}italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ∈ { italic_I , italic_X , italic_Y , italic_Z } start_POSTSUPERSCRIPT ⊗ italic_n end_POSTSUPERSCRIPT, and the coefficients αPsubscript𝛼𝑃\alpha_{P}italic_α start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT are computed via αP=⟨A,σP⟩=12n⁢Tr⁢(A†⁢σP).subscript𝛼𝑃𝐴subscript𝜎𝑃1superscript2𝑛Trsuperscript𝐴†subscript𝜎𝑃\alpha_{P}=\langle A,\sigma_{P}\rangle=\frac{1}{2^{n}}{\rm Tr}(A^{\dagger}% \sigma_{P}).italic_α start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT = ⟨ italic_A , italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ⟩ = divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG roman_Tr ( italic_A start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ) . Each σP=σ1⊗⋯⊗σnsubscript𝜎𝑃tensor-productsubscript𝜎1⋯subscript𝜎𝑛\sigma_{P}=\sigma_{1}\otimes\cdots\otimes\sigma_{n}italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT = italic_σ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ⊗ ⋯ ⊗ italic_σ start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT defines a Pauli degree #⁢{i∈[n]:σi≠I}#conditional-set𝑖delimited-[]𝑛subscript𝜎𝑖𝐼\#\{i\in[n]:\sigma_{i}\neq I\}# { italic_i ∈ [ italic_n ] : italic_σ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≠ italic_I }. The Pauli degree of A𝐴Aitalic_A is the largest Pauli degree of all σPsubscript𝜎𝑃\sigma_{P}italic_σ start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT with αP≠0subscript𝛼𝑃0\alpha_{P}\neq 0italic_α start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ≠ 0. All our main results above are based on the following theorem. We actually proved a more general result that says 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits can be approximated by low Pauli degree operators in the Pauli decomposition, see Theorem 2.8 for more details. However, for the main results stated above, the following special case is enough. The degree in the following theorem refers to the degree of polynomials, not the Pauli degree of operators we just discussed, highlighting a key difference between the following theorem and Theorem 2.8. Theorem 1.11. Let U𝑈Uitalic_U be a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of depth d𝑑ditalic_d and size s𝑠sitalic_s, acting on n+a𝑛𝑎n+aitalic_n + italic_a qubits. Let ε,δ∈(0,1)𝜀𝛿01\varepsilon,\delta\in(0,1)italic_ε , italic_δ ∈ ( 0 , 1 ). Then there is a distribution 𝒟𝒟\mathcal{D}caligraphic_D on polynomials from {0,1}n→[−1,1]→superscript01𝑛11\{0,1\}^{n}\rightarrow[-1,1]{ 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → [ - 1 , 1 ] of degree at most (O⁢((log⁡(n+a))⁢(log⁡1/ε)⁢(log⁡log⁡1/ε)))dsuperscript𝑂𝑛𝑎1𝜀1𝜀𝑑\Big{(}O\big{(}(\log(n+a))(\log 1/\varepsilon)(\log\log 1/\varepsilon)\big{)}% \Big{)}^{d}( italic_O ( ( roman_log ( italic_n + italic_a ) ) ( roman_log 1 / italic_ε ) ( roman_log roman_log 1 / italic_ε ) ) ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT (1.12) such that for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, Prg∼𝒟⁡[|g⁢(x)−⟨x,0a|⁢U†⁢Zn+1⁢U⁢|x,0a⟩|≤2⁢s⁢ε]≥(1−ε)s,subscriptPrsimilar-to𝑔𝒟𝑔𝑥bra𝑥superscript0𝑎superscript𝑈†subscript𝑍𝑛1𝑈ket𝑥superscript0𝑎2𝑠𝜀superscript1𝜀𝑠\Pr_{g\sim\mathcal{D}}\left[\,\Big{|}g(x)-\bra{x,0^{a}}U^{\dagger}Z_{n+1}U\ket% {x,0^{a}}\Big{|}\leq 2s\varepsilon\,\right]\geq(1-\varepsilon)^{s},roman_Pr start_POSTSUBSCRIPT italic_g ∼ caligraphic_D end_POSTSUBSCRIPT [ | italic_g ( italic_x ) - ⟨ start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ | ≤ 2 italic_s italic_ε ] ≥ ( 1 - italic_ε ) start_POSTSUPERSCRIPT italic_s end_POSTSUPERSCRIPT , (1.13) In particular, if 1/ε=O⁢(s/δ)1𝜀𝑂𝑠𝛿1/\varepsilon=O(s/\delta)1 / italic_ε = italic_O ( italic_s / italic_δ ), then for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, Prg∼𝒟⁡[|g⁢(x)−⟨x,0a|⁢U†⁢Zn+1⁢U⁢|x,0a⟩|≤δ]≥1−δ.subscriptPrsimilar-to𝑔𝒟𝑔𝑥bra𝑥superscript0𝑎superscript𝑈†subscript𝑍𝑛1𝑈ket𝑥superscript0𝑎𝛿1𝛿\Pr_{g\sim\mathcal{D}}\left[\,\Big{|}g(x)-\bra{x,0^{a}}U^{\dagger}Z_{n+1}U\ket% {x,0^{a}}\Big{|}\leq\delta\,\right]\geq 1-\delta.roman_Pr start_POSTSUBSCRIPT italic_g ∼ caligraphic_D end_POSTSUBSCRIPT [ | italic_g ( italic_x ) - ⟨ start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ | ≤ italic_δ ] ≥ 1 - italic_δ . (1.14) Theorem 1.11 can be viewed as a quantum analog of Razborov-Smolensky’s low-degree approximation for 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits, see [19, 21]. For an 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit of depth d𝑑ditalic_d and size s𝑠sitalic_s, Razborov-Smolensky’s result shows that there is a distribution on real polynomials of degree O⁢((log⁡s)2⁢d)𝑂superscript𝑠2𝑑O((\log s)^{2d})italic_O ( ( roman_log italic_s ) start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT ) such that for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, if we randomly choose a polynomial from the distribution, then with high probability it coincides with the output of the 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit. On the other hand, it was also proved that the parity function cannot be computed in the same sense by a low-degree polynomial. Thus, this proves that parity is not in 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT. Theorem 1.11 above is indeed inspired by Razborov-Smolensky’s result. However, we obtained more than Razborov-Smolensky’s proof. A surprising result is the quantum analog of the LMN theorem, stated in Theorem 1.10. In comparison, Razborov-Smolensky’s proof does not lead to a result on the Fourier spectrum of 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuits.333From our proofs, we feel Razborov-Smolensky’s proof should lead to a result similar to the LMN theorem, but this may not have been obvious previously. See Section 4. Once we have this result on low-degree approximation, together with some classical results on parity function, we can prove Theorem 1.5 and relevant results stated in the above section, see Section 3. To highlight the proof of Theorem 1.11, we first recall Razborov-Smolensky’s idea for low-degree approximation of the OR function. Note that the n𝑛nitalic_n-bit OR function is ORn⁢(x)=1−∏i=1n(1−xi)subscriptOR𝑛𝑥1superscriptsubscriptproduct𝑖1𝑛1subscript𝑥𝑖{\rm OR}_{n}(x)=1-\prod_{i=1}^{n}(1-x_{i})roman_OR start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) = 1 - ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( 1 - italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ), to approximate it by a low-degree polynomial, we introduce m=log⁡n𝑚𝑛m=\log nitalic_m = roman_log italic_n random linear polynomials pi⁢(x)=∑j∈Sixjsubscript𝑝𝑖𝑥subscript𝑗subscript𝑆𝑖subscript𝑥𝑗p_{i}(x)=\sum_{j\in S_{i}}x_{j}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) = ∑ start_POSTSUBSCRIPT italic_j ∈ italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT and construct c⁢(x)=1−∏i=1m(1−pi⁢(x))𝑐𝑥1superscriptsubscriptproduct𝑖1𝑚1subscript𝑝𝑖𝑥c(x)=1-\prod_{i=1}^{m}(1-p_{i}(x))italic_c ( italic_x ) = 1 - ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( 1 - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ). Here j∈[n]𝑗delimited-[]𝑛j\in[n]italic_j ∈ [ italic_n ] is put into Sisubscript𝑆𝑖S_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT with probability 1/2i1superscript2𝑖1/2^{i}1 / 2 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT. As we can see, there is a distribution in the construction of pisubscript𝑝𝑖p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. It can be proved that for any x𝑥xitalic_x, with a constant probability with respect to this distribution, c⁢(x)=ORn⁢(x)𝑐𝑥subscriptOR𝑛𝑥c(x)={\rm OR}_{n}(x)italic_c ( italic_x ) = roman_OR start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ). We can increase the success probability to 1−ε1𝜀1-\varepsilon1 - italic_ε for any given x𝑥xitalic_x by generating ℓ=Ω⁢(log⁡1/ε)ℓΩ1𝜀\ell=\Omega(\log 1/\varepsilon)roman_ℓ = roman_Ω ( roman_log 1 / italic_ε ) such polynomials c1⁢(x),…,cℓ⁢(x)subscript𝑐1𝑥…subscript𝑐ℓ𝑥c_{1}(x),\ldots,c_{\ell}(x)italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x ) , … , italic_c start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ( italic_x ) and considering their average C⁢(x)=1−∏i=1ℓ(1−ci⁢(x))𝐶𝑥1superscriptsubscriptproduct𝑖1ℓ1subscript𝑐𝑖𝑥C(x)=1-\prod_{i=1}^{\ell}(1-c_{i}(x))italic_C ( italic_x ) = 1 - ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT ( 1 - italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) ). The degree of C⁢(x)𝐶𝑥C(x)italic_C ( italic_x ) is only log⁡(n)⁢log⁡(1/ε)𝑛1𝜀\log(n)\log(1/\varepsilon)roman_log ( italic_n ) roman_log ( 1 / italic_ε ). In the quantum case, the basic building blocks of 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits are the CC..CZ gates. By definition, CZ[n]=I−12n−1⁢∏i=1n(I−Zi).subscriptCZdelimited-[]𝑛𝐼1superscript2𝑛1superscriptsubscriptproduct𝑖1𝑛𝐼subscript𝑍𝑖{\rm CZ}_{[n]}=I-\frac{1}{2^{n-1}}\prod_{i=1}^{n}(I-Z_{i}).roman_CZ start_POSTSUBSCRIPT [ italic_n ] end_POSTSUBSCRIPT = italic_I - divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_I - italic_Z start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . (1.15) So we also generate m=log⁡n𝑚𝑛m=\log nitalic_m = roman_log italic_n random linear operators pi=∑j∈SiZjsubscript𝑝𝑖subscript𝑗subscript𝑆𝑖subscript𝑍𝑗p_{i}=\sum_{j\in S_{i}}Z_{j}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_j ∈ italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_Z start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT (here j∈[n]𝑗delimited-[]𝑛j\in[n]italic_j ∈ [ italic_n ] is put into Sisubscript𝑆𝑖S_{i}italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT also with probability 1/2i1superscript2𝑖1/2^{i}1 / 2 start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT) and consider q=I−2M2⁢∏i=1m(I−pi)2𝑞𝐼2superscript𝑀2superscriptsubscriptproduct𝑖1𝑚superscript𝐼subscript𝑝𝑖2q=I-\frac{2}{M^{2}}\prod_{i=1}^{m}(I-p_{i})^{2}italic_q = italic_I - divide start_ARG 2 end_ARG start_ARG italic_M start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( italic_I - italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT (1.16) for some M𝑀Mitalic_M such that ⟨1n|⁢q⁢|1n⟩=−1brasuperscript1𝑛𝑞ketsuperscript1𝑛1\bra{1^{n}}q\ket{1^{n}}=-1⟨ start_ARG 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG | italic_q | start_ARG 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ⟩ = - 1, i.e., M=∏i=1m(1+#⁢(Si))𝑀superscriptsubscriptproduct𝑖1𝑚1#subscript𝑆𝑖M=\prod_{i=1}^{m}(1+\#(S_{i}))italic_M = ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( 1 + # ( italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ). In (1.16), the square is added to ensure that ⟨x|⁢q⁢|x⟩∈[−1,1]bra𝑥𝑞ket𝑥11\bra{x}q\ket{x}\in[-1,1]⟨ start_ARG italic_x end_ARG | italic_q | start_ARG italic_x end_ARG ⟩ ∈ [ - 1 , 1 ] for all x𝑥xitalic_x, i.e., ‖q‖≤1norm𝑞1\|q\|\leq 1∥ italic_q ∥ ≤ 1.444This is a big difference between the standard classical construction and ours. Classically, c⁢(x)𝑐𝑥c(x)italic_c ( italic_x ) defined above is not a bounded polynomial as it can take values as large as poly⁢(n)poly𝑛{\rm poly}(n)roman_poly ( italic_n ) at some inputs. However, quantumly q𝑞qitalic_q is a bounded operator. In Lemma 2.1, we will prove that for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and x≠1n𝑥superscript1𝑛x\neq 1^{n}italic_x ≠ 1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, with a constant probability, |⟨x|⁢q⁢|x⟩−1|≤1/3bra𝑥𝑞ket𝑥113|\bra{x}q\ket{x}-1|\leq 1/3| ⟨ start_ARG italic_x end_ARG | italic_q | start_ARG italic_x end_ARG ⟩ - 1 | ≤ 1 / 3. Finally, we can increase the level of accuracy and the success probability by considering Q=I−12ℓ−1⁢∏i=1ℓ(I−qi).𝑄𝐼1superscript2ℓ1superscriptsubscriptproduct𝑖1ℓ𝐼subscript𝑞𝑖Q=I-\frac{1}{2^{\ell-1}}\prod_{i=1}^{\ell}(I-q_{i}).italic_Q = italic_I - divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT roman_ℓ - 1 end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_ℓ end_POSTSUPERSCRIPT ( italic_I - italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) . (1.17) Let 𝒟q,𝒟Qsubscript𝒟𝑞subscript𝒟𝑄\mathcal{D}_{q},\mathcal{D}_{Q}caligraphic_D start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT , caligraphic_D start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT denote the distributions on operators q𝑞qitalic_q and Q𝑄Qitalic_Q, respectively. We will use these distributions throughout the paper. The connection between classical and quantum approximation can be understood by observing for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, we have that ⟨x|⁢CZ[n]⁢|x⟩=(−1)ANDn⁢(x)bra𝑥subscriptCZdelimited-[]𝑛ket𝑥superscript1subscriptAND𝑛𝑥\bra{x}{\rm CZ}_{[n]}\ket{x}=(-1)^{{\rm AND}_{n}(x)}⟨ start_ARG italic_x end_ARG | roman_CZ start_POSTSUBSCRIPT [ italic_n ] end_POSTSUBSCRIPT | start_ARG italic_x end_ARG ⟩ = ( - 1 ) start_POSTSUPERSCRIPT roman_AND start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) end_POSTSUPERSCRIPT. For function ANDn⁢(x)=1−ORn⁢(x¯)subscriptAND𝑛𝑥1subscriptOR𝑛¯𝑥{\rm AND}_{n}(x)=1-{\rm OR}_{n}(\bar{x})roman_AND start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) = 1 - roman_OR start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( over¯ start_ARG italic_x end_ARG ), using (−1)x=1−2⁢xsuperscript1𝑥12𝑥(-1)^{x}=1-2x( - 1 ) start_POSTSUPERSCRIPT italic_x end_POSTSUPERSCRIPT = 1 - 2 italic_x for x∈{0,1}𝑥01x\in\{0,1\}italic_x ∈ { 0 , 1 }, we have that ANDn⁢(x)=12n⁢∏i=1n(1−(−1)xi).subscriptAND𝑛𝑥1superscript2𝑛superscriptsubscriptproduct𝑖1𝑛1superscript1subscript𝑥𝑖{\rm AND}_{n}(x)=\frac{1}{2^{n}}\prod_{i=1}^{n}(1-(-1)^{x_{i}}).roman_AND start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) = divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( 1 - ( - 1 ) start_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) . (1.18) Namely, (−1)ANDn⁢(x)=1−2⁢A⁢N⁢Dn⁢(x)=1−12n−1⁢∏i=1n(1−(−1)xi).superscript1subscriptAND𝑛𝑥12ANsubscriptD𝑛𝑥11superscript2𝑛1superscriptsubscriptproduct𝑖1𝑛1superscript1subscript𝑥𝑖(-1)^{{\rm AND}_{n}(x)}=1-2{\rm AND}_{n}(x)=1-\frac{1}{2^{n-1}}\prod_{i=1}^{n}% (1-(-1)^{x_{i}}).( - 1 ) start_POSTSUPERSCRIPT roman_AND start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) end_POSTSUPERSCRIPT = 1 - 2 roman_A roman_N roman_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) = 1 - divide start_ARG 1 end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( 1 - ( - 1 ) start_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) . (1.19) In (1.16), for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, ⟨x|⁢q⁢|x⟩=1−2M2⁢∏i=1m(1−∑j∈Si(−1)xj)2.bra𝑥𝑞ket𝑥12superscript𝑀2superscriptsubscriptproduct𝑖1𝑚superscript1subscript𝑗subscript𝑆𝑖superscript1subscript𝑥𝑗2\bra{x}q\ket{x}=1-\frac{2}{M^{2}}\prod_{i=1}^{m}\left(1-\sum_{j\in S_{i}}(-1)^% {x_{j}}\right)^{2}.⟨ start_ARG italic_x end_ARG | italic_q | start_ARG italic_x end_ARG ⟩ = 1 - divide start_ARG 2 end_ARG start_ARG italic_M start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT ( 1 - ∑ start_POSTSUBSCRIPT italic_j ∈ italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT ( - 1 ) start_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT . (1.20) Compared with (−1)ANDn⁢(x)superscript1subscriptAND𝑛𝑥(-1)^{{\rm AND}_{n}(x)}( - 1 ) start_POSTSUPERSCRIPT roman_AND start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) end_POSTSUPERSCRIPT, it replaces each (−1)xisuperscript1subscript𝑥𝑖(-1)^{x_{i}}( - 1 ) start_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT by the square of a random linear function. For a general 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit, to approximate it by a low-degree polynomial, we only need to replace each OR and AND function with a random low-degree polynomial. After d𝑑ditalic_d layers of composition, the degree of this low-degree approximate polynomial is (log⁡(n)⁢log⁡(1/ε))dsuperscript𝑛1𝜀𝑑(\log(n)\log(1/\varepsilon))^{d}( roman_log ( italic_n ) roman_log ( 1 / italic_ε ) ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. If the size of the 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit is s𝑠sitalic_s, then it suffices to set ε=1/O⁢(s)𝜀1𝑂𝑠\varepsilon=1/O(s)italic_ε = 1 / italic_O ( italic_s ) to ensure a high probability of approximation. In the end, the degree is bounded by (log⁡s)2⁢dsuperscript𝑠2𝑑(\log s)^{2d}( roman_log italic_s ) start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT. However, in the quantum case, the proof of low-degree approximation of 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is more involved. We work with the observable U†⁢Zn+1⁢Usuperscript𝑈†subscript𝑍𝑛1𝑈U^{\dagger}Z_{n+1}Uitalic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U corresponding to measurement of the (n+1)𝑛1(n+1)( italic_n + 1 )-th qubit following a QAC circuit U𝑈Uitalic_U. In the circuit U𝑈Uitalic_U, we can similarly replace each CC..CZ gate by a random low-degree operator defined above to obtain a new operator U~~𝑈\widetilde{U}over~ start_ARG italic_U end_ARG. However, although each multi-qubit operator in U~~𝑈\widetilde{U}over~ start_ARG italic_U end_ARG is low-degree, U~†⁢Zn+1⁢U~superscript~𝑈†subscript𝑍𝑛1~𝑈\widetilde{U}^{\dagger}Z_{n+1}\widetilde{U}over~ start_ARG italic_U end_ARG start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT over~ start_ARG italic_U end_ARG can still be a high-degree operator. To obtain a truly low-degree approximation, we have to further modify the operator U~†⁢Zn+1⁢U~superscript~𝑈†subscript𝑍𝑛1~𝑈\widetilde{U}^{\dagger}Z_{n+1}\widetilde{U}over~ start_ARG italic_U end_ARG start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT over~ start_ARG italic_U end_ARG and use a lightcone argument. Below, we use a simple example to explain our main idea; the detailed argument is given in Section 2. Assume that M=σA⊗IB+IA⊗σB𝑀tensor-productsubscript𝜎𝐴subscript𝐼𝐵tensor-productsubscript𝐼𝐴subscript𝜎𝐵M=\sigma_{A}\otimes I_{B}+I_{A}\otimes\sigma_{B}italic_M = italic_σ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_I start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT + italic_I start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_σ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT is a low-degree operator. Let C=CZA⊗CZB𝐶tensor-productsubscriptCZ𝐴subscriptCZ𝐵C={\rm CZ}_{A}\otimes{\rm CZ}_{B}italic_C = roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, which is a 1-layer QAC0 circuit. We can approximate CZAsubscriptCZ𝐴{\rm CZ}_{A}roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT by QAsubscript𝑄𝐴Q_{A}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT and approximate CZBsubscriptCZ𝐵{\rm CZ}_{B}roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT by QBsubscript𝑄𝐵Q_{B}italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, where QA,QBsubscript𝑄𝐴subscript𝑄𝐵Q_{A},Q_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT are low-degree operators defined via Equation (1.17). It is easy to check that M0:=C⁢M⁢C=CZA⁢σA⁢CZA⊗IB+IA⊗CZB⁢σB⁢CZBassignsubscript𝑀0𝐶𝑀𝐶tensor-productsubscriptCZ𝐴subscript𝜎𝐴subscriptCZ𝐴subscript𝐼𝐵tensor-productsubscript𝐼𝐴subscriptCZ𝐵subscript𝜎𝐵subscriptCZ𝐵M_{0}:=CMC={\rm CZ}_{A}\sigma_{A}{\rm CZ}_{A}\otimes I_{B}+I_{A}\otimes{\rm CZ% }_{B}\sigma_{B}{\rm CZ}_{B}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := italic_C italic_M italic_C = roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_I start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT + italic_I start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT. A natural way to approximate this is considering M1:=(QA⊗QB)⁢M⁢(QA⊗QB)assignsubscript𝑀1tensor-productsubscript𝑄𝐴subscript𝑄𝐵𝑀tensor-productsubscript𝑄𝐴subscript𝑄𝐵M_{1}:=(Q_{A}\otimes Q_{B})M(Q_{A}\otimes Q_{B})italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT := ( italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) italic_M ( italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ), which is QA⁢σA⁢QA⊗QB2+QA2⊗QB⁢σB⁢QBtensor-productsubscript𝑄𝐴subscript𝜎𝐴subscript𝑄𝐴superscriptsubscript𝑄𝐵2tensor-productsuperscriptsubscript𝑄𝐴2subscript𝑄𝐵subscript𝜎𝐵subscript𝑄𝐵Q_{A}\sigma_{A}Q_{A}\otimes Q_{B}^{2}+Q_{A}^{2}\otimes Q_{B}\sigma_{B}Q_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT; so we see that the degree has increased. If there are many terms like QA2,QB2superscriptsubscript𝑄𝐴2superscriptsubscript𝑄𝐵2Q_{A}^{2},Q_{B}^{2}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the degree could increase significantly. As QA≈CZA,QB≈CZBformulae-sequencesubscript𝑄𝐴subscriptCZ𝐴subscript𝑄𝐵subscriptCZ𝐵Q_{A}\approx{\rm CZ}_{A},Q_{B}\approx{\rm CZ}_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ≈ roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ≈ roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, we have QA2≈IA,QB2≈IBformulae-sequencesuperscriptsubscript𝑄𝐴2subscript𝐼𝐴superscriptsubscript𝑄𝐵2subscript𝐼𝐵Q_{A}^{2}\approx I_{A},Q_{B}^{2}\approx I_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≈ italic_I start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≈ italic_I start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT. Thus, we can consider a truly low-degree operator M2:=QA⁢σA⁢QA⊗IB+IA⊗QB⁢σB⁢QBassignsubscript𝑀2tensor-productsubscript𝑄𝐴subscript𝜎𝐴subscript𝑄𝐴subscript𝐼𝐵tensor-productsubscript𝐼𝐴subscript𝑄𝐵subscript𝜎𝐵subscript𝑄𝐵M_{2}:=Q_{A}\sigma_{A}Q_{A}\otimes I_{B}+I_{A}\otimes Q_{B}\sigma_{B}Q_{B}italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_I start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT + italic_I start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT. The technical part is to prove M0≈M2subscript𝑀0subscript𝑀2M_{0}\approx M_{2}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≈ italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Although each term in M0,M2subscript𝑀0subscript𝑀2M_{0},M_{2}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is close to each other, there may be exponentially many terms in M𝑀Mitalic_M in the general case. So we apparently cannot bound the error directly using the triangle inequality. Our key idea here is to encode QA,QBsubscript𝑄𝐴subscript𝑄𝐵Q_{A},Q_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT into unitaries acting on a larger set of qubits and estimate the error in a global way. To be more exact, it is easy to prove M0,M1subscript𝑀0subscript𝑀1M_{0},M_{1}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT are close to each other by noting that CZA⊗CZB≈QA⊗QBtensor-productsubscriptCZ𝐴subscriptCZ𝐵tensor-productsubscript𝑄𝐴subscript𝑄𝐵{\rm CZ}_{A}\otimes{\rm CZ}_{B}\approx Q_{A}\otimes Q_{B}roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ≈ italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT because it is a tensor product form. If QA,QBsubscript𝑄𝐴subscript𝑄𝐵Q_{A},Q_{B}italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT are unitary, then M1=M2subscript𝑀1subscript𝑀2M_{1}=M_{2}italic_M start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Unfortunately, they are not in general. But we can encode them into unitaries, denoted as UA,UBsubscript𝑈𝐴subscript𝑈𝐵U_{A},U_{B}italic_U start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_U start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT respectively, because ‖QA‖≤1,‖QB‖≤1formulae-sequencenormsubscript𝑄𝐴1normsubscript𝑄𝐵1\|Q_{A}\|\leq 1,\|Q_{B}\|\leq 1∥ italic_Q start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ∥ ≤ 1 , ∥ italic_Q start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ∥ ≤ 1. We can also put them in the top left corner. For CZA,CZBsubscriptCZ𝐴subscriptCZ𝐵{\rm CZ}_{A},{\rm CZ}_{B}roman_CZ start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , roman_CZ start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT, we can do a similar encoding and obtain two unitaries VA,VBsubscript𝑉𝐴subscript𝑉𝐵V_{A},V_{B}italic_V start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT , italic_V start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT. For consistency, we carefully encode M𝑀Mitalic_M to obtain a new operator M~~𝑀\widetilde{M}over~ start_ARG italic_M end_ARG such that M𝑀Mitalic_M is in the top left corner. Finally, we prove that M0subscript𝑀0M_{0}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is a block of M~0:=(VA⊗VB)†⁢M~⁢(VA⊗VB)assignsubscript~𝑀0superscripttensor-productsubscript𝑉𝐴subscript𝑉𝐵†~𝑀tensor-productsubscript𝑉𝐴subscript𝑉𝐵\widetilde{M}_{0}:=(V_{A}\otimes V_{B})^{\dagger}\widetilde{M}(V_{A}\otimes V_% {B})over~ start_ARG italic_M end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := ( italic_V start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_V start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT over~ start_ARG italic_M end_ARG ( italic_V start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_V start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) and M2subscript𝑀2M_{2}italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is a block of M~2:=(UA⊗UB)†⁢M~⁢(UA⊗UB)assignsubscript~𝑀2superscripttensor-productsubscript𝑈𝐴subscript𝑈𝐵†~𝑀tensor-productsubscript𝑈𝐴subscript𝑈𝐵\widetilde{M}_{2}:=(U_{A}\otimes U_{B})^{\dagger}\widetilde{M}(U_{A}\otimes U_% {B})over~ start_ARG italic_M end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT := ( italic_U start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_U start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT over~ start_ARG italic_M end_ARG ( italic_U start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ⊗ italic_U start_POSTSUBSCRIPT italic_B end_POSTSUBSCRIPT ). Now it is not hard to prove M~0≈M~2subscript~𝑀0subscript~𝑀2\widetilde{M}_{0}\approx\widetilde{M}_{2}over~ start_ARG italic_M end_ARG start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≈ over~ start_ARG italic_M end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT without considering the error caused by each term. As a result, M0≈M2subscript𝑀0subscript𝑀2M_{0}\approx M_{2}italic_M start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≈ italic_M start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. The error depends on the operator norm of M~~𝑀\widetilde{M}over~ start_ARG italic_M end_ARG, which will be proved smaller than the operator norm of M𝑀Mitalic_M. In the end, we use Table 1 to compare the Razborov-Smolensky result [19, 21], the LMN theorem [15] for AC0 circuits and our results for QAC0 circuits. In the table, we omitted the big-O notation. 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT Boolean functions Real-valued Boolean functions f:{0,1}n→{0,1}:𝑓→superscript01𝑛01f:\{0,1\}^{n}\rightarrow\{0,1\}italic_f : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → { 0 , 1 } f⁢(x)=⟨x,0a|⁢U†⁢Zn+1⁢U⁢|x,0a⟩:{0,1}n→[−1,1]:𝑓𝑥bra𝑥superscript0𝑎superscript𝑈†subscript𝑍𝑛1𝑈ket𝑥superscript0𝑎→superscript01𝑛11f(x)=\bra{x,0^{a}}U^{\dagger}Z_{n+1}U\ket{x,0^{a}}:\{0,1\}^{n}\rightarrow[-1,1]italic_f ( italic_x ) = ⟨ start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_Z start_POSTSUBSCRIPT italic_n + 1 end_POSTSUBSCRIPT italic_U | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ : { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → [ - 1 , 1 ] Degree of (log⁡n)⁢(log⁡1/ε)𝑛1𝜀(\log n)(\log 1/\varepsilon)( roman_log italic_n ) ( roman_log 1 / italic_ε ) (log⁡(n+a))⁢(log⁡1/ε)⁢(log⁡log⁡1/ε)𝑛𝑎1𝜀1𝜀(\log(n+a))(\log 1/\varepsilon)(\log\log 1/\varepsilon)( roman_log ( italic_n + italic_a ) ) ( roman_log 1 / italic_ε ) ( roman_log roman_log 1 / italic_ε ) ε𝜀\varepsilonitalic_ε-approximation n𝑛nitalic_n-bit OR function [RS] CC..CZ gate on n+a𝑛𝑎n+aitalic_n + italic_a qubits Choice of ε𝜀\varepsilonitalic_ε ≈δ/sabsent𝛿𝑠\approx\delta/s≈ italic_δ / italic_s [RS] ≈δ/sabsent𝛿𝑠\approx\delta/s≈ italic_δ / italic_s Overall degree k𝑘kitalic_k k=((log⁡n)⁢(log⁡s/δ))d𝑘superscript𝑛𝑠𝛿𝑑k=((\log n)(\log s/\delta))^{d}italic_k = ( ( roman_log italic_n ) ( roman_log italic_s / italic_δ ) ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT [RS] k=(((log(n+a))(logs/δ)(loglogs/δ))dk=(((\log(n+a))(\log s/\delta)(\log\log s/\delta))^{d}italic_k = ( ( ( roman_log ( italic_n + italic_a ) ) ( roman_log italic_s / italic_δ ) ( roman_log roman_log italic_s / italic_δ ) ) start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT of approximation (log⁡s/δ)d−1⁢log⁡(1/δ)superscript𝑠𝛿𝑑11𝛿(\log s/\delta)^{d-1}\log(1/\delta)( roman_log italic_s / italic_δ ) start_POSTSUPERSCRIPT italic_d - 1 end_POSTSUPERSCRIPT roman_log ( 1 / italic_δ ) [LMN] Correlation ≤1/2+o⁢(1/n)absent12𝑜1𝑛\leq 1/2+o(1/\sqrt{n})≤ 1 / 2 + italic_o ( 1 / square-root start_ARG italic_n end_ARG ) [RS] ≤1/2+2−Ω⁢(n1/d/log⁡n)absent12superscript2Ωsuperscript𝑛1𝑑𝑛\leq 1/2+2^{-\Omega(n^{1/d}/\log n)}≤ 1 / 2 + 2 start_POSTSUPERSCRIPT - roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / roman_log italic_n ) end_POSTSUPERSCRIPT with parity ≤1/2+2−Ω⁢(n1/d)absent12superscript2Ωsuperscript𝑛1𝑑\leq 1/2+2^{-\Omega(n^{1/d})}≤ 1 / 2 + 2 start_POSTSUPERSCRIPT - roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT [LMN] Compute parity s≥2Ω⁢(n1/2⁢d)𝑠superscript2Ωsuperscript𝑛12𝑑s\geq 2^{\Omega(n^{1/2d})}italic_s ≥ 2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / 2 italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT [RS] a≥2Ω⁢(n1/d/log⁡n)𝑎superscript2Ωsuperscript𝑛1𝑑𝑛a\geq 2^{\Omega(n^{1/d}/\log n)}italic_a ≥ 2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT / roman_log italic_n ) end_POSTSUPERSCRIPT requires s≥2Ω⁢(n1/d)𝑠superscript2Ωsuperscript𝑛1𝑑s\geq 2^{\Omega(n^{1/d})}italic_s ≥ 2 start_POSTSUPERSCRIPT roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT [LMN] Fourier spectrum ∑|S|>kf^⁢(S)2≤δsubscript𝑆𝑘^𝑓superscript𝑆2𝛿\sum_{|S|>k}\widehat{f}(S)^{2}\leq\delta∑ start_POSTSUBSCRIPT | italic_S | > italic_k end_POSTSUBSCRIPT over^ start_ARG italic_f end_ARG ( italic_S ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≤ italic_δ [LMN] ∑|S|>kf^⁢(S)2≤δsubscript𝑆𝑘^𝑓superscript𝑆2𝛿\sum_{|S|>k}\widehat{f}(S)^{2}\leq\delta∑ start_POSTSUBSCRIPT | italic_S | > italic_k end_POSTSUBSCRIPT over^ start_ARG italic_f end_ARG ( italic_S ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≤ italic_δ Table 1: Comparison between the Razborov-Smolensky result [19, 21], the LMN theorem [15] for AC0 and our results for QAC0. In the table, s𝑠sitalic_s is the size, d𝑑ditalic_d is the depth, a𝑎aitalic_a is the number of ancillary qubits and n𝑛nitalic_n is the number of inputs. [RS] refers to results of [19, 21], and [LMN] refers to results of [15]. From Table 1, the overall difference is small. Interestingly, our proof is inspired by Razborov-Smolensky’s approach, yet it yields stronger results akin to those in the LMN theorem [15]. The main reason for this is that in Razborov-Smolensky’s proof for 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, the function, which is not bounded (see footnote 4), agrees with the OR function with high probability, while for 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT, the operator, whose operator norm is bounded by 1, approximates the CC..CZ gate up to certain errors with high probability. As a result, the low-degree polynomial approximating the boolean function defined via 𝐀𝐂0superscript𝐀𝐂0{\bf AC}^{0}bold_AC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is not bounded, while the low-degree polynomial approximating the real function defined via 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT is bounded by 1. Thus in the quantum case, from the bounded low-degree approximating polynomial, we can obtain useful information about the Fourier coefficients of the original bounded real function. Notice that in the quantum case, we do not have a lower bound on the size s𝑠sitalic_s. A reason for this is given after the proof of Theorem 1.7. 1.4 Relevant previous results In [8], Fang, Fenner, Green, Homer, and Zhang studied the computation of the parity function in a clean way by QAC0 circuits. In their paper, a QAC circuit C𝐶Citalic_C acting on n+a𝑛𝑎n+aitalic_n + italic_a qubits cleanly computes parity if for any x,y∈{0,1}n𝑥𝑦superscript01𝑛x,y\in\{0,1\}^{n}italic_x , italic_y ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT we have ⟨y,0a|⁢C⁢|x,0a⟩=⟨y,0a|⁢UParityn⊗I⁢|x,0a⟩.bra𝑦superscript0𝑎𝐶ket𝑥superscript0𝑎tensor-productbra𝑦superscript0𝑎subscript𝑈subscriptParity𝑛𝐼ket𝑥superscript0𝑎\bra{y,0^{a}}C\ket{x,0^{a}}=\bra{y,0^{a}}U_{{\rm Parity}_{n}}\otimes I\ket{x,0% ^{a}}.⟨ start_ARG italic_y , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_C | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ = ⟨ start_ARG italic_y , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG | italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⊗ italic_I | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ . Equivalently, C⁢|x,0a⟩=UParityn⊗I⁢|x,0a⟩𝐶ket𝑥superscript0𝑎tensor-productsubscript𝑈subscriptParity𝑛𝐼ket𝑥superscript0𝑎C\ket{x,0^{a}}=U_{{\rm Parity}_{n}}\otimes I\ket{x,0^{a}}italic_C | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ = italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⊗ italic_I | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ for any x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. As a result, for any measurement operator M𝑀Mitalic_M on the target bit and b∈{0,1}𝑏01b\in\{0,1\}italic_b ∈ { 0 , 1 }, we have ⟨x,b,0a−1|⁢C†⁢M⁢C⁢|x,b,0a−1⟩=⟨x,b|⁢UParityn†⁢M⁢UParityn⁢|x,b⟩.bra𝑥𝑏superscript0𝑎1superscript𝐶†𝑀𝐶ket𝑥𝑏superscript0𝑎1bra𝑥𝑏superscriptsubscript𝑈subscriptParity𝑛†𝑀subscript𝑈subscriptParity𝑛ket𝑥𝑏\bra{x,b,0^{a-1}}C^{\dagger}MC\ket{x,b,0^{a-1}}=\bra{x,b}U_{{\rm Parity}_{n}}^% {\dagger}MU_{{\rm Parity}_{n}}\ket{x,b}.⟨ start_ARG italic_x , italic_b , 0 start_POSTSUPERSCRIPT italic_a - 1 end_POSTSUPERSCRIPT end_ARG | italic_C start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_M italic_C | start_ARG italic_x , italic_b , 0 start_POSTSUPERSCRIPT italic_a - 1 end_POSTSUPERSCRIPT end_ARG ⟩ = ⟨ start_ARG italic_x , italic_b end_ARG | italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_M italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT | start_ARG italic_x , italic_b end_ARG ⟩ . In [8], it was proved that a QAC circuit of depth d𝑑ditalic_d and n+a𝑛𝑎n+aitalic_n + italic_a qubits that cleanly computes the parity function must have d≥2⁢log⁡na+1𝑑2𝑛𝑎1d\geq 2\log\frac{n}{a+1}italic_d ≥ 2 roman_log divide start_ARG italic_n end_ARG start_ARG italic_a + 1 end_ARG. Later in [18, Theorem 4], Padé, Fenner, Grier, and Thierauf showed that no depth-2 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit cleanly computes parity for any n≥4𝑛4n\geq 4italic_n ≥ 4, regardless of the number of its ancillary qubits. In [20], Rosenthal made more interesting progress towards the computation of parity function with errors. Rosenthal considered the phase-dependent fidelity, which is defined as 1−‖|ψ⟩−|ϕ⟩‖21superscriptnormket𝜓ketitalic-ϕ21-\|\ket{\psi}-\ket{\phi}\|^{2}1 - ∥ | start_ARG italic_ψ end_ARG ⟩ - | start_ARG italic_ϕ end_ARG ⟩ ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT for any two states |ψ⟩ket𝜓\ket{\psi}| start_ARG italic_ψ end_ARG ⟩ and |ϕ⟩ketitalic-ϕ\ket{\phi}| start_ARG italic_ϕ end_ARG ⟩. A 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT circuit C𝐶Citalic_C acting on n+a𝑛𝑎n+aitalic_n + italic_a qubits is said to (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximate clean parity if for any state n𝑛nitalic_n-qubit state |ϕ⟩ketitalic-ϕ\ket{\phi}| start_ARG italic_ϕ end_ARG ⟩, we have that the phase-dependent fidelity between C⁢|ϕ,0a⟩𝐶ketitalic-ϕsuperscript0𝑎C\ket{\phi,0^{a}}italic_C | start_ARG italic_ϕ , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ and (UParityn⊗I)⁢|ϕ,0a⟩tensor-productsubscript𝑈subscriptParity𝑛𝐼ketitalic-ϕsuperscript0𝑎(U_{{\rm Parity}_{n}}\otimes I)\ket{\phi,0^{a}}( italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT ⊗ italic_I ) | start_ARG italic_ϕ , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ is at least 1−η1𝜂1-\eta1 - italic_η. It is said to (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximate dirty parity if ‖(⟨ϕ|⁢UParityn†⊗I)⁢C⁢|ϕ,0a⟩‖2≥1−η.superscriptnormtensor-productbraitalic-ϕsuperscriptsubscript𝑈subscriptParity𝑛†𝐼𝐶ketitalic-ϕsuperscript0𝑎21𝜂\|(\bra{\phi}U_{{\rm Parity}_{n}}^{\dagger}\otimes I)C\ket{\phi,0^{a}}\|^{2}% \geq 1-\eta.∥ ( ⟨ start_ARG italic_ϕ end_ARG | italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ⊗ italic_I ) italic_C | start_ARG italic_ϕ , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≥ 1 - italic_η . In other words, C𝐶Citalic_C (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximates clean parity if C⁢|ϕ,0a⟩=p⁢UParityn⁢|ϕ⟩⊗|0a⟩+Others𝐶ketitalic-ϕsuperscript0𝑎tensor-product𝑝subscript𝑈subscriptParity𝑛ketitalic-ϕketsuperscript0𝑎OthersC\ket{\phi,0^{a}}=pU_{{\rm Parity}_{n}}\ket{\phi}\otimes\ket{0^{a}}+\text{Others}italic_C | start_ARG italic_ϕ , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ = italic_p italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT | start_ARG italic_ϕ end_ARG ⟩ ⊗ | start_ARG 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ + Others with |p−1|2≤ηsuperscript𝑝12𝜂|p-1|^{2}\leq\eta| italic_p - 1 | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≤ italic_η; and C𝐶Citalic_C (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximates dirty parity if C⁢|ϕ,0a⟩=p⁢UParityn⁢|ϕ⟩⊗|ϕ′⟩+Others𝐶ketitalic-ϕsuperscript0𝑎tensor-product𝑝subscript𝑈subscriptParity𝑛ketitalic-ϕketsuperscriptitalic-ϕ′OthersC\ket{\phi,0^{a}}=pU_{{\rm Parity}_{n}}\ket{\phi}\otimes\ket{\phi^{\prime}}+% \text{Others}italic_C | start_ARG italic_ϕ , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ = italic_p italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT | start_ARG italic_ϕ end_ARG ⟩ ⊗ | start_ARG italic_ϕ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_ARG ⟩ + Others, where |p|2≥1−ηsuperscript𝑝21𝜂|p|^{2}\geq 1-\eta| italic_p | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≥ 1 - italic_η. As proved in [20], clean and dirty approximations are equivalent. For the clean appropriation, it is also equivalent to restricting to |ϕ⟩=|x⟩ketitalic-ϕket𝑥\ket{\phi}=\ket{x}| start_ARG italic_ϕ end_ARG ⟩ = | start_ARG italic_x end_ARG ⟩ for x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. So with probability at least (1−η)2superscript1𝜂2(1-\sqrt{\eta})^{2}( 1 - square-root start_ARG italic_η end_ARG ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, the output of measuring the (n+1)𝑛1(n+1)( italic_n + 1 )-th qubit of C⁢|x,0a⟩𝐶ket𝑥superscript0𝑎C\ket{x,0^{a}}italic_C | start_ARG italic_x , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ is Parityn⁢(x)subscriptParity𝑛𝑥{\rm Parity}_{n}(x)roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ). It was proved in [20, Corollary 1.1] that for all d≥7𝑑7d\geq 7italic_d ≥ 7 and η>0𝜂0\eta>0italic_η > 0, there exist depth-d𝑑ditalic_d 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuits C⊕subscript𝐶direct-sumC_{\oplus}italic_C start_POSTSUBSCRIPT ⊕ end_POSTSUBSCRIPT of size and number of ancillae exp⁡(poly⁢(n1/d)⁢log⁡(n/η))polysuperscript𝑛1𝑑𝑛𝜂\exp({\rm poly}(n^{1/d})\log(n/\eta))roman_exp ( roman_poly ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) roman_log ( italic_n / italic_η ) ), where the poly⁢(n1/d)polysuperscript𝑛1𝑑{\rm poly}(n^{1/d})roman_poly ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) term is at most O⁢(n)𝑂𝑛O(n)italic_O ( italic_n ), such that C⊕subscript𝐶direct-sumC_{\oplus}italic_C start_POSTSUBSCRIPT ⊕ end_POSTSUBSCRIPT (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximates clean UParitynsubscript𝑈subscriptParity𝑛U_{{\rm Parity}_{n}}italic_U start_POSTSUBSCRIPT roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT. Rosenthal also studied the connection between parity approximation and cat state preparation (or more generally nekomata state preparation). A circuit C𝐶Citalic_C is said to (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximate a clean cat state if the phase-dependent fidelity between C⁢|0n+a⟩𝐶ketsuperscript0𝑛𝑎C\ket{0^{n+a}}italic_C | start_ARG 0 start_POSTSUPERSCRIPT italic_n + italic_a end_POSTSUPERSCRIPT end_ARG ⟩ and |CATn,0a⟩ketsubscriptCAT𝑛superscript0𝑎\ket{{\rm CAT}_{n},0^{a}}| start_ARG roman_CAT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , 0 start_POSTSUPERSCRIPT italic_a end_POSTSUPERSCRIPT end_ARG ⟩ is at least 1−η1𝜂1-\eta1 - italic_η. It is called a (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximation of a dirty cat state if ‖(⟨CAT|n⊗I)⁢C⁢|0n+a⟩‖2≥1−η.superscriptnormtensor-productsubscriptbraCATnICketsuperscript0na21𝜂\|(\bra{\rm CAT}_{n}\otimes I)C\ket{0^{n+a}}\|^{2}\geq 1-\eta.∥ ( ⟨ start_ARG roman_CAT end_ARG | start_POSTSUBSCRIPT roman_n end_POSTSUBSCRIPT ⊗ roman_I ) roman_C | start_ARG 0 start_POSTSUPERSCRIPT roman_n + roman_a end_POSTSUPERSCRIPT end_ARG ⟩ ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ≥ 1 - italic_η . A circuit C𝐶Citalic_C is said (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximates n𝑛nitalic_n-nekomata if the fidelity of C⁢|0n+a⟩𝐶ketsuperscript0𝑛𝑎C\ket{0^{n+a}}italic_C | start_ARG 0 start_POSTSUPERSCRIPT italic_n + italic_a end_POSTSUPERSCRIPT end_ARG ⟩ and |ν⟩ket𝜈\ket{\nu}| start_ARG italic_ν end_ARG ⟩ is at least 1−η1𝜂1-\eta1 - italic_η. In [20, Theorem 3.1], it was proved that for any η≥0𝜂0\eta\geq 0italic_η ≥ 0, if there is a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of size s𝑠sitalic_s, depth d𝑑ditalic_d, and number of ancillae a𝑎aitalic_a that (1−η)1𝜂(1-\eta)( 1 - italic_η )-approximates n𝑛nitalic_n-nekomata state, then there is a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit of size O⁢(s+n)𝑂𝑠𝑛O(s+n)italic_O ( italic_s + italic_n ), depth 4⁢d+34𝑑34d+34 italic_d + 3, and number of ancillae a𝑎aitalic_a that (1−O⁢(η))1𝑂𝜂(1-O(\eta))( 1 - italic_O ( italic_η ) )-approximates (n+1)𝑛1(n+1)( italic_n + 1 )-qubit clean parity problem. Consequently, if we cannot compute parity then we cannot prepare n𝑛nitalic_n-nekomata state, and so cannot prepare the cat state. In 2023, the famous LMN theorem [15] was extended to the quantum case for 𝐐𝐀𝐂0superscript𝐐𝐀𝐂0{\bf QAC}^{0}bold_QAC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT when a=O⁢(n1/d)𝑎𝑂superscript𝑛1𝑑a=O(n^{1/d})italic_a = italic_O ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) by Nadimpalli, Parham, Vasconcelos, and Yuen [17]. They introduced a new notation of the Pauli spectrum for quantum channels using the Choi representation. Using this new notion, they obtained a quantum version of the LMN theorem, which states that any polynomial size, single-qubit-output QAC0 circuit that uses at most O⁢(n1/d)𝑂superscript𝑛1𝑑O(n^{1/d})italic_O ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) auxiliary qubits must have the Pauli spectrum that is concentrated on low-degree Pauli coefficients. This immediately yields average-case circuit lower bounds, see [17, Theorem 2]: Suppose that U𝑈Uitalic_U is a 𝐐𝐀𝐂𝐐𝐀𝐂{\bf QAC}bold_QAC circuit with depth d=O⁢(1)𝑑𝑂1d=O(1)italic_d = italic_O ( 1 ) and at most 12⁢n1/d12superscript𝑛1𝑑\frac{1}{2}n^{1/d}divide start_ARG 1 end_ARG start_ARG 2 end_ARG italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT auxiliary qubits. Let Q⁢(x)∈{0,1}𝑄𝑥01Q(x)\in\{0,1\}italic_Q ( italic_x ) ∈ { 0 , 1 } denote the random measurement outcome in the computational basis of a single output qubit of Q𝑄Qitalic_Q on input |x⟩ket𝑥\ket{x}| start_ARG italic_x end_ARG ⟩. Then Prx∈{0,1}n⁡[Q⁢(x)=Parityn⁢(x)]≤12+2−Ω⁢(n1/d).subscriptPr𝑥superscript01𝑛𝑄𝑥subscriptParity𝑛𝑥12superscript2Ωsuperscript𝑛1𝑑\Pr_{x\in\{0,1\}^{n}}\Big{[}Q(x)={\rm Parity}_{n}(x)\Big{]}\leq\frac{1}{2}+2^{% -\Omega(n^{1/d})}.roman_Pr start_POSTSUBSCRIPT italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_Q ( italic_x ) = roman_Parity start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ( italic_x ) ] ≤ divide start_ARG 1 end_ARG start_ARG 2 end_ARG + 2 start_POSTSUPERSCRIPT - roman_Ω ( italic_n start_POSTSUPERSCRIPT 1 / italic_d end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT . This result is comparable to Theorem 1.9. As the Pauli spectrum is concentrated on the low-degree parts, a learning algorithm for QAC0 was obtained. Very recently in [2], Anshu, Dong, Ou, and Yao extended the results of [8, 18, 20, 17] and showed similar results when the number of ancillae is relaxed to a=O~⁢(n1+3−d)𝑎~𝑂superscript𝑛1superscript3𝑑a=\widetilde{O}(n^{1+3^{-d}})italic_a = over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1 + 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). Their main result [2, Theorem 1.1] says that, for any operator A𝐴Aitalic_A acting on n𝑛nitalic_n qubits with Pauli degree ℓℓ\ellroman_ℓ, and any QAC0 circuit of depth d𝑑ditalic_d, the operator U†⁢A⁢Usuperscript𝑈†𝐴𝑈U^{\dagger}AUitalic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_A italic_U is approximated by an operator of degree at most O⁢(n1−3−d⁢ℓ3−d)𝑂superscript𝑛1superscript3𝑑superscriptℓsuperscript3𝑑O(n^{1-3^{-d}}\ell^{3^{-d}})italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT roman_ℓ start_POSTSUPERSCRIPT 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). The idea of [2] is a little similar to ours because they also approximate CC..CZ gates by low-degree operators. The difference is that the operator they constructed is deterministic and has degree roughly n𝑛\sqrt{n}square-root start_ARG italic_n end_ARG when there are n𝑛nitalic_n qubits involved, see [2, Corollary 3.3]. Then they replace some large CC..CZ gates carefully in the QAC0 circuit and obtain an approximation of U†⁢A⁢Usuperscript𝑈†𝐴𝑈U^{\dagger}AUitalic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_A italic_U with degree O⁢(n1−3−d⁢ℓ3−d)𝑂superscript𝑛1superscript3𝑑superscriptℓsuperscript3𝑑O(n^{1-3^{-d}}\ell^{3^{-d}})italic_O ( italic_n start_POSTSUPERSCRIPT 1 - 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT roman_ℓ start_POSTSUPERSCRIPT 3 start_POSTSUPERSCRIPT - italic_d end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ). In our case, we approximate CC..CZ gate by a random operator of degree polylog(n)𝑛(n)( italic_n ). We do not just replace all CC..CZ gates by these low-degree operators. We still need to make further modifications to obtain an approximation of U†⁢A⁢Usuperscript𝑈†𝐴𝑈U^{\dagger}AUitalic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT italic_A italic_U with degree polylog(n)𝑛(n)( italic_n ). Finally, several separations are known between quantum and classical constant-depth circuits with bounded fan-in (the class 𝐐𝐍𝐂0superscript𝐐𝐍𝐂0{\bf QNC}^{0}bold_QNC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT), e.g., the 2D Hidden Linear Function problem is in 𝐐𝐍𝐂0superscript𝐐𝐍𝐂0{\bf QNC}^{0}bold_QNC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT but not in 𝐍𝐂0superscript𝐍𝐂0{\bf NC}^{0}bold_NC start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT [5]."
https://arxiv.org/html/2411.00946v1,Classical versus quantum queries in quantum PCPswith classical proofs,"We generalize quantum-classical PCPs, first introduced by Weggemans, Folkertsma and Cade (TQC 2024), to allow for q𝑞qitalic_q quantum queries to a polynomially-sized classical proof (𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{Q,c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ]). Exploiting a connection with the polynomial method, we prove that for any constant q𝑞qitalic_q, promise gap c−s=Ω⁢(1/poly⁢(n))𝑐𝑠Ω1poly𝑛c-s=\Omega(1/\mathrm{poly}(n))italic_c - italic_s = roman_Ω ( 1 / roman_poly ( italic_n ) ) and δ>0𝛿0\delta>0italic_δ > 0, we have 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]⊆𝖰𝖢𝖯𝖢𝖯1−δ,1/2+δ⁢[3]⊆𝖡𝖰⋅𝖭𝖯subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞subscript𝖰𝖢𝖯𝖢𝖯1𝛿12𝛿delimited-[]3⋅𝖡𝖰𝖭𝖯\mathsf{QCPCP}_{Q,c,s}[q]\subseteq\mathsf{QCPCP}_{1-\delta,1/2+\delta}[3]% \subseteq\mathsf{BQ}\cdot\mathsf{NP}sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ] ⊆ sansserif_QCPCP start_POSTSUBSCRIPT 1 - italic_δ , 1 / 2 + italic_δ end_POSTSUBSCRIPT [ 3 ] ⊆ sansserif_BQ ⋅ sansserif_NP, where 𝖡𝖰⋅𝖭𝖯⋅𝖡𝖰𝖭𝖯\mathsf{BQ}\cdot\mathsf{NP}sansserif_BQ ⋅ sansserif_NP is the class of promise problems with quantum reductions to an 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP-complete problem. Surprisingly, this shows that we can amplify the promise gap from inverse polynomial to constant for constant query quantum-classical PCPs, and that any quantum-classical PCP making any constant number of quantum queries can be simulated by one that makes only three classical queries. Nevertheless, even though we can achieve promise gap amplification, our result also gives strong evidence that there exists no constant query quantum-classical PCP for 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA, as it is unlikely that 𝖰𝖢𝖬𝖠⊆𝖡𝖰⋅𝖭𝖯𝖰𝖢𝖬𝖠⋅𝖡𝖰𝖭𝖯\mathsf{QCMA}\subseteq\mathsf{BQ}\cdot\mathsf{NP}sansserif_QCMA ⊆ sansserif_BQ ⋅ sansserif_NP, which we support by giving oracular evidence. In the (poly-)logarithmic query regime, we show for any positive integer c𝑐citalic_c, there exists an oracle relative to which 𝖰𝖢𝖯𝖢𝖯⁢[𝒪⁢(logc⁡n)]⊊𝖰𝖢𝖯𝖢𝖯Q⁢[𝒪⁢(logc⁡n)]𝖰𝖢𝖯𝖢𝖯delimited-[]𝒪superscript𝑐𝑛subscript𝖰𝖢𝖯𝖢𝖯𝑄delimited-[]𝒪superscript𝑐𝑛\mathsf{QCPCP}[\mathcal{O}(\log^{c}n)]\subsetneq\mathsf{QCPCP}_{Q}[\mathcal{O}% (\log^{c}n)]sansserif_QCPCP [ caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) ] ⊊ sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) ], contrasting the constant query case where the equivalence of both query models holds relative to any oracle. Finally, we connect our results to more general quantum-classical interactive proof systems.","A probabilistically checkable proof (PCP) system consists of a polynomial-time verifier that uses r⁢(n)𝑟𝑛r(n)italic_r ( italic_n ) random coins and has query access to some proof provided by a prover, to which it can make at most q⁢(n)𝑞𝑛q(n)italic_q ( italic_n ) queries. The celebrated PCP theorem states that the full power of 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP can be captured by a PCP that only has q⁢(n)=𝒪⁢(1)𝑞𝑛𝒪1q(n)=\mathcal{O}(1)italic_q ( italic_n ) = caligraphic_O ( 1 ) and r=𝒪⁢(log⁡n)𝑟𝒪𝑛r=\mathcal{O}(\log n)italic_r = caligraphic_O ( roman_log italic_n ) [ALM+98, AS98, Din07]. In quantum complexity theory, one of the biggest open questions is whether the de facto quantum generalization of 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP, i.e. 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA, can also be characterized in terms of a quantum probabilistically checkable proof system [AAV13]. This question is formalized as the quantum PCP conjecture, and is usually considered in terms of its local Hamiltonian formulation: this states that it is 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard to estimate the ground state energy of a local Hamiltonian up to constant additive error relative to the operator norm. Much less studied is its proof-checking formulation, which posits that any promise problem in 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA can be verified by a quantum polynomial-time verifier that only acts non-trivially on a subset of a polynomially-sized proof (effectively tracing out the rest). Both formulations are known to be equivalent under quantum reductions [AALV09, AAV13, BHW24]. Ref. [WFC24] proposed to study an intermediate version of a quantum probabilistically checkable proof system, where the verifier remains quantum but the proof is classical (𝖰𝖢𝖯𝖢𝖯⁢[q]𝖰𝖢𝖯𝖢𝖯delimited-[]𝑞\mathsf{QCPCP}[q]sansserif_QCPCP [ italic_q ]). They showed that for a constant amount of classical queries, the corresponding class is contained in 𝖡𝖰𝖯𝖭𝖯⁢[1]superscript𝖡𝖰𝖯𝖭𝖯delimited-[]1\mathsf{BQP}^{\mathsf{NP}[1]}sansserif_BQP start_POSTSUPERSCRIPT sansserif_NP [ 1 ] end_POSTSUPERSCRIPT, which is 𝖡𝖰𝖯𝖡𝖰𝖯\mathsf{BQP}sansserif_BQP allowed to make a single query to an 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP oracle. Whilst the definition of 𝖰𝖢𝖯𝖢𝖯⁢[q]𝖰𝖢𝖯𝖢𝖯delimited-[]𝑞\mathsf{QCPCP}[q]sansserif_QCPCP [ italic_q ] preserves the locality aspect of PCPs, it does not capture the query aspect as usually considered in a quantum setting: one generally considers quantum queries instead of classical access to a string. This means that in a single query, the whole proof can be “accessed” in superposition, a model which is known to have an exponential advantage over classical queries for some computational tasks.111See https://quantumalgorithmzoo.org for a list of examples. Generally, query lower bounds in the randomized setting also hold in the quantum setting when only classical queries are allowed, provided the lower bound method works even when all intermediate computations (in between the queries) can be inefficient. This is because any quantum query algorithm in this model can be simulated with exponential overhead (in time and space) by a classical computation, but using the same number of queries. Hence, the following question arises: Can quantum-classical PCPs be made more powerful when they are allowed to make quantum queries to a classical proof? 1.1 Our results In this work, we generalize the class 𝖰𝖢𝖯𝖢𝖯c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ] to 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{Q,c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ] such that it captures the standard quantum query model to an unknown bit string [BdW02]. A 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{Q,c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ]-verifier consists of a uniform family of quantum circuits V={Vn:n∈ℕ}𝑉conditional-setsubscript𝑉𝑛𝑛ℕV=\{V_{n}:n\in\mathbb{N}\}italic_V = { italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ blackboard_N }, where the description of each Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is generated by a fixed polynomial-time Turing machine given 1nsuperscript1𝑛1^{n}1 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT as an input. We have that each circuit Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT is allowed to make q𝑞qitalic_q queries to a classical proof y∈{0,1}poly⁢(n)𝑦superscript01poly𝑛y\in\{0,1\}^{\mathrm{poly}(n)}italic_y ∈ { 0 , 1 } start_POSTSUPERSCRIPT roman_poly ( italic_n ) end_POSTSUPERSCRIPT provided by an untrusted prover, via a unitary Uysubscript𝑈𝑦U_{y}italic_U start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT such that Uy⁢|i⟩⁢|a⟩=|i⟩⁢|a⊕yi⟩subscript𝑈𝑦ket𝑖ket𝑎ket𝑖ketdirect-sum𝑎subscript𝑦𝑖U_{y}\ket{i}\ket{a}=\ket{i}\ket{a\oplus y_{i}}italic_U start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT | start_ARG italic_i end_ARG ⟩ | start_ARG italic_a end_ARG ⟩ = | start_ARG italic_i end_ARG ⟩ | start_ARG italic_a ⊕ italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG ⟩.222One can also view this as having the proof stored in a quantum read-only memory (QROM), and the verifier is only allowed to access the memory q𝑞qitalic_q number of times. We then say that a promise problem A=(Ayes,Ano)𝐴subscript𝐴yessubscript𝐴noA=(A_{\text{\sc yes}},A_{\text{\sc no}})italic_A = ( italic_A start_POSTSUBSCRIPT yes end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT no end_POSTSUBSCRIPT ) is in 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{Q,c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ] if for all inputs x∈Ayes𝑥subscript𝐴yesx\in A_{\text{\sc yes}}italic_x ∈ italic_A start_POSTSUBSCRIPT yes end_POSTSUBSCRIPT, there exists a proof y𝑦yitalic_y such that the 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞\mathsf{QCPCP}_{Q,c,s}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ]-verifier accepts with probability at least c𝑐citalic_c, and for all x∈Ano𝑥subscript𝐴nox\in A_{\text{\sc no}}italic_x ∈ italic_A start_POSTSUBSCRIPT no end_POSTSUBSCRIPT, the verifier accepts all proofs y𝑦yitalic_y with probability at most s𝑠sitalic_s (Definition 7 and 7a). We will study quantum-classical PCPs in both types of query models in the setting where the number of queries is constant or (poly)-logarithmic. Constant number of proof queries. We show that in the constant query regime the following result holds. Theorem 1 (From Corollary 2 and Proposition 4). For any positive integer q∈ℕ𝑞ℕq\in\mathbb{N}italic_q ∈ blackboard_N and for any computable functions c,s𝑐𝑠c,sitalic_c , italic_s such that c−s≥1/poly⁢(n)𝑐𝑠1poly𝑛c-s\geq 1/\mathrm{poly}(n)italic_c - italic_s ≥ 1 / roman_poly ( italic_n ), we have 𝖰𝖢𝖯𝖢𝖯Q,c,s⁢[q]⊆𝖰𝖢𝖯𝖢𝖯1−δ,1/2+δ⁢[3]⊆𝖡𝖰⋅𝖭𝖯,subscript𝖰𝖢𝖯𝖢𝖯𝑄𝑐𝑠delimited-[]𝑞subscript𝖰𝖢𝖯𝖢𝖯1𝛿12𝛿delimited-[]3⋅𝖡𝖰𝖭𝖯\displaystyle\mathsf{QCPCP}_{Q,c,s}[q]\subseteq\mathsf{QCPCP}_{1-\delta,1/2+% \delta}[3]\subseteq\mathsf{BQ}\cdot\mathsf{NP},sansserif_QCPCP start_POSTSUBSCRIPT italic_Q , italic_c , italic_s end_POSTSUBSCRIPT [ italic_q ] ⊆ sansserif_QCPCP start_POSTSUBSCRIPT 1 - italic_δ , 1 / 2 + italic_δ end_POSTSUBSCRIPT [ 3 ] ⊆ sansserif_BQ ⋅ sansserif_NP , for any constant δ>0𝛿0\delta>0italic_δ > 0 . Here ‘𝖡𝖰𝖡𝖰\mathsf{BQ}sansserif_BQ’ is a quantum extension of Schöning’s 𝖡𝖯𝖡𝖯\mathsf{BP}sansserif_BP-operator [Sch89],333Both are examples of what is known as dot operators [BS01]. such that 𝖡𝖰⋅𝒞⋅𝖡𝖰𝒞\mathsf{BQ}\cdot\mathcal{C}sansserif_BQ ⋅ caligraphic_C for a class 𝒞𝒞\mathcal{C}caligraphic_C contains all promise problems that have a quantum reduction to a promise problem A𝐴Aitalic_A that is complete for 𝒞𝒞\mathcal{C}caligraphic_C. Hence, when 𝒞𝒞\mathcal{C}caligraphic_C is a classical complexity class, one can view the 𝖡𝖰𝖡𝖰\mathsf{BQ}sansserif_BQ-operator as “pulling the quantumness” out of a problem. In Section 3, we prove that the 𝖡𝖰𝖡𝖰\mathsf{BQ}sansserif_BQ-operator satisfies many of the similar properties as the 𝖡𝖯𝖡𝖯\mathsf{BP}sansserif_BP-operator (Proposition 3) and also discuss its alternative formulation (for classes 𝒞⊇𝖯𝖯𝒞\mathcal{C}\supseteq\mathsf{P}caligraphic_C ⊇ sansserif_P) in terms of feeding random strings generated by measuring the output states of quantum algorithms as extra input to the class (Definition 6a). The following conclusions can be drawn from Theorem 1: (i) Any constant query quantum-classical PCP protocol can be simulated by a quantum-classical PCP making only 3333 classical queries which has a constant promise gap. Even more surprisingly, this even holds when the original completeness/soundness gap was inverse polynomial(!) instead of constant, showing that amplification in this regime can be done without increasing the query count.444If the original number of queries was at least 3333. (ii) It states that one can pull out the quantumness of quantum-classical PCPs, in terms of its interpretation in the context of the 𝖡𝖰𝖡𝖰\mathsf{BQ}sansserif_BQ-operator, no matter if the access to the proof is quantum or classical. Since it seems very unlikely that 𝖰𝖢𝖬𝖠⊆𝖡𝖰⋅𝖭𝖯𝖰𝖢𝖬𝖠⋅𝖡𝖰𝖭𝖯\mathsf{QCMA}\subseteq\mathsf{BQ}\cdot\mathsf{NP}sansserif_QCMA ⊆ sansserif_BQ ⋅ sansserif_NP—as it would imply that the “quantum part” in the computation does not have to use the proof—this provides very strong evidence that it is unlikely that there exists some notion of a “quantum PCP” that uses a classical proof. We strengthen point (ii) by giving a classical oracle relative to which 𝖰𝖢𝖯𝖢𝖯Q⁢[𝒪⁢(1)]subscript𝖰𝖢𝖯𝖢𝖯𝑄delimited-[]𝒪1\mathsf{QCPCP}_{Q}[\mathcal{O}(1)]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ caligraphic_O ( 1 ) ] does not capture the power of 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA. Theorem 2. For any positive integer q∈ℕ𝑞ℕq\in\mathbb{N}italic_q ∈ blackboard_N, there exists an oracle 𝓞𝓞\bm{\mathcal{O}}bold_caligraphic_O relative to which 𝖰𝖢𝖯𝖢𝖯⁢[q]𝓞⊆𝖰𝖢𝖯𝖢𝖯Q⁢[q]𝓞⊊𝖰𝖢𝖬𝖠𝓞.𝖰𝖢𝖯𝖢𝖯superscriptdelimited-[]𝑞𝓞subscript𝖰𝖢𝖯𝖢𝖯𝑄superscriptdelimited-[]𝑞𝓞superscript𝖰𝖢𝖬𝖠𝓞\displaystyle\mathsf{QCPCP}[q]^{\bm{\mathcal{O}}}\subseteq\mathsf{QCPCP}_{Q}[q% ]^{\bm{\mathcal{O}}}\subsetneq\mathsf{QCMA}^{\bm{\mathcal{O}}}.sansserif_QCPCP [ italic_q ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊆ sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ italic_q ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊊ sansserif_QCMA start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT . Unconditionally proving 𝖰𝖢𝖯𝖢𝖯Q⁢[𝒪⁢(1)]≠𝖰𝖢𝖬𝖠subscript𝖰𝖢𝖯𝖢𝖯𝑄delimited-[]𝒪1𝖰𝖢𝖬𝖠\mathsf{QCPCP}_{Q}[\mathcal{O}(1)]\neq\mathsf{QCMA}sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ caligraphic_O ( 1 ) ] ≠ sansserif_QCMA would imply 𝖯≠𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{P}\neq\mathsf{PSPACE}sansserif_P ≠ sansserif_PSPACE and therefore seems to be beyond the current techniques. We believe that Point (i) highlights the intuition that a classical proof in a quantum verification setting can be viewed as being “uncompiled.” In the fully quantum case, it’s easy to show that there exists a polynomial p⁢(n)𝑝𝑛p(n)italic_p ( italic_n ) such that 𝖰𝖯𝖢𝖯c,s⁢[2]=𝖰𝖬𝖠subscript𝖰𝖯𝖢𝖯𝑐𝑠delimited-[]2𝖰𝖬𝖠\mathsf{QPCP}_{c,s}[2]=\mathsf{QMA}sansserif_QPCP start_POSTSUBSCRIPT italic_c , italic_s end_POSTSUBSCRIPT [ 2 ] = sansserif_QMA when c−s=1/p⁢(n)𝑐𝑠1𝑝𝑛c-s=1/p(n)italic_c - italic_s = 1 / italic_p ( italic_n ); roughly speaking, one picks a term of a 𝖰𝖬𝖠𝖰𝖬𝖠\mathsf{QMA}sansserif_QMA-hard 2222-local Hamiltonian uniformly at random, and applies a 3333-qubit unitary operation which maps an ancillary qubit in |0⟩ket0\ket{0}| start_ARG 0 end_ARG ⟩ to |1⟩ket1\ket{1}| start_ARG 1 end_ARG ⟩ proportional to the energy of the 2222-local density matrix with respect the sampled local term.555See for example [KSV02] and [BHW24]. Similarly, in the fully classical case, one can sample a term of a 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP-hard 3333-local constraint satisfaction problem uniformly at random and detect unsatisfiability with a probability 1/m1𝑚1/m1 / italic_m, where m𝑚mitalic_m is the total number of constraints. Therefore, the whole game of proving quantum PCP conjecture is to show that for some q∈𝒪⁢(1)𝑞𝒪1q\in\mathcal{O}(1)italic_q ∈ caligraphic_O ( 1 ), we have 𝖰𝖯𝖢𝖯c,s⁢[2]=𝖰𝖯𝖢𝖯c′,s′⁢[q]subscript𝖰𝖯𝖢𝖯𝑐𝑠delimited-[]2subscript𝖰𝖯𝖢𝖯superscript𝑐′superscript𝑠′delimited-[]𝑞\mathsf{QPCP}_{c,s}[2]=\mathsf{QPCP}_{c^{\prime},s^{\prime}}[q]sansserif_QPCP start_POSTSUBSCRIPT italic_c , italic_s end_POSTSUBSCRIPT [ 2 ] = sansserif_QPCP start_POSTSUBSCRIPT italic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ italic_q ] with c′−s′=Ω⁢(1)superscript𝑐′superscript𝑠′Ω1c^{\prime}-s^{\prime}=\Omega(1)italic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - italic_s start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = roman_Ω ( 1 ). For quantum PCPs with classical proofs (independent of the access model), Theorem 1 shows that such an amplification step is indeed possible, however, we lose the property that “local information” about a proof is enough to verify any problem in 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA with an inverse polynomially small promise gap. In particular, variants of the local Hamiltonian which are 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA-complete use a classical proof to describe a quantum circuit which prepares a quantum state with low energy (or has a large overlap with such a state) [WJB03, WFC24], which can again only be “locally verified” after the quantum state is prepared, i.e., compiled. (Poly-)logarithmic number of queries. We show that when the number of queries to the proof becomes (poly-)logarithmic both query models can be separated relative to an oracle. Theorem 3. For any positive integer c∈ℕ𝑐ℕc\in\mathbb{N}italic_c ∈ blackboard_N, there exists an oracle 𝓞𝓞\bm{\mathcal{O}}bold_caligraphic_O such that 𝖰𝖢𝖯𝖢𝖯⁢[𝒪⁢(logc⁡n)]𝓞⊊𝖰𝖢𝖯𝖢𝖯Q⁢[𝒪⁢(logc⁡n)]𝓞.𝖰𝖢𝖯𝖢𝖯superscriptdelimited-[]𝒪superscript𝑐𝑛𝓞subscript𝖰𝖢𝖯𝖢𝖯𝑄superscriptdelimited-[]𝒪superscript𝑐𝑛𝓞\displaystyle\mathsf{QCPCP}[\mathcal{O}(\log^{c}n)]^{\bm{\mathcal{O}}}% \varsubsetneq\mathsf{QCPCP}_{Q}[\mathcal{O}(\log^{c}n)]^{\bm{\mathcal{O}}}.sansserif_QCPCP [ caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊊ sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT . This contrasts the constant query case, where Theorem 1 holds even in the presence of oracles. 1.2 Proof ideas To prove Theorem 1, we exploit the connection between quantum-classical PCPs and the polynomial method of [BBC+01]. The polynomial method is a technique used to prove lower bounds on quantum query complexity, and utilizes the idea that the square of the amplitudes of every q𝑞qitalic_q-query quantum algorithm to a string y∈{0,1}N𝑦superscript01𝑁y\in\{0,1\}^{N}italic_y ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT can be expressed as a real-valued multi-linear polynomial P⁢(y)𝑃𝑦P(y)italic_P ( italic_y ) of degree 2⁢q2𝑞2q2 italic_q on N𝑁Nitalic_N bits. In our case, we will be interested in the case when N=|y|=poly⁢(n)𝑁𝑦poly𝑛N=|y|=\mathrm{poly}(n)italic_N = | italic_y | = roman_poly ( italic_n ) and q𝑞qitalic_q is constant, so P𝑃Pitalic_P consists of at most (|y|2⁢q)=poly⁢(n)binomial𝑦2𝑞poly𝑛\binom{|y|}{2q}=\mathrm{poly}(n)( FRACOP start_ARG | italic_y | end_ARG start_ARG 2 italic_q end_ARG ) = roman_poly ( italic_n ) number of monomials. We prove that for a fixed input x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, an approximation of P𝑃Pitalic_P can be efficiently learned by sampling from the measurement outcome of the runs 𝖰𝖢𝖯𝖢𝖯Q⁢[q]subscript𝖰𝖢𝖯𝖢𝖯𝑄delimited-[]𝑞\mathsf{QCPCP}_{Q}[q]sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ italic_q ]-verification circuit (Theorem 4). In these runs, it never queries the actual proof through Uysubscript𝑈𝑦U_{y}italic_U start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT, instead making queries to constructed UySsubscript𝑈superscript𝑦𝑆U_{y^{S}}italic_U start_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_POSTSUBSCRIPT’s for some “fake” proofs ySsuperscript𝑦𝑆y^{S}italic_y start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT, which can be efficiently implemented given a description of ySsuperscript𝑦𝑆y^{S}italic_y start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT. Here S⊆[N]𝑆delimited-[]𝑁S\subseteq[N]italic_S ⊆ [ italic_N ] indicates a subset of at most 2⁢q2𝑞2q2 italic_q variables participating in a term. Combined with the promise on the acceptance probabilities of the quantum-classical PCP verifier in the yes- and no-cases, this yields a quantum reduction to a multi-linear polynomial threshold problem: here you are given classical descriptions of the coefficients βSsubscript𝛽𝑆{\beta_{S}}italic_β start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT up to a certain number of bits of precision of some constant degree multi-linear polynomial P:{0,1}p⁢(n)→ℝ:𝑃→superscript01𝑝𝑛ℝP:\{0,1\}^{p(n)}\rightarrow\mathbb{R}italic_P : { 0 , 1 } start_POSTSUPERSCRIPT italic_p ( italic_n ) end_POSTSUPERSCRIPT → blackboard_R with p⁢(n)=poly⁢(n)𝑝𝑛poly𝑛p(n)=\mathrm{poly}(n)italic_p ( italic_n ) = roman_poly ( italic_n ), and an efficiently computable number a∈[0,1]𝑎01a\in[0,1]italic_a ∈ [ 0 , 1 ], and the task is to decide whether there exists a y∈{0,1}p⁢(n)𝑦superscript01𝑝𝑛y\in\{0,1\}^{p(n)}italic_y ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_p ( italic_n ) end_POSTSUPERSCRIPT such that P⁢(y)≥a𝑃𝑦𝑎P(y)\geq aitalic_P ( italic_y ) ≥ italic_a or for all y𝑦yitalic_y it holds that P⁢(y)<a𝑃𝑦𝑎P(y)<aitalic_P ( italic_y ) < italic_a. The multi-linear polynomial threshold problem is clearly in 𝖭𝖯𝖭𝖯\mathsf{NP}sansserif_NP, as the smallest possible function value of P𝑃Pitalic_P above a𝑎aitalic_a can be discriminated from a𝑎aitalic_a using only a polynomial number of bits, which follows from the fact that each of the coefficients is specified up to a certain number of bits. Using a classical PCP construction, one then also has that the multi-linear polynomial threshold problem is in 𝖯𝖢𝖯⁢[3,𝒪⁢(log⁡r)]𝖯𝖢𝖯3𝒪𝑟\mathsf{PCP}[3,\mathcal{O}(\log r)]sansserif_PCP [ 3 , caligraphic_O ( roman_log italic_r ) ] [H0̊1]. Moreover, conditioning on the quantum reduction succeeding, the output of the reduction can be made deterministic, which means that the prover can fix the proof used by the classical PCP verification protocol in the yes-case. The above construction is somewhat similar in spirit to a recent work by Arad and Santha [AS24], in which a “quasi-quantum PCP theorem” in terms of a local Hamiltonian problem over so-called quasi-quantum states is shown by using a classical PCP construction to achieve amplification. However, a key difference is that they want to reduce to a (quasi-)quantum problem from an amplified CSP, whilst we reduce from a quantum problem to a CSP, which can then be gap amplified. The proof of Theorem 2 relies on the OR ∘\circ∘ Forrelation oracle from [AIK22], which was used to demonstrate an oracle separation between 𝖭𝖯𝖡𝖰𝖯superscript𝖭𝖯𝖡𝖰𝖯\mathsf{NP}^{\mathsf{BQP}}sansserif_NP start_POSTSUPERSCRIPT sansserif_BQP end_POSTSUPERSCRIPT and 𝖡𝖰𝖯𝖭𝖯superscript𝖡𝖰𝖯𝖭𝖯\mathsf{BQP}^{\mathsf{NP}}sansserif_BQP start_POSTSUPERSCRIPT sansserif_NP end_POSTSUPERSCRIPT. We extend this result to show that the same oracle separation holds when 𝖭𝖯𝖡𝖰𝖯superscript𝖭𝖯𝖡𝖰𝖯\mathsf{NP}^{\mathsf{BQP}}sansserif_NP start_POSTSUPERSCRIPT sansserif_BQP end_POSTSUPERSCRIPT is replaced by 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA. Additionally, we make use of the fact that the inclusion 𝖰𝖢𝖯𝖢𝖯Q⁢[𝒪⁢(1)]⊆𝖡𝖰⋅𝖭𝖯subscript𝖰𝖢𝖯𝖢𝖯𝑄delimited-[]𝒪1⋅𝖡𝖰𝖭𝖯\mathsf{QCPCP}_{Q}[\mathcal{O}(1)]\subseteq\mathsf{BQ}\cdot\mathsf{NP}sansserif_QCPCP start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT [ caligraphic_O ( 1 ) ] ⊆ sansserif_BQ ⋅ sansserif_NP from Theorem 1 holds even under relativization. The key insight in proving Theorem 3 is to consider the decision version of a search problem, specifically computing the OR-function over a string of poly-logarithmic length. Using quantum queries, the Bernstein-Vazirani algorithm [BV93] can decode 𝒪⁢(log⁡n)𝒪𝑛\mathcal{O}(\log n)caligraphic_O ( roman_log italic_n ) bits with just a single quantum query to a string of polynomial size. By concatenating 𝒪⁢(logc⁡n)𝒪superscript𝑐𝑛\mathcal{O}(\log^{c}n)caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) of such strings into a proof, we can learn a total of 𝒪⁢(logc+1⁡n)𝒪superscript𝑐1𝑛\mathcal{O}(\log^{c+1}n)caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c + 1 end_POSTSUPERSCRIPT italic_n ) bits using only 𝒪⁢(logc⁡n)𝒪superscript𝑐𝑛\mathcal{O}(\log^{c}n)caligraphic_O ( roman_log start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT italic_n ) quantum queries, after which a single classical query is sufficient to solve the decision problem. To show that this is not achievable with classical access to a proof, we establish a quantum lower bound on computing the OR function for n𝑛nitalic_n bits, even in cases where k𝑘kitalic_k bits (from a potentially larger proof) are observed to aid in finding the hidden string. Our lower bound generalizes a result from [BHW24, Appendix D]. Although their proof technique could also be applied to achieve the same result, we argue that our approach is simpler and more straightforward. 1.3 Implication to quantum-classical interactive proof systems As a final side result, our oracle separation between 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA and 𝖡𝖰⋅𝖭𝖯⋅𝖡𝖰𝖭𝖯\mathsf{BQ}\cdot\mathsf{NP}sansserif_BQ ⋅ sansserif_NP also leads to a corollary regarding quantum-classical interactive proof systems. We define a new class of quantum-classical interactive proof systems, denoted 𝖰𝖢𝖨𝖯⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘\mathsf{QCIP}[k]sansserif_QCIP [ italic_k ], which, to the best of our knowledge, has not been explored in the literature. This class contains all promise problems that can be decided by a k𝑘kitalic_k-message interaction between a polynomial-time quantum verifier and a prover, where only classical strings are exchanged between them. Definition 1 (Quantum-classical interactive proofs). Let n∈ℕ𝑛ℕn\in\mathbb{N}italic_n ∈ blackboard_N and p⁢(n):ℕ→ℕ:𝑝𝑛→ℕℕp(n):\mathbb{N}\rightarrow\mathbb{N}italic_p ( italic_n ) : blackboard_N → blackboard_N be a polynomial. A promise problem A=(Ayes,Ano)𝐴subscript𝐴yessubscript𝐴noA=(A_{\textup{\sc yes}},A_{\textup{\sc no}})italic_A = ( italic_A start_POSTSUBSCRIPT yes end_POSTSUBSCRIPT , italic_A start_POSTSUBSCRIPT no end_POSTSUBSCRIPT ) is in 𝖰𝖢𝖨𝖯c,s⁢[k]subscript𝖰𝖢𝖨𝖯𝑐𝑠delimited-[]𝑘\mathsf{QCIP}_{c,s}[k]sansserif_QCIP start_POSTSUBSCRIPT italic_c , italic_s end_POSTSUBSCRIPT [ italic_k ] if there exists a 𝖯𝖯\mathsf{P}sansserif_P-uniform family of polynomial-time quantum verifier circuits {Vn:n∈ℕ}conditional-setsubscript𝑉𝑛𝑛ℕ\{V_{n}:n\in\mathbb{N}\}{ italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT : italic_n ∈ blackboard_N }, where each verifier Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT takes x∈{0,1}n𝑥superscript01𝑛x\in\{0,1\}^{n}italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT as an input and exchanges k𝑘kitalic_k classical messages of length at most p⁢(n)𝑝𝑛p(n)italic_p ( italic_n ) with a computationally unbounded prover P:{0,1}∗→{0,1}∗:𝑃→superscript01superscript01P:\{0,1\}^{*}\rightarrow\{0,1\}^{*}italic_P : { 0 , 1 } start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT → { 0 , 1 } start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT, such that the following conditions hold: • If x∈Ayes𝑥subscript𝐴yesx\in A_{\textup{\sc yes}}italic_x ∈ italic_A start_POSTSUBSCRIPT yes end_POSTSUBSCRIPT, there exists a prover P𝑃Pitalic_P that causes Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT to accept with probability at least c𝑐citalic_c. • If x∈Ano𝑥subscript𝐴nox\in A_{\textup{\sc no}}italic_x ∈ italic_A start_POSTSUBSCRIPT no end_POSTSUBSCRIPT, then for every prover P𝑃Pitalic_P, Vnsubscript𝑉𝑛V_{n}italic_V start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT accepts with probability at most s𝑠sitalic_s. We define 𝖰𝖢𝖨𝖯⁢[k]=𝖰𝖢𝖨𝖯2/3,1/3⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘subscript𝖰𝖢𝖨𝖯2313delimited-[]𝑘\mathsf{QCIP}[k]=\mathsf{QCIP}_{2/3,1/3}[k]sansserif_QCIP [ italic_k ] = sansserif_QCIP start_POSTSUBSCRIPT 2 / 3 , 1 / 3 end_POSTSUBSCRIPT [ italic_k ], 𝖰𝖢𝖨𝖯=⋃α≥1𝖰𝖢𝖨𝖯⁢[nα]𝖰𝖢𝖨𝖯subscript𝛼1𝖰𝖢𝖨𝖯delimited-[]superscript𝑛𝛼\mathsf{QCIP}=\bigcup_{\alpha\geq 1}\mathsf{QCIP}[n^{\alpha}]sansserif_QCIP = ⋃ start_POSTSUBSCRIPT italic_α ≥ 1 end_POSTSUBSCRIPT sansserif_QCIP [ italic_n start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT ], and 𝖰𝖢𝖬𝖠=𝖰𝖢𝖨𝖯⁢[1]𝖰𝖢𝖬𝖠𝖰𝖢𝖨𝖯delimited-[]1\mathsf{QCMA}=\mathsf{QCIP}[1]sansserif_QCMA = sansserif_QCIP [ 1 ]. We have that 𝖰𝖢𝖨𝖯𝖰𝖢𝖨𝖯\mathsf{QCIP}sansserif_QCIP in itself is not a particularly interesting class, as it is already known that 𝖰𝖨𝖯=𝖨𝖯=𝖯𝖲𝖯𝖠𝖢𝖤𝖰𝖨𝖯𝖨𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{QIP}=\mathsf{IP}=\mathsf{PSPACE}sansserif_QIP = sansserif_IP = sansserif_PSPACE. Therefore, since 𝖯𝖲𝖯𝖠𝖢𝖤=𝖨𝖯⊆𝖰𝖢𝖨𝖯𝖯𝖲𝖯𝖠𝖢𝖤𝖨𝖯𝖰𝖢𝖨𝖯\mathsf{PSPACE}=\mathsf{IP}\subseteq\mathsf{QCIP}sansserif_PSPACE = sansserif_IP ⊆ sansserif_QCIP [Sha92] and 𝖰𝖢𝖨𝖯⊆𝖰𝖨𝖯=𝖯𝖲𝖯𝖠𝖢𝖤𝖰𝖢𝖨𝖯𝖰𝖨𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{QCIP}\subseteq\mathsf{QIP}=\mathsf{PSPACE}sansserif_QCIP ⊆ sansserif_QIP = sansserif_PSPACE [JJUW11], we actually have 𝖰𝖢𝖨𝖯=𝖰𝖨𝖯=𝖨𝖯=𝖯𝖲𝖯𝖠𝖢𝖤𝖰𝖢𝖨𝖯𝖰𝖨𝖯𝖨𝖯𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{QCIP}=\mathsf{QIP}=\mathsf{IP}=\mathsf{PSPACE}sansserif_QCIP = sansserif_QIP = sansserif_IP = sansserif_PSPACE. This implies that, for interactive proof systems allowing a polynomial number of interaction rounds, the computational power is independent of whether the proofs are classical or quantum, or whether the verifier is quantum. However, it is well-known that 𝖰𝖨𝖯⁢[3]=𝖰𝖨𝖯𝖰𝖨𝖯delimited-[]3𝖰𝖨𝖯\mathsf{QIP}[3]=\mathsf{QIP}sansserif_QIP [ 3 ] = sansserif_QIP [KW00], which demonstrates that quantum interactive proofs with a constant number of rounds (specifically, k≥3𝑘3k\geq 3italic_k ≥ 3) are more powerful than classical ones, as 𝖨𝖯⁢[k]=𝖠𝖬𝖨𝖯delimited-[]𝑘𝖠𝖬\mathsf{IP}[k]=\mathsf{AM}sansserif_IP [ italic_k ] = sansserif_AM for all k≥2𝑘2k\geq 2italic_k ≥ 2. It seems unlikely that a similar result holds for quantum-classical interactive proofs, as the proof that 𝖰𝖨𝖯⁢[3]=𝖰𝖨𝖯𝖰𝖨𝖯delimited-[]3𝖰𝖨𝖯\mathsf{QIP}[3]=\mathsf{QIP}sansserif_QIP [ 3 ] = sansserif_QIP heavily relies on the ability to exchange quantum registers, creating entanglement between the verifier and the prover’s quantum states. Trivially, for any k≥1𝑘1k\geq 1italic_k ≥ 1 and any oracle 𝓞𝓞\bm{\mathcal{O}}bold_caligraphic_O, we have that 𝖰𝖢𝖬𝖠𝓞⊆𝖰𝖢𝖨𝖯⁢[k]𝓞superscript𝖰𝖢𝖬𝖠𝓞𝖰𝖢𝖨𝖯superscriptdelimited-[]𝑘𝓞\mathsf{QCMA}^{\bm{\mathcal{O}}}\subseteq\mathsf{QCIP}[k]^{\bm{\mathcal{O}}}sansserif_QCMA start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊆ sansserif_QCIP [ italic_k ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT (the verifier does not have to make use of their ability to send a message to the prover, yielding the exact same class). Using the oracle 𝓞𝓞\bm{\mathcal{O}}bold_caligraphic_O from Definition 2 and the result from Proposition 1, we have that (𝖡𝖰⋅𝖭𝖯)𝓞⊆𝖡𝖰𝖯𝖭𝖯𝓞⊅𝖰𝖢𝖬𝖠𝓞⊆𝖰𝖢𝖨𝖯⁢[k]𝓞superscript⋅𝖡𝖰𝖭𝖯𝓞superscript𝖡𝖰𝖯superscript𝖭𝖯𝓞not-superset-ofsuperscript𝖰𝖢𝖬𝖠𝓞𝖰𝖢𝖨𝖯superscriptdelimited-[]𝑘𝓞\left(\mathsf{BQ}\cdot\mathsf{NP}\right)^{\bm{\mathcal{O}}}\subseteq\mathsf{% BQP}^{\mathsf{NP}^{\bm{\mathcal{O}}}}\not\supset\mathsf{QCMA}^{\bm{\mathcal{O}% }}\subseteq\mathsf{QCIP}[k]^{\bm{\mathcal{O}}}( sansserif_BQ ⋅ sansserif_NP ) start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊆ sansserif_BQP start_POSTSUPERSCRIPT sansserif_NP start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ⊅ sansserif_QCMA start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊆ sansserif_QCIP [ italic_k ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT, leading directly to the following corollary. Corollary 1. For any k≥1𝑘1k\geq 1italic_k ≥ 1, there exists an oracle 𝓞𝓞\bm{\mathcal{O}}bold_caligraphic_O relative to which 𝖰𝖢𝖨𝖯⁢[k]𝓞⊄(𝖡𝖰⋅𝖭𝖯)𝓞.not-subset-of𝖰𝖢𝖨𝖯superscriptdelimited-[]𝑘𝓞superscript⋅𝖡𝖰𝖭𝖯𝓞\displaystyle\mathsf{QCIP}[k]^{\bm{\mathcal{O}}}\not\subset\left(\mathsf{BQ}% \cdot\mathsf{NP}\right)^{\bm{\mathcal{O}}}.sansserif_QCIP [ italic_k ] start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT ⊄ ( sansserif_BQ ⋅ sansserif_NP ) start_POSTSUPERSCRIPT bold_caligraphic_O end_POSTSUPERSCRIPT . The same result holds by considering 𝖰𝖢𝖠𝖬⁢[k]𝖰𝖢𝖠𝖬delimited-[]𝑘\mathsf{QCAM}[k]sansserif_QCAM [ italic_k ] instead of 𝖰𝖢𝖨𝖯⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘\mathsf{QCIP}[k]sansserif_QCIP [ italic_k ], where is 𝖰𝖢𝖠𝖬⁢[k]𝖰𝖢𝖠𝖬delimited-[]𝑘\mathsf{QCAM}[k]sansserif_QCAM [ italic_k ] the quantum generalization of 𝖠𝖬⁢[k]𝖠𝖬delimited-[]𝑘\mathsf{AM}[k]sansserif_AM [ italic_k ] (see, for example, [AGKR24, AH23]). This contrasts the classical result that 𝖠𝖬⁢[k]⊆𝖨𝖯⁢[k]=𝖡𝖯⋅𝖭𝖯𝖠𝖬delimited-[]𝑘𝖨𝖯delimited-[]𝑘⋅𝖡𝖯𝖭𝖯\mathsf{AM}[k]\subseteq\mathsf{IP}[k]=\mathsf{BP}\cdot\mathsf{NP}sansserif_AM [ italic_k ] ⊆ sansserif_IP [ italic_k ] = sansserif_BP ⋅ sansserif_NP for all k∈ℕ≥2𝑘subscriptℕabsent2k\in\mathbb{N}_{\geq 2}italic_k ∈ blackboard_N start_POSTSUBSCRIPT ≥ 2 end_POSTSUBSCRIPT, which holds relative to all oracles. Intuitively, we believe that our statements for quantum-classical PCPs hold because one can pull out the quantumness, while Corollary 1 for quantum-classical interactive proof systems holds because one cannot pull out the quantumness. 1.4 Discussion and open questions In this work, we have introduced a quantum version of the 𝖡𝖯𝖡𝖯\mathsf{BP}sansserif_BP-operator and applied it to explore interactive proof systems with a quantum verifier and classical messages. For quantum-classical PCPs, many open questions appear to be resolved by this work, as achieving an unconditional separation from 𝖰𝖢𝖬𝖠𝖰𝖢𝖬𝖠\mathsf{QCMA}sansserif_QCMA would require overcoming the 𝖯𝖯\mathsf{P}sansserif_P versus 𝖯𝖲𝖯𝖠𝖢𝖤𝖯𝖲𝖯𝖠𝖢𝖤\mathsf{PSPACE}sansserif_PSPACE barrier, which seems beyond current techniques. For future work, we would like to extend the direction of this work to general quantum- classical interactive proof systems, for which we believe that the concept of not being able to “pull out the quantumness” has many implications. We conjecture that, relative to an oracle, one can demonstrate that no round reduction exists for a constant number of rounds, and that 𝖰𝖢𝖠𝖬⁢[k]𝖰𝖢𝖠𝖬delimited-[]𝑘\mathsf{QCAM}[k]sansserif_QCAM [ italic_k ] does not contain 𝖰𝖢𝖨𝖯⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘\mathsf{QCIP}[k]sansserif_QCIP [ italic_k ], highlighting the distinction between “quantumness” and randomness. Another direction worth exploring is whether, for some fixed k≥2𝑘2k\geq 2italic_k ≥ 2, 𝖰𝖢𝖨𝖯⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘\mathsf{QCIP}[k]sansserif_QCIP [ italic_k ] admits perfect completeness, possibly with a constant overhead in the number of rounds. Additionally, what is the relationship between 𝖰𝖢𝖨𝖯⁢[k]𝖰𝖢𝖨𝖯delimited-[]𝑘\mathsf{QCIP}[k]sansserif_QCIP [ italic_k ] and 𝖰𝖨𝖯⁢[2]𝖰𝖨𝖯delimited-[]2\mathsf{QIP}[2]sansserif_QIP [ 2 ] for larger values of k𝑘kitalic_k? For the 𝖡𝖰𝖡𝖰\mathsf{BQ}sansserif_BQ-operator, it would be interesting to investigate whether it has broader applications. Specifically, are there other problems that allow a quantum reduction to a classical problem? Some examples in a non-quantum PCP context can be found in cryptography [Reg09, DART23], although the reduction in [Reg09] has also been shown to exist in a classical setting [Pei09]."
https://arxiv.org/html/2411.00082v1,Testing and learning structured quantum Hamiltonians,"We consider the problems of testing and learning an n𝑛nitalic_n-qubit Hamiltonian H=∑xλx⁢σx𝐻subscript𝑥subscript𝜆𝑥subscript𝜎𝑥H=\sum_{x}\lambda_{x}\sigma_{x}italic_H = ∑ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT expressed in its Pauli basis, from queries to its evolution operator U=e−i⁢H⁢t𝑈superscript𝑒𝑖𝐻𝑡U=e^{-iHt}italic_U = italic_e start_POSTSUPERSCRIPT - italic_i italic_H italic_t end_POSTSUPERSCRIPT with respect the normalized Frobenius norm. To this end, we prove the following results (with and without quantum memory) for Hamiltonians whose Pauli spectrum involves only k𝑘kitalic_k-local terms or has sparsity at most s𝑠sitalic_s:Local Hamiltonians: We give a tolerant testing protocol to decide if a Hamiltonian is ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-close to k𝑘kitalic_k-local or ε2subscript𝜀2\varepsilon_{2}italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-far from k𝑘kitalic_k-local, with O⁢(1/(ε2−ε1)4)𝑂1superscriptsubscript𝜀2subscript𝜀14O(1/(\varepsilon_{2}-\varepsilon_{1})^{4})italic_O ( 1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) queries, thereby solving two open questions posed in a recent work by Bluhm, Caro and Oufkir [5]. For learning a k𝑘kitalic_k-local Hamiltonian up to error ε𝜀\varepsilonitalic_ε, we give a protocol with query complexity and total time evolution exp⁡(O⁢(k2+k⁢log⁡(1/ε)))𝑂superscript𝑘2𝑘1𝜀\exp(O(k^{2}+k\log(1/\varepsilon)))roman_exp ( italic_O ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_k roman_log ( 1 / italic_ε ) ) ). Our algorithm leverages the non-commutative Bohnenblust-Hille inequality in order to get a complexity independent of n𝑛nitalic_n.Sparse Hamiltonians: We give a protocol for testing whether a Hamiltonian is ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-close to being s𝑠sitalic_s-sparse or ε2subscript𝜀2\varepsilon_{2}italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-far from being s𝑠sitalic_s-sparse, with O⁢(s6/(ε22−ε12)6)𝑂superscript𝑠6superscriptsuperscriptsubscript𝜀22superscriptsubscript𝜀126O(s^{6}/(\varepsilon_{2}^{2}-\varepsilon_{1}^{2})^{6})italic_O ( italic_s start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT ) queries. For learning up to error ε𝜀\varepsilonitalic_ε, we show that O⁢(s4/ε8)𝑂superscript𝑠4superscript𝜀8O(s^{4}/\varepsilon^{8})italic_O ( italic_s start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT / italic_ε start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT ) queries suffices.Learning without quantum memory: The learning results stated above have no dependence on the system size n𝑛nitalic_n, but require n𝑛nitalic_n-qubit quantum memory. We give subroutines that allow us to reproduce all the above learning results without quantum memory; increasing the query complexity by a (log⁡n)𝑛(\log n)( roman_log italic_n )-factor in the local case and an n𝑛nitalic_n-factor in the sparse case.Testing without quantum memory: We give a new subroutine called Pauli hashing, which allows one to tolerantly test s𝑠sitalic_s-sparse Hamiltonians using O~⁢(s14/(ε22−ε12)18)~𝑂superscript𝑠14superscriptsuperscriptsubscript𝜀22superscriptsubscript𝜀1218\tilde{O}(s^{14}/(\varepsilon_{2}^{2}-\varepsilon_{1}^{2})^{18})over~ start_ARG italic_O end_ARG ( italic_s start_POSTSUPERSCRIPT 14 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 18 end_POSTSUPERSCRIPT ) query complexity. A key ingredient is showing that s𝑠sitalic_s-sparse Pauli channels can be tested in a tolerant fashion as being ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-close to being s𝑠sitalic_s-sparse or ε2subscript𝜀2\varepsilon_{2}italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-far under the diamond norm, using O~⁢(s2/(ε2−ε1)6)~𝑂superscript𝑠2superscriptsubscript𝜀2subscript𝜀16\tilde{O}(s^{2}/(\varepsilon_{2}-\varepsilon_{1})^{6})over~ start_ARG italic_O end_ARG ( italic_s start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT ) queries via Pauli hashing.In order to prove these results, we prove new structural theorems for local Hamiltonians, sparse Pauli channels and sparse Hamiltonians. We complement our learning algorithms with lower bounds that are polynomially weaker. Furthermore, our algorithms use short time evolutions and do not assume prior knowledge of the terms on which the Pauli spectrum is supported on, i.e., we do not require prior knowledge about the support of the Hamiltonian terms.","A fundamental and important challenge with building quantum devices is being able to characterize and calibrate its behavior. One approach to do so is Hamiltonian learning which seeks to learn the Hamiltonian governing the dynamics of a quantum system given finite classical and quantum resources. Beyond system characterization, it is also carried out during validation of physical systems and designing control strategies for implementing quantum gates [39]. However, learning an n𝑛nitalic_n-qubit Hamiltonian is known to be difficult, requiring complexity that scales exponential in the number of qubits [12]. In practice, however, prior knowledge on the structure of Hamiltonians is available e.g., those of engineered quantum devices [53] where the underlying Hamiltonians primarily involve local interactions with few non-local interactions, and even naturally occurring physical quantum systems such as those with translationally invariant Hamiltonians. To highlight these structural properties, consider an n𝑛nitalic_n-qubit Hamiltonian H𝐻Hitalic_H (which is a self-adjoint operator acting on (ℂ2)⊗nsuperscriptsuperscriptℂ2tensor-productabsent𝑛(\mathbb{C}^{2})^{\otimes n}( blackboard_C start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT ⊗ italic_n end_POSTSUPERSCRIPT) expanded in terms of the n𝑛nitalic_n-qubit Pauli operators: H=∑x∈{0,1}2⁢nλx⁢σx,𝐻subscript𝑥superscript012𝑛subscript𝜆𝑥subscript𝜎𝑥H=\sum_{x\in\{0,1\}^{2n}}\lambda_{x}\sigma_{x},italic_H = ∑ start_POSTSUBSCRIPT italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT 2 italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , where λxsubscript𝜆𝑥\lambda_{x}italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT are real-valued coefficients (also called interaction strengths) of the Pauli operators σxsubscript𝜎𝑥\sigma_{x}italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT denoted by the string x=(a,b)∈𝔽2n𝑥𝑎𝑏superscriptsubscript𝔽2𝑛x=(a,b)\in\mathbb{F}_{2}^{n}italic_x = ( italic_a , italic_b ) ∈ blackboard_F start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT with σ(a,b)=ia⋅b⊗i=1nXai⁢Zbisubscript𝜎𝑎𝑏superscriptsubscripttensor-product𝑖1𝑛superscript𝑖⋅𝑎𝑏superscript𝑋subscript𝑎𝑖superscript𝑍subscript𝑏𝑖\sigma_{(a,b)}=i^{a\cdot b}\otimes_{i=1}^{n}X^{a_{i}}Z^{b_{i}}italic_σ start_POSTSUBSCRIPT ( italic_a , italic_b ) end_POSTSUBSCRIPT = italic_i start_POSTSUPERSCRIPT italic_a ⋅ italic_b end_POSTSUPERSCRIPT ⊗ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_X start_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT italic_Z start_POSTSUPERSCRIPT italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT. We call the set of Paulis with non-zero coefficients λxsubscript𝜆𝑥\lambda_{x}italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT as the Pauli spectrum of the Hamiltonian denoted by 𝒮={x∈{0,1}2⁢n:λx≠0}𝒮conditional-set𝑥superscript012𝑛subscript𝜆𝑥0\mathcal{S}=\{x\in\{0,1\}^{2n}:\ \lambda_{x}\neq 0\}caligraphic_S = { italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT 2 italic_n end_POSTSUPERSCRIPT : italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ≠ 0 }. Of particular relevance are k𝑘kitalic_k-local Hamiltonians which involve Pauli operators that act non-trivially on all but at most k𝑘kitalic_k qubits and s𝑠sitalic_s-sparse Hamiltonians whose Pauli expansion contains at most s𝑠sitalic_s non-zero Pauli operators i.e., |𝒮|≤s𝒮𝑠|\mathcal{S}|\leq s| caligraphic_S | ≤ italic_s. There has thus been a growing suite of Hamiltonian learning results that have shown that when the underlying n𝑛nitalic_n-qubit Hamiltonian H𝐻Hitalic_H satisfies these structural properties, learning can be performed with only poly⁡(n)poly𝑛\operatorname{poly}(n)roman_poly ( italic_n ) query complexity, either by making “queries” to the unitary evolution operator U⁢(t)=exp⁡(−i⁢H⁢t)𝑈𝑡𝑖𝐻𝑡U(t)=\exp(-iHt)italic_U ( italic_t ) = roman_exp ( - italic_i italic_H italic_t ) [23, 34, 62, 36, 59, 21, 38, 40, 52, 28], or by assuming one has access to Gibbs state [1, 36, 51, 48, 8, 28]. Notably, [9] considered the problem of learning Hamiltonians that are both local and sparse, without prior knowledge of the support. Several of the learning algorithms mentioned above however require assumptions on the support of the Hamiltonian beyond locality or sparsity, such as [38] which considers geometrically-local Hamiltonians (a subset of local Hamiltonians) and [59] which requires assumptions on the support. Moreover, before learning, it might be desirable to uncover what is the structure of an unknown Hamiltonian in order to choose specialized learning algorithms. Even deciding if a Hamiltonian has a particular structure is a fundamental challenge and constitutes the problem of testing if an unknown Hamiltonian satisfies a certain structural property. As far as we know, this line of investigation is nascent with only a few works on Hamiltonian property testing [54, 2, 41] with Blum et al. [6] having considered the problem of testing local Hamiltonians and the problem of testing sparse Hamiltonians yet to be tackled. This leads us to the motivating question of our work: What is the query complexity of learning and testing structured Hamiltonians? 1.1 Problem statement Before we state our results answering the question above, we clearly mention our learning and testing problems first. If H𝐻Hitalic_H is the Hamiltonian describing the dynamics of a certain physical system, then the state of that system evolves according to the time evolution operator U⁢(t)=e−i⁢H⁢t𝑈𝑡superscript𝑒𝑖𝐻𝑡U(t)=e^{-iHt}italic_U ( italic_t ) = italic_e start_POSTSUPERSCRIPT - italic_i italic_H italic_t end_POSTSUPERSCRIPT. This means that if ρ⁢(0)𝜌0\rho(0)italic_ρ ( 0 ) is the state at time 00, at time t𝑡titalic_t the state would have evolved to ρ⁢(t)=U⁢(t)⁢ρ⁢(0)⁢U†⁢(t)𝜌𝑡𝑈𝑡𝜌0superscript𝑈†𝑡\rho(t)=U(t)\rho(0)U^{\dagger}(t)italic_ρ ( italic_t ) = italic_U ( italic_t ) italic_ρ ( 0 ) italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ( italic_t ). Hence, to test and learn a Hamiltonian one can do the following: prepare a desired state, apply U⁢(t)𝑈𝑡U(t)italic_U ( italic_t ) or tensor products of U⁢(t)𝑈𝑡U(t)italic_U ( italic_t ) with identity to the state, and finally measure in a chosen basis. From here onwards, this is what we mean by querying the unitary U⁢(t)𝑈𝑡U(t)italic_U ( italic_t ). It is usual to impose the normalization condition ∥H∥∞≤1subscriptdelimited-∥∥𝐻1\lVert H\rVert_{\infty}\leq 1∥ italic_H ∥ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ≤ 1 (i.e., that the eigenvalues of H𝐻Hitalic_H are bounded in absolute value by 1111), as otherwise the complexities scale with the norm of the Hamiltonian. Throughout this paper, we will consider the normalized Frobenius norm as the distance between Hamiltonians, namely d⁢(H,H′)=∥H−H′∥2=Tr⁡[(H−H′)2]2n,𝑑𝐻superscript𝐻′subscriptdelimited-∥∥𝐻superscript𝐻′2Trsuperscript𝐻superscript𝐻′2superscript2𝑛d(H,H^{\prime})=\lVert H-H^{\prime}\rVert_{2}=\sqrt{\frac{\operatorname{Tr}[(H% -H^{\prime})^{2}]}{2^{n}}},italic_d ( italic_H , italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) = ∥ italic_H - italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = square-root start_ARG divide start_ARG roman_Tr [ ( italic_H - italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] end_ARG start_ARG 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_ARG end_ARG , which equals the 2-norm of the Pauli spectrum, d⁢(H,H′)=∑|λx−λx′|2𝑑𝐻superscript𝐻′superscriptsubscript𝜆𝑥subscriptsuperscript𝜆′𝑥2d(H,H^{\prime})=\sqrt{\sum|\lambda_{x}-\lambda^{\prime}_{x}|^{2}}italic_d ( italic_H , italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) = square-root start_ARG ∑ | italic_λ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT - italic_λ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG. A property of a Hamiltonian, denoted ℋℋ\mathcal{H}caligraphic_H is a class of Hamiltonians that satisfy the property (here we will be interested in sparse and local properties). We say that H𝐻Hitalic_H is ε𝜀\varepsilonitalic_ε-far from having a property ℋℋ\mathcal{H}caligraphic_H if d⁢(H,H′)>ε𝑑𝐻superscript𝐻′𝜀d(H,H^{\prime})>\varepsilonitalic_d ( italic_H , italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) > italic_ε for every H′∈ℋsuperscript𝐻′ℋH^{\prime}\in\mathcal{H}italic_H start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ caligraphic_H, and otherwise is ε𝜀\varepsilonitalic_ε-close. Now, we are ready to state the testing and learning problems. Let ℋℋ\mathcal{H}caligraphic_H be a property and let H𝐻Hitalic_H be an unknown Hamiltonian with ∥H∥∞≤1subscriptdelimited-∥∥𝐻1\lVert H\rVert_{\infty}\leq 1∥ italic_H ∥ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ≤ 1 and Tr⁡[H]=0Tr𝐻0\operatorname{Tr}[H]=0roman_Tr [ italic_H ] = 0. Problem 1.1 (Tolerant testing). Promised H𝐻Hitalic_H is either ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-close or ε2subscript𝜀2\varepsilon_{2}italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT-far from satisfying property ℋℋ\mathcal{H}caligraphic_H, decide which is the case by making queries to U⁢(t)𝑈𝑡U(t)italic_U ( italic_t ). Problem 1.2 (Hamiltonian learning). Promised H∈ℋ𝐻ℋH\in\mathcal{H}italic_H ∈ caligraphic_H, output a classical description of H~∈ℋ~𝐻ℋ\widetilde{H}\in\mathcal{H}over~ start_ARG italic_H end_ARG ∈ caligraphic_H such that ‖H−H~‖2≤εsubscriptnorm𝐻~𝐻2𝜀\|H-\widetilde{H}\|_{2}\leq\varepsilon∥ italic_H - over~ start_ARG italic_H end_ARG ∥ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ≤ italic_ε by making queries to U⁢(t)𝑈𝑡U(t)italic_U ( italic_t ). 1.2 Summary of results The main results of this submission are query-efficient algorithms for testing and learning Hamiltonians that are local and/or sparse. We can reproduce these results without using quantum memory by increasing the number of queries. We summarize our results in the table below (for simplicity we state our results for constant accuracy). Testing Learning with memory w/o memory with memory w/o memory s𝑠sitalic_s-sparse poly⁡(s)poly𝑠\operatorname{poly}(s)roman_poly ( italic_s ) poly⁡(s)poly𝑠\operatorname{poly}(s)roman_poly ( italic_s ) poly⁡(s)poly𝑠\operatorname{poly}(s)roman_poly ( italic_s ) n⋅poly⁡(s)⋅𝑛poly𝑠n\cdot\operatorname{poly}(s)italic_n ⋅ roman_poly ( italic_s ) k𝑘kitalic_k-local O⁢(1)𝑂1O(1)italic_O ( 1 ) O⁢(1)𝑂1O(1)italic_O ( 1 ) [6] exp⁡(k2)superscript𝑘2\exp(k^{2})roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) (log⁡n)⋅exp⁡(k2)⋅𝑛superscript𝑘2(\log n)\cdot\exp(k^{2})( roman_log italic_n ) ⋅ roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) k𝑘kitalic_k-local & s𝑠sitalic_s-sparse poly⁡(s)poly𝑠\operatorname{poly}(s)roman_poly ( italic_s ) poly⁡(s)poly𝑠\operatorname{poly}(s)roman_poly ( italic_s ) min⁡{exp⁡(k2),poly⁡(s⁢k)}superscript𝑘2poly𝑠𝑘\min\{\exp(k^{2}),\operatorname{poly}(sk)\}roman_min { roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , roman_poly ( italic_s italic_k ) } (log⁡n)⋅min⁡{exp⁡(k2),poly⁡(s⁢k)}⋅𝑛superscript𝑘2poly𝑠𝑘(\log n)\cdot\min\{\exp(k^{2}),\operatorname{poly}(sk)\}( roman_log italic_n ) ⋅ roman_min { roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) , roman_poly ( italic_s italic_k ) } Table 1: Query complexity for learning and testing n𝑛nitalic_n-qubit structured Hamiltonians. Dependence on n𝑛nitalic_n and the structural property is shown for constant accuracy. Results are indicated with quantum memory (i.e., an n𝑛nitalic_n-qubit ancillary system is available) and without quantum memory. Before we discuss our results in more detail, we make a few remarks about our main results. (i)𝑖(i)( italic_i ) As far as we know, this is the first work: (a)𝑎(a)( italic_a ) with complexities that are independent of n𝑛nitalic_n (with memory)111We remark that there are a few works that achieve n𝑛nitalic_n-independent complexities for learning local Hamiltonians in the ∞\infty∞-norm of the Pauli coefficients, but when transformed into 2222-norm learners they yield complexities depending on nksuperscript𝑛𝑘n^{k}italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT., and (b)𝑏(b)( italic_b ) that does not assume knowledge of the support.222Soon after the third-author’s work [32], Bakshi et al. [9] presented a learning algorithm that does not require prior knowledge of the support, although their result achieve Heisenberg scaling in complexity using heavy machinery. (i⁢v)𝑖𝑣(iv)( italic_i italic_v ) We give the first learning algorithm for Hamiltonians that are only promised to be sparse, and not necessarily local. Similarly, our local Hamiltonian learning problem doesn’t assume geometric locality which was assumed in several prior works. (i⁢i⁢i)𝑖𝑖𝑖(iii)( italic_i italic_i italic_i ) Our testing algorithms are tolerant, i.e., they can handle the setting where ε1≠0subscript𝜀10\varepsilon_{1}\neq 0italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ≠ 0. As far as we know, there are only a handful of polynomial-time tolerant testers for quantum objects. (i⁢v)𝑖𝑣(iv)( italic_i italic_v ) We show that all our all the learning protocols with quantum memory can be translated to ones which require no quantum memory. In the case of learning structured Hamiltonians, we obtain a protocol with only a factor log⁡n𝑛\log nroman_log italic_n overhead for local Hamiltonians and a protocol with a factor n𝑛nitalic_n overhead for sparse Hamiltonians. (v)𝑣(v)( italic_v ) We also give a tolerant testing algorithm for s𝑠sitalic_s-sparse Hamiltonians that requires no quantum memory based on a new subroutine called Pauli hashing. The query complexity is O⁢(poly⁡(s))𝑂poly𝑠O(\operatorname{poly}(s))italic_O ( roman_poly ( italic_s ) ) and is notably independent of dimension n𝑛nitalic_n. We remark that most previous work on Hamiltonian learning (that we highlighted earlier) are done under the distance induced by the supremum norm of the Pauli spectrum and with extra constraints apart from locality [23, 34, 62, 36, 58, 59, 12, 21, 38, 40, 42, 52, 28]. When transformed into learning algorithms under the finer distance induced by the 2-norm of the Pauli spectrum, these proposals yield complexities that depend polynomially on nksuperscript𝑛𝑘n^{k}italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT and only work for a restricted family of k𝑘kitalic_k-local Hamiltonians. The works that explicitly consider the problem of learning under the 2-norm have complexities depending on n𝑛nitalic_n and assume a stronger access model [19, 9]. 1.3 Results Local Hamiltonians. Recently, Bluhm, Caro and Oufkir proposed a non-tolerant testing algorithm, meaning that it only works for the case ε1=0,subscript𝜀10\varepsilon_{1}=0,italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 , whose query complexity is O⁢(n2⁢k+2/(ε2−ε1)4)𝑂superscript𝑛2𝑘2superscriptsubscript𝜀2subscript𝜀14O(n^{2k+2}/(\varepsilon_{2}-\varepsilon_{1})^{4})italic_O ( italic_n start_POSTSUPERSCRIPT 2 italic_k + 2 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) and with total evolution time O⁢(nk+1/(ε2−ε1)3)𝑂superscript𝑛𝑘1superscriptsubscript𝜀2subscript𝜀13O(n^{k+1}/(\varepsilon_{2}-\varepsilon_{1})^{3})italic_O ( italic_n start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT ). They posed as open questions whether the dependence on n𝑛nitalic_n could be removed and whether an efficient tolerant-tester was possible [5, Section 1.5]. Our first result gives positive answer to both questions. Result 1.3. There is an algorithm that solves 1.1 for k𝑘kitalic_k-local Hamiltonians by making poly⁡(1/(ε2−ε1))poly1subscript𝜀2subscript𝜀1\operatorname{poly}(1/(\varepsilon_{2}-\varepsilon_{1}))roman_poly ( 1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ) queries to the evolution operator and with poly⁡(1/(ε2−ε1))poly1subscript𝜀2subscript𝜀1\operatorname{poly}(1/(\varepsilon_{2}-\varepsilon_{1}))roman_poly ( 1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ) total evolution time. See Theorem 4.1 for a formal statement of this result. Our algorithm to test for locality is simple. It consists of repeating the following process 1/(ε2−ε1)41superscriptsubscript𝜀2subscript𝜀141/(\varepsilon_{2}-\varepsilon_{1})^{4}1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT times: prepare n𝑛nitalic_n EPR pairs, apply U⁢(ε2−ε1)⊗Id2ntensor-product𝑈subscript𝜀2subscript𝜀1subscriptIdsuperscript2𝑛U(\varepsilon_{2}-\varepsilon_{1})\otimes\mathop{\rm Id}\nolimits_{2^{n}}italic_U ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ⊗ roman_Id start_POSTSUBSCRIPT 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT to them and measure in the Bell basis. Each time that we repeat this process, we sample from the Pauli sprectrum of U⁢(ε2−ε1)𝑈subscript𝜀2subscript𝜀1U(\varepsilon_{2}-\varepsilon_{1})italic_U ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ).333The Pauli spectrum of a unitary U=∑xU^x⁢σx𝑈subscript𝑥subscript^𝑈𝑥subscript𝜎𝑥U=\sum_{x}\widehat{U}_{x}\sigma_{x}italic_U = ∑ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT over^ start_ARG italic_U end_ARG start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT determines a probability distribution because ∑x|U^x|2=1subscript𝑥superscriptsubscript^𝑈𝑥21\sum_{x}|\widehat{U}_{x}|^{2}=1∑ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT | over^ start_ARG italic_U end_ARG start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 1. As ε2−ε1subscript𝜀2subscript𝜀1\varepsilon_{2}-\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT is small, Taylor expansion ensures that U⁢(ε2−ε1)≈Id2n−i⁢(ε2−ε1)⁢H𝑈subscript𝜀2subscript𝜀1subscriptIdsuperscript2𝑛𝑖subscript𝜀2subscript𝜀1𝐻U(\varepsilon_{2}-\varepsilon_{1})\approx\mathop{\rm Id}\nolimits_{2^{n}}-i(% \varepsilon_{2}-\varepsilon_{1})Hitalic_U ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ≈ roman_Id start_POSTSUBSCRIPT 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT end_POSTSUBSCRIPT - italic_i ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) italic_H, so sampling from the Pauli spectrum of U⁢(ε2−ε1)𝑈subscript𝜀2subscript𝜀1U(\varepsilon_{2}-\varepsilon_{1})italic_U ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) allows us to estimate the weight of the non-local terms of H𝐻Hitalic_H. If that weight is big, we output that H𝐻Hitalic_H is far from k𝑘kitalic_k-local, and otherwise we conclude that H𝐻Hitalic_H is close to k𝑘kitalic_k-local. Our second result is a learning algorithm for k𝑘kitalic_k-local Hamiltonians. Result 1.4. There is an algorithm that solves 1.2 for k𝑘kitalic_k-local Hamiltonians by making exp⁡(k2+k⁢log⁡(1/ε))superscript𝑘2𝑘1𝜀\exp(k^{2}+k\log(1/\varepsilon))roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_k roman_log ( 1 / italic_ε ) ) queries to the evolution operator with exp⁡(k2+k⁢log⁡(1/ε))superscript𝑘2𝑘1𝜀\exp(k^{2}+k\log(1/\varepsilon))roman_exp ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + italic_k roman_log ( 1 / italic_ε ) ) total evolution time. See Theorem 4.3 for a formal statement of this result. The learning algorithm has two stages. In the first stage one samples from the Pauli distribution of U⁢(ε)𝑈𝜀U(\varepsilon)italic_U ( italic_ε ), as in the testing algorithm, and from that one can detect which are the big Pauli coefficients of H𝐻Hitalic_H. In the second stage we learn the big Pauli coefficients the swap test. One can ensure that the coefficients not detected as big in the first stage of the algorithm can be neglected. To argue this formally, we use the non-commutative Bohnenblust-Hille inequality, which has been used recently for various quantum learning algorithms [35, 56]. Sparse Hamiltonians. Despite the numerous papers in the classical literature studying the problems of testing and learning sparse Boolean functions [31, 46, 61, 24], there are not many results on learning Hamiltonians that are sparse (and not necessarily local) and the only testing result that we are aware of requires O⁢(s⁢n)𝑂𝑠𝑛O(sn)italic_O ( italic_s italic_n ) queries [6, Remark B.2]. Here, we present the first sparsity testing algorithm whose complexity does not depend on n𝑛nitalic_n and the first learning algorithm for sparse Hamiltonians which does not make any assumptions regarding the support of the Hamiltonian beyond sparsity. Result 1.5. There is an algorithm that solves 1.1 for s𝑠sitalic_s-sparse Hamiltonians by making poly⁡(s/(ε2−ε1))poly𝑠subscript𝜀2subscript𝜀1\operatorname{poly}(s/(\varepsilon_{2}-\varepsilon_{1}))roman_poly ( italic_s / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ) queries to the evolution operator and with poly⁡(s/(ε2−ε1))poly𝑠subscript𝜀2subscript𝜀1\operatorname{poly}(s/(\varepsilon_{2}-\varepsilon_{1}))roman_poly ( italic_s / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ) total evolution time. See Theorem 4.5 for a formal statement. This testing algorithm consists on performing Pauli sampling of U⁢((ε22−ε12)/s)𝑈superscriptsubscript𝜀22superscriptsubscript𝜀12𝑠U(\sqrt{(\varepsilon_{2}^{2}-\varepsilon_{1}^{2})/s})italic_U ( square-root start_ARG ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) / italic_s end_ARG ) a total of O⁢(s4/(ε22−ε12)4)𝑂superscript𝑠4superscriptsuperscriptsubscript𝜀22superscriptsubscript𝜀124O(s^{4}/(\varepsilon_{2}^{2}-\varepsilon_{1}^{2})^{4})italic_O ( italic_s start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) times. From these samples one can estimate the sum of the squares of the top s𝑠sitalic_s Pauli coefficients of U𝑈Uitalic_U. If this quantity is big enough, we output that the Hamiltonian is close to s𝑠sitalic_s-sparse, and otherwise that is far. Although from this high-level description the algorithm seems similar to the locality testing one, the analysis is more involved and requires taking the second order Taylor expansion, which is the reason why the dependence on (ε2−ε1)subscript𝜀2subscript𝜀1(\varepsilon_{2}-\varepsilon_{1})( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) is worse in this case. Result 1.6. There is an algorithm that solves 1.2 for s𝑠sitalic_s-sparse Hamiltonians by making poly⁡(s/ε)poly𝑠𝜀\operatorname{poly}(s/\varepsilon)roman_poly ( italic_s / italic_ε ) queries to the evolution operator with poly⁡(s/ε)poly𝑠𝜀\operatorname{poly}(s/\varepsilon)roman_poly ( italic_s / italic_ε ) total evolution time. See Theorem 4.6 for a formal statement. This learning algorithm begins by detecting which are the top s𝑠sitalic_s Pauli coefficients, which can be done via Pauli sampling, and concludes by learning the top s𝑠sitalic_s Pauli coefficients using a swap test, similarly to the locality learning algorithm. Learning and testing without quantum memory. Motivated by the limitations of current devices, there has been a series of recent works aiming to understand the power of quantum memory in testing and learning tasks, exhibiting exponential separations in some cases [14, 16, 17]. A natural question is, if the problems that we mentioned above become harder without quantum memory? Learning without memory. We surprisingly show that, the learning protocols that we mention above, can be implemented efficiently when one has no quantum memory. To this end, we provide two crucial subroutines for (i)𝑖(i)( italic_i ) estimating the Pauli spectrum of a unitary, (i⁢i)𝑖𝑖(ii)( italic_i italic_i ) estimating a single Pauli coefficient to make our protocols work in the memory-less setting. Subroutine (i⁢i)𝑖𝑖(ii)( italic_i italic_i ) incurs in no extra query-cost, and subroutine (i)𝑖(i)( italic_i ) only incurs in a factor-n𝑛nitalic_n overhead in the case of learning s𝑠sitalic_s-sparse Hamiltonians and a factor log⁡(n)𝑛\log(n)roman_log ( italic_n ) in the case of learning k𝑘kitalic_k-local Hamiltonians. These subroutines can also be useful in other contexts. In particular, we propose tolerant tester to decide if an unknown unitary is a k𝑘kitalic_k-junta which uses O⁢(4k)𝑂superscript4𝑘O(4^{k})italic_O ( 4 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) queries (see Proposition 3.5), making progress on a question of Chen et al. [18, Section 1.3], and then we use subroutine (i)𝑖(i)( italic_i ) to turn it into a memory-less tester that only makes O⁢(4k⁢n)𝑂superscript4𝑘𝑛O(4^{k}n)italic_O ( 4 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT italic_n ) queries. Testing sparse Pauli channels via Pauli hashing. In order to test for sparsity of Hamiltonian without memory we reduce to the problem of testing sparsity of a Pauli channel Φ:ρ↦∑xp⁢(x)⁢σx⁢ρ⁢σx:Φmaps-to𝜌subscript𝑥𝑝𝑥subscript𝜎𝑥𝜌subscript𝜎𝑥\Phi:\rho\mapsto\sum_{x}p(x)\sigma_{x}\rho\sigma_{x}roman_Φ : italic_ρ ↦ ∑ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_p ( italic_x ) italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_ρ italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT, which is of independent interest. To do that, we introduce a new technique called Pauli Hashing which allows to construct random partitions of Pauli operators. The high-level idea is to bucket the error rates p⁢(x)𝑝𝑥p(x)italic_p ( italic_x ) and thereby the corresponding Pauli operators: for this, we choose a random subgroup G𝐺Gitalic_G of the n𝑛nitalic_n-qubit Pauli group with dimension t=O⁢(log⁡s)𝑡𝑂𝑠t=O(\log s)italic_t = italic_O ( roman_log italic_s ). Pauli hashing allows us to partition all the Pauli operators into cosets the centralizer of G𝐺Gitalic_G which contains all the Paulis that commute with the Paulis in G𝐺Gitalic_G. The buckets are then the O⁢(s)𝑂𝑠O(s)italic_O ( italic_s ) cosets of the centralizer of G𝐺Gitalic_G. The main work then goes into arguing that the sum of the weights of the top s𝑠sitalic_s buckets is a good estimate of the top s𝑠sitalic_s error rates, and then a structural lemma we prove shows this is a good proxy for indicating whether the Pauli channel is close to being s𝑠sitalic_s-sparse or not. Putting everything together, with some careful analysis, we get an efficient tolerant tester for s𝑠sitalic_s-sparse Pauli channels. Result 1.7. There is an algorithm requiring no quantum memory that tests if a Pauli channel ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-close to or ε1subscript𝜀1\varepsilon_{1}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-far-from being s𝑠sitalic_s-sparse in diamond norm by making O~⁢(s2/(ε2−ε1)6)~𝑂superscript𝑠2superscriptsubscript𝜀2subscript𝜀16\widetilde{O}(s^{2}/(\varepsilon_{2}-\varepsilon_{1})^{6})over~ start_ARG italic_O end_ARG ( italic_s start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT ) queries to the channel. See Theorem 5.3 for a formal statement. We remark that Pauli Hashing only requires the preparation of Pauli eigenstates and Pauli measurements, making it suitable for the near-term. Testing sparse Hamiltonians without memory. We provide a memory-less testing algorithm for s𝑠sitalic_s-sparse Hamiltonians that uses Pauli hashing, that is completely independent of our tester with memory and only requires poly⁡(s/ε)poly𝑠𝜀\operatorname{poly}(s/\varepsilon)roman_poly ( italic_s / italic_ε ) queries and total evolution time, notably avoiding any dependence on n𝑛nitalic_n. To do this, we reduce the problem of testing Hamiltonian sparsity to testing the sparsity of an associated Pauli channel. To be precise, given the time evolution channel ℋt:ρ→U⁢(t)⁢ρ⁢U†⁢(t):subscriptℋ𝑡→𝜌𝑈𝑡𝜌superscript𝑈†𝑡\mathcal{H}_{t}:\rho\to U(t)\rho U^{\dagger}(t)caligraphic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT : italic_ρ → italic_U ( italic_t ) italic_ρ italic_U start_POSTSUPERSCRIPT † end_POSTSUPERSCRIPT ( italic_t ), we define its Pauli-twirled channel via ℋt𝒯⁢(ρ)=𝔼x⁢[σx⁢ℋt⁢(σx⁢ρ⁢σx)⁢σx],superscriptsubscriptℋ𝑡𝒯𝜌subscript𝔼𝑥delimited-[]subscript𝜎𝑥subscriptℋ𝑡subscript𝜎𝑥𝜌subscript𝜎𝑥subscript𝜎𝑥\mathcal{H}_{t}^{\mathcal{T}}(\rho)=\mathbb{E}_{x}[\sigma_{x}\mathcal{H}_{t}(% \sigma_{x}\rho\sigma_{x})\sigma_{x}],caligraphic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT ( italic_ρ ) = blackboard_E start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT [ italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT caligraphic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ( italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_ρ italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ) italic_σ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ] , and we prove that ℋtsubscriptℋ𝑡\mathcal{H}_{t}caligraphic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is sparse if and only if ℋt𝒯superscriptsubscriptℋ𝑡𝒯\mathcal{H}_{t}^{\mathcal{T}}caligraphic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT start_POSTSUPERSCRIPT caligraphic_T end_POSTSUPERSCRIPT is sparse. Our result is then as follows. See Theorem 5.7 for a formal statement. Result 1.8. There is an algorithm requiring no quantum memory that solves 1.2 for s𝑠sitalic_s-sparse Hamiltonians by making poly⁡(s/ε)poly𝑠𝜀\operatorname{poly}(s/\varepsilon)roman_poly ( italic_s / italic_ε ) queries to the evolution operator with poly⁡(s/ε)poly𝑠𝜀\operatorname{poly}(s/\varepsilon)roman_poly ( italic_s / italic_ε ) total evolution time. Lower bounds. One drawback of our learning and testing algorithms is the exponent of the sparsity parameter s𝑠sitalic_s, locality parameter k𝑘kitalic_k and the tolerance (ε2−ε1)subscript𝜀2subscript𝜀1(\varepsilon_{2}-\varepsilon_{1})( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ). Reducing to classical Boolean functions, we show lower bounds without memory that cerfity that the dependence on these parameters cannot be completely avoided, but an interesting and important future direction is to obtain the optimal results for these near-term relevant problems.444We remark that, Bakshi et al. [9] used highly non-trivial ideas to get Heisenberg scaling for their learning algorithm, and potentially similar ideas could be useful here. 1.4 Discussion and open questions Our work opens up several interesting directions which we state here and leave for future work. 1. Dependence on parameters ε1,ε2subscript𝜀1subscript𝜀2\varepsilon_{1},\varepsilon_{2}italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Our main objective in this work was to obtain query complexities for testing and learning with good dependence on the structural parameters. It is natural to ask if we could improve the dependence on the error parameters and perhaps achieve Heisenberg limited scaling as has been shown to be possible in some particular cases for Hamiltonian learning [38, 9]. 2. Robustness to SPAM noise. It would be desirable to make the protocols introduced in this work to be robust to SPAM noise. A potential approach is to adapt strategies in [26]. 3. Adaptivity. For learning structured Hamiltonians, adaptive strategies [29, 22] can improve query complexity by shedding constant factors over baseline learning algorithms, thereby improving performance in practice. Another direction is to then explore adaptive protocols for testing structured Hamiltonians and the performance gains they may bring. 4. Testing and learning with limited quantum memory. For estimating properties of quantum states, Chen et al. [14] showcased the utility of the resource of quantum memory or a k𝑘kitalic_k-qubit ancillary system (k<n𝑘𝑛k<nitalic_k < italic_n). Large separations in query complexity when learning with memory (even for k≪nmuch-less-than𝑘𝑛k\ll nitalic_k ≪ italic_n) and without memory have been reported for learning Pauli channels [20, 15] and shadow tomography [16]. We could thus imagine having access to only limited quantum memory during learning or testing structured Hamiltonians as well. However, it should be noted that given the separation between the query complexities (see Table 1) with access to n𝑛nitalic_n-qubit quantum memory and without any, only marginal gains in complexity are expected from having access to limited quantum memory. 5. Testing and learning Hamiltonians from Gibbs states. Another natural learning model is that of having access to copies of the Gibbs state of a quantum Hamiltonian at a certain inverse temperature. There has been a suite of work investigating learning local Hamiltonians from Gibbs states [1, 8] but answering the question of testing structured Hamiltonians given access to copies of the Gibbs state remains wide open. Note added. After sharing Theorem 4.1 with Bluhm et al., they independently improved the analysis of their testing algorithm and showed that it only requires O⁢(1/(ε2−ε1)3⁢ε2)𝑂1superscriptsubscript𝜀2subscript𝜀13subscript𝜀2O(1/(\varepsilon_{2}-\varepsilon_{1})^{3}\varepsilon_{2})italic_O ( 1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) queries and O⁢(1/(ε2−ε1)2.5⁢ε20.5)𝑂1superscriptsubscript𝜀2subscript𝜀12.5superscriptsubscript𝜀20.5O(1/(\varepsilon_{2}-\varepsilon_{1})^{2.5}\varepsilon_{2}^{0.5})italic_O ( 1 / ( italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT - italic_ε start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT 2.5 end_POSTSUPERSCRIPT italic_ε start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0.5 end_POSTSUPERSCRIPT ) total evolution time, which is very similar to our Theorem 4.1 [6]. In addition, for a wide range of k=O⁢(n)𝑘𝑂𝑛k=O(n)italic_k = italic_O ( italic_n ), their algorithm does not require the use of auxiliary qubits. Acknowledgements. S.A. and A.D. thank the Institute for Pure and Applied Mathematics (IPAM) for its hospitality throughout the long program “Mathematical and Computational Challenges in Quantum Computing” in Fall 2023 during which part of this work was initiated. This work was done in part while S.A. was visiting the Simons Institute for the Theory of Computing, supported by DOE QSA grant #FP00010905. This research was supported by the Europea union’s Horizon 2020 research and innovation programme under the Marie Skłodowska-Curie grant agreement no. 945045, and by the NWO Gravitation project NETWORKS under grant no. 024.002.003. We thank Amira Abbas, Francesco Anna Mele, Andreas Bluhm, Jop Briët, Matthias Caro, Nunzia Cerrato, Aadil Oufkir, and Daniel Liang for useful comments and discussions. A.D. thanks Patrick Rall for multiple conversations on stabilizer subgroups and Pauli twirling. A.D. thanks Isaac Chuang for discussions on the problem of testing Hamiltonians. F.E.G. is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy – EXC-2047/1 – 390685813."
