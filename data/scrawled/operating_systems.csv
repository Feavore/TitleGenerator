URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.01129v1,Mewz: Lightweight Execution Environment for WebAssembly with High Isolation and Portability using Unikernels,"Cloud computing requires isolation and portability for workloads. Cloud vendors must isolate each user’s resources from others to prevent them from attacking other users or the whole system. Users may want to move their applications to different environments, for instance other cloud, on-premise servers, or edge devices. Virtual machines (VMs) and containers are widely used to achieve these requirements. However, there are two problems with combined use of VMs and containers. First, container images depend on host operating systems and CPU architectures. Users need to manage different container images for each platform to run the same codes on different OSes and ISAs. Second, performance is degraded by the overheads of both VMs and containers. Previous researches have solved each of these problems separately, but no solution solves both problems simultaneously. Therefore, execution environments of applications on cloud are required to be more lightweight and portable while ensuring isolation is required. We propose a new system that combines WebAssembly (Wasm) and unikernels. Wasm is a portable binary format, so it can be run on any host operating systems and architectures. Unikernels are kernels statically linked with applications, which reduces the overhead of guest kernel. In this approach, users deploy applications as a Wasm binary and it runs as a unikernel on cloud. To realize this system, we propose a mechanism to convert a Wasm binary into a unikernel image with the Wasm AoT-compiled to native code. We developed a unikernel with Wasm System Interface (WASI) API and an Ahead-of-Time (AoT) compiler that converts Wasm to native code. We evaluated the performance of the system by running a simple HTTP server compiled into Wasm and native code. The performance was improved by 30% compared to running it with an existing Wasm runtime on Linux on a virtual machine.","Cloud computing and container-based virtualization technologies are widely used in modern system development. In cloud computing, multiple users share the same physical resources of a data center. In such environments, it might be possible for users to attack other users by exploiting vulnerabilities in the system. For example, malicious users can steal sensitive information from other users or destroy the whole cloud system. To achieve multi tenacy, cloud providers must isolate each user’s resources from others. There are several isolation mechanisms, and the intensity of isolation depends on the type. The most isolated mechanism is separating the physical machines. Providing a physical machine for each user prevents interference between users. This method, called bare-metal cloud[36], is not mainstream for some drawbacks such as difficulty in immediate resource allocation. The second most isolated mechanism is virtual machine (VM) based isolation. In this method a hypervisor runs on a physical machine and creates multiple VMs. Each VM is isolated from others, and it has its own operating system. This method is widely used nowadays. The third most isolated mechanism is container-based isolation. An container is an isolated environment that runs on a host operating system. Since containers share the same kernel, they are more lightweight than VMs. However, containers does not provide enough isolation for multi-tenancy[29]. Despite the lack of isolation, containers are widely used in cloud computing for their portability. Container images can be easily moved between different environments, such as development, testing, and production. Containers are used in cloud environments with VMs to ensure isolation. Combining containers and cloud computing entails two problems. First, container images depend on host operating systems and CPU architectures. To distribute container images to environments with different operating systems and architectures, developers must build images for each one. Second, the virtualization overhead of both containers and VMs degrades performance. There are existing solutions to each of these challenges. For example, substitution of containers with WebAssembly is proposed to solve the portability problem[19]. Binary translation is also proposed, which converts instructions of one architecture to another[3]. However, these solutions do not solve the overhead problem. To reduce the overheads of guest kernel on VMs, previous researches proposed unikernels, which are specialized kernels for each application[17]. There is also a work that implements a lightweight hypervisor with limited functionality to reduce the overhead of hypervisors[1]. Conversely, these solutions do not enhance application portability. No solution solves both problems. We propose a new system where applications are distributed as WebAssembly and run them as unikernels on cloud. WebAssembly is a portable binary format, so it can be run on any host operating systems and architectures. Unikernels are kernels statically linked with applications. This design enables applications to call kernel functions directly, reducing the overhead from guest OSes. This system solves both the portability and virtualization overhead problems. To implement this system, we need to link WebAssembly binaries with kernel codes. However, the issue lies in converting a WebAssembly binary into a unikernel image, because WebAssembly cannot be simply linked with kernel codes. Moreover, it is preferable to compile WebAssembly ahead of time (AoT) into native code for performance reasons. We devise a new mechanism to do it by exploiting WebAssembly System Interface, which is the standardized API for WebAssembly to access system resources. We combine an AoT-compiled WebAssembly binary and kernel codes that provide WebAssembly System Interface by symbol resolution. We realized it by developing a unikernel that provides WebAssembly System Interface and an AoT compiler that converts WebAssembly to native code. We evaluate our system with an HTTP server that distributes static files. The result shows that our system executes Wasm applications with lower overhead than existing technologies. The rest of this paper is organized as follows. Section 2 summarizes the requirements for the execution environment of workloads on cloud and describes the problems of existing solutions. Section 3 explains the architecture and implementation of the proposed system. Section 4 evaluates the performance of our system. Section 5 describes related works. Section 6 concludes this paper."
https://arxiv.org/html/2411.00572v1,Enhancing Adaptive Mixed-Criticality Schedulingwith Deep Reinforcement Learning,"Adaptive Mixed-Criticality (AMC) is a fixed-priority preemptive scheduling algorithm for mixed-criticality hard real-time systems. It dominates many other scheduling algorithms for mixed-criticality systems, but does so at the cost of occasionally dropping jobs of less important/critical tasks, when low-priority jobs overrun their time budgets. In this paper we enhance AMC with a deep reinforcement learning (DRL) approach based on a Deep-Q Network. The DRL agent is trained off-line, and at run-time adjusts the low-criticality budgets of tasks to avoid budget overruns, while ensuring that no job misses its deadline if it does not overrun its budget. We have implemented and evaluated this approach by simulating realistic workloads from the automotive domain. The results show that the agent is able to reduce budget overruns by at least up to 50505050%, even when the budget of each task is chosen based on sampling the distribution of its execution time. To the best of our knowledge, this is the first use of DRL in AMC reported in the literature.","Many systems in the automotive and avionics industries are designed as mixed-criticality systems (MCS), i.e. as systems with tasks with more than one level of criticality that execute on the same hardware platform. From the point of view of scheduling, the overriding goal is to ensure a high level of assurance regarding timing of critical tasks, while leveraging the increasingly available computing power for lower criticality tasks. Sharing resources is also a goal to reduce system complexity, energy/power and weight, in particular in airborne systems where it is at a premium. Adaptive Mixed Criticality (AMC) (Baruah et al., [n. d.]) is a fixed-priority preemptive scheduling algorithm, that descends from Vestal’s seminal scheduling algorithm for MCS (Vestal, 2007). In this approach, the tasks are assigned different criticality levels: HI and LO, in its simplest form. In this case, the system may operate in two modes, HI and LO. The system starts in LO-mode. In LO-mode, every task may execute for its (time) budget, which is fixed and assigned off-line. Whenever a job exceeds its budget, the system changes to HI-mode and no new LO-tasks are released in that mode. While effective, this approach has a major drawback. Just because a task has a low criticality, it does not mean that it is less important and that it can be abandoned (Esper et al., 2018; Ernst and Di Natale, 2016). In this paper, we propose a novel approach based on deep reinforcement learning (DRL) to adjust the budgets of both LO- and HI-criticality tasks at run time, so as to reduce the number of budget overruns, and therefore the number of LO-criticality job cancellations. The DRL agent is trained off-line, so as to reduce the load on the system at run-time. At run-time, it takes as input the current budgets and execution times of the different jobs, and outputs the adjustments to apply to the budgets of different tasks. We ensure that in spite of these changes the system is still schedulable according to AMC-rtb (Baruah et al., [n. d.]), a sufficient schedulability test for AMC that requires the solution of recurrences, without running AMC-rtb at run-time. To avoid interference with application tasks, the agent runs with the lowest priority as a high-criticality task, thus ensuring that it can adjust the budgets after a switch from LO- to HI-mode. The main contributions of this paper are as follows: • Describes a DRL agent using a Deep-Q Network that adjusts at run-time the budgets of tasks in LO-mode so as to reduce time budget overruns, while providing the same guarantees as AMC: i) all HI jobs meet their deadlines; ii) all LO tasks that do not overrun their budgets meet their deadlines; • Describes an event-driven simulator that is able to simulate the timing behavior of realistic automotive applications (Kramer et al., [n. d.]) on a uniprocessor platform; • Presents an exhaustive experimental evaluation of the DRL agent for a realistic tasks workload drawn from an automotive application (Kramer et al., [n. d.]). The results we obtained show that the DQN-agent can reduce the number of budget overruns of both LO-criticality and HI-criticality jobs by at least 50%. The remainder of this paper is organized as follows. In the next section, we discuss the related work. In Section 3 we provide some background on AMC-rtb, and on deep reinforcement learning. Section 4 describes the proposed approach. The design of the DRL agent is presented in Section 5. Section 6 describes the simulator used for training and evaluating the agent. In Section 7 we evaluate the proposed approach using a scenario-based simulation. Section 8 concludes with a summary."
