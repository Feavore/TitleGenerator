URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.04615v1,The Functional Machine Calculus III: ChoiceEarly Announcement,"The Functional Machine Calculus (Heijltjes 2022) is an extension of the lambda-calculus that preserves confluent reduction and typed termination, while enabling both call-by-name and call-by-value reduction behaviour and encoding the computational effects of mutable higher-order store, input/output, and probabilistic computation. In this note the calculus is extended to capture exception handling and loop constructs.","The Functional Machine Calculus (FMC) [25, 5] is a new approach to combining the Î»ğœ†\lambdaitalic_Î»-calculusâ€”as the foundation of functional programmingâ€”with computational effects. It takes a view of the Î»ğœ†\lambdaitalic_Î»-calculus as an instruction language for an abstract machine with a single stack in the style of Krivine [38], where application is push, abstraction is pop, and variable is execute. To accommodate effects, the calculus introduces the following two extensions [25]. Locations Multiple stacks on the machine, each named by a location, allow the encoding of various effects via push and pop actions: mutable higher-order store, as stacks of depth at most one; input/output, as pop-only respectively push-only streams; and probabilities and non-determinism as probabilistically respectively non-deterministically generated streams. Sequencing The introduction of sequential composition and its unit, imperative skip, gives control over evaluation behaviour away from strict callâ€“byâ€“name, and allows the encoding of Plotkinâ€™s callâ€“byâ€“value Î»ğœ†\lambdaitalic_Î»-calculus [68], Moggiâ€™s computational metalanguage [58], and Levyâ€™s callâ€“byâ€“pushâ€“value [43]. Encoding effects into the generalized operators of the calculus, rather than introducing primitives, means that two key properties of the Î»ğœ†\lambdaitalic_Î»-calculus are preserved. Confluence Reduction in the FMC is confluent in the presence of effects. This is a consequence of the separation of operational behaviour, which governs the machine, from local reduction behaviour, which is the interaction of consecutive push and pop actions. Reduction equivalence for state then implements the algebraic laws of Plotkin and Power [66]. Types The FMC can be simply typed, which conveys strong normalization and termination of the machine. This gives a solution to the problem of typing higher-order store: Landinâ€™s Knot [39], which encodes recursion via higher-order store, cannot be typed (in its full generality). This paper introduces a third extension to the FMC, choice, to include a wider range of computational behaviours: constants, conditionals, data constructors, exception handling, and loops. These have in common that, semantically, they are modelled by sums or coproducts: for example, the Booleans are given by the type 1+1111+11 + 1, the error monad is given by the functor Tâ¢X=E+Xğ‘‡ğ‘‹ğ¸ğ‘‹TX=E+Xitalic_T italic_X = italic_E + italic_X for a set of exceptions Eğ¸Eitalic_E, and loops are modelled by taking a map in Aâ†’A+Bâ†’ğ´ğ´ğµA\to A+Bitalic_A â†’ italic_A + italic_B to one in Aâ†’Bâ†’ğ´ğµA\to Bitalic_A â†’ italic_B (looping on Ağ´Aitalic_A, exiting on BğµBitalic_B) [8]. Together, these will be referred to as choice constructs. The aim is sixfold. First and second, to preserve confluence and types: the resulting calculus should support a natural, confluent reduction relation, and a notion of simple types that guarantees termination of the machine and strong normalization of reduction (in the absence of loops). Third, minimality: choice constructs should be captured with as few syntactic operators as possible, avoiding any overlap in functionality and minimizing the interactions or reductions governing the semantics of the calculus. Fourth, operational semantics: the calculus should continue to be an instruction language for a simple and natural abstract machine. Fifth, seamless integration: different effects should combine seamlessly, without requiring lifting operations. Finally, the FMC has a natural first-order restriction, where function arguments are restricted to be (first-order) values, not arbitrary terms. The sixth aim is to preserve this restriction, which ensures that choice constructs are independent of the calculus being first-order or higher-order. The approach has been to reconsider the notion of choice from first principles, with the aim of capturing coproducts and the constructs that they model in a simple and natural way, satisfying the six criteria above. This led to three (mostly) standard syntactic constructions, which however interact with the stack in subtle ways to give new and unexpected reduction behaviours. The resulting calculus is in some ways highly familiar, yet simultaneously in other ways novel and surprising. In contrast with stateful effects, confluence and type safety are expected for exception handling. The main results are to integrate exceptions seamlessly with stateful effects, to support natural operational and denotational semantics, and to capture a wide range of behaviours with an elegant, minimal syntax. This note will discuss the background literature, introduce the selected choice constructs from operational considerations, formally define the calculus and its type system, and demonstrate how it captures existing formulations. For simplicity of exposition, the calculus will omit the locations modification, and feature only sequencing and choice. Proofs are incomplete at the time of writing, and hence omitted, leaving the intended theorems as conjectures."
https://arxiv.org/html/2411.04555v1,An Axiomatic Study of the Evaluation of Enthymeme Decoding inWeighted Structured Argumentation,"An argument can be seen as a pair consisting of a set of premises and a claim supported by them. Arguments used by humans are often enthymemes, i.e., some premises are implicit. To better understand, evaluate, and compare enthymemes, it is essential to decode them, i.e., to find the missing premisses. Many enthymeme decodings are possible. We need to distinguish between reasonable decodings and unreasonable ones. However, there is currently no research in the literature on â€œHow to evaluate decodings?â€. To pave the way and achieve this goal, we introduce seven criteria related to decoding, based on different research areas. Then, we introduce the notion of criterion measure, the objective of which is to evaluate a decoding with regard to a certain criterion. Since such measures need to be validated, we introduce several desirable properties for them, called axioms. Another main contribution of the paper is the construction of certain criterion measures that are validated by our axioms. Such measures can be used to identify the best enthymemes decodings.","In the literature on logic-based argumentation, a deductive argument is usually defined as a premise-claim pair where the claim is inferred (according to a logic) from the premises. However, when studying human debates (i.e. real world argumentation), it is common to find incomplete arguments, called enthymemes, for which the premises are insufficient for implying the claim. The reason for this incompleteness is varied, for example it may result from imprecision or error, e.g. a human may argue without knowing all the necessary information, or it may be intentional, e.g. one may presuppose that some information is commonly known and therefore does not need to be stated, or the employment of enthymemes is an instrument well known since Aristotle (Faure 2010) as one of the most effective in rhetoric and persuasion when it comes to interacting with an audience. There are studies in the literature on understanding enthymemes in argumentation, using natural language processing (Habernal et al. 2017; Singh et al. 2022; Wei et al. 2022), but these do not identify logic-based arguments. There are also symbolic approaches for decoding enthymemes in structured argumentation including (Hunter 2007; Dupin de Saint-Cyr 2011; Black and Hunter 2012; Hosseini, Modgil, and Rodrigues 2014; Xydis et al. 2020; Panisson, McBurney, and Bordini 2022; Hunter 2022; Leiva, Gottifredi, and GarcÃ­a 2023; Ben-Naim, David, and Hunter 2024), but they only consider the task as identifying a set of formulae that could be added to the incomplete premises in order to entail the claim. This offers potentially many decodings, and there is currently a lack of means for comparing these decoding candidates. In real-world argumentation, it is important to note that decoding is more general than that of completion. In fact, when we decode, we may add and subtract information, to obtain the most appropriate decoding. Furthermore, given that several decodings of an enthymeme can be proposed, we then have the question of how to â€œhow to evaluate the quality of a candidate for decoding an enthymemeâ€ in order to make an optimal choice of decoding. Let us take the following example (which will be part of our running example) to illustrate an enthymeme with two possible decodings. â€¢ Enthymeme Eğ¸Eitalic_E: Knowing that Bob is wealthy, he is a researcher, he makes people happy, and he has people around him who seem to love him, then Bob is happy. â€¢ Decoding D1subscriptğ·1D_{1}italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT: Bob is a researcher and researchers are generally happy, so Bob is happy. â€¢ Decoding D2subscriptğ·2D_{2}italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT: Bob makes people happy and is surrounded by people who love him, and because giving and receiving love often makes people happy, Bob is happy. To study whether D1subscriptğ·1D_{1}italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or D2subscriptğ·2D_{2}italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is a better decoding for Eğ¸Eitalic_E, we will represent knowledge by weighted logics, then we will propose quality measures based on measuring different aspects of a candidate for decoding (criterion measures). Given that the number of criterion measures for a criterion is infinite, we adopt an axiomatic approach, defining the constraints of a good measure."
https://arxiv.org/html/2411.04003v1,Learning Aggregate Queries Defined byFirst-Order Logic with Counting111This is the extended version of the conference contribution[11].,"In the logical framework introduced by Grohe and TurÃ¡n (TOCS 2004) for Boolean classification problems, the instances to classify are tuples from a logical structure, and Boolean classifiers are described by parametric models based on logical formulas. This is a specific scenario for supervised passive learning, where classifiers should be learned based on labelled examples. Existing results in this scenario focus on Boolean classification. This paper presents learnability results beyond Boolean classification. We focus on multiclass classification problems where the task is to assign input tuples to arbitrary integers. To represent such integer-valued classifiers, we use aggregate queries specified by an extension of first-order logic with counting terms called FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT.Our main result shows the following: given a database of polylogarithmic degree, within quasi-linear time, we can build an index structure that makes it possible to learn FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-definable integer-valued classifiers in time polylogarithmic in the size of the database and polynomial in the number of training examples.","We study the complexity of learning aggregate queries from examples. This is a classification problem of the following form. The elements that are to be classified come from a set Xğ‘‹Xitalic_X, the instance space. For a given set Vğ‘‰Vitalic_V, a Vğ‘‰Vitalic_V-valued classifier on Xğ‘‹Xitalic_X is a function c:Xâ†’V:ğ‘â†’ğ‘‹ğ‘‰c\colon X\to Vitalic_c : italic_X â†’ italic_V. We are given a training set Sğ‘†Sitalic_S of labelled examples (x,Î»)âˆˆXÃ—Vğ‘¥ğœ†ğ‘‹ğ‘‰(x,\lambda)\in X\times V( italic_x , italic_Î» ) âˆˆ italic_X Ã— italic_V, i. e., Î»ğœ†\lambdaitalic_Î» is the label assigned to the instance xğ‘¥xitalic_x. The goal is to find a classifier, called a hypothesis, that can be used to predict the label of elements from Xğ‘‹Xitalic_X, including those not given in Sğ‘†Sitalic_S. The term Boolean classification problem refers to the case where |V|=2ğ‘‰2\left\lvert V\right\rvert=2| italic_V | = 2 (often, Vğ‘‰Vitalic_V is {1,0}10\{1,0\}{ 1 , 0 }). We use the term multiclass classification problem to refer to cases where Vğ‘‰Vitalic_V may be arbitrarily large. In machine learning, these problems fall into the category of supervised learning tasks: we want to learn a function from given input-output pairs. In contrast to this, in unsupervised learning (e. g. clustering), the goal is to learn patterns from unlabelled data [49]. We focus on learning problems related to the framework introduced by Grohe and TurÃ¡n [36]. There, the instance space Xğ‘‹Xitalic_X is a set of tuples from a logical structure (that is sometimes called the background structure), and the classifiers are Boolean and are described using parametric models based on logical formulas. In this paper, we extend the framework to multiclass classification problems where the classifiers are integer-valued, i. e., V=â„¤ğ‘‰â„¤V=\mathbb{Z}italic_V = blackboard_Z. In the framework that we consider, the background structure is a relational database ğ’œğ’œ\mathcal{A}caligraphic_A, and the instance space Xğ‘‹Xitalic_X is the set Aksuperscriptğ´ğ‘˜A^{k}italic_A start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT of all kğ‘˜kitalic_k-tuples of elements from the active domain Ağ´Aitalic_A of ğ’œğ’œ\mathcal{A}caligraphic_A (also called the universe of ğ’œğ’œ\mathcal{A}caligraphic_A). Here, kğ‘˜kitalic_k is a fixed positive integer. One fixes a parameter length â„“â„“\ellroman_â„“ (a fixed non-negative integer). A classifier is specified by a pair p=(t,wÂ¯)ğ‘ğ‘¡Â¯ğ‘¤p=(t,\bar{w})italic_p = ( italic_t , overÂ¯ start_ARG italic_w end_ARG ), where wÂ¯=(w1,â€¦,wâ„“)Â¯ğ‘¤subscriptğ‘¤1â€¦subscriptğ‘¤â„“\bar{w}=(w_{1},\dots,w_{\ell})overÂ¯ start_ARG italic_w end_ARG = ( italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_w start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT ) is an â„“â„“\ellroman_â„“-tuple of elements in Ağ´Aitalic_A, and tğ‘¡titalic_t is a counting term in the first-order logic with counting FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT [35] with free variables x1,â€¦,xk,y1,â€¦,yâ„“subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘˜subscriptğ‘¦1â€¦subscriptğ‘¦â„“x_{1},\dots,x_{k},y_{1},\dots,y_{\ell}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_y start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT. This pair pğ‘pitalic_p represents the classifier cp:Xâ†’â„¤:subscriptğ‘ğ‘â†’ğ‘‹â„¤c_{p}\colon X\to\mathbb{Z}italic_c start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT : italic_X â†’ blackboard_Z that assigns to each kğ‘˜kitalic_k-tuple aÂ¯=(a1,â€¦,ak)âˆˆXÂ¯ğ‘subscriptğ‘1â€¦subscriptğ‘ğ‘˜ğ‘‹\bar{a}=(a_{1},\dots,a_{k})\in XoverÂ¯ start_ARG italic_a end_ARG = ( italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) âˆˆ italic_X the integer iğ‘–iitalic_i that is obtained by evaluating the counting term tğ‘¡titalic_t in the database ğ’œğ’œ\mathcal{A}caligraphic_A while interpreting the variables x1,â€¦,xksubscriptğ‘¥1â€¦subscriptğ‘¥ğ‘˜x_{1},\dots,x_{k}italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT with the elements a1,â€¦,aksubscriptğ‘1â€¦subscriptğ‘ğ‘˜a_{1},\dots,a_{k}italic_a start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and the variables y1,â€¦,yâ„“subscriptğ‘¦1â€¦subscriptğ‘¦â„“y_{1},\dots,y_{\ell}italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_y start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT with the â€œparametersâ€ w1,â€¦,wâ„“subscriptğ‘¤1â€¦subscriptğ‘¤â„“w_{1},\dots,w_{\ell}italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_w start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT. We will write ht,wÂ¯ğ’œsubscriptsuperscriptâ„ğ’œğ‘¡Â¯ğ‘¤h^{\mathcal{A}}_{t,\bar{w}}italic_h start_POSTSUPERSCRIPT caligraphic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t , overÂ¯ start_ARG italic_w end_ARG end_POSTSUBSCRIPT to denote this classifier cpsubscriptğ‘ğ‘c_{p}italic_c start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT. Given a training set SâŠ†AkÃ—â„¤ğ‘†superscriptğ´ğ‘˜â„¤S\subseteq A^{k}\times\mathbb{Z}italic_S âŠ† italic_A start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT Ã— blackboard_Z, we want to find a pair p=(t,wÂ¯)ğ‘ğ‘¡Â¯ğ‘¤p=(t,\bar{w})italic_p = ( italic_t , overÂ¯ start_ARG italic_w end_ARG ) such that the classifier ht,wÂ¯ğ’œsubscriptsuperscriptâ„ğ’œğ‘¡Â¯ğ‘¤h^{\mathcal{A}}_{t,\bar{w}}italic_h start_POSTSUPERSCRIPT caligraphic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t , overÂ¯ start_ARG italic_w end_ARG end_POSTSUBSCRIPT is consistent with Sğ‘†Sitalic_S, i. e., it satisfies ht,wÂ¯ğ’œâ¢(aÂ¯)=isubscriptsuperscriptâ„ğ’œğ‘¡Â¯ğ‘¤Â¯ğ‘ğ‘–h^{\mathcal{A}}_{t,\bar{w}}(\bar{a})=iitalic_h start_POSTSUPERSCRIPT caligraphic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t , overÂ¯ start_ARG italic_w end_ARG end_POSTSUBSCRIPT ( overÂ¯ start_ARG italic_a end_ARG ) = italic_i for every (aÂ¯,i)âˆˆSÂ¯ğ‘ğ‘–ğ‘†(\bar{a},i)\in S( overÂ¯ start_ARG italic_a end_ARG , italic_i ) âˆˆ italic_S. Example 1.1. Let ğ’œğ’œ\mathcal{A}caligraphic_A be a relational database where the active domain Ağ´Aitalic_A contains authors and publications, the binary relation Author contains all pairs (a,p)ğ‘ğ‘(a,p)( italic_a , italic_p ) where ağ‘aitalic_a is an author of the publication pğ‘pitalic_p, and the binary relation Citation contains all pairs (p1,p2)subscriptğ‘1subscriptğ‘2(p_{1},p_{2})( italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) where the publication p1subscriptğ‘1p_{1}italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT cites the publication p2subscriptğ‘2p_{2}italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Suppose we are given a training set Sğ‘†Sitalic_S that consists of a few pairs (a,i)ğ‘ğ‘–(a,i)( italic_a , italic_i ) where ağ‘aitalic_a is an author and iğ‘–iitalic_i is the total number of citations of the publications of ağ‘aitalic_a. A reasonable classifier for this setting would be a mapping c:Aâ†’â„¤:ğ‘â†’ğ´â„¤c\colon A\to\mathbb{Z}italic_c : italic_A â†’ blackboard_Z that assigns to every author ağ‘aitalic_a present in the database the total number iğ‘–iitalic_i of citations of their publications. In our setting, this can be represented as follows. We let k=1ğ‘˜1k=1italic_k = 1 and â„“=0â„“0\ell=0roman_â„“ = 0. Since â„“=0â„“0\ell=0roman_â„“ = 0, the â€œparameterâ€ wğ‘¤witalic_w is fixed to be the empty tuple ()()( ). Since k=1ğ‘˜1k=1italic_k = 1, we use a counting term with a single free variable xğ‘¥xitalic_x (that will be assigned with authors present in the database). We choose the counting term t(x)â‰”#(z1,z2).(Author(x,z1)âˆ§Citation(z2,z1)).t(x)\ \coloneqq\ \ \#{(z_{1},z_{2})}.{\bigl{(}\texttt{Author}(x,z_{1})\land% \texttt{Citation}(z_{2},z_{1})\bigr{)}}.italic_t ( italic_x ) â‰” # ( italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) . ( Author ( italic_x , italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) âˆ§ Citation ( italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) ) . Evaluating tâ¢(x)ğ‘¡ğ‘¥t(x)italic_t ( italic_x ) for an author xğ‘¥xitalic_x yields the number of tuples (z1,z2)subscriptğ‘§1subscriptğ‘§2(z_{1},z_{2})( italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) such that xğ‘¥xitalic_x is an author of publication z1subscriptğ‘§1z_{1}italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, and z2subscriptğ‘§2z_{2}italic_z start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT is a publication that cites z1subscriptğ‘§1z_{1}italic_z start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. This is precisely the total number of citations of publications authored by xğ‘¥xitalic_x. Hence, ht,()ğ’œsubscriptsuperscriptâ„ğ’œğ‘¡h^{\mathcal{A}}_{t,()}italic_h start_POSTSUPERSCRIPT caligraphic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t , ( ) end_POSTSUBSCRIPT is the desired classifier cğ‘citalic_c. Example 1.2. Suppose we have a database that maintains a list of all cakes colleagues brought to work. We model this as a relational database ğ’œğ’œ\mathcal{A}caligraphic_A whose active domain Ağ´Aitalic_A contains persons, IDs of cakes, and types of cake. The binary relation Brought contains all pairs (p,c)ğ‘ğ‘(p,c)( italic_p , italic_c ) where pğ‘pitalic_p is a person that brought the cake with ID cğ‘citalic_c, and the binary relation Type contains all pairs (c,Ï„)ğ‘ğœ(c,\tau)( italic_c , italic_Ï„ ) where cğ‘citalic_c is the ID of a cake of type Ï„ğœ\tauitalic_Ï„ (e. g., â€œchocolate cakeâ€, â€œstrawberry cakeâ€, â€œcarrot cakeâ€, etc). Suppose we want to find a classifier that predicts the popularity of colleagues. For this, via a survey, we gather examples (p,i)âˆˆAÃ—â„¤ğ‘ğ‘–ğ´â„¤(p,i)\in A\times\mathbb{Z}( italic_p , italic_i ) âˆˆ italic_A Ã— blackboard_Z where pğ‘pitalic_p is a person and iğ‘–iitalic_i is the popularity of the person, and we call the resulting set of labelled examples Sğ‘†Sitalic_S. We choose k=â„“=1ğ‘˜â„“1k=\ell=1italic_k = roman_â„“ = 1, so we want to find a classifier that uses a single parameter. According to our own experience at work, it seems conceivable that the following classifier ht,wğ’œsubscriptsuperscriptâ„ğ’œğ‘¡ğ‘¤h^{\mathcal{A}}_{t,w}italic_h start_POSTSUPERSCRIPT caligraphic_A end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t , italic_w end_POSTSUBSCRIPT is consistent with Sğ‘†Sitalic_S: the parameter wğ‘¤witalic_w is â€œchocolate cakeâ€ and tğ‘¡titalic_t is the counting term t(x,y)â‰”#(z).(Brought(x,z)âˆ§Â¬Type(z,y))+ 2â‹…#(z).(Brought(x,z)âˆ§Type(z,y)).t(x,y)\ \coloneqq\ \ \#{(z)}.{\bigl{(}\texttt{Brought}(x,z)\land\neg\texttt{% Type}(z,y)\bigr{)}}\ \ +\ \ 2\cdot\#{(z)}.{\bigl{(}\texttt{Brought}(x,z)\land% \texttt{Type}(z,y)\bigr{)}}.italic_t ( italic_x , italic_y ) â‰” # ( italic_z ) . ( Brought ( italic_x , italic_z ) âˆ§ Â¬ Type ( italic_z , italic_y ) ) + 2 â‹… # ( italic_z ) . ( Brought ( italic_x , italic_z ) âˆ§ Type ( italic_z , italic_y ) ) . Note that tğ‘¡titalic_t counts the number of cakes brought by person xğ‘¥xitalic_x, where cakes of type yğ‘¦yitalic_y are counted twice, and the variable yğ‘¦yitalic_y will always be assigned the value of the parameter wğ‘¤witalic_w. In many application scenarios, the same database is used multiple times with different training sets to learn different classifiers. Thus, we consider a setting in which we are first only given the database, without any training examples. In a precomputation step, we allow gathering information that will be helpful for solving future learning tasks. This precomputation step can be viewed as building an index structure that is designed in order to support solving multiple learning tasks. In the actual learning phase, we are repeatedly given training sets of labelled examples, and our task is to output a hypothesis that is consistent with the corresponding training set. For this learning phase, it would be desirable to have algorithms that run efficiently even if the database is too large to fit into the main memory. To achieve this, we are interested in algorithms that require only local access to the database, i. e., instead of having random access to the database, a learning algorithm should initially start with the elements given in the training set; subsequently, it may only retrieve the neighbours of elements it already holds in memory. By utilising the memory hierarchy, such local access can be achieved efficiently even in cases where random access is too prohibitive. In the context of learning (concerning Boolean classification problems), this local-access model has been introduced by Grohe and Ritzert [34]. Our contribution Our main result is an algorithm that builds the index structure in time linear in the size and polynomial in the degree of the database. Afterwards, upon input of concrete training sets, classifiers definable in FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT can be learned in time polynomial in the degree of the database and polynomial in the number of examples given in the training set. Moreover, the classifiers returned by our algorithm can be evaluated in time polynomial in the degree of the database. Furthermore, our algorithms for finding a classifier and for evaluating this classifier do not require random access to the database but only rely on the local-access model. For databases of polylogarithmic degree (i. e., of degree up to (logâ¡n)csuperscriptğ‘›ğ‘(\log n)^{c}( roman_log italic_n ) start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT where cğ‘citalic_c is a constant and nğ‘›nitalic_n is the size of the database), our main result implies that the index structure can be built in quasi-linear time (i. e., time nâ‹…(logâ¡n)câ‹…ğ‘›superscriptğ‘›ğ‘n{\cdot}(\log n)^{c}italic_n â‹… ( roman_log italic_n ) start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT); afterwards, FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-definable integer-valued classifiers can be learned in time polylogarithmic (so, in particular, sublinear) in the size of the database and polynomial in the number of training examples. Previous results in the framework of Grohe and TurÃ¡n for Boolean classification problems relied on the fact that it suffices to check a constant number of queries while limiting the search space for the parameters to a neighbourhood of a certain radius [34, 7, 10]. For our setting of multiclass classification with aggregate queries, however, this does not hold any more. Hence, a priori, it is not clear that sublinear-time learning algorithms are possible for the multiclass case at all. The main technical challenge towards our learnability result was to find an approach that keeps the number of queries to check small (i. e., polynomial in the degree of the database), while still being able to limit the search space for the parameters to a small neighbourhood around the given training tuples. Organisation We provide the necessary definitions concerning FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT in Section 2, and we formally introduce the learning problem that we consider in Section 3. The precise statement of our main result is given in Theorem 3.1. Our proof makes heavy use of the locality properties of the logic FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT shown in [35], including a decomposition of FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-formulas into local formulas. These properties are used in Section 4 to provide our main technical tool for the proof of the main result. Section 5 concludes the paper with a summary and an outlook on future work. In the remainder of this introduction, we give an overview of related work. Related work The first-order logic with counting FOC was introduced in [43] and further studied in [35, 7]. This logic extends first-order logic (FO) by the ability to formulate counting terms that evaluate to integers, and by numerical predicates that allow to compare results of counting terms. It was shown in [43] that the model-checking problem for FOC is fixed-parameter tractable on classes of structures of bounded degree. From [35] it is known that the fixed-parameter tractability of FOC cannot be generalised to even very simple classes of structures of unbounded degree such as unranked trees (under a reasonable assumption in parameterised complexity). However, [35] identified a fragment called FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT for which model-checking of formulas and evaluation of counting terms are fixed-parameter tractable on all nowhere dense classes of structures. The present paper uses counting terms of FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT to represent integer-valued classifiers. The learning framework we consider has been introduced for Boolean classification problems in [36], which provides information-theoretic learnability results for classes of classifiers that can be specified using FO- and MSO-formulas on restricted classes of structures, such as the class of planar graphs or classes of graphs of bounded degree. Algorithmic aspects of the framework, including the running time of a learning algorithm, were first studied in [34]. The paper showed that Boolean classifiers definable in FO can be learned in sublinear time on structures of polylogarithmic degree. Analogous results have been obtained for MSO on strings [33] and on trees [30], which included a precomputation step to allow for efficient repeated learning. The paper [9] studied the parameterised complexity of the Boolean classification problem and showed that on arbitrary relational structures, learning hypotheses definable in FO is hard for the parameterised complexity class AWâ¢[âˆ—]AWdelimited-[]\textup{{AW}}[*]AW [ âˆ— ] (i. e., subject to a plausible complexity-theoretic assumption, it is not fixed-parameter tractable). The paper also showed that the problem is fixed-parameter tractable if the structures come from a nowhere dense class. For Boolean classifiers definable in the extension FOCN of FO with counting quantifiers and numerical predicates, [7] obtained a sublinear-time learning algorithm for structures of bounded degree, i. e., classes of structures where the degree is bounded by a constant. Recently, [8] lifted this result to structures of tiny degree, i. e., classes of structures of degree up to (logâ¡logâ¡n)csuperscriptğ‘›ğ‘(\log\log n)^{c}( roman_log roman_log italic_n ) start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT for some constant cğ‘citalic_c, where nğ‘›nitalic_n is the size of the structure. The paper [10] considered a notion of weighted structures, which extend ordinary relational structures by assigning weights, i. e. elements from particular rings or abelian groups, to tuples present in the structure. It introduced the expressive logic FOWA, which extends FO by means of aggregating weights and formulating both formulas (that evaluate to â€œtrueâ€ or â€œfalseâ€) and terms (that â€œaggregateâ€ weights and evaluate to values in the associated ring or abelian group). For the fragment FOWA1subscriptFOWA1\textup{{FOWA}}_{1}FOWA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT (that still extends FO), the paper showed that Boolean classifiers definable by FOWA1subscriptFOWA1\textup{{FOWA}}_{1}FOWA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-formulas over weighted background structures of polylogarithmic degree can be learned in sublinear time after quasi-linear-time preprocessing. This lifts the results obtained in [34] for FO to the substantially more expressive logic FOWA1subscriptFOWA1\textup{{FOWA}}_{1}FOWA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. As the logic FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT can be embedded in FOWA1subscriptFOWA1\textup{{FOWA}}_{1}FOWA start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, it follows from [10] that Boolean classifiers definable by FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT-formulas over background structures of polylogarithmic degree can be learned in sublinear time after quasi-linear-time preprocessing. The main result of the present paper can be viewed as a generalisation of this to integer-valued classification problems. The algorithmic results obtained so far within the framework introduced in [36] all focus on Boolean classification problems. However, many application scenarios require multiclass classification (cf. [22, 15, 37]). In the database systems literature, multiclass classifiers typically are described by aggregate queries [52, 53, 54, 55, 46]. In this paper, aggregate queries are represented by the counting terms of FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT. Closely related to the framework we consider is the framework of inductive logic programming (ILP) [47, 48, 40, 20, 21]. Both frameworks deal with a passive supervised learning setting, where the learning algorithms are given labelled examples. These examples are labelled according to some target concept, and the algorithms should return a hypothesis that approximately matches this target concept. One of the main differences between both frameworks is that we represent the background knowledge by a relational database, whereas in ILP, it is represented in a background theory, i. e., a set of formulas. Related logical learning frameworks have also been studied in formal verification [28, 44, 24, 57, 19]. In the database literature, various approaches to learning queries from examples have been studied, both in passive (such as ours) and active learning settings. In passive learning settings, results often focus on conjunctive queries [38, 39, 6, 41, 5, 56] or consider queries outside the relational database model [51, 12], while we focus on FOC1subscriptFOC1\textup{{FOC}}_{1}FOC start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, an extension of full first-order logic. In the active learning setting introduced by Angluin [4], learning algorithms are allowed to actively query an oracle. Results in this setting [2, 50, 1, 12, 13, 16] again consider various types of queries. Another related subject in the database literature is the problem of learning schema mappings from examples [14, 29, 3, 17, 18]."
https://arxiv.org/html/2411.03451v1,Redundancy Is All You Need,"The seminal work of BenczÃºr and Karger demonstrated cut sparsifiers of near-linear size, with several applications throughout theoretical computer science. Subsequent extensions have yielded sparsifiers for hypergraph cuts and more recently linear codes over Abelian groups. A decade ago, Kogan and Krauthgamer asked about the sparsifiability of arbitrary constraint satisfaction problems (CSPs). For this question, a trivial lower bound is the size of a non-redundant CSP instance, which admits, for each constraint, an assignment satisfying only that constraint (so that no constraint can be dropped by the sparsifier). For instance, for graph cuts, spanning trees are non-redundant instances.Our main result is that redundant clauses are sufficient for sparsification: for any CSP predicate Rğ‘…Ritalic_R, every unweighted instance of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) has a sparsifier of size at most its non-redundancy (up to polylog factors). For weighted instances, we similarly pin down the sparsifiability to the so-called chain length of the predicate. These results precisely determine the extent to which any CSP can be sparsified. A key technical ingredient in our work is a novel application of the entropy method from Gilmerâ€™s recent breakthrough on the union-closed sets conjecture.As an immediate consequence of our main theorem, a number of results in the non-redundancy literature immediately extend to CSP sparsification. We also contribute new techniques for understanding the non-redundancy of CSP predicates. In particular, we give an explicit family of predicates whose non-redundancy roughly corresponds to the structure of matching vector families in coding theory. By adapting methods from the matching vector codes literature, we are able to construct an explicit predicate whose non-redundancy lies between Î©â¢(n1.5)Î©superscriptğ‘›1.5\Omega(n^{1.5})roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) and O~â¢(n1.6)~ğ‘‚superscriptğ‘›1.6\widetilde{O}(n^{1.6})over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT ), the first example with a provably non-integral exponent.","The broad goal in sparsification is to replace an object by a more compact surrogate, typically a carefully chosen subsample, that preserves the behavior of the object under some metric of interest. For instance, for preserving cuts in undirected graphs, the influential works of Karger [Kar93] and BenczÃºr and Karger [BK96] showed that every graph has an edge-weighted subgraph with near-linear number of edges that preserves the value of all (edge) cuts up to a (1Â±Ïµ)plus-or-minus1italic-Ïµ(1\pm\epsilon)( 1 Â± italic_Ïµ ) multiplicative factor. These papers have had a substantial impact in shaping the last thirty years of work in areas such as spectral sparsifiers [ST11, BSS12, LS18], clustering [KVV04, SPR11], hypergraph sparsifiers [KK15, CKN20, KKTY21, KK23, KPS24c], linear solvers [ST04, Vis13, KMP14], convex optimization [LS14, AK16, Tod16], sketching/streaming algorithms [AG09, AGM12b, AGM12a, ACK+16, McG14, KLM+17, BHM+21], max-flow/min-cut algorithms [LR99, CKM+11, KLOS14, CKL+22], machine learning [LCY+21, CSZ22, ZSW+23, GBY+24], submodular functions [KK23, Sch24, Raf24, Qua24], differential privacy [BBDS12, AU19], PageRank [Chu14], and even theoretical physics [HKTH16, Van18, TN22], among many other works. Among the multiple exciting dimensions in which cut sparsification has been generalized, we now highlight two which form the backdrop for our work. Note that the graph cut problem can be modeled by the arity-two Boolean constraint x+y=1(mod2)ğ‘¥ğ‘¦annotated1pmod2x+y=1\pmod{2}italic_x + italic_y = 1 start_MODIFIER ( roman_mod start_ARG 2 end_ARG ) end_MODIFIER. One can thus generalize cut sparsification by allowing for arbitrary constraints (of any arity over some finite domain) as considered in the field of constraint satisfaction problems (CSPs), leading to CSP sparsification. This direction was proposed by Kogan and Krauthgamer [KK15] in their work on hypergraph cut sparsifiers, where the not-all-equal constraint captures hypergraph cut. As as special case, arbitrary binary CSPs (where each constraint has two variables) were studied in [FK17] for the Boolean domain and in [BÅ½20] for general domains, leading to a dichotomy: either near-linear sized sparsifiers exist, or no improvement over quadratic is possible. In another direction, one can instead look toward more general structures to sparsify. For instance, a recent line of work by Khanna, Putterman, and Sudan turned toward sparsifying linear codes [KPS24a], or more generally subgroups of powers of Abelian groups [KPS24b]. Beyond being algorithmically efficient [KPS24b], these structural results have led to exciting new results in CSP sparsification by constructing optimal sparsifiers when the constraints can be embedded into linear/Abelian equations. In this work, we obtain sparsifiers encompassing both these generalizations via a unified approach to sparsification of non-linear codes. The resulting sparsifiers for CSPs have optimal asymptotic size up to polylogarithmic factors, for every choice of predicate defining the CSP. In other words, we pinpoint the optimal extent to which an arbitrary CSP can be sparsified.111In this work we focus on the existence of sparsifiers, which is already highly non-trivial (e.g., [KPS24a, BÅ½20] are also non-algorithmic). Future directions (and barriers) for algorithmic aspects are briefly discussed in Sections 1.7 and 9. 1.1 Non-linear code sparsification We first state our result for codes as it is very general and crisply stated, and then turn to the consequences and further new results for CSPs. For a non-linear code CâŠ†{0,1}mğ¶superscript01ğ‘šC\subseteq\{0,1\}^{m}italic_C âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT, an Îµğœ€\varepsilonitalic_Îµ-sparsifier (for a parameter Îµâˆˆ(0,1)ğœ€01\varepsilon\in(0,1)italic_Îµ âˆˆ ( 0 , 1 )) is a weight function w:[m]â†’â„â‰¥0:ğ‘¤â†’delimited-[]ğ‘šsubscriptâ„absent0w:[m]\to\mathbb{R}_{\geq 0}italic_w : [ italic_m ] â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT such that for every codeword cğ‘citalic_c, adding up the weights of its nonzero positions, i.e., âˆ‘iwâ¢(i)â¢cisubscriptğ‘–ğ‘¤ğ‘–subscriptğ‘ğ‘–\sum_{i}w(i)c_{i}âˆ‘ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_w ( italic_i ) italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, is an accurate estimate of the Hamming weight of cğ‘citalic_c (i.e., âˆ‘icisubscriptğ‘–subscriptğ‘ğ‘–\sum_{i}c_{i}âˆ‘ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) to within a (1Â±Îµ)plus-or-minus1ğœ€(1\pm\varepsilon)( 1 Â± italic_Îµ ) multiplicative factor (Definition 2.8). The goal is to minimize the support of wğ‘¤witalic_w (i.e., the number of nonzero entries wâ¢(i)ğ‘¤ğ‘–w(i)italic_w ( italic_i )), and the minimum value is called Îµğœ€\varepsilonitalic_Îµ-sparsifiability of Cğ¶Citalic_C and is denoted SPRâ¡(C,Îµ)SPRğ¶ğœ€\operatorname{SPR}(C,\varepsilon)roman_SPR ( italic_C , italic_Îµ ). One of our main results is an upper bound on the sparsifiability in terms of a natural combinatorial parameter of the code called its non-redundancy NRDâ¡(C)NRDğ¶\operatorname{NRD}(C)roman_NRD ( italic_C ), defined as follows: NRDâ¡(C)NRDğ¶\operatorname{NRD}(C)roman_NRD ( italic_C ) is the size of the largest subset of indices IâŠ†[m]ğ¼delimited-[]ğ‘šI\subseteq[m]italic_I âŠ† [ italic_m ] such that for each iâˆˆIğ‘–ğ¼i\in Iitalic_i âˆˆ italic_I, there is a codeword câˆˆCğ‘ğ¶c\in Citalic_c âˆˆ italic_C with ci=1subscriptğ‘ğ‘–1c_{i}=1italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 and ciâ€²=0subscriptğ‘superscriptğ‘–â€²0c_{i^{\prime}}=0italic_c start_POSTSUBSCRIPT italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = 0 for iâ€²âˆˆIâˆ–{i}superscriptğ‘–â€²ğ¼ğ‘–i^{\prime}\in I\setminus\{i\}italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT âˆˆ italic_I âˆ– { italic_i }. In other words, if we imagine the code as a matrix whose rows are codewords, its non-redundancy is largest square submatrix which is a permutation matrix. Our result can then be stated compactly as follows. Theorem 1.1 (Main). For all CâŠ†{0,1}mğ¶superscript01ğ‘šC\subseteq\{0,1\}^{m}italic_C âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT and Îµâˆˆ(0,1)ğœ€01\varepsilon\in(0,1)italic_Îµ âˆˆ ( 0 , 1 ), SPRâ¡(C,Îµ)=Oâ¢(NRDâ¡(C)â¢(logâ¡m)6/Îµ2).SPRğ¶ğœ€ğ‘‚NRDğ¶superscriptğ‘š6superscriptğœ€2\operatorname{SPR}(C,\varepsilon)=O(\operatorname{NRD}(C)(\log m)^{6}/% \varepsilon^{2}).roman_SPR ( italic_C , italic_Îµ ) = italic_O ( roman_NRD ( italic_C ) ( roman_log italic_m ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT / italic_Îµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . To see how our theorem generalizes linear code sparsification [KPS24a, KPS24b], let ğ”½ğ”½\mathbb{F}blackboard_F be a (finite) field and let VâŠ†ğ”½mğ‘‰superscriptğ”½ğ‘šV\subseteq\mathbb{F}^{m}italic_V âŠ† blackboard_F start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT be a subspace. Let C:={(ğŸâ¢[v1=0],â€¦,ğŸâ¢[vm=0]):vâˆˆV}assignğ¶conditional-set1delimited-[]subscriptğ‘£10â€¦1delimited-[]subscriptğ‘£ğ‘š0ğ‘£ğ‘‰C:=\{({\bf 1}[v_{1}=0],\ldots,{\bf 1}[v_{m}=0]):v\in V\}italic_C := { ( bold_1 [ italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0 ] , â€¦ , bold_1 [ italic_v start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = 0 ] ) : italic_v âˆˆ italic_V } be the zero/non-zero pattern of Vğ‘‰Vitalic_V. Then, any Îµğœ€\varepsilonitalic_Îµ-sparsifier of Cğ¶Citalic_C is an Îµğœ€\varepsilonitalic_Îµ-sparsifier of Vğ‘‰Vitalic_V and NRDâ¡(C)=dimVNRDğ¶dimensionğ‘‰\operatorname{NRD}(C)=\dim Vroman_NRD ( italic_C ) = roman_dim italic_V. In fact, for any finite group GğºGitalic_G and subgroup Hâ‰¤Gmğ»superscriptğºğ‘šH\leq G^{m}italic_H â‰¤ italic_G start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT, we can show for the corresponding Cğ¶Citalic_C that NRDâ¡(C)â‰¤log2â¡|H|NRDğ¶subscript2ğ»\operatorname{NRD}(C)\leq\log_{2}|H|roman_NRD ( italic_C ) â‰¤ roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_H | (see Theorem 5.1), matching [KPS24b]â€™s result for Abelian groups (modulo their efficiency). If we view CâŠ†{0,1}mğ¶superscript01ğ‘šC\subseteq\{0,1\}^{m}italic_C âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT as a set family over the universe [m]delimited-[]ğ‘š[m][ italic_m ], the above result in effect says that the non-redundancy NRDâ¡(C)NRDğ¶\operatorname{NRD}(C)roman_NRD ( italic_C ) plays the role of the VC dimension of Cğ¶Citalic_C when the goal is to estimate the size of the set câˆˆCğ‘ğ¶c\in Citalic_c âˆˆ italic_C rather than learn cğ‘citalic_c itself. In fact, it turns out that NRDâ¡(C)NRDğ¶\operatorname{NRD}(C)roman_NRD ( italic_C ) is precisely the VC dimension of the union-closure of Cğ¶Citalic_C. This connection to union-closed families plays a crucial role in the proof of Theorem 1.1. See the technical overview (Section 1.6) for more details, including discussion of a significantly simpler O~Îµâ¢(NRDâ¡(C)â¢logâ¡|C|)subscript~ğ‘‚ğœ€NRDğ¶ğ¶\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C)\log|C|)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) roman_log | italic_C | )-sized sparsifier. 1.2 CSP sparsification We now turn to (unweighted222The weighted case is discussed in Section 1.4.) CSP sparsification. For a relation RâŠ†Drğ‘…superscriptğ·ğ‘ŸR\subseteq D^{r}italic_R âŠ† italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT of arity rğ‘Ÿritalic_r over a finite domain Dğ·Ditalic_D, an instance Î¨Î¨\Psiroman_Î¨ of the CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) problem consists a variable set Xğ‘‹Xitalic_X and a constraint set YâŠ†Xrğ‘Œsuperscriptğ‘‹ğ‘ŸY\subseteq X^{r}italic_Y âŠ† italic_X start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT. An assignment Ïƒ:Xâ†’D:ğœâ†’ğ‘‹ğ·\sigma:X\to Ditalic_Ïƒ : italic_X â†’ italic_D satisfies a constraint y=(x1,x2,â€¦,xr)âˆˆYğ‘¦subscriptğ‘¥1subscriptğ‘¥2â€¦subscriptğ‘¥ğ‘Ÿğ‘Œy=(x_{1},x_{2},\dots,x_{r})\in Yitalic_y = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) âˆˆ italic_Y if (Ïƒâ¢(x1),Ïƒâ¢(x2),â€¦,Ïƒâ¢(xr))âˆˆRğœsubscriptğ‘¥1ğœsubscriptğ‘¥2â€¦ğœsubscriptğ‘¥ğ‘Ÿğ‘…(\sigma(x_{1}),\sigma(x_{2}),\dots,\sigma(x_{r}))\in R( italic_Ïƒ ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , italic_Ïƒ ( italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , â€¦ , italic_Ïƒ ( italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ) ) âˆˆ italic_R. The value valâ¡(Î¨,Ïƒ)valÎ¨ğœ\operatorname{val}(\Psi,\sigma)roman_val ( roman_Î¨ , italic_Ïƒ ) of an assignment Ïƒğœ\sigmaitalic_Ïƒ is the number of constraints yâˆˆYğ‘¦ğ‘Œy\in Yitalic_y âˆˆ italic_Y that it satisfies. Similarly, for a weight function w:Yâ†’â„â‰¥0:ğ‘¤â†’ğ‘Œsubscriptâ„absent0w:Y\to\mathbb{R}_{\geq 0}italic_w : italic_Y â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT, the weighted value valâ¡(Î¨,w,Ïƒ)valÎ¨ğ‘¤ğœ\operatorname{val}(\Psi,w,\sigma)roman_val ( roman_Î¨ , italic_w , italic_Ïƒ ) is the sum of weights wâ¢(y)ğ‘¤ğ‘¦w(y)italic_w ( italic_y ) of all constraints yâˆˆYğ‘¦ğ‘Œy\in Yitalic_y âˆˆ italic_Y that Ïƒğœ\sigmaitalic_Ïƒ satisfies. The goal in CSP sparsification is to output a weight function w:Yâ†’â„â‰¥0:ğ‘¤â†’ğ‘Œsubscriptâ„absent0w:Y\to\mathbb{R}_{\geq 0}italic_w : italic_Y â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT of small support, such that for every assignment Ïƒ:Xâ†’D:ğœâ†’ğ‘‹ğ·\sigma:X\to Ditalic_Ïƒ : italic_X â†’ italic_D, (1âˆ’Îµ)â¢valâ¡(Î¨,Ïƒ)â‰¤valâ¡(Î¨,w,Ïƒ)â‰¤(1+Îµ)â¢valâ¡(Î¨,Ïƒ),1ğœ€valÎ¨ğœvalÎ¨ğ‘¤ğœ1ğœ€valÎ¨ğœ(1-\varepsilon)\operatorname{val}(\Psi,\sigma)\leq\operatorname{val}(\Psi,w,% \sigma)\leq(1+\varepsilon)\operatorname{val}(\Psi,\sigma)\ ,( 1 - italic_Îµ ) roman_val ( roman_Î¨ , italic_Ïƒ ) â‰¤ roman_val ( roman_Î¨ , italic_w , italic_Ïƒ ) â‰¤ ( 1 + italic_Îµ ) roman_val ( roman_Î¨ , italic_Ïƒ ) , and minimum such support size is denoted SPRâ¡(Î¨,Îµ)SPRÎ¨ğœ€\operatorname{SPR}(\Psi,\varepsilon)roman_SPR ( roman_Î¨ , italic_Îµ ). The Îµğœ€\varepsilonitalic_Îµ-sparsifiability of the relation RâŠ†Drğ‘…superscriptğ·ğ‘ŸR\subseteq D^{r}italic_R âŠ† italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT, as a function of number of variables, is defined to the maximum (i.e., worst-case) value of SPRâ¡(Î¨,Îµ)SPRÎ¨ğœ€\operatorname{SPR}(\Psi,\varepsilon)roman_SPR ( roman_Î¨ , italic_Îµ ) over all nğ‘›nitalic_n-variables instances Î¨Î¨\Psiroman_Î¨ of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ). We denote it by SPRâ¡(R,n,Îµ)SPRğ‘…ğ‘›ğœ€\operatorname{SPR}(R,n,\varepsilon)roman_SPR ( italic_R , italic_n , italic_Îµ ) and it is the chief object of our study. Note that this is for the unweighted case, see Section 1.4 how this result can be (tightly) applied to the weighted case. Let us note an obvious obstruction to sparsification. Suppose we have an instance Î¨=(X,Y)Î¨ğ‘‹ğ‘Œ\Psi=(X,Y)roman_Î¨ = ( italic_X , italic_Y ) of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) such that for each of its constraints yâˆˆYğ‘¦ğ‘Œy\in Yitalic_y âˆˆ italic_Y, there is an assignment Ïƒy:Xâ†’D:subscriptğœğ‘¦â†’ğ‘‹ğ·\sigma_{y}:X\to Ditalic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT : italic_X â†’ italic_D that satisfies only yğ‘¦yitalic_y and no other constraint. Then clearly Î¨Î¨\Psiroman_Î¨ cannot be sparsified at allâ€”dropping any constraint yğ‘¦yitalic_y would make the value of Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT drop from 1111 to 00. We call such an instance a non-redundant instance of CSPâ¡(RÂ¯)CSPÂ¯ğ‘…\operatorname{CSP}(\overline{R})roman_CSP ( overÂ¯ start_ARG italic_R end_ARG ), where RÂ¯=Drâˆ–RÂ¯ğ‘…superscriptğ·ğ‘Ÿğ‘…\overline{R}=D^{r}\setminus RoverÂ¯ start_ARG italic_R end_ARG = italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT âˆ– italic_R (cf., [BCH+13, BCK20]).333We use RÂ¯Â¯ğ‘…\overline{R}overÂ¯ start_ARG italic_R end_ARG rather than Rğ‘…Ritalic_R due to the conventions of each community. See Remark 2.6 for deeper technical reasons. As introduced by Bessiere, Carbonnel, and Katsirelos [BCK20], we denote the size of the largest such non-redundant instance of CSPâ¡(RÂ¯)CSPÂ¯ğ‘…\operatorname{CSP}(\overline{R})roman_CSP ( overÂ¯ start_ARG italic_R end_ARG ) on nğ‘›nitalic_n-variables by NRDâ¡(RÂ¯,n)NRDÂ¯ğ‘…ğ‘›\operatorname{NRD}(\overline{R},n)roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) and call it the non-redundancy of RÂ¯Â¯ğ‘…\overline{R}overÂ¯ start_ARG italic_R end_ARG. Thus a trivial lower bound on sparsifiability of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ), regardless of the choice of Îµâˆˆ(0,1)ğœ€01\varepsilon\in(0,1)italic_Îµ âˆˆ ( 0 , 1 ), is given by SPRâ¡(R,n,Îµ)â‰¥NRDâ¡(RÂ¯,n),SPRğ‘…ğ‘›ğœ€NRDÂ¯ğ‘…ğ‘›\displaystyle\operatorname{SPR}(R,n,\varepsilon)\geq\operatorname{NRD}(% \overline{R},n)\ ,roman_SPR ( italic_R , italic_n , italic_Îµ ) â‰¥ roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) , (1) and this holds even if the goal is merely to preserve which assignments have nonzero value. Rather remarkably, this simplistic lower bound can be met and one can sparsify all the way down to NRDâ¡(RÂ¯,n)NRDÂ¯ğ‘…ğ‘›\operatorname{NRD}(\overline{R},n)roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) times polylogarithmic factors! In fact, this turns out to be an easy corollary of Theorem 1.1. One can associate a canonical code CÎ¨âŠ†{0,1}Ysubscriptğ¶Î¨superscript01ğ‘ŒC_{\Psi}\subseteq\{0,1\}^{Y}italic_C start_POSTSUBSCRIPT roman_Î¨ end_POSTSUBSCRIPT âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_Y end_POSTSUPERSCRIPT with any CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) instance Î¨=(X,Y)Î¨ğ‘‹ğ‘Œ\Psi=(X,Y)roman_Î¨ = ( italic_X , italic_Y ) whose codewords cÏƒsubscriptğ‘ğœc_{\sigma}italic_c start_POSTSUBSCRIPT italic_Ïƒ end_POSTSUBSCRIPT correspond to the assignments Ïƒ:Xâ†’D:ğœâ†’ğ‘‹ğ·\sigma:X\to Ditalic_Ïƒ : italic_X â†’ italic_D, and cÏƒ,ysubscriptğ‘ğœğ‘¦c_{\sigma,y}italic_c start_POSTSUBSCRIPT italic_Ïƒ , italic_y end_POSTSUBSCRIPT is 1111 precisely when Ïƒğœ\sigmaitalic_Ïƒ satisfies yğ‘¦yitalic_y. It is easy to check that CSP sparsification of Î¨Î¨\Psiroman_Î¨ reduces to code sparsification of CÎ¨subscriptğ¶Î¨C_{\Psi}italic_C start_POSTSUBSCRIPT roman_Î¨ end_POSTSUBSCRIPT, and the non-redundancy of Cğ¶Citalic_C equals the size of the largest non-redundant sub-instance of Î¨Î¨\Psiroman_Î¨ (viewed as an instance of CSPâ¡(RÂ¯)CSPÂ¯ğ‘…\operatorname{CSP}(\overline{R})roman_CSP ( overÂ¯ start_ARG italic_R end_ARG )). Combining Theorem 1.1 and (1), we therefore have our main result pinning down the sparsifiability of every CSP up to polylogarithmic factors. Theorem 1.2. For every nonempty RâŠŠDrğ‘…superscriptğ·ğ‘ŸR\subsetneq D^{r}italic_R âŠŠ italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT and Îµâˆˆ(0,1)ğœ€01\varepsilon\in(0,1)italic_Îµ âˆˆ ( 0 , 1 ), we have that NRDâ¡(RÂ¯,n)â‰¤SPRâ¡(R,n,Îµ)â‰¤Oâ¢(NRDâ¡(RÂ¯,n)â¢(râ¢logâ¡n)6/Îµ2).NRDÂ¯ğ‘…ğ‘›SPRğ‘…ğ‘›ğœ€ğ‘‚NRDÂ¯ğ‘…ğ‘›superscriptğ‘Ÿğ‘›6superscriptğœ€2\operatorname{NRD}(\overline{R},n)\leq\operatorname{SPR}(R,n,\varepsilon)\leq O% (\operatorname{NRD}(\overline{R},n)(r\log n)^{6}/\varepsilon^{2}).roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) â‰¤ roman_SPR ( italic_R , italic_n , italic_Îµ ) â‰¤ italic_O ( roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) ( italic_r roman_log italic_n ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT / italic_Îµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . 1.3 Non-redundancy of specific relations The non-redundancy of relations is readily computed in some simple cases. For example, for the relation ORr:=Drâˆ–{0r}assignsubscriptORğ‘Ÿsuperscriptğ·ğ‘Ÿsuperscript0ğ‘Ÿ\operatorname{OR}_{r}:=D^{r}\setminus\{0^{r}\}roman_OR start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT := italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT âˆ– { 0 start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT }, we have that NRDâ¡(ORr,n)=Î˜â¢(nr)NRDsubscriptORğ‘Ÿğ‘›Î˜superscriptğ‘›ğ‘Ÿ\operatorname{NRD}(\operatorname{OR}_{r},n)=\Theta(n^{r})roman_NRD ( roman_OR start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT , italic_n ) = roman_Î˜ ( italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ). Indeed Y=(Xr)ğ‘Œbinomialğ‘‹ğ‘ŸY=\binom{X}{r}italic_Y = ( FRACOP start_ARG italic_X end_ARG start_ARG italic_r end_ARG ) is a non-redundant instance because setting all but rğ‘Ÿritalic_r variables to 1111 fails to satisfy exactly that rğ‘Ÿritalic_r-tuple (see [FK17, Car22, KPS24b]). When Rğ‘…Ritalic_R is affine, NRDâ¡(R,n)=Î˜â¢(n)NRDğ‘…ğ‘›Î˜ğ‘›\operatorname{NRD}(R,n)=\Theta(n)roman_NRD ( italic_R , italic_n ) = roman_Î˜ ( italic_n ), and when Rğ‘…Ritalic_R is defined as the zero set of a degree kğ‘˜kitalic_k polynomial, NRDâ¡(R,n)=Oâ¢(nk)NRDğ‘…ğ‘›ğ‘‚superscriptğ‘›ğ‘˜\operatorname{NRD}(R,n)=O(n^{k})roman_NRD ( italic_R , italic_n ) = italic_O ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ); these follow from simple rank arguments (e.g., [LW20]). Via Theorem 1.2, these special cases (plus simple gadget reductions) already capture all the previously known upper and lower bounds for CSP sparsification (see Section 1.5 for more details on the CSP sparsification literature). Furthermore, there are also some non-trivial upper bounds known on NRD in the literature, which we can now import to sparsifiability for free courtesy Theorem 1.2. For instance, the so-called Malâ€™tsev relations, which generalize affine predicates (i.e., cosets) over Abelian groups, have been shown to have ODâ¢(n)subscriptğ‘‚ğ·ğ‘›O_{D}(n)italic_O start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_n ) non-redundancy [LW20, BCK20], and therefore by Theorem 1.2 their complements have near-linear sparsifiability. Carbonnel [Car22] showed that if Rğ‘…Ritalic_R is an arity rğ‘Ÿritalic_r relation that doesnâ€™t contain444See Theorem 5.2 for a precise definition. any copy of ORrsubscriptORğ‘Ÿ\operatorname{OR}_{r}roman_OR start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT, then NRDâ¡(R,n)â‰¤Oâ¢(nrâˆ’Î´r)NRDğ‘…ğ‘›ğ‘‚superscriptğ‘›ğ‘Ÿsubscriptğ›¿ğ‘Ÿ\operatorname{NRD}(R,n)\leq O(n^{r-\delta_{r}})roman_NRD ( italic_R , italic_n ) â‰¤ italic_O ( italic_n start_POSTSUPERSCRIPT italic_r - italic_Î´ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) for Î´r=21âˆ’rsubscriptğ›¿ğ‘Ÿsuperscript21ğ‘Ÿ\delta_{r}=2^{1-r}italic_Î´ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = 2 start_POSTSUPERSCRIPT 1 - italic_r end_POSTSUPERSCRIPT (the specific bound arises from a classic hypergraph TurÃ¡n result [Erd64]). By Theorem 1.2 this immediately implies SPRâ¡(RÂ¯,n,Îµ)â‰¤O~Îµâ¢(nrâˆ’Î´r)SPRÂ¯ğ‘…ğ‘›ğœ€subscript~ğ‘‚ğœ€superscriptğ‘›ğ‘Ÿsubscriptğ›¿ğ‘Ÿ\operatorname{SPR}(\overline{R},n,\varepsilon)\leq\widetilde{O}_{\varepsilon}(% n^{r-\delta_{r}})roman_SPR ( overÂ¯ start_ARG italic_R end_ARG , italic_n , italic_Îµ ) â‰¤ over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT italic_r - italic_Î´ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ), where O~â¢(â‹…)~ğ‘‚â‹…\widetilde{O}(\cdot)over~ start_ARG italic_O end_ARG ( â‹… ) hides polylogarithmic factors in nğ‘›nitalic_n, yielding an Î©â¢(nr)Î©superscriptğ‘›ğ‘Ÿ\Omega(n^{r})roman_Î© ( italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ) vs O~â¢(nrâˆ’Î´r)~ğ‘‚superscriptğ‘›ğ‘Ÿsubscriptğ›¿ğ‘Ÿ\widetilde{O}(n^{r-\delta_{r}})over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT italic_r - italic_Î´ start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) dichotomy for sparsification of arity rğ‘Ÿritalic_r CSPs. (This was known for the Boolean case [KPS24b]; see the related work subsection.) The non-redundancy of a relation can in general be difficult to estimate. Thus while in principle Theorem 1.2 pins down the sparisifiability of every CSP, for specific relations, it can still be non-trivial to actually determine the asymptotic behavior of its sparsifiability. Our next set of results makes progress in this direction via novel methods to bound non-redundancy. Given that the non-redundancy of linear predicates is easy to pin down, we consider a natural family of relations which are very close to being linear. Specifically, let 3â¢Lâ¢Iâ¢NG={(x,y,z)âˆ£x+y+z=0}subscript3LINğºconditional-setğ‘¥ğ‘¦ğ‘§ğ‘¥ğ‘¦ğ‘§0\operatorname{3LIN}_{G}=\{(x,y,z)\mid x+y+z=0\}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = { ( italic_x , italic_y , italic_z ) âˆ£ italic_x + italic_y + italic_z = 0 } over an Abelian group GğºGitalic_G, and consider 3â¢Lâ¢Iâ¢NGâˆ—=3â¢Lâ¢Iâ¢NGâˆ–{(0,0,0)}subscriptsuperscript3LINğºsubscript3LINğº000\operatorname{3LIN}^{*}_{G}=\operatorname{3LIN}_{G}\setminus\{(0,0,0)\}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT âˆ– { ( 0 , 0 , 0 ) }. (We pick arity 3333 since the arity 2222 case is already fully resolved [FK17, BÅ½20].) Being defined by a linear equation over an Abelian group, we already know that NRDâ¡(3â¢Lâ¢Iâ¢NG,n)=Î˜Gâ¢(n)NRDsubscript3LINğºğ‘›subscriptÎ˜ğºğ‘›\operatorname{NRD}(\operatorname{3LIN}_{G},n)=\Theta_{G}(n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ) = roman_Î˜ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_n ). However the non-redundancy of 3â¢Lâ¢Iâ¢NGâˆ—subscriptsuperscript3LINğº\operatorname{3LIN}^{*}_{G}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT seems challenging to understand. Existing methods in the literature only yield NRDâ¡(3â¢Lâ¢Iâ¢NGâˆ—,n)âˆˆ[Î©Gâ¢(n),OGâ¢(n2)]NRDsubscriptsuperscript3LINğºğ‘›subscriptÎ©ğºğ‘›subscriptğ‘‚ğºsuperscriptğ‘›2\operatorname{NRD}(\operatorname{3LIN}^{*}_{G},n)\in[\Omega_{G}(n),O_{G}(n^{2})]roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ) âˆˆ [ roman_Î© start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_n ) , italic_O start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ]. We introduce a new method for bounding the non-redundancy of predicates like 3â¢Lâ¢Iâ¢NGâˆ—subscriptsuperscript3LINğº\operatorname{3LIN}^{*}_{G}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT by connecting them to the theory of matching vector (MV) families [Yek08, DGY11] that have been used in the construction of locally decodable codes. Exploiting this connection, we construct a non-redundant instance to establish that NRDâ¡(3â¢Lâ¢Iâ¢NG,n)â‰¥Î©â¢(n1.5)NRDsubscript3LINğºğ‘›Î©superscriptğ‘›1.5\operatorname{NRD}(\operatorname{3LIN}_{G},n)\geq\Omega(n^{1.5})roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ) â‰¥ roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) for all Abelian groups of order â‰¥3absent3\geq 3â‰¥ 3. Adapting ideas from the analysis of MV families together with some combinatorial ideas, we also prove an upper bound NRDâ¡(3â¢Lâ¢Iâ¢Nâ„¤/pâ¢â„¤,n)=O~pâ¢(n2âˆ’Îµp)NRDsubscript3LINâ„¤ğ‘â„¤ğ‘›subscript~ğ‘‚ğ‘superscriptğ‘›2subscriptğœ€ğ‘\operatorname{NRD}(\operatorname{3LIN}_{\mathbb{Z}/p\mathbb{Z}},n)=\widetilde{% O}_{p}(n^{2-\varepsilon_{p}})roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT blackboard_Z / italic_p blackboard_Z end_POSTSUBSCRIPT , italic_n ) = over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT 2 - italic_Îµ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ) for Îµp=22â¢pâˆ’1subscriptğœ€ğ‘22ğ‘1\varepsilon_{p}=\tfrac{2}{2p-1}italic_Îµ start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT = divide start_ARG 2 end_ARG start_ARG 2 italic_p - 1 end_ARG and pğ‘pitalic_p prime. Specializing for p=3ğ‘3p=3italic_p = 3, we have the following result, which also gives the first examples of relations whose non-redundancy and sparsifiability have a non-integral exponent. Theorem 1.3. We have NRDâ¡(3â¢Lâ¢Iâ¢Nâ„¤/3â¢â„¤âˆ—,n)NRDsubscriptsuperscript3LINâ„¤3â„¤ğ‘›\displaystyle\operatorname{NRD}(\operatorname{3LIN}^{*}_{\mathbb{Z}/3\mathbb{Z% }},n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT blackboard_Z / 3 blackboard_Z end_POSTSUBSCRIPT , italic_n ) âˆˆ[Î©â¢(n1.5),O~â¢(n1.6)], andabsentÎ©superscriptğ‘›1.5~ğ‘‚superscriptğ‘›1.6 and\displaystyle\in[\Omega(n^{1.5}),\widetilde{O}(n^{1.6})],\ \ \ \text{ and }âˆˆ [ roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) , over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT ) ] , and SPRâ¡(3â¢Lâ¢Iâ¢Nâ„¤/3â¢â„¤âˆ—Â¯,n,Îµ)SPRÂ¯subscriptsuperscript3LINâ„¤3â„¤ğ‘›ğœ€\displaystyle\operatorname{SPR}(\overline{\operatorname{3LIN}^{*}_{\mathbb{Z}/% 3\mathbb{Z}}},n,\varepsilon)roman_SPR ( overÂ¯ start_ARG start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT blackboard_Z / 3 blackboard_Z end_POSTSUBSCRIPT end_ARG , italic_n , italic_Îµ ) âˆˆ[Î©â¢(n1.5),O~â¢(n1.6/Îµ2)].absentÎ©superscriptğ‘›1.5~ğ‘‚superscriptğ‘›1.6superscriptğœ€2\displaystyle\in[\Omega(n^{1.5}),\widetilde{O}(n^{1.6}/\varepsilon^{2})].âˆˆ [ roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) , over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT / italic_Îµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) ] . 1.4 Weighted CSP sparsification The discussion so far has focused on unweighted CSP instances, and we now shift our focus to the weighted case, where each constraint of Yğ‘ŒYitalic_Y comes with a weight. We also get a tight characterization of weighted CSP sparsifiablity, in terms of a parameter called the chain length, which was defined by Lagerkvist and WahlstrÃ¶m [LW17, LW20] in the context of CSP kernelization and later utilized by Bessiere, Carbonnel, and Katsirelos [BCK20] in the context of learning CSPs in a certain query model (see Section 1.5 for more details on these connections). As before, the result is obtained in the setting of weighted non-linear codes, with the consequence for weighted CSPs being an easy corollary. We just state the result for codes here (see Section 8 for the full treatment of weighted CSPs). For weighted sparsification of a code CâŠ†{0,1}mğ¶superscript01ğ‘šC\subseteq\{0,1\}^{m}italic_C âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT, we might have an arbitrary input weighting Î¶:[m]â†’â„â‰¥0:ğœâ†’delimited-[]ğ‘šsubscriptâ„absent0\zeta:[m]\to\mathbb{R}_{\geq 0}italic_Î¶ : [ italic_m ] â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT of its coordinates, and we must find a sparsifier w~:[n]â†’â„â‰¥0:~ğ‘¤â†’delimited-[]ğ‘›subscriptâ„absent0\widetilde{w}:[n]\to\mathbb{R}_{\geq 0}over~ start_ARG italic_w end_ARG : [ italic_n ] â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT of low support that sparsifies Cğ¶Citalic_C with respect to the weighting Î¶ğœ\zetaitalic_Î¶, i.e., âŸ¨w~,câŸ©âˆˆ(1Â±Îµ)â¢âŸ¨Î¶,câŸ©~ğ‘¤ğ‘plus-or-minus1ğœ€ğœğ‘\langle\widetilde{w},c\rangle\in(1\pm\varepsilon)\langle\zeta,c\rangleâŸ¨ over~ start_ARG italic_w end_ARG , italic_c âŸ© âˆˆ ( 1 Â± italic_Îµ ) âŸ¨ italic_Î¶ , italic_c âŸ©. The minimum possible support of sparsifiers over all weightings Î¶ğœ\zetaitalic_Î¶ is called the weighted Îµğœ€\varepsilonitalic_Îµ-sparsity wSPRâ¡(C,Îµ)wSPRğ¶ğœ€\operatorname{wSPR}(C,\varepsilon)roman_wSPR ( italic_C , italic_Îµ ). Now we define chain length. If we line up the codewords of Cğ¶Citalic_C as rows of an |C|Ã—mğ¶ğ‘š|C|\times m| italic_C | Ã— italic_m matrix and allow arbitrary column permutations, the chain length of Cğ¶Citalic_C, denoted CLâ¡(C)CLğ¶\operatorname{CL}(C)roman_CL ( italic_C ), is the dimension of the largest upper triangular square submatrix with 1111â€™s on the diagonal.555In this view NRDâ¡(C)NRDğ¶\operatorname{NRD}(C)roman_NRD ( italic_C ) is the dimension of the largest identity submatrix, so clearly NRDâ¡(C)â‰¤CLâ¡(C)NRDğ¶CLğ¶\operatorname{NRD}(C)\leq\operatorname{CL}(C)roman_NRD ( italic_C ) â‰¤ roman_CL ( italic_C ). The quantity CLâ¡(C)CLğ¶\operatorname{CL}(C)roman_CL ( italic_C ) was called visible rank in [AG21] and served as a field independent lower bound on the rank of Cğ¶Citalic_C. In our main result for the weighted setting, we pin the sparsifiability of a weighted code to its chain length. Note that in the weighted case CLâ¡(C)CLğ¶\operatorname{CL}(C)roman_CL ( italic_C ) is also a lower bound. Theorem 1.4. For all CâŠ†{0,1}mğ¶superscript01ğ‘šC\subseteq\{0,1\}^{m}italic_C âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT and Îµâˆˆ(0,1)ğœ€01\varepsilon\in(0,1)italic_Îµ âˆˆ ( 0 , 1 ), we have CLâ¡(C)â‰¤wSPRâ¡(C,Îµ)=Oâ¢(CLâ¡(C)â¢(logâ¡m)6/Îµ2).CLğ¶wSPRğ¶ğœ€ğ‘‚CLğ¶superscriptğ‘š6superscriptğœ€2\operatorname{CL}(C)\leq\operatorname{wSPR}(C,\varepsilon)=O(\operatorname{CL}% (C)(\log m)^{6}/\varepsilon^{2}).roman_CL ( italic_C ) â‰¤ roman_wSPR ( italic_C , italic_Îµ ) = italic_O ( roman_CL ( italic_C ) ( roman_log italic_m ) start_POSTSUPERSCRIPT 6 end_POSTSUPERSCRIPT / italic_Îµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) . The upper bound proceeds by using Theorem 1.1 as a black-box together with a geometric weight bucketing technique from [KPS24b]. The lower bound proceeds by applying an exponential sequence of weights to the indices i1,â€¦,iCLâ¡(C)âˆˆ[m]subscriptğ‘–1â€¦subscriptğ‘–CLğ¶delimited-[]ğ‘ši_{1},\ldots,i_{\operatorname{CL}{(C)}}\in[m]italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_i start_POSTSUBSCRIPT roman_CL ( italic_C ) end_POSTSUBSCRIPT âˆˆ [ italic_m ] forming a maximal chain. Of note, if for a particular set of weights, the ratio between maximum and minimal weights is Î»â‰ªexpâ¡(CLâ¡(C)/NRDâ¡(C))much-less-thanğœ†CLğ¶NRDğ¶\lambda\ll\exp(\operatorname{CL}(C)/\operatorname{NRD}(C))italic_Î» â‰ª roman_exp ( roman_CL ( italic_C ) / roman_NRD ( italic_C ) ), we get a sharper upper bound of O~Îµâ¢(NRDâ¡(C)â¢logâ¡Î»)subscript~ğ‘‚ğœ€NRDğ¶ğœ†\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C)\log\lambda)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) roman_log italic_Î» ) (see Corollary 8.18). We now transition to discussing the broader context of our work in the literature. 1.5 Related Work Our results and techniques have connections to many areas including computational complexity theory, extremal combinatorics, coding theory, and learning theory. We now give a general overview of these connections. CSP Sparsification. Since we already discussed the history of CSP sparsification, we give a comprehensive list of known results about CSP sparsification (up to polylog factors). â€¢ The case of binary CSPs (r=2ğ‘Ÿ2r=2italic_r = 2) is fully classified. In particular, for every finite domain Dğ·Ditalic_D and RâŠ†D2ğ‘…superscriptğ·2R\subseteq D^{2}italic_R âŠ† italic_D start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT, we either have that SPRâ¡(R,n,Îµ)=Oâ¢(n/Îµ2)SPRğ‘…ğ‘›ğœ€ğ‘‚ğ‘›superscriptğœ€2\operatorname{SPR}(R,n,\varepsilon)=O(n/\varepsilon^{2})roman_SPR ( italic_R , italic_n , italic_Îµ ) = italic_O ( italic_n / italic_Îµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) or SPRâ¡(R,n,Îµ)=Î©â¢(n2)SPRğ‘…ğ‘›ğœ€Î©superscriptğ‘›2\operatorname{SPR}(R,n,\varepsilon)=\Omega(n^{2})roman_SPR ( italic_R , italic_n , italic_Îµ ) = roman_Î© ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) [BÅ½20]. However, the sparsification routine is only efficient in the Boolean case [FK17]. Of note, SPRâ¡(R,n,Îµ)=Î©â¢(n2)SPRğ‘…ğ‘›ğœ€Î©superscriptğ‘›2\operatorname{SPR}(R,n,\varepsilon)=\Omega(n^{2})roman_SPR ( italic_R , italic_n , italic_Îµ ) = roman_Î© ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) if and only if there exist D1,D2âŠ†Dsubscriptğ·1subscriptğ·2ğ·D_{1},D_{2}\subseteq Ditalic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT âŠ† italic_D of size exactly 2222 such that |Râˆ©(D1Ã—D2)|=1ğ‘…subscriptğ·1subscriptğ·21|R\cap(D_{1}\times D_{2})|=1| italic_R âˆ© ( italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT Ã— italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) | = 1 (informally Rğ‘…Ritalic_R has an â€œinduced copyâ€ of AND2subscriptAND2\operatorname{AND}_{2}roman_AND start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT). â€¢ For râ‰¥3ğ‘Ÿ3r\geq 3italic_r â‰¥ 3, much less is known. Kogan and Krauthgamer [KK15] contributed near-linear hypergraph cut sparsifiers (i.e., the predicate is NAEr:={0,1}râˆ–{0r,1r}assignsubscriptNAEğ‘Ÿsuperscript01ğ‘Ÿsuperscript0ğ‘Ÿsuperscript1ğ‘Ÿ\operatorname{NAE}_{r}:=\{0,1\}^{r}\setminus\{0^{r},1^{r}\}roman_NAE start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT := { 0 , 1 } start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT âˆ– { 0 start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT , 1 start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT }). Since then, there have been multiple improvements in efficiently constructing hypergraph sparsifiers/sketches (e.g., [CKN20, KKTY21, KPS24c]). â€¢ The breakthroughs of Khanna, Putterman, and Sudan [KPS24a, KPS24b] construct non-linear sparsifiers for any predicate which can defined by a system of linear (in)equations (possibly over a higher domain). For example NAEr={xâˆˆ{0,1}r:x1+â‹¯+xrâ‰¢0modr}subscriptNAEğ‘Ÿconditional-setğ‘¥superscript01ğ‘Ÿnot-equivalent-tosubscriptğ‘¥1â‹¯subscriptğ‘¥ğ‘Ÿmodulo0ğ‘Ÿ\operatorname{NAE}_{r}=\{x\in\{0,1\}^{r}:x_{1}+\cdots+x_{r}\not\equiv 0\mod r\}roman_NAE start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT = { italic_x âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT : italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + â‹¯ + italic_x start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT â‰¢ 0 roman_mod italic_r }. Of note, their first paper [KPS24a] only proved the result over finite fields (and was nonalgorithmic), whereas their second paper [KPS24b] extended the result to all Abelian groups and was computationally efficient. â€¢ The framework of Khanna, Putterman, and Sudan [KPS24b] produced numerous corollaries. In particular, if a predicate can be expressed as the nonzero set of a degree kğ‘˜kitalic_k polynomial, then it has a sparsifier of size O~Îµâ¢(nk)subscript~ğ‘‚ğœ€superscriptğ‘›ğ‘˜\widetilde{O}_{\varepsilon}(n^{k})over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ). Furthermore, they show if a predicate Rğ‘…Ritalic_R can express666More specifically, we say that RâŠ†{0,1}rğ‘…superscript01ğ‘ŸR\subseteq\{0,1\}^{r}italic_R âŠ† { 0 , 1 } start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT can express ANDksubscriptANDğ‘˜\operatorname{AND}_{k}roman_AND start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT if there exits a map z:[r]â†’{0,1,x1,â€¦,xk,x1Â¯,â€¦,xkÂ¯}:ğ‘§â†’delimited-[]ğ‘Ÿ01subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘˜Â¯subscriptğ‘¥1â€¦Â¯subscriptğ‘¥ğ‘˜z:[r]\to\{0,1,x_{1},\ldots,x_{k},\overline{x_{1}},\ldots,\overline{x_{k}}\}italic_z : [ italic_r ] â†’ { 0 , 1 , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , overÂ¯ start_ARG italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_ARG , â€¦ , overÂ¯ start_ARG italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG } such that Râ¢(zâ¢(1),â€¦,zâ¢(r))=ANDkâ¡(x1,â€¦,xk)ğ‘…ğ‘§1â€¦ğ‘§ğ‘ŸsubscriptANDğ‘˜subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘˜R(z(1),\ldots,z(r))=\operatorname{AND}_{k}(x_{1},\ldots,x_{k})italic_R ( italic_z ( 1 ) , â€¦ , italic_z ( italic_r ) ) = roman_AND start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ). We discuss a more general framework of gadget reductions in Section 5.4. ANDk:={1k}assignsubscriptANDğ‘˜superscript1ğ‘˜\operatorname{AND}_{k}:=\{1^{k}\}roman_AND start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT := { 1 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT }, then SPRâ¡(R,n,Îµ)=Î©â¢(nk)SPRğ‘…ğ‘›ğœ€Î©superscriptğ‘›ğ‘˜\operatorname{SPR}(R,n,\varepsilon)=\Omega(n^{k})roman_SPR ( italic_R , italic_n , italic_Îµ ) = roman_Î© ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ). As a consequence, they also classify all ternary Boolean predicates (r=3ğ‘Ÿ3r=3italic_r = 3) as well as which Boolean predicates of arity rğ‘Ÿritalic_r cannot be sparsified below Î©â¢(nr)Î©superscriptğ‘›ğ‘Ÿ\Omega(n^{r})roman_Î© ( italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ) (just ANDrsubscriptANDğ‘Ÿ\operatorname{AND}_{r}roman_AND start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT and its bit flips), while also constructing a sparsifier of size O~Îµâ¢(nrâˆ’1)subscript~ğ‘‚ğœ€superscriptğ‘›ğ‘Ÿ1\widetilde{O}_{\varepsilon}(n^{r-1})over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT italic_r - 1 end_POSTSUPERSCRIPT ) in the other cases. â€¢ It appears that lower bounds with a nontrivial dependence on Îµğœ€\varepsilonitalic_Îµ are only known for cut sparsifiers (and thus hypergraph cut sparsifiers via a simple gadget reduction). See [ACK+16, CKST19] as well as Section 9 for further discussion. CSP Kernelization. Another question similar in spirit to CSP sparsification is that of CSP kernelization.777More commonly, CSP kernelization is referred to as CSP sparsification (e.g., [DvM14, LW20]). However, we refer to this line of work by the former name to reduce ambiguity. This similarity in name has been noted before in the literature (e.g., [BÅ½20]), but we appear to be the first work to notice both variants of â€œCSP sparsificationâ€ can be analyzed with similar techniques. The basic question is to, given an instance Î¨Î¨\Psiroman_Î¨ of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ), efficiently find as small of an instance Î¨â€²superscriptÎ¨â€²\Psi^{\prime}roman_Î¨ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) as possible (not necessarily a subinstance) such that Î¨Î¨\Psiroman_Î¨ and Î¨â€²superscriptÎ¨â€²\Psi^{\prime}roman_Î¨ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT are either both satisfiable or both unsatisfiable. This particular question can be attributed to Dell and van Melkebeek [DvM14], who were particularly inspired Impagliazzo, Paturi, and Zaneâ€™s sparsification lemma [IPZ01] and Harnik and Naorâ€™s compression framework [HN10]. See the literature review in [DvM14] for further motivations. At first, the problem seems rather unrelated to CSP sparsification. For example, if CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) is polynomial-time tractable, then there trivially exists a kernel of size Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 ). When CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) is NP-hard, however, the size of the smallest possible kernelization seems to much more closely track with the non-redundancy of Rğ‘…Ritalic_R. In particular, Dell and van Melkebeek [DvM14], proved that assuming ğ–¼ğ—ˆğ–­ğ–¯âŠˆğ–­ğ–¯/ğ—‰ğ—ˆğ—…ğ—’not-subset-of-nor-equalsğ–¼ğ—ˆğ–­ğ–¯ğ–­ğ–¯ğ—‰ğ—ˆğ—…ğ—’\mathsf{coNP}\nsubseteq\mathsf{NP/poly}sansserif_coNP âŠˆ sansserif_NP / sansserif_poly, the problem kğ‘˜kitalic_k-SAT cannot be kernelized below Î©â¢(nkâˆ’Îµ)Î©superscriptğ‘›ğ‘˜ğœ€\Omega(n^{k-\varepsilon})roman_Î© ( italic_n start_POSTSUPERSCRIPT italic_k - italic_Îµ end_POSTSUPERSCRIPT ) for any constant Îµ>0ğœ€0\varepsilon>0italic_Îµ > 0, which is close to kğ‘˜kitalic_k-SATâ€™s non-redundancy of Î˜â¢(nk)Î˜superscriptğ‘›ğ‘˜\Theta(n^{k})roman_Î˜ ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ). Furthermore, most upper bounds on the kernelization of NP-hard predicates follow from upper bounds on non-redundancy (see [Car22]). For example the works of Chen, Jansen, and Pieterse [CJP20] as well as Lagerkvist and WahlstrÃ¶m [LW17, LW20] develop various kernelization methods that happen to just be â€œefficientâ€ non-redundancy upper bounds. For example, these works show that if the predicate Rğ‘…Ritalic_R can be expressed as the zero set of a polynomial of degree kğ‘˜kitalic_k, then there exist a kernel of size Oâ¢(nk)ğ‘‚superscriptğ‘›ğ‘˜O(n^{k})italic_O ( italic_n start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ). This kernel happens to preserve every solution to Rğ‘…Ritalic_R, so it is also a non-redundancy upper bound. Using techniques like these, they are able to prove a number of results similar to the state-of-the-art in CSP sparsification, such as a complete classification of ternary Boolean predicates and a Oâ¢(nrâˆ’1)ğ‘‚superscriptğ‘›ğ‘Ÿ1O(n^{r-1})italic_O ( italic_n start_POSTSUPERSCRIPT italic_r - 1 end_POSTSUPERSCRIPT ) vs Î©â¢(nrâˆ’Îµ)Î©superscriptğ‘›ğ‘Ÿğœ€\Omega(n^{r-\varepsilon})roman_Î© ( italic_n start_POSTSUPERSCRIPT italic_r - italic_Îµ end_POSTSUPERSCRIPT ) Boolean dichotomy [CJP20]. See [JP19, JW20, Jan20, Tak23, Beu21] and citations therein for related work. We seek to emphasize that any efficient CSP sparsification algorithm for CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) is by design a kernelization algorithm for CSPâ¡(RÂ¯)CSPÂ¯ğ‘…\operatorname{CSP}(\overline{R})roman_CSP ( overÂ¯ start_ARG italic_R end_ARG ) (since all codewords with weight 00 are preserved). As such, making Theorem 1.2 efficient would require explicitly proving that every CSP can be kernelized to (approximately) its non-redundancy, which is a significant open question in the CSP kernelization community (see [Car22]). See Section 1.7 and Section 9 for further discussion. The Union-closed Sets Conjecture. A family â„±â„±\mathcal{F}caligraphic_F of subsets of [n]delimited-[]ğ‘›[n][ italic_n ] is union-closed if A,Bâˆˆâ„±ğ´ğµâ„±A,B\in\mathcal{F}italic_A , italic_B âˆˆ caligraphic_F imply that AâˆªBâˆˆâ„±ğ´ğµâ„±A\cup B\in\mathcal{F}italic_A âˆª italic_B âˆˆ caligraphic_F. In 1979, Frankl [Fra95] conjectured that there always exists iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n]italic_i âˆˆ [ italic_n ] which appears in at least half of the sets of â„±â„±\mathcal{F}caligraphic_F. For decades, progress on the conjecture was minimal, with the best general result being that some iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n]italic_i âˆˆ [ italic_n ] appears in Î©â¢(1/log2â¡|â„±|)Î©1subscript2â„±\Omega(1/\log_{2}|\mathcal{F}|)roman_Î© ( 1 / roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | caligraphic_F | ) of the sets [Kni94, WÃ³j99, Gil22]. However, in 2022, Gilmer [Gil22] shocked the combinatorics community by using an entropy-based approach to prove that some iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n]italic_i âˆˆ [ italic_n ] appears in 1/10011001/1001 / 100 of the sets. This immediately led to a large number of follow-up works refining Gilmerâ€™s entropy method [AHS22, CL22, Peb22, Saw23, Yu23, Cam22]. In particular, we can now replace â€˜1/10011001/1001 / 100â€™ with â€˜0.382â¢â€¦0.382â€¦0.382\ldots0.382 â€¦â€™, leaving Franklâ€™s conjecture (technically) still open. For our application to CSP sparsification, the entropy method used by Gilmer (and its subsequent refinements by many other reseachers) is the key idea needed to show that non-redundancy is essentially the optimal size for a CSP sparsifier. In particular, the improvement from 1/log2â¡|â„±|1subscript2â„±1/\log_{2}|\mathcal{F}|1 / roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | caligraphic_F | to Î©â¢(1)Î©1\Omega(1)roman_Î© ( 1 ) is precisely the same â€œgainâ€ we utilize to go from a very simple O~Îµâ¢(NRDâ¡(C)â‹…log2â¡|C|)subscript~ğ‘‚ğœ€â‹…NRDğ¶subscript2ğ¶\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C)\cdot\log_{2}|C|)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) â‹… roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_C | ) sparsifier (see Section 3) to our O~Îµâ¢(NRDâ¡(C))subscript~ğ‘‚ğœ€NRDğ¶\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C))over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) ) sparsifier. See the technical overview (Section 1.6) for more details. To the best of our knowledge, our work is the first application of Gilmerâ€™s entropy method to sparsification.888Gilmerâ€™s breakthough is cited in the literature review of [CDL+24], but the property-testing question they study on union-closed families has no technical connection to Gilmerâ€™s entropy method. See also [Wak24] for applications of the entropy method to learning theory and statistical physics. Matching Vector Families and Locally Decodable Codes. In coding theory, locally decodable codes (LDCs) are a class of codes which allow for jthe reliable recovery of any message symbol based on a small sample of codeword symbols, even in the presence of a constant fraction of errors. A particularly interesting familiy of constructions of LDCs has arisen out of a theory of matching vector codes [Yek08] and follow-ups [Rag07, Gop09, Efr09, DGY11]. See [DGY11] for a literature survey. Simply stated, a matching vector (MV) family over a (finite) ring â„›â„›\mathcal{R}caligraphic_R is a pair of lists of vectors u1,â€¦,uk,v1,â€¦,vkâˆˆâ„›dsubscriptğ‘¢1â€¦subscriptğ‘¢ğ‘˜subscriptğ‘£1â€¦subscriptğ‘£ğ‘˜superscriptâ„›ğ‘‘u_{1},\ldots,u_{k},v_{1},\ldots,v_{k}\in\mathcal{R}^{d}italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_u start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_v start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT âˆˆ caligraphic_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT such that the inner products âŸ¨ui,vjâŸ©subscriptğ‘¢ğ‘–subscriptğ‘£ğ‘—\langle u_{i},v_{j}\rangleâŸ¨ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT âŸ© are nonzero999Or, more generally the inner products lie in some restricted subset of â„›â„›\mathcal{R}caligraphic_R. if and only iâ‰ jğ‘–ğ‘—i\neq jitalic_i â‰  italic_j. Informally, the uisubscriptğ‘¢ğ‘–u_{i}italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTâ€™s play a role in the encoding of the iğ‘–iitalic_iâ€™th message symbol, with the matching vector visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT helping with its local decoding. Given a choice of â„›â„›\mathcal{R}caligraphic_R and dğ‘‘ditalic_d, the primary question of interest is to find the maximal possible value of kğ‘˜kitalic_k. This â€œspin offâ€ question about LDCs has become a topic of interest in its own right [DGY11, Yek12, GHSY12, BDL13]. In this work, we demonstrate a novel application of matching vector families to the study of non-redundancy and thus (by Theorem 1.2) sparsification. In particular, we construct an explicit family of predicates such that their non-redundant instances can be viewed as a generalized MV family. We then use techniques developed for MV families to given nontrivial bounds on the non-redundancy of the predicates. See Section 6 and the technical overview (Section 1.6) for more details. Extremal Combinatorics. Computing the non-redundancy of a predicate can be viewed as a problem in extremal combinatorics known as a hypergraph TurÃ¡n problem. In particular, for an instance of a CSP to be non-redundant, every instance induced by a subset of the variables must also be non-redundant. In particular, if â„±â„±\mathcal{F}caligraphic_F is a family of hypergraphs which can never appear in non-redundant instances of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ), then NRDâ¡(R,n)â‰¤exrâ¡(n,â„±)NRDğ‘…ğ‘›subscriptexğ‘Ÿğ‘›â„±\operatorname{NRD}(R,n)\leq\operatorname{ex}_{r}(n,\mathcal{F})roman_NRD ( italic_R , italic_n ) â‰¤ roman_ex start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_n , caligraphic_F ), where the hypergraph TurÃ¡n number exrâ¡(n,â„±)subscriptexğ‘Ÿğ‘›â„±\operatorname{ex}_{r}(n,\mathcal{F})roman_ex start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_n , caligraphic_F ) is the size of the largest rğ‘Ÿritalic_r-uniform hypergraph on nğ‘›nitalic_n vertices without any Fâˆˆâ„±ğ¹â„±F\in\mathcal{F}italic_F âˆˆ caligraphic_F as a subgraph. This observation was first made explicit by Carbonnel [Car22] although the technique was also used in earlier work [BCK20]. As far as we are aware, ours is the first work to observe that these insights can also benefit the study of CSP sparsification. The literature on hypergraph TurÃ¡n numbers is quite rich. For instance, Keevash [Kee11] surveys the vast body of work on the â€œnon-degenerateâ€ case in which exrâ¡(n,â„±)=Î©râ¢(nr)subscriptexğ‘Ÿğ‘›â„±subscriptÎ©ğ‘Ÿsuperscriptğ‘›ğ‘Ÿ\operatorname{ex}_{r}(n,\mathcal{F})=\Omega_{r}(n^{r})roman_ex start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_n , caligraphic_F ) = roman_Î© start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ). However, for our applications, we are mostly interested in the â€œdenegerateâ€ case in which exrâ¡(n,â„±)=Oâ¢(nc)subscriptexğ‘Ÿğ‘›â„±ğ‘‚superscriptğ‘›ğ‘\operatorname{ex}_{r}(n,\mathcal{F})=O(n^{c})roman_ex start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT ( italic_n , caligraphic_F ) = italic_O ( italic_n start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT ) for some câˆˆ[1,r)ğ‘1ğ‘Ÿc\in[1,r)italic_c âˆˆ [ 1 , italic_r ). The works [BCK20, Car22] apply some of the most well-known works in this setting [Erd64, SEB73, RS78] to get some nontrivial results such as classifying precisely which predicates Rğ‘…Ritalic_R have NRDâ¡(R,n)=Î˜â¢(nr)NRDğ‘…ğ‘›Î˜superscriptğ‘›ğ‘Ÿ\operatorname{NRD}(R,n)=\Theta(n^{r})roman_NRD ( italic_R , italic_n ) = roman_Î˜ ( italic_n start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ), extending Chen, Jansen, and Pieterseâ€™s result for the Boolean case [CJP20]. See Sections 5.2, 7.1, and 8.4.2 for more details on specific applications. Query Complexity and Learning Theory. Rather surprisingly, the definition of non-redundancy appears to have come out of the artificial intelligence community [BCK20]. In particular, a rather broad and well-studied question (e.g., [FW02, PBS08, LLMV10, BK12, BCH+13, BCK20]) is that of constraint acquisition: how can an agent learn the constraints defining an instance of a constraint satisfaction problem? A model specifically relevant to our work is the partial membership queries model studied by Bessiere, Carbonnel, and Katsirelos [BCK20]. In this model, the domain Dğ·Ditalic_D, the constraint type Rğ‘…Ritalic_R (or types), and the set of variables Xğ‘‹Xitalic_X are known but the constraints are hidden. For each query, the agent picks some subset of variables Xâ€²âŠ†Xsuperscriptğ‘‹â€²ğ‘‹X^{\prime}\subseteq Xitalic_X start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT âŠ† italic_X as well as a partial assignment Ïƒ:Xâ€²â†’D:ğœâ†’superscriptğ‘‹â€²ğ·\sigma:X^{\prime}\to Ditalic_Ïƒ : italic_X start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT â†’ italic_D. The response to the query is â€˜YESâ€™ if Ïƒğœ\sigmaitalic_Ïƒ satisfies every constraint induced by Xâ€²superscriptğ‘‹â€²X^{\prime}italic_X start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, and â€˜NOâ€™ otherwise. The goal is to construct an instance of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) with the same solution set as the hidden CSP. For every CSP predicate Rğ‘…Ritalic_R, they prove that the query complexity of an instance of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) on nğ‘›nitalic_n variables is bounded between Î©â¢(NRDâ¡(R,n))Î©NRDğ‘…ğ‘›\Omega(\operatorname{NRD}(R,n))roman_Î© ( roman_NRD ( italic_R , italic_n ) ) and Oâ¢(CLâ¡(R,n)â‹…logâ¡n)ğ‘‚â‹…CLğ‘…ğ‘›ğ‘›O(\operatorname{CL}(R,n)\cdot\log n)italic_O ( roman_CL ( italic_R , italic_n ) â‹… roman_log italic_n ). Notably, the lower bound is proved by showing that the VC dimension of the query complexity problem equals NRDâ¡(R,n)NRDğ‘…ğ‘›\operatorname{NRD}(R,n)roman_NRD ( italic_R , italic_n ).101010This observation is directly used in proving our main result, see Section 4.1. 1.6 Technical Overview We next describe the primary techniques we use to prove Theorem 1.1 and Theorem 1.3. A Simple Sparsifier. To begin, we discuss a warm-up version of Theorem 1.1 which proves a weaker upper bound of SPRâ¡(C,Îµ)â‰¤O~Îµâ¢(NRDâ¡(C)â‹…logâ¡|C|)SPRğ¶ğœ€subscript~ğ‘‚ğœ€â‹…NRDğ¶ğ¶\operatorname{SPR}(C,\varepsilon)\leq\widetilde{O}_{\varepsilon}(\operatorname% {NRD}(C)\cdot\log|C|)roman_SPR ( italic_C , italic_Îµ ) â‰¤ over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) â‹… roman_log | italic_C | ) (see Theorem 3.1), which for CSPs corresponds to an extra factor of the number of variables nğ‘›nitalic_n. The key technical insight (Lemma 3.3) is that for all dâˆˆ[m]ğ‘‘delimited-[]ğ‘šd\in[m]italic_d âˆˆ [ italic_m ], the set of codewords of Cğ¶Citalic_C with Hamming weight at most dğ‘‘ditalic_d (denoted by Câ‰¤dsubscriptğ¶absentğ‘‘C_{\leq d}italic_C start_POSTSUBSCRIPT â‰¤ italic_d end_POSTSUBSCRIPT) has total support size at most dâ‹…NRDâ¡(C)â‹…ğ‘‘NRDğ¶d\cdot\operatorname{NRD}(C)italic_d â‹… roman_NRD ( italic_C ). This can proved inductively by noticing that dropping a suitable non-redundant set of coordinates decreases the Hamming weight of every codeword of Cğ¶Citalic_C by at least one. With this lemma, we can recursively construct a sparsifier as follows, similar to the divide-and-conquer framework in [KPS24a, KPS24b] for linear codes. Pick dâ‰ˆÎ˜~Îµâ¢(logâ¡|C|)ğ‘‘subscript~Î˜ğœ€ğ¶d\approx\widetilde{\Theta}_{\varepsilon}(\log|C|)italic_d â‰ˆ over~ start_ARG roman_Î˜ end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_log | italic_C | ) and let IâŠ†[m]ğ¼delimited-[]ğ‘šI\subseteq[m]italic_I âŠ† [ italic_m ] be the support of Câ‰¤dsubscriptğ¶absentğ‘‘C_{\leq d}italic_C start_POSTSUBSCRIPT â‰¤ italic_d end_POSTSUBSCRIPT. Every iâˆˆIğ‘–ğ¼i\in Iitalic_i âˆˆ italic_I is given weight 1111 in our sparsifier. For the rest of [m]delimited-[]ğ‘š[m][ italic_m ], let JâŠ†[m]âˆ–Iğ½delimited-[]ğ‘šğ¼J\subseteq[m]\setminus Iitalic_J âŠ† [ italic_m ] âˆ– italic_I be a subsample where each iâˆˆ[m]âˆ–Iğ‘–delimited-[]ğ‘šğ¼i\in[m]\setminus Iitalic_i âˆˆ [ italic_m ] âˆ– italic_I is kept independently with probability 1/3131/31 / 3. Using a standard Chernoff bound, we can show that with positive111111We only need positive probability since we are focused on existence. This can easily be amplified to 1âˆ’1/mÎ©â¢(1)11superscriptğ‘šÎ©11-1/m^{\Omega(1)}1 - 1 / italic_m start_POSTSUPERSCRIPT roman_Î© ( 1 ) end_POSTSUPERSCRIPT probability by making dğ‘‘ditalic_d a factor of logâ¡mğ‘š\log mroman_log italic_m bigger. In applications to CSPs, the main algorithmic bottleneck is (approximately) finding Iğ¼Iitalic_I, which appears to be similar in difficulty to an open problem in CSP kernelization (see Section 1.7). probability the following holds for all câˆˆCğ‘ğ¶c\in Citalic_c âˆˆ italic_C: 3â¢Hamâ¡(c|J)+Hamâ¡(c|I)âˆˆ[1âˆ’Îµ2â¢log2â¡m,1+Îµ2â¢log2â¡m]â‹…Hamâ¡(c).3Hamevaluated-atğ‘ğ½Hamevaluated-atğ‘ğ¼â‹…1ğœ€2subscript2ğ‘š1ğœ€2subscript2ğ‘šHamğ‘3\operatorname{Ham}(c|_{J})+\operatorname{Ham}(c|_{I})\in\left[1-\frac{% \varepsilon}{2\log_{2}m},1+\frac{\varepsilon}{2\log_{2}m}\right]\cdot% \operatorname{Ham}(c).3 roman_Ham ( italic_c | start_POSTSUBSCRIPT italic_J end_POSTSUBSCRIPT ) + roman_Ham ( italic_c | start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT ) âˆˆ [ 1 - divide start_ARG italic_Îµ end_ARG start_ARG 2 roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m end_ARG , 1 + divide start_ARG italic_Îµ end_ARG start_ARG 2 roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m end_ARG ] â‹… roman_Ham ( italic_c ) . By induction, we can find a O~Îµâ€²â¢(NRDâ¡(Câ€²)â‹…logâ¡|Câ€²|)subscript~ğ‘‚superscriptğœ€â€²â‹…NRDsuperscriptğ¶â€²superscriptğ¶â€²\widetilde{O}_{\varepsilon^{\prime}}(\operatorname{NRD}(C^{\prime})\cdot\log|C% ^{\prime}|)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ( roman_NRD ( italic_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) â‹… roman_log | italic_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT | ) Îµâ€²superscriptğœ€â€²\varepsilon^{\prime}italic_Îµ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT-sparsifier for Câ€²:=C|Jassignsuperscriptğ¶â€²evaluated-atğ¶ğ½C^{\prime}:=C|_{J}italic_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT := italic_C | start_POSTSUBSCRIPT italic_J end_POSTSUBSCRIPT with Îµâ€²:=(1âˆ’1/log2â¡m)â¢Îµassignsuperscriptğœ€â€²11subscript2ğ‘šğœ€\varepsilon^{\prime}:=(1-1/\log_{2}m)\varepsilonitalic_Îµ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT := ( 1 - 1 / roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m ) italic_Îµ. Scaling this sparsifier by 3333 and adding weights for Iğ¼Iitalic_I gives us an Îµğœ€\varepsilonitalic_Îµ-sparsifier of Cğ¶Citalic_C. Entropy-based Sparsification. The key inefficiency of the O~Îµâ¢(NRDâ¡(C)â‹…logâ¡|C|)subscript~ğ‘‚ğœ€â‹…NRDğ¶ğ¶\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C)\cdot\log|C|)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) â‹… roman_log | italic_C | ) bound is that the use of Lemma 3.3 is too conservative. For the purposes of this overview, assume that all codewords of Cğ¶Citalic_C have the same Hamming weight dâ‰ˆNRDâ¡(C)ğ‘‘NRDğ¶d\approx\operatorname{NRD}(C)italic_d â‰ˆ roman_NRD ( italic_C ) as that is is the most representative case. Naively, Lemma 3.3 says we should set aside d2superscriptğ‘‘2d^{2}italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT coordinates of [m]delimited-[]ğ‘š[m][ italic_m ] to â€œsparsifyâ€ all codewords of weight dğ‘‘ditalic_d. However, we can give a heuristic argument that far fewer than d2superscriptğ‘‘2d^{2}italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT of these potential coordinates contain useful information for our sparsifier. Assume without loss of generality that the support of Cğ¶Citalic_C lies in [d2]delimited-[]superscriptğ‘‘2[d^{2}][ italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ]. For each iâˆˆ[d2]ğ‘–delimited-[]superscriptğ‘‘2i\in[d^{2}]italic_i âˆˆ [ italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ], let pisubscriptğ‘ğ‘–p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT be the probability that a codeword câˆˆCğ‘ğ¶c\in Citalic_c âˆˆ italic_C selected uniformly at random has ci=1subscriptğ‘ğ‘–1c_{i}=1italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1. Since each codeword of Cğ¶Citalic_C has Hamming weight dğ‘‘ditalic_d, we have that p1+â‹¯+pd2=dsubscriptğ‘1â‹¯subscriptğ‘superscriptğ‘‘2ğ‘‘p_{1}+\cdots+p_{d^{2}}=ditalic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + â‹¯ + italic_p start_POSTSUBSCRIPT italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT = italic_d. Thus, the average value of pisubscriptğ‘ğ‘–p_{i}italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is 1/d1ğ‘‘1/d1 / italic_d. Consider the case in which each pi=Oâ¢(1/d)subscriptğ‘ğ‘–ğ‘‚1ğ‘‘p_{i}=O(1/d)italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_O ( 1 / italic_d ). In particular, no coordinate is distinguishing itself as a â€œmustâ€ to add to the sparsifier. A priori, the size of Cğ¶Citalic_C may be expâ¡(Î©~â¢(d))~Î©ğ‘‘\exp(\widetilde{\Omega}(d))roman_exp ( over~ start_ARG roman_Î© end_ARG ( italic_d ) ), so we cannot immediately use Chernoff bounds to analyze a random subsampling of the coordinates. To get around this issue, we need to prove a much stronger upper bound on the size of Cğ¶Citalic_C, similar to BenczÃºr and Kargerâ€™s cut-counting bound [BK96] and its adaptation to linear codes [KPS24a, KPS24b]. However, we use an entirely new method for proving such bounds based on the entropy method Gilmer [Gil22] developed to prove the union-closed sets conjecture up to a constant factor. In our context, pick t=Î˜~â¢(d)ğ‘¡~Î˜ğ‘‘t=\widetilde{\Theta}(d)italic_t = over~ start_ARG roman_Î˜ end_ARG ( italic_d ) and sample uniformly and independently tğ‘¡titalic_t codewords c1,â€¦,ctâˆˆCsubscriptğ‘1â€¦subscriptğ‘ğ‘¡ğ¶c_{1},\ldots,c_{t}\in Citalic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_c start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT âˆˆ italic_C. Let cğ‘citalic_c be the bitwise OR of these tğ‘¡titalic_t codewords, and let ğ’Ÿğ’Ÿ\mathcal{D}caligraphic_D be the distribution of cğ‘citalic_c over {0,1}d2superscript01superscriptğ‘‘2\{0,1\}^{d^{2}}{ 0 , 1 } start_POSTSUPERSCRIPT italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT (recall that the weight dğ‘‘ditalic_d codewords are supported on d2superscriptğ‘‘2d^{2}italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT coordinates). Since each pi=Oâ¢(1/d)subscriptğ‘ğ‘–ğ‘‚1ğ‘‘p_{i}=O(1/d)italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_O ( 1 / italic_d ), by adapting Gilmerâ€™s method (or more precisely, a refinement due to Sawin [Saw23]), we can show the entropy of ğ’Ÿğ’Ÿ\mathcal{D}caligraphic_D is at least Î˜~â¢(t)=Î˜~â¢(d)~Î˜ğ‘¡~Î˜ğ‘‘\widetilde{\Theta}(t)=\widetilde{\Theta}(d)over~ start_ARG roman_Î˜ end_ARG ( italic_t ) = over~ start_ARG roman_Î˜ end_ARG ( italic_d ) times the entropy of the uniform distribution over Cğ¶Citalic_C (i.e., log2â¡|C|subscript2ğ¶\log_{2}|C|roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_C |)â€“a similar inequality appears in [Wak24]. To apply this fact, observe that each sample of ğ’Ÿğ’Ÿ\mathcal{D}caligraphic_D lies in the â€œOROR\operatorname{OR}roman_OR-closureâ€ of Cğ¶Citalic_C (denoted by spanORâ¡(C)subscriptspanORğ¶\operatorname{span}_{\operatorname{OR}}(C)roman_span start_POSTSUBSCRIPT roman_OR end_POSTSUBSCRIPT ( italic_C )). As such, the entropy of ğ’Ÿğ’Ÿ\mathcal{D}caligraphic_D is at most logâ¡|spanORâ¡(C)|subscriptspanORğ¶\log\lvert\operatorname{span}_{\operatorname{OR}}(C)\rvertroman_log | roman_span start_POSTSUBSCRIPT roman_OR end_POSTSUBSCRIPT ( italic_C ) |, which by the Sauer-Shelah-Peres lemma is at most (up to log factors) the VC dimension of spanORâ¡(C)subscriptspanORğ¶\operatorname{span}_{\operatorname{OR}}(C)roman_span start_POSTSUBSCRIPT roman_OR end_POSTSUBSCRIPT ( italic_C ). It is easily seen that the VC dimension of spanORâ¡(C)subscriptspanORğ¶\operatorname{span}_{\operatorname{OR}}(C)roman_span start_POSTSUBSCRIPT roman_OR end_POSTSUBSCRIPT ( italic_C ) equals the non-redundancy of Cğ¶Citalic_C [BCK20]. Therefore, we have proved that Î˜~â¢(t)â‹…log2â¡(C)â‰¤O~â¢(NRDâ¡(C))â‹…~Î˜ğ‘¡subscript2ğ¶~ğ‘‚NRDğ¶\widetilde{\Theta}(t)\cdot\log_{2}(C)\leq\widetilde{O}(\operatorname{NRD}(C))over~ start_ARG roman_Î˜ end_ARG ( italic_t ) â‹… roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_C ) â‰¤ over~ start_ARG italic_O end_ARG ( roman_NRD ( italic_C ) ). Since tâ‰ˆdâ‰ˆNRDâ¡(C)ğ‘¡ğ‘‘NRDğ¶t\approx d\approx\operatorname{NRD}(C)italic_t â‰ˆ italic_d â‰ˆ roman_NRD ( italic_C ), Cğ¶Citalic_C is actually at most quasipolynomial in size! Thus we can now use a Chernoff bound to prove that Cğ¶Citalic_C can be subsampled to O~Îµâ¢(d)subscript~ğ‘‚ğœ€ğ‘‘\widetilde{O}_{\varepsilon}(d)over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( italic_d ) coordinates while approximately preserving all Hamming weights. Recall this discussion was purely about the â€œuniformâ€ case pi=Oâ¢(1/d)subscriptğ‘ğ‘–ğ‘‚1ğ‘‘p_{i}=O(1/d)italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_O ( 1 / italic_d ). In general, we apply minimax theorem to prove the following â€œskewedâ€ versus â€œsparseâ€ dichotomy (see Proposition 4.14): for every code Cğ¶Citalic_C and parameter choice Î¸â‰¥1ğœƒ1\theta\geq 1italic_Î¸ â‰¥ 1 there is either a probability distribution ğ’«ğ’«\mathcal{P}caligraphic_P over Cğ¶Citalic_C for which each coordinate equals 1111 with probability at most 1/Î¸1ğœƒ1/\theta1 / italic_Î¸ (i.e., ğ’«ğ’«\mathcal{P}caligraphic_P is â€œÎ¸ğœƒ\thetaitalic_Î¸-sparseâ€); or, there is a probability distribution ğ’¬ğ’¬\mathcal{Q}caligraphic_Q over the coordinates of Cğ¶Citalic_C such that for every (nonzero) câˆˆCğ‘ğ¶c\in Citalic_c âˆˆ italic_C, we have that ğ’¬ğ’¬\mathcal{Q}caligraphic_Qâ€™s measure of suppâ¡(c)suppğ‘\operatorname{supp}(c)roman_supp ( italic_c ) is at least 1/Î¸1ğœƒ1/\theta1 / italic_Î¸ (i.e., ğ’¬ğ’¬\mathcal{Q}caligraphic_Q is a â€œÎ¸ğœƒ\thetaitalic_Î¸-cover.â€) For a suitable choice of Î¸ğœƒ\thetaitalic_Î¸, we repeatedly apply Proposition 4.14 to recursively build the sparsifier: in the Î¸ğœƒ\thetaitalic_Î¸-sparse case, we use the entropy method to prove that a â€œsmallâ€ number of codewords of Cğ¶Citalic_C can be removed to put us in the Î¸ğœƒ\thetaitalic_Î¸-cover case (see Lemma 4.15); and in the Î¸ğœƒ\thetaitalic_Î¸-cover case, we sample from the Î¸ğœƒ\thetaitalic_Î¸-cover to get a coordinate to add to our sparsifier. This procedure culminates in showing that we can set aside O~Îµâ¢(NRDâ¡(C))subscript~ğ‘‚ğœ€NRDğ¶\widetilde{O}_{\varepsilon}(\operatorname{NRD}(C))over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) ) coordinates to have weight 1111 in our sparsifier with the remainder of the code being sufficiently sparse that subsampling can be used (Theorem 4.16). Note that the statement of Theorem 4.16 resembles the analogous decompositions for linear codes [KPS24a, KPS24b]. However, their method found all the coordinates to set aside in â€œone pass,â€ whereas we iteratively understand the dense and sparse structure of our non-linear code. With Theorem 4.16 in hand, we construct the sparsifier with a recursive argument similar to that of Theorem 3.1. As mentioned earlier, extended these ideas to weighted sparsification (Theorem 1.4) is relatively straightforward. We adapt a weight-binning argument of [KPS24b] by essentially computing an (unweighted) sparsifier for each group of coordinates that is similar in weight (within polyâ¡(m)polyğ‘š\operatorname{poly}(m)roman_poly ( italic_m )). We then analyze the aggregated size of these sparsifiers by comparing the sum of the non-redundancies of the groups of coordinates to the chain length of the code. Connections to Matching Vector Families. We now switch gears to briefly discussing the key ideas behind Theorem 1.3. Let G:=â„¤/3â¢â„¤assignğºâ„¤3â„¤G:=\mathbb{Z}/3\mathbb{Z}italic_G := blackboard_Z / 3 blackboard_Z and recall that 3â¢Lâ¢Iâ¢NG={(x,y,z)âˆ£x+y+z=0}subscript3LINğºconditional-setğ‘¥ğ‘¦ğ‘§ğ‘¥ğ‘¦ğ‘§0\operatorname{3LIN}_{G}=\{(x,y,z)\mid x+y+z=0\}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = { ( italic_x , italic_y , italic_z ) âˆ£ italic_x + italic_y + italic_z = 0 } and 3â¢Lâ¢Iâ¢NGâˆ—=3â¢Lâ¢Iâ¢NGâˆ–{(0,0,0)}subscriptsuperscript3LINğºsubscript3LINğº000\operatorname{3LIN}^{*}_{G}=\operatorname{3LIN}_{G}\setminus\{(0,0,0)\}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT âˆ– { ( 0 , 0 , 0 ) }. It is well-known that since 3â¢Lâ¢Iâ¢NGsubscript3LINğº\operatorname{3LIN}_{G}start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT is an affine predicate, we have that NRDâ¡(3â¢Lâ¢Iâ¢NG,n)=Î˜â¢(n)NRDsubscript3LINğºğ‘›Î˜ğ‘›\operatorname{NRD}(\operatorname{3LIN}_{G},n)=\Theta(n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ) = roman_Î˜ ( italic_n ), which is much smaller than our bound on NRDâ¡(3â¢Lâ¢Iâ¢NGâˆ—,n)NRDsubscriptsuperscript3LINğºğ‘›\operatorname{NRD}(\operatorname{3LIN}^{*}_{G},n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ). As such, we prove that to understand the asymptotics of NRDâ¡(3â¢Lâ¢Iâ¢NGâˆ—,n)NRDsubscriptsuperscript3LINğºğ‘›\operatorname{NRD}(\operatorname{3LIN}^{*}_{G},n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_n ) it suffices to look at specially-structured non-redundant instances. Recall that an instance Î¨:=(X,Y)assignÎ¨ğ‘‹ğ‘Œ\Psi:=(X,Y)roman_Î¨ := ( italic_X , italic_Y ) of CSPâ¡(3â¢Lâ¢Iâ¢NGâˆ—)CSPsubscriptsuperscript3LINğº\operatorname{CSP}(\operatorname{3LIN}^{*}_{G})roman_CSP ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) is non redundant if for every clause yâˆˆYğ‘¦ğ‘Œy\in Yitalic_y âˆˆ italic_Y there is an assignment Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT which satisfies every clause of Î¨Î¨\Psiroman_Î¨ except yğ‘¦yitalic_y. We show that with at most an additive Î˜â¢(n)Î˜ğ‘›\Theta(n)roman_Î˜ ( italic_n ) change in size, we can assume that Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT maps yğ‘¦yitalic_y to (0,0,0)000(0,0,0)( 0 , 0 , 0 ). In other words, each Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT is a satisfying assignment to Î¨Î¨\Psiroman_Î¨ when viewed as an instance of CSPâ¡(3â¢Lâ¢Iâ¢NG)CSPsubscript3LINğº\operatorname{CSP}(\operatorname{3LIN}_{G})roman_CSP ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) (see Proposition 6.3). This idea of â€œconditionalâ€ non-redundancy abstracts and generalizes an approach from [BCK20]. Since the set of solutions to an instance of CSPâ¡(3â¢Lâ¢Iâ¢NG)CSPsubscript3LINğº\operatorname{CSP}(\operatorname{3LIN}_{G})roman_CSP ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) form a vector space (of some dimension, say dğ‘‘ditalic_d) over ğ”½3subscriptğ”½3\mathbb{F}_{3}blackboard_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT, we can think of each variable xâˆˆXğ‘¥ğ‘‹x\in Xitalic_x âˆˆ italic_X of Î¨Î¨\Psiroman_Î¨ as a vector vxâˆˆğ”½3dsubscriptğ‘£ğ‘¥superscriptsubscriptğ”½3ğ‘‘v_{x}\in\mathbb{F}_{3}^{d}italic_v start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT âˆˆ blackboard_F start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT and the assignments as linear maps on the vectors. Because we are studying satisfying assignment to CSPâ¡(3â¢Lâ¢Iâ¢NG)CSPsubscript3LINğº\operatorname{CSP}(\operatorname{3LIN}_{G})roman_CSP ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ), these vectors are highly structured: for each y:=(x1,x2,x3)âˆˆYassignğ‘¦subscriptğ‘¥1subscriptğ‘¥2subscriptğ‘¥3ğ‘Œy:=(x_{1},x_{2},x_{3})\in Yitalic_y := ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) âˆˆ italic_Y, we have that vx1+vx2+vx3=0subscriptğ‘£subscriptğ‘¥1subscriptğ‘£subscriptğ‘¥2subscriptğ‘£subscriptğ‘¥30v_{x_{1}}+v_{x_{2}}+v_{x_{3}}=0italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT + italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT + italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT = 0. Further, Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT can be viewed as a linear map taking each of vx1,vx2,vx3subscriptğ‘£subscriptğ‘¥1subscriptğ‘£subscriptğ‘¥2subscriptğ‘£subscriptğ‘¥3v_{x_{1}},v_{x_{2}},v_{x_{3}}italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT end_POSTSUBSCRIPT to 00, while mapping at least one vector in every other triple in Yğ‘ŒYitalic_Y to a nonzero value. We call this family of vectors together with these assignments a GğºGitalic_G-ensemble (Definition 6.5), and note that it bears a strong resemblance to matching vector families. In particular, we adapt techniques used by Dvir, Gopalan, and Yekhanin [DGY11] for constraining the size of matching vector families to give nontrivial upper and lower bounds on the size of GğºGitalic_G-ensembles. For the lower bound (Theorem 6.8), we directly construct a non-redundant instance with Î©â¢(n1.5)Î©superscriptğ‘›1.5\Omega(n^{1.5})roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) clauses. The proof is self-contained and elementary. The upper bound (Theorem 6.13) is slightly more technical. We break the proof into cases based on whether the embedding dimension dğ‘‘ditalic_d of the vectors is small (d=O~â¢(n0.4)ğ‘‘~ğ‘‚superscriptğ‘›0.4d=\widetilde{O}(n^{0.4})italic_d = over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 0.4 end_POSTSUPERSCRIPT )) or large (d=Î©~â¢(n0.4)ğ‘‘~Î©superscriptğ‘›0.4d=\widetilde{\Omega}(n^{0.4})italic_d = over~ start_ARG roman_Î© end_ARG ( italic_n start_POSTSUPERSCRIPT 0.4 end_POSTSUPERSCRIPT )). For small dğ‘‘ditalic_d, we adapt the polynomial method used in [DGY11] to prove there can be at most Oâ¢(d4)=O~â¢(n1.6)ğ‘‚superscriptğ‘‘4~ğ‘‚superscriptğ‘›1.6O(d^{4})=\widetilde{O}(n^{1.6})italic_O ( italic_d start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT ) = over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT ) non-redundant clauses. On the other hand, when dğ‘‘ditalic_d is large, we ignore the assignments Ïƒysubscriptğœğ‘¦\sigma_{y}italic_Ïƒ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT and use a careful induction (Lemma 6.11) to show that the geometry of the vectors imply that some xâˆˆXğ‘¥ğ‘‹x\in Xitalic_x âˆˆ italic_X is a member of at most O~â¢(n/d)=O~â¢(n0.6)~ğ‘‚ğ‘›ğ‘‘~ğ‘‚superscriptğ‘›0.6\widetilde{O}(n/d)=\widetilde{O}(n^{0.6})over~ start_ARG italic_O end_ARG ( italic_n / italic_d ) = over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 0.6 end_POSTSUPERSCRIPT ) clauses, thereby leading to a bound of at most O~â¢(n1.6)~ğ‘‚superscriptğ‘›1.6\widetilde{O}(n^{1.6})over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT ) clauses total. Closing the gap between Î©â¢(n1.5)Î©superscriptğ‘›1.5\Omega(n^{1.5})roman_Î© ( italic_n start_POSTSUPERSCRIPT 1.5 end_POSTSUPERSCRIPT ) and O~â¢(n1.6)~ğ‘‚superscriptğ‘›1.6\widetilde{O}(n^{1.6})over~ start_ARG italic_O end_ARG ( italic_n start_POSTSUPERSCRIPT 1.6 end_POSTSUPERSCRIPT ) for NRDâ¡(3â¢Lâ¢Iâ¢Nâ„¤/3â¢â„¤âˆ—,n)NRDsuperscriptsubscript3LINâ„¤3â„¤ğ‘›\operatorname{NRD}(\operatorname{3LIN}_{\mathbb{Z}/3\mathbb{Z}}^{*},n)roman_NRD ( start_OPFUNCTION 3 roman_L roman_I roman_N end_OPFUNCTION start_POSTSUBSCRIPT blackboard_Z / 3 blackboard_Z end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT , italic_n ) is a tantalizing open question. 1.7 Open Questions We conclude the introduction with a few directions of further study. See Section 7 and Section 9 for a more thorough discussion of directions for future exploration. â€¢ Making Theorem 1.2 efficient. Note that the underlying construction for Theorem 1.1, if made algorithmic, runs in polynomial time with respect to the size of the code, yielding an expâ¡(Oâ¢(n))ğ‘‚ğ‘›\exp(O(n))roman_exp ( italic_O ( italic_n ) )-time algorithm121212This is already nontrivial, as a naive guess-and-check algorithm would require expâ¡(O~â¢(NRDâ¡(RÂ¯,n)))~ğ‘‚NRDÂ¯ğ‘…ğ‘›\exp(\widetilde{O}(\operatorname{NRD}(\overline{R},n)))roman_exp ( over~ start_ARG italic_O end_ARG ( roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ) ) ) time. for Theorem 1.2. The primary barrier in constructing our sparsifier in polyâ¡(n)polyğ‘›\operatorname{poly}(n)roman_poly ( italic_n ) time is the fact that an efficient sparsifier is also a kernelization algorithm, but kernelizing every CSP instance to its non-redundancy is a significant open question in the kernelization community [Car22]. â€¢ Computing NRDâ¡(R,n)NRDğ‘…ğ‘›\operatorname{NRD}(R,n)roman_NRD ( italic_R , italic_n ). For a general predicate RâŠ†Drğ‘…superscriptğ·ğ‘ŸR\subseteq D^{r}italic_R âŠ† italic_D start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT, there is no simple (even conjectured) expression for NRDâ¡(R,n)NRDğ‘…ğ‘›\operatorname{NRD}(R,n)roman_NRD ( italic_R , italic_n ). In fact, even determining when NRDâ¡(R,n)=Î˜â¢(n)NRDğ‘…ğ‘›Î˜ğ‘›\operatorname{NRD}(R,n)=\Theta(n)roman_NRD ( italic_R , italic_n ) = roman_Î˜ ( italic_n ) is an open question (e.g., [BCK20, Car22]). In Section 7, we explore a number of predicates from the various parts of the literature whose status is unresolved, including a predicate we categorize as the â€œsimplest unresolved predicate.â€ â€¢ Non-redundancy versus Chain Length. Recall we show that unweighted sparsification is closely tied to non-redundancy while weighted sparsification is closely tied to chain length. For non-linear codes, NRDNRD\operatorname{NRD}roman_NRD and CLCL\operatorname{CL}roman_CL can be very different (e.g., Example 8.8), but the relationship for CSPs is unknown [BCK20, Car22]. In particular, it seems quite possible that there exists a CSP predicate Rğ‘…Ritalic_R for which wSPRâ¡(R,n,Îµ)/SPRâ¡(R,n,Îµ)=nÎ©â¢(1).wSPRğ‘…ğ‘›ğœ€SPRğ‘…ğ‘›ğœ€superscriptğ‘›Î©1\operatorname{wSPR}(R,n,\varepsilon)/\operatorname{SPR}(R,n,\varepsilon)=n^{% \Omega(1)}.roman_wSPR ( italic_R , italic_n , italic_Îµ ) / roman_SPR ( italic_R , italic_n , italic_Îµ ) = italic_n start_POSTSUPERSCRIPT roman_Î© ( 1 ) end_POSTSUPERSCRIPT . â€¢ Average-case behavior. From Theorem 1.2, we know that every instance CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) has a sparsifier of size approximately its own non-redundancy, even if that value is much smaller than NRDâ¡(RÂ¯,n)NRDÂ¯ğ‘…ğ‘›\operatorname{NRD}(\overline{R},n)roman_NRD ( overÂ¯ start_ARG italic_R end_ARG , italic_n ). As such, it may be possible that â€˜averageâ€™ instances of CSPâ¡(R)CSPğ‘…\operatorname{CSP}(R)roman_CSP ( italic_R ) admit sparsifiers much smaller than the worst case. 1.8 Organization In Section 2, we prove some basic facts about non-redundancy, sparsification and their relationship. In Section 3, we give a straightforward proof that SPRâ¡(C,Îµ)=O~Îµâ¢(NRDâ¡(C)â¢log2â¡|C|)SPRğ¶ğœ€subscript~ğ‘‚ğœ€NRDğ¶subscript2ğ¶\operatorname{SPR}(C,\varepsilon)=\widetilde{O}_{\varepsilon}(\operatorname{% NRD}(C)\log_{2}|C|)roman_SPR ( italic_C , italic_Îµ ) = over~ start_ARG italic_O end_ARG start_POSTSUBSCRIPT italic_Îµ end_POSTSUBSCRIPT ( roman_NRD ( italic_C ) roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_C | ). In Section 4, we prove Theorem 1.2 by connecting CSP sparsification to non-redundancy via Gilmerâ€™s entropy method. In Section 5, we discuss the immediate applications of Theorem 1.2 based on what is known about non-redundancy in the literature. In Section 6, we bound the non-redundancy of a family of predicates via methods related to matching vector families. In Section 7, we give examples of CSP predicates in the literature whose non-redundancy is unresolved. In Section 8, we extend Theorem 1.2 to weighted instances. In Section 9, we wrap up with other directions of exploration. 1.9 Acknowledgments We thank Libor Barto, Dmitry Zhuk, Madhu Sudan, and Aaron Putterman for valuable conversations. This research was supported in part by a Simons Investigator award and NSF grant CCF-2211972."
https://arxiv.org/html/2411.03069v1,Conformance Games for Graded Semantics,"Game-theoretic characterizations of process equivalences traditionally form a central topic in concurrency; for example, most equivalences on the classical linear-time / branching-time spectrum come with such characterizations. Recent work on so-called graded semantics has led to a generic behavioural equivalence game that covers the mentioned games on the linear-time / branching-time spectrum and moreover applies in coalgebraic generality, and thus instantiates also to equivalence games on systems with non-relational branching type (probabilistic, weighted, game-based etc.). In the present work, we generalize this approach to cover other types of process comparison beyond equivalence, such as behavioural preorders or pseudometrics. At the most general level, we abstract such notions of behavoiural conformance in terms of topological categories, and later specialize to conformances presented as relational structures to obtain a concrete syntax. We obtain a sound and complete generic game for behavioural conformances in this sense. We present a number of instantiations, obtaining game characterizations of, e.g., trace inclusion, probabilistic trace distance, bisimulation topologies, and simulation distances on metric labelled transition systems.","Game-theoretic characterizations of equivalences have a firm place in the study of concurrent systems. A well-known example is the classical Spoiler-Duplicator game for bisimilarity, which is played on pairs of states in labelled transition systems (LTS), and in which Duplicator has a winning strategy at a pair of states iff the two states are bisimilar [Stirling99]. One benefit of such games is that they provide witnesses for both equivalence and inequivalence, in the shape of winning strategies for the respective player; from winning strategies of Spoiler, one can in fact often extract distinguishing formulae in suitable characteristic modal logics (e.g. [KoenigEA20]). Besides the mentioned branching-time bisimulation game, one has behavioural equivalence games for most of the equivalences on the linear-time / branching-time spectrum of process equivalences on LTS [Glabbeek01]. Similar spectra of behavioural equivalences live over other system types beyond relational transition systems, such as probabilistic [JouSmolka90], weighted, or neighbourhood-based systems. We generally refer to equivalences on such spectra as the semantics of systems (bisimulation semantics, trace semantics etc.). Recently, a general treatment of behavioural equivalence games has been given that works generically over both the both the system type and the system semantics [DBLP:conf/lics/FordMSB022]. This is achieved by on the one hand encapsulating the system type as a set functor following the paradigm of universal coalgebra [Rutten00] and on the other hand by abstracting the system semantics in the framework of graded semantics [DBLP:conf/calco/MiliusPS15], which is based on mapping the type functor into a graded monad [Smirnov08]. Now the behaviour of concurrent systems can be compared in various ways that go beyond equivalence. For instance, even classically, (pre-)order-theoretic notions such as simulation or trace inclusion have played a key role in system verification; and beyond two-valued comparisons, there has been long-standing interest in behavioural distances [GiacaloneEA90]. Following recent usage [BeoharEA24], we refer to such more general ways of comparing systems as behavioural conformances. In a nutshell, the contribution of the present work is to provide a generic game-theoretic characterization of behavioural conformances, parametrizing over the system type (given as a functor), the system semantics (given as a graded semantics), and additionally the type of behavioural conformance. Our technical assumption on behavioural conformances is that they form a topological category [AHS90] (essentially equivalently, a CLatâŠ“subscriptCLatsquare-intersection\textbf{CLat}_{\sqcap}CLat start_POSTSUBSCRIPT âŠ“ end_POSTSUBSCRIPT-fibration [DBLP:conf/lics/KomoridaKHKH19]). We present two variants of the game, one where a finite number nğ‘›nitalic_n is determined beforehand and the game is then played for exactly nğ‘›nitalic_n rounds, and one where the game is played for an infinite number of rounds (or until a player gets stuck). Under the assumptions of the framework, we show that the former characterizes the finite-depth behavioural conformance induced by the given graded semantics, while the latter characterizes an infinite-depth behavioural conformance induced from the graded semantics under additional assumptions saying essentially that no behaviour can be observed without taking at least one evolution step in the system. Departing from the most general setup, we subsequently refine the game under the assumption that the toplogical category modelling the behavioural conformance is a category of relational structures [DBLP:conf/calco/FordMS21], which holds, for instance, for behavioural preorders and behavioural (pseudo-)metrics. The coalgebraic codensity games pioneered by Komorida et al. [DBLP:conf/lics/KomoridaKHKH19] are similarly parametrized over the type of behavioural conformances via topological categories / CLatâŠ“subscriptCLatsquare-intersection\textbf{CLat}_{\sqcap}CLat start_POSTSUBSCRIPT âŠ“ end_POSTSUBSCRIPT-fibrations. One key difference with our games is that codensity games so far apply only to the branching-time case, while we are interested primarily in coarser behavioural conformances on generalized linear-time / branching-time spectra. That said, our generic games do apply also in the branching-time case, and then instantiate to games that are markedly different from codensity games. Indeed, our games are, roughly speaking, dual to codensity games in that codensity games work with modal observations on states, while our games concern the way behaviours of states are constructed in an algebraic sense. We apply this framework to a number case studies, obtaining game-theoretic characterizations of classical trace inclusion of LTS; bisimulation toppologies; quantitative similarity of metric LTS; and probabilistic trace semantics. Related Work We have already discussed work on coalgebraic codensity games [DBLP:conf/lics/KomoridaKHKH19]. Similarly, Kupke and Rot [KupkeRot21] give a coalgebraic treatment of coinductive predicates in terms of fibrations, generalizing in particular behavioural distances but focusing on the branching-time setting. By the fixpoint nature of behavioural equivalence, our infinite game relates to some degree to general fixpoint games [BaldanEA19, BaldanEA20]. Our topological version of the powerset functor that appears in the case study on bisimulation topologies owes ideas to the Vietoris topoology (via the use of hit sets), and more broadly to work on Vietoris bisimulations [BezhanishviliEA10]. The treatment of spectra of behavioural metrics via graded semantics goes back to work on characteristic quantitative modal logics [ForsterEA24, ForsterEA23]. This work joins a strand of work on the coalgebraic treatment of behavioural distances (e.g. [BreugelWorrell05, BaldanEA18, WildSchroder22]) and the treatment of spectra of behavioural equivalences via graded semantics [DBLP:conf/calco/MiliusPS15, DBLP:conf/concur/DorschMS19, DBLP:conf/lics/FordMSB022]. Graded semantics essentially subsumes earlier coalgebraic treatments of linear-time equivalences based on Kleisli [HasuoEA07] and Eilenberg-Moore categories [JacobsEA15], respectively. The Kleisli and Eilenberg-Moore setups are alternatively subsumed by an approach based on corecursive algebras [RotEA21]. Spectra of behavioural metrics have been studied in a highly general approach based on Galois connections, which, broadly speaking, subsumes a wide range of examples but leaves more work to concrete instances [BeoharEA23, BeoharEA24]. For the presentation of graded monads on relational structures, we build on work on presenting monads [DBLP:conf/lics/MardarePP16] and graded monads on metric spaces [ForsterEA23] and posets [DBLP:journals/mscs/AdamekFMS21, DBLP:conf/lics/FordMS21] as well as generalizations to categories of relational structures [DBLP:conf/calco/FordMS21, DBLP:phd/dnb/Ford23]."
https://arxiv.org/html/2411.02977v1,Relating Apartness andBranching Bisimulation Gamesâ€ â€ thanks:This research is partially supported by the Royal Society International Exchange grant (IES\R3\223092). The third author was also partially supported by EPSRC NIA grant EP/X019373/1.,"Geuvers and Jacobs (LMCS 2021) formulated the notion of apartness relation on state-based systems modelled as coalgebras. In this context apartness is formally dual to bisimilarity, and gives an explicit proof system for showing that certain states are not bisimilar. In the current paper, we relate apartness to another classical element of the theory of behavioural equivalences: that of turn-based two-player games. Studying both strong and branching bisimilarity, we show that winning configurations for the Spoiler player correspond to apartness proofs, for transition systems that are image-finite (in the case of strong bisimilarity) and finite (in the case of branching bisimilarity).","Bisimilarity is one of the fundamental notions of equivalence [12], encoding when two states of a labelled transition system (LTS) have the same behaviour. Bisimilarity is well studied in the literature from both logical and game-theoretic viewpoints. For instance, the classical Hennessy-Milner characterisation theorem [5] states that two states of an image-finite LTS are bisimilar if and only if they satisfy the same set of modal formulas. Similarly, the well-known result by Stirling [9] states that two states of an LTS are bisimilar if and only if Duplicator has a winning strategy from this pair of states in the Spoiler/Duplicator bisimulation game. These two viewpoints have almost become a standard in the sense that it is expected that similar characterisation results hold, whenever a new notion of behavioural equivalence is proposed. Orthogonally to these logical and game-theoretic viewpoints, in the recent work of Geuvers and Jacobs [4], a dual approach to bisimilarity is postulated in terms of apartness in transition systems. Instead of describing when two states are behaviourally equivalent, as in bisimilarity, the motive of an apartness relation is in showing differences in behaviour. More formally, where bisimilarity is a coinductive characterisation of behavioural equivalence, apartness inductively provide a proof system for constructing witnesses of such differences. Geuvers and Jacobs propose a general coalgebraic formulation of apartness, and show how this yields concrete proof systems for deterministic automata, labelled transition systems and streams. They also develop versions of apartness for weak and branching bisimilarity. This research strand allows us to study connections between modal logic, games and bisimilarity through the lens of apartness. In particular, the Hennessy-Milner theorem says that two states are apart if and only if there is a distinguishing formula, i.e., a formula that holds in one state but not the other. For games, a natural formulation is that two states are apart if and only if Spoiler has a winning strategy. Both results hold by simply observing that bisimilarity is the complement of apartness [4]. However, such an approach is rather implicit: it does not really show how to move between apartness proofs, distinguishing formulas and winning strategies for Spoiler. The relation between apartness proofs and distinguishing formulas is studied in [3], and revisited in an abstract coalgebraic setting in [11]. In the current paper, we focus on the relation between apartness and bisimulation games. One of the main messages of this paper is the following dichotomy: bisimulations correspond to the winning strategies for Duplicator, while apartness relations correspond to winning strategies for Spoiler. We explicitly relate winning configurations for Spoiler to apartness proofs. We first develop the correspondence between apartness relations and Spoiler strategies for strong bisimilarity, and then move on to branching bisimilarity [13], following the game characterisation in [15]. Our proofs rely on the assumption that Duplicator has only finitely many possible moves; this is true under the assumption that the LTS is image-finite, in the case of strong bisimilarity. For branching bisimilarity, since Duplicator can answer with a sequence of Ï„ğœ\tauitalic_Ï„ moves, we make a stronger assumption for our proof strategy to work: that the LTS is finite."
https://arxiv.org/html/2411.03231v2,Formal Logic-guided Robust Federated Learning against Poisoning Attacks,"Federated Learning (FL) offers a promising solution to the privacy concerns associated with centralized Machine Learning (ML) by enabling decentralized, collaborative learning. However, FL is vulnerable to various security threats, including poisoning attacks, where adversarial clients manipulate the training data or model updates to degrade overall model performance. These attacks can introduce critical malfunctions, such as biased predictions or reduced accuracy, undermining the integrity and robustness of the global model. Recognizing this threat, researchers have focused on developing defense mechanisms to counteract poisoning attacks in FL systems. However, existing robust FL methods predominantly focus on computer vision tasks, leaving a gap in addressing the unique challenges of FL with time series data. These tasks, which often involve sequential dependencies and temporal patterns, have been largely overlooked in the context of poisoning attack defenses.In this paper, we present FLORAL, a defense mechanism designed to mitigate poisoning attacks in federated learning for time-series tasks, even in scenarios with heterogeneous client data and a large number of adversarial participants. Based on our investigation of the effectiveness of poisoning attack defenses within the Federated Time Series (FTS) domain, we pinpoint the limitations of mainstream defenses against such attacks. Unlike traditional model-centric defenses, FLORAL leverages logic reasoning to evaluate client trustworthiness by aligning their predictions with global time-series patterns, rather than relying solely on the similarity of client updates. Our approach extracts logical reasoning properties from clients, then hierarchically infers global properties, and uses these to verify client updates. Through formal logic verification, we assess the robustness of each client contribution, identifying deviations indicative of adversarial behavior. Experimental results on two datasets demonstrate the superior performance of our approach compared to existing baseline methods, highlighting its potential to enhance the robustness of FL to time series applications. Notably, FLORAL reduced the prediction error by 93.27% in the best-case scenario compared to the second-best baseline. Our code is available at https://anonymous.4open.science/r/FLORAL-Robust-FTS.","Federated Learning (FL) has emerged as a promising solution that enables using data and computing resources from multiple clients to train a shared model under the orchestration of a central server [33]. In FL, clients use their data to train the model locally and iteratively share the local updates with the server, which then combines the contributions of the participating clients to generate a global update. The security aggregation mechanism and its distinctive distributed training mode render it highly compatible with a wide range of practical applications that have stringent privacy demands [49, 59, 40, 21]. Recently, FL has been demonstrated to be efficient in time-series related tasks [10, 48, 3] to securely share knowledge of similar expertise among different tasks and protect user privacy. Although FL has many notable characteristics and has been successful in many applications [2, 21, 46, 52, 66, 22, 41], recent studies indicate that FL is fundamentally susceptible to adversarial attacks in which malicious clients manipulate the local training process to contaminate the global model [6, 55, 44]. Based on the attackâ€™s goal, adversarial attacks can be broadly classified into untargeted and targeted attacks. The former aims to deteriorate the performance of the global model on all test samples [9, 14]; while the latter focuses on causing the model to generate false predictions following specific objectives of the adversaries [62, 6]. Figure 1: Illustration of logical verification given by benign and malicious clientsâ€™ predictions. The global property here is â–¡(0,10]â¢(y^â¢(t)â‰¤p1)âˆ§â–¡(10,20]â¢(y^â¢(t)â‰¤p2)âˆ§â–¡(20,30]â¢(y^â¢(t)â‰¤p3)âˆ§â–¡(30,40]â¢(y^â¢(t)â‰¤p4)subscriptâ–¡010^ğ‘¦ğ‘¡subscriptğ‘1subscriptâ–¡1020^ğ‘¦ğ‘¡subscriptğ‘2subscriptâ–¡2030^ğ‘¦ğ‘¡subscriptğ‘3subscriptâ–¡3040^ğ‘¦ğ‘¡subscriptğ‘4\square_{(0,10]}(\hat{y}(t)\leq p_{1})\wedge\square_{(10,20]}(\hat{y}(t)\leq p% _{2})\wedge\square_{(20,30]}(\hat{y}(t)\leq p_{3})\wedge\square_{(30,40]}(\hat% {y}(t)\leq p_{4})â–¡ start_POSTSUBSCRIPT ( 0 , 10 ] end_POSTSUBSCRIPT ( over^ start_ARG italic_y end_ARG ( italic_t ) â‰¤ italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) âˆ§ â–¡ start_POSTSUBSCRIPT ( 10 , 20 ] end_POSTSUBSCRIPT ( over^ start_ARG italic_y end_ARG ( italic_t ) â‰¤ italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) âˆ§ â–¡ start_POSTSUBSCRIPT ( 20 , 30 ] end_POSTSUBSCRIPT ( over^ start_ARG italic_y end_ARG ( italic_t ) â‰¤ italic_p start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT ) âˆ§ â–¡ start_POSTSUBSCRIPT ( 30 , 40 ] end_POSTSUBSCRIPT ( over^ start_ARG italic_y end_ARG ( italic_t ) â‰¤ italic_p start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT ). Examples of points violating this property are marked with x. Many efforts have been devoted to dealing with existing threats in FL, which can be roughly classified into two directions: robust FL aggregation [50, 47, 69, 71] and anomaly model detection. The former aims to optimize the aggregation function to limit the effects of polluted updates caused by attackers, whereas the latter attempts to identify and remove malicious updates. For instance, Xie et al. [69] presented a certified defense mechanism based on the clipping and perturbation paradigm. Other approaches focused on new estimators such as coordinate-wise median, Î±ğ›¼\alphaitalic_Î±-trimmed mean [72], and geometric median [50] for aggregation. The main drawback of the methods mentioned above is that polluted updates remain in the global model, reducing the modelâ€™s precision while not mitigating the attack impact [43]. Several methods have been proposed to identify and remove adversarial clients from the aggregation [9, 60, 42, 54, 17, 73]. In [60], the authors proposed a defense mechanism against poisoning attacks in collaborative learning based on the Kğ¾Kitalic_K-Means algorithm. Sattler et al. [57] proposed dividing the clientsâ€™ updates into normal updates and suspicious updates based on their cosine similarities. However, most methods for identifying malicious clients proposed so far follow the majority-based paradigm in that they assume benign local model updates are a majority compared to the malicious ones; thus, polluted updates are supposed to be outliers in the distribution of all updates. Unfortunately, this hypothesis holds only if the data of the clients is IID (independent and identically distributed) and the number of malicious clients is small. Though these two approaches can mitigate poisoning attacks in FL, most of them have been evaluated primarily in the context of computer vision tasks, where image-based datasets dominate the landscape [17, 47, 44, 63]. However, FL applied to time-series data remains underexplored, particularly regarding its vulnerabilities, where adversarial attacks pose a significant threat, much like those observed in image-based datasets [23, 12, 13, 38]. Given the critical applications of time-series analysis, such as in healthcare [5, 36], financial systems [35, 34], and industrial monitoring [31, 30], ensuring the robustness and security of FL models in these scenarios is of paramount importance. Our empirical result demonstrates that these methods are not effective in the scenario of FL with time-series tasks where the data itself reflects a high level of non-iid due to the different locations where it is collected. To fill this gap, we propose FLORAL, a defense mechanism capable of mitigating poisoning attacks against Federated Time Series (FTS) under the most challenging scenarios, i.e., in the presence of heterogeneous client data and a large number of adversarial clients. Our approach is orthogonal to existing model-centric defenses. Instead, we rely on logic-based reasoning to evaluate the reliability of clients based on their behavior and resistance to poisoning attacks. This approach assesses the trustworthiness of clients by aligning their predictions with global time-series patterns. Specifically, we use symbolic reasoning to capture the logical semantics embedded in time series data, which has been shown to improve the learning process and produce more robust models for future predictions [3, 31, 29]. Our FL defense method builds on this by using symbolic reasoning to evaluate diverging intra-task logic patterns in client predictions, allowing for the detection of anomalous clients without relying solely on model similarity. This highlights the enhanced effectiveness of reasoning logic in identifying malicious behaviors in FL. The intuition behind our approach is that, after rounds of training, benign models naturally converge toward the same global objective and share consistent logical reasoning patterns, while malicious models diverge, aiming to manipulate global behavior and thereby exhibit deviant reasoning patterns. The high-level idea is visualized in Figure 1. In centralized FL, we expect the final model GTsubscriptğºğ‘‡G_{T}italic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT to have the minimized error on the local data, with local models converging on a unified objective [49, 27, 24]. In light of these findings, we propose FLORAL, a logic-guided defense for FL which includes three key components. First, we extract logical reasoning properties (e.g., when training models relating to traffic and driving, a dataset measuring vehicle density over time would by expected to reach an upper extreme value of, say, 100) from clients and apply hierarchical clustering to group client updates based on the logical properties of their local models. This allows us to infer the global reasoning properties that represent the systemâ€™s clients based on clustered properties. These formal logic properties rigorous assessment of the consistency and validity of client contributions by identifying deviations from expected model behaviors. This verification-based defense substantially strengthens the security of federated learning in time-series applications, where the risk of undetected adversarial behavior is particularly high due to the sensitive nature of these tasks. By optimizing for the unique challenges of time-series data, our method enhances the robustness of FL systems, providing a more reliable safeguard compared to existing defenses. Experimental results validate the effectiveness of our approach in mitigating poisoning attacks while maintaining high model performance. In summary, our contributions are specified as follows: â€¢ We introduce FLORAL â€” a novel poisoning-resistant defense for FL. It identifies and eliminates suspicious clients that distort the global model using logical reasoning property inference and verification. FLORAL is the first work that, to the best of our knowledge, thoroughly addresses poisoning attacks in FTS, even in the presence of a large number of compromised participants and complicated attack strategies. â€¢ We are the first to study the efficacy of existing robust FL defenses in the context of FTS and pinpoint their limitation when adapted to the time-series domain. â€¢ We conduct comprehensive experiments and in-depth studies on various datasets, FL settings, and attack scenarios to demonstrate the superiority of FLORAL over state-of-the-art defense techniques."
https://arxiv.org/html/2411.01393v1,Thoughts on sub-Turing interactive computability,"The article contains an outline of a possible new direction for Computability Logic, focused on computability without infinite memory or other impossible-to-possess computational resources. The new approach would see such resources as external rather than internal to computing devices. They could or should be accounted for explicitly in the antecedents of logical formulas expressing computational problems.","The present article lies within the framework of computability logic (CoL) â€” an ambitious long-term research project with a beginning but no end, initiated by the author in [9] and actively pursued since then [10, 1, 11, 13, 15, 17]. Among many characterizations of CoLâ€™s formalism would be to say that it potentially provides a medium for communication between humans and computers, something inbetween programming languages on one hand, and the language used by humans in their intellectual activities on the other hand. Just like the former, the language of CoL is formal and thus well understood by machines; and, just like the latter, it can be relatively easily â€œspokenâ€ by humans without any special expertise and training generally required for programmers. The question â€˜what can be computed?â€™ is fundamental to computer science. CoL is about answering this question in a systematic way using logical formalism, with formulas understood as computational problems and logical operators as operations on them. The first basic issue to be clarified here is what a computational problem means. With a few exceptions in the literature, starting from Turing [16], this term usually refers to an entity that is modeled by a very simple interface between a computing agent and its environment, consisting in asking a question (input) and generating an answer (output). In other words, computational problems are understood as functions. This understanding, however, captures only a small part of our broader intuition and the reality of computational problems. Most tasks that real computers perform are interactive and not reducible to simple pairs of input/output events. In such tasks, input/output events, also called observable actions [7] by the computing agent and its environment, can be multiple and interspersed, perhaps taking place throughout the entire process of computation rather than just at the beginning (input) and the end (output) of it. Computability that CoL deals with is interactive computability, and throughout this article by a â€œ(computational) problemâ€ we always mean an interactive computational problem. This concept is formalized in Section 2 below. Section 3 provides a brief informal overview of operations generating complex computational problems from simpler ones, and Section 4 discusses the basic model of interactive computation used in CoL. These sections serve the purpose of establishing a background necessary for understanding the final Section 5, where the reader will find a discussion of a possible new direction into which CoL may branch: a direction that switches the attention of CoL from computability-in-principle (Turing computability) to sub-Turing comutability, where the latter does not assume the presence of (in fact) supernatural resources such as the infinite-capacity tape memory."
https://arxiv.org/html/2411.01188v1,Learning Rules Explaining Interactive Theorem Proving Tactic Prediction,"Formally verifying the correctness of mathematical proofs is more accessible than ever, however, the learning curve remains steep for many of the state-of-the-art interactive theorem provers (ITP). Deriving the most appropriate subsequent proof step, and reasoning about it, given the multitude of possibilities, remains a daunting task for novice users. To improve the situation, several investigations have developed machine learning based guidance for tactic selection. Such approaches struggle to learn non-trivial relationships between the chosen tactic and the structure of the proof state and represent them as symbolic expressions.To address these issues we (i) We represent the problem as an Inductive Logic Programming (ILP) task, (ii) Using the ILP representation we enriched the feature space by encoding additional, computationally expensive properties as background knowledge predicates, (iii) We use this enriched feature space to learn rules explaining when a tactic is applicable to a given proof state, (iv) We use the learned rules to filter the output of an existing tactic selection approach and empirically show improvement over the non-filtering approaches.","Interactive Theorem Provers (ITP), such as Coq [27], Lean [20], and Isabelle [22], are powerful tools that combine human instruction with computer verification to construct formal mathematical proofs, providing a reliable means of certification and ensuring safety in critical applications. These systems operate as follows: the user specifies a goal to prove, the initial proof state. Then the user specifies tactics (an operation transforming a proof state into proof states). Certain tactics close proof states. The proof is complete if there are no remaining open proof states, i.e., the goal has been proved. Given the complexity of ITP systems, a fully automated approach to proving user specified goals is intractable. Numerous investigations have instead focused on providing the user with guidance through tactic suggestion. The methods used in practice by ITP users are statistical machine learning methods such as kğ‘˜kitalic_k-nearest neighbors (kğ‘˜kitalic_k-NN) and naive Bayes [9]. These methods take a goal gğ‘”gitalic_g, select a goal gâ€²superscriptğ‘”â€²g^{\prime}italic_g start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT most similar goal to gğ‘”gitalic_g, and rank the particular tactics relevant for solving gâ€²superscriptğ‘”â€²g^{\prime}italic_g start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT based on their likelihood of solving gğ‘”gitalic_g. Neural network and LLM-based approaches addressing the task include: CoqGym [29] trains tree neural networks to automatically construct proofs for Coq. Thor [14] combines LLMs and external symbolic solvers to search for proofs for Isabelle. LLMs are also applied to synthesising training data to enhance the performance of theorem proving [28]. Despite showing slight improvement in performance during machine learning evaluations, in practice these methods require long training for each new theory, which makes them less useful for day to day proof development. Additionally, they lack interpretability. When a user receives predictions, they may want to know why a particular tactic was chosen over another tactic to better understand what actions they should take in the future. Furthermore, guidance based on statistical learning approaches often requires propositionalisation of features, calculated based on the structure of the abstract syntax tree (AST) of a proof state [30], e.g., there is a path between nodes X and Y in tree T. For complex and precise features, pre-computation is prohibitively expensive. Moreover, logical inference is significantly influenced by the small error margins present in the statistical inferencing mechanisms of LLMs and similar models. Thus, predictions based on chained logical inferences will quickly suffer a loss of predicative accuracy [17]. In contrast to pre-computed features, we represent such features as logic programs and compute them only when needed for learning. For example, we define logic programs for the existence of two particular nodes on a path (of arbitrary length) from the root of the tree as (ğ‘ğ‘ğ‘œğ‘£ğ‘’â¢(Aâ¢Sâ¢T,X,Y)ğ‘ğ‘ğ‘œğ‘£ğ‘’ğ´ğ‘†ğ‘‡ğ‘‹ğ‘Œ\mathit{above}(AST,X,Y)italic_above ( italic_A italic_S italic_T , italic_X , italic_Y )). Below, we present a learned rule for the simplification tactic which states that the tactic is applicable to a proof state when the goal node of the proof state contains a constant above two constructs (also in the goal) which differ. {minted} prolog tac(A,""simpl"") :- goal_node(const,A,B,C), goal_node(construct,A,D,E), goal_above(A,B,D), goal_node(construct,A,F,E),dif(F,D), goal_above(A,B,F). The rules, as presented above, are learned using inductive logic programming (ILP), in particular, Aleph [26]. In addition to providing rules explaining tactic prediction, we use the resulting rules to filter the output of kğ‘˜kitalic_k-NN, in particular, the classifier presented in [3, 9] (Tactician and TacticToe). Essentially, we want to determine whether pâ¢s,râŠ¨ptâŠ¨ğ‘ğ‘ ğ‘Ÿsubscriptğ‘ğ‘¡ps,r\vDash p_{t}italic_p italic_s , italic_r âŠ¨ italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT where pâ¢sğ‘ğ‘ psitalic_p italic_s is a logic program representing the proof state, rğ‘Ÿritalic_r is a learned rule for the tactic tğ‘¡titalic_t, and ptsubscriptğ‘ğ‘¡p_{t}italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT is the head predicate of rğ‘Ÿritalic_r denoting that tğ‘¡titalic_t should be applied to pâ¢sğ‘ğ‘ psitalic_p italic_s. Thus, given the list of recommended tactics by a kğ‘˜kitalic_k-NN classifier, we can further filter this list using the learned rules. Our hypothesis is that features of proof state defined through logic programs can be used to learn rules which can be used to filter the output of a kğ‘˜kitalic_k-NN model to improve accuracy. In addition to improved performance, our approach produces rules to explain the predictions. Consider again the aforementioned rule of simpl that specifies that the goal may be simplified if it contains a constant above two constructors with different positions. Here, the constructor and the constant denote the datatypes of Coqâ€™s terms. The same variable Eğ¸Eitalic_E confirms that the two constructors must correspond to the same identifier in Coq. This rule may suit the Coq structure Sâ¢xâˆ’Sâ¢yğ‘†ğ‘¥ğ‘†ğ‘¦S\ x-S\ yitalic_S italic_x - italic_S italic_y which denotes (1+x)âˆ’(1+y)1ğ‘¥1ğ‘¦(1+x)-(1+y)( 1 + italic_x ) - ( 1 + italic_y ). It can be simplified to xâˆ’yğ‘¥ğ‘¦x-yitalic_x - italic_y. Sğ‘†Sitalic_S denotes a constructor, and âˆ’-- denotes a constant. The first argument of goal_node is a constant that is constrained by us via mode declarations [26]. We use the ILP system Aleph [26] together with a user-defined cost function to evaluate the learned rules on Coqâ€™s standard library. We chose Aleph because it has empirically good results [5]. We refrain from using modern ILP approaches such as Popper [6] as the underlying ASP solvers have difficulty generating models when many variables are required and high-arity definitions are included in the background. We develop representation predicates (goal_node) to efficiently denote the nodes of the AST. We also develop feature predicates (goal_above) which denote the properties of the AST calculated based on the representation predicates. The motivation for developing feature predicates is that propositionalization of it would significantly enlarge the representation making it impractical to use. Our experiments confirm that feature predicates can learn more precise rules (rules with higher F-1 scores [25]) compared to representation predicates. Additionally, the experiments demonstrate that the combination of ILP and kğ‘˜kitalic_k-NN can improve the accuracy of tactic suggestions in Tactician, the main tactic prediction system for Coq. Contributions First, we express the task of predicting the best tactic to apply to the given proof state as an ILP task. Second, using the ILP representation we enriched the feature space by encoding additional, computationally expensive features as background knowledge predicates, allowing us to avoid grounding the features which are computationally expensive. Third, We use this enriched feature space to learn rules explaining when a tactic is applicable to a given proof state and filter the output of an existing tactic selection approach using these rules. Finally, We empirically show improvement over the non-filtering approaches. This is the first time an investigation has considered ILP as a tool for improving tactic suggestion methods for ITPs."
https://arxiv.org/html/2411.02318v2,Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast,"Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources. This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic. LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers. However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic.To address this gap, this paper explores the effectiveness of large language models (LLMs), specifically OpenAIâ€™s GPT models, in generating fully correct specifications based on separation logic for static verification of human-written programs in VeriFast. Our first experiment employed traditional prompt engineering and the second used Chain-of-Thought (CoT) Prompting to identify and address common errors generated across the GPT models. The results indicate that GPT models can successfully generate specifications for verifying heap manipulating code with VeriFast. Furthermore, while CoT prompting significantly reduces syntax errors generated by the GPT models, it does not greatly improve verification error rates compared to prompt engineering.","Auto-active (Hoare-logic styled (Hoare, 1969), static) verifiers, such as Viper (MÃ¼ller et al., 2016), Verus (Lattuada et al., 2023), Dafny (Leino, 2010), Gillian (Fragoso Santos et al., 2020), and VeriFast (Jacobs et al., 2011), are powerful as they can prove the absence of large classes of bugs in code. Ideally, users of such tools need only specify the intended behavior of their code on the code itself (as pre- and postconditions), and the tool will automatically provide feedback on whether or not the code is provably correct with respect to this behavior. In reality, auto-active verifiers require many more auxiliary specifications (such as loop invariants, lemmas, folds, unfolds, etc.) to achieve this goal, burdening their users. In recent years, large language models (LLMs) have been effective in generating code (Chen et al., 2022; Sarsa et al., 2022), test-cases (Deng et al., 2023; Lemieux et al., 2023; Rao et al., 2023; SchÃ¤fer et al., 2023; Wang et al., 2024; Xia et al., 2024), and proofs in theorem provers (proof assistants) (Zheng et al., 2023; Yang et al., 2024; Jiang et al., 2021; Welleck and Saha, 2023; First et al., 2023). LLMs have also been shown to be effective for generating specifications supported by auto-active verifiers (Ma et al., 2024; Kamath et al., 2023; Misu et al., 2024; He et al., 2024; Mugnier et al., 2024). However, related work has not explored whether or not off-the-shelf LLMs can generate specifications based on a permissions logic, such as separation logic (Reynolds, 2002), that can be verified by auto-active verifiers such as VeriFast, Gillian, and Viper. Thanks to such specifications, these verifiers do well at verifying programs that manipulate the heap for both memory safety and functional properties. But, permissions logic based specifications (auxiliary and non-auxiliary) are particularly cumbersome to write, because they must specify the shape of the heap alongside functional constraints. This leads to specifications containing a number of predicates that hide heap details; and as a result, numerous lemmas, folds, unfolds, and special loop invariants that are used to connect the content of these predicates. While such specifications are difficult to reason about, they are written in a patterned way that may be amenable to generation via LLMs. Therefore, this paper evaluates how effective LLMs are at generating specifications that can be verified by VeriFast (Jacobs et al., 2011), which supports separation logic based verification of C and Java code. We specifically target OpenAIâ€™s GPT models in this preliminary work, and employ two different prompt engineering techniques on the models. We develop input-output pairs to prompt the models with and use as ground truth for the modelsâ€™ output, respectively. The input-output pairs are generated from a subset of 150 publicly available, statically verified examples on VeriFastâ€™s Github. The GPT modelsâ€™ output after prompting is inspected manually for correctness compared to the ground truth and results are recorded. Results indicate that GPT models can generate specifications for verification with VeriFast using traditional prompt engineering. When they fail to generate correct specifications, errors range from syntax to deeper verification errors. The second prompting approach based on Chain of Thought Prompting reduced syntax error rates significantly, but not verification error rates."
https://arxiv.org/html/2411.01184v1,Guiding Multi-agent Multi-task Reinforcement Learning by a Hierarchical Framework with Logical Reward Shaping,"Multi-agent hierarchical reinforcement learning (MAHRL) has been studied as an effective means to solve intelligent decision problems in complex and large-scale environments. However, most current MAHRL algorithms follow the traditional way of using reward functions in reinforcement learning, which limits their use to a single task. This study aims to design a multi-agent cooperative algorithm with logic reward shaping (LRS), which uses a more flexible way of setting the rewards, allowing for the effective completion of multi-tasks. LRS uses Linear Temporal Logic (LTL) to express the internal logic relation of subtasks within a complex task. Then, it evaluates whether the subformulae of the LTL expressions are satisfied based on a designed reward structure. This helps agents to learn to effectively complete tasks by adhering to the LTL expressions, thus enhancing the interpretability and credibility of their decisions. To enhance coordination and cooperation among multiple agents, a value iteration technique is designed to evaluate the actions taken by each agent. Based on this evaluation, a reward function is shaped for coordination, which enables each agent to evaluate its status and complete the remaining subtasks through experiential learning. Experiments have been conducted on various types of tasks in the Minecraft-like environment. The results demonstrate that the proposed algorithm can improve the performance of multi-agents when learning to complete multi-tasks.","Deep reinforcement learning (DRL) has shown remarkable success in solving decision-making problems that surpass human-level performance, such as the Atari game [16], chess confrontation [30, 23], and real-time strategy game (RTS) [14]. However, as the environments become increasingly complex, some limitations (such as low learning efficiency and quality) may appear in single-agent DRL systems. To address this, there is an urgent need for multi-agent DRL [9], where multiple agents can solve complex tasks through collaboration [8]. However, multi-agent learning [26] for complex tasks suffers from an exponential growth of the action and state spaces, which is known as the curse of dimensionality [7]. To overcome this, hierarchical reinforcement learning (HRL) [40] has been introduced into multi-agent DRL, giving rise to multi-agent hierarchical reinforcement learning (MAHRL) [44, 11]. I-A The Challenges Most existing MAHRL algorithms follow the traditional way of setting the reward functions, which is not appropriate when multiple tasks need to be completed in complex environments. For instance, in the Minecraft environment, in order to complete the task of making bows and arrows, agents have to find wood to make the body of bows and arrows, spider silk to make bowstrings, as well as feathers to make arrow fletchings. To learn the strategies for completing the task, an appropriate reward is needed for the agent. However, designing a reward function for one task is challenging and difficult to generalize for other tasks [15]. Moreover, in the task of making bows and arrows, if an agent only finds some of the required materials, it can not get a reward; thus, it is challenging for agents to learn how to complete the remaining tasks. In MAHRL, the decision of each agent is typically treated as a black box, making it difficult to understand the logic behind this decision, leading to the untrustworthiness of the system. Hence, it is essential to develop a general and effective way of shaping rewards with a description of the internal logic of the tasks, which helps the agents easily understand the progress of the task and make reasonable decisions. I-B Our Contributions This work explores a flexible approach to setting rewards, called logic reward shaping (LRS), for multi-task learning. LRS uses the Linear Temporal Logic (LTL) [24, 3, 5, 42] to represent environmental tasks, making use of its precise semantics and compact syntax to clearly show the internal logical construction of the tasks and provide guidance for the agents. A reward structure is appropriately defined to give rewards, based on whether LTL expressions are satisfied or not. To promote strategy learning, a technique of value iteration is used to evaluate the actions taken by each agent; after that, a reward shaping mechanism is utilized to shape a reward function, which can accelerate the learning and coordination between agents. The advantage of the LRS mechanism lies in the formalization provided by LTL to specify the constraints of tasks, ensuring that the agentâ€™s decisions meet the specified requirements. Through the feedback of rewards, the agent gradually adjusts its strategy to meet the logical specifications defined in LTL. Consequently, the agent can execute tasks more reliably by adhering to the prescribed logical requirements, thus enhancing the credibility of decisions. Based on LRS, we propose a multi-agent hierarchical reinforcement learning algorithm, dubbed Multi-agent Hierarchy via Logic Reward Shaping (MHLRS). In MHLRS, the agents aim to achieve joint tasks, but each maintains their own individual structures. Each agent has its own meta-controller, which learns sub-goal strategies based on the state of the environment. The experiments on different scenarios show that the proposed MHLRS enhances the cooperative performance of multi-agents in completing multi-tasks. I-C Related Work Learning coordination in multi-agent systems is a challenging task due to increased complexity and the involvement of multiple agents. As a result, many methods and ideas have been proposed to address this issue [34, 43]. Kumar et al. [17] used a master-slave architecture to solve the coordination problem between the agents. A higher-level controller guides the information exchange between decentralized agents. Based on the guidance of the controller, each agent communicates with another agent in each time step, which allows for the exploration of distributed strategies. However, the scalability of this method remains to be improved, since information exchange between agents that are far away becomes more difficult as the number of agents increases. Budhitama et al. [44] also adopted a similar structure that included the commander agent and unit agent models. The commander makes decisions based on environmental states, and then the units execute those decisions. However, the commanderâ€™s global decisions might need to be more suitable for some units. In the proposed MHLRS, each agent has its own meta-controller that proposes suitable sub-goal strategies according to the state of the environment and other agents. Constructed with propositions on environmental states, logical connectors, and temporal operators, LTL [28, 6, 39] can naturally represent the tasks in reinforcement learning. Some studies on using LTL for reinforcement learning [18, 4, 10] have been reported, where different methods have been employed to guide the RL agent to complete various tasks. Toro Icarte et al. [13] used the co-safe LTL expression to solve agentsâ€™ multi-task learning problems and introduced the extension of Q-learning, viz., LTL Progression Off-Policy Learning (LPOPL). To reduce the cost of learning LTL semantics, Vaczipoor et al. [35] introduced an environment-independent LTL pre-training scheme. They utilized a neural network to encode the LTL formulae so that RL agents can learn strategies with task conditions. However, these methods are proposed for single-agent systems rather than multi-agent systems. G. Leon et al. [20] extended LTL from a single-agent framework to a multi-agent framework, and proposed two MARL algorithms that are highly relevant to our work. Nevertheless, traditional Q-learning and DQN frameworks are used, which makes it difficult for agents to explore stable collaborative strategies in dynamic environments. To address this issue, a hierarchical structure is introduced in this work to enable more flexible strategy exploration, accelerate the learning process, and enable agents to adapt faster to task changes in multi-agent systems. Furthermore, logical reward shaping is employed to enhance agentsâ€™ cooperation and improve the interpretability of their decision-making when completing multiple tasks. I-D Organization of the Paper The rest of this article is organized as follows. Section II introduces the preliminaries of reinforcement learning and LTL. Section III describes the algorithm model. Section IV presents the experimental design and results. Finally, the last section summarizes this work with future research directions."
https://arxiv.org/html/2411.00589v1,Early Announcement: Parametricity for GADTs,"Relational parametricity was first introduced by Reynolds for System F. Although System F provides a strong model for the type systems at the core of modern functional programming languages, it lacks features of daily programming practice such as complex data types. In order to reason parametrically about such objects, Reynoldsâ€™ seminal ideas need to be generalized to extensions of System F. Here, we explore such a generalization for the extension of System F by Generalized Algebraic Data Types (GADTs) as found in Haskell. Although GADTs generalize Algebraic Data Types (ADTs) â€” i.e., simple recursive types such as lists, trees, etc. â€” we show that naively extending the parametric treatment of these recursive types is not enough to tackle GADTs. We propose a tentative workaround for this issue, borrowing ideas from the categorical semantics of GADTs known as (functorial) completion. We discuss some applications, as well as some limitations, of this solution.","Relational parametricity [8] is a key technique for reasoning about programs in strongly typed languages. It can be used to enforce invariants guaranteeing strong properties of programs, programming languages, and programming language implementations supporting parametric polymorphism. A polymorphic program is a program that can be applied to arguments and return results of different types; a parametric polymorphic program is a program that is not only polymorphic over all types, but is also defined by the same type-uniform algorithm regardless of the concrete type at which it is applied. Since parametric polymorphic programs cannot perform type-specific operations, the computational behaviors they can exhibit are actually quite constrained. Parametricity was originally put forth by Reynolds [8] for System F [3, 7], the formal calculus at the core of all polymorphic functional languages. It was later popularized as Wadlerâ€™s â€œtheorems for freeâ€ [10], so-called because it allows the deduction of properties of programs in such languages solely from their types, i.e., with no knowledge whatsoever of the text of the programs involved. However, to get interesting free theorems, Wadler actually treats System F extended with built-in lists. Indeed, most of the free theorems in [10] are essentially naturality properties for polymorphic list-processing functions. It is easy to extend the techniques developed in [10] for handling lists to non-list algebraic data types (ADTs). Parametricity for such types can then be used to derive not just naturality (i.e., commutativity) properties, but also results â€” such as proofs of type inhabitance and correctness of the program optimization known as short cut fusion [2] â€” that go beyond simple naturality. In his original formulation, Reynolds gives each type expression of System F a relational interpretation defined inductively. Each type expression Î¦Î¦Î¦roman_Î¦ with type variables Î±â¢â‚,Î±â¢â‚‚,â‹¯,Î±â¢â‚™ğ›¼â‚ğ›¼â‚‚â‹¯ğ›¼italic-â‚™Î±â‚,Î±â‚‚,â‹¯,Î±â‚™italic_Î± â‚ , italic_Î± â‚‚ , â‹¯ , italic_Î± italic_â‚™ thus gives, for each tuple RÂ¯Â¯ğ‘…\overline{R}overÂ¯ start_ARG italic_R end_ARG of relations Râ¢áµ¢ğ‘…italic-áµ¢Ráµ¢italic_R italic_áµ¢ between types Aâ¢áµ¢ğ´italic-áµ¢Aáµ¢italic_A italic_áµ¢ and Bâ¢áµ¢ğµitalic-áµ¢Báµ¢italic_B italic_áµ¢, a relation Î¦^â¢RÂ¯^Î¦Â¯ğ‘…\widehat{Î¦}\,\overline{R}over^ start_ARG roman_Î¦ end_ARG overÂ¯ start_ARG italic_R end_ARG between the type Î¦â¢[AÂ¯/Î±Â¯]Î¦delimited-[]Â¯ğ´Â¯ğ›¼Î¦[\overline{A}/\overline{\alpha}]roman_Î¦ [ overÂ¯ start_ARG italic_A end_ARG / overÂ¯ start_ARG italic_Î± end_ARG ] and Î¦â¢[BÂ¯/Î±Â¯]Î¦delimited-[]Â¯ğµÂ¯ğ›¼Î¦[\overline{B}/\overline{\alpha}]roman_Î¦ [ overÂ¯ start_ARG italic_B end_ARG / overÂ¯ start_ARG italic_Î± end_ARG ]. To capture the intended type-uniformity of System Fâ€™s polymorphic expressions, these relational interpretations are defined in such a way that every function fâ¢:â¢âˆ€â¢Î±Â¯.Î¦â¢â†’â¢Î¨formulae-sequenceğ‘“:âˆ€Â¯ğ›¼Î¦â†’Î¨f\,\mathord{\mathchar 58\relax}\,âˆ€\overline{\alpha}.Î¦\textrightarrow Î¨italic_f : âˆ€ overÂ¯ start_ARG italic_Î± end_ARG . roman_Î¦ â†’ roman_Î¨, where Î¦Î¦Î¦roman_Î¦ and Î¨Î¨Î¨roman_Î¨ are two type expressions in the same type variables Î±Â¯Â¯ğ›¼\overline{\alpha}overÂ¯ start_ARG italic_Î± end_ARG, is parametric in the following sense: for each tuple of relations RÂ¯Â¯ğ‘…\overline{R}overÂ¯ start_ARG italic_R end_ARG, the pairs related by Î¦^â¢RÂ¯^Î¦Â¯ğ‘…\widehat{Î¦}\,\overline{R}over^ start_ARG roman_Î¦ end_ARG overÂ¯ start_ARG italic_R end_ARG are sent by fğ‘“fitalic_f to pairs related by Î¨^â¢RÂ¯^Î¨Â¯ğ‘…\widehat{Î¨}\,\overline{R}over^ start_ARG roman_Î¨ end_ARG overÂ¯ start_ARG italic_R end_ARG. As mentioned above, better approximations of realistic programming languages result from adding built-in data types to System F. Each such added data type induces a type constructor, and this type constructor must also be given a relational interpretation. Wadler [10] considers the case of lists, which we review in detail in Section 2. To add a new inductive data type constructor Tğ‘‡Titalic_T to an ambient parametric language in such a way that parametricity is preserved, the method is always the same: Define its relational interpretation as a (dependent) inductive family T^^ğ‘‡\widehat{T}over^ start_ARG italic_T end_ARG with one data constructor c^^ğ‘\widehat{c}over^ start_ARG italic_c end_ARG for each data constructor cğ‘citalic_c of Tğ‘‡Titalic_T expressing precisely that cğ‘citalic_c is a parametric polymorphic function. The data constructors of such a data typeâ€™s relational interpretation thus make formal the intuitive type-uniformity required of its data constructors by the grammars of languages such as Haskell. The relational interpretation T^^ğ‘‡\widehat{T}over^ start_ARG italic_T end_ARG captures the intuition that, if we regard data types as containers, then two data structures of (two instances of) Tğ‘‡Titalic_T are related by T^â¢R^ğ‘‡ğ‘…\widehat{T}\,Rover^ start_ARG italic_T end_ARG italic_R exactly when the data they store are related by Rğ‘…Ritalic_R. This intuition also requires that T^^ğ‘‡\widehat{T}over^ start_ARG italic_T end_ARG preserves inclusion, i.e., that T^â¢RâŠ†T^â¢S^ğ‘‡ğ‘…^ğ‘‡ğ‘†\widehat{T}\,R\subseteq\widehat{T}\,Sover^ start_ARG italic_T end_ARG italic_R âŠ† over^ start_ARG italic_T end_ARG italic_S whenever RâŠ†Sğ‘…ğ‘†R\subseteq Sitalic_R âŠ† italic_S. Indeed, if two data structures are related by T^â¢R^ğ‘‡ğ‘…\widehat{T}\,Rover^ start_ARG italic_T end_ARG italic_R, then the data they store are related by Rğ‘…Ritalic_R, and thus by Sğ‘†Sitalic_S, so the two data structures must be related by T^â¢S^ğ‘‡ğ‘†\widehat{T}\,Sover^ start_ARG italic_T end_ARG italic_S. Fortunately, for lists and other ADTs, the relational interpretations defined in this way enjoy this crucial inclusion-preservation property. Here, we report our ongoing efforts to add the generalization of ADTs known as Generalized Algebraic Data Types (GADTs) to System F in such a way that parametricity is preserved. In doing so, we insist on understanding GADTs as types of data structures, i.e., as types of containers that can be filled with data. Since this entails in particular that GADTs are inductive data type constructors, we might expect that following the method outlined above will suffice. In Section 2, we show that naively doing so results in relational interpretations of GADTs that do not satisfy the inclusion-preservation property identified at the end of the preceding paragraph. This is problematic: if we are to understand GADTs as types of data structures, then they should certainly satisfy all properties â€” among them the inclusion-preservation property â€” expected of such types. In Section 3, we explore a promising approach to overcoming this issue. This approach consists in defining the relational interpretation of a GADT through that of its completion, an ADT-like type constructor that contains the original GADT. In Section 4 we offer some applications of parametricity for GADTs obtained using our proposed approach. In Section 5 we discuss some issues that arise when making our proposed approach precise. Doing so requires defining a source language (an extension of System F that allows for GADTs), a target language (a dependent type theory strong enough to encode relations), and interpretations of each type of the source language as both a type and a relation in the target language. We point out some difficulties in the design of the target language, and also offer some thoughts on how to resolve them. Throughout the paper, we use an Agda-like syntax to write examples of types and terms of the anticipated target language. We note, however, that this language might end up being very different from Agdaâ€™s type theory. In particular, this early announcement by no means reports on an attempt to formalize our work in a proof assistant. We are not the first to consider parametricity for GADTs. Very recent progress on the subject has been presented in [9]. Sieczkowski et al. construct there a parametric model of an extension of System F supporting GADTs, with the aim of deriving free theorems and representation independence results. However, their work differs drastically from the line of research presented here in several ways. First, the semantics presented by Sieczkowski et al. targets normalization-by-evaluation. By contrast, our work is in no way concerned with such methods. Second, Sieczkowski et al. make essential use of guarded recursion through a universe of step-indexed propositions equipped with a later modality (as exists, e.g., in Iris). By contrast, we are concerned only with structural recursion in this work. Third, Sieczkowski et al. insist on the importance of two particular rules of their type system: discriminability and injectivity of type constructors. By contrast, we are agnostic about such rules, thus accommodating more diverse host languages. Finally, and most importantly, the semantics of Sieczkowski et al. models parametricity for GADTs only in those type indices that are unconstrained, i.e., that can be promoted to parameters. In particular, their approach cannot handle free theorems such as the one presented in Section 4.1 for ğ–²ğ–¾ğ—Šğ–²ğ–¾ğ—Š\operatorname{\sf Seq}sansserif_Seq, since ğ—‰ğ–ºğ—‚ğ—‹ğ—‚ğ—‡ğ—€ğ—‰ğ–ºğ—‚ğ—‹ğ—‚ğ—‡ğ—€\operatorname{\sf pairing}sansserif_pairing has a constrained instance of ğ–²ğ–¾ğ—Šğ–²ğ–¾ğ—Š\operatorname{\sf Seq}sansserif_Seq as return type. By contrast, we not only recognize the non-uniformity of GADTs acknowledged by Sieczkowski et al., but we also recognize that this break of uniformity is governed by uniform type constructors (namely, those constraining the instances of the return types of GADTsâ€™ data constructors), and that this uniformity must be captured by parametric models of the language at play."
https://arxiv.org/html/2411.00149v1,A â€œSymbolicâ€ Representation of Object-Nets,"In this contribution we extend the concept of a Petri net morphism to Elementary Object Systems (Eos). Eos are a nets-within-nets formalism, i.e. we allow the tokens of a Petri net to be Petri nets again. This nested structure has the consequence that even systems defined by very small Petri nets have a quite huge reachability graph. In this contribution we use automorphism to describe symmetries of the Petri net topology. Since these symmetries carry over to markings as well this leads to a condensed state space, too. utomorphism, canonical representation, nets within nets, nets as tokens, state space reductions, symmetry","1 Exploiting Symmetry and Canonical Representations In this paper we study Elementary Object Systems (Eos) [10] a Nets-within-Nets formalism as proposed by Valk [18], i.e., we allow the tokens of a Petri net to be Petri nets again. Due to the nesting structure many of the classical decision problems, like reachability and liveness, become undecidable for Eos. From a complexity perspective we have studied these problems for safe Eos [12, 13, 10] where markings are restricted to sets (i.e., places are either marked or unmarked). More precisely: All problems that are expressible in LTL or CTL, which includes reachability and liveness, are PSpace-complete. This means that in terms of complexity theory safe Eos are no more complex than safe place transition nets (p/t nets). But, a look at the details shows a difference that is pratically relevant: For safe p/t nets it is known that whenever there are nğ‘›nitalic_n places, then the number of reachable states is bounded by Oâ¢(2n)ğ‘‚superscript2ğ‘›O(2^{n})italic_O ( 2 start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ); but, for safe Eos the number of reachable states is in Oâ¢(2(n2))ğ‘‚superscript2superscriptğ‘›2O(2^{(n^{2})})italic_O ( 2 start_POSTSUPERSCRIPT ( italic_n start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT ) â€“ a quite drastic increase. Therefore, our main goal is to derive a condensed state space for Eos, were â€˜condensedâ€™ is expressed as a factorisation modulo an equivalence. In this contribution we extend the concept of a Petri net morphism to Elementary Object Systems (Eos). Eos are a nets-within-nets formalism. Here, we use automorphism to describe symmetries of the Petri net topology. Since these symmetries carry over to markings as well this leads to a condensed state space, too. In our approach these symmetries are introduced very naturally to the representation of the state space using canonical representations of markings. The paper has the following structure. Section 2 introduces base nets-within-nets (Eos). In Section 3 we define a symbolic representation of the Eos structure. The work closes with a conclusion and outlook."
https://arxiv.org/html/2411.00117v1,Openness and Partial Adjacency in One Variable TPTL.,"Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are prominent real-time extensions of Linear Temporal Logic (LTL). MTL extends LTL modalities, Until, ğ–´ğ–´\>\mathsf{U}sansserif_U and Since, ğ–²ğ–²\>\mathsf{S}sansserif_S to family of modalities ğ–´Isubscriptğ–´ğ¼\>\mathsf{U}_{I}sansserif_U start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT and ğ–²Isubscriptğ–²ğ¼\>\mathsf{S}_{I}sansserif_S start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT, respectively, where Iğ¼Iitalic_I is an interval of the form âŸ¨l,uâŸ©ğ‘™ğ‘¢\langle l,u\rangleâŸ¨ italic_l , italic_u âŸ© to express real-time constraints. On the contrary, TPTL extends LTL by real-valued freeze quantification, and constraints over those freeze variables to do the same. It is well known that one variable fragment of TPTL is strictly more expressive than MTL. In general, the satisfiability checking problem for both MTL and TPTL is undecidable. MTL enjoys the benefits of relaxing punctuality. That is, satisfiability checking for Metric Interval Temporal Logic (MITL), a subclass of MTL where the intervals are restricted to be of the form âŸ¨l,uâŸ©ğ‘™ğ‘¢\langle l,u\rangleâŸ¨ italic_l , italic_u âŸ© where l<uğ‘™ğ‘¢l<uitalic_l < italic_u, is decidable with elementary complexity (EXPSPACE complete). Moreover, Partially Punctual Metric Temporal Logic (PMTL), a subclass of MTL where punctual intervals are only allowed in either ğ–´ğ–´\>\mathsf{U}sansserif_U modalities or ğ–²ğ–²\>\mathsf{S}sansserif_S modalities, but not both, is also decidable over finite timed words with non-primitive recursive complexity.In case of TPTL, punctuality can be trivially recovered due to freeze quantifiers and boolean over guards. Hence, we study a more restrictive version of non-punctuality, called Openness. Intuitively, this restriction only allows a property to be specified within timing intervals which are topologically open. We show that even with this restriction, 1-TPTL is undecidable. Our results make a case for a the new refined notion of non-adjacency by Krishna et. al. for getting a decidable fragment of 1-TPTL, called non-adjacency. We extend the notion of non-adjacency to partial adjacency, where the restriction is only applicable in either past or future but not in both directions. We show that partially adjacent 1- TPTL (PA-1-TPTL) is decidable over finite timed words. Moreover, it is strictly more expressive than PMTL, making it the most expressive boolean closed decidable timed logic known in the literature.","Metric Temporal Logic ğ–¬ğ–³ğ–«â¢[ğ–´I,ğ–²I]ğ–¬ğ–³ğ–«subscriptğ–´ğ¼subscriptğ–²ğ¼\mathsf{MTL}[\>\mathsf{U}_{I},\>\mathsf{S}_{I}]sansserif_MTL [ sansserif_U start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT , sansserif_S start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT ] is a well established logic useful for specifying quantitative properties of real-time systems. The main modalities of ğ–¬ğ–³ğ–«ğ–¬ğ–³ğ–«\mathsf{MTL}sansserif_MTL are ğ–´Isubscriptğ–´ğ¼\>\mathsf{U}_{I}sansserif_U start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT (read â€œuntil Iğ¼Iitalic_Iâ€) and ğ–²Isubscriptğ–²ğ¼\>\mathsf{S}_{I}sansserif_S start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT (read â€œsince Iğ¼Iitalic_Iâ€), where Iğ¼Iitalic_I is a time interval with endpoints in â„•â„•\mathbb{N}blackboard_N. These formulae are interpreted over timed behaviours or timed words. For example, a formula aâ¢ğ–´[2,3]â¢bğ‘subscriptğ–´23ğ‘a\>\mathsf{U}_{[2,3]}bitalic_a sansserif_U start_POSTSUBSCRIPT [ 2 , 3 ] end_POSTSUBSCRIPT italic_b is satisfied by a position iğ‘–iitalic_i of a timed word ÏğœŒ\rhoitalic_Ï if and only if there is a position jğ‘—jitalic_j strictly in the future of iğ‘–iitalic_i where bğ‘bitalic_b is true, and at all intermediate positions between iğ‘–iitalic_i and jğ‘—jitalic_j, ağ‘aitalic_a is true; moreover, the difference in the timestamps of iğ‘–iitalic_i and jğ‘—jitalic_j must lie in the interval [2,3]23[2,3][ 2 , 3 ]. Similarly, aâ¢ğ–²[2,3]â¢bğ‘subscriptğ–²23ğ‘a\>\mathsf{S}_{[2,3]}bitalic_a sansserif_S start_POSTSUBSCRIPT [ 2 , 3 ] end_POSTSUBSCRIPT italic_b is true at a point iğ‘–iitalic_i if and only if there is a position jğ‘—jitalic_j strictly in the past of iğ‘–iitalic_i where bğ‘bitalic_b is true, and at all intermediate positions between iğ‘–iitalic_i and jğ‘—jitalic_j, ağ‘aitalic_a is true; further, the difference in the timestamps between iğ‘–iitalic_i and jğ‘—jitalic_j lie in the interval [2,3]23[2,3][ 2 , 3 ]. In their seminal paper, Alur and Henzinger [4] showed that the satisfiability of full ğ–¬ğ–³ğ–«ğ–¬ğ–³ğ–«\mathsf{MTL}sansserif_MTL, with until and since modalities is undecidable even over finite words. This ability to encode undecidable problems is due to the presence of punctual intervals, i.e., intervals of the form [x,x]ğ‘¥ğ‘¥[x,x][ italic_x , italic_x ]. This allows the logic to specify constraints like â€œan event ağ‘aitalic_a occurs exactly after 5 time units, âŠ¤ğ–´[5,5]â¢atopsubscriptğ–´55ğ‘\top\>\mathsf{U}_{[5,5]}aâŠ¤ sansserif_U start_POSTSUBSCRIPT [ 5 , 5 ] end_POSTSUBSCRIPT italic_a.â€ In practice, such exact constraints are not used extensively. Hence, Alur et al. studied the non-punctual fragment of MTL called Metric Interval Temporal Logic (MITL) in [2] [1] where the time intervals used in the until, since modalities are non-punctual, i.e. of the form âŸ¨x,yâŸ©ğ‘¥ğ‘¦\langle x,y\rangleâŸ¨ italic_x , italic_y âŸ© where x<yğ‘¥ğ‘¦x<yitalic_x < italic_y. They show that the satisfiability becomes decidable over finite as well as infinite timed words with EXPSPACE complexity. The satisfiability of the future only fragment of ğ–¬ğ–³ğ–«ğ–¬ğ–³ğ–«\mathsf{MTL}sansserif_MTL, where since modalities are not used (MTL[ğ–´Isubscriptğ–´ğ¼\>\mathsf{U}_{I}sansserif_U start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT]), was open for a long time. Ouaknine and Worrell [16] showed its decidability via a reduction to 1-clock Alternating Timed Automata over finite timed words. A natural extension to both these problems studied in [1][2] [16] is to ask what happens to the decidability and expressiveness of ğ–¬ğ–³ğ–«â¢[ğ–´I,ğ–²nâ¢p]ğ–¬ğ–³ğ–«subscriptğ–´ğ¼subscriptğ–²ğ‘›ğ‘\mathsf{MTL}[\>\mathsf{U}_{I},\>\mathsf{S}_{np}]sansserif_MTL [ sansserif_U start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT , sansserif_S start_POSTSUBSCRIPT italic_n italic_p end_POSTSUBSCRIPT ], subclass of MTL where ğ–²ğ–²\>\mathsf{S}sansserif_S modalities are non-punctual, when interpreted over finite timed words. This was resolved by Krishna et. al. in [9]. Timed Propositional Temporal Logic (TPTL) extends LTL with freeze quantifiers. A freeze quantifier [3][5] has the form x.Ï†formulae-sequenceğ‘¥ğœ‘x.\varphiitalic_x . italic_Ï† with freeze variable xğ‘¥xitalic_x (also called a clock [6][18]). When it is evaluated at a point iğ‘–iitalic_i on a timed word, the time stamp of iğ‘–iitalic_i (say Ï„isubscriptğœğ‘–\tau_{i}italic_Ï„ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT) is frozen or registered in xğ‘¥xitalic_x, and the formula Ï†ğœ‘\varphiitalic_Ï† is evaluated using this value for xğ‘¥xitalic_x. Variable xğ‘¥xitalic_x is used in Ï†ğœ‘\varphiitalic_Ï† in a constraint of the form Tâˆ’xâˆˆIğ‘‡ğ‘¥ğ¼T-x\in Iitalic_T - italic_x âˆˆ italic_I; this constraint, when evaluated at a point jğ‘—jitalic_j, checks if Ï„jâˆ’Ï„iâˆˆIsubscriptğœğ‘—subscriptğœğ‘–ğ¼\tau_{j}-\tau_{i}\in Iitalic_Ï„ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT - italic_Ï„ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_I, where Ï„jsubscriptğœğ‘—\tau_{j}italic_Ï„ start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT is the time stamp at point jğ‘—jitalic_j. Here Tğ‘‡Titalic_T can be seen as a special variable giving the timestamp of the present point. For example, the formula Ï†=â—‡â¢x.(aâˆ§â—‡â¢(bâˆ§Tâˆ’xâˆˆ[1,2]âˆ§â—‡â¢(câˆ§Tâˆ’xâˆˆ[1,2])))formulae-sequenceğœ‘â—‡ğ‘¥ğ‘â—‡ğ‘ğ‘‡ğ‘¥12â—‡ğ‘ğ‘‡ğ‘¥12\varphi=\Diamond x.(a\wedge\Diamond(b\wedge T-x\in[1,2]\wedge\Diamond(c\wedge T% -x\in[1,2])))italic_Ï† = â—‡ italic_x . ( italic_a âˆ§ â—‡ ( italic_b âˆ§ italic_T - italic_x âˆˆ [ 1 , 2 ] âˆ§ â—‡ ( italic_c âˆ§ italic_T - italic_x âˆˆ [ 1 , 2 ] ) ) ) asserts that there is a point iğ‘–iitalic_i in the future where ağ‘aitalic_a holds and in its future there is a bğ‘bitalic_b within interval [1,2]12[1,2][ 1 , 2 ] followed by a cğ‘citalic_c within interval [1,2]12[1,2][ 1 , 2 ] from iğ‘–iitalic_i. The contributions of this paper are two fold: (1) We study the satisfiability checking problem for a restricted fragment of the TPTL that can only specify properties within topologically open timing intervals. We call this fragment as Open TPTL (denoted by ğ–®ğ—‰ğ–³ğ–¯ğ–³ğ–«1superscriptğ–®ğ—‰ğ–³ğ–¯ğ–³ğ–«1\mathsf{OpTPTL}^{1}sansserif_OpTPTL start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT). Notice that the restriction of openness is more restrictive than that of non-punctuality, and with openness punctual guards can not be simulated even with the use of freeze quantifiers and boolean operators. In spite of such a restriction, we show that satisfiability checking of ğ–®ğ—‰ğ–³ğ–¯ğ–³ğ–«1superscriptğ–®ğ—‰ğ–³ğ–¯ğ–³ğ–«1\mathsf{OpTPTL}^{1}sansserif_OpTPTL start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT is as hard as that of 1-ğ–³ğ–¯ğ–³ğ–«ğ–³ğ–¯ğ–³ğ–«\mathsf{TPTL}sansserif_TPTL (i.e. undecidable on infinite words, and decidable with non-primitive recursive lower bound for finite words). This implies that it is something more subtle than just the presence of punctual guards that makes the satisfiability checking problem hard for 1-ğ–³ğ–¯ğ–³ğ–«ğ–³ğ–¯ğ–³ğ–«\mathsf{TPTL}sansserif_TPTL. This makes a strong case for studying non-adjacency of ğ–³ğ–¯ğ–³ğ–«ğ–³ğ–¯ğ–³ğ–«\mathsf{TPTL}sansserif_TPTL. (2) We define the notion of partial adjacency, generalizing the notion of non-adjacency. Here, we allow adjacent guards but only in one direction. We show that Partially Punctual One variable Timed Propositional Temporal Logic (ğ–¯ğ– â¢-â¢ğŸ£â¢-â¢ğ–³ğ–¯ğ–³ğ–«ğ–¯ğ– -1-ğ–³ğ–¯ğ–³ğ–«\mathsf{PA\text{-}1\text{-}TPTL}sansserif_PA - sansserif_1 - sansserif_TPTL) is decidable over finite timed words. Moreover, this logic is the most expressive known decidable subclass of the logic known till date."
https://arxiv.org/html/2411.00025v1,Probabilistic Obstruction Temporal Logic:a Probabilistic Logic to Reason about Dynamic Models,"In this paper, we propose a novel formalism called Probabilistic Obstruction Temporal Logic (POTL), which extends Obstruction Logic (OL) by incorporating probabilistic elements. POTL provides a robust framework for reasoning about the probabilistic behaviors and strategic interactions between attackers and defenders in environments where probabilistic events influence outcomes. We explore the model checking complexity of POTL and demonstrate that it is not higher than that of Probabilistic Computation Tree Logic (PCTL), making it both expressive and computationally feasible for cybersecurity and privacy applications.","Understanding and quantifying uncertainty is essential in cybersecurity, and probability theory offers a robust framework for this purpose, making it particularly valuable for risk analysis. As digital systems grow increasingly complex and dynamic, effectively assessing and managing risks becomes more challenging. Probability theory allows organizations to model the likelihood of various cyber threats, such as hacking attempts, data breaches, and software vulnerabilities, which are inherently uncertain and variable. Cybersecurity professionals can estimate the likelihood of these threats materializing and assess their potential impact on systems by applying probabilistic and non-probabilistic formalisms. Researchers have developed various solutions over the past fifty years, with formal methods emerging as a notable success. These techniques allow for the verification of system correctness by checking if a mathematical model meets the formalized desired behavior. Notably, traditional formal approaches like model checking (Baier and Katoen 2008), initially designed for monolithic systems, have been effectively adapted to manage open and Multi-Agent Systems (MAS). In recent years, the study of MAS has garnered significant attention due to its wide-ranging applications in fields such as cybersecurity, robotics, and distributed computing. MAS consists of two or more interacting agents, each capable of making autonomous decisions. These systems often operate in dynamic and uncertain environments, necessitating robust formal verification techniques to ensure their reliability and correctness. An important logic in the context of MAS is Alternating-time Temporal Logic (ATL) (Alur, Henzinger, and Kupferman 2002). The latter extends CTL (Clarke and Emerson 1981) by introducing strategic modalities, enabling the specification of properties that involve the strategic abilities of agents. ATL can express whether a group of agents can achieve a certain goal regardless of the actions of other agents, making it a powerful tool for reasoning about cooperation and competition in MAS. Another relevant formalism in this area is Obstruction Logic (OL) (Catta, Leneutre, and Malvone 2023b), which focuses on obstructions in two-player games. In OL, one player, called the Demon, can temporarily disable edges in the graph as long as their total weight remains below a specified natural number, thereby preventing the other agent from achieving its temporal goal. As illustrated in their paper, OL can be well-suited for representing cybersecurity problems, where a defender can activate defense mechanisms (by disabling edges) and an attacker aims to access private resources through a sequence of atomic attacks. In this context, a key aspect when performing cybersecurity risk analysis is to assess the likelihood (or probability) of success of the attack scenarios. However, OL did not address this aspect, where no probabilistic concepts were introduced. For the above reasons, in this paper, we present Probabilistic Obstruction Temporal Logic (POTL), a logic that extends OL into a probabilistic context. POTL offers a comprehensive framework for analyzing the probabilistic behaviors and strategic interactions between attackers and defenders in scenarios where probabilistic events influence outcomes. We investigate the model checking complexity of POTL and show that it is comparable to that of Probabilistic Computation Tree Logic, ensuring that POTL remains both expressive and computationally practical for cybersecurity and privacy applications. Structure of the work. The contribution is structured as follows. Theoretical background is presented in Section 2. In Section 3, we present the syntax and the semantics of our new logic, called Probabilistic Obstruction Temporal Logic (POTL). In Section 4, we show our model checking algorithm and prove that the model checking problem for POTL is decidable in polyonimal-time. In section 5, we present an illustrative example related to the cybersecurity analysis. In Section 6, we compare our approach to related work. Finally, Section 7 concludes and presents possible future directions."
https://arxiv.org/html/2411.00431v1,Integrating Fuzzy Logic into Deep Symbolic Regression,"Credit card fraud detection is a critical concern for financial institutions, intensified by the rise of contactless payment technologies. While deep learning models offer high accuracy, their lack of explainability poses significant challenges in financial settings. This paper explores the integration of fuzzy logic into Deep Symbolic Regression (DSR) to enhance both performance and explainability in fraud detection. We investigate the effectiveness of different fuzzy logic implications, specifically Åukasiewicz, GÃ¶del, and Product, in handling the complexity and uncertainty of fraud detection datasets. Our analysis suggest that the Åukasiewicz implication achieves the highest F1-score and overall accuracy, while the Product implication offers a favorable balance between performance and explainability. Despite having a performance lower than state-of-the-art (SOTA) models due to information loss in data transformation, our approach provides novelty and insights into into integrating fuzzy logic into DSR for fraud detection, providing a comprehensive comparison between different implications and methods.","Credit card fraud poses a significant and growing challenge for financial institutions, amplified by the advent of innovative technologies such as contactless payment (Europol, 2021). Global losses due to credit card fraud were estimated at $32.39 billion in 2020 and are projected to exceed $40 billion by 2027 (Nilson, S., 2019). The Covid-19 pandemic further accelerated the shift from cash to cashless transactions, intensifying the issue of credit card fraud. To protect customers from fraudulent activities, banks deploy Fraud Detection Systems (FDS) to automatically flag and block suspicious transactions in real-time. Significant advancements in these systems have been achieved through improvements in data quality and the enhanced use and performance of Artificial Intelligence (AI) and Deep Learning (DL) techniques (Cherif et al., 2023). Although DL has demonstrated exceptional performance in classification accuracy (Alarfaj et al., 2022), a major limitation is its lack of explainability. (Mill et al., 2023). This â€black boxâ€ nature has hindered the adoption of AI in financial settings, where decisions must be transparent and explainable. Explainable Artificial Intelligence (XAI) offers a potential solution to this problem. Despite the growing interest in XAI, the intersection of fraud detection and XAI remains underexplored. Recent efforts have taken various approaches to bridge this gap. One approach employs XAI methods to interpret Machine Learning (ML) models post-training using techniques such as SHAP (Shapley Additive Explanations) or LIME (Local Interpretable Model-Agnostic Explanations), which have shown only modest improvements in user trust (Ji et al., 2021). Another promising approach involves leveraging Symbolic Regression (SR), which seeks to extract closed-form expressions to describe underlying patterns in the data. These expressions are inherently explainable, resolving transparency issues. To advance SR, Petersen et al. (Petersen et al., 2021) combined SR with Reinforcement Learning (RL), resulting in Deep Symbolic Regression (DSR). DSR employs a recurrent neural network (RNN) trained with deep reinforcement learning, where the reward is task-specific, producing expressions tailored to specific problems. These closed-form expressions show high predictive power and transparency, making them a viable solution to many of the previously mentioned issues. DSR utilizes a library of tokens representing features, constants, or mathematical operators to generate expressions. The DSR framework creates a list of tokens subject to constraints, optimizing them using the RNN based on the reward function. An extension to DSR by Visbeek et al. successfully applied DSR to the fraud detection domain, resulting in Deep Symbolic Classification (DSC) (Visbeek et al., 2023). DSC adapts DSR for classification tasks and uses the F1-score as the reward metric, offering competitive predictive performance with improved explainability. In this paper, we propose extensions to the DSR framework by integrating fuzzy logic. Fuzzy logic, based on the fuzzy set theory by Zadeh (Zadeh, 1965), categorizes reasoning into multiple levels, similar to human reasoning. Unlike strict classifications, fuzzy logic handles uncertainty and vagueness, making it suitable for real-world complexities. For instance, a person is not simply tall or short but can manifest varying degrees of tallness. Fuzzy logic facilitates smooth transitions between such degrees. In DSC, the output is a closed-form mathematical expression (Visbeek et al., 2023). Logical implications provide intuitive explanations, since they naturally represent general rules e.g., If transaction amount is high and receiver balance is low then fraud is the case. These expressions are more intuitive as they mirror human reasoning. Various formulas derive fuzzy implications from fuzzy sets, and fuzzy logic provides a natural medium for expressing the vagueness within this logical structure. For instance, vague expressions such as amount being high might have a varying degree of truth from 0 being false, to 1 being absolutely true. This leads us to the main research question: How can we integrate fuzzy logic into deep symbolic regression for fraud detection? To address our main research question, we elaborate on the following specific sub-research questions: (1) What specific fuzzy logic implications are most effective in enhancing the modelâ€™s ability to handle the inherent complexity and uncertainty in fraud detection datasets? (2) What specific choice of fuzzy implication is most effective in DSR? (3) Does the fuzzy logic oriented DSR provide intuitive expressions that are easy to interpret? (4) What is the trade off between the size of the fuzzy logic formula and performance metrics? To assess performance, we compare the proposed framework against current state-of-the-art algorithms as detailed in Table 2. Performance evaluation is conducted using accuracy, which is common in real-life fraud detection, and the F1-score, which addresses the inherent imbalance in credit card fraud data. The popular PaySim dataset is utilized (Alonso Lopez-Rojas et al., 2016), offering a controlled environment for comparison. This synthetically generated dataset contains no privacy concerns, as it lacks personally identifiable information (PII). In addition to performance assessment, the explainability of the rule expressions are evaluated. Furthermore, we employ a Pareto front (Langdon, 1998) to balance predictive performance and explainability, optimizing the complexity of expressions based on the factors and performance, identifying the most suitable expressions for the task."
