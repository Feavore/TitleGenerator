URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.04391v1,Improved Maximin Share Approximations for Choresby Bin Packing,"We study fair division of indivisible chores among nğ‘›nitalic_n agents with additive cost functions using the popular fairness notion of maximin share (MMS). Since MMS allocations do not always exist for more than two agents, the goal has been to improve its approximations and identify interesting special cases where MMS allocations exists. We show the existence of1-out-of-âŒŠ911â¢nâŒ‹911ğ‘›\lfloor\frac{9}{11}n\rfloorâŒŠ divide start_ARG 9 end_ARG start_ARG 11 end_ARG italic_n âŒ‹ MMS allocations, which improves the state-of-the-art factor of 1-out-of-âŒŠ34â¢nâŒ‹34ğ‘›\lfloor\frac{3}{4}n\rfloorâŒŠ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n âŒ‹.MMS allocations for factored instances, which resolves an open question posed by Ebadian et al. (2021).15/13151315/1315 / 13-MMS allocations for personalized bivalued instances, improving the state-of-the-art factor of 13/11131113/1113 / 11.We achieve these results by leveraging the HFFD algorithm of Huang and Lu (2021). Our approach also provides polynomial-time algorithms for computing an MMS allocation for factored instances and a 15/13151315/1315 / 13-MMS allocation for personalized bivalued instances.","Fair division of indivisible tasks (or chores) has garnered significant attention recently due to its applications in various multi-agent settings; see recent surveys (Amanatidis et al., 2023; Liu et al., 2024). The problem is to find a fair partition of a set â„³â„³\mathcal{M}caligraphic_M of mğ‘šmitalic_m indivisible chores among nğ‘›nitalic_n agents with preferences. We assume that each agent iğ‘–iitalic_i has additive preferences represented by the cost functions vi(.)v_{i}(.)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( . ) such that the cost of a set of chores Sğ‘†Sitalic_S is given by viâ¢(S)=âˆ‘câˆˆSviâ¢(c)subscriptğ‘£ğ‘–ğ‘†subscriptğ‘ğ‘†subscriptğ‘£ğ‘–ğ‘v_{i}(S)=\sum_{c\in S}v_{i}(c)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) = âˆ‘ start_POSTSUBSCRIPT italic_c âˆˆ italic_S end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ), where viâ¢(c)subscriptğ‘£ğ‘–ğ‘v_{i}(c)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) represents the cost of chore cğ‘citalic_c for agent iğ‘–iitalic_i. A natural and popular fairness notion in the context of indivisible items is called maximin share (MMS), introduced by Budish (2011). It appears to be also favored by participating agents in real-life experiments (Gates et al., 2020). An agentâ€™s MMS is defined as the minimum cost they can ensure by partitioning all the chores into nğ‘›nitalic_n bundles (one for each agent) and then receiving a bundle with the highest cost. Formally, for a set Sğ‘†Sitalic_S of chores and an integer dğ‘‘ditalic_d, let Î dâ¢(S)subscriptÎ ğ‘‘ğ‘†\Pi_{d}(S)roman_Î  start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_S ) denote the set of all partitions of Sğ‘†Sitalic_S into dğ‘‘ditalic_d bundles. Then, MMSidâ¢(S):=min(S1,â€¦,Sd)âˆˆÎ dâ¢(S)â¡maxjâ¡viâ¢(Sj).assignsuperscriptsubscriptMMSğ‘–ğ‘‘ğ‘†subscriptsubscriptğ‘†1â€¦subscriptğ‘†ğ‘‘subscriptÎ ğ‘‘ğ‘†subscriptğ‘—subscriptğ‘£ğ‘–subscriptğ‘†ğ‘—\text{MMS}_{i}^{d}(S):=\min_{(S_{1},\dots,S_{d})\in\Pi_{d}(S)}\max_{j}v_{i}(S_% {j}).MMS start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ( italic_S ) := roman_min start_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) âˆˆ roman_Î  start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_S ) end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) . Let us denote the MMS of an agent iğ‘–iitalic_i by Î¼isubscriptğœ‡ğ‘–\mu_{i}italic_Î¼ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT := MMS(â„³)in{}_{i}^{n}(\mathcal{M})start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( caligraphic_M ). In an MMS allocation, each agentâ€™s bundle cost does not exceed their MMS. However, for more than two agents, MMS allocations are not guaranteed to exist (Aziz et al., 2017; Feige et al., 2021). Therefore, the focus shifted to exploring approximations of MMS and identifying interesting special classes where MMS allocations can be achieved. Two natural relaxations are multiplicative and ordinal approximations. Î±ğ›¼\alphaitalic_Î±-MMS This approach involves multiplying the MMS by a factor Î±>1ğ›¼1\alpha>1italic_Î± > 1 to raise each agentâ€™s threshold. An allocation is said to be Î±ğ›¼\alphaitalic_Î±-MMS if the cost of each agentâ€™s bundle is at most Î±ğ›¼\alphaitalic_Î± times their MMS. Research has progressed to demonstrate the existence of 13/11131113/1113 / 11-MMS allocations (Huang and Segal-Halevi, 2023). 1111-out-of-dğ‘‘ditalic_d-MMS Another way to adjust the threshold is by considering the MMS when the chores are divided into d<nğ‘‘ğ‘›d<nitalic_d < italic_n bundles. An allocation is 1111-out-of-dğ‘‘ditalic_d-MMS if each agentâ€™s bundle cost is no more than MMS(â„³)id{}_{i}^{d}(\mathcal{M})start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ( caligraphic_M ). This relaxation, initially introduced in (Budish, 2011) for the case of goods, is valued for its resilience to small perturbations in chores costs; see (Hosseini et al., 2021a) for more details. The current best-known factor for which existence is established is 1-out-of-âŒŠ34â¢nâŒ‹34ğ‘›\lfloor\frac{3}{4}n\rfloorâŒŠ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n âŒ‹ (Hosseini et al., 2022). 1.1 Our contributions In this paper, we advance the state-of-the-art on all three fronts: achieving exact MMS, and exploring both multiplicative and ordinal approximations. We establish the existence of â€¢ 1-out-of-âŒŠ911â¢nâŒ‹911ğ‘›\lfloor\frac{9}{11}n\rfloorâŒŠ divide start_ARG 9 end_ARG start_ARG 11 end_ARG italic_n âŒ‹ MMS allocations for all additive instances, improving the current best-known factor of 1-out-of-âŒŠ34â¢nâŒ‹34ğ‘›\lfloor\frac{3}{4}n\rfloorâŒŠ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n âŒ‹. â€¢ MMS allocations for factored instances, where each viâ¢(c)âˆˆ{p1,p2,â€¦,pk}subscriptğ‘£ğ‘–ğ‘subscriptğ‘1subscriptğ‘2â€¦subscriptğ‘ğ‘˜v_{i}(c)\in\{p_{1},p_{2},\dots,p_{k}\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) âˆˆ { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , â€¦ , italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } such that pâ„“=pâ„“âˆ’1â‹…qsubscriptğ‘â„“â‹…subscriptğ‘â„“1ğ‘p_{\ell}=p_{\ell-1}\cdot qitalic_p start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT roman_â„“ - 1 end_POSTSUBSCRIPT â‹… italic_q for some integer q>0ğ‘0q>0italic_q > 0 for each â„“âˆˆ[kâˆ’1]â„“delimited-[]ğ‘˜1\ell\in[k-1]roman_â„“ âˆˆ [ italic_k - 1 ]. Factored instances encompass the well-studied class of weakly lexicographic preferences (Aziz et al., 2019; Hosseini et al., 2021b). This contribution also resolves an open question posed by ebadian2021fairly. â€¢ 15/13151315/1315 / 13-MMS allocations for personalized bivalued instances, where each viâ¢(c)âˆˆ{ai,bi}subscriptğ‘£ğ‘–ğ‘subscriptğ‘ğ‘–subscriptğ‘ğ‘–v_{i}(c)\in\{a_{i},b_{i}\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) âˆˆ { italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } for some positive rational numbers ai,bisubscriptğ‘ğ‘–subscriptğ‘ğ‘–a_{i},b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. They generalize the well-studied bivalued instances, where each viâ¢(c)âˆˆ{a,b}subscriptğ‘£ğ‘–ğ‘ğ‘ğ‘v_{i}(c)\in\{a,b\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) âˆˆ { italic_a , italic_b } for some positive constants a,bğ‘ğ‘a,bitalic_a , italic_b, as the values of ai,bisubscriptğ‘ğ‘–subscriptğ‘ğ‘–a_{i},b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can vary between different agents. This is better than the factor of 13/11131113/1113 / 11 for general instances. We achieve these results by leveraging the Heterogeneous First Fit Decreasing (HFFD) algorithm of Huang and Lu (2021). The HFFD algorithm is a heterogeneous variant of the classic First Fit Decreasing (FFD) algorithm used in the bin packing problem (Johnson, 1973), with an approximation factor proven to be 13/11131113/1113 / 11 (Huang and Segal-Halevi, 2023). As in previous works on MMS, the algorithm is straightforward; however, the novelty and challenge lie in the intricate analysis. For our first result, we extend the analysis of HFFD algorithm in (Huang and Segal-Halevi, 2023) to the ordinal approximation of MMS, providing an improved bound. Our second result demonstrates that the HFFD algorithm is optimal for factored instances. Our third result establishes that the HFFD algorithm attains a factor of 15/13151315/1315 / 13 for personalized bivalued instances through a detailed case analysis. Additionally, our approach results in polynomial-time algorithms for the second and third contributions, enabling the computation of an MMS allocation for factored instances and a 15/13151315/1315 / 13-MMS allocation for personalized bivalued instances in polynomial time. 1.2 Further related work Given the intense study of MMS notion and its variants, we focus on closely related work here. Computing the MMS value of an agent is NP-hard, even for two agents, using a straightforward reduction from the Partition problem. However, a Polynomial Time Approximation Scheme (PTAS) exists for this computation using a PTAS for the job scheduling problem (Hochbaum and Shmoys, 1987). However, for factored instances, MMS values can be computed in polynomial time (Ebadian et al., 2021). MMS allocations are not guaranteed to exist for more than two agents (Aziz et al., 2017; Feige et al., 2021), which has motivated the exploration of approximate MMS allocations to ensure their existence. For multiplicative approximation, a series of works (Aziz et al., 2017; Barman and Krishnamurthy, 2020; Huang and Lu, 2021; Huang and Segal-Halevi, 2023) have established the current best approximation factor of 13/11131113/1113 / 11. On the other hand, for ordinal approximation, research has progressed to show the existence of 1-out-of-âŒŠ34â¢nâŒ‹34ğ‘›\lfloor\frac{3}{4}n\rfloorâŒŠ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n âŒ‹ MMS allocations (Aigner-Horev and Segal-Halevi, 2022; Hosseini et al., 2022). For the special case of (non-personalized) bivalued instances, MMS allocations are known to exist (Feige, 2022). Goods The MMS notion can similarly be defined for the fair division of goods. Like the case of chores, MMS allocations for goods do not always exist (Kurokawa et al., 2018). Extensive research has been dedicated to approximate MMS allocations for goods. Notable works (Amanatidis et al., 2017; Ghodsi et al., 2018; Garg and Taki, 2021; Akrami et al., 2023; Hosseini and Searns, 2021; Hosseini et al., 2021a) have led to a multiplicative approximation factor of 3/4+3/383634338363/4+3/38363 / 4 + 3 / 3836 (Akrami and Garg, 2024) and an ordinal approximation factor of 1-out-of-4â¢âŒŠn/3âŒ‹4ğ‘›34\lfloor n/3\rfloor4 âŒŠ italic_n / 3 âŒ‹ (Akrami et al., 2024)."
https://arxiv.org/html/2411.04204v1,Online Budgeted Matching with General Bids,"Online Budgeted Matching (OBM) is a classic problem with important applications in online advertising, online service matching, revenue management, and beyond. Traditional online algorithms typically assume a small bid setting, where the maximum bid-to-budget ratio (Îºğœ…\kappaitalic_Îº) is infinitesimally small. While recent algorithms have tried to address scenarios with non-small or general bids, they often rely on the Fractional Last Matching (FLM) assumption, which allows for accepting partial bids when the remaining budget is insufficient. This assumption, however, does not hold for many applications with indivisible bids. In this paper, we remove the FLM assumption and tackle the open problem of OBM with general bids. We first establish an upper bound of 1âˆ’Îº1ğœ…1-\kappa1 - italic_Îº on the competitive ratio for any deterministic online algorithm. We then propose a novel meta algorithm, called MetaAd, which reduces to different algorithms with first known provable competitive ratios parameterized by the maximum bid-to-budget ratio Îºâˆˆ[0,1]ğœ…01\kappa\in[0,1]italic_Îº âˆˆ [ 0 , 1 ]. As a by-product, we extend MetaAd to the FLM setting and get provable competitive algorithms. Finally, we apply our competitive analysis to the design learning-augmented algorithms.","Online Budgeted Matching (OBM) with general bids is a fundamental online optimization problem that generalizes to many important settings, such as online bipartite matching and Adwords with equal bids [23]. It has applications in various domains, including online advertising, online resource allocation, and revenue management among others [5, 16, 32]. OBM is defined on a bipartite graph with a set of offline nodes (bidders) and a set of online nodes (queries). The task is to select an available offline node to match with an online query in each round. When an offline node is matched to an online node, a bid value is subtracted from the budget of the offline node, and a reward equal to the consumed budget is obtained. If the remaining budget of an offline node is less than the bid value of an online query, the offline node cannot be matched to the online query. The goal is to maximize the total reward throughout the entire online matching process. OBM is challenging due to the nature of online discrete decisions. Previous works have studied this problem under one of the following two additional assumptions on bids or matching rules: â€¢ Small bids. The small-bid assumption is a special case of general bids corresponding to the maximum bid-budget ratio Îºâ†’0â†’ğœ…0\kappa\to 0italic_Îº â†’ 0. That is, while the bid values can vary arbitrarily, the size of each individual bid is infinitely small compared to each offline nodeâ€™s budget, and there is always enough budget for matching. Under this assumption, the first online algorithm was provided by [24], achieving an optimal competitive ratio of 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e [23]. This competitive ratio has also been attained by subsequent algorithms based on primal-dual techniques [4, 7]. However, the small-bid assumption significantly limits these algorithms for broader applications in practice. Take the application of matching Virtual Machines (VMs) to physical servers as an example. An online VM request typically takes up a non-negligible fraction of the total computing units in a server. â€¢ Fractional last match (FLM). Under FLM, if an offline node has an insufficient budget for an online query, the offline node can still be matched to the query, obtaining a partial reward equal to the remaining budget. Given the limitations of small bids, some recent studies [15, 29, 30] have studied competitive algorithms for OBM with general bids by making the additional assumption of FLM. For example, under FLM, the greedy algorithm (Greedy) achieves a competitive ratio of 1/2121/21 / 2, while other studies [4, 15, 29, 30] aim to achieve a competitive ratio greater than 1/2121/21 / 2 under various settings and/or using randomized algorithms. Although FLM allows fractional matching of a query to an offline node with insufficient budgets, it essentially assumes that any bids are potentially divisible. This assumption may not hold in many real applications, e.g., allocating fractional physical resources to a VM can result in significant performance issues that render the allocation unacceptable, and charging a fractional advertising fee may not be allowed in online advertising. Despite its practical relevance and theoretical importance, OBM with general bids has remained a challenging open problem in the absence of the small-bid and FLM assumptions. Specifically, an offline node may have insufficient budget and cannot be matched to a later query with a large value, potentially causing large sub-optimality in the worst case. This issue does not apply to small bids, as the small-bid setting implies that insufficient budgets will never occur. Additionally, this challenge is alleviated in the FLM setting, where fractional matching in cases of insufficient budgets can reduce sub-optimality. Indeed, removing the small-bid and FLM assumptions fundamentally changes and add significant challenges to the problem of OBM [30]. To further highlight the intrinsic difficulty of OBM with general bids, we formally prove in Proposition 4.1 an upper bound of the competitive ratio, i.e., 1âˆ’Îº1ğœ…1-\kappa1 - italic_Îº, achieved by any deterministic online algorithm, where Îºâˆˆ[0,1]ğœ…01\kappa\in[0,1]italic_Îº âˆˆ [ 0 , 1 ] is the maximum bid-budget ratio. Contributions: In this paper, we address OBM without the small-bid or FLM assumptions and design a meta algorithm called MetaAd, which adapts to different algorithms with provable competitive ratios. To our knowledge, MetaAd is the first provable competitive algorithm for general bids without the FLM assumption. Specifically, MetaAd generates a discounted score for each offline node by a general discounting function, which is then used to select the offline node. The discounting function evaluates the degree of budget insufficiency given a bid-budget ratio Îºâˆˆ[0,1]ğœ…01\kappa\in[0,1]italic_Îº âˆˆ [ 0 , 1 ], addressing the challenge of infeasible matching due to insufficient budgets. Given different discounting functions, MetaAd yields concrete algorithms, and their competitive ratios are derived from Theorem 4.2, established through a novel proof technique. We show that with small bids (i.e., Îºâ†’0â†’ğœ…0\kappa\rightarrow 0italic_Îº â†’ 0), MetaAd recovers the optimal competitive ratio of 1âˆ’1e11ğ‘’1-\frac{1}{e}1 - divide start_ARG 1 end_ARG start_ARG italic_e end_ARG. Furthermore, we show that MetaAd, with discounting functions from the exponential and polynomial function classes, achieves a positive competitive ratio for Îºâˆˆ[0,1)ğœ…01\kappa\in[0,1)italic_Îº âˆˆ [ 0 , 1 ). As an extension, we adapt the design of MetaAd to the FLM setting, resulting in a meta-algorithm with provable competitive ratios for Îºâˆˆ[0,1]ğœ…01\kappa\in[0,1]italic_Îº âˆˆ [ 0 , 1 ] (Theorem 4.3). The framework of MetaAd potentially opens an interesting direction for exploring concrete discounting function designs that yield high competitive ratios for settings both with and without FLM. Finally, we apply our competitive analysis to the design of LOBM, a learning-augmented algorithm for OBM, which enhances average performance while still guaranteeing a competitive ratio (Theorem 5.1). We validate the empirical benefits of MetaAd and LOBM through numerical experiments on the applications of an online movie matching an VM placement on physical servers."
https://arxiv.org/html/2411.03973v1,Temporal Network Creation Games:The Impact of Non-Locality and Terminals,"We live in a world full of networks where our economy, our communication, and even our social life crucially depends on them. These networks typically emerge from the interaction of many entities, which is why researchers study agent-based models of network formation. While traditionally static networks with a fixed set of links were considered, a recent stream of works focuses on networks whose behavior may change over time. In particular, BilÃ² et al. (IJCAI 2023) recently introduced a game-theoretic network formation model that embeds temporal aspects in networks. More precisely, a network is formed by selfish agents corresponding to nodes in a given host network with edges having labels denoting their availability over time. Each agent strategically selects local, i.e., incident, edges to ensure temporal reachability towards everyone at low cost.In this work we set out to explore the impact of two novel conceptual features: agents are no longer restricted to creating incident edges, called the global setting, and agents might only want to ensure that they can reach a subset of the other nodes, called the terminal model. For both, we study the existence, structure, and quality of equilibrium networks. For the terminal model, we prove that many core properties crucially depend on the number of terminals. We also develop a novel tool that allows translating equilibrium constructions from the non-terminal model to the terminal model. For the global setting, we show the surprising result that equilibria in the global and the local model are incomparable and we establish a high lower bound on the Price of Anarchy of the global setting that matches the upper bound of the local model. This shows the counter-intuitive fact that allowing agents more flexibility in edge creation does not improve the quality of equilibrium networks. Finally, in contrast to BilÃ² et al. (IJCAI 2023) where the authors restrict the model to single labels per connection, all of our results hold for the restricted case and the generalized case where every edge can have multiple labels.","Networks are an integral part of our everyday lives, playing a key role in almost every aspect of human existence. Prominent examples include transportation networks (road networks, train tracks, airplaine routes, etc.), communication networks (e.g. the Internet), neural networks (both biological and artificial), biological networks (e.g. protein-protein interaction networks) and many more. With the growing digitization of society, networks, in particular communication networks and (online) social networks, came more and more into the focus of computer science research over the last decades. Many different topics have been studied ranging from the formation of social networks over information diffusion and generating synthetic social networks with real-world properties ; to uncover their underlying geometry . To understand how social networks (and many other types of networks) emerge, one must understand the mechanisms and principles that govern the formation of networks among several non-cooperative agents . This sparked the investigation of game-theoretic network formation models like the Network Creation Game (NCG) . In this model, selfish agents act as nodes of a network which can form costly connections to others to gain a central position in the arising network. In particular, each agent can build connections only locally, i.e., via creating incident edges. Since then, many variations and extensions of this model have been formulated and studied, e.g., variants with non-uniform edge cost ; ; ; , robustness considerations ; ; ; , or geometric aspects ; ; . Although all these models aim to capture time-dependent processes of network formation, in practice, they consider networks that, once formed, are static. This is in contrast to many real-world networks in which temporal aspects play a prominent role. We highlight two motivating examples to make this more evident. One example is the commercial airline network: each time an airline company wants to serve a new route, the company also has to take into account connecting flights with their corresponding departure and arrival times. Planning the routes carefully can ensure reachability: customers can get from any airport to any other airport by taking a sequence of flights, possibly of different airlines, with ascending departure and arrival times. Here, the airlines are the selfish agents that can establish new connections to enable their customers to travel anywhere. For another example, consider the supply chain network of companies that are participating in the production of a particular product X. Assume that company A wants to make product X and sell it. Unless company A owns every part of the production chain (which is highly unlikely in todayâ€™s world), they want to have a connection to other companies in order to send materials and use their means of production that are missing from their production chain. As such, they want to guarantee that they have the logistical infrastructure to send their parts to all other companies participating. But company A may want to combine deliveries. For example, load a vehicle with parts that goes to company B, and then the vehicle loads up parts from company B and moves them to company C. In order for this behaviour to be accurately portrayed, the scheduling of the connections must happen in ascending order (time-wise). Other examples of network formation that include temporal properties are scheduling problems in which jobs have an order of preferences, neural networks where neurons forming a chain are serially activated one after the other, navigation networks in which the travel time of roads changes over time (e.g. due to traffic, or roadblocks), as well as pathways in biological networks which are series of actions among molecules in a cell that lead to a certain product or a change in the cell. These examples motivate, that understanding network formation of temporal networks is crucial. Recently, made a first step towards incorporating temporal aspects into NCGs. In their model, the game is played on an underlying temporal host network that defines the time steps in which the bought edges will be available and each agent can only build incident edges. However, this setting might not be general enough to represent real-world networks. Let us consider our two previous motivating examples again. In the airline route network, the 5th Freedom Right111https://www.icao.int/Pages/freedomsAir.aspx allows airline companies to create connections among countries that do not necessarily include the country the airline is based at. Meanwhile, a company is not interested in reaching every possible destination in other countries, but it mainly serves the hubs and cities which are in high demand for its customers. Finally, an airline company may want to have multiple connections between two countries on each day. Similarly, in the supply chain network, company A will send parts to company B for processing and then may want to use its own transport vehicles to transfer the processed parts to company C afterwards. Additionally, company A may not need to have a connection to the whole supply chain network, but only to particular other companies. Finally, company A may want to establish more than one connection between two factories during a day, due to a multitude of logistical reasons. In this work, we extend the model by to cope with the three raised issues. First, we introduce the terminal model in which nodes want to reach only a subset of the nodes, called terminals. The second addition is the global setting in which we allow each agent to build connections anywhere in the network, i.e., agents can create non-incident edges. Finally, in contrast to where the authors restrict the model to single labels per connection, we study the restricted case and also generalize to multiple labels per connection. Before giving an overview of our contribution, we introduce our model and some notation. 1.1. Model and Notation We first introduce temporal graphs, then we move on to the game-theoretic definition of our model. Temporal Graphs and Temporal Spanners A temporal graph G=(VG,EG,Î»G)ğºsubscriptğ‘‰ğºsubscriptğ¸ğºsubscriptğœ†ğºG=(V_{G},E_{G},\lambda_{G})italic_G = ( italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) consists of a set of nodes VGsubscriptğ‘‰ğºV_{G}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, a set of undirected edges EGâŠ†{{u,v}âŠ†VGâˆ£uâ‰ v}subscriptğ¸ğºconditional-setğ‘¢ğ‘£subscriptğ‘‰ğºğ‘¢ğ‘£E_{G}\subseteq\{\{u,v\}\subseteq V_{G}\mid u\neq v\}italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT âŠ† { { italic_u , italic_v } âŠ† italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT âˆ£ italic_u â‰  italic_v }, and a labeling function Î»G:EGâ†’Pâ¢(â„•)âˆ–âˆ…:subscriptğœ†ğºâ†’subscriptğ¸ğºğ‘ƒâ„•\lambda_{G}\colon E_{G}\rightarrow P(\mathds{N})\setminus\emptysetitalic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT : italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT â†’ italic_P ( blackboard_N ) âˆ– âˆ…, where, for each edge eâˆˆEHğ‘’subscriptğ¸ğ»e\in E_{H}italic_e âˆˆ italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, the term Î»Gâ¢(e)subscriptğœ†ğºğ‘’\lambda_{G}(e)italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) denotes the set of time labels of eğ‘’eitalic_e. Informally, the labeling function Î»Gsubscriptğœ†ğº\lambda_{G}italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT describes the time steps in which edge eğ‘’eitalic_e is available. We sometimes write Î»Gâ¢(e)+csubscriptğœ†ğºğ‘’ğ‘\lambda_{G}(e)+citalic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) + italic_c for some câˆˆâ„•ğ‘â„•c\in\mathds{N}italic_c âˆˆ blackboard_N to denote the set {Î»+câˆ£Î»âˆˆÎ»Gâ¢(e)}conditional-setğœ†ğ‘ğœ†subscriptğœ†ğºğ‘’\{\lambda+c\mid\lambda\in\lambda_{G}(e)\}{ italic_Î» + italic_c âˆ£ italic_Î» âˆˆ italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) }. We define the set Î›GsubscriptÎ›ğº\Lambda_{G}roman_Î› start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT of time edges as the set of tuples of edges and each of their time labels, i.e. Î›Gâ‰”{(e,Î»)âˆ£eâˆˆEG,Î»âˆˆÎ»Gâ¢(e)}â‰”subscriptÎ›ğºconditional-setğ‘’ğœ†formulae-sequenceğ‘’subscriptğ¸ğºğœ†subscriptğœ†ğºğ‘’\Lambda_{G}\coloneqq\{(e,\lambda)\mid e\in E_{G},\lambda\in\lambda_{G}(e)\}roman_Î› start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT â‰” { ( italic_e , italic_Î» ) âˆ£ italic_e âˆˆ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_Î» âˆˆ italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) }. For nodes u,vâˆˆVGğ‘¢ğ‘£subscriptğ‘‰ğºu,v\in V_{G}italic_u , italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and a time label Î»ğœ†\lambdaitalic_Î», we sometimes abuse notation and write (u,v,Î»)ğ‘¢ğ‘£ğœ†(u,v,\lambda)( italic_u , italic_v , italic_Î» ) instead of ({u,v},Î»)ğ‘¢ğ‘£ğœ†(\{u,v\},\lambda)( { italic_u , italic_v } , italic_Î» ). Furthermore, we call the largest label Î»Gmâ¢aâ¢xâ‰”maxeâˆˆEGâ¡maxÎ»âˆˆÎ»Gâ¢(e)â¡Î»â‰”subscriptsuperscriptğœ†ğ‘šğ‘ğ‘¥ğºsubscriptğ‘’subscriptğ¸ğºsubscriptğœ†subscriptğœ†ğºğ‘’ğœ†\lambda^{max}_{G}\coloneqq\max_{e\in E_{G}}\max_{\lambda\in\lambda_{G}(e)}\lambdaitalic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT â‰” roman_max start_POSTSUBSCRIPT italic_e âˆˆ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_Î» âˆˆ italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) end_POSTSUBSCRIPT italic_Î» the lifetime of GğºGitalic_G. If the graph GğºGitalic_G is clear from context, we might omit the subscript GğºGitalic_G to enhance readability. We call a temporal graph simple if there is exactly one time label on each edge. For simple graphs GğºGitalic_G, we sometimes treat Î»Gâ¢(e)subscriptğœ†ğºğ‘’\lambda_{G}(e)italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) as a number instead of a set for easier notation. A temporal path is a sequence of nodes v0,â€¦,vâ„“âˆˆVsubscriptğ‘£0â€¦subscriptğ‘£â„“ğ‘‰v_{0},\dots,v_{\ell}\in Vitalic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , â€¦ , italic_v start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT âˆˆ italic_V that form a path in GğºGitalic_G, such that there exists an increasing sequence of time labels Î»0â‰¤â‹¯â‰¤Î»â„“âˆ’1subscriptğœ†0â‹¯subscriptğœ†â„“1\lambda_{0}\leq\dots\leq\lambda_{\ell-1}italic_Î» start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT â‰¤ â‹¯ â‰¤ italic_Î» start_POSTSUBSCRIPT roman_â„“ - 1 end_POSTSUBSCRIPT with Î»iâˆˆÎ»â¢({vi,vi+1})subscriptğœ†ğ‘–ğœ†subscriptğ‘£ğ‘–subscriptğ‘£ğ‘–1\lambda_{i}\in\lambda(\{v_{i},v_{i+1}\})italic_Î» start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_Î» ( { italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT } ) for every i=0,â€¦,â„“âˆ’1ğ‘–0â€¦â„“1i=0,\ldots,\ell-1italic_i = 0 , â€¦ , roman_â„“ - 1. We define â„“â„“\ellroman_â„“ to be the length of the temporal path. Note that we do not require the labels on the temporal path to increase strictly. We say that a node uâˆˆVGğ‘¢subscriptğ‘‰ğºu\in V_{G}italic_u âˆˆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT reaches vâˆˆVGğ‘£subscriptğ‘‰ğºv\in V_{G}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT if there is a temporal path from uğ‘¢uitalic_u to vğ‘£vitalic_v in GğºGitalic_G. Observe that, even though the edges are undirected, a temporal path from uğ‘¢uitalic_u to vğ‘£vitalic_v does not necessarily imply the existence of a temporal path from vğ‘£vitalic_v to uğ‘¢uitalic_u. Moreover, we define RGâ¢(v)âŠ†VGsubscriptğ‘…ğºğ‘£subscriptğ‘‰ğºR_{G}(v)\subseteq V_{G}italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) âŠ† italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT as the set of nodes that node vğ‘£vitalic_v can reach in GğºGitalic_G. We call the graph GğºGitalic_G temporally connected if RGâ¢(v)=VGsubscriptğ‘…ğºğ‘£subscriptğ‘‰ğºR_{G}(v)=V_{G}italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) = italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT for every node vâˆˆVGğ‘£subscriptğ‘‰ğºv\in V_{G}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. We define a temporal host graph with terminals (or host graph for short) as H=(VH,EH,Î»H,TH)ğ»subscriptğ‘‰ğ»subscriptğ¸ğ»subscriptğœ†ğ»subscriptğ‘‡ğ»H=(V_{H},E_{H},\lambda_{H},T_{H})italic_H = ( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ), where (VH,EH,Î»H)subscriptğ‘‰ğ»subscriptğ¸ğ»subscriptğœ†ğ»(V_{H},E_{H},\lambda_{H})( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) is a complete temporal graph, i.e. EH={{u,v}âŠ†VHâˆ£uâ‰ v}subscriptğ¸ğ»conditional-setğ‘¢ğ‘£subscriptğ‘‰ğ»ğ‘¢ğ‘£E_{H}=\{\{u,v\}\subseteq V_{H}\mid u\neq v\}italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT = { { italic_u , italic_v } âŠ† italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT âˆ£ italic_u â‰  italic_v }, while THâŠ†VHsubscriptğ‘‡ğ»subscriptğ‘‰ğ»T_{H}\subseteq V_{H}italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT âŠ† italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is a set of terminal nodes (or terminals), which is the same for all agents. W.l.o.g., we assume that, for every Ï„=1,â€¦,Î»Hmaxğœ1â€¦superscriptsubscriptğœ†ğ»\tau=1,\ldots,\lambda_{H}^{\max}italic_Ï„ = 1 , â€¦ , italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT, there is an edge eâˆˆEHğ‘’subscriptğ¸ğ»e\in E_{H}italic_e âˆˆ italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT with Ï„âˆˆÎ»Hâ¢(e)ğœsubscriptğœ†ğ»ğ‘’\tau\in\lambda_{H}(e)italic_Ï„ âˆˆ italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_e ).222Indeed, as long as some value of Ï„ğœ\tauitalic_Ï„, with 1â‰¤Ï„â‰¤Î»Hmax1ğœsuperscriptsubscriptğœ†ğ»1\leq\tau\leq\lambda_{H}^{\max}1 â‰¤ italic_Ï„ â‰¤ italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT, is missing, we can decrease by 1 all the edge labels that are strictly larger than Ï„ğœ\tauitalic_Ï„. A temporal subgraph of Hğ»Hitalic_H is a temporal graph GğºGitalic_G such that (VG,EG)subscriptğ‘‰ğºsubscriptğ¸ğº(V_{G},E_{G})( italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) is a subgraph of (VH,EH)subscriptğ‘‰ğ»subscriptğ¸ğ»(V_{H},E_{H})( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) and Î»Gâ¢(e)âŠ†Î»Hâ¢(e)subscriptğœ†ğºğ‘’subscriptğœ†ğ»ğ‘’\lambda_{G}(e)\subseteq\lambda_{H}(e)italic_Î» start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) âŠ† italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_e ) for every eâˆˆEGğ‘’subscriptğ¸ğºe\in E_{G}italic_e âˆˆ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. A terminal spanner of Hğ»Hitalic_H is a temporal subgraph GğºGitalic_G of Hğ»Hitalic_H, with VG=VHsubscriptğ‘‰ğºsubscriptğ‘‰ğ»V_{G}=V_{H}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, where every node reaches all the terminals, i.e., THâŠ†RGâ¢(v)subscriptğ‘‡ğ»subscriptğ‘…ğºğ‘£T_{H}\subseteq R_{G}(v)italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT âŠ† italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) for every vâˆˆVHğ‘£subscriptğ‘‰ğ»v\in V_{H}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. Note that each terminal also needs to reach all the other terminals. Furthermore, for k=nğ‘˜ğ‘›k=nitalic_k = italic_n this is the definition of a temporal spanner. Game-Theoretic Model We introduce the game-theoretic model that we study in this paper. Let Hğ»Hitalic_H be a temporal host graph with terminals that serves as a host graph for our game. Each node vâˆˆVHğ‘£subscriptğ‘‰ğ»v\in V_{H}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is a selfish agent whose strategy SvâŠ†Î›Hsubscriptğ‘†ğ‘£subscriptÎ›ğ»S_{v}\subseteq\Lambda_{H}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT âŠ† roman_Î› start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT corresponds to the set of time edges that agent vğ‘£vitalic_v buys. We distinguish two settings: Global edge-buying, where agents have no restrictions on the time edges they can buy, and local edge-buying where agents can only buy incident time edges, i.e. SvâŠ†{({v,u},Î»)âˆ£uâˆˆVHâˆ–{v}}subscriptğ‘†ğ‘£conditional-setğ‘£ğ‘¢ğœ†ğ‘¢subscriptğ‘‰ğ»ğ‘£S_{v}\subseteq\{(\{v,u\},\lambda)\mid u\in V_{H}\setminus\{v\}\}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT âŠ† { ( { italic_v , italic_u } , italic_Î» ) âˆ£ italic_u âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT âˆ– { italic_v } }. We denote by ğ¬=â‹ƒvâˆˆVH{(v,Sv)}ğ¬subscriptğ‘£subscriptğ‘‰ğ»ğ‘£subscriptğ‘†ğ‘£\mathbf{s}=\bigcup_{v\in V_{H}}\{(v,S_{v})\}bold_s = â‹ƒ start_POSTSUBSCRIPT italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) } the strategy profile and by Gâ¢(ğ¬)ğºğ¬G(\mathbf{s})italic_G ( bold_s ) the temporal graph formed by the agents. Formally, the graph Gâ¢(ğ¬)ğºğ¬G(\mathbf{s})italic_G ( bold_s ) is a temporal subgraph of Hğ»Hitalic_H with VG=VHsubscriptğ‘‰ğºsubscriptğ‘‰ğ»V_{G}=V_{H}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT and Î›Gâ¢(ğ¬)=â‹ƒ(v,Sv)âˆˆğ¬SvsubscriptÎ›ğºğ¬subscriptğ‘£subscriptğ‘†ğ‘£ğ¬subscriptğ‘†ğ‘£\Lambda_{G(\mathbf{s})}=\bigcup_{(v,S_{v})\in\mathbf{s}}S_{v}roman_Î› start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT = â‹ƒ start_POSTSUBSCRIPT ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) âˆˆ bold_s end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT. Note that EGâ¢(ğ¬)subscriptğ¸ğºğ¬E_{G(\mathbf{s})}italic_E start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT and Î»Gâ¢(ğ¬)subscriptğœ†ğºğ¬\lambda_{G(\mathbf{s})}italic_Î» start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT are implicitly defined when Î›Gâ¢(ğ¬)subscriptÎ›ğºğ¬\Lambda_{G(\mathbf{s})}roman_Î› start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT is known. In figures, we sometimes display edges as directed to illustrate the edge ownership. Such edges are bought by the node they originate in and can still be used in both direction for the purpose of temporal reachability. In the global setting this simplification does not always work. In this case we write onto the edge who buys it. For simple temporal graphs we sometimes talk about buying edges instead of time edges as they are equivalent in this case. Each agent vâˆˆVHğ‘£subscriptğ‘‰ğ»v\in V_{H}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT aims at reaching all terminals while buying as few time edges as possible. Formally, agent vğ‘£vitalic_v wants to minimize its costs given by cHâ¢(v,ğ¬)subscriptğ‘ğ»ğ‘£ğ¬\displaystyle c_{H}(v,\mathbf{s})italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ) =|Sv|+Câ‹…|Tâˆ–RGâ¢(ğ¬)â¢(v)|.absentsubscriptğ‘†ğ‘£â‹…ğ¶ğ‘‡subscriptğ‘…ğºğ¬ğ‘£\displaystyle=|S_{v}|+C\cdot|T\setminus R_{G(\mathbf{s})}(v)|.= | italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT | + italic_C â‹… | italic_T âˆ– italic_R start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT ( italic_v ) | . where C>1ğ¶1C>1italic_C > 1 is a large constant ensuring that reaching any terminal is more beneficial than not buying a single edge. Indeed, as Hğ»Hitalic_H is a complete temporal graph, each agent vğ‘£vitalic_v can always reach all terminals in THsubscriptğ‘‡ğ»T_{H}italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT by buying, for example, an arbitrary time edge for each edge of the form {v,u}ğ‘£ğ‘¢\{v,u\}{ italic_v , italic_u }, with uâˆˆTHğ‘¢subscriptğ‘‡ğ»u\in T_{H}italic_u âˆˆ italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. We call the defined models global edge-buying kğ‘˜kitalic_k-terminal Temporal Network Creation Game (global kğ‘˜kitalic_k-tNCG) and local edge-buying kğ‘˜kitalic_k-terminal Temporal Network Creation Game (local kğ‘˜kitalic_k-tNCG), respectively. Before defining the solution concepts, we need some more notation regarding strategies. Let ğ¬ğ¬\mathbf{s}bold_s be a strategy profile and consider any agent vâˆˆVHğ‘£subscriptğ‘‰ğ»v\in V_{H}italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. We define ğ¬âˆ’vâ‰”ğ¬âˆ–{(v,Sv)}â‰”subscriptğ¬ğ‘£ğ¬ğ‘£subscriptğ‘†ğ‘£\mathbf{s}_{-v}\coloneqq\mathbf{s}\setminus\{(v,S_{v})\}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT â‰” bold_s âˆ– { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) } as the strategy profile without the strategy of agent vğ‘£vitalic_v. Now, consider an alternative strategy Svâ€²â‰ Svsuperscriptsubscriptğ‘†ğ‘£â€²subscriptğ‘†ğ‘£S_{v}^{\prime}\neq S_{v}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT â‰  italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT for agent vğ‘£vitalic_v. We denote by ğ¬âˆ’vâˆªSvâ€²subscriptğ¬ğ‘£superscriptsubscriptğ‘†ğ‘£â€²\mathbf{s}_{-v}\cup S_{v}^{\prime}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT âˆª italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT the strategy profile ğ¬âˆ’vâˆª{(v,Svâ€²)}subscriptğ¬ğ‘£ğ‘£superscriptsubscriptğ‘†ğ‘£â€²\mathbf{s}_{-v}\cup\{(v,S_{v}^{\prime})\}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT âˆª { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) }. If cHâ¢(v,ğ¬âˆ’vâˆªSvâ€²)<cHâ¢(v,ğ¬)subscriptğ‘ğ»ğ‘£subscriptğ¬ğ‘£superscriptsubscriptğ‘†ğ‘£â€²subscriptğ‘ğ»ğ‘£ğ¬c_{H}(v,\mathbf{s}_{-v}\cup S_{v}^{\prime})<c_{H}(v,\mathbf{s})italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT âˆª italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) < italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ), we say that ğ¬âˆ’vâˆªSvâ€²subscriptğ¬ğ‘£superscriptsubscriptğ‘†ğ‘£â€²\mathbf{s}_{-v}\cup S_{v}^{\prime}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT âˆª italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT is an improving response for vğ‘£vitalic_v (w.r.t. ğ¬ğ¬\mathbf{s}bold_s). If additionally, the strategies Svsubscriptğ‘†ğ‘£S_{v}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT and Svâ€²superscriptsubscriptğ‘†ğ‘£â€²S_{v}^{\prime}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT differ by at most one element (i.e. vğ‘£vitalic_v either adds or removes a single time edge), we call this a greedy improving response333Note that, in the literature , a greedy improving response also allows a swap, i.e. removing one edge and adding one edge simultaneously. However, in our game, every improving response consisting of a swap also implies an improving response that only adds an edge and omits the remove part. This is because a swap is an improving response for an agent only when the number of reached terminals increases. This means, we can disregard swaps for our definition of greedy improving responses.. We call ğ¬ğ¬\mathbf{s}bold_s a best response of agent vğ‘£vitalic_v (resp., a greedy best response) if there is no improving response (resp., greedy improving response) for agent vğ‘£vitalic_v. We can now introduce our solution concepts. A strategy profile ğ¬ğ¬\mathbf{s}bold_s is a Pure Nash Equilibrium (NE) (resp., Greedy Equilibrium (GE)) if no agent has an improving response (resp., greedy improving response). As every greedy improving response is also an improving response, we have that every NE is also a GE. Furthermore, every NE (and thus every GE) guarantees pairwise disjoint strategies, since any agent can trivially remove the intersection of its strategy and some other agentâ€™s strategy without affecting its reachability. Moreover, our definition of the cost function directly implies that the created graph Gâ¢(ğ¬)ğºğ¬G(\mathbf{s})italic_G ( bold_s ) must be a terminal spanner. Lastly, we introduce a measure for the well-being of all agents combined. Let Hğ»Hitalic_H be a host graph and let ğ¬ğ¬\mathbf{s}bold_s be any strategy profile. The social cost of ğ¬ğ¬\mathbf{s}bold_s on Hğ»Hitalic_H is then defined as SCHâ¡(ğ¬)=âˆ‘vâˆˆVHcHâ¢(v,ğ¬).subscriptSCğ»ğ¬subscriptğ‘£subscriptğ‘‰ğ»subscriptğ‘ğ»ğ‘£ğ¬\displaystyle\operatorname{SC}_{H}(\mathbf{s})=\sum_{v\in V_{H}}c_{H}(v,% \mathbf{s}).roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) = âˆ‘ start_POSTSUBSCRIPT italic_v âˆˆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ) . Note that SCHâ¡(ğ¬)=|Î›Gâ¢(ğ¬)|subscriptSCğ»ğ¬subscriptÎ›ğºğ¬\operatorname{SC}_{H}(\mathbf{s})=|\Lambda_{G(\mathbf{s})}|roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) = | roman_Î› start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT | for every NE or GE ğ¬ğ¬\mathbf{s}bold_s. A strategy profile of minimum social cost for the given host graph Hğ»Hitalic_H is called social optimum and denoted as ğ¬Hâˆ—superscriptsubscriptğ¬ğ»\mathbf{s}_{H}^{*}bold_s start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT. When considering the efficiency of equilibria, we will compare their social costs to the social optimum. For n,kâˆˆâ„•ğ‘›ğ‘˜â„•n,k\in\mathds{N}italic_n , italic_k âˆˆ blackboard_N with kâ‰¤nğ‘˜ğ‘›k\leq nitalic_k â‰¤ italic_n, let â„‹n,ksubscriptâ„‹ğ‘›ğ‘˜\mathcal{H}_{n,k}caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT be the set of all host graphs containing nğ‘›nitalic_n nodes and kğ‘˜kitalic_k terminals. Furthermore, for a host graph Hğ»Hitalic_H, let ğ–­ğ–¤Hğ—…ğ—ˆsubscriptsuperscriptğ–­ğ–¤ğ—…ğ—ˆğ»{\sf NE}^{\sf lo}_{H}sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, ğ–­ğ–¤Hğ—€ğ—…subscriptsuperscriptğ–­ğ–¤ğ—€ğ—…ğ»{\sf NE}^{\sf gl}_{H}sansserif_NE start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, ğ–¦ğ–¤Hğ—…ğ—ˆsubscriptsuperscriptğ–¦ğ–¤ğ—…ğ—ˆğ»{\sf GE}^{\sf lo}_{H}sansserif_GE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT and ğ–¦ğ–¤Hğ—€ğ—…subscriptsuperscriptğ–¦ğ–¤ğ—€ğ—…ğ»{\sf GE}^{\sf gl}_{H}sansserif_GE start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT be the sets of Nash Equilibria and Greedy Equilibria in the local edge-buying and the global edge-buying setting, respectively. We define the Price of Anarchy (PoA) for the local edge-buying setting with respect to Nash Equilibria as the ratio of the socially worst equilibrium and the social optimum ğ–¯ğ—ˆğ– ğ–­ğ–¤ğ—…ğ—ˆâ¢(n,k)â‰”maxHâˆˆâ„‹n,kâ¡maxğ¬âˆˆğ–­ğ–¤Hğ—…ğ—ˆâ¡SCHâ¡(ğ¬)SCHâ¡(sHâˆ—).â‰”subscriptsuperscriptğ–¯ğ—ˆğ– ğ—…ğ—ˆğ–­ğ–¤ğ‘›ğ‘˜subscriptğ»subscriptâ„‹ğ‘›ğ‘˜subscriptğ¬subscriptsuperscriptğ–­ğ–¤ğ—…ğ—ˆğ»subscriptSCğ»ğ¬subscriptSCğ»subscriptsuperscriptğ‘ ğ»\displaystyle{\sf PoA}^{\sf lo}_{\sf NE}(n,k)\coloneqq\max_{H\in\mathcal{H}_{n% ,k}}\max_{\mathbf{s}\in{\sf NE}^{\sf lo}_{H}}\frac{\operatorname{SC}_{H}(% \mathbf{s})}{\operatorname{SC}_{H}(s^{*}_{H})}.sansserif_PoA start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT ( italic_n , italic_k ) â‰” roman_max start_POSTSUBSCRIPT italic_H âˆˆ caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT bold_s âˆˆ sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) end_ARG start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_s start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) end_ARG . We define ğ–¯ğ—ˆğ– ğ–­ğ–¤ğ—€ğ—…subscriptsuperscriptğ–¯ğ—ˆğ– ğ—€ğ—…ğ–­ğ–¤{\sf PoA}^{\sf gl}_{\sf NE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT, ğ–¯ğ—ˆğ– ğ–¦ğ–¤ğ—…ğ—ˆsubscriptsuperscriptğ–¯ğ—ˆğ– ğ—…ğ—ˆğ–¦ğ–¤{\sf PoA}^{\sf lo}_{\sf GE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT, and ğ–¯ğ—ˆğ– ğ–¦ğ–¤ğ—€ğ—…subscriptsuperscriptğ–¯ğ—ˆğ– ğ—€ğ—…ğ–¦ğ–¤{\sf PoA}^{\sf gl}_{\sf GE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT analogously. If a result holds for both settings (local and global), we omit the superscript. If a result holds for both GE and NE, we omit the subscript. Lastly, we define the Price of Stability as ğ–¯ğ—ˆğ–²ğ–­ğ–¤ğ—…ğ—ˆâ¢(n,k)â‰”maxHâˆˆâ„‹n,kâ¡minğ¬âˆˆğ–­ğ–¤Hğ—…ğ—ˆâ¡SCHâ¡(ğ¬)SCHâ¡(sHâˆ—).â‰”subscriptsuperscriptğ–¯ğ—ˆğ–²ğ—…ğ—ˆğ–­ğ–¤ğ‘›ğ‘˜subscriptğ»subscriptâ„‹ğ‘›ğ‘˜subscriptğ¬subscriptsuperscriptğ–­ğ–¤ğ—…ğ—ˆğ»subscriptSCğ»ğ¬subscriptSCğ»subscriptsuperscriptğ‘ ğ»\displaystyle{\sf PoS}^{\sf lo}_{\sf NE}(n,k)\coloneqq\max_{H\in\mathcal{H}_{n% ,k}}\min_{\mathbf{s}\in{\sf NE}^{\sf lo}_{H}}\frac{\operatorname{SC}_{H}(% \mathbf{s})}{\operatorname{SC}_{H}(s^{*}_{H})}.sansserif_PoS start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT ( italic_n , italic_k ) â‰” roman_max start_POSTSUBSCRIPT italic_H âˆˆ caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_min start_POSTSUBSCRIPT bold_s âˆˆ sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) end_ARG start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_s start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) end_ARG . Again, we define ğ–¯ğ—ˆğ–²ğ–­ğ–¤ğ—€ğ—…subscriptsuperscriptğ–¯ğ—ˆğ–²ğ—€ğ—…ğ–­ğ–¤{\sf PoS}^{\sf gl}_{\sf NE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT, ğ–¯ğ—ˆğ–²ğ–¦ğ–¤ğ—…ğ—ˆsubscriptsuperscriptğ–¯ğ—ˆğ–²ğ—…ğ—ˆğ–¦ğ–¤{\sf PoS}^{\sf lo}_{\sf GE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT, and ğ–¯ğ—ˆğ–²ğ–¦ğ–¤ğ—€ğ—…subscriptsuperscriptğ–¯ğ—ˆğ–²ğ—€ğ—…ğ–¦ğ–¤{\sf PoS}^{\sf gl}_{\sf GE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT analogously. 1.2. Our Contribution (local nğ‘›nitalic_n-)TNCG local kğ‘˜kitalic_k-TNCG global kğ‘˜kitalic_k-TNCG Optimum min temporal spanner min terminal spanner min terminal spanner Equilibria Î»mâ¢aâ¢x=2::superscriptğœ†ğ‘šğ‘ğ‘¥2absent\lambda^{max}=2\colonitalic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree mâ‰¤6â¢n32ğ‘š6superscriptğ‘›32m\leq\sqrt{6}n^{\frac{3}{2}}italic_m â‰¤ square-root start_ARG 6 end_ARG italic_n start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT Î»mâ¢aâ¢x=2::superscriptğœ†ğ‘šğ‘ğ‘¥2absent\lambda^{max}=2\colonitalic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree [2] k=2::ğ‘˜2absentk=2\colonitalic_k = 2 :exists [2] mâ‰¤6â¢kâ¢n+nğ‘š6ğ‘˜ğ‘›ğ‘›m\leq\sqrt{6k}n+nitalic_m â‰¤ square-root start_ARG 6 italic_k end_ARG italic_n + italic_n [3] Î»mâ¢aâ¢x=2::superscriptğœ†ğ‘šğ‘ğ‘¥2absent\lambda^{max}=2\colonitalic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree [2] k=2::ğ‘˜2absentk=2\colonitalic_k = 2 :exists [2] GE: exists [2.2] PoA ğ’ªâ¢(n)ğ’ªğ‘›\mathcal{O}(\sqrt{n})caligraphic_O ( square-root start_ARG italic_n end_ARG ) ğ’ªâ¢(Î»mâ¢aâ¢x)ğ’ªsuperscriptğœ†ğ‘šğ‘ğ‘¥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) Î©â¢(logâ¡n)Î©ğ‘›\Omega(\log n)roman_Î© ( roman_log italic_n ) ğ–¯ğ—ˆğ– ğ–¦ğ–¤â‰¤ğ’ªâ¢(logâ¡(n))â¢ğ–¯ğ—ˆğ– ğ–­ğ–¤subscriptğ–¯ğ—ˆğ– ğ–¦ğ–¤ğ’ªğ‘›subscriptğ–¯ğ—ˆğ– ğ–­ğ–¤{\sf PoA}_{\sf GE}\leq\mathcal{O}(\log(n)){\sf PoA}_{\sf NE}sansserif_PoA start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT â‰¤ caligraphic_O ( roman_log ( italic_n ) ) sansserif_PoA start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT ğ’ªâ¢(k)ğ’ªğ‘˜\mathcal{O}(\sqrt{k})caligraphic_O ( square-root start_ARG italic_k end_ARG ) [3] ğ’ªâ¢(Î»mâ¢aâ¢x)ğ’ªsuperscriptğœ†ğ‘šğ‘ğ‘¥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) [3] Î©â¢(logâ¡k)Î©ğ‘˜\Omega(\log k)roman_Î© ( roman_log italic_k ) [3] ğ’ªâ¢(k)ğ’ªğ‘˜\mathcal{O}(k)caligraphic_O ( italic_k ) [3] ğ’ªâ¢(Î»mâ¢aâ¢x)ğ’ªsuperscriptğœ†ğ‘šğ‘ğ‘¥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) [3] Î©â¢(k)Î©ğ‘˜\Omega(\sqrt{k})roman_Î© ( square-root start_ARG italic_k end_ARG ) [3] ğ–¯ğ—ˆğ– ğ–¦ğ–¤âˆˆÎ˜â¢(k)subscriptğ–¯ğ—ˆğ– ğ–¦ğ–¤Î˜ğ‘˜{\sf PoA}_{\sf GE}\in\Theta(k)sansserif_PoA start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT âˆˆ roman_Î˜ ( italic_k )[3,3] PoS ? ? 1 (for GE) [3] Table 1. An overview of our results (yellow) and comparison with the existing results from . Here, nğ‘›nitalic_n is the number of nodes, mğ‘šmitalic_m the number of (time) edges, kğ‘˜kitalic_k the number of terminals, and Î»mâ¢aâ¢xsuperscriptğœ†ğ‘šğ‘ğ‘¥\lambda^{max}italic_Î» start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT the largest label in the host graph. The main contribution of this work is the generalization of the model introduced by and its game-theoretic analysis. We introduce the concepts of terminals, global edge-buying and multiple labels. To the best of our knowledge terminals have not been considered yet on any network creation model. While the terminal version is just a generalization of the normal model, we show that the global edge-buying leads to a completely different model with an incomparable set of equilibrium graphs. Our results for the generalized model work for both single label graphs and multi label graphs. Note that our techniques can be used to extend the results of to the multi label model. Table 1 gives an overview of our results in comparison with the results of . In Section 2, we study the structure and properties of equilibria. First, we introduce a special kind of graph product, see Section 2, that allows us to take any two host networks and respective equilibria and construct a new host graph together with a new equilibrium. This can then be used to construct lower bound examples for the PoA for a wide range of numbers of nodes nğ‘›nitalic_n and numbers of terminals kğ‘˜kitalic_k by constructing only a few initial equilibria. Additionally, we show that, in the local setting, many structural properties of equilibria and bounds on the price of anarchy derived by that seemed to be dependent on the number of nodes in the graph are actually dependent on the number of terminals instead. Moreover, we show that for two terminals in the local and global setting, Greedy and Nash Equilibria always exist. We also show that for the global setting, Greedy Equilibrium graphs are exactly the set of inclusion minimal temporal spanners. We conclude the section by showing that the set of equilibrium graphs in the global setting are incomparable to the ones from the local setting. In Section 3, we analyze the efficiency of equilibria. For the global setting, many results carry over from the local setting but there are notable differences. Our findings show that allowing the agents to buy non-incident edges does not improve the efficiency of equilibria but in fact might make them even worse. For the case of Greedy Equilibria, we show that the PoA in the global setting is in Î©â¢(k)Î©ğ‘˜\Omega(k)roman_Î© ( italic_k ), in contrast to the upper bound of Oâ¢(k)ğ‘‚ğ‘˜O(\sqrt{k})italic_O ( square-root start_ARG italic_k end_ARG ) that exists for the local setting. We also show that for Nash Equilibria, the PoA is in ğ’ªâ¢(k)ğ’ªğ‘˜\mathcal{O}(\sqrt{k})caligraphic_O ( square-root start_ARG italic_k end_ARG ) in the local setting, while it is in Î©â¢(k)Î©ğ‘˜\Omega(\sqrt{k})roman_Î© ( square-root start_ARG italic_k end_ARG ) for the global setting. While it is still possible that those bounds match asymptotically, we conjecture that the actual PoA is much closer to the lower bound of Î©â¢(logâ¡k)Î©ğ‘˜\Omega(\log k)roman_Î© ( roman_log italic_k ) in the local setting. Simple Host Graphs As mentioned before, all our results also hold for the special case where the host graph is a simple temporal graph, i.e. every edge has exactly one time label. For all results from Section 2 to Figure 2 this is true since given simple host graphs, the constructions in turn admit simple host graphs. All remaining results are either general upper bounds/statements, and therefore, they also hold for the special case of simple graphs or constructions that are already simple graphs. 1.3. Related Work As mentioned in the introduction, this paper extends the temporal network creation game proposed by , which studies the all-pairs reachability in the local edge-buying model. In particular, in , the authors first prove the existence of NE for host graphs with lifetime Î»Hmax=2superscriptsubscriptğœ†ğ»2\lambda_{H}^{\max}=2italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT = 2 and show that, for every host graph with lifetime Î»Hmaxâ‰¥2superscriptsubscriptğœ†ğ»2\lambda_{H}^{\max}\geq 2italic_Î» start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT â‰¥ 2, the problems of computing a best response strategy and the problem of deciding whether a strategy profile is a NE are both NP-hard. The authors then consider upper and lower bounds to the PoA w.r.t. both NE and GE. In particular, they show that the PoA w.r.t. NE is in between Î©â¢(logâ¡n)Î©ğ‘›\Omega(\log n)roman_Î© ( roman_log italic_n ) and ğ’ªâ¢(n)ğ’ªğ‘›\mathcal{O}(\sqrt{n})caligraphic_O ( square-root start_ARG italic_n end_ARG ). Moreover, they connect GE with NE by showing that the PoA w.r.t. GE is no more than a ğ’ªâ¢(logâ¡n)ğ’ªğ‘›\mathcal{O}(\log n)caligraphic_O ( roman_log italic_n ) factor away the PoA w.r.t. NE. Besides the paper by which, to the best of our knowledge, is the only one that combines temporal aspects with network formation games, there has been an extensive line of research on related games in the last decades. One of the earliest models which is close to our work is by , where selfish agents buy incident edges and their utility increases with the number of agents they can reach while it decreases with the number of edges bought. For the version where undirected edges are formed, the authors prove that equilibria always exist forming either stars or empty graphs, and that improving response dynamics quickly converge to such states. They also show how to efficiently compute a best response strategy as well as deciding if a given state is in equilibrium. extended this model to a setting with attacks on the formed network, where the objective is to maintain post-attack reachability. This variant is more complex, yet proved that best response strategies can still be computed efficiently. Recently, studied a variant where the attacks are probabilistic. studied the different, yet related, topology control game, where the agents are points in the plane and edge costs are proportional to the Euclidean distance between the endpoints. A similar game was studied by , with the difference that agents are points in hyperbolic space and using greedy routing. Regarding the idea of using global edge-buying in network creation games, the model by is related. There, coalitions of agents can buy costshares of any edge in the network. From a centralized algorithmic perspective, starting from the work by , a lot of research has been devoted to the problem of computing sparse spanners in temporal graphs. More precisely, temporal cliques admit sparse temporally connected spanners , even when we seek for all-pairs temporal paths of bounded length . In contrast, there exist very dense temporal graphs that are not complete whose temporal spanners are all dense . Closely related to the reachability problem, study the problem of finding the minimum number of labels required to achieve temporal connectivity in a graph."
https://arxiv.org/html/2411.03802v1,On the Decomposition of Differential Game,"To understand the complexity of the dynamic of learning in differential games, we decompose the game into components where the dynamic is well understood. One of the possible tools is Helmholtzâ€™s theorem, which can decompose a vector field into a potential and a harmonic component. This has been shown to be effective in finite and normal-form games. However, applying Helmholtzâ€™s theorem by connecting it with the Hodge theorem on â„nsuperscriptâ„ğ‘›{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT (which is the strategy space of differential game) is non-trivial due to the non-compactness of â„nsuperscriptâ„ğ‘›{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Bridging the dynamic-strategic disconnect through Hodge/Helmoltzâ€™s theorem in differential games is then left as an open problem [LBR+19]. In this work, we provide two decompositions of differential games to answer this question: the first as an exact scalar potential part, a near vector potential part, and a non-strategic part; the second as a near scalar potential part, an exact vector potential part, and a non-strategic part. We show that scalar potential games coincide with potential games proposed by [MS96], where the gradient descent dynamic can successfully find the Nash equilibrium. For the vector potential game, we show that the individual gradient field is divergence-free, in which case the gradient descent dynamic may either be divergent or recurrent.","One of the most fundamental questions in game-theoretic learning is whether an uncoupled learning dynamic can ultimately achieve a stable equilibrium through repeated interactions among players. Specifically, in which games and under what conditions can players reach a stable state using learning algorithms such as gradient descent? This issue has gained significant attention, particularly as many advancements in machine learning have relied on gradient descent to optimize the parameters of neural networks, with objective functions that model non-cooperative games. Popular examples include adversarially generative networks [GPAM+20], federated learning [KMA+21, DK21], multi-agent reinforcement learning [Lit94, LWT+17], and any machine learning algorithm trained in an adversarial way. A notable result by [HMC03, HMC06] presents a negative finding, demonstrating that no uncoupled learning dynamics can converge to a Nash equilibrium in all games from any initial condition. This raises the critical question of which games a learning process can successfully converge to a Nash equilibrium and which games it cannot. In the case where the game is finite, or if the game is a normal-form game, this question can be partially answered by decomposing the game through Helmholtzâ€™s theorem. When the number of strategies for each player is finite, or when the strategies considered are on a probability simplex, [COP10, LMP24] showed that a game can be decomposed into a potential game and a harmonic game. This decomposition categorizes finite games along a spectrum, ranging from players with fully aligned interests (represented by games containing only the potential component) to players with entirely conflicting interests (represented by games containing only the harmonic component). In potential games, where there exists a potential function to quantify how individual strategy changes affect collective utility, players can thus descent along the direction of the gradient of their utility functions, which is equivalent to collectively minimizing the potential function, to reach the Nash equilibrium. In normal form games, the harmonic game is shown to be incompressible, hence implying that common learning dynamics, such as the exponential weight, can lead to PoincarÃ© recurrence [LMP24]. In differential games, where the strategies are assumed to be in â„nsuperscriptâ„ğ‘›{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, applying Helmholtzâ€™s theorem becomes non-straightforward. Different from the normal form games, where the utilities are multilinear and the strategies are naturally in a compact set, the utility of differential games can be much more complicated. Specifically, Helmholtzâ€™s theorem operates in â„3superscriptâ„3{\mathbb{R}}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, where the curl of the gradient field is still a vector field, which means naively applying Helmholtzâ€™s theorem only gives a decomposition in â„3superscriptâ„3{\mathbb{R}}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. When nâ‰¥4ğ‘›4n\geq 4italic_n â‰¥ 4, the curl of the gradient field is no longer a vector field, and one then needs to leverage the Hodge Theorem to perform the decomposition on a manifold. Connecting and applying Hodge/Helmholtz decomposition on the manifolds is yet to be investigated. A direct sum decomposition, like those in finite games and normal-form games, remains open in differential games [LBR+19]. 1.1 Related works In finite games, where the number of strategies is finite for each player, [CMOP11] introduced a method to decompose a given game into a potential and harmonic component. This decomposition maps finite games into a spectrum of players having fully aligned interests (games with only the potential component), to players having completely conflicting interests (games with only the harmonic component). Follow-up works then develop different variants of decompositions for the finite games [CLZQ16, WLC17, LCH19, APSV22]. This decomposition framework is then extended to normal form games [LMP24], where classic no-regret algorithms such as exponential weights are known to be possibly chaotic [PPP17, MPP18, VGFP19]. Based on the decomposition of normal form games, [LMP24] provided a principled way to identify cycling behaviors of exponential weights. In differential games, [LBR+19] identified two classes of games based on the symmetric and skew-symmetric parts of the gameâ€™s Jacobian matrix. The games with the symmetric Jacobian matrix are identified to be potential games, while games with skew-symmetric Jacobian matrix are named Hamiltonian games, which are closely related to harmonic games. However, this is different from the direct sum decomposition results in finite and normal-form games. Specifically, given a game with individual gradient field gğ‘”gitalic_g, it is impossible in general to find a potential game gpsubscriptğ‘”ğ‘g_{p}italic_g start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and a Hamiltonian game ghsubscriptğ‘”â„g_{h}italic_g start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT such that g=gp+ghğ‘”subscriptğ‘”ğ‘subscriptğ‘”â„g=g_{p}+g_{h}italic_g = italic_g start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT. Classic gradient descent methods are known to be convergent for potential games, but they can be non-convergent for Hamiltonian games. They thus introduced symplectic gradient adjustment to find stable fixed points in differential games. They also remarked that connecting the differential-geometric Hodge/Helmholtz decomposition in differential games is left as an open problem. 1.2 Differential games We consider a differential game with Mğ‘€Mitalic_M players. Each player iğ‘–iitalic_i has utility {ui:â„nâ†’â„}i=1Msuperscriptsubscriptconditional-setsubscriptğ‘¢ğ‘–â†’superscriptâ„ğ‘›â„ğ‘–1ğ‘€\left\{u_{i}:\mathbb{R}^{n}\rightarrow\mathbb{R}\right\}_{i=1}^{M}{ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT â†’ blackboard_R } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT and can play a strategy Ï‰iâˆˆâ„nisubscriptğœ”ğ‘–superscriptâ„subscriptğ‘›ğ‘–\omega_{i}\in\mathbb{R}^{n_{i}}italic_Ï‰ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT to maximize its utility. We denote the joint strategy as Ï‰=(Ï‰1,â€¦,Ï‰M)âˆˆâ„nğœ”subscriptğœ”1â€¦subscriptğœ”ğ‘€superscriptâ„ğ‘›\omega=\left(\omega_{1},\ldots,\omega_{M}\right)\in\mathbb{R}^{n}italic_Ï‰ = ( italic_Ï‰ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_Ï‰ start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ) âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT where âˆ‘i=1Mni=nsuperscriptsubscriptğ‘–1ğ‘€subscriptğ‘›ğ‘–ğ‘›\sum_{i=1}^{M}n_{i}=nâˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_n. We also let Ï‰âˆ’isubscriptğœ”ğ‘–\omega_{-i}italic_Ï‰ start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT be the joint strategy of all players except for player iğ‘–iitalic_i. To denote the individual components of Ï‰ğœ”\omegaitalic_Ï‰, we write Ï‰=(Ï‰1,â€¦,Ï‰M)=(x1,â€¦,xn)ğœ”subscriptğœ”1â€¦subscriptğœ”ğ‘€subscriptğ‘¥1â€¦subscriptğ‘¥ğ‘›\omega=(\omega_{1},\ldots,\omega_{M})=(x_{1},\ldots,x_{n})italic_Ï‰ = ( italic_Ï‰ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_Ï‰ start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ) = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , â€¦ , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ). 1.3 Our contributions We identified two different inner products on the space of differential games, which allows us to apply the Helmholtz decomposition on the vector field space of the utility gradient. Similar to the decomposition of the finite games, we decompose the differential games into three parts, which enjoy different dynamic properties. However, different from the case of finite games, the differential games cannot be decomposed straightforwardly into a potential part and a harmonic part. This is due to the fact that the harmonic component is isomorphic to the de Rham cohomology of the manifold, which is zero when the differential kğ‘˜kitalic_k-form is with k=1ğ‘˜1k=1italic_k = 1 and the manifold is â„nsuperscriptâ„ğ‘›{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Instead, we identify a Vector Potential part of the differential games, which are similar to a harmonic game in many ways, such as the challenges it imposes on dynamical systems induced by gradient descent. Our two decompositions provide different interpretations of the space of differential games. In the first decomposition, the game is decomposed into an exact scalar potential part, a near vector potential part, and a non-strategic part. We show that the exact scalar potential part of the game is an exact potential game, and the vector potential part poses similar challenges to learning algorithms. Specifically, the standard gradient descent dynamic can exhibit non-convergent behaviors on the vector potential game. To relate the vector potential games and the Hamiltonian games, we show that a Hamiltonian game has to be a vector potential game, but not vice versa. In the second decomposition, the game is decomposed into a near scalar potential part, an exact vector potential part, and a non-strategic part. We show that the vector potential part of the game is flat on any local Nash equilibrium, which imposes significant challenges to first and second-order local Nash equilibrium finding algorithms."
https://arxiv.org/html/2411.03390v1,Six Candidates Suffice to Win a Voter Majority,"A cornerstone of social choice theory is Condorcetâ€™s paradox which says that in an election where nğ‘›nitalic_n voters rank mğ‘šmitalic_m candidates it is possible that, no matter which candidate is declared the winner, a majority of voters would have preferred an alternative candidate. Instead, can we always choose a small committee of winning candidates that is preferred to any alternative candidate by a majority of voters?Elkind, Lang, and Saffidine raised this question and called such a committee a Condorcet winning set. They showed that winning sets of size 2222 may not exist, but sets of size logarithmic in the number of candidates always do. In this work, we show that Condorcet winning sets of size 6666 always exist, regardless of the number of candidates or the number of voters. More generally, we show that if Î±1âˆ’lnâ¡Î±â‰¥2k+1ğ›¼1ğ›¼2ğ‘˜1\frac{\alpha}{1-\ln\alpha}\geq\frac{2}{k+1}divide start_ARG italic_Î± end_ARG start_ARG 1 - roman_ln italic_Î± end_ARG â‰¥ divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG, then there always exists a committee of size kğ‘˜kitalic_k such that less than an Î±ğ›¼\alphaitalic_Î± fraction of the voters prefer an alternate candidate. These are the first nontrivial positive results that apply for all kâ‰¥2ğ‘˜2k\geq 2italic_k â‰¥ 2.Our proof uses the probabilistic method and the minimax theorem, inspired by recent work on approximately stable committee selection. We construct a distribution over committees that performs sufficiently well (when compared against any candidate on any small subset of the voters) so that this distribution must contain a committee with the desired property in its support.","Voting is a versatile model for the aggregation of individual preferences to reach a collective decision. Disparate situations, such as constituents choosing representatives, organizations hiring employees, judges choosing prize winners, and even friends choosing games to play, can all be understood as a group of voters choosing from a pool of candidates. Voting theory seeks to understand how winning candidates can be selected in a fair and representative manner. One of the longest known challenges with voting is Condorcetâ€™s paradox, discovered by Nicolas de Condorcet around the French Revolution [dC85].111It is plausible that in early academic explorations of voting, 13th-century philosopher Ramon Llull had already discovered the possibility of this paradoxical situation [Llu83, HP00]. The paradox is that in an election where voters have ranked preferences over candidates, the preferences of the â€œmajorityâ€ can be contradictory â€” no matter which candidate is declared the winner, a majority of the voters would have preferred another candidate. In fact, the contradiction can be even more dramatic, with â€œmajorityâ€ replaced by a fraction arbitrarily close to 1. An illustrative example is when the voters have cyclic preferences as, for example, displayed in Table 1. v1subscriptğ‘£1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT v2subscriptğ‘£2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT v3subscriptğ‘£3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT v4subscriptğ‘£4v_{4}italic_v start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT v5subscriptğ‘£5v_{5}italic_v start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT v6subscriptğ‘£6v_{6}italic_v start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT 1 2 3 4 5 6 2 3 4 5 6 1 3 4 5 6 1 2 4 5 6 1 2 3 5 6 1 2 3 4 6 1 2 3 4 5 Table 1: An election where voters have cyclic preferences. The column headed with visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the iğ‘–iitalic_ith voterâ€™s ranking of the candidates (labeled 1,2,â€¦,612â€¦61,2,\dots,61 , 2 , â€¦ , 6 from top to bottom). For each candidate, another candidate is preferred by every voter except one. Though it is impossible to always find a single candidate that is always preferred over the others by a majority (called a Condorcet winner), one hope is that relaxations of this condition are still possible to achieve. A natural relaxation arises in the setting of committee selection, where rather than choosing a single winner, the goal is to choose a committee of kğ‘˜kitalic_k winners. For example, a political system may have districts with multiple representatives, organizations may make many hires at once, and friends might play more than one game in an evening. Another view is that committee selection can be used as an filtering step in a process with more than one round, like primaries or runoffs, choosing interviewees for a position, or nominations for a prize. In this context, Elkind, Lang, and Saffidine [ELS11, ELS15] asked: is it always possible to find a small committee of candidates such that no other candidate is preferred by a majority of voters over each member of the committee? They called this committee-analogue of a Condorcet winner a Condorcet winning set, and defined the Condorcet dimension of an election as the size of its smallest Condorcet winning set. For example, the election depicted in Table 1 has Condorcet dimension 2, since any pair of diametrically opposite candidates such as {3,6}36\{3,6\}{ 3 , 6 } would be a Condorcet winning set. More generally, [ELS15] raised the following question for an arbitrary threshold of Î±ğ›¼\alphaitalic_Î± in place of 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG, and a target committee size kğ‘˜kitalic_k. Question 1 ([ELS15]). A committee Sğ‘†Sitalic_S is Î±ğ›¼\alphaitalic_Î±-undominated if for all candidates aâˆ‰Sğ‘ğ‘†a\notin Sitalic_a âˆ‰ italic_S, less than an Î±ğ›¼\alphaitalic_Î± fraction of voters prefer ağ‘aitalic_a over each member of Sğ‘†Sitalic_S. For what values of kâˆˆâ„¤+ğ‘˜superscriptâ„¤k\in\mathbb{Z}^{+}italic_k âˆˆ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT and Î±âˆˆ(0,1]ğ›¼01\alpha\in(0,1]italic_Î± âˆˆ ( 0 , 1 ] does every election have an Î±ğ›¼\alphaitalic_Î±-undominated committee of size kğ‘˜kitalic_k? In particular, we would like to know, for each kğ‘˜kitalic_k, what is the smallest Î±ğ›¼\alphaitalic_Î± for which Î±ğ›¼\alphaitalic_Î±-undominated committees of size kğ‘˜kitalic_k always exist (and, equivalently, for each Î±ğ›¼\alphaitalic_Î±, the smallest kğ‘˜kitalic_k such that these committees always exist). Condorcetâ€™s paradox (or rather, its aformentioned generalization) shows that for k=1ğ‘˜1k=1italic_k = 1 and any Î±ğ›¼\alphaitalic_Î± bounded away from 1, there are elections with no Î±ğ›¼\alphaitalic_Î±-undominated singleton candidates. For the threshold of Î±=12ğ›¼12\alpha=\frac{1}{2}italic_Î± = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, [ELS15] constructed instances with Condorcet dimension 3 by taking the Kronecker product of two elections with cyclic preferences (see Table 3). This construction can be easily extended to give a lower bound of 2k+12ğ‘˜1\frac{2}{k+1}divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG on the smallest Î±ğ›¼\alphaitalic_Î± such that there always exists an Î±ğ›¼\alphaitalic_Î±-undominated committee of size kğ‘˜kitalic_k (see Appendix B). They also showed that an election with mğ‘šmitalic_m candidates has Condorcet dimension at most âŒˆlog2â¡mâŒ‰subscript2ğ‘š\lceil\log_{2}m\rceilâŒˆ roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m âŒ‰; to see this, note that some candidate beats a majority of the other candidates, so we can iteratively add such a candidate to our committee and remove all the candidates that it beats. 1.1 Our Contributions We prove that every election has Condorcet dimension at most 6. This result is a corollary of our main theorem, which gives a nontrivial existence result for Î±ğ›¼\alphaitalic_Î±-undominated committees of size kâ‰¥2ğ‘˜2k\geq 2italic_k â‰¥ 2. We note that the final result we prove (Theorem 5) is stronger, but we start with the approximation below as it is easier to get a handle on. (For a comparison, see Table 2.) Theorem 1. If Î±1âˆ’lnâ¡Î±â‰¥2k+1ğ›¼1ğ›¼2ğ‘˜1\frac{\alpha}{1-\ln\alpha}\geq\frac{2}{k+1}divide start_ARG italic_Î± end_ARG start_ARG 1 - roman_ln italic_Î± end_ARG â‰¥ divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG, then in any election, there exists an Î±ğ›¼\alphaitalic_Î±-undominated committee of size kğ‘˜kitalic_k. For the specific threshold of Î±=12ğ›¼12\alpha=\frac{1}{2}italic_Î± = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, Theorem 1 applies as long as kâ‰¥3+4â¢lnâ¡2â‰ˆ5.77ğ‘˜3425.77k\geq 3+4\ln 2\approx 5.77italic_k â‰¥ 3 + 4 roman_ln 2 â‰ˆ 5.77, and so any election has Condorcet dimension at most 6666 (which is not far from the lower bound of 3333). Taking k=2ğ‘˜2k=2italic_k = 2, Theorem 1 implies that there always exists a pair of candidates such that no third candidate is preferred by more than roughly 80%percent8080\%80 % of the voters. Even replacing 80%percent8080\%80 % with 99%percent9999\%99 %, this was previously unknown. These results show that just by having a few winners instead of one, the most dramatic failures of Condorcetâ€™s paradox are avoidable. We emphasize that these results hold for any election, regardless of the number of voters, the number of candidates, or the preferences that the voters have over candidates. Our starting point for proving Theorem 1 is the observation that 1 is closely linked to the problem of approximate stability in committee selection [JMW20]. The principle behind stability is that a subset of voters should have control over a subset of the committee of proportional size. That is, a committee of size kğ‘˜kitalic_k is stable (also referred to as in the core [Sca67, Fol70, FMS18]) if the fraction of voters that prefers any committee of size kâ€²superscriptğ‘˜â€²k^{\prime}italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT is less than kâ€²ksuperscriptğ‘˜â€²ğ‘˜\frac{k^{\prime}}{k}divide start_ARG italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_ARG start_ARG italic_k end_ARG. We note that in this setting, voters have preferences over committees rather than candidates. This more expressive space of preferences gives it the power to model a wide variety of preference structures, such as approval voting and participatory budgeting. Unfortunately, in many settings, stable committees do not always exist. To remedy this, [JMW20] put forth the following approximate notion of stability, and showed the surprising result that for any monotone preference structure and any kğ‘˜kitalic_k, a 32323232-stable committee of size kğ‘˜kitalic_k exists. Definition 1 (Approximately stable committees [JMW20]). A committee Sğ‘†Sitalic_S of kğ‘˜kitalic_k candidates is cğ‘citalic_c-stable if for any committee Sâ€²superscriptğ‘†â€²S^{\prime}italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT of size kâ€²superscriptğ‘˜â€²k^{\prime}italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, the fraction of voters that prefers Sâ€²superscriptğ‘†â€²S^{\prime}italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT over Sğ‘†Sitalic_S is less than câ‹…kâ€²kâ‹…ğ‘superscriptğ‘˜â€²ğ‘˜c\cdot\frac{k^{\prime}}{k}italic_c â‹… divide start_ARG italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_ARG start_ARG italic_k end_ARG. Consider the natural preference order over committees induced by rankings over candidates, where vğ‘£vitalic_v prefers Sâ€²superscriptğ‘†â€²S^{\prime}italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT over Sğ‘†Sitalic_S if and only if she prefers her favorite candidate in Sâ€²superscriptğ‘†â€²S^{\prime}italic_S start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT over her favorite in Sğ‘†Sitalic_S. A simple observation (explained more fully in Appendix A) shows that a committee of size kğ‘˜kitalic_k is cğ‘citalic_c-stable if and only if it is ckğ‘ğ‘˜\frac{c}{k}divide start_ARG italic_c end_ARG start_ARG italic_k end_ARG-undominated. For this ranked preference structure, the constant of 32323232 in the result of [JMW20] can be improved to 16161616 using the existence of stable lotteries for these preferences [CJMW20]. Then, as a black box, [JMW20] implies that 16k16ğ‘˜\frac{16}{k}divide start_ARG 16 end_ARG start_ARG italic_k end_ARG-undominated committees of size kğ‘˜kitalic_k always exist, which in turn implies that we can always find Condorcet winning sets of size at most 32323232. Since this conclusion follows easily from [JMW20], we attribute the first constant upper bound on the size of Condorcet winning sets to their work. One can interpret the approximately stable committee problem as a version of 1 focused on the asymptotics of Î±ğ›¼\alphaitalic_Î± as the committee size kğ‘˜kitalic_k grows large. For this purpose, [JMW20] implies a result that is optimal up to a constant factor, but it says nothing nontrivial for committees of size at most 16161616. In contrast, Theorem 1 gives results even for k=2ğ‘˜2k=2italic_k = 2, and outperforms the bound implied by [JMW20] for kâ‰¤1.75Ã—104ğ‘˜1.75superscript104k\leq 1.75\times 10^{4}italic_k â‰¤ 1.75 Ã— 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT, despite only implying the existence of Oâ¢(logâ¡k)ğ‘‚ğ‘˜O(\log k)italic_O ( roman_log italic_k )-stable committees. Nonetheless, we show that our techniques can be applied to the asymptotic setting as well, giving an improvement over [JMW20]. Theorem 2. In any election, there exists a 9.8217k9.8217ğ‘˜\frac{9.8217}{k}divide start_ARG 9.8217 end_ARG start_ARG italic_k end_ARG-undominated committee of size kğ‘˜kitalic_k. As a corollary, Theorem 2 implies the existence of 9.82179.82179.82179.8217-stable committees for preferences induced by rankings over candidates. We note that Theorem 2 improves Theorem 1 for kâ‰¥496ğ‘˜496k\geq 496italic_k â‰¥ 496. 1.2 Technical Overview Our approach, building on [JMW20], is to first construct a particular distribution over committees of size kğ‘˜kitalic_k, and then to show that by sampling from this distribution, the resulting committee is Î±ğ›¼\alphaitalic_Î±-undominated in expectation. In fact, [ELS15]â€™s proof that the existence of Oâ¢(logâ¡m)ğ‘‚ğ‘šO(\log m)italic_O ( roman_log italic_m ) size Condorcet winning committees in elections with mğ‘šmitalic_m candidates can also be viewed through this framework. There, we can consider the uniform distribution over candidates. To construct the committee, we sample from this distribution, remove the candidates that are beaten, and recurse on the remaining candidates. In expectation, half of the candidates are removed in each round, so the algorithm is likely to end with a committee of Oâ¢(logâ¡m)ğ‘‚ğ‘šO(\log m)italic_O ( roman_log italic_m ) candidates. The greedy algorithm of choosing the candidate that beats the most others in each round can be viewed as derandomization via conditional expectation. In this light, a natural approach to improving the Oâ¢(logâ¡m)ğ‘‚ğ‘šO(\log m)italic_O ( roman_log italic_m ) guarantee is to find a better distribution over committees. One of the insights in [JMW20] was to construct this distribution via the equilibrium of a zero-sum game. In the game, the defender chooses a committee Sğ‘†Sitalic_S of size kğ‘˜kitalic_k, and the attacker chooses a candidate ağ‘aitalic_a. After the choices are made, the defender pays the attacker a dollar for each voter that prefers ağ‘aitalic_a over all members of Sğ‘†Sitalic_S. The optimal strategy for the defender is to choose a committee randomly according to some distribution, which [JMW20] call the stable lottery. Then to create a committee of size kğ‘˜kitalic_k, [JMW20] take a recursive approach. First, they sample a committee Sğ‘†Sitalic_S of size k/2ğ‘˜2k/2italic_k / 2, and show that ignoring the 25% of voters that least like Sğ‘†Sitalic_S, any candidate ağ‘aitalic_a is preferred over Sğ‘†Sitalic_S by less than a 8k8ğ‘˜\frac{8}{k}divide start_ARG 8 end_ARG start_ARG italic_k end_ARG fraction of the voters (which are treated as an irrevocable loss). In the next step, they recurse on the ignored voters, sample a committee of size k/4ğ‘˜4k/4italic_k / 4, and lose less than another 4k4ğ‘˜\frac{4}{k}divide start_ARG 4 end_ARG start_ARG italic_k end_ARG fraction of the voters against any candidate ağ‘aitalic_a. The committee size and fraction of voters we lose continue to decrease exponentially, and in the end we have a committee of size kğ‘˜kitalic_k such that less than 16k16ğ‘˜\frac{16}{k}divide start_ARG 16 end_ARG start_ARG italic_k end_ARG voters prefer any candidate ağ‘aitalic_a. To prove Theorem 1, we introduce three twists into this framework. Two are part of how we set up the zero-sum game in order to construct a distribution over committees that individual candidates perform poorly against (Lemma 1), and one is in how we show that in expectation, a random committee sampled from the distribution performs well (Lemma 2 and 4). Improving the game by confining the adversary. First, we modify the setup of the game so that the adversary must choose both a candidate ağ‘aitalic_a and a subset Uğ‘ˆUitalic_U of an Î±ğ›¼\alphaitalic_Î± fraction of the voters. The adversary then only gets paid for the voters in Uğ‘ˆUitalic_U that prefer ağ‘aitalic_a over the committee Sğ‘†Sitalic_S. By tying the hands of the adversary in this way, we can drive down the value of the game, which gives a more favorable guarantee for the distribution over committees. Once we fix the distribution over committees (referred to by Î”Î”\Deltaroman_Î”), we measure the quality of a candidate ağ‘aitalic_a or committee Sğ‘†Sitalic_S with respect to a voter vğ‘£vitalic_v with a crucial notion that we call the rank, denoted rankvâ¡(a)subscriptrankğ‘£ğ‘\operatorname{rank}_{v}(a)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_a ) or rankvâ¡(S)subscriptrankğ‘£ğ‘†\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) (see Definition 3). Roughly speaking, this is simply the probability when we sample from Î”Î”\Deltaroman_Î” that we get a committee that is worse than ağ‘aitalic_a or Sğ‘†Sitalic_S in vğ‘£vitalic_vâ€™s preference. The activation function. The second twist is what we call the activation function gğ‘”gitalic_g, which allows us freedom in how we measure each voterâ€™s preferences for candidates and committees. This function may seem somewhat enigmatic in the proof, but here we try to give some rough intuition for the idea behind it. The initial observation is that by using versions of the zero-sum game with different committee sizes, we can construct distributions over committees of size kğ‘˜kitalic_k in a variety of ways. The simplest would be to take the optimal mixed strategy for the defender in the original game with committee size kğ‘˜kitalic_k, but we could also take the optimal strategy for size k/2ğ‘˜2k/2italic_k / 2, sample twice from it and take the union. These different ways of constructing the distributions can actually be interpreted as attaching different activation functions to the defenderâ€™s distribution in the payoffs of the original game. For example, sampling twice from the k/2ğ‘˜2k/2italic_k / 2 distribution is equivalent to attaching the function gâ¢(x)=xğ‘”ğ‘¥ğ‘¥g(x)=\sqrt{x}italic_g ( italic_x ) = square-root start_ARG italic_x end_ARG, and the reason corresponds to the fact that sampling two uniform reals from [0,1]01[0,1][ 0 , 1 ] and taking the max is equivalent to sampling one uniform real from [0,1]01[0,1][ 0 , 1 ] and taking the square root. In the end, thanks to the generality of the minimax theorem, the proof works for any non-constant, non-decreasing function g:[0,1]â†’â„â‰¥0:ğ‘”â†’01subscriptâ„absent0g\colon[0,1]\to\mathbb{R}_{\geq 0}italic_g : [ 0 , 1 ] â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT such that gâ¢(xk)ğ‘”superscriptğ‘¥ğ‘˜g(x^{k})italic_g ( italic_x start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) is convex. These functions give a richer continuous space of options for modifying the game, some of which are not easily interpretable in terms of the intuition described above. Each choice of gğ‘”gitalic_g gives a different bound for Î±ğ›¼\alphaitalic_Î± as a function of kğ‘˜kitalic_k, and so we can simply choose the function that gives the best guarantee. A one-shot approach with finer accounting of all voters. Third, we use a more precise approach for showing that some committee in the support of our distribution performs well, by diligently accounting for the contributions of each voter. In each step of [JMW20]â€™s recursion, when they sample committee Sğ‘†Sitalic_S, they consider for each voter vğ‘£vitalic_v whether or not rankvâ¡(S)subscriptrankğ‘£ğ‘†\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) is above some threshold (called Î²ğ›½\betaitalic_Î², which is set to 1414\frac{1}{4}divide start_ARG 1 end_ARG start_ARG 4 end_ARG). The voters below the threshold are ignored, and then recursed on in the next iteration. There are two potential roadblocks in using this approach for small committee sizes. Intuitively, if we are aiming for a final committee size of around 6, the recursion cannot be very deep. Each iteration can only choose 2 or 3 candidates, for which the guarantee is insufficient. That is, the benefits of the recursion only kick in for sufficiently large committees, and for small committees, it is better to sample the whole committee in one shot (without recursion). Second, there is too much loss in evaluating each voter with a binary threshold, and without recursion, we need better accounting for voters with a low opinion of the committee. In Lemma 2 and 4, we give a smoother analysis, which allows us to more precisely account for the contributions of each voter. To give some rough intuition, what we would like to show is that there is some Sğ‘†Sitalic_S such that the total sum of rankvâ¡(S)subscriptrankğ‘£ğ‘†\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) is large for any subset of an Î±ğ›¼\alphaitalic_Î± fraction of the voters. If we fix Sğ‘†Sitalic_S and plot each rankvâ¡(S)subscriptrankğ‘£ğ‘†\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ), ordered from smallest to largest, it suffices to bound the area under the bottom Î±ğ›¼\alphaitalic_Î± fraction. It turns out that the worst case for these ranks (that minimizes the area for all Sğ‘†Sitalic_S) is not a step function with a sharp threshold, but rather a linear function with slope 1111 (akin to the cyclic preferences depicted in Table 1). Finally, to prove Theorem 2, we use our modifications in tandem with the recursive approach. In the proof of this theorem, the idea above that does the heavy lifting is the use of the activation function gğ‘”gitalic_g. 1.3 Related Work Proportionality in committee selection. In the context of committee selection, the principle of proportionality says that large voter coalitions should have their preferences fairly represented â€” an idea that dates back to at least the 19th century [Dro81]. Since its advent, a substantial body of research has been dedicated to studying the possibility and implications of proportionality. One of the most widely studied models is approval voting, where voters express their preferences by selecting a subset of candidates they approve of. We refer the reader to a survey by Lackner and Skowron [LS23] for a detailed discussion on the topic. A key appeal of this model is that there are a wide variety of proportionality axioms such as justified representation (JR) [ABC+17] and its variants (for example, [FEL+17, BP23]) that are satisfied by natural rules (such as Proportional Approval Voting (Thieleâ€™s rule) [Thi95, Kil10, ABC+17, PS20], PhragmÃ©nâ€™s rule [Phr94, PS20], and the Method of Equal Shares [PS20, PPS21]). These ideas have also been impactful in practice, with for example, the historical use of Thieleâ€™s rule and PhragmÃ©nâ€™s rule [Jan16], and the recent successful implementation of the Method of Equal Shares for participatory budgeting in several European cities [PS]. Additionally, this line of work is driven forward by intriguing conjectures that even stronger axioms, such as core stability [ABC+17, FMS18], might be universally satisfiable as well. In comparison, proportionality in committee selection with ranked preferences is relatively under-explored. As [LS23] suggest, part of the challenge is that notions of proportionality in the approval setting do not always generalize to the ranking setting. (Or, like with core stability, the analogous axioms are not always satisfiable [CJMW20].) One particularly well studied class of rank-based committee selection rules is that of committee scoring rules [EFSS17]. These voting rules, which generalize scoring rules in the single-winner setting, capture several natural committee selection rules, and have been axiomatically characterized [FSST19, SFS19]. We refer the reader to [FSST17] for a more in-depth discussion. Committee analogues of Condorcet winners. Grappling with Condorcetâ€™s paradox has been a major driving force in social choice theory, and naturally, other attempts have been made to extend the notion of Condorcet winners to the multi-winner setting. Fishburn [Fis81b, Fis81a] introduced the idea of a majority committee, defined as a committee preferred by a majority of voters over any other committee of the same size. The Smith set [Goo71, Smi73] Sğ‘†Sitalic_S is defined as the minimal committee such that for any aâˆ‰Sğ‘ğ‘†a\notin Sitalic_a âˆ‰ italic_S and bâˆˆSğ‘ğ‘†b\in Sitalic_b âˆˆ italic_S, a majority of voters prefers bğ‘bitalic_b over ağ‘aitalic_a. Uncovered sets [Fis77, Mil80], bipartisan sets [LLLB93] (the support of maximal lotteries [Fis84]), and other tournament solutions [BBH16] can also be viewed as multi-winner generalizations of Condorcet winners. However, these notions face the same challenge as Condorcet winners: they either do not always exist or sometimes coincide with the entire (potentially large) set of candidates. As in the single-winner case, the goal shifts to identifying Condorcet-consistent rules, which select a Condorcet winner (or the analogous multi-winner notion) when one exists [Coe05, BC08]. In this context, Theorem 1 highlights a distinct advantage of the approach by Elkind, Lang, and Saffidine [ELS15]: small Condorcet-undominated sets are guaranteed to exist. Other explorations of 1. Lastly, we mention a few other interesting explorations of Condorcet winning sets, and more generally Î±ğ›¼\alphaitalic_Î±-undominated sets. [Gei14] used SAT solving to determine the largest Condorcet dimension in elections with a small number of voters and candidates. Their search did not turn up any instances with dimension larger than 3, but they found an election with just 6 voters and candidates with dimension 3, and they showed that this is the smallest possible. (We include one such instance in Table 4.) [Blo18] also explored whether elections with Condorcet dimension 4 could be constructed by exploring dominating sets in tourament graphs, but that approach did not yield any such elections. On the positive side, [LVvS24] very recently showed that in elections where the voters and candidates are embedded in a 2-dimensional space, and their preferences are defined by their distance according to the â„“1subscriptâ„“1\ell_{1}roman_â„“ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or â„“âˆsubscriptâ„“\ell_{\infty}roman_â„“ start_POSTSUBSCRIPT âˆ end_POSTSUBSCRIPT norm, the Condorcet dimension is at most 3. In a more informal setting, a question isomorphic to 1 has also been explored from a combinatorial perspective in a series of Math Overflow posts [PÃ¡l13, Spe13, Bra13]. These posts offer an intriguing window into different approaches to resolving the problem, including why some natural approaches fall short. In their formulation [PÃ¡l13], each candidate ağ‘aitalic_a is represented by a function fa:[n]â†’â„•:subscriptğ‘“ğ‘â†’delimited-[]ğ‘›â„•f_{a}\colon[n]\to\mathbb{N}italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT : [ italic_n ] â†’ blackboard_N, which can be thought of as a map from each voter vğ‘£vitalic_v to the rank of ağ‘aitalic_a in vğ‘£vitalic_vâ€™s preference order. They ask 1, with a particular focus on the case where k=2ğ‘˜2k=2italic_k = 2. The responses contain examples of elections with Condorcet dimension 3, including the general lower bound that Î±ğ›¼\alphaitalic_Î±-undominated committees of size kğ‘˜kitalic_k do not always exist when Î±<2k+1ğ›¼2ğ‘˜1\alpha<\frac{2}{k+1}italic_Î± < divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG [Zba14]. One natural approach towards positive results, suggested by Speyer [Spe13], is to solve the following graph theory question. Question 2. For what choices of â„“,kâˆˆâ„¤+â„“ğ‘˜superscriptâ„¤\ell,k\in\mathbb{Z}^{+}roman_â„“ , italic_k âˆˆ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT does there exist a directed graph with girth larger than â„“â„“\ellroman_â„“ such that every subset of kğ‘˜kitalic_k vertices has a common in-neighbor? If there does not exist such a graph for some choice of â„“â„“\ellroman_â„“ and kğ‘˜kitalic_k, then this implies that every election has a (1âˆ’1â„“)11â„“(1-\frac{1}{\ell})( 1 - divide start_ARG 1 end_ARG start_ARG roman_â„“ end_ARG )-undominated set of size kğ‘˜kitalic_k, by considering the graph on candidates where there is an edge (a,b)ğ‘ğ‘(a,b)( italic_a , italic_b ) whenever more than 1âˆ’1â„“11â„“1-\frac{1}{\ell}1 - divide start_ARG 1 end_ARG start_ARG roman_â„“ end_ARG fraction of the voters prefer ağ‘aitalic_a over bğ‘bitalic_b. In particular, if every triangle-free graph has a pair of vertices without a common in-neighbor (â„“=3â„“3\ell=3roman_â„“ = 3 and k=2ğ‘˜2k=2italic_k = 2), then this would imply that 2323\frac{2}{3}divide start_ARG 2 end_ARG start_ARG 3 end_ARG-undominated sets of size 2222 always exist, which would resolve 1 for k=2ğ‘˜2k=2italic_k = 2. Unfortunately, such graphs do exist. [AHL+15] gave a positive answer to 2 for every â„“,kâˆˆâ„¤+â„“ğ‘˜superscriptâ„¤\ell,k\in\mathbb{Z}^{+}roman_â„“ , italic_k âˆˆ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, using a construction based on additive combinatorics."
https://arxiv.org/html/2411.03955v1,"Large Deviations Inequalities for Unequal Probability Sampling
Without Replacementâ€ â€ thanks:This note answers a question posed by Noam Nisan. We thank Noam Nisan and
Benji Weiss for useful discussions and suggestions.","We provide bounds on the tail probabilities for simple procedures that generate random samples without replacement, when the probabilities of being selected need not be equal.","1 Martingale-Based Procedures It is convenient to rescale the weights so that they add to k;ğ‘˜k;italic_k ; thus, put Î”:={xâˆˆ[0,1]n:âˆ‘i=1nxi=k},assignÎ”conditional-setğ‘¥superscript01ğ‘›superscriptsubscriptğ‘–1ğ‘›superscriptğ‘¥ğ‘–ğ‘˜\Delta:=\{x\in[0,1]^{n}:\sum_{i=1}^{n}x^{i}=k\},\ roman_Î” := { italic_x âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT : âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_k } ,and let Î”0:={xâˆˆ{0,1}n:âˆ‘i=1nxi=k}assignsubscriptÎ”0conditional-setğ‘¥superscript01ğ‘›superscriptsubscriptğ‘–1ğ‘›superscriptğ‘¥ğ‘–ğ‘˜\Delta_{0}:=\{x\in\{0,1\}^{n}:\sum_{i=1}^{n}x^{i}=k\}roman_Î” start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := { italic_x âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT : âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_k } be the set of extreme points of Î”,Î”\Delta,roman_Î” , i.e., those weight vectors that contain kğ‘˜kitalic_k ones and nâˆ’kğ‘›ğ‘˜n-kitalic_n - italic_k zeros. For every set AâŠ‚[n]ğ´delimited-[]ğ‘›A\subset[n]italic_A âŠ‚ [ italic_n ] we write xA:=âˆ‘iâˆˆAxi.assignsuperscriptğ‘¥ğ´subscriptğ‘–ğ´superscriptğ‘¥ğ‘–x^{A}:=\sum_{i\in A}x^{i}.italic_x start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT := âˆ‘ start_POSTSUBSCRIPT italic_i âˆˆ italic_A end_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT . A procedure that generates a random sample Sğ‘†Sitalic_S of size kğ‘˜kitalic_k such that â„™â¢[iâˆˆS]=xiâ„™delimited-[]ğ‘–ğ‘†superscriptğ‘¥ğ‘–\mathbb{P}\left[i\in S\right]=x^{i}blackboard_P [ italic_i âˆˆ italic_S ] = italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT for every iâˆˆ[n]ğ‘–delimited-[]ğ‘›i\in[n]italic_i âˆˆ [ italic_n ] is called an xğ‘¥xitalic_x-procedure. The vector of normalized weights (w1,â€¦,wn)superscriptğ‘¤1â€¦superscriptğ‘¤ğ‘›(w^{1},...,w^{n})( italic_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , â€¦ , italic_w start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) yields the vector of weights x0:=kâ¢w=(kâ¢w1,â€¦,kâ¢wn)assignsubscriptğ‘¥0ğ‘˜ğ‘¤ğ‘˜superscriptğ‘¤1â€¦ğ‘˜superscriptğ‘¤ğ‘›x_{0}:=kw=(kw^{1},...,kw^{n})italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := italic_k italic_w = ( italic_k italic_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , â€¦ , italic_k italic_w start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) in Î”.Î”\Delta.roman_Î” . We start with a trivial observation. Observation. Let x=âˆ‘â„“=1LÎ»â„“â¢xâ„“ğ‘¥superscriptsubscriptâ„“1ğ¿subscriptğœ†â„“subscriptğ‘¥â„“x=\sum_{\ell=1}^{L}\lambda_{\ell}x_{\ell}italic_x = âˆ‘ start_POSTSUBSCRIPT roman_â„“ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_Î» start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT where xâ„“âˆˆÎ”subscriptğ‘¥â„“Î”x_{\ell}\in\Deltaitalic_x start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT âˆˆ roman_Î” and Î»â„“â‰¥0subscriptğœ†â„“0\lambda_{\ell}\geq 0italic_Î» start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT â‰¥ 0 for each â„“â„“\ellroman_â„“, and âˆ‘â„“=1LÎ»â„“=1superscriptsubscriptâ„“1ğ¿subscriptğœ†â„“1\sum_{\ell=1}^{L}\lambda_{\ell}=1âˆ‘ start_POSTSUBSCRIPT roman_â„“ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_Î» start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT = 1 (and thus xâˆˆÎ”ğ‘¥Î”x\in\Deltaitalic_x âˆˆ roman_Î” as well). If ğ”›â„“subscriptğ”›â„“\mathfrak{X}_{\ell}fraktur_X start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT is an xâ„“subscriptğ‘¥â„“x_{\ell}italic_x start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT-procedure for each â„“,â„“\ell,roman_â„“ , then the procedure ğ”›ğ”›\mathfrak{X}fraktur_X that with probability Î»â„“subscriptğœ†â„“\lambda_{\ell}italic_Î» start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT follows ğ”›â„“subscriptğ”›â„“\mathfrak{X}_{\ell}fraktur_X start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT is an xğ‘¥xitalic_x-procedure. This is immediate by â„™ğ”›â¢[iâˆˆS]=âˆ‘â„“=1LÎ»â„“â¢â„™ğ”›â„“â¢[iâˆˆS].subscriptâ„™ğ”›delimited-[]ğ‘–ğ‘†superscriptsubscriptâ„“1ğ¿subscriptğœ†â„“subscriptâ„™subscriptğ”›â„“delimited-[]ğ‘–ğ‘†\mathbb{P}_{\mathfrak{X}}\left[i\in S\right]=\sum_{\ell=1}^{L}\lambda_{\ell}% \mathbb{P}_{\mathfrak{X}_{\ell}}\left[i\in S\right].blackboard_P start_POSTSUBSCRIPT fraktur_X end_POSTSUBSCRIPT [ italic_i âˆˆ italic_S ] = âˆ‘ start_POSTSUBSCRIPT roman_â„“ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_Î» start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT blackboard_P start_POSTSUBSCRIPT fraktur_X start_POSTSUBSCRIPT roman_â„“ end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_i âˆˆ italic_S ] . Iterating this observation yields a martingale: a stochastic process where at each step the (conditional) expectation of the â€œvalueâ€ of the next state equals the â€œvalueâ€ of the current state; in our case, these â€œvaluesâ€ will be weight vectors in Î”.Î”\Delta.roman_Î” . Let thus (Xt)t=0,1,2,â€¦subscriptsubscriptğ‘‹ğ‘¡ğ‘¡012â€¦(X_{t})_{t=0,1,2,...}( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t = 0 , 1 , 2 , â€¦ end_POSTSUBSCRIPT be a Î”Î”\Deltaroman_Î”-valued martingale starting with the constant X0=x0=kâ¢wsubscriptğ‘‹0subscriptğ‘¥0ğ‘˜ğ‘¤X_{0}=x_{0}=kwitalic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_k italic_w and ending at a finite time Tğ‘‡Titalic_T with XTsubscriptğ‘‹ğ‘‡X_{T}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT in Î”0subscriptÎ”0\Delta_{0}roman_Î” start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT (i.e., XTisuperscriptsubscriptğ‘‹ğ‘‡ğ‘–X_{T}^{i}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT is either 00 or 1111 for every iğ‘–iitalic_i).333The time Tğ‘‡Titalic_T may well be random; for simplicity, once Î”0subscriptÎ”0\Delta_{0}roman_Î” start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is reached the martingale stays constant, i.e., Xt=XTsubscriptğ‘‹ğ‘¡subscriptğ‘‹ğ‘‡X_{t}=X_{T}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT for all tâ‰¥T.ğ‘¡ğ‘‡t\geq T.italic_t â‰¥ italic_T . Since for every xğ‘¥xitalic_x in Î”0subscriptÎ”0\Delta_{0}roman_Î” start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT there is a unique xğ‘¥xitalic_x-procedureâ€”namely, the deterministic choice of the sample as those iğ‘–iitalic_i whose xisuperscriptğ‘¥ğ‘–x^{i}italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT is 1111 (i.e., S={i:xi=1}ğ‘†conditional-setğ‘–superscriptğ‘¥ğ‘–1S=\{i:x^{i}=1\}italic_S = { italic_i : italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = 1 })â€”the observation above yields an x0subscriptğ‘¥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-procedure that uses these deterministic XTsubscriptğ‘‹ğ‘‡X_{T}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT-choices. Thus, iğ‘–iitalic_i belongs to the random sample Sğ‘†Sitalic_S if and only if XTi=1superscriptsubscriptğ‘‹ğ‘‡ğ‘–1X_{T}^{i}=1italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = 1; and, for every set AâŠ‚[n]ğ´delimited-[]ğ‘›A\subset[n]italic_A âŠ‚ [ italic_n ], the number of elements of Ağ´Aitalic_A in the sample is |Sâˆ©A|=âˆ‘iâˆˆAXTi=XTA.ğ‘†ğ´subscriptğ‘–ğ´superscriptsubscriptğ‘‹ğ‘‡ğ‘–superscriptsubscriptğ‘‹ğ‘‡ğ´|S\cap A|=\sum_{i\in A}X_{T}^{i}=X_{T}^{A}.| italic_S âˆ© italic_A | = âˆ‘ start_POSTSUBSCRIPT italic_i âˆˆ italic_A end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT . The martingale constructions below are based on moving weights around as much as possible, subject to the constraint that all weights stay between 00 and 1.11.1 ."
https://arxiv.org/html/2411.03865v1,AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making,"Traditional interactive environments limit agentsâ€™ intelligence growth with fixed tasks. Recently, single-agent environments address this by generating new tasks based on agent actions, enhancing task diversity. We consider the decision-making problem in multi-agent settings, where tasks are further influenced by social connections, affecting rewards and information access. However, existing multi-agent environments lack a combination of adaptive physical surroundings and social connections, hindering the learning of intelligent behaviors. To address this, we introduce AdaSociety, a customizable multi-agent environment featuring expanding state and action spaces, alongside explicit and alterable social structures. As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake. In AdaSociety, we develop three mini-games showcasing distinct social structures and tasks. Initial results demonstrate that specific social structures can promote both individual and collective benefits, though current reinforcement learning and LLM-based algorithms show limited effectiveness in leveraging social structures to enhance performance. Overall, AdaSociety serves as a valuable research platform for exploring intelligence in diverse physical and social settings. The code is available at https://github.com/bigai-ai/AdaSociety.","Classic learning environments [55, 41, 9, 42, 34] have agents trained in small and stationary worlds, which hinders the improvement of agentsâ€™ intelligence. The learning process stagnates once the environments can no longer provide novel data for agentsâ€™ explorations. Additionally, agents trained on a fixed task set may suffer from a loss of generalization ability [13]. Single-agent environments [18, 25, 61] set out to solve this problem by constructing adaptive environments that continuously generate new tasks based on agent actions, providing a multitudinous task set. In multi-agent settings, however, the task set is determined by not only physical surroundings but also social connections among agents. Social connections dramatically impact agentsâ€™ decision-making by shaping their reward structures and information access [20], and different social structures endow the environments with radically different research problems. For example, centralized scenarios focus on issues like credit assignment and consensus establishment [21, 44], while decentralized settings require agents to address opponent modeling issues and non-stationarity [3, 21, 29, 33]. What makes the problem even more challenging is that social connections are not predefined but adaptive, which means thereâ€™s a dynamical interplay between the topology of social connections and agentsâ€™ states [23]. The adaptive nature of social connections and physical surroundings requires agents to learn continuously, reason about other agentsâ€™ policies, and balance between physical explorations and establishing social connections. While contemporary multi-agent decision-making environments [6, 2, 53, 66, 48] have achieved great progress in stimulating and testing capabilities of learning algorithms in fixed task sets, they fail to generate new tasks by concurrently considering expanding physical surroundings and adaptive social connections. To bridge this gap, we propose AdaSociety, a multi-agent environment with massive and diverse tasks generated by adaptive social connections and expanding physical surroundings, which are influenced by agentsâ€™ behavior. In particular, to the best of our knowledge, AdaSociety first introduces social states (expressed as a multi-layer directed graph) to explicitly and quantitatively describe the adaptive and dynamic connections between entities, including agents and emerged organizations. This greatly enriches the diversity of tasks, supporting the establishment of stable and long-term relations between entities and the quantitative study of social intelligence, like coalition formation and the emergence of hierarchy. In such an environment, agents need to balance the exploration of physical surroundings and the alteration of social connections, leading to multiple possible victory paths and significant decision-making challenges. To stimulate algorithm design and theoretical analysis in AdaSociety, we provide a formulation of the multi-agent decision-making problems, named Growing-MG (Sec. 3). AdaSociety serves as a platform for researchers to customize the environment for diverse research needs. Specifically, a set of fundamental elements and mechanisms can be used, and interfaces are provided to set environment attributes and hyper-parameters. Moreover, AdaSociety exhibits its characteristics by offering three mini-games, where both tensor- and LLM-based methods are tested. In summary, this paper makes three contributions. 1) We introduce a novel multi-agent general-sum environment featuring expanding physical surroundings and adaptive social connections. 2) We offer a customizable environment with three built-in mini-games, supporting both tensor- and LLM-based methods. 3) We implement RL and LLM methods in these mini-games and provide preliminary results, laying the groundwork for further research in this environment. Figure 1: An overview of AdaSociety, composed of physical component and social component. Physical Component consists of diverse resources and events on the map and heterogeneous agentsâ€™ inventories. Social Component describes the adaptive connections between agents and organizations, which shape information access and reward structure. Agents take social actions to alter their social connections. As shown in the rightmost flowchart, agents are initially independent and can establish individual connections (edges between nodes) and form groups (gray ovals)."
https://arxiv.org/html/2411.03651v1,Policy Aggregation,"We consider the challenge of AI value alignment with multiple individuals that have different reward functions and optimal policies in an underlying Markov decision process. We formalize this problem as one of policy aggregation, where the goal is to identify a desirable collective policy. We argue that an approach informed by social choice theory is especially suitable. Our key insight is that social choice methods can be reinterpreted by identifying ordinal preferences with volumes of subsets of the state-action occupancy polytope. Building on this insight, we demonstrate that a variety of methods â€” including approval voting, Borda count, the proportional veto core, and quantile fairness â€” can be practically applied to policy aggregation.","Early discussion of AI value alignment had often focused on learning desirable behavior from an individual teacher, for example, through inverse reinforcement learning [27, 1]. But, in recent years, the conversation has shifted towards aligning AI models with large groups of people or even entire societies. This shift is exemplified at a policy level by OpenAIâ€™s â€œdemocratic inputs to AIâ€ program [41] and Metaâ€™s citizensâ€™ assembly on AI governance [8], and at a technical level by the ubiquity of reinforcement learning from human feedback [30] as a method for fine-tuning large language models. We formalize the challenge of value alignment with multiple individuals as a problem that we view as fundamental â€” policy aggregation. Our starting point is the common assumption that the environment can be represented as a Markov decision process (MDP). While the states, actions and transition functions are shared by all agents, their reward functions â€” which incorporate values, priorities or subjective beliefs â€” may be different. In particular, each agent has its own optimal policy in the underlying MDP. Our question is this: How should we aggregate the individual policies into a desirable collective policy? A naÃ¯ve answer is to define a new reward function that is the sum of the agentsâ€™ reward functions (for each state-action pair separately) and compute an optimal policy for this aggregate reward function; such a policy would guarantee maximum utilitarian social welfare. This approach has a major shortcoming, however, in that it is sensitive to affine transformations of rewards, so, for example, if we doubled one of the reward functions, the aggregate optimal policy may change. This is an issue because each agentâ€™s individual optimal policy is invariant to (positive) affine transformations of rewards, so while it is possible to recover a reward function that induces an agentâ€™s optimal policy by observing their actions over time,111And we assume this is done accurately, in order to focus on the essence of the policy aggregation problem. it is impossible to distinguish between reward functions that are affine transformations of each other. More broadly, economists and moral philosophers have long been skeptical about interpersonal comparisons of utility [19] due to the lack of universal scale â€” an issue that is especially pertinent in our context. Therefore, aggregation methods that are invariant to affine transformations are strongly preferred. Our approach. To develop such aggregation methods, we look to social choice theory, which typically deals with the aggregation of ordinal preferences. To take a canonical example, suppose agents report rankings over mğ‘šmitalic_m alternatives. Under the Borda count rule, each voter gives mâˆ’kğ‘šğ‘˜m-kitalic_m - italic_k points to the alternative they rank in the kğ‘˜kitalic_kâ€™th position, and the alternative with most points overall is selected. The voting approach can be directly applied to our setting. For each agent, it is (in theory) possible to compute the value of every possible (deterministic) policy, and rank them all by value. Then, any standard voting rule, such as Borda count, can be used to aggregate the rankings over policies and single out a desirable policy. The caveat, of course, is that this method is patently impractical, because the number of policies is exponential in the number of states of the MDP. The main insight underlying our approach is that ordinal preferences over policies have a much more practical volumetric interpretation in the state-action occupancy polytope ğ’ªğ’ª\mathcal{O}caligraphic_O. Roughly speaking, a point in the state-action occupancy polytope represents a (stochastic) policy through the frequency it is expected to visit different state-action pairs. If a policy is preferred by an agent to a subset of policies ğ’ªâ€²superscriptğ’ªâ€²\mathcal{O^{\prime}}caligraphic_O start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, its â€œrankâ€ is the volume of ğ’ªâ€²superscriptğ’ªâ€²\mathcal{O^{\prime}}caligraphic_O start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT as a fraction of the volume of ğ’ªğ’ª\mathcal{O}caligraphic_O. The â€œscoreâ€ of a policy under Borda count, for example, can be interpreted as the sum of these â€œranksâ€ over all agents. Our results. We investigate two classes of rules from social choice theory, those that guarantee a notion of fairness and voting rules. By mapping ordinal preferences to the state-action occupancy polytope, we adapt the different rules to the policy aggregation problem. The former class is examined in Section 5. As a warm-up we start from the notion of proportional veto core; it follows from recent work by Chaudhury et al. [7] that a volumetric interpretation of this notion is nonempty and can be computed efficiently. We then turn to quantile fairness, which was recently introduced by Babichenko et al. [4]; we prove that the volumetric interpretation of this notion yields guarantees that are far better than those known for the original, discrete setting, and we design a computationally efficient algorithm to optimize those guarantees. The latter class is examined in Section 6; we focus on volumetric interpretations of Î±ğ›¼\alphaitalic_Î±-approval (including the ubiquitous plurality rule, which is the special case of Î±=1ğ›¼1\alpha=1italic_Î± = 1) and the aforementioned Borda count. In contrast to the rules studied in Section 5, existence is a nonissue for these voting rules, but computation is a challenge, and indeed we establish several computational hardness results. To overcome this obstacle, we implement voting rules for policy aggregation through mixed integer linear programming, which leads to practical solutions. Finally, our experiments in Section 7 evaluate the policies returned by different rules based on their fairness; the results identify quantile fairness as especially appealing. The experiments also illustrate the advantage of our approach over rules that optimize measures of social welfare (which are sensitive to affine transformations of the rewards)."
https://arxiv.org/html/2411.03248v2,On the Role of Constraints in the Complexityof Min-Max Optimization,"We investigate the role of constraints in the computational complexity of min-max optimization. The work of \citet*daskalakis2021complexity was the first to study min-max optimization through the lens of computational complexity, showing that min-max problems with nonconvex-nonconcave objectives are PPAD-hard. However, their proof hinges on the presence of joint constraints between the maximizing and minimizing players. The main goal of this paper is to understand the role of these constraints in min-max optimization. The first contribution of this paper is a fundamentally new proof of their main result, which improves it in multiple directions: it holds for degree 2222 polynomials, it is essentially tight in the parameters, and it is much simpler than previous approaches, clearly highlighting the role of constraints in the hardness of the problem. Second, we show that with general constraints (i.e., the min player and max player have different constraints), even convex-concave min-max optimization becomes PPAD-hard. Along the way, we also provide PPAD-membership of a general problem related to quasi-variational inequalities, which has applications beyond our problem.","The primary interest in this paper is investigating how different structures of constraints drive the computational complexity of min-max optimization problems. This class of problems plays a key role in the development of game theory \citepv1928theorie, adversarial robustness in optimization, statistics, machine learning \citepben2002robust,huber2011robust,mkadry2017towards,sinha2018certifying, and generative models such as Generative Adversarial Networks \citepgoodfellow2014generative,arjovsky2017wasserstein. In its simplest form, a min-max optimization problem can be informally written as minxâˆˆâ„dâ¡maxyâˆˆâ„dâ¡fâ¢(x,y)s.t.â¢gâ¢(x,y)â‰¤0,subscriptğ‘¥superscriptâ„ğ‘‘subscriptğ‘¦superscriptâ„ğ‘‘ğ‘“ğ‘¥ğ‘¦s.t.ğ‘”ğ‘¥ğ‘¦0\begin{array}[]{l}\displaystyle\min_{x\in\mathbb{R}^{d}}\,\max_{y\in\mathbb{R}% ^{d}}\,\,f(x,y)\\ \textnormal{s.t.}\hskip 8.5359ptg(x,y)\leq 0,\end{array}start_ARRAY start_ROW start_CELL roman_min start_POSTSUBSCRIPT italic_x âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_y âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) end_CELL end_ROW start_ROW start_CELL s.t. italic_g ( italic_x , italic_y ) â‰¤ 0 , end_CELL end_ROW end_ARRAY (1) where f:â„dÃ—â„dâ†’â„:ğ‘“â†’superscriptâ„ğ‘‘superscriptâ„ğ‘‘â„f:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_f : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R, and g:â„dÃ—â„dâ†’â„:ğ‘”â†’superscriptâ„ğ‘‘superscriptâ„ğ‘‘â„g:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_g : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R. Due to the strong connection with zero-sum games, xğ‘¥xitalic_x and yğ‘¦yitalic_y are often thought of as selected by players seeking to maximize and minimize the payoff function in a game. While the benign setting in which fğ‘“fitalic_f is convex-concave and gğ‘”gitalic_g is convex is well understood, many fundamental questions remain open regarding more general settings. In this paper, we are specifically interested in these more general settings. Akin to regular (i.e., non-saddle-point) optimization, in nonconvex domains it is too much to ask for a global solution. Instead, local min-max solutions (also known as local equilibria) serve as the target solution concept for our investigation. Specifically, given Ïµ,Î´>0italic-Ïµğ›¿0\epsilon,\delta>0italic_Ïµ , italic_Î´ > 0, we will call (Ïµ,Î´)italic-Ïµğ›¿(\epsilon,\delta)( italic_Ïµ , italic_Î´ )-solution of Problem (1) any pair (xâ‹†,yâ‹†)superscriptğ‘¥â‹†superscriptğ‘¦â‹†(x^{\star},y^{\star})( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) such that gâ¢(xâ‹†,yâ‹†)â‰¤0ğ‘”superscriptğ‘¥â‹†superscriptğ‘¦â‹†0g(x^{\star},y^{\star})\leq 0italic_g ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¤ 0, and such that each player cannot improve their utility through any feasible, local, unilateral deviation, that is, fâ¢(xâ‹†,yâ‹†)â‰¤fâ¢(x,yâ‹†)+Ïµâ¢ for all â¢xâ¢ s.t. â¢â€–xâˆ’xâ‹†â€–â‰¤Î´â¢ and â¢gâ¢(x,yâ‹†)â‰¥0â¢; andfâ¢(xâ‹†,yâ‹†)â‰¥fâ¢(xâ‹†,y)âˆ’Ïµâ¢ for all â¢yâ¢ s.t. â¢â€–yâˆ’yâ‹†â€–â‰¤Î´â¢ and â¢gâ¢(xâ‹†,y)â‰¥0.ğ‘“superscriptğ‘¥â‹†superscriptğ‘¦â‹†ğ‘“ğ‘¥superscriptğ‘¦â‹†italic-Ïµ for all ğ‘¥ s.t. normğ‘¥superscriptğ‘¥â‹†ğ›¿ and ğ‘”ğ‘¥superscriptğ‘¦â‹†0; andğ‘“superscriptğ‘¥â‹†superscriptğ‘¦â‹†ğ‘“superscriptğ‘¥â‹†ğ‘¦italic-Ïµ for all ğ‘¦ s.t. normğ‘¦superscriptğ‘¦â‹†ğ›¿ and ğ‘”superscriptğ‘¥â‹†ğ‘¦0\begin{array}[]{l}f(x^{\star},y^{\star})\leq f(x,y^{\star})+\epsilon\,\,% \textnormal{ for all }x\textnormal{ s.t. }\|x-x^{\star}\|\leq\delta\textnormal% { and }g(x,y^{\star})\geq 0\textnormal{; and}\\ f(x^{\star},y^{\star})\geq f(x^{\star},y)-\epsilon\,\,\textnormal{ for all }y% \textnormal{ s.t. }\|y-y^{\star}\|\leq\delta\textnormal{ and }g(x^{\star},y)% \geq 0.\end{array}start_ARRAY start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¤ italic_f ( italic_x , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) + italic_Ïµ for all italic_x s.t. âˆ¥ italic_x - italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT âˆ¥ â‰¤ italic_Î´ and italic_g ( italic_x , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¥ 0 ; and end_CELL end_ROW start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¥ italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y ) - italic_Ïµ for all italic_y s.t. âˆ¥ italic_y - italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT âˆ¥ â‰¤ italic_Î´ and italic_g ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y ) â‰¥ 0 . end_CELL end_ROW end_ARRAY (2) Our work is not the first to study min-max optimization beyond the convex-concave setup (see, e.g., \citepjin2020local,jin2021nonconvex,daskalakis2023stay and pointers in Section 1.3). For example, several papers have focused on nonconvex-concave objectives under constraints gğ‘”gitalic_g that induce product feasible sets of the form ğ’³Ã—ğ’´ğ’³ğ’´\mathcal{X}\times\mathcal{Y}caligraphic_X Ã— caligraphic_Y, where numerous algorithms find approximate solutions efficiently \citepnouiehed2019solving,lin2020gradient,lin2020near,kong2021accelerated,fiez2021global,ostrovskii2021efficient. On the other hand, in a recent landmark result, \citet*daskalakis2021complexity proved that finding solutions to Problem (2), in the case of nonconvex-concave objective, is PPAD-complete. However, such hardness result only holds in a special case in which gğ‘”gitalic_g couples (i.e., correlates) the feasible sets of the minimization and maximization (the importance of these constraints was also pointed out in \citepfearnley2022complexity, babichenko2021settling, hollender2024complexity, kalogiannis2024learning). Given that the presence of joint constraints turns an otherwise manageable problem into a hard one (Figure 1, second row, first and second column), the following question arises naturally: What role does the coupling of the feasible sets play in the hardness result of \citetdaskalakis2021complexity? We provide a fundamentally new perspective on the problem, clarifying the role of these constraints and disentangling their impact on computational hardness from that of the structure of the objective function. Moreover, this is not the only setting in which we can identify a â€œphase changeâ€ between traceability and hardness when the generality of the constraints is increased. Indeed, as an additional instance of this phenomenon, we show that, as the complexity of constraints increases to capture more general constraints (i.e., the min player and max player have different constraints), even convex-concave optimization can become PPAD-hard (bottom-right cell of Figure 1). In turn, this has implications on the complexity of computing solutions to quasi-variational inequalities with monotone operators. Our result complements known positive results in optimization for QVIs, which either have finite-time guarantees with strong assumptions \citepnesterov2006solving or asymptotic guarantees \citepfacchinei2014solving. We discuss our contributions and their implications in more depth in the next subsection. 1.1 Contributions and Implications Structure of constraintsStructure of utilitiesBilinear Jointly convex Product Convex concave Nonconvex concave Nonconvex nonconcave Open question PPAD-complete PPAD-complete Theorem 3.4 Easy (âˆˆ\inâˆˆ FP) [ostrovskii2021efficient] PPAD-complete\citep daskalakis2021complexity, Theorem 4.1 PPAD-complete Easy (âˆˆ\inâˆˆ FP) (Folklore) Easy (âˆˆ\inâˆˆ FP) (Folklore) PPAD-complete Theorem 4.2 Figure 1: Summary of known results regarding the complexity of min-max optimization for a different combination of structures of utilities and constraints. The arrows point in the direction of increased generality and thus hardness. A key factor in our taxonomy of optimization problems is the structure of the constraints. We consider the following classes of constraints, in increasing order of generality, as listed on the x-axis of Figure 1. â€¢ Product constraints: The feasible set gâ¢(x,y)â‰¤0ğ‘”ğ‘¥ğ‘¦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) â‰¤ 0 is equal to K1Ã—K2subscriptğ¾1subscriptğ¾2K_{1}\times K_{2}italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT Ã— italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT for some appropriate K1,K2âŠ‚â„dsubscriptğ¾1subscriptğ¾2superscriptâ„ğ‘‘K_{1},K_{2}\subset\mathbb{R}^{d}italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT âŠ‚ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. In other words, there is no coupling between the optimization domains of the players. â€¢ Jointly convex constraints: Constraints for both the maximizing and minimizing player are encoded by a function gğ‘”gitalic_g that is jointly convex, that is, convex as a function of (x,y)ğ‘¥ğ‘¦(x,y)( italic_x , italic_y ). In particular, this implies that gâ¢(x,y)â‰¤0ğ‘”ğ‘¥ğ‘¦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) â‰¤ 0 is a convex subset of â„dÃ—â„dsuperscriptâ„ğ‘‘superscriptâ„ğ‘‘\mathbb{R}^{d}\times\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. We remark that for our hardness result highlighted in Figure 1, it is enough to restrict to functions gğ‘”gitalic_g such that gâ¢(x,y)â‰¤0ğ‘”ğ‘¥ğ‘¦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) â‰¤ 0 defines a convex polytope. This is the same class of constraints used in the results of \citetdaskalakis2021complexity. â€¢ Bilinear constraints: Finally, to be able to capture problems corresponding to quasi-variational inequalities, we also consider a more general setting in which the set of feasible local deviations of the players might differ, and is controlled by two constraint functions g1,g2:â„dÃ—â„dâ†’â„:subscriptğ‘”1subscriptğ‘”2â†’superscriptâ„ğ‘‘superscriptâ„ğ‘‘â„g_{1},g_{2}:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT Ã— blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R, one for each player. This leads to the modified notion of (Ïµ,Î´)italic-Ïµğ›¿(\epsilon,\delta)( italic_Ïµ , italic_Î´ )-solution (or local equilibrium) given as fâ¢(xâ‹†,yâ‹†)â‰¤fâ¢(x,yâ‹†)+Ïµâ¢ for all â¢xâ¢ s.t. â¢â€–xâˆ’xâ‹†â€–â‰¤Î´â¢ and â¢g1â¢(x,yâ‹†)â‰¥0â¢; andfâ¢(xâ‹†,yâ‹†)â‰¥fâ¢(xâ‹†,y)âˆ’Ïµâ¢ for all â¢xâ¢ s.t. â¢â€–yâˆ’yâ‹†â€–â‰¤Î´â¢ and â¢g2â¢(xâ‹†,y)â‰¥0.ğ‘“superscriptğ‘¥â‹†superscriptğ‘¦â‹†ğ‘“ğ‘¥superscriptğ‘¦â‹†italic-Ïµ for all ğ‘¥ s.t. normğ‘¥superscriptğ‘¥â‹†ğ›¿ and subscriptğ‘”1ğ‘¥superscriptğ‘¦â‹†0; andğ‘“superscriptğ‘¥â‹†superscriptğ‘¦â‹†ğ‘“superscriptğ‘¥â‹†ğ‘¦italic-Ïµ for all ğ‘¥ s.t. normğ‘¦superscriptğ‘¦â‹†ğ›¿ and subscriptğ‘”2superscriptğ‘¥â‹†ğ‘¦0\begin{array}[]{l}f(x^{\star},y^{\star})\leq f(x,y^{\star})+\epsilon\,\,% \textnormal{ for all }x\textnormal{ s.t. }\|x-x^{\star}\|\leq\delta\textnormal% { and }g_{1}(x,y^{\star})\geq 0\textnormal{; and}\\ f(x^{\star},y^{\star})\geq f(x^{\star},y)-\epsilon\,\,\textnormal{ for all }x% \textnormal{ s.t. }\|y-y^{\star}\|\leq\delta\textnormal{ and }g_{2}(x^{\star},% y)\geq 0.\end{array}start_ARRAY start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¤ italic_f ( italic_x , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) + italic_Ïµ for all italic_x s.t. âˆ¥ italic_x - italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT âˆ¥ â‰¤ italic_Î´ and italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¥ 0 ; and end_CELL end_ROW start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT ) â‰¥ italic_f ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y ) - italic_Ïµ for all italic_x s.t. âˆ¥ italic_y - italic_y start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT âˆ¥ â‰¤ italic_Î´ and italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT â‹† end_POSTSUPERSCRIPT , italic_y ) â‰¥ 0 . end_CELL end_ROW end_ARRAY (3) In particular, we are interested in the case of bilinear constraint functions g1,g2subscriptğ‘”1subscriptğ‘”2g_{1},g_{2}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Due to their bilinear nature, each of this functions defines a local convex polytope of feasible local deviations for each player. We will also consider different classes of objective functions: convex-concave, nonconvex-concave, and nonconvex-nonconcave. We analyze how the problemâ€™s complexity evolves as the structure of the constraints changes. We categorize our results into hardness and membership results. Hardness results The main contribution of this paper is the following hardness result. Theorem 1.1 (Informal version of Theorem 4.1). The problem of computing approximate local min-max equilibria with jointly convex constraints, and nonconvex-concave, GğºGitalic_G-Lipschitz, and Lğ¿Litalic_L-smooth utilities is PPAD-hard for Ïµ=Î˜â¢(Î´)italic-ÏµÎ˜ğ›¿\epsilon=\Theta(\delta)italic_Ïµ = roman_Î˜ ( italic_Î´ ), L=Oâ¢(1)ğ¿ğ‘‚1L=O(1)italic_L = italic_O ( 1 ), and G=polyâ¢(d)ğºpolyğ‘‘G=\textnormal{poly}(d)italic_G = poly ( italic_d ). This result has several implications with respect to the hardness result by \citet[Theorem 4.4]daskalakis2021complexity. First, our result holds for Î´=Oâ¢(ÏµL)ğ›¿ğ‘‚italic-Ïµğ¿\delta=O\left(\frac{\epsilon}{L}\right)italic_Î´ = italic_O ( divide start_ARG italic_Ïµ end_ARG start_ARG italic_L end_ARG ) since Lğ¿Litalic_L is constant, while the hardness result by \citetdaskalakis2021complexity holds only for the regime Î´â‰¥Ïµ/Lğ›¿italic-Ïµğ¿\delta\geq\sqrt{\epsilon/L}italic_Î´ â‰¥ square-root start_ARG italic_Ïµ / italic_L end_ARG. Second, as shown in Figure 2, our reduction also shows that the problem is PPAD-hard for Î´=Ï‰â¢(Ïµ/G)ğ›¿ğœ”italic-Ïµğº\delta=\omega(\epsilon/G)italic_Î´ = italic_Ï‰ ( italic_Ïµ / italic_G ) as Ïµâ†’0â†’italic-Ïµ0\epsilon\to 0italic_Ïµ â†’ 0, while \citetdaskalakis2021complexity proves that the problem is tractable for Î´â‰¤Ïµ/Gğ›¿italic-Ïµğº\delta\leq\epsilon/Gitalic_Î´ â‰¤ italic_Ïµ / italic_G. Therefore, our result pushes the hardness boundary to the point where the problem transitions from intractable to tractable, leaving open only the case in which Î´=Oâ¢(Ïµ/G)ğ›¿ğ‘‚italic-Ïµğº\delta=O(\epsilon/G)italic_Î´ = italic_O ( italic_Ïµ / italic_G ). Î´ğ›¿\displaystyle\deltaitalic_Î´ÏµGitalic-Ïµğº\displaystyle\frac{\epsilon}{G}divide start_ARG italic_Ïµ end_ARG start_ARG italic_G end_ARG2â¢ÏµL2italic-Ïµğ¿\displaystyle\sqrt{\frac{2\epsilon}{L}}square-root start_ARG divide start_ARG 2 italic_Ïµ end_ARG start_ARG italic_L end_ARG end_ARGÏ‰â¢(ÏµG)ğœ”italic-Ïµğº\displaystyle\omega\!\left(\frac{\epsilon}{G}\right)italic_Ï‰ ( divide start_ARG italic_Ïµ end_ARG start_ARG italic_G end_ARG )ÏµLitalic-Ïµğ¿\displaystyle\sqrt{\frac{\epsilon}{L}}square-root start_ARG divide start_ARG italic_Ïµ end_ARG start_ARG italic_L end_ARG end_ARG00âˆˆ\inâˆˆPPAD\citepdaskalakis2021complexityâˆˆ\inâˆˆFPPPAD-hard [Theorem 4.1]PPAD-hard \citepdaskalakis2021complexity Figure 2: Our results nearly settle the complexity of finding local equilibria of nonconvex-nonconcave objective functions under jointly convex constraints as a function of the parameter Î´ğ›¿\deltaitalic_Î´. In Section 1.2, we give a first high-level overview of our new approach highlighting the role played by the constraints in the construction. In essence, we could say that coupled constraints enable an simple embedding of a generic vector field into Equation 2, thereby solving a variational inequality (VI) associated with this vector field. Our novel perspective on the problem suggests that characterizing the computational complexity of computing approximate local min-max equilibria for nonconvex-nonconcave objectives under product constraints remains an open challenge, and it will likely require new techniques beyond those currently at our disposal. We complement the above result by proving PPAD-hardness for the setting where the objective function is restricted to only be convex-concave, but the constraints class is made more complex by allowing bilinear constraints. This marks a second â€œphase changeâ€ in the complexity of the problem due to constraints since the convex-concave problem is clearly solvable with jointly convex constraints by using the monotone VI formulation of the problem. Theorem 1.2 (Informal version of Theorem 4.2). The problem of computing approximate local min-max equilibria with bilinear constraints, and convex-concave, GğºGitalic_G-Lipschitz, and Lğ¿Litalic_L-smooth utilities is PPAD-hard for Ïµ=Î˜â¢(Î´)italic-ÏµÎ˜ğ›¿\epsilon=\Theta(\delta)italic_Ïµ = roman_Î˜ ( italic_Î´ ), L=Oâ¢(1)ğ¿ğ‘‚1L=O(1)italic_L = italic_O ( 1 ), G=polyâ¢(d)ğºpolyğ‘‘G=\textnormal{poly}(d)italic_G = poly ( italic_d ). Furthermore, our reduction has an interesting consequence about the complexity of quasi-variational inequality (QVI), showing that even with linear constraints, monotone QVIs are unlikely to be polynomial-time solvable in general. Corollary 1.3 (Informal version of Corollary 4.3). The problem of computing solutions to QVIs is PPAD-hard even when the set-valued fixed-point problem encoded by the QVI constraints is linear (and thus solvable in polynomial time) and the operator is monotone. PPAD-membership results PPAD-membership for the case of jointly convex constraints is due to \citet[Theorem 5.2]daskalakis2021complexity. We look at the case of bilinear constraints. To do so, we prove PPAD-membership of a very general problem related to computing solutions to quasi-variational inequalities. A classic variational inequality (VI) problem is that of finding a point zâˆˆQğ‘§ğ‘„z\in Qitalic_z âˆˆ italic_Q, for some convex set QâŠ‚â„dğ‘„superscriptâ„ğ‘‘Q\subset\mathbb{R}^{d}italic_Q âŠ‚ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, such that Fâ¢(z)âŠ¤â¢(zâ€²âˆ’z)â‰¥0ğ¹superscriptğ‘§topsuperscriptğ‘§â€²ğ‘§0F(z)^{\top}(z^{\prime}-z)\geq 0italic_F ( italic_z ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT ( italic_z start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT - italic_z ) â‰¥ 0 for all zâ€²âˆˆQsuperscriptğ‘§â€²ğ‘„z^{\prime}\in Qitalic_z start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT âˆˆ italic_Q, where F:â„dâ†’â„d:ğ¹â†’superscriptâ„ğ‘‘superscriptâ„ğ‘‘F:\mathbb{R}^{d}\to\mathbb{R}^{d}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \citepstampacchia1964formes. VIs are a powerful framework for modeling optimization problems across diverse fields, including game theory \citeprockafellar1970monotone, economics \citepfacchinei2003finite, and machine learning \citepgoodfellow2014generative, and they generalize classical optimization problems like complementarity problems \citepcottle1968complementary. QVIs are an extension of VI in which Qğ‘„Qitalic_Q is no longer a fixed set but a correspondence, which depends on the optimization variable. Then, our PPAD-membership result for local min-max equilibria follows from the connection between QVIs, fixed points of gradient descent-ascent dynamics, and approximate local min-max equilibria. Theorem 1.4 (Informal version of Theorem 3.4). The problem of finding an approximate solution to quasi-variational inequalities is in PPAD. This result may be of independent interest, as the generality of the QVI problem could enable new PPAD-membership results. For example, we can easily give PPAD membership for generalized equilibrium [rosen1965existence], which are more general than those recently considered in [filos2024ppad] (see Section 3.4). 1.2 Overview of Our Techniques This section provides a high-level overview of the primary techniques employed throughout the paper by describing the main steps of the proof of our main result (Theorem 1.2). This is a concise summary of the discussion provided in Section 4.1. Linear variational inequalities The first step in our reduction is proving the hardness of an intermediate problem related to VI with linear operators defined on the hypercube, which we call LinearVI-HC. Specifically, given an affine operator Fâ¢(z)=Dâ¢z+cğ¹ğ‘§ğ·ğ‘§ğ‘F(z)=Dz+citalic_F ( italic_z ) = italic_D italic_z + italic_c the problem is to find a point zğ‘§zitalic_z such that Fâ¢(z)âŠ¤â¢(zâ€²âˆ’z)â‰¥0ğ¹superscriptğ‘§topsuperscriptğ‘§â€²ğ‘§0F(z)^{\top}(z^{\prime}-z)\geq 0italic_F ( italic_z ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT ( italic_z start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT - italic_z ) â‰¥ 0. We show that LinearVI-HC is PPAD-hard through a reduction from the problem of finding Nash equilibria in polymatrix games. This choice is instrumental in obtaining a hard problem on the hypercube and strong inapproximability results. Then, we connect our problem to find fixed points of gradient descent-ascent dynamics, and we reformulate it as solving a variational inequality (VI) problem. Unfortunately, gradient descent-ascent dynamics are related to VI with a specific operator Fğ¹Fitalic_F, constructed by stacking the gradients âˆ‡xfsubscriptâˆ‡ğ‘¥ğ‘“\nabla_{x}fâˆ‡ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f and âˆ’âˆ‡yfsubscriptâˆ‡ğ‘¦ğ‘“-\nabla_{y}f- âˆ‡ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f, which correspond to the utilities of the two players. In game theory this is sometimes called â€œpseudo-gradientâ€ and we indicate it with the symbol âˆ‡~â¢fâ¢(x,y)â‰”(âˆ‡xfâ¢(x,y),âˆ’âˆ‡yfâ¢(x,y)).â‰”~âˆ‡ğ‘“ğ‘¥ğ‘¦subscriptâˆ‡ğ‘¥ğ‘“ğ‘¥ğ‘¦subscriptâˆ‡ğ‘¦ğ‘“ğ‘¥ğ‘¦\widetilde{\nabla}f(x,y)\coloneqq(\nabla_{x}f(x,y),-\nabla_{y}f(x,y)).over~ start_ARG âˆ‡ end_ARG italic_f ( italic_x , italic_y ) â‰” ( âˆ‡ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) , - âˆ‡ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) ) . It is not hard to see that a fixed point of the gradient descent-ascent map defined on fğ‘“fitalic_f is a solution of the VI instance defined with the operator âˆ‡~â¢f~âˆ‡ğ‘“\widetilde{\nabla}fover~ start_ARG âˆ‡ end_ARG italic_f (Theorem B.3). (a) Embedding of Fâ¢(y)=(yâˆ’13)â‹…(yâˆ’23)ğ¹ğ‘¦â‹…ğ‘¦13ğ‘¦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) â‹… ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ) with fâ¢(x,y)=xâŠ¤â¢Fâ¢(y)ğ‘“ğ‘¥ğ‘¦superscriptğ‘¥topğ¹ğ‘¦f(x,y)=x^{\top}F(y)italic_f ( italic_x , italic_y ) = italic_x start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT italic_F ( italic_y ). (b) Embedding of Fâ¢(y)=(yâˆ’13)â‹…(yâˆ’23)ğ¹ğ‘¦â‹…ğ‘¦13ğ‘¦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) â‹… ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ) with fâ¢(x,y)=(xâˆ’y)âŠ¤â¢Fâ¢(y)ğ‘“ğ‘¥ğ‘¦superscriptğ‘¥ğ‘¦topğ¹ğ‘¦f(x,y)=(x-y)^{\top}F(y)italic_f ( italic_x , italic_y ) = ( italic_x - italic_y ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT italic_F ( italic_y ). Figure 3: The two embeddings of the field F:â„dâ†’â„d:ğ¹â†’superscriptâ„ğ‘‘superscriptâ„ğ‘‘F:\mathbb{R}^{d}\to\mathbb{R}^{d}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT into the pseudo-gradient of f:â„2â¢dâ†’â„:ğ‘“â†’superscriptâ„2ğ‘‘â„f:\mathbb{R}^{2d}\to\mathbb{R}italic_f : blackboard_R start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT â†’ blackboard_R. The box on the right is the field xâ†’âˆ‡xfâ†’ğ‘¥subscriptâˆ‡ğ‘¥ğ‘“x\to\nabla_{x}fitalic_x â†’ âˆ‡ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f, while the one on top represents the field yâ†’âˆ’âˆ‡yfâ†’ğ‘¦subscriptâˆ‡ğ‘¦ğ‘“y\to-\nabla_{y}fitalic_y â†’ - âˆ‡ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f. The embedded field is Fâ¢(y)=(yâˆ’13)â‹…(yâˆ’23)ğ¹ğ‘¦â‹…ğ‘¦13ğ‘¦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) â‹… ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ); the blue dots are in correspondence with its zeros and are inserted only for reference. In both figures we have that the xğ‘¥xitalic_x-projection of the pseudo-gradient field on the x=yğ‘¥ğ‘¦x=yitalic_x = italic_y subspace corresponds to the field Fğ¹Fitalic_F, while only in Figure 3(b), both the xğ‘¥xitalic_x and yğ‘¦yitalic_y projections are aligned with the field Fğ¹Fitalic_F. Pseudo-gradient fields It is clear that if we had to deal with standard gradients, then the problem would be much easier (and PPAD-hardness would be hopeless), as any local minima would satisfy the first-order optimality conditions given by the VI. Therefore, our approach to establishing hardness results by using this point of view hinges on the distinction between â€œpseudo-gradientâ€ fields (vector fields generated by applying the pseudo-gradient operator to a differentiable function fğ‘“fitalic_f) and gradient fields. Pseudo-gradient fields are more general then gradient fields, and allow for more complex behavior, e.g. gradient lines might form connected paths, while for conservative vector fields the gradients lines decrease the potential. Perfect imitation and bilinear constraints Bilinear constraints offers a simple tool to implement the linear operator through imitation. Given the linear operator zâ†¦Dâ¢z+cmaps-toğ‘§ğ·ğ‘§ğ‘z\mapsto Dz+citalic_z â†¦ italic_D italic_z + italic_c defining the LinearVI-HC instance, we embed it into the first half components xâˆˆ[0,1]dğ‘¥superscript01ğ‘‘x\in[0,1]^{d}italic_x âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT of the function fğ‘“fitalic_f, while using the constraints to force the yâˆˆ[0,1]dğ‘¦superscript01ğ‘‘y\in[0,1]^{d}italic_y âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT components to lay on a specific dğ‘‘ditalic_d-subdomain of [0,1]2â¢dsuperscript012ğ‘‘[0,1]^{2d}[ 0 , 1 ] start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT. Specifically, if we want to embed the operator [0,1]dâˆ‹zâ†¦Fâ¢(z)âˆˆ[0,1]dcontainssuperscript01ğ‘‘ğ‘§maps-toğ¹ğ‘§superscript01ğ‘‘[0,1]^{d}\ni z\mapsto F(z)\in[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT âˆ‹ italic_z â†¦ italic_F ( italic_z ) âˆˆ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT into a pseudo-gradient âˆ‡~â¢f~âˆ‡ğ‘“\widetilde{\nabla}fover~ start_ARG âˆ‡ end_ARG italic_f, we can consider the following function fâ¢(x,y)=xâŠ¤â¢Fâ¢(y)ğ‘“ğ‘¥ğ‘¦superscriptğ‘¥topğ¹ğ‘¦f(x,y)=x^{\top}F(y)italic_f ( italic_x , italic_y ) = italic_x start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT italic_F ( italic_y ) and force yğ‘¦yitalic_y to imitate xğ‘¥xitalic_x (for a illustration with d=1ğ‘‘1d=1italic_d = 1 see Figure 3(a)). Indeed, with bilinear constraint we can build instances in which yğ‘¦yitalic_y player must choose yâˆˆ{x}ğ‘¦ğ‘¥y\in\{x\}italic_y âˆˆ { italic_x } while the xğ‘¥xitalic_x player is only constrained to play in the hypercube. Now, we have that âˆ‡xfâ¢(x,y)=Fâ¢(y)=Fâ¢(x)subscriptâˆ‡ğ‘¥ğ‘“ğ‘¥ğ‘¦ğ¹ğ‘¦ğ¹ğ‘¥\nabla_{x}f(x,y)=F(y)=F(x)âˆ‡ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_y ) = italic_F ( italic_x ) and thus, if xğ‘¥xitalic_x is a fixed point of gradient descent-ascent, we have that Fâ¢(x)âŠ¤â¢(xâ€²âˆ’x)â‰¥0ğ¹superscriptğ‘¥topsuperscriptğ‘¥â€²ğ‘¥0F(x)^{\top}(x^{\prime}-x)\geq 0italic_F ( italic_x ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT ( italic_x start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT - italic_x ) â‰¥ 0, implying that xğ‘¥xitalic_x is a solution to LinearVI-HC. This idea is enough to prove hardness of the convex-concave case with bilinear constraints (Theorem 1.4). Approximate imitation and jointly convex constraints Attempting to apply the same construction as in the case of bilinear constraints quickly leads to seemingly insurmountable challenges. First, the function used in the previous construction was convex-concave, and equilibria for such functions are easy to compute on a jointly convex set Kğ¾Kitalic_K. Therefore, we must increase the complexity of fğ‘“fitalic_f to be at least quadratic in xğ‘¥xitalic_x or yğ‘¦yitalic_y. Second, the most natural way to extend the imitation gadget from bilinear constraints to jointly convex ones is to consider the set Kâ‰”{x,y:â€–xâˆ’yâ€–âˆâ‰¤Î”}â‰”ğ¾conditional-setğ‘¥ğ‘¦subscriptnormğ‘¥ğ‘¦Î”K\coloneqq\{x,y:\|x-y\|_{\infty}\leq\Delta\}italic_K â‰” { italic_x , italic_y : âˆ¥ italic_x - italic_y âˆ¥ start_POSTSUBSCRIPT âˆ end_POSTSUBSCRIPT â‰¤ roman_Î” }, for â€œsmallâ€ values of Î”Î”\Deltaroman_Î”. However, this comes at a high cost: we can no longer disregard player yğ‘¦yitalic_y and consider only the optimality condition of the xğ‘¥xitalic_x player. What if the solution x,yğ‘¥ğ‘¦x,yitalic_x , italic_y found by solving the min-max problem is on the boundary of the set Kğ¾Kitalic_K? Intuitively, we can see that the constraint {x,y:â€–xâˆ’yâ€–âˆâ‰¤Î”}conditional-setğ‘¥ğ‘¦subscriptnormğ‘¥ğ‘¦Î”\{x,y:\|x-y\|_{\infty}\leq\Delta\}{ italic_x , italic_y : âˆ¥ italic_x - italic_y âˆ¥ start_POSTSUBSCRIPT âˆ end_POSTSUBSCRIPT â‰¤ roman_Î” } can only limit one player at the time and either the xğ‘¥xitalic_x player or the yğ‘¦yitalic_y player can move towards any deviation xâ€²superscriptğ‘¥â€²x^{\prime}italic_x start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT.111Formally this is not entirely accurate; we need to decompose a deviation direction into two distinct components, one corresponding to the xğ‘¥xitalic_x-player and the other to the yğ‘¦yitalic_y-player. See Section 4.1 for more details. However, now we have to design fğ‘“fitalic_f to align the gradient of the yğ‘¦yitalic_y player to the operator Fâ¢(z)=Dâ¢z+cğ¹ğ‘§ğ·ğ‘§ğ‘F(z)=Dz+citalic_F ( italic_z ) = italic_D italic_z + italic_c of the LinearVI-HC instance we are reducing from. Otherwise an optimality condition of the yğ‘¦yitalic_y player on fğ‘“fitalic_f would be meaningless in terms of its implications for the original LinearVI-HC instance. A better embedding of an operator Fâ¢(z)ğ¹ğ‘§F(z)italic_F ( italic_z ) is to consider the function fâ¢(x,y)=(xâˆ’y)âŠ¤â¢Fâ¢(x)ğ‘“ğ‘¥ğ‘¦superscriptğ‘¥ğ‘¦topğ¹ğ‘¥f(x,y)=(x-y)^{\top}F(x)italic_f ( italic_x , italic_y ) = ( italic_x - italic_y ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT italic_F ( italic_x ). We can see that this is a promising choice since âˆ‡xfâ¢(x,y)=Fâ¢(x)+JFâ¢(x)âŠ¤â¢(xâˆ’y)subscriptâˆ‡ğ‘¥ğ‘“ğ‘¥ğ‘¦ğ¹ğ‘¥subscriptğ½ğ¹superscriptğ‘¥topğ‘¥ğ‘¦\nabla_{x}f(x,y)=F(x)+J_{F}(x)^{\top}(x-y)âˆ‡ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_x ) + italic_J start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ( italic_x ) start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT ( italic_x - italic_y ), where JFâ¢(x)subscriptğ½ğ¹ğ‘¥J_{F}(x)italic_J start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ( italic_x ) is the Jacobian of Fğ¹Fitalic_F at xğ‘¥xitalic_x, and âˆ’âˆ‡yfâ¢(x,y)=Fâ¢(x)subscriptâˆ‡ğ‘¦ğ‘“ğ‘¥ğ‘¦ğ¹ğ‘¥-\nabla_{y}f(x,y)=F(x)- âˆ‡ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_x ). Given that the constraints enforce that â€–xâˆ’yâ€–â‰¤Î”normğ‘¥ğ‘¦Î”\|x-y\|\leq\Deltaâˆ¥ italic_x - italic_y âˆ¥ â‰¤ roman_Î”, we have that approximately both gradients are aligned with Fâ¢(x)ğ¹ğ‘¥F(x)italic_F ( italic_x ), and thus a solution to min-max would be a solution to the original LinearVI-HC instance (Figure 3(b)). Incidentally, the set Kğ¾Kitalic_K is the same considered in the reduction by \citetdaskalakis2021complexity. We analyze the connections with their reduction in the following paragraph. Relationship with the reduction of \citetdaskalakis2021complexity Our reduction follows a completely different approach than previous works. While we reduce from a continuous optimization problem, naturally defined on the hypercube, \citetdaskalakis2021complexity reduce from a discrete optimization problem related to Spernerâ€™s lemma. This allows us to work with simple degree-two polynomials instead of building functions that are defined by circuits of some discrete problem. This simpler construction provides stronger results, such as simpler functions, constant smoothness, and hardness for larger approximations. More in detail, the reduction of \citetdaskalakis2021complexity starts from a problem (HighD-BiSperner) related to a generalization of Spernerâ€™s lemma \citepsperner1928neuer. They partition the dğ‘‘ditalic_d-dimensional hypercube in cublets and color each vertex with dğ‘‘ditalic_d colors out of a total of 2â¢d2ğ‘‘2d2 italic_d colors (instead of the d+1ğ‘‘1d+1italic_d + 1 usually used in Spernerâ€™s lemma). This problem is shown to be PPAD-hard by a reduction from Brouwer. Then they build a function fğ‘“fitalic_f such that the fixed points of gradient descent-ascent dynamics are close to panchromatic cubelets of the simplicization, in which they interpret the dğ‘‘ditalic_d colors of each vertex as directions of the pseudo-gradient of fğ‘“fitalic_f. To do so, they give a function value and direction based on the local coloring and then interpolate the function with a high-degree smooth step function. This ingenious construction is extremely technical and requires careful techniques to ensure that no extra fixed points of gradient descent-ascent are created outside of those corresponding to panchromatic cubelets. It is precisely this last requirement that forces a coupling between the strategies of the minimizer and maximizer variables since the coefficients of the interpolation produce perturbations in the pseudo-gradient, which depend on the difference xâˆ’yğ‘¥ğ‘¦x-yitalic_x - italic_y. It might seem that this issue is merely technical, and it might be corrected, for example, by using another interpolation scheme. However, our reduction, which uses completely orthogonal techniques, shows that such constraints alone are enough to make the problem hard. This suggests that, in \citetdaskalakis2021complexity, these constraints are not merely a technical detail but play a fundamental role in driving the complexity of the problem. 1.3 Further Related Work Complexity of optimization problems We contribute to the line of work that shows lower bounds of optimization problems employing tools from computational complexity. This new line of research has achieved remarkable results with significant implications across complexity theory \citepfearnley2022complexity, game theory \citepbabichenko2021settling, and machine learning \citepdaskalakis2021complexity, hollender2023computational. Optimization problems belong naturally to the class of total search problem (TFNP) \citepjohnson1988easy,megiddo1991total,papadimitriou1994complexity. The bridge between optimization and search problems is not new and, for instance, it has been the main motivation for the definition of the PLS class \citepjohnson1988easy, schaffer1991simple, krentel1989structure. \citetfearnley2022complexity showed that the problem of computing fixed points of gradient descent is complete for the class PLSâˆ©PPADPLSPPAD{\textup{{PLS}}}\cap{\textup{{PPAD}}}PLS âˆ© PPAD, and this result also proves that such class is equal to CLS. Therefore, it lies much lower in the hierarchy of TFNP problems then PPAD. Moreover, while we work inside the framework of â€œconstrainedâ€ optimization (meaning that we work inside the hypercube rather than on the entire Euclidean space), there are some very recent works that consider the computational complexity of optimization in the unconstrained setting \citephollender2023computational, kontogiannis2024computational. Membership results There are a few recent works that give general techniques to prove PPAD-membership of TFNP problems. \citetpapadimitriou2023computational is the first to define a meaningful computational problem related to Kakutaniâ€™s theorem. Their main contribution is enabling a highly general representation of the sets (e.g., via separation oracles). Their main interest is Kakutaniâ€™s problem with application to concave games, while our focus is on QVIs, which are more general. More details about this relationship can be found in Section C.3. More recently, \citetfilos2024ppad extended the â€œpseudogateâ€ technique of \citetfilos2023fixp (originally used for FIXP-membership results) to the PPAD setting. They designed a general technique, based on pseudogates, that can be used to easily prove membership of an impressive number of problems with exact rational solutions. Imitation The idea of imitation in recent years has been instrumental in various PPAD-hardness results \citepmclennan2005imitation,rubinstein2015inapproximability,babichenko2016query,babichenko2020communication,babichenko2021settling. These settings mainly focus on general-sum games, and imitation is attained through carefully designed payoffs of one (or more) player. However, our setting is zero-sum, and adding an imitation component to the payoff would discourage one player from imitating just as much as it would encourage the other. Thus, our result can be seen as enforcing imitation through constraints rather than payoffs. Solving min-max problems A substantial body of recent research has focused on developing practical first-order and low-order methods for min-max optimization problems. A wide range of works illustrate divergent or cycling behavior when extending beyond minimization problems \citepmertikopoulos2018cycles,hsieh2021limits. However, efficient algorithms are available for well-behaved objectives. In the convex-concave setup, solutions can be efficiently computed using convex programming techniques \citepkorpelevich1976extragradient,azizian2020tight,golowich2020last,mazumdar2020gradient,hamedani2021primal,daskalakis2019last,mokhtari2020unified,abernethy2021last and via algorithms for monotone VIs \citepbruck1977weak,eckstein1992douglas,tseng1995linear,nemirovski2004prox,chen2017accelerated,gorbunov2022extragradient. Nonconvex-concave problems with â€œsimpleâ€ constraints can also be solved efficiently \citepdaskalakis2018training,nouiehed2019solving,lin2020gradient,lin2020near,kong2021accelerated,ostrovskii2021efficient. In the nonconvex-nonconcave setting, motivated by the complexity results of \citepdaskalakis2021complexity, research has focused on identifying structural assumptions on the objective (e.g., assuming the weak Minty variational inequality holds) that can help overcome the computational hardness barriers \citepdiakonikolas2021efficient,pethick2022escaping, and identifying different notions of local solutions and studying convergence to these points \citepjin2020local,mangoubi2021greedy,keswani2022convergent. Finally, a more recent stream of works considers different notions of stationarity, such as Goldsteinâ€™s stationarity to handle nonsmooth objectives \citepzhang2020complexity,jordan2022complexity,kornowski2024hardness."
https://arxiv.org/html/2411.02942v1,Constant Approximation for Weighted Nash Social Welfare with Submodular Valuations,"We study the problem of assigning items to agents so as to maximize the weighted Nash Social Welfare (NSW) under submodular valuations. The best-known result for the problem is an Oâ¢(nâ¢wmax)ğ‘‚ğ‘›subscriptğ‘¤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT )-approximation due to Garg, Husic, Li, Vega, and Vondrak [13], where wmaxsubscriptğ‘¤w_{\max}italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum weight over all agents. Obtaining a constant approximation algorithm is an open problem in the field that has recently attracted considerable attention.We give the first such algorithm for the problem, thus solving the open problem in the affirmative. Our algorithm is based on the natural Configuration LP for the problem, which was introduced recently by Feng and Li [11] for the additive valuation case. Our rounding algorithm is similar to that of Li [25] developed for the unrelated machine scheduling problem to minimize weighted completion time. Roughly speaking, we designate the largest item in each configuration as a large item and the remaining items as small items. So, every agent gets precisely 1 fractional large item in the configuration LP solution. With the rounding algorithm in [25], we can ensure that in the obtained solution, every agent gets precisely 1 large item, and the assignments of small items are negatively correlated.","We study the problem of allocating a set Mğ‘€Mitalic_M of indivisible items among a set Nğ‘Nitalic_N of agents, where each agent iâˆˆNğ‘–ğ‘i\in Nitalic_i âˆˆ italic_N has a monotone non-negative submodular valuation vi:2Mâ†’â„â‰¥0:subscriptğ‘£ğ‘–â†’superscript2ğ‘€subscriptâ„absent0v_{i}:2^{M}\to\mathbb{R}_{\geq 0}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : 2 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT â†’ blackboard_R start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT and a weight wiâˆˆ(0,1)subscriptğ‘¤ğ‘–01w_{i}\in(0,1)italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ ( 0 , 1 ) with âˆ‘iâˆˆNwi=1subscriptğ‘–ğ‘subscriptğ‘¤ğ‘–1\sum_{i\in N}w_{i}=1âˆ‘ start_POSTSUBSCRIPT italic_i âˆˆ italic_N end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1. The weighted Nash Social Welfare (NSW) problem under submodular valuations asks for partition ğ’®:=(Si)iâˆˆNassignğ’®subscriptsubscriptğ‘†ğ‘–ğ‘–ğ‘{\cal S}:=(S_{i})_{i\in N}caligraphic_S := ( italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i âˆˆ italic_N end_POSTSUBSCRIPT of Mğ‘€Mitalic_M that maximizes the weighted geometric mean of the agentsâ€™ valuations: ğ–­ğ–²ğ–¶â¢(ğ’®)=âˆiâˆˆN(viâ¢(Si))wi.ğ–­ğ–²ğ–¶ğ’®subscriptproductğ‘–ğ‘superscriptsubscriptğ‘£ğ‘–subscriptğ‘†ğ‘–subscriptğ‘¤ğ‘–\mathsf{NSW}({\cal S})=\prod_{i\in N}\left(v_{i}(S_{i})\right)^{w_{i}}.sansserif_NSW ( caligraphic_S ) = âˆ start_POSTSUBSCRIPT italic_i âˆˆ italic_N end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT . The case when all wisubscriptğ‘¤ğ‘–w_{i}italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPTâ€™s are equal to 1/n1ğ‘›1/n1 / italic_n is called the unweighted Nash Social Welfare problem. As usual, we assume we are given a value oracle for each visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. W.l.o.g, we assume viâ¢(âˆ…)=0subscriptğ‘£ğ‘–0v_{i}(\emptyset)=0italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( âˆ… ) = 0 for every agent iâˆˆNğ‘–ğ‘i\in Nitalic_i âˆˆ italic_N 111If viâ¢(âˆ…)>0subscriptğ‘£ğ‘–0v_{i}(\emptyset)>0italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( âˆ… ) > 0 for some iâˆˆNğ‘–ğ‘i\in Nitalic_i âˆˆ italic_N, we can create a â€œprivateâ€ item jisubscriptğ‘—ğ‘–j_{i}italic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for iğ‘–iitalic_i which has 00-value to all agents other than iğ‘–iitalic_i. We replace the valuation of iğ‘–iitalic_i with viâ€²subscriptsuperscriptğ‘£â€²ğ‘–v^{\prime}_{i}italic_v start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, which is defined as follows: viâ€²â¢(S):=viâ¢(S)âˆ’viâ¢(âˆ…)assignsubscriptsuperscriptğ‘£â€²ğ‘–ğ‘†subscriptğ‘£ğ‘–ğ‘†subscriptğ‘£ğ‘–v^{\prime}_{i}(S):=v_{i}(S)-v_{i}(\emptyset)italic_v start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) := italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) - italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( âˆ… ) if jiâˆ‰Ssubscriptğ‘—ğ‘–ğ‘†j_{i}\notin Sitalic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ‰ italic_S and viâ€²â¢(S)=viâ¢(Sâˆ–ji)subscriptsuperscriptğ‘£â€²ğ‘–ğ‘†subscriptğ‘£ğ‘–ğ‘†subscriptğ‘—ğ‘–v^{\prime}_{i}(S)=v_{i}(S\setminus j_{i})italic_v start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) = italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S âˆ– italic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) if jiâˆˆSsubscriptğ‘—ğ‘–ğ‘†j_{i}\in Sitalic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆˆ italic_S.. Fair and efficient allocation of resources is a central problem in computer science, game theory, and social choices, with applications across diverse domains [1, 3, 4, 22, 27, 31, 32, 37]. Three distinct communities independently discovered the notation of Nash social welfare: as a solution to the bargaining problem in classical game theory [28], as a well-established concept of proportional fairness in networking [23], and as the celebrated notion of competitive equilibrium with equal incomes in economics [35]. The unweighted case for the problem was introduced by Nash [28], and it was later extended to the weighted case [17, 21]. This extension has since been widely studied and applied across various fields, such as bargaining theory [7, 24, 34], water allocation [9, 19], climate agreements [38], and more. One of the most important features of the NSW objective is that it offers a tradeoff between the frequently conflicting demands of fairness and efficiency. A special case for the valuations visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is when they are additive. The unweighted NSW problem with additive valuations is an important topic in optimization and has received considerable interest. Barman, Krishnamurthy, and Vaish [2] developed a (ğ–¾1/ğ–¾â‰ˆ1.445)superscriptğ–¾1ğ–¾1.445(\mathsf{e}^{1/\mathsf{e}}\approx 1.445)( sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT â‰ˆ 1.445 )-approximation algorithm that finds an allocation that is both Pareto-efficient and envy-free up to one item (EF1). They showed that this problem can be reduced to the case of identical valuations, where any EF1 allocation can achieve an approximation ratio of ğ–¾1/ğ–¾â‰ˆ1.445superscriptğ–¾1ğ–¾1.445\mathsf{e}^{1/\mathsf{e}}\approx 1.445sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT â‰ˆ 1.445. On the negative side, Garg, Hoefer, and Mehlhorn [12] established a hardness of 8/787\sqrt{8/7}square-root start_ARG 8 / 7 end_ARG. For the weighted case with additive valuations, Brown, Laddha, Pittu, and Singh [5] introduced an approximation algorithm with a ratio of 5â‹…expâ¢(2â¢logâ¡n+2â¢âˆ‘iâˆˆAwiâ¢logâ¡wi)â‹…5exp2ğ‘›2subscriptğ‘–ğ´subscriptğ‘¤ğ‘–subscriptğ‘¤ğ‘–5\cdot\text{exp}(2\log n+2\sum_{i\in A}w_{i}\log w_{i})5 â‹… exp ( 2 roman_log italic_n + 2 âˆ‘ start_POSTSUBSCRIPT italic_i âˆˆ italic_A end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_log italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Later, Feng and Li [11] presented an elegant (ğ–¾1/ğ–¾+Ïµ)superscriptğ–¾1ğ–¾italic-Ïµ(\mathsf{e}^{1/\mathsf{e}}+\epsilon)( sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_Ïµ )-approximation algorithm for the weighted case, using their novel configuration LP and the Shmoys-Tardos rounding procedure developed in the context of unrelated machine scheduling. The approximation ratio matches the best-known ratio for the unweighted case. When the nğ‘›nitalic_n valuation functions are additive and identical, Nguyen and Rothe [29] developed a PTAS for the unweighted NSW problem. Later, Inoue and Kobayashi [20] gave an additive PTAS for the problem, i.e., a polynomial-time algorithm that maximizes the Nash social welfare within an additive error of Ïµâ¢vmaxitalic-Ïµsubscriptğ‘£\epsilon v_{\max}italic_Ïµ italic_v start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT, where vmaxsubscriptğ‘£v_{\max}italic_v start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum utility of an item. Li and Vondrak [26] developed the first constant approximation algorithm for unweighted NSW with submodular valuations using convex programming. The ratio has been improved by Garg, Husic, Li, Vega, and Vondrak [13] to (4+Ïµ)4italic-Ïµ(4+\epsilon)( 4 + italic_Ïµ ) using an elegant local-search-based algorithm. When additionally n=Oâ¢(1)ğ‘›ğ‘‚1n=O(1)italic_n = italic_O ( 1 ), by guessing the value and the Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 ) largest items for each agent, and using the multilinear extension of submodular functions, a ğ–¾/(ğ–¾âˆ’1)ğ–¾ğ–¾1\mathsf{e}/(\mathsf{e}-1)sansserif_e / ( sansserif_e - 1 )-approximation can be achieved [16]. In the same paper, [16] proved that unweighted NSW with submodular valuations is hard to approximate within ğ–¾/(ğ–¾âˆ’1)âˆ’Ïµğ–¾ğ–¾1italic-Ïµ\mathsf{e}/(\mathsf{e}-1)-\epsilonsansserif_e / ( sansserif_e - 1 ) - italic_Ïµ. The hardness holds even for the case n=Oâ¢(1)ğ‘›ğ‘‚1n=O(1)italic_n = italic_O ( 1 ). For the weighted NSW problem with submodular valuations, [13] showed that the approximation ratio of the local search algorithm becomes Oâ¢(nâ¢wmax)ğ‘‚ğ‘›subscriptğ‘¤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ), where wmax:=maxiâˆˆ[n]â¡wiassignsubscriptğ‘¤subscriptğ‘–delimited-[]ğ‘›subscriptğ‘¤ğ‘–w_{\max}:=\max_{i\in[n]}w_{i}italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT := roman_max start_POSTSUBSCRIPT italic_i âˆˆ [ italic_n ] end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the maximum weight over the agents. In the new version [15] of the paper, the authors presented a (6â¢ğ–¾+Ïµ)6ğ–¾italic-Ïµ(6\mathsf{e}+\epsilon)( 6 sansserif_e + italic_Ïµ )-approximation algorithm with running time 2Oâ¢(nâ¢logâ¡n)â¢polyâ¢(m,1/Ïµ)superscript2ğ‘‚ğ‘›ğ‘›polyğ‘š1italic-Ïµ2^{O(n\log n)}\mathrm{poly}(m,1/\epsilon)2 start_POSTSUPERSCRIPT italic_O ( italic_n roman_log italic_n ) end_POSTSUPERSCRIPT roman_poly ( italic_m , 1 / italic_Ïµ ), which is polynomial when n=Oâ¢(1)ğ‘›ğ‘‚1n=O(1)italic_n = italic_O ( 1 ). For the more general setting where the valuations are subadditive, Dobzinski, Li, Rubinstein, and VondrÃ¡k [10] recently proposed a constant approximation algorithm when agents are unweighted, provided that we have access to demand oracles for the valuation functions. Our Result. In this paper, we give the first polynomial-time Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 )-approximation algorithm for weighted Nash social welfare under the submodular valuations. The best result prior to this work was the Oâ¢(nâ¢wmax)ğ‘‚ğ‘›subscriptğ‘¤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT )-approximation due to Garg, Husic, Li, Vega, and Vondrak [13]. Theorem 1.1. For any Ïµ>0italic-Ïµ0\epsilon>0italic_Ïµ > 0, there is a randomized (233+Ïµ)233italic-Ïµ(233+\epsilon)( 233 + italic_Ïµ )-approximation algorithm for the weighted Nash social welfare problem with submodular valuations, with running time polynomial in the size of the input and 1Ïµ1italic-Ïµ\frac{1}{\epsilon}divide start_ARG 1 end_ARG start_ARG italic_Ïµ end_ARG. For convenience, we list the known approximation results for the NSW problem in table 1. Additive Submodular Subadditive LB UB LB UB LB UB Unweighted 8787\sqrt{\frac{8}{7}}square-root start_ARG divide start_ARG 8 end_ARG start_ARG 7 end_ARG end_ARG [12] ğ–¾1/ğ–¾+Ïµsuperscriptğ–¾1ğ–¾italic-Ïµ\mathsf{e}^{1/\mathsf{e}}+\epsilonsansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_Ïµ [2] ğ–¾ğ–¾âˆ’1ğ–¾ğ–¾1\frac{\mathsf{e}}{\mathsf{e}-1}divide start_ARG sansserif_e end_ARG start_ARG sansserif_e - 1 end_ARG [16] 4+Ïµ4italic-Ïµ4+\epsilon4 + italic_Ïµ [13] Oâ¢(1)âˆ—ğ‘‚superscript1O(1)^{*}italic_O ( 1 ) start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT [10] Weighted ğ–¾1/ğ–¾+Ïµsuperscriptğ–¾1ğ–¾italic-Ïµ\mathsf{e}^{1/\mathsf{e}}+\epsilonsansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_Ïµ [11] 233+Ïµ233italic-Ïµ233+\epsilon233 + italic_Ïµ (theorem 1.1) Table 1: Known Results for Nash social welfare. LB and UB stand for lower and upper bounds, respectively. The result with âˆ— requires demand oracles for valuation functions. When the function is identical additive, the upper bound for the unweighted case is PTAS [20, 29]. When n=Oâ¢(1)ğ‘›ğ‘‚1n=O(1)italic_n = italic_O ( 1 ), the upper bounds for unweighted and weighted NSW with submodular valuations are respectively ğ–¾/(ğ–¾âˆ’1)ğ–¾ğ–¾1\mathsf{e}/(\mathsf{e}-1)sansserif_e / ( sansserif_e - 1 ) [16] and 6â¢ğ–¾+Ïµ6ğ–¾italic-Ïµ6\mathsf{e}+\epsilon6 sansserif_e + italic_Ïµ [15]. 1.1 Overview of Our Techniques Our algorithm leverages the configuration LP introduced in [11] for the additive valuation case. For each agent iâˆˆNğ‘–ğ‘i\in Nitalic_i âˆˆ italic_N and subset of items SâŠ†Mğ‘†ğ‘€S\subseteq Mitalic_S âŠ† italic_M, we define a variable yi,Ssubscriptğ‘¦ğ‘–ğ‘†y_{i,S}italic_y start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT to indicate whether the set of items assigned to iğ‘–iitalic_i is precisely Sğ‘†Sitalic_S. The objective of this LP is to minimize âˆ‘i,Syi,Sâ‹…wiâ‹…lnâ¡viâ¢(S)subscriptğ‘–ğ‘†â‹…subscriptğ‘¦ğ‘–ğ‘†subscriptğ‘¤ğ‘–subscriptğ‘£ğ‘–ğ‘†\sum_{i,S}y_{i,S}\cdot w_{i}\cdot\ln v_{i}(S)âˆ‘ start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT â‹… italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT â‹… roman_ln italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ), the logarithm of the NSW objective. After solving the LP, we apply the rounding procedure from [25], developed for the weighted completion time minimization problem in the unrelated machine scheduling setting. Then we prove concentration bounds for the values obtained by each agent, using arguments developed for pipage rounding. To build intuition, let us focus on the unweighted case. For the special case where |M|=|N|ğ‘€ğ‘|M|=|N|| italic_M | = | italic_N |, the problem reduces to a maximum-weight bipartite matching problem with weights given by the logarithm of values. So, any general algorithm for the problem must capture the maximum weight of the bipartite matching algorithm as a special case. Interestingly, previous results showed that if one is given the largest (i.e., the most valuable) item assigned to every agent, then an Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 )-approximation algorithm is easy to obtain using local search [13] or LP rounding [14, 26]. For example, with this idea, Garg, Husic, Li, Vega, and Vondrak [13] designed an elegant 4-approximation local search algorithm. They first compute an initial matching of one item to every agent so as to maximize the NSW objective, then assign the remaining items using local search with an endowed valuation function, and finally rematch the initially assigned items to agents to maximize the final Nash social welfare. Unfortunately, their algorithm fails to give an Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 )-approximation when the agents are weighted. Our algorithm implements the idea of â€œmatching largest items to agentsâ€ using the configuration LP solution as a guide. We achieve a per-client guarantee, allowing us to give an Oâ¢(1)ğ‘‚1O(1)italic_O ( 1 )-approximation for the weighted NSW problem with submodular valuations. After obtaining an LP solution (yi,Sâˆ—)i,Ssubscriptsubscriptsuperscriptğ‘¦ğ‘–ğ‘†ğ‘–ğ‘†(y^{*}_{i,S})_{i,S}( italic_y start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT, for each agent iğ‘–iitalic_i and configuration Sğ‘†Sitalic_S, we designate the largest item in Sğ‘†Sitalic_S as a â€œlargeâ€ item for iğ‘–iitalic_i, while treating the remaining items as â€œsmallâ€. This creates a fractional assignment in which each agent receives exactly one fractional large item. While maintaining marginal probabilities in our rounding algorithm, we ensure that each agent gets exactly one large item, and the assignment of small items are negatively correlated. That is, we select a random matching for large items. If the large and small items were disjoint, the rounding algorithm would be straightforward. However, complications arise when an item may be large for one agent and small for another â€” or even for the same agent in different configurations. This necessitates a correlated assignment strategy for large and small items. This is where we employ the iterative rounding procedure of [25]. We construct a bipartite multi-graph between agents and items, with two edge types: marked edges for large items and unmarked edges for small items. During iterative rounding, we identify either a simple cycle of marked edges or a pseudo-marked path â€“ a simple path of marked edges with two unmarked edges at the ends â€“ and apply rotation or shifting operations on the cycle or path in each iteration. This process ultimately yields an integral assignment. To analyze the approximation ratio, we focus on each agent iğ‘–iitalic_i and analyze ğ”¼â¢[lnâ¡(viâ¢(T))]ğ”¼delimited-[]subscriptğ‘£ğ‘–ğ‘‡\mathbb{E}[\ln(v_{i}(T))]blackboard_E [ roman_ln ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T ) ) ], where Tğ‘‡Titalic_T is the set of items assigned to iğ‘–iitalic_i. Note that Tğ‘‡Titalic_T includes exactly one large item, respecting the marginal probabilities. Let TSsuperscriptğ‘‡ST^{\mathrm{S}}italic_T start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT denote the remaining items, i.e., the small items assigned to iğ‘–iitalic_i. The assignments of the large item and the small items may be positively correlated, so we analyze the worst-case scenario for this correlation. However, the assignments of the small items are negatively correlated; more precisely, they are determined through a pipage-rounding procedure. Using the concave pessimistic estimator technique from [18] and the submodularity of the function visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we can establish concentration bounds for viâ¢(TS)subscriptğ‘£ğ‘–superscriptğ‘‡Sv_{i}(T^{\mathrm{S}})italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT ). With the bounds, we can lower bound ğ”¼â¢[lnâ¡(viâ¢(T))]ğ”¼delimited-[]subscriptğ‘£ğ‘–ğ‘‡\mathbb{E}[\ln(v_{i}(T))]blackboard_E [ roman_ln ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T ) ) ] by âˆ‘Syi,Sâˆ—â¢lnâ¡viâ¢(S)âˆ’Oâ¢(1)subscriptğ‘†subscriptsuperscriptğ‘¦ğ‘–ğ‘†subscriptğ‘£ğ‘–ğ‘†ğ‘‚1\sum_{S}y^{*}_{i,S}\ln v_{i}(S)-O(1)âˆ‘ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT roman_ln italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) - italic_O ( 1 ). Organization. The rest of the paper is organized as follows. We introduce some preliminaries in section 2, describe our algorithm in section 3, and give its analysis in section 4. For a smoother flow in the main text, we defer some proofs to the appendix."
https://arxiv.org/html/2411.02661v1,Pricing and Competition for Generative AI,"Compared to classical machine learning (ML) models, generative models offer a new usage paradigm where (i) a single model can be used for many different tasks out-of-the-box; (ii) users interact with this model over a series of natural language prompts; and (iii) the model is ideally evaluated on binary user satisfaction with respect to model outputs. Given these characteristics, we explore the problem of how developers of new generative AI software can release and price their technology. We first develop a comparison of two different models for a specific task with respect to user cost-effectiveness. We then model the pricing problem of generative AI software as a game between two different companies who sequentially release their models before users choose their preferred model for each task. Here, the price optimization problem becomes piecewise continuous where the companies must choose a subset of the tasks on which to be cost-effective and forgo revenue for the remaining tasks. In particular, we reveal the value of market information by showing that a company who deploys later after knowing their competitorâ€™s price can always secure cost-effectiveness on at least one task, whereas the company who is the first-to-market must price their model in a way that incentivizes higher prices from the latecomer in order to gain revenue. Most importantly, we find that if the different tasks are sufficiently similar, the first-to-market model may become cost-ineffective on all tasks regardless of how this technology is priced.","The recent explosion of generative artificial intelligence (AI) has introduced new machine learning (ML) frameworks for applications from chatbots to robotics (Wu et al., 2023; Nasiriany et al., 2024). Whereas in classical ML, a user interacted with a single model designed for a specific predictive task (e.g., classification) via input data and output predictions, a single generative AI model can solve a variety of tasks for a user out-of-the-box (Brown et al., 2020). Moreover, users interact with the generative model over a universal interface of natural language prompting (Arora et al., 2022). The prompt-based paradigm has fostered two recent human-AI interaction trends. First, prompting facilitates such a wide distribution of tasks (i.e., user inputs and model outputs) that conventional metrics for evaluating models have become insufficient, leaving the most effective evaluation metric to be a binary score of whether the user is satisfied with the model output (Li et al., 2024; Chiang et al., 2024). For example, Ziegler et al. (2024) empirically analyzed the GitHub Copilot software to reveal that the frequency of generated code approved by a user â€˜is a better predictor of perceived [user] productivity than alternative measures.â€™ Second, if a user does not receive a satisfactory output, they can try again in another prompting round by inputting to the model additional information (Castro et al., 2023). For instance, the Anthropic HH and the Chatbot Arena datasets report on average 2.3 and 1.3 prompting rounds per conversation, respectively (Bai et al., 2022; Chiang et al., 2024). In this work, we study the impact of these interaction characteristics on the pricing of generative AI technology. While classical ML products can be priced by analyzing the user demand for a model that can achieve a given performance metric on a specific task (Gurkan and de VÃ©ricourt, 2022; Mahmood et al., 2022), a generative AI model is priced per user prompt 111 In practice, generative AI models are typically priced-per-token. In Appendix B, we show that all our results extend to the price-per-token setting with a minor change of variables. For a list of prices for current generative AI prices, see: https://docsbot.ai/tools/gpt-openai-api-pricing-calculator.. This set price determines the user cost for multiple different tasks and variable number of prompting rounds, e.g., the cost of using GPT-4 for math reasoning or code generation depends only on the per-token price, and the length and number of prompts. Thus, developers of a generative AI product must factor the demand for all potential use-case tasks of the technology when setting a price. This pricing problem becomes further challenging when considering the rapidly growing marketplace of competing generative AI models, since companies must also ensure that their products do not become unattractive to users as soon as a competitor develops a newer and better model. We first characterize when, for a given task, a user will prefer one generative AI model versus another. We argue that users minimize their total cost, measured by the cost-per-prompt times the number of prompting rounds needed for the model to produce a satisfactory output; this leads to a comparison of price-performance competitiveness between AI models. We then study a game with two firms developing competing models used for a set of tasks. Both firms know each otherâ€™s modelâ€™s performance on the tasks. The first firm deploys their product and sets a price, followed by the second firm with their product and price. Finally, a user decides which models to use for each task. Both firms seek to maximize revenue, but the first firm acts without knowledge of their competitorâ€™s price. Figure 1 summarizes the problem setting and insights. Our key observations include: 1. The pricing problem reduces to a piecewise optimization problem, where firms price their model to be competitive on a subset of the tasks while forgoing revenue from the others. This subset can be determined by ranking the tasks on the competitive ratio between the two models for each task and selecting the most competitive tasks. 2. A firm who deploys late always obtains revenue from at least one task by leveraging the available market information. In contrast, the first-to-market must strategically set their prices to encourage the latecomer to set higher prices and focus on fewer tasks. 3. Under certain conditions on model performance and user demand, the first-to-market may acquire zero revenue regardless of their price. In these settings, the latecomer naturally maximizes their revenue by being competitive for all tasks. Thus, developers that are first should have a minimum model performance before deploying their product. Figure 1: Overview of the competitive pricing problem for generative AI models."
https://arxiv.org/html/2411.02654v1,Fair and Welfare-EfficientConstrained Multi-matchings under Uncertainty,"We study fair allocation of constrained resources, where a market designer optimizes overall welfare while maintaining group fairness. In many large-scale settings, utilities are not known in advance, but are instead observed after realizing the allocation. We therefore estimate agent utilities using machine learning. Optimizing over estimates requires trading-off between mean utilities and their predictive variances. We discuss these trade-offs under two paradigms for preference modeling â€“ in the stochastic optimization regime, the market designer has access to a probability distribution over utilities, and in the robust optimization regime they have access to an uncertainty set containing the true utilities with high probability. We discuss utilitarian and egalitarian welfare objectives, and we explore how to optimize for them under stochastic and robust paradigms. We demonstrate the efficacy of our approaches on three publicly available conference reviewer assignment datasets. The approaches presented enable scalable constrained resource allocation under uncertainty for many combinations of objectives and preference models.","Constrained resource allocation without money underpins many important systems, including reviewer assignment for peer review (our primary example throughout the paper) [31, 54, 45, 16, 4], assigning resources to homeless populations [5, 49, 34], distributing emergency response resources [51, 56, 57], and more [53, 44, 1]. In these settings we assign resources to agents. Agents and resources are constrained; each agent has bounds on the minimum or maximum number of items they receive from different categories, and each item has required minimums and limited total capacity. Each agent has a valuation for every item, and we optimize a welfare function of the agent-item valuations. In the case of reviewer assignment, the reviewer-paper valuations measure the alignment between reviewers and papers, papers must receive a certain number of reviews from unique reviewers, reviewers have upper limits on the number of papers they can review, and conflicts of interest prevent some reviewers from being assigned to certain papers. A crucial factor in all of the above settings is the presence of uncertainty. Uncertainty often stems from the fact that agentsâ€™ valuations for resources depend on future outcomes. In reviewer assignment, a reviewer-paper pairâ€™s match quality is observed only after the reviewer submits his or her review. Uncertainty may also stem from our limited ability to collect data; for example, in deciding where to target lead pipe mitigation projects based on number of school-aged children per neighborhood, we may have access to imperfect school enrollment records, allowing only an approximate model of the impacts of mitigation on children in each neighborhood [53]. We adopt two possible stances towards uncertainty, depending on the information available. When we have access to a probability distribution over preferences, we optimize the conditional expectation of the distribution at percentiles of interest [50, 33]. When we have access to a set of possible preferences, we adopt the robust approach, which is related to the minimax regret objective used in solving robust assignment problems [3, 10, 11, 32]. Uncertainty-aware optimization approaches can often result in significantly different allocations from the default of optimizing for welfare over a central estimate (see Example 2.1 for an intuitive explanation for this phenomenon). Typically, we maximize the sum of agent utilities. However, in many of these settings, we are also concerned with fairness to individuals or groups of agents. Groups of agents may represent subject areas of papers in reviewer assignment, demographic groups in poverty alleviation campaigns, or regional groupings of computational resources in bandwidth allocation. Fairness to these groups may be legally required in some cases; in others it is an ethical choice by the decision maker. Although groups are often first-class objects worthy of receiving fair treatment, group fairness is often the smallest granularity of fairness achievable under uncertainty â€“ in a large dataset uncertainty will always cause some individuals to have vanishing welfare, but group welfare can still be upheld. Although there is much literature on combinatorial optimization under uncertainty [33, 3, 10, 11, 32], to our knowledge it has not addressed the intersection of fairness and uncertainty in the constrained multi-matching problem. 1.1 Our Contributions We study the broad problem of fair and efficient constrained multi-matchings under uncertainty about agentsâ€™ valuations. We optimize for welfare while simultaneously accounting for the uncertainty inherent in real-world resource allocation problems. Specifically, we develop methods to efficiently optimize the utilitarian and egalitarian welfare objectives using the robust approach [26, 8, 7] and the CVaRCVaR\operatorname{CVaR}roman_CVaR approach [50]. Our results are summarized in Table 1. For robust optimization, we construct an uncertainty set containing the true preferences with high probability (Section 3). This model is appropriate when building a predictor with statistical error bounds, but without making any assumptions on the full probability distribution over valuations. For utilitarian and egalitarian welfare functions, we robustly maximize welfare over such uncertainty sets. When the uncertainty sets are linear we can efficiently compute the exact optimal allocations for both utilitarian and egalitarian welfare in polynomial time (Corollaries 3.2 and 3.6). Under a single ellipsoidal uncertainty set, we can apply an iterated quadratic programming approach (Corollaries 3.3 and 3.7), while a projected subgradient ascent approach is needed when uncertainty sets consist of multiple ellipsoids (Propositions 3.1 and 3.5). Under general monotonic, concave welfare functions and arbitrary convex uncertainty sets, we apply the relatively expensive adversarial projected subgradient ascent algorithm of Cousins et al. [16]. When the market designer can construct a full probability distribution over preferences or sample from such a distribution, we consider stochastic optimization using the concept of Conditional Value at Risk, or CVaRCVaR\operatorname{CVaR}roman_CVaR [50]. This approach, laid out in Section 4, selects an allocation that maximizes the conditional expectation of welfare over the left tail of the welfare distribution. We often approximate CVaRCVaR\operatorname{CVaR}roman_CVaR objectives using sampling, then solve the resulting linear program or LP (as in Propositions 4.1 and H.3). However, in the case of utilitarian welfare and Gaussian-distributed valuations we present a simple reformulation of the CVaRCVaR\operatorname{CVaR}roman_CVaR objective (Proposition 4.3). Optimizing CVaRCVaR\operatorname{CVaR}roman_CVaR for general monotonic, concave welfare functions can require solving arbitrary concave optimization problems, even after sampling. We also compare these optimization approaches empirically in Section 5 on reviewer assignment data from AAMAS 2015201520152015, 2016201620162016, and 2021202120212021. 1.2 Related work We discuss the history of prior work on robust and CVaRCVaR\operatorname{CVaR}roman_CVaR optimization in Appendix A. Some existing work applies stochastic or robust optimization to fair division problems. A line of work studies the minimax regret objective in combinatorial optimization problems, such as constrained resource allocation [3, 10, 11, 32]. This work does not explicitly consider multi-matching problems like those considered here, nor does it address the robust egalitarian welfare problem. Pujol et al. [48] study fair division problems with parameters noised for differential privacy, showing that the noise can cause unfair allocations; they propose a Monte Carlo approach to mitigate the unfairness with high probability. Peters et al. [46] study envy-free rent division under probabilistic uncertainty. A central mechanism divides rooms and sets room prices for the items to minimize envy. We study a setting without money, both utilitarian and egalitarian objectives, and robust optimization in addition to stochastic optimization. Cousins et al. [16] study robust optimization under the utilitarian objective. They propose an adversarial projected subgradient ascent method which requires solving a two quadratic programs (one for the adversary and one for the projection) at each iteration for a large number of iterations. Our empirical analysis in Section 5 demonstrates the inefficiency of this method. Fair machine learning algorithms [43, 23, 17, 59, 22] often employ similar adversarial optimization techniques over an uncertainty set in a machine learning context. Other fair allocation research has studied the case where agent demand or item availability are uncertain but preferences are known [14, 21, 27, 2]. In our case demand and availability are known but preferences are not. Devic et al. [20] consider fair two-sided matching where the fairness constraint is defined with respect to unknown parameters; we assume knowledge of the parameters that define the fairness constraint (i.e., group identities)."
https://arxiv.org/html/2411.02377v1,Two-Sided Learning in Decentralized Matching Markets,"Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications. In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups. However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another. In this work, we design completely uncoupled and uncoordinated policies that use an agentâ€™s limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences. In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets. Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy. We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group. To the best of the authorsâ€™ knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty.","Two-sided matching markets are a fundamental feature of various socioeconomic and engineered systems. In a two-sided market, agents from two distinct groups interact to form mutually beneficial partnerships. From college admissions to online dating, such markets arise ubiquitously. However, the ways in which matchingsâ€”sets of partnerships between agentsâ€”emerge can vary significantly depending on the market. Consider, for example, the American residency admissions process. Every year, residency applicants and hospitals submit their rankings of one another to the National Resident Matching Program (NRMP), the organization that assigns a matching between the two groups (Figure 1, left). Then, the NRMP employs an algorithm that uses these rankings to identify a stable matching, characterized by the property that no applicant and hospital prefer one another to their assigned partner. Identifying stable matchings is of paramount importance, as it ensures notions of fairness and efficiency in the resulting assignment. Providentially, at least one stable matching is guaranteed to exist in every two-sided matching market Gale and Shapley (1962), and a number of celebrated algorithms such as the one utilized in the NRMP have been developed to identify them Gale and Shapley (1962); Vate (1989); Roth et al. (1993); Roth and Peranson (1997). Importantly, because this process is centralized (i.e., the matching is assigned by the NRMP), one can always ensure that the resulting matching is stable. In contrast, in decentralized matching markets, there is no centralized entity that assigns the partnerships between agents. Instead, there is typically an active group of agents that iteratively seeks out, or proposes to, a passive group of agents that receives, or accepts, these proposals. This situation often arises in labor markets, where workers repeatedly attempt to win over desirable clients, and clients accept their most attractive offer from a worker. Depending on the agentsâ€™ policies (i.e., how they choose to make and accept proposals), a variety of matchings may arise in decentralized markets. However, in the case where agents know their own preferences over the other side of the market a priori, a number of natural policies are known to result in a matching that is stable Gale and Shapley (1962); Roth and Vate (1990); Blum et al. (1997); Ackermann et al. (2008), preserving the guarantees of fairness and efficiency ingrained in the centralized setting. However, in many practical decentralized markets, the assumption that agents know their own preferences does not hold. For example, in labor markets with massive numbers of workers and clients, it can be challenging for every worker to rank all of the clients and vice versa, making it difficult or impossible for agents to follow any kind of policy that uses their rankings. Motivated by these kinds of decentralized markets, several recent works have made significant progress in designing novel policies whereby agents simultaneously and independently learn their own preferences while forming matchings, with the added guarantee that the matchings resulting from these policies are stable Liu et al. (2020, 2021); Basu et al. (2021); Jagadeesan et al. (2021); Cen and Shah (2022); Maheshwari et al. (2022); Kong and Li (2023); Hosseini et al. (2024). In the case of one-sided learning, where the proposing agents do not know their own preferences, but the accepting agents do, a handful of completely decentralized and uncoordinated policies have recently been shown to guarantee different notions of probabilistic convergence to stable matchings Etesami and Srikant (2024); Shah et al. (2024). In the case of two-sided learning, where no agent knows their own preferences (Figure 1, right), a few works have designed algorithms with similar guarantees, but they require some form of centralized communication or coordination between the agents that may not be possible in practical scenarios Das and Kamenica (2005); Pagare and Ghosh (2023); Pokharel and Das (2023). Thus, the challenge of designing completely decentralized and uncoordinated policies for the two-sided setting that guarantee convergence to stability remains unresolved. Figure 1. A two-sided matching market with 3 proposers and 3 acceptors. In a centralized environment with full information (left), an algorithm uses the agentsâ€™ known preferences to assign a matching. In a decentralized environment with two-sided uncertainty (right), agents learn their own preferences over one another as they interact and form matchings. In this work, we aim to design policies for both the one- and two-sided learning settings that do not require agents to communicate or coordinate with one another. To this end, we consider trial-and-error learning, a type of policy that enables agents to learn their preferences over partners through structured yet random exploration. In our preliminary results (Theorem 1), we demonstrate that a simple form of trial-and-error learning guarantees a notion of probabilistic convergence to stable matchings in the case of one-sided learning. Then, in our first main contribution (Theorem 2), we show that the same result holds true in the case of two-sided learning. Inspired by similar questions of strategyproofness in matching markets Dubins and Freedman (1981); Gale and Sotomayor (1985), we then ask whether one group of agents can strategically improve their outcome when the other group of agents continues to follow simple trial-and-error learning. In our second main contribution (Theorem 3), we constructively answer this question in the affirmative, demonstrating that if the accepting group of agents follows a more advanced version of trial-and-error learning, then the process will converge to their most preferable stable matching. To the best of the authorsâ€™ knowledge, these are the first completely decentralized and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized matching markets with two-sided uncertainty. These policies are inspired by results on learning in games, a subfield of game theory concerned with the design of policies that ensure probabilistic convergence to desirable configurations such as Nash equilibria or Pareto efficient action profiles Young (1993); Fudenberg and Levine (1998); Marden et al. (2009); Pradelski and Young (2012); Marden et al. (2014). By adapting these ideas to the realm of two-sided matching markets, we are able to provide fundamental results regarding the existence of simple policies that guarantee convergence to stability in the presence of uncertainty."
https://arxiv.org/html/2411.02308v1,Nash Equilibria via Stochastic Eigendecomposition,"This work proposes a novel set of techniques for approximating a Nash equilibrium in a finite, normal-form game. It achieves this by constructing a new reformulation as solving a parameterized system of multivariate polynomials with tunable complexity. In doing so, it forges an itinerant loop from game theory to machine learning and back. We show a Nash equilibrium can be approximated with purely calls to stochastic, iterative variants of singular value decomposition and power iteration, with implications for biological plausibility. We provide pseudocode and experiments demonstrating solving for all equilibria of a general-sum game using only these readily available linear algebra tools.","Nash equilibrium (NE) is the central solution concept for finite, normal-form games. Unfortunately, unless PPAD âŠ†\subseteqâŠ† P, no fully polynomial time algorithm exists to approximate it in generic, general-sum games (Daskalakis et al., 2009; Chen and Deng, 2006; Daskalakis, 2013). Nevertheless, it is important to develop a variety of techniques, for instance, tailored to different restricted game classes or honed to select out equilibria with particular properties. No-regret or gradient-based approaches are particularly lightweight and have been effective in certain applications although they come with no NE-convergence guarantees beyond 2222-player, zero-sum (Facchinei and Pang, 2007; Gordon et al., 2008; Blackwell et al., 1956; Vlatakis-Gkaragkounis et al., 2020). Homotopy methods have been designed to select out specific equilibria (Lemke and Howson, 1964; Govindan and Wilson, 2003, 2004; Harsanyi et al., 1988; Perolat et al., 2020), some with the additional characteristic of modelling players with bounded rationality (McKelvey and Palfrey, 1995, 1998; Turocy, 2005; EibelshÃ¤user and Poensgen, 2019; Gemp et al., 2022). The primary measure of approximation for NEs is exploitability, the maximum any player can gain by deviating from an approximate equilibrium profile. Hence, there exists a line of work that directly attempts to minimize exploitability using an optimization formulation (Shoham and Leyton-Brown, 2009; Sandholm et al., 2005; Gemp et al., 2023). Similarly, the property that no player can gain by deviating can be viewed as a constraint. Constraint satisfaction approaches were found to be effective empirically (Porter et al., 2008); other methods also take a search-tree approach (Berg and Sandholm, 2017; Gemp et al., 2023). Figure 1. (An Itinerant Loop) We identify a series of bridgesâ€”some new, some old, and some a mixâ€”that connects the problem of approximating Nash equilibria in normal-form games to problems in algebraic geometry, linear algebra, machine learning, and back again to finite games (albeit not precisely where the loop began). The boundaries between these families are not strict: search-based approaches mix with optimization, gradient based with homotopy-based approaches, etc. Of particular relevance to this work is the family of approaches that view the NE problem (NEP) as solving for the common roots of a system of multivariate polynomials subject to some constraints. For instance, an NEP can be represented as a polynomial complementarity problem (PCP) (Wilson, 1971): for each player, either an action is played with zero probability at an NE or it achieves the maximum payoff possible at the NE. Probabilities can be recovered from the unconstrained solutions to the PCP via normalization. An NEP can also be represented as a multivariate polynomial problem (MVP) with simplex constraints (Sturmfels, 2002, Section 6.3). Assuming a fully-mixed NE (i.e., one that lies in the interior of the simplex) exists, it can be solved for via a similar approach as above. Sturmfels (2002) demonstrates solving for these equilibria via PHCpack (Verschelde, 1999), a software package to solve polynomial systems by homotopy continuation methods. Unsurprisingly, these and other methods (Li, 1997) have parallels with the homotopy methods for approximating Nash equilibria mentioned above. Recently, renewed interest in numerical methods for solving polynomial systems via eigendecompositions has surged. While knowledge of these techniques has existed for some time, the goal of new research is to make these techniques more accessible to non-experts (Dreesen et al., 2012; Williams, 2010) as well as further developing the techniques (Vermeersch, 2023). These techniques generally assume access to linear algebra routines that make few assumptions on the matrices of interest. Contrast that with machine learning (ML) (Allen-Zhu and Li, 2017), where singular value decomposition (SVD) has received the bulk of the communityâ€™s interest, and whose underlying eigenvalue problem assumes a symmetric, positive semi-definite matrix. The focus here has been scaling to large matrices and reducing memory requirements by leveraging stochastic access to matrix entries. In this work, we develop a novel formulation of the approximate Nash equilibrium problem as a multivariate polynomial problem. Central to this formulation is the regularization of the game with Tsallis entropy (Gemp et al., 2022). Similar to other frameworks of bounded rationality such as logit equilibria (McKelvey and Palfrey, 1995), we can show this Tsallis regularized game is equivalent to a game where the log of the payoffs are perturbed by Gumbel(0,Ï„0ğœ0,\tau0 , italic_Ï„) noise (see Appendix B). Critically, given an approximate equilibrium x(Ï„)superscriptğ‘¥ğœx^{(\tau)}italic_x start_POSTSUPERSCRIPT ( italic_Ï„ ) end_POSTSUPERSCRIPT of the transformed game, we also provide bounds on the exploitability of x(Ï„)superscriptğ‘¥ğœx^{(\tau)}italic_x start_POSTSUPERSCRIPT ( italic_Ï„ ) end_POSTSUPERSCRIPT as measured in the original game similar to prior work (Gemp et al., 2023). Our MVP formulation is different from prior work and exhibits a distinct advantage. Whereas prior work results in MVPs that are at least quadratic, an NP-hard problem (Courtois et al., 2002), ours results in an MVP that is linear for the class of 2222-player, general-sum games and for a specific setting of the Tsallis entropy parameter Ï„ğœ\tauitalic_Ï„. Therefore, this new formulation can provide fast approximate solutions to 2222-player, general-sum games via a simple least squares solver. For the wider class of Nğ‘Nitalic_N-player, general-sum games, we show how to solve for NEs using only access to stochastic singular value decomposition (SVD) and power iteration (Golub and Van Loan, 2013). Lastly, given SVDâ€™s recent reformulation as a Nash equilibrium problem, specifically an EigenGame (Gemp et al., 2021a), we explain a mapping from the original NE problem to a sequence of NE problems on larger, albeit strategically simpler games (see Figure 1). All but the final step of our approach that uses power iteration can be interpreted as a new normal-form game thereby establishing a tree of NE problems (see Figure 6)."
https://arxiv.org/html/2411.01810v1,A Polynomial-Time Algorithm for Fair and Efficient Allocation with a Fixed Number of Agents,"We study the problem of fairly and efficiently allocating indivisible goods among agents with additive valuation functions. Envy-freeness up to one good (EF1) is a well-studied fairness notion for indivisible goods, while Pareto optimality (PO) and its stronger variant, fractional Pareto optimality (fPO), are widely recognized efficiency criteria. Although each property is straightforward to achieve individually, simultaneously ensuring both fairness and efficiency is challenging. Caragiannis et al. [CKM+19] established the surprising result that maximizing Nash social welfare yields an allocation that is both EF1 and PO; however, since maximizing Nash social welfare is NP-hard, this approach does not provide an efficient algorithm. To overcome this barrier, Barman, Krishnamurthy, and Vaish [BKV18] designed a pseudo-polynomial time algorithm to compute an EF1 and PO allocation, and showed the existence of EF1 and fPO allocations. Nevertheless, the latter existence proof relies on a non-constructive convergence argument and does not directly yield an efficient algorithm for finding EF1 and fPO allocations. Whether a polynomial-time algorithm exists for finding an EF1 and PO (or fPO) allocation remains an important open problem.In this paper, we propose a polynomial-time algorithm to compute an allocation that achieves both EF1 and fPO under additive valuation functions when the number of agents is fixed. Our primary idea is to avoid processing the entire instance at once; instead, we sequentially add agents to the instance and construct an allocation that satisfies EF1 and fPO at each step.","The fair division problem has been a central research topic across various fields, including mathematics, economics and computer science, since it was formally introduced by Steinhaus [Ste49]. This problem aims to allocate resources among agents in a fair and efficient manner. It has various real-world applications, including rent division [ES99], course allocation [BCKO17, OSB10], pilot-to-plane assignment for airlines, allocation of tasks to workers, articles to reviewers, and fair recommender systems. Early studies primarily focused on divisible goods, resulting in extensive literature on fair division in mathematics and economics [BT96, RW98, Mou04, BCE+16]. A widely accepted standard of fairness is envy-freeness (EF) [Fol66], which requires that each agent prefers their own bundle to that of any other agent. On the other hand, Pareto optimality (PO) is a fundamental efficiency criterion: an allocation is Pareto optimal if no allocation exists that makes an agent better off without making any other agent worse off. Pareto optimality is independent of fairness, and is widely used to evaluate whether allocations are efficient and free of waste. Varian [Var74] notably showed that, for divisible goods, there always exists an envy-free and Pareto optimal allocation. Furthermore, it can be computed in polynomial time under additive valuation functions [EG59, DPSV08, Orl10, VÃ©g12]. In contrast, for indivisible goods, where each good must be allocated to a single agent, envy-free allocations are not guaranteed to exist. For instance, even in the simple case of distributing a single good between two agents, no envy-free allocation is possible. This limitation implies that classical fairness concepts and algorithms are often inapplicable to indivisible goods, motivating research into new fairness concepts and algorithms specifically suited to discrete fair division problems. For an overview of recent advances in this area, we refer the reader to recent surveys [AAB+23, Wal21]. To address the fair division problem with indivisible goods, several relaxed fairness notions have been proposed. One well-studied fairness notion is Envy-Freeness up to one good (EF1), introduced by Budish [Bud11]. EF1 requires that each agent prefers their own bundle to that of any other agent after removing at most one good from the latterâ€™s bundle. Under monotone valuation functions, it has been shown that an EF1 allocation always exists and can be computed in polynomial time [LMMS04]. Achieving EF1 or PO individually is straightforward; however, whether EF1 and PO can be attained simultaneously is a key question. Caragiannis et al. [CKM+19] established the surprising result that, under additive 111Additivity implies that each agentâ€™s valuation for a set of goods equals the sum of their valuations for each individual good within that set. valuations, maximizing Nash social welfare [Nas50, KN79], defined as the geometric mean of the agentsâ€™ valuations, results in an allocation that is both EF1 and PO. However, since maximizing Nash social welfare is NP-hard [NNRR14] and even APX-hard [Lee17], this approach does not directly yield an efficient algorithm. To overcome this barrier, Barman, Krishnamurthy, and Vaish [BKV18] proposed a pseudo-polynomial time algorithm that computes an EF1 and PO allocation and proved that an EF1 and fractionally Pareto optimal (fPO) allocation always exists. An allocation is fractionally Pareto optimal (fPO) if no fractional allocation exists that makes an agent better off without making any other agent worse off. Nevertheless, their existence proof relies on a non-constructive convergence argument and does not directly yield an algorithm for computing such an allocation. Clearly, fPO is a stronger efficiency criterion than PO. In addtion, fPO allocations offer another advantage over PO allocations: Given an allocation, fPO can be verified efficiently [SSH22], whereas verifying whether an allocation is PO is coNP-complete [DKBKZ09]. This efficient verification is particularly advantageous when a centralized authority conducts the allocation since all participants can verify that the allocation is fPO (and therefore also PO). However, this efficient verification is not feasible for PO allocations. Whether a polynomial-time algorithm exists for finding an EF1 and PO (or fPO) allocation remains an important open problem. 1.1 Related Work Fair and efficient allocation for indivisible goods Caragiannis et al. [CKM+19] established that, under additive valuations, maximizing Nash social welfare [Nas50, KN79] yields an allocation that is both EF1 and PO. An approach commonly used to find allocations that satisfy both fairness and PO uses the connection between fair division and market equilibrium in Fisher markets [Bud11]. Barman, Krishnamurthy, and Vaish [BKV18] developed a pseudo-polynomial time algorithm to compute an allocation that is both EF1 and PO. They further showed the existence of an EF1 and fPO allocation. Barman and Krishnamurthy [BK19] developed a strongly polynomial-time algorithm that computes a PROP1 and fPO allocation, where PROP1 (Proportionality up to one good) is a fairness notion that is weaker than EF1 under additive valuation functions. Garg and Murhekar [GM24] proposed a pseudo-polynomial time algorithm for computing EF1 and fPO allocations. However, due to significant issues in their proof, we were unable to verify its correctness (see Appendix B for details). They also reported that when the number of agents is fixed, there exists a polynomial-time algorithm to compute an EF1 and PO allocation. Garg and Murhekar [GM23] showed that under additive, bi-valued valuation functions, an EFX (envy-free up to any good) and fPO allocation exists and can be computed in polynomial time. They also established that EFX and PO are incompatible in instances with three distinct values. Here, EFX, which is a stronger fairness notion than EF1, requires that each agent prefers their own bundle to that of any other agent after removing any single good from the latterâ€™s bundle. Freeman et al. [FSVX19] showed that if all values are positive, an EQX+PO allocation always exists; however, they also showed that when values may be zero, an EQ1+PO allocation does not exist. Here, EQ1 (equitability up to one good) and EQX (equitability up to any good) refer to equitability criteria. Fair and efficient allocation for indivisible chores The fair division problem for chores (items with negative value) is also an important research topic. In this context, concepts such as EF1 and PO can be defined analogously to their counterparts in the case of goods. However, unlike for indivisible goods, the existence of an EF1 and PO allocation for chores under additive valuations remains an open problem. To address this issue, several studies have focused on restricted instances. The existence and polynomial-time computability of EF1 and fPO allocations for chores are known in the following cases: bi-valued instances [EPS22, GMQ22]; instances with two types of chores [ALRS23]; instances with three agents [GMQ23]; and instances with two types of agents [GMQ23]. Approximating Nash social welfare The development of approximation algorithms for maximizing Nash social welfare has been an active research topic in theoretical computer science in recent years, as maximum Nash social welfare (MNW) allocations satisfy both EF1 and PO [CKM+19]. For additive valuation functions, the first constant-factor approximation algorithm, achieving a ratio of 2â‹…e1/eâ‰ˆ2.88â‹…2superscripte1e2.882\cdot\mathrm{e}^{1/\mathrm{e}}\approx 2.882 â‹… roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT â‰ˆ 2.88, was proposed by Cole and Gkatzelis [CG18]. This factor was subsequently improved to ee\mathrm{e}roman_e [AOGSS17], further refined to 2 [CDG+17], and currently stands at the best-known approximation ratio of e1/e+Ïµâ‰ˆ1.45superscripte1eitalic-Ïµ1.45\mathrm{e}^{1/\mathrm{e}}+\epsilon\approx 1.45roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT + italic_Ïµ â‰ˆ 1.45 [BKV18]. Although approximating MNW is itself an interesting research topic, it is worth noting that an approximate MNW allocation does not necessarily satisfy EF1 or PO. In contrast, the 1.45-approximation algorithm by [BKV18] notably provides guarantees of approximate EF1 and PO, a significant achievement in this context. In addition, similar approximation guarantees have been established for more general market models, such as piecewise-linear concave valuations [AMGV18], budget-additive valuations [GHM18], submodular valuations [GKK23], and multi-unit markets [BGHM17]. 1.2 Our Contributions The main contribution of this paper lies in proposing a polynomial-time algorithm to compute an allocation that achieves both EF1 and fPO under additive valuation functions when the number of agents is fixed. Theorem 1.1. When each agent has an additive valuation function and the number of agents is fixed, an EF1 and fPO allocation can be computed in polynomial time. Moreover, our approach directly contributes to the Nash social welfare maximization problem. As mentioned above, Barman, Krishnamurthy, and Vaish [BKV18] developed a 1.45-approximation algorithm for maximizing Nash social welfare that achieves approximate EF1 and PO. We show that similar results hold: the EF1 and fPO allocation produced by our algorithm also serves as an e1/eâ‰ˆ1.444superscripte1ğ‘’1.444\mathrm{e}^{1/e}\approx 1.444roman_e start_POSTSUPERSCRIPT 1 / italic_e end_POSTSUPERSCRIPT â‰ˆ 1.444-approximation algorithm for the Nash social welfare maximization problem. Note that the Nash social welfare maximization problem is NP-hard even when there are only two agents. This result is significant as it provides theoretical guarantees for both fairness and efficiency while also approximating Nash social welfare. Theorem 1.2. When each agent has an additive valuation function and the number of agents is fixed, there exists a polynomial-time e1/esuperscripte1e\mathrm{e}^{1/\mathrm{e}}roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT-approximation algorithm for the Nash social welfare maximization problem. Furthermore, the resulting allocation satisfies both EF1 and fPO. 1.3 Our Techniques Our approach builds on the techniques introduced by Barman, Krishnamurthy, and Vaish [BKV18]. We begin by briefly outlining their method. They developed a pseudo-polynomial time algorithm to compute an allocation that is both EF1 and PO. Their algorithm first perturbs valuations to a desirable form, then computes an EF1 and fPO allocation for this perturbed instance. This resulting allocation is approximately EF1 and PO with respect to the original instance and becomes EF1 and PO if the perturbation is sufficiently small. Specifically, their algorithm maintains an integral allocation and prices for goods at each step, ensuring they correspond to an equilibrium outcome in a Fisher market. This equilibrium guarantees fPO by the first welfare theorem. The algorithm adjusts the allocation and prices iteratively by reallocating goods and increasing prices to approach a fairer allocation. The algorithm stops once the current allocation and prices achieve approximate price envy-freeness up to one good (pEF1). Here, pEF1 requires that the spending of each agent is at least as high as that of any other agent after removing the most expensive good in the latterâ€™s bundle. Requiring the spending to be balanced in this manner yields EF1 for the corresponding fair division instance. Our primary idea is to avoid processing the entire instance at once; instead, we sequentially add agents to the instance and construct an allocation that satisfies EF1 and fPO at each step. In the kğ‘˜kitalic_k-th iteration of the algorithm, we start with an EF1 and fPO allocation for an instance of kâˆ’1ğ‘˜1k-1italic_k - 1 agents, add the kğ‘˜kitalic_k-th agent to the instance, and find a new allocation that satisfies EF1 and fPO for kğ‘˜kitalic_k agents. To do this, the algorithm maintains an allocation and prices for goods that correspond to an equilibrium outcome in a Fisher market. In the kğ‘˜kitalic_k-th iteration, the algorithm achieves a PEF1 allocation by reallocating goods and adjusting prices. During this process, the allocation remains EF1 and fPO for the existing kâˆ’1ğ‘˜1k-1italic_k - 1 agents, while the reallocating and price increase are designed to eliminate the dissatisfaction of the newly added kğ‘˜kitalic_k-th agent. Our approach differs from previous methods in several notable respects. First, we do not perturb the instance; rather, we compute an allocation that directly satisfies EF1 and fPO for the given instance. Second, in each iteration of our algorithm, we ensure that the minimum spender, who is the agent with the lowest spending, is always the newly added agent kğ‘˜kitalic_k. In previous algorithms, the minimum spender may change during reallocation, but our algorithm consistently operates to eliminate the dissatisfaction of kğ‘˜kitalic_k-th agent. This introduces a â€œdirectionâ€ for achieving fairness and enables new techniques to bound the number of iterations. Third, in the kğ‘˜kitalic_k-th iteration, since we need to maintain EF1 and fPO for the existing kâˆ’1ğ‘˜1k-1italic_k - 1 agents, we allow for simultaneous exchanges of multiple goods. As far as we know, this approach is novel in the context of constructing fair and efficient allocations. 1.4 Organization In Section 2, we introduce the fair division model and the relevant notions of fairness and efficiency. We also present the Fisher market framework and define key notions such as price envy-freeness, minimum spenders, maximum violators, and the MBB graph. Section 3 gives a detailed description of the algorithms we propose. In Section 4, we analyze our algorithms and prove Theorem 1.1. Finally, in Section 5, we summarize our results and suggest directions for future research. Additionally, in Appendix A, we provide the proof of Theorem 1.2, and in Appendix B, we discuss an error of the proof in [GM24]."
https://arxiv.org/html/2411.01721v1,Computational Lower Bounds for Regret Minimizationin Normal-Form Games,"A celebrated connection in the interface of online learning and game theory establishes that players minimizing swap regret converge to correlated equilibria (CE)â€”a seminal game-theoretic solution concept. Despite the long history of this problem and the renewed interest it has received in recent years, a basic question remains open: how many iterations are needed to approximate an equilibrium under the usual normal-form representation? In this paper, we provide evidence that existing learning algorithms, such as multiplicative weights update, are close to optimal. In particular, we prove lower bounds for the problem of computing a CE that can be expressed as a uniform mixture of Tğ‘‡Titalic_T product distributionsâ€”namely, a uniform Tğ‘‡Titalic_T-sparse CE; such lower bounds immediately circumscribe (computationally bounded) regret minimization algorithms in games. Our results are obtained in the algorithmic framework put forward by Kothari and Mehta (STOC 2018) in the context of computing Nash equilibria, which consists of the sum-of-squares (SoS) relaxation in conjunction with oracle access to a verification oracle; the goal in that framework is to lower bound either the degree of the SoS relaxation or the number of queries to the verification oracle. Here, we obtain two such hardness results, precluding computing i) uniform logâ¡nğ‘›\log nroman_log italic_n-sparse CE when Ïµ=polyâ¢(1/logâ¡n)italic-Ïµpoly1ğ‘›\epsilon=\mathrm{poly}(1/\log n)italic_Ïµ = roman_poly ( 1 / roman_log italic_n ) and ii) uniform n1âˆ’oâ¢(1)superscriptğ‘›1ğ‘œ1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT-sparse CE when Ïµ=polyâ¢(1/n)italic-Ïµpoly1ğ‘›\epsilon=\mathrm{poly}(1/n)italic_Ïµ = roman_poly ( 1 / italic_n ).","A celebrated line of research in the interface of algorithmic game theory and online learning revolves around the repeated interaction of multiple players in a game. Much of this theory stems from the realization that players engaging rationallyâ€”in that their behavior is consistent with some notion of hindsight rationality or no-regretâ€”converge to a certain game-theoretic solution concept known as (coarse) correlated equilibrium (CE) \citepHart00:Simple,Foster97:Calibrated. From an algorithmic standpoint, perhaps the most pressing question emerging from that connection pertains to the number of iterations needed to approximate an equilibrium. One answer put forward in the online learning literature postulates that each player is facing an adversarial environment, a regime which is by now well-understood commencing from some early influential work \citepLittlestone94:Weighted,Littlestone87:Learning. When learning in games, however, players instead interact with other learning algorithms; the obvious concern thus is that the predictions of the traditional no-regret framework are overly pessimistic. Indeed, it turns out that barriers ingrained in the adversarial regime can be circumvented when specialized algorithms are in place (e.g., \citepSyrgkanis15:Fast,Rakhlin13:Optimization,Daskalakis15:Near,Daskalakis21:Near,Erez23:Regret,Daskalakis22:Fast,Cai24:Near). As a notable example, \citetDaskalakis21:Near showed that a simple variant of the celebrated multiplicative weights update algorithm guarantees (external) regret growing only as Oâ¢(log4â¡Tâ¢logâ¡n)ğ‘‚superscript4ğ‘‡ğ‘›O(\log^{4}T\log n)italic_O ( roman_log start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT italic_T roman_log italic_n ) after Tğ‘‡Titalic_T repetitions of any game with a constant number of players, where nğ‘›nitalic_n here and throughout represents the number of actions of each player; this is a significant improvement over the Î©â¢(Tâ¢logâ¡n)Î©ğ‘‡ğ‘›\Omega(\sqrt{T\log n})roman_Î© ( square-root start_ARG italic_T roman_log italic_n end_ARG ) information-theoretic barrier when facing an adversary \citepCesa-Bianchi06:Prediction. Practical experience also suggests a considerable gap between existing theoretical predictions and observed behavior for no-regret dynamics, manifested in attaining remarkable performance even in enormous games \citepBowling15:Heads. It is worth stressing that even though a correlated equilibrium can be computed exactly via linear programming \citepPapadimitriou08:Computing, no-regret dynamics are in many ways more appealing from a computational standpoint, mostly attributed to their scalability and their decentralized nature; it has also been argued that they constitute more plausible models of learning \citepSandholm10:Population. Despite the rich history of this foundational problem, the number of iterations needed for no-regret learners to approximate an equilibrium remains an outstanding open problem. In this paper, we study the complexity of no-regret learning in games from a computational perspective, under the premise that learners employ polynomial-time algorithms to update their strategies. At first glance, it might be unclear why and how computation circumscribes no-regret learning. This can be grasped by considering first an extreme case: what prevents both learners from incurring small regret after a single iteration? The answer is that this would result in a Nash equilibrium (NE) of the underlying gameâ€”a stronger notion than correlated equilibria, which can be immediately ruled out in light of well-known computational barriers in general-sum games \citepRubinstein16:Settling,Chen09:Settling,Daskalakis08:Complexity,Boodaghians20:Smoothed,Deligkas22:Pure,Etessami07:Complexity,Kothari18:Sum. But can those lower bounds be extended for multiple iterations of no-regret learning? To address this question, we investigate the complexity of computing a correlated equilibrium under the additional constraint that it can be expressed as a uniform mixture of Tğ‘‡Titalic_T product distributionsâ€”henceforth, uniform Tğ‘‡Titalic_T-sparse CE (Definition 1.2). Intractability concerning sparse CE immediately lower bounds the number of iterations for computationally bounded no-regret learners. Further, a compelling aspect of this approach is that, unlike other lower bounds based on query complexity (discussed in Section 1.4), it applies even if the players know the game upfront and can coordinate prior to the learning phase. This program has been followed with success starting from the work of \citetFoster23:Hardness in the context of Markov (aka. stochastic) games, and continued by \citetPeng24:Complexity targeting games with imperfect information. Yet, no progress has been made in understanding the complexity of sparse CE in normal-form games, which constitutes the canonical representation treated in the literature. It is worth stressing here that although computing 2222-sparse CE appears to be a similar problem to computing NE (that is, 1111-sparse CE), adapting existing reductions based on the latter to the former turns out to be particularly challenging; relaxing playersâ€™ independenceâ€”as in Nash equilibriaâ€”immediately introduces considerable technical obstacles. Our contribution here is to tackle those challenges and provide strong evidence for the intractability of computing sparse CE in normal-form games. In particular, we extend the sum-of-squares (SoS)-based lower bounds of \citetKothari18:Sum from Nash equilibria to sparse CE under a broad sparsity regime. The algorithmic framework We operate in the algorithmic framework put forward by \citetKothari18:Sum revolving around SoS, a sequence of increasingly more powerful semidefinite programs (SDPs). The SoS hierarchy has proven to be a remarkably effective technique for algorithm design in many fundamental problems from diverse areas (e.g., \citepArora15:Subexponential,Barak11:Rounding,Ma16:Polynomial,Harrow16:Tight,Barak15:Dictionary,Barak14:Rounding,Arora09:Expander,Kothari22:Polynomial,Barak14:Sum). As a result, in light of the power of the framework, an SoS lower bound serves as strong evidence for the intractability of a problem. Such a lower bound typically manifests itself in the form of an integrality gap, precluding approximating a certain objective function without ascending excessively high in the SoS hierarchy. When it comes to equilibrium computation, however, there is no underlying objective; and the decision version of the problem is also of little use since, by virtue of its totality, a solution always exists. \citetKothari18:Sum propose to address such issues by instead relying on what they refer to as rounding gaps. The idea here is as follows. An SoS relaxation will output a relaxed solution with respect to our problem of interestâ€”namely, Tğ‘‡Titalic_T-sparse CE. Such a relaxation will generally not be a legitimate solution, so an additional stepâ€”known as roundingâ€”is required so as to identify an actual equilibrium. Now, for this approach to be meaningful, it is necessary to impose constraints on how the rounding algorithm operates, for otherwise it can simply ignore the relaxed solution and compute an equilibrium from scratch by accessing the game; proving lower bounds against such algorithms is precisely what we set out for in the first place. Following \citetFeige16:Oblivious, \citetKothari18:Sum address this issue by restricting the rounding algorithm to be oblivious, in that the true solution can only depend on the relaxed one. This algorithmic framework, although restricted, is powerful enough to capture several famous algorithms \citepFeige16:Oblivious, including threshold rounding for vertex cover \citepHochbaum82:Approximation; randomized rounding for set cover \citepRaghavan87:Randomized; random hyperplane rounding for maximum cut \citepGoemans95:Improved; and welfare maximization for fractionally subadditive (XOS) and submodular valuations \citepFeige09:Maximizing,Feige10:Submodular. To strengthen the rounding algorithm and capture more existing techniques, \citetKothari18:Sum also allow it to adaptively produce a list of candidate solutionsâ€”instead of a single oneâ€”by checking whether one of them is indeed a solution through a verification oracle; this enables capturing enumeration techniques over a restricted search space, which have been successful in equilibrium computation problemsâ€”most notably, by \citetLipton03:Playing. A lower bound in this framework consists of proving that either the levelâ€”aka. the degreeâ€”in the SoS hierarchy is highâ€”thereby rendering the corresponding SDP out of reachâ€”or the number of queries to the verification oracle is prohibitively large. 1.1 Preliminaries To describe our results, we first need to formally introduce the problem of interest and the algorithmic framework outlined above; further background is provided later in Section 2. The familiar reader can mostly skim the upcoming paragraphs leading to Section 1.2 for our notation. Two-player games We consider two-player games represented in normal form. (Since we are aiming to prove lower bounds, concentrating on two-player games will only make the results stronger.) Here, each player has a finite set of available actions; without any loss of generality, we may and will assume that the set of actions of each player is [n]â‰”{1,2,â€¦,n}â‰”delimited-[]ğ‘›12â€¦ğ‘›[n]\coloneqq\{1,2,\dots,n\}[ italic_n ] â‰” { 1 , 2 , â€¦ , italic_n }. Under a pair of actions (i,j)âˆˆ[n]Ã—[n]ğ‘–ğ‘—delimited-[]ğ‘›delimited-[]ğ‘›(i,j)\in[n]\times[n]( italic_i , italic_j ) âˆˆ [ italic_n ] Ã— [ italic_n ], the utility of the players is given by ğ‘i,jsubscriptğ‘ğ‘–ğ‘—\mathbf{R}_{i,j}bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT and ğ‚i,jsubscriptğ‚ğ‘–ğ‘—\mathbf{C}_{i,j}bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT, respectively, where ğ‘,ğ‚âˆˆâ„nÃ—nğ‘ğ‚superscriptâ„ğ‘›ğ‘›\mathbf{R},\mathbf{C}\in{\mathbb{R}}^{n\times n}bold_R , bold_C âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_n Ã— italic_n end_POSTSUPERSCRIPT are the payoff matrices of the game given as part of the input; by convention, we will refer to the players as Player xğ‘¥xitalic_x (for the â€œrow playerâ€) and Player yğ‘¦yitalic_y (for the â€œcolumn playerâ€), respectively. ğ’¢â‰”(ğ‘,ğ‚)â‰”ğ’¢ğ‘ğ‚\mathcal{G}\coloneqq(\mathbf{R},\mathbf{C})caligraphic_G â‰” ( bold_R , bold_C ) will sometimes be referred to as an nÃ—nğ‘›ğ‘›n\times nitalic_n Ã— italic_n game. Players can randomize by selecting as strategy a probability distribution, a point in Î”nâ‰”{ğ’™âˆˆâ„â‰¥0n:âˆ‘i=1nğ’™i=1}â‰”superscriptÎ”ğ‘›conditional-setğ’™subscriptsuperscriptâ„ğ‘›absent0superscriptsubscriptğ‘–1ğ‘›subscriptğ’™ğ‘–1\Delta^{n}\coloneqq\{\bm{x}\in{\mathbb{R}}^{n}_{\geq 0}:\sum_{i=1}^{n}\bm{x}_{% i}=1\}roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT â‰” { bold_italic_x âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT â‰¥ 0 end_POSTSUBSCRIPT : âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 }. The expected utility under a pair of mixed strategies (ğ’™,ğ’š)âˆˆÎ”nÃ—Î”nğ’™ğ’šsuperscriptÎ”ğ‘›superscriptÎ”ğ‘›(\bm{x},\bm{y})\in\Delta^{n}\times\Delta^{n}( bold_italic_x , bold_italic_y ) âˆˆ roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT Ã— roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is given by ğ”¼(i,j)âˆ¼(ğ’™,ğ’š)â¢ğ‘i,j=âŸ¨ğ’™,ğ‘â¢ğ’šâŸ©subscriptğ”¼similar-toğ‘–ğ‘—ğ’™ğ’šsubscriptğ‘ğ‘–ğ‘—ğ’™ğ‘ğ’š{\mathbb{E}}_{(i,j)\sim(\bm{x},\bm{y})}\mathbf{R}_{i,j}=\langle\bm{x},\mathbf{% R}\bm{y}\rangleblackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ ( bold_italic_x , bold_italic_y ) end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = âŸ¨ bold_italic_x , bold_R bold_italic_y âŸ© and ğ”¼(i,j)âˆ¼(ğ’™,ğ’š)â¢ğ‚i,j=âŸ¨ğ’™,ğ‚â¢ğ’šâŸ©subscriptğ”¼similar-toğ‘–ğ‘—ğ’™ğ’šsubscriptğ‚ğ‘–ğ‘—ğ’™ğ‚ğ’š{\mathbb{E}}_{(i,j)\sim(\bm{x},\bm{y})}\mathbf{C}_{i,j}=\langle\bm{x},\mathbf{% C}\bm{y}\rangleblackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ ( bold_italic_x , bold_italic_y ) end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = âŸ¨ bold_italic_x , bold_C bold_italic_y âŸ© for Player xğ‘¥xitalic_x and Player yğ‘¦yitalic_y, respectively. Correlated equilibria and sparsity We next recall the notion of a correlated equilibrium (CE) \citepAumann74:Subjectivity. Central to this definition is the set of swap deviations Î¦swapsubscriptÎ¦swap\Phi_{\text{swap}}roman_Î¦ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT, which contains all functions mapping [n]delimited-[]ğ‘›[n][ italic_n ] to [n]delimited-[]ğ‘›[n][ italic_n ]. Even though there are nnsuperscriptğ‘›ğ‘›n^{n}italic_n start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT such functions, there is still an efficient algorithm minimizing Î¦swapsubscriptÎ¦swap\Phi_{\text{swap}}roman_Î¦ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT-regret \citepBlum07:From. In fact, we will show that lower bounds persist even if one considers a certain subset of deviations Î¦âŠ†Î¦swapÎ¦subscriptÎ¦swap\Phi\subseteq\Phi_{\text{swap}}roman_Î¦ âŠ† roman_Î¦ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT with polynomial (in nğ‘›nitalic_n) size (defined later in Section 2.1). Definition 1.1. A distribution ğğ\bm{\mu}bold_italic_Î¼ on [n]Ã—[n]delimited-[]ğ‘›delimited-[]ğ‘›[n]\times[n][ italic_n ] Ã— [ italic_n ] is an Ïµitalic-Ïµ\epsilonitalic_Ïµ-correlated equilibrium (Ïµitalic-Ïµ\epsilonitalic_Ïµ-CE) if for any deviations Ï•xâˆˆÎ¦subscriptitalic-Ï•ğ‘¥Î¦\phi_{x}\in\Phiitalic_Ï• start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT âˆˆ roman_Î¦ and Ï•yâˆˆÎ¦subscriptitalic-Ï•ğ‘¦Î¦\phi_{y}\in\Phiitalic_Ï• start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT âˆˆ roman_Î¦, ğ”¼(i,j)âˆ¼ğâ¢ğ‘i,jâ‰¥ğ”¼(i,j)âˆ¼ğâ¢ğ‘Ï•xâ¢(i),jâˆ’Ïµandğ”¼(i,j)âˆ¼ğâ¢ğ‚i,jâ‰¥ğ”¼(i,j)âˆ¼ğâ¢ğ‚i,Ï•yâ¢(j)âˆ’Ïµ.formulae-sequencesubscriptğ”¼similar-toğ‘–ğ‘—ğsubscriptğ‘ğ‘–ğ‘—subscriptğ”¼similar-toğ‘–ğ‘—ğsubscriptğ‘subscriptitalic-Ï•ğ‘¥ğ‘–ğ‘—italic-Ïµandsubscriptğ”¼similar-toğ‘–ğ‘—ğsubscriptğ‚ğ‘–ğ‘—subscriptğ”¼similar-toğ‘–ğ‘—ğsubscriptğ‚ğ‘–subscriptitalic-Ï•ğ‘¦ğ‘—italic-Ïµ{\mathbb{E}}_{(i,j)\sim\bm{\mu}}\mathbf{R}_{i,j}\geq{\mathbb{E}}_{(i,j)\sim\bm% {\mu}}\mathbf{R}_{\phi_{x}(i),j}-\epsilon\quad\text{and}\quad{\mathbb{E}}_{(i,% j)\sim\bm{\mu}}\mathbf{C}_{i,j}\geq{\mathbb{E}}_{(i,j)\sim\bm{\mu}}\mathbf{C}_% {i,\phi_{y}(j)}-\epsilon.blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ bold_italic_Î¼ end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT â‰¥ blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ bold_italic_Î¼ end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_Ï• start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( italic_i ) , italic_j end_POSTSUBSCRIPT - italic_Ïµ and blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ bold_italic_Î¼ end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT â‰¥ blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ bold_italic_Î¼ end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_Ï• start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_j ) end_POSTSUBSCRIPT - italic_Ïµ . (1) Coarse correlated equilibria (CCE) relax CE by instead imposing (1) only for external deviations Î¦extâ‰”{Ï•âˆˆÎ¦swap:âˆƒiâ€²âˆˆ[n]â¢ s.t. â¢Ï•â¢(i)=iâ€²â¢ â¢âˆ€iâˆˆ[n]}â‰”subscriptÎ¦extconditional-setitalic-Ï•subscriptÎ¦swapsuperscriptğ‘–â€²delimited-[]ğ‘› s.t. italic-Ï•ğ‘–superscriptğ‘–â€² for-allğ‘–delimited-[]ğ‘›\Phi_{\text{ext}}\coloneqq\{\phi\in\Phi_{\text{swap}}:\exists i^{\prime}\in[n]% \text{ s.t. }\phi(i)=i^{\prime}\text{ }\forall i\in[n]\}roman_Î¦ start_POSTSUBSCRIPT ext end_POSTSUBSCRIPT â‰” { italic_Ï• âˆˆ roman_Î¦ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT : âˆƒ italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT âˆˆ [ italic_n ] s.t. italic_Ï• ( italic_i ) = italic_i start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT âˆ€ italic_i âˆˆ [ italic_n ] }. Interestingly, our lower bound does not seem to apply to CCE; as we shall see in the sequel, employing certain non-external deviations is crucial for the argument. This brings us to the notion of a sparse distribution, introduced below. Definition 1.2 (Sparse distribution). We say that a (correlated) distribution ğğ\bm{\mu}bold_italic_Î¼ on [n]Ã—[n]delimited-[]ğ‘›delimited-[]ğ‘›[n]\times[n][ italic_n ] Ã— [ italic_n ] is uniform Tğ‘‡Titalic_T-sparse if there exist ğ’™(1),â€¦,ğ’™(T)âˆˆÎ”nsuperscriptğ’™1â€¦superscriptğ’™ğ‘‡superscriptÎ”ğ‘›\bm{x}^{(1)},\dots,\bm{x}^{(T)}\in\Delta^{n}bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT âˆˆ roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and ğ’š(1),â€¦,ğ’š(T)âˆˆÎ”nsuperscriptğ’š1â€¦superscriptğ’šğ‘‡superscriptÎ”ğ‘›\bm{y}^{(1)},\dots,\bm{y}^{(T)}\in\Delta^{n}bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT âˆˆ roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT such that ğ=1Tâ¢âˆ‘t=1Tğ’™(t)âŠ—ğ’š(t)ğ1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡tensor-productsuperscriptğ’™ğ‘¡superscriptğ’šğ‘¡\bm{\mu}=\frac{1}{T}\sum_{t=1}^{T}\bm{x}^{(t)}\otimes\bm{y}^{(t)}bold_italic_Î¼ = divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT âŠ— bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT. (Above, we denote by ğ’™âŠ—ğ’šâ‰”ğ’™â¢ğ’šâŠ¤â‰”tensor-productğ’™ğ’šğ’™superscriptğ’štop\bm{x}\otimes\bm{y}\coloneqq\bm{x}\bm{y}^{\top}bold_italic_x âŠ— bold_italic_y â‰” bold_italic_x bold_italic_y start_POSTSUPERSCRIPT âŠ¤ end_POSTSUPERSCRIPT the outer (tensor) product of ğ’™ğ’™\bm{x}bold_italic_x and ğ’šğ’š\bm{y}bold_italic_y.) In words, a sparse distribution is one that can be expressed as a uniform mixture of Tâˆˆâ„•ğ‘‡â„•T\in{\mathbb{N}}italic_T âˆˆ blackboard_N product distributions. As we explained earlier, a Nash equilibrium can be equivalently thought of as a 1111-sparse CE. A key connection that motivates Definition 1.2 is that Tğ‘‡Titalic_T iterations of no-regret learning produces, by definition, a uniform Tğ‘‡Titalic_T-sparse distribution whose CE gap grows with the playersâ€™ Î¦Î¦\Phiroman_Î¦-regret (Proposition 2.1). Social welfare The (expected) social welfare of a correlated distribution ğğ\bm{\mu}bold_italic_Î¼ on [n]Ã—[n]delimited-[]ğ‘›delimited-[]ğ‘›[n]\times[n][ italic_n ] Ã— [ italic_n ] is defined as ğ–²ğ–¶â¡(ğ)â‰”ğ”¼(i,j)âˆ¼ğâ¢[ğ‘i,j+ğ‚i,j]â‰”ğ–²ğ–¶ğsubscriptğ”¼similar-toğ‘–ğ‘—ğdelimited-[]subscriptğ‘ğ‘–ğ‘—subscriptğ‚ğ‘–ğ‘—\operatorname{\mathsf{SW}}(\bm{\mu})\coloneqq{\mathbb{E}}_{(i,j)\sim\bm{\mu}}[% \mathbf{R}_{i,j}+\mathbf{C}_{i,j}]sansserif_SW ( bold_italic_Î¼ ) â‰” blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) âˆ¼ bold_italic_Î¼ end_POSTSUBSCRIPT [ bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT + bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ]; under a product distribution induced by (ğ’™,ğ’š)ğ’™ğ’š(\bm{x},\bm{y})( bold_italic_x , bold_italic_y ), we will write ğ–²ğ–¶â¡(ğ’™âŠ—ğ’š)=âŸ¨ğ’™,(ğ‘+ğ‚)â¢ğ’šâŸ©ğ–²ğ–¶tensor-productğ’™ğ’šğ’™ğ‘ğ‚ğ’š\operatorname{\mathsf{SW}}(\bm{x}\otimes\bm{y})=\langle\bm{x},(\mathbf{R}+% \mathbf{C})\bm{y}\ranglesansserif_SW ( bold_italic_x âŠ— bold_italic_y ) = âŸ¨ bold_italic_x , ( bold_R + bold_C ) bold_italic_y âŸ©. SoS and pseudo-equilibria The sum-of-squares (SoS) hierarchy is a sequence of increasingly tighter semidefinite programs (SDPs), parameterized by a degree dâˆˆâ„•ğ‘‘â„•d\in{\mathbb{N}}italic_d âˆˆ blackboard_N, for the solution of a system of polynomial inequalities. Central to the SoS framework is the notion of a pseudo-distribution, which is a generalization of the usual notion of a probability distribution. Definition 1.3 (Pseudo-distribution). A degree-dğ‘‘ditalic_d pseudo-distribution is a discrete signed measure Î¼~~ğœ‡\tilde{\mu}over~ start_ARG italic_Î¼ end_ARG on â„msuperscriptâ„ğ‘š{\mathbb{R}}^{m}blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that the associated linear functional (namely, the pseudo-expectation) ğ”¼~Î¼~:fâ†¦ğ”¼~Î¼~â¢[f]=âˆ‘ğ’›:Î¼~â¢(ğ’›)â‰ 0Î¼~â¢(ğ’›)â¢fâ¢(ğ’›):subscript~ğ”¼~ğœ‡maps-toğ‘“subscript~ğ”¼~ğœ‡delimited-[]ğ‘“subscript:ğ’›~ğœ‡ğ’›0~ğœ‡ğ’›ğ‘“ğ’›\tilde{{\mathbb{E}}}_{\tilde{\mu}}:f\mapsto\tilde{{\mathbb{E}}}_{\tilde{\mu}}[% f]=\sum_{\bm{z}:\tilde{\mu}(\bm{z})\neq 0}\tilde{\mu}(\bm{z})f(\bm{z})over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_Î¼ end_ARG end_POSTSUBSCRIPT : italic_f â†¦ over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_Î¼ end_ARG end_POSTSUBSCRIPT [ italic_f ] = âˆ‘ start_POSTSUBSCRIPT bold_italic_z : over~ start_ARG italic_Î¼ end_ARG ( bold_italic_z ) â‰  0 end_POSTSUBSCRIPT over~ start_ARG italic_Î¼ end_ARG ( bold_italic_z ) italic_f ( bold_italic_z ), where f:â„mâ†’â„:ğ‘“â†’superscriptâ„ğ‘šâ„f:{\mathbb{R}}^{m}\to{\mathbb{R}}italic_f : blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT â†’ blackboard_R, has the following properties: 1. normalization: ğ”¼~Î¼~â¢[1]=1subscript~ğ”¼~ğœ‡delimited-[]11\tilde{{\mathbb{E}}}_{\tilde{\mu}}[1]=1over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_Î¼ end_ARG end_POSTSUBSCRIPT [ 1 ] = 1, and 2. positivity: ğ”¼~Î¼~â¢[p2]â‰¥0subscript~ğ”¼~ğœ‡delimited-[]superscriptğ‘20\tilde{{\mathbb{E}}}_{\tilde{\mu}}[p^{2}]\geq 0over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_Î¼ end_ARG end_POSTSUBSCRIPT [ italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] â‰¥ 0 for every polynomial pğ‘pitalic_p on â„msuperscriptâ„ğ‘š{\mathbb{R}}^{m}blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT with degree at most d/2ğ‘‘2d/2italic_d / 2. In this context, following \citetKothari18:Sum, we introduce a relaxation of uniform Tğ‘‡Titalic_T-sparse CE based on the notion of a constrained pseudo-distribution (Definition 2.3), which we refer to as uniform Tğ‘‡Titalic_T-sparse pseudo-CE (a 1111-sparse pseudo-CE will also be called pseudo-NE). Definition 1.4. For a game (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ), a degree-dğ‘‘ditalic_d, uniform Tğ‘‡Titalic_T-sparse pseudo-CE is a degree-dğ‘‘ditalic_d pseudo-distribution on (ğ’™(1),â€¦,ğ’™(T),ğ’š(1),â€¦,ğ’š(T))superscriptğ’™1â€¦superscriptğ’™ğ‘‡superscriptğ’š1â€¦superscriptğ’šğ‘‡(\bm{x}^{(1)},\dots,\bm{x}^{(T)},\bm{y}^{(1)},\dots,\bm{y}^{(T)})( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT , bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ) that satisfies ğ’™(1),â€¦,ğ’™(T),ğ’š(1),â€¦,ğ’š(T)âˆˆÎ”nsuperscriptğ’™1â€¦superscriptğ’™ğ‘‡superscriptğ’š1â€¦superscriptğ’šğ‘‡superscriptÎ”ğ‘›\bm{x}^{(1)},\dots,\bm{x}^{(T)},\bm{y}^{(1)},\dots,\bm{y}^{(T)}\in\Delta^{n}bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT , bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT âˆˆ roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and for all (Ï•x,Ï•y)âˆˆÎ¦Ã—Î¦subscriptitalic-Ï•ğ‘¥subscriptitalic-Ï•ğ‘¦Î¦Î¦(\phi_{x},\phi_{y})\in\Phi\times\Phi( italic_Ï• start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_Ï• start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ) âˆˆ roman_Î¦ Ã— roman_Î¦ the system of quadratic inequalities 1Tâ¢âˆ‘t=1TâŸ¨ğ’™(t),ğ‘â¢ğ’š(t)âŸ©â‰¥1Tâ¢âˆ‘t=1TâŸ¨Ï•xâ¢(ğ’™(t)),ğ‘â¢ğ’š(t)âŸ©â¢ and â¢1Tâ¢âˆ‘t=1TâŸ¨ğ’™(t),ğ‚â¢ğ’š(t)âŸ©â‰¥1Tâ¢âˆ‘t=1TâŸ¨ğ’™(t),ğ‚â¢Ï•yâ¢(ğ’š(t))âŸ©.1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡superscriptğ’™ğ‘¡ğ‘superscriptğ’šğ‘¡1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡subscriptitalic-Ï•ğ‘¥superscriptğ’™ğ‘¡ğ‘superscriptğ’šğ‘¡ and 1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡superscriptğ’™ğ‘¡ğ‚superscriptğ’šğ‘¡1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡superscriptğ’™ğ‘¡ğ‚subscriptitalic-Ï•ğ‘¦superscriptğ’šğ‘¡\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{R}\bm{y}^{(t)}\rangle\geq% \frac{1}{T}\sum_{t=1}^{T}\langle\phi_{x}(\bm{x}^{(t)}),\mathbf{R}\bm{y}^{(t)}% \rangle\text{ and }\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{C}\bm{% y}^{(t)}\rangle\geq\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{C}\phi% _{y}(\bm{y}^{(t)})\rangle.divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT âŸ¨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_R bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT âŸ© â‰¥ divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT âŸ¨ italic_Ï• start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) , bold_R bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT âŸ© and divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT âŸ¨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_C bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT âŸ© â‰¥ divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT âŸ¨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_C italic_Ï• start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) âŸ© . (2) (We clarify that Ï•x,Ï•y:Î”nâ†’Î”n:subscriptitalic-Ï•ğ‘¥subscriptitalic-Ï•ğ‘¦â†’superscriptÎ”ğ‘›superscriptÎ”ğ‘›\phi_{x},\phi_{y}:\Delta^{n}\to\Delta^{n}italic_Ï• start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_Ï• start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT : roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT â†’ roman_Î” start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT are linear functions, and so (2) above is indeed quadratic.) Definition 1.4 constitutes the natural SoS relaxation for computing uniform Tğ‘‡Titalic_T-sparse CE. An Ïµitalic-Ïµ\epsilonitalic_Ïµ-pseudo-CE incorporates an additive slackness Ïµ>0italic-Ïµ0\epsilon>0italic_Ïµ > 0 in (2). Oblivious rounding with a verification oracle We first state the definition of an oblivious rounding algorithm \citepFeige16:Oblivious. Definition 1.5 (Oblivious rounding algorithm). A degree-dğ‘‘ditalic_d oblivious rounding algorithm for a game ğ’¢ğ’¢{\mathcal{G}}caligraphic_G takes as input a degree-dğ‘‘ditalic_d, uniform Tğ‘‡Titalic_T-sparse Ïµitalic-Ïµ\epsilonitalic_Ïµ-pseudo-CE per Definition 1.4, and has to output a uniform Tğ‘‡Titalic_T-sparse Ïµitalic-Ïµ\epsilonitalic_Ïµ-CE of ğ’¢ğ’¢{\mathcal{G}}caligraphic_G. As explained earlier, it is desirable to also capture rounding algorithms endowed with the ability to adaptively produce a list of candidate solutions by checking whether one of them is indeed a solution through a verification oracle. Definition 1.6 (Verification oracle). A verification oracle with respect to a game ğ’¢ğ’¢{\mathcal{G}}caligraphic_G takes as input a candidate solution, in the form of (ğ’™(1),â€¦,ğ’™(T))superscriptğ’™1â€¦superscriptğ’™ğ‘‡(\bm{x}^{(1)},\dots,\bm{x}^{(T)})( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ) and (ğ’š(1),â€¦,ğ’š(T))superscriptğ’š1â€¦superscriptğ’šğ‘‡(\bm{y}^{(1)},\dots,\bm{y}^{(T)})( bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , â€¦ , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ), and outputs Accept if ğ=1Tâ¢âˆ‘t=1Tğ’™(t)âŠ—ğ’š(t)ğ1ğ‘‡superscriptsubscriptğ‘¡1ğ‘‡tensor-productsuperscriptğ’™ğ‘¡superscriptğ’šğ‘¡\bm{\mu}=\frac{1}{T}\sum_{t=1}^{T}\bm{x}^{(t)}\otimes\bm{y}^{(t)}bold_italic_Î¼ = divide start_ARG 1 end_ARG start_ARG italic_T end_ARG âˆ‘ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT âŠ— bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT is an Ïµitalic-Ïµ\epsilonitalic_Ïµ-CE of ğ’¢ğ’¢{\mathcal{G}}caligraphic_G and Reject otherwise. We are now ready to introduce the general class of rounding algorithms captured by the upcoming lower bounds. Definition 1.7. A degree-dğ‘‘ditalic_d, qğ‘qitalic_q-query oblivious rounding algorithm with verification oracle (OV rounding algorithm) is a degree-dğ‘‘ditalic_d oblivious rounding algorithm that can additionally access a verification oracle for the underlying game at most qğ‘qitalic_q times. Lower bounds within this algorithmic framework boil down to proving that any OV rounding algorithm either requires high degree or must otherwise submit a large number of (potentially adaptive) queries. 1.2 Our results As expected based on existing upper bounds, the lower bounds we obtain with respect to the sparsity parameter of Definition 1.2 crucially depend on the desired precision of the approximation (per Definition 1.1). In particular, we present results on two different regimes: Ïµ=polyâ¢(1/n)italic-Ïµpoly1ğ‘›\epsilon=\mathrm{poly}(1/n)italic_Ïµ = roman_poly ( 1 / italic_n ) and Ïµ=polyâ¢(1/logâ¡n)italic-Ïµpoly1ğ‘›\epsilon=\mathrm{poly}(1/\log n)italic_Ïµ = roman_poly ( 1 / roman_log italic_n ); we shall refer to those as high and low precision, respectively. We begin with the high-precision regime. Here, our main result is summarized below. Theorem 1.8. Suppose that there is a degree-dğ‘‘ditalic_d, qğ‘qitalic_q-query OV rounding algorithm for uniform n1âˆ’oâ¢(1)superscriptğ‘›1ğ‘œ1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT-sparse Ïµitalic-Ïµ\epsilonitalic_Ïµ-CE, with Ïµ=nâˆ’citalic-Ïµsuperscriptğ‘›ğ‘\epsilon=n^{-c}italic_Ïµ = italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT for some constant cğ‘citalic_c. Then, either d=2Î©â¢(logâ¡nâ¢logâ¡logâ¡n)ğ‘‘superscript2Î©ğ‘›ğ‘›d=2^{\Omega(\sqrt{\log n\log\log n})}italic_d = 2 start_POSTSUPERSCRIPT roman_Î© ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT or q=2Î©â¢(n)ğ‘superscript2Î©ğ‘›q=2^{\Omega(n)}italic_q = 2 start_POSTSUPERSCRIPT roman_Î© ( italic_n ) end_POSTSUPERSCRIPT. It is worth noting here that there is a tradeoff between the sparsity and the degree precluded by Theorem 1.8; one can elevate the degree at the cost of reducing the sparsityâ€”the extreme case being the result of \citetKothari18:Sum in which T=1ğ‘‡1T=1italic_T = 1 and d=Î©â¢(n)ğ‘‘Î©ğ‘›d=\Omega(n)italic_d = roman_Î© ( italic_n ). To put Theorem 1.8 into better context, we point out that an exact CE can be computed in polynomial time via a linear program, and every distribution can be expressed as a mixtureâ€”albeit not necessarily uniform per Definition 1.2â€”of nğ‘›nitalic_n product distributions; that is, modulo the use of non-uniform mixtures, the sparsity ruled out by Theorem 1.8 is the best one can hope for. Turning to the low-precision regime, our result mirrors Theorem 1.8 but with quantitatively weaker bounds on dğ‘‘ditalic_d and qğ‘qitalic_q. Theorem 1.9. Suppose that there is a degree-dğ‘‘ditalic_d, qğ‘qitalic_q-query OV rounding algorithm for uniform logâ¡nğ‘›\log nroman_log italic_n-sparse Ïµitalic-Ïµ\epsilonitalic_Ïµ-CE, with Ïµ=(logâ¡n)âˆ’citalic-Ïµsuperscriptğ‘›ğ‘\epsilon=(\log n)^{-c}italic_Ïµ = ( roman_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT for some constant cğ‘citalic_c. Then, either d=Î©â¢(logâ¡nlogâ¡logâ¡n)ğ‘‘Î©ğ‘›ğ‘›d=\Omega(\frac{\log n}{\log\log n})italic_d = roman_Î© ( divide start_ARG roman_log italic_n end_ARG start_ARG roman_log roman_log italic_n end_ARG ) or q=nÎ©â¢(logâ¡n)ğ‘superscriptğ‘›Î©ğ‘›q=n^{\Omega(\log n)}italic_q = italic_n start_POSTSUPERSCRIPT roman_Î© ( roman_log italic_n ) end_POSTSUPERSCRIPT. A few remarks are again in order. First, even when T=1ğ‘‡1T=1italic_T = 1, there is a quasipolynomial-time algorithm due to \citetLipton03:Playing based on exhaustive enumeration on a carefully constructed search space. Further, since Î¦Î¦\Phiroman_Î¦ contains a polynomial number of deviations, there are (efficient) no-regret dynamics producing an Oâ¢(logâ¡n/Ïµ2)ğ‘‚ğ‘›superscriptitalic-Ïµ2O(\log n/\epsilon^{2})italic_O ( roman_log italic_n / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )-sparse CE (e.g., via the algorithm of \citetGordon08:No). In particular, in the regime of Theorem 1.9, there is a polynomial-time algorithm for computing logOâ¢(1)â¡nsuperscriptğ‘‚1ğ‘›\log^{O(1)}nroman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n-sparse CE, thereby matching the sparsity precluded by Theorem 1.9 up to a constant in the exponent; as in Theorem 1.8, optimizing the dependence on Ïµitalic-Ïµ\epsilonitalic_Ïµ (as a function of nğ‘›nitalic_n) was not our focus. In fact, by virtue of recent breakthrough results \citepDagan24:From,Peng24:Fast, it is worth noting that polylogarithmic sparsity is also attainable with respect to the entire set of swap deviations when Ïµ=Î˜â¢(1)italic-ÏµÎ˜1\epsilon=\Theta(1)italic_Ïµ = roman_Î˜ ( 1 ). 1.3 Technical overview The proof of Theorems 1.8 and 1.9 follows the blueprint of \citetKothari18:Sum but with certain important twists and modifications, which are the subject of this subsection. The overarching goal is to establish Theorems 1.10 and 1.11, which we state and discuss below. Theorem 1.10. Let T=n1âˆ’oâ¢(1)ğ‘‡superscriptğ‘›1ğ‘œ1T=n^{1-o(1)}italic_T = italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT. There is a family of 2Î©â¢(n)superscript2Î©ğ‘›2^{\Omega(n)}2 start_POSTSUPERSCRIPT roman_Î© ( italic_n ) end_POSTSUPERSCRIPT games {ğ’¢k}ksubscriptsubscriptğ’¢ğ‘˜ğ‘˜\{\mathcal{G}_{k}\}_{k}{ caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that 1. there is a degree-2Î©â¢(logâ¡nâ¢logâ¡logâ¡n)superscript2Î©ğ‘›ğ‘›2^{\Omega(\sqrt{\log n\log\log n})}2 start_POSTSUPERSCRIPT roman_Î© ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT, uniform Tğ‘‡Titalic_T-sparse pseudo-CE for every ğ’¢ksubscriptğ’¢ğ‘˜{\mathcal{G}}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT simultaneously, 2. for every kâ‰ kâ€²ğ‘˜superscriptğ‘˜â€²k\neq k^{\prime}italic_k â‰  italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, if ğğ\bm{\mu}bold_italic_Î¼ and ğâ€²superscriptğâ€²\bm{\mu}^{\prime}bold_italic_Î¼ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT are uniform Tğ‘‡Titalic_T-sparse polyâ¢(1/n)poly1ğ‘›\mathrm{poly}(1/n)roman_poly ( 1 / italic_n )-CE of ğ’¢ksubscriptğ’¢ğ‘˜\mathcal{G}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and ğ’¢kâ€²subscriptğ’¢superscriptğ‘˜â€²\mathcal{G}_{k^{\prime}}caligraphic_G start_POSTSUBSCRIPT italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, ğâ‰ ğâ€²ğsuperscriptğâ€²\bm{\mu}\neq\bm{\mu}^{\prime}bold_italic_Î¼ â‰  bold_italic_Î¼ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT. Theorem 1.10 immediately implies Theorem 1.8. Indeed, suppose that one selects a game from the family described in Theorem 1.10, unbeknownst to the underlying algorithm. By the first property (Item 1), a degree-2Î©â¢(logâ¡nâ¢logâ¡logâ¡n)superscript2Î©ğ‘›ğ‘›2^{\Omega(\sqrt{\log n\log\log n})}2 start_POSTSUPERSCRIPT roman_Î© ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT, uniform Tğ‘‡Titalic_T-sparse pseudo-CE could not provide any information to discern the game from the class. An OV rounding algorithm is thus left with only query access to the verification oracle. But, by the second property (Item 2), each query can eliminate only a single game at a time, thereby leading to Theorem 1.8. The counterpart of Theorem 1.10 in the low-precision regime is stated below. Theorem 1.11. Let T=logâ¡nğ‘‡ğ‘›T=\log nitalic_T = roman_log italic_n. There is a family of nÎ©â¢(logâ¡n)superscriptğ‘›Î©ğ‘›n^{\Omega(\log n)}italic_n start_POSTSUPERSCRIPT roman_Î© ( roman_log italic_n ) end_POSTSUPERSCRIPT games {ğ’¢k}ksubscriptsubscriptğ’¢ğ‘˜ğ‘˜\{\mathcal{G}_{k}\}_{k}{ caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that 1. there is a degree-Î©â¢(logâ¡nlogâ¡logâ¡n)Î©ğ‘›ğ‘›\Omega(\frac{\log n}{\log\log n})roman_Î© ( divide start_ARG roman_log italic_n end_ARG start_ARG roman_log roman_log italic_n end_ARG ), uniform Tğ‘‡Titalic_T-sparse pseudo-CE for every ğ’¢ksubscriptğ’¢ğ‘˜{\mathcal{G}}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT simultaneously, 2. for every kâ‰ kâ€²ğ‘˜superscriptğ‘˜â€²k\neq k^{\prime}italic_k â‰  italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT, if ğğ\bm{\mu}bold_italic_Î¼ and ğâ€²superscriptğâ€²\bm{\mu}^{\prime}bold_italic_Î¼ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT are uniform Tğ‘‡Titalic_T-sparse polyâ¢(1/logâ¡n)poly1ğ‘›\mathrm{poly}(1/\log n)roman_poly ( 1 / roman_log italic_n )-CE of ğ’¢ksubscriptğ’¢ğ‘˜\mathcal{G}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and ğ’¢kâ€²subscriptğ’¢superscriptğ‘˜â€²\mathcal{G}_{k^{\prime}}caligraphic_G start_POSTSUBSCRIPT italic_k start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, ğâ‰ ğâ€²ğsuperscriptğâ€²\bm{\mu}\neq\bm{\mu}^{\prime}bold_italic_Î¼ â‰  bold_italic_Î¼ start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT. Establishing Theorems 1.10 and 1.11 can be in turn divided into three key steps, which are treated separately in what follows. SoS hardness for the welfare maximization variant The first one revolves around establishing SoS lower bounds for uniform Tğ‘‡Titalic_T-sparse CE but under an additional welfare maximization constraint; of course, the final problem of interest does not involve any welfare constraint, but this focus will be justified in the next part of the argument. Starting from the high-precision regime, let us first consider the special case where T=1ğ‘‡1T=1italic_T = 1 (that is, Nash equilibria). With a slight modification to the construction of \citetGilboa89:Nash, \citetKothari18:Sum observed that there is a reduction from (the decision variant of) the independent set problem to deciding whether there is a Nash equilibrium exceeding a certain welfare threshold. In conjunction with the SoS hardness result for the independent set problem due to \citetTulsiani09:CSP, they were able to construct a game such that there is a pseudo-NE exceeding a certain welfare threshold, while in reality all NE attain welfare considerably below it; such a game is referred to as SoSHard. For the more challenging problem of uniform Tğ‘‡Titalic_T-sparse CE (still subject to maximizing welfare), the question is to understand how the sparsity constraint interacts with such reductions. We show that uniform Tğ‘‡Titalic_T-sparse CE can still be accounted for by starting from a gap-amplified (PCP-type) version of independent set. In particular, our starting point is a recent lower bound for welfare-optimal sparse coarse correlated equilibria \citepAnonymous24:Barriers. Even though a uniform Tğ‘‡Titalic_T-sparse CE is a stronger notion than uniform Tğ‘‡Titalic_T-sparse CCE, hardness results for the latter do not readily carry over because of the underlying welfare constraint. Indeed, it turns out that in their reduction any CE obtains lower welfare than the welfare-optimal CCE. As a result, we observe that a direct adaptation of their approach to sparse CE necessitates a gap of Î˜â¢(T2)Î˜superscriptğ‘‡2\Theta(T^{2})roman_Î˜ ( italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) (Lemma 3.6). One of our key contributions is to appropriately leverage internal deviations so as to reduce the gap of the reduction to Î˜â¢(T)Î˜ğ‘‡\Theta(T)roman_Î˜ ( italic_T ) (Lemma 3.8); our reduction for sparse CE presents several interesting geometric features, discussed in detail in Section 3. Now, crucially, the result of \citetTulsiani09:CSP can support a gap up to n1âˆ’oâ¢(1)superscriptğ‘›1ğ‘œ1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT (Theorem 3.9), and this is precisely why the sparsity bound T=n1âˆ’oâ¢(1)ğ‘‡superscriptğ‘›1ğ‘œ1T=n^{1-o(1)}italic_T = italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT appears in Theorem 1.10. In particular, this leads to an SoSHard game with respect to uniform Tğ‘‡Titalic_T-sparse CE (per Definition 3.1), as we formalize in Theorem 3.11. The argument in the low-precision regime has a similar flavor (Theorem 3.13), but instead relies on SoS lower bounds for the planted clique problem \citepPang21:SOS. It is worth noting that \citetKothari18:Sum had to follow a different path since Pangâ€™s result was not available at the timeâ€”and earlier integrality gaps \citepBarak19:Nearly were not quite suited for such purposes. Hardness for enumeration algorithms The second step is to provide (information-theoretic) lower bounds against algorithms that access the game only through a verification oracleâ€”oblivious algorithms in the parlance of \citetDaskalakis09:Oblivious; the rationale behind this consideration is that an OV rounding algorithm that obtains no meaningful information from the SoS relaxation is thereby reduced to an oblivious algorithm. This problem is well-understood for Nash equilibria since the work of \citetDaskalakis09:Oblivious. The basic idea is that one can construct a large family of games whose set of Ïµitalic-Ïµ\epsilonitalic_Ïµ-Nash equilibria are pairwise disjoint (as in Item 2 we saw earlier); deriving sharp bounds requires a careful construction, discussed in Section 4. In Theorems 4.2 and 4.9, we show that such bounds carry over to coarse correlated equilibria as well (no matter the sparsity). The simple observation here is that the existing lower bounds for Nash equilibria against oblivious algorithms are based on (modulo strictly dominated actions that can be easily accounted for) constant-sum games; in such games, CCE and NE are tantamountâ€”in the precise sense of 4.3. We call such a family EnumHard games (Definition 4.1). Combining the games The final crucial piece in the construction shows how to appropriately combine such games to arrive at Theorems 1.10 and 1.11. In particular, let (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) be SoSHard: a game such that there is a degree-dğ‘‘ditalic_d, uniform Tğ‘‡Titalic_T-sparse pseudo-CE in which both players obtain utility at least Î´ğ›¿\deltaitalic_Î´, while all uniform Tğ‘‡Titalic_T-sparse CE attain welfare at most 2â¢Î´âˆ’2â¢Ïµ2ğ›¿2italic-Ïµ2\delta-2\epsilon2 italic_Î´ - 2 italic_Ïµ. Consider further a family of EnumHard games {(ğ‘S,ğ‚S)}Sâˆˆğ’®subscriptsuperscriptğ‘ğ‘†superscriptğ‚ğ‘†ğ‘†ğ’®\{(\mathbf{R}^{S},\mathbf{C}^{S})\}_{S\in\mathcal{S}}{ ( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_S âˆˆ caligraphic_S end_POSTSUBSCRIPT. The idea is to consider the game ğ‘â€²=(ğ‘âˆ’kâ¢ğŸnÃ—nÎ´â¢ğŸnÃ—nğ‘S)andğ‚â€²=(ğ‚Î´â¢ğŸnÃ—nâˆ’kâ¢ğŸnÃ—nğ‚S),formulae-sequencesuperscriptğ‘â€²matrixğ‘ğ‘˜subscript1ğ‘›ğ‘›ğ›¿subscript1ğ‘›ğ‘›superscriptğ‘ğ‘†andsuperscriptğ‚â€²matrixğ‚ğ›¿subscript1ğ‘›ğ‘›ğ‘˜subscript1ğ‘›ğ‘›superscriptğ‚ğ‘†\mathbf{R}^{\prime}=\begin{pmatrix}\mathbf{R}&-k\mathbf{1}_{n\times n}\\ \delta\mathbf{1}_{n\times n}&\mathbf{R}^{S}\end{pmatrix}\quad\text{and}\quad% \mathbf{C}^{\prime}=\begin{pmatrix}\mathbf{C}&\delta\mathbf{1}_{n\times n}\\ -k\mathbf{1}_{n\times n}&\mathbf{C}^{S}\end{pmatrix},bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = ( start_ARG start_ROW start_CELL bold_R end_CELL start_CELL - italic_k bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_Î´ bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT end_CELL start_CELL bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ) and bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = ( start_ARG start_ROW start_CELL bold_C end_CELL start_CELL italic_Î´ bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL - italic_k bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT end_CELL start_CELL bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ) , where ğŸnÃ—nsubscript1ğ‘›ğ‘›\mathbf{1}_{n\times n}bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT denotes the all-ones nÃ—nğ‘›ğ‘›n\times nitalic_n Ã— italic_n matrix and kâ‰«1much-greater-thanğ‘˜1k\gg 1italic_k â‰« 1. We first want to argue that uniform Tğ‘‡Titalic_T-sparse CE in (ğ‘â€²,ğ‚â€²)superscriptğ‘â€²superscriptğ‚â€²(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) are close to uniform Tğ‘‡Titalic_T-sparse CE in (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ). Indeed, the crucial role of the âˆ’kâ¢ğŸnÃ—nğ‘˜subscript1ğ‘›ğ‘›-k\mathbf{1}_{n\times n}- italic_k bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT term in the off-diagonal of ğ‘â€²+ğ‚â€²superscriptğ‘â€²superscriptğ‚â€²\mathbf{R}^{\prime}+\mathbf{C}^{\prime}bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT + bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT is that it forces any product distribution comprising a Tğ‘‡Titalic_T-sparse (C)CE in (ğ‘â€²,ğ‚â€²)superscriptğ‘â€²superscriptğ‚â€²(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) to be either supported only on (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) or only (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT )â€”up to some probability mass that decays when kğ‘˜kitalic_k is large (Lemma 5.2). The goal is to prove that actually only the second case can arise: each product is essentially only supported on (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), at which point it readily follows that a uniform Tğ‘‡Titalic_T-sparse CE in (ğ‘â€²,ğ‚â€²)superscriptğ‘â€²superscriptğ‚â€²(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ) must be a uniform Tğ‘‡Titalic_T-sparse CE in (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) as well (with roughly the same solution quality). To prove the former assertion, we show that in the contrary case, the conditional distribution on (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) must be a uniform Tğ‘‡Titalic_T-sparse CE for that game (Lemma 5.3). This argument carefully hinges on using a richer set of deviations than external ones. The basic reason is that we want to apply a different mapping when on (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) compared to when being on (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), a functionality not supported by external deviations. To explain this point further, an external deviation for Player xğ‘¥xitalic_x to an action in ğ‘ğ‘\mathbf{R}bold_R could result in an overwhelmingly negative utility due to the âˆ’kâ¢ğŸnÃ—nğ‘˜subscript1ğ‘›ğ‘›-k\mathbf{1}_{n\times n}- italic_k bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT term: for every component supported on (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), such a deviation inevitable incurs âˆ’kğ‘˜-k- italic_k. It is thus unclear how to argue about deviations in (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) starting from (ğ‘â€²,ğ‚â€²)superscriptğ‘â€²superscriptğ‚â€²(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT ). This is no longer a concern when players are able to deviate differently on different components of the game. Continuing from Lemma 5.3, we now reach a contradiction: uniform Tğ‘‡Titalic_T-sparse CE of (ğ‘,ğ‚)ğ‘ğ‚(\mathbf{R},\mathbf{C})( bold_R , bold_C ) attain welfare considerably lower than 2â¢Î´2ğ›¿2\delta2 italic_Î´ (by the property of the SoSHard game), and at the same time, there is a suitable deviation that takes advantage of the Î´â¢ğŸnÃ—nğ›¿subscript1ğ‘›ğ‘›\delta\mathbf{1}_{n\times n}italic_Î´ bold_1 start_POSTSUBSCRIPT italic_n Ã— italic_n end_POSTSUBSCRIPT term in ğ‘â€²superscriptğ‘â€²\mathbf{R}^{\prime}bold_R start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT and ğ‚â€²superscriptğ‚â€²\mathbf{C}^{\prime}bold_C start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT (Lemma 5.4); this contradicts the assumption that we started from a CE. What remains to show is that there is a degree-dğ‘‘ditalic_d, uniform Tğ‘‡Titalic_T-sparse pseudo-CE shared among the games no matter the selection of (ğ‘S,ğ‚S)superscriptğ‘ğ‘†superscriptğ‚ğ‘†(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) from the family of EnumHard games. This is a fairly straightforward exercise, similar to the completeness proof for Nash equilibria (Lemma 5.1). 1.4 Related work Related to sparsity per Definition 1.2, it is worth pointing out here a notion of sparsity which instead imposes a bound on the supportâ€”the number of nonzero elementsâ€”of the correlated distribution ğğ\bm{\mu}bold_italic_Î¼. The latter is clearly more stringent, and has been the subject of much investigation in the past (e.g., \citepBabichenko14:Simple,Feder07:Approximating,Althofer94:Sparse). From the perspective of regret minimization, lower bounds on the support of ğğ\bm{\mu}bold_italic_Î¼ have been successfully employed so as to preclude fast convergence of no-regret dynamics when players select pure strategies, while the more permissive notion we study here accounts for mixed strategies as well. One crucial difference between the two is that there are no such information-theoretic barriers surrounding Definition 1.2, in that a 1111-sparse CE always exists \citepNash50:Non; this is precisely why we need to resort to computational lower bounds. \citet Foster23:Hardness recently introduced Definition 1.2 in the context of Markov games (see also \citepPeng24:Complexity), and showed thatâ€”under standard complexity assumptionsâ€”no polynomial sparsity can be attained in such games; this stands in stark contrast to normal-form games. Unfortunately, directly translating such lower bounds to normal-form games appears to be of little use as it does not result in a polynomial-time reduction. Yet, it is worth noting that certain lower bounds have been documented for restricted classes of algorithms, such as multiplicative weights update \citepPeng24:Complexity. Besides those recent works, sparsity played a key role in the celebrated ellipsoid against hope algorithm of \citetPapadimitriou08:Computing (cf. \citepJiang11:Polynomial,Farina24:Polynomial). Indeed, that algorithm outputs a CE that is a convex combination of polynomially many product distributions, and is able to compute a correlated equilibrium even in many succinctly represented multi-player games; a correlated distribution in such games is in general an exponential object, but sparsity crucially provides a succinct representation. Beyond the computational perspective, a rather orthogonal approach to proving lower bounds for no-regret dynamics is to resort to query or communication complexity (e.g., \citepMaiti23:Query,Conitzer04:Communication,Goldberg16:Bounds,Goldberg23:Lower,Babichenko15:Query,Fearnley16:Finding,Goos23:Near,Hadiji23:Towards). One compelling aspect of the former compared to the latter approach is that computational lower bounds apply even in the centralized model of computation where the entire game is known in advance. This is crucial given that no-regret learning is consistently part of the best known algorithms for equilibrium computation problems. Further, query or communication lower bounds are quite brittle depending on how the game is accessed and information is distributed among the players. On the other hand, it has to be noted that the model we operate in is so permissive that no meaningful lower bounds can be established in, for example, (two-player) zero-sum games."
https://arxiv.org/html/2411.01720v1,Barriers to Welfare Maximization withNo-Regret Learning,"A celebrated result in the interface of online learning and game theory guarantees that the repeated interaction of no-regret players leads to a coarse correlated equilibrium (CCE)â€”a natural game-theoretic solution concept. Despite the rich history of this foundational problem and the tremendous interest it has received in recent years, a basic question still remains open: how many iterations are needed for no-regret players to approximate an equilibrium? In this paper, we establish the first computational lower bounds for that problem in two-player (general-sum) games under the constraint that the CCE reached approximates the optimal social welfare (or some other natural objective). From a technical standpoint, our approach revolves around proving lower bounds for computing a near-optimal Tğ‘‡Titalic_T-sparse CCEâ€”a mixture of Tğ‘‡Titalic_T product distributions, thereby circumscribing the iteration complexity of no-regret learning even in the centralized model of computation. Our proof proceeds by extending a classical reduction of Gilboa and Zemel [1989] for optimal Nash to sparse (approximate) CCE. In particular, we show that the inapproximability of maximum clique precludes attaining any non-trivial sparsity in polynomial time. Moreover, we strengthen our hardness results to apply in the low-precision regime as well via the planted clique conjecture.","One of the most influential results in the interface of algorithmic game theory and online learning is the realization that repeated play under no-regretâ€”a basic notion of hindsight rationalityâ€” leads to a natural game-theoretic solution concept known as coarse correlated equilibrium (CCE) \citepHart00:Simple,Foster97:Calibrated. Many ubiquitous algorithms guarantee the no-regret property, including (online) gradient descent and multiplicative weights update, and so one should expect CCE to arise from the repeated interaction of rational playersâ€”as it has been corroborated empirically \citepNekipelov15:Econometrics,Kolumbus22:Auctions. From an algorithmic standpoint, perhaps the most well-studied question that emerged from that connection concerns the number of iterations needed to approximate an equilibrium. Remarkably, although this problem traces back to the early pioneering works of \citetBlackwell56:analog and \citetRobinson51:iterative in the 1950s, it remains poorly understood. This stands in contrast to the so-called adversarial regime, wherein a learner engages repeatedly with an adversarial environment acting so as to maximize the playerâ€™s regret; in that setting, the minimax regret of the learner has long been resolved in the online learning literature \citepLittlestone94:Weighted. Yet, it turns out that substantially improved guarantees are possible when the learner is instead competing against other learning players, as witnesses by a flurry of recent results (e.g., \citepDaskalakis15:Near,Syrgkanis15:Fast,Rakhlin13:Optimization,Daskalakis21:Near,Piliouras22:Beyond). Indeed, such learning dynamics have emerged as a key component in practical equilibrium computation \citepBrown19:Superhuman,Bowling15:Heads,Bakhtin22:Human,Perolat22:Mastering, proving to be more scalable than traditional linear programming-based approaches. In this paper, we study the iteration-complexity of no-regret learning in games under the constraint that the equilibrium reached approximates the optimal social welfare (or some other natural objective); henceforth, we will simply refer to such equilibria as near-optimal. Taking a step back, there has been tremendous interest in understanding the performance of no-regret learning in terms of welfare, primarily stemming from the price of anarchy literature (e.g., \citepRoughgarden15:Intrinsic,Blum08:Regret), but here we ask an entirely different but equally fundamental question: How many iterations are needed so that no-regret players converge to a near-optimal (approximate) equilibrium? In terms of proving a lower bound, one natural approach revolves around the premise that players initially possess no information about the game, and in each iteration they receive only some limited utility feedback. We argue that there are certain caveats to such an approach. First, it does not apply to the usual centralized model of computation where the underlying game is given as part of the input. Furthermore, even in decentralized settings there is often a centralized party endeavoring to intervene and guide players to desirable outcomes \citepMguni19:Coordinating,Kempe20:Inducing,Li20:End,Liu22:Inducing,Balcan13:Circumventing,Balcan14:Near. Many models have been proposed that differ based on the amount of information gathered by the centralized party, as well as the way communication occurs between the different entities; each such model is arguably reasonable depending on the application. The question thus is how to come up with a lower bound that is not brittle to assumptions regarding the way information is distributed, and thereby applies to all such settings. We address this by resorting to computational lower bounds, thereby ruling out fast convergence to a near-optimal equilibrium even when the entire game is known in advanceâ€”subsuming the so-called full feedback setting (recalled in Section 2)â€”and players can fully coordinate; at first glance, it might seem counterintuitive that non-trivial lower bounds can be established under such permissive assumptions. In particular, we focus on perhaps the simplest class of games for which such questions become meaningful: two-player (general-sum) games represented in normal form; since we are aiming to prove lower bounds, concentrating on a simple class of games only makes the result stronger. 1.1 Our results We establish tight computational lower bounds for the number of iterations needed for no-regret players to reach a near-optimal equilibrium in two-player games. To do so, a key observation that drives our approach is that no-regret learning produces, essentially by definition, a CCE with a particular structure: one expressed as a mixture (that is, a convex combination) of product distributions. In particular, Tğ‘‡Titalic_T rounds of learning results in a mixture of Tğ‘‡Titalic_T product distributions. We call such a distribution Tğ‘‡Titalic_T-sparse (Definition 2.1). In this context, our main contribution is to prove hardness results for the problem of computing a near-optimal Tğ‘‡Titalic_T-sparse CCE, whichâ€”by virtue of the observation aboveâ€”immediately circumscribes the number of iterations for no-regret learning as well, even in the centralized model of computation. Even though this is a fundamental problem, to our knowledge, we are the first to examine its computational complexity as a function of Tğ‘‡Titalic_T. One special case of this problem is well-understood: a near-optimal 1111-sparse CCE is nothing other than a near-optimal Nash equilibrium, treated in the seminal work of \citetGilboa89:Nash (and subsequently extended by \citetConitzer08:New and \citetKothari18:Sum), and shown to be \NP\NP\NP-complete. On the other end of the spectrum, assuming that each player has nğ‘›nitalic_n available actions, it is easy to see that any correlated distributionâ€”and in particular any CCEâ€”is nğ‘›nitalic_n-sparse. In light of the well-known fact that the optimal CCE can be computed in polynomial time via a linear program (Proposition 2.3), we see that there is a phase transition dictated by the sparsity parameter. In fact, our first main result shows that attaining non-trivial sparsity in polynomial time is impossible (subject to Â¶â‰ \NPÂ¶\NP\P\neq\NPÂ¶ â‰ ). Below, for an nÃ—nğ‘›ğ‘›n\times nitalic_n Ã— italic_n two-player game ğ’¢ğ’¢{\mathcal{G}}caligraphic_G, we denote by OptimalSparseCCEâ¢(ğ’¢,T,Ïµ,Ïµ^)OptimalSparseCCEğ’¢ğ‘‡italic-Ïµ^italic-Ïµ\textsc{OptimalSparseCCE}({\mathcal{G}},T,\epsilon,\hat{\epsilon})OptimalSparseCCE ( caligraphic_G , italic_T , italic_Ïµ , over^ start_ARG italic_Ïµ end_ARG ) the problem of computing a Tğ‘‡Titalic_T-sparse CCE with equilibrium gap at most Ïµitalic-Ïµ\epsilonitalic_Ïµ (in an additive sense; see Definition 2.2) and welfare at least ğ–®ğ–¯ğ–³âˆ’Ïµ^ğ–®ğ–¯ğ–³^italic-Ïµ\mathsf{OPT}-\hat{\epsilon}sansserif_OPT - over^ start_ARG italic_Ïµ end_ARG, where ğ–®ğ–¯ğ–³ğ–®ğ–¯ğ–³\mathsf{OPT}sansserif_OPT is the welfare attained by the optimal Tğ‘‡Titalic_T-sparse CCE. (Further background is given later in Section 2.) Theorem 1.1. OptimalSparseCCEâ¢(ğ’¢,n1âˆ’Ïµ,nâˆ’c,nâˆ’c)OptimalSparseCCEğ’¢superscriptğ‘›1italic-Ïµsuperscriptğ‘›ğ‘superscriptğ‘›ğ‘\textsc{OptimalSparseCCE}({\mathcal{G}},n^{1-\epsilon},n^{-c},n^{-c})OptimalSparseCCE ( caligraphic_G , italic_n start_POSTSUPERSCRIPT 1 - italic_Ïµ end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) with respect to nÃ—nğ‘›ğ‘›n\times nitalic_n Ã— italic_n games is \NP\NP\NP-hard for any constant Ïµ>0italic-Ïµ0\epsilon>0italic_Ïµ > 0 and some constant cğ‘citalic_c. This means that roughly nğ‘›nitalic_n iterations are needed for (computationally bounded) no-regret learners to converge to a CCE with ğ—‰ğ—ˆğ—…ğ—’â¢(1/n)ğ—‰ğ—ˆğ—…ğ—’1ğ‘›\mathsf{poly}(1/n)sansserif_poly ( 1 / italic_n ) equilibrium and optimality gap; that is, the trivial upper bound of nğ‘›nitalic_n is essentially the best one can hope for. Further, a slightly stronger complexity assumption precludes even a sparsity of n/2(ğ—…ğ—ˆğ—€â¢n)1âˆ’Î³ğ‘›superscript2superscriptğ—…ğ—ˆğ—€ğ‘›1ğ›¾n/2^{(\mathsf{log}n)^{1-\gamma}}italic_n / 2 start_POSTSUPERSCRIPT ( sansserif_log italic_n ) start_POSTSUPERSCRIPT 1 - italic_Î³ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT for some constant Î³>0ğ›¾0\gamma>0italic_Î³ > 0 (Corollary 3.3). It is worth noting that Tâ‰”nâ‰”ğ‘‡ğ‘›T\coloneqq nitalic_T â‰” italic_n iterations also represent a natural information-theoretic threshold: in the full feedback setting, to which our lower bounds readily apply, there is a trivial exploration protocol that enables each player to fully determine its own payoff matrix (by simply iterating over all rows or columns)â€”trivializing the problem at least in (two-player) zero-sum games. In addition, Theorem 1.1 establishes a complexity separation between OptimalSparseCCE and SparseCCEâ€”the latter problem lifts the welfare constraint imposed by the former. Namely, since SparseCCEâ¢(ğ’¢,T,0)SparseCCEğ’¢ğ‘‡0\textsc{SparseCCE}({\mathcal{G}},T,0)SparseCCE ( caligraphic_G , italic_T , 0 ) is in \PPAD\PPAD\PPAD even for T=1ğ‘‡1T=1italic_T = 1 \citepPapadimitriou94:On, OptimalSparseCCE is harder (subject to \coNPâ‰ \NP\coNP\NP\coNP\neq\NPâ‰  \citepJohnson88:How) for any sparsity Tâ‰¤n1âˆ’Ïµğ‘‡superscriptğ‘›1italic-ÏµT\leq n^{1-\epsilon}italic_T â‰¤ italic_n start_POSTSUPERSCRIPT 1 - italic_Ïµ end_POSTSUPERSCRIPT. Moreover, we strengthen Theorem 1.1 in two key aspects. First, we show that it applies under a broad class of objectives, beyond (utilitarian) welfare, which additionally includes the egalitarian social welfare and each playerâ€™s (individual) utility (Corollaries 3.13 and 3.12). Second, \NP-hardness persists for any multiplicative approximation to the objective (Corollary 3.14). The key construction behind those results, Theorem 3.11, implies similar hardness results for two other natural problems pertaining to sparse CCE: deciding uniqueness (Theorem 3.9), and determining existence after excluding certain (joint) action profiles (Theorem 3.10); those two latter problems do not hinge on any underlying objective. Technical approach Compared to Nash equilibria, the crux in proving lower bounds for sparse CCE lies in introducing correlation between the players. Many natural reductions designed for Nash equilibria are of little use even for sparsity T=2ğ‘‡2T=2italic_T = 2, which partly explains why the complexity of sparse CCE remains poorly understood. The key challenge is to identify a basic construction that handles near-optimal Tğ‘‡Titalic_T-sparse CCE even when Tâ‰«1much-greater-thanğ‘‡1T\gg 1italic_T â‰« 1. In this context, to prove Theorem 1.1, we extend the reduction of \citetGilboa89:Nash who proved \NP\NP\NP-hardness only when T=1ğ‘‡1T=1italic_T = 1. In particular, they came up with a reduction from the decision version of the maximum clique problem (MaxClique) to OptimalSparseCCEâ¢(ğ’¢,1,0,0)OptimalSparseCCEğ’¢100\textsc{OptimalSparseCCE}({\mathcal{G}},1,0,0)OptimalSparseCCE ( caligraphic_G , 1 , 0 , 0 ). We establish a natural generalization of their reduction (Algorithm 1); namely, we show that computing a 2â¢T2ğ‘‡2T2 italic_T-approximation to MaxClique polynomially reduces to OptimalSparseCCEâ¢(ğ’¢,T,nâˆ’c,nâˆ’c)OptimalSparseCCEğ’¢ğ‘‡superscriptğ‘›ğ‘superscriptğ‘›ğ‘\textsc{OptimalSparseCCE}({\mathcal{G}},T,n^{-c},n^{-c})OptimalSparseCCE ( caligraphic_G , italic_T , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) (Theorem 3.1). That is, the sparsity of the underlying CCE translates to a degradation in the resulting approximation factor. We are then able to rely on the celebrated inapproximability of MaxClique \citepZuckerman07:Linear (Theorem 2.4) to arrive at Theorem 1.1. The overall reduction has various new technical aspects, discussed in Section 3.1. The refinements to Theorem 1.1 described earlier are established by suitably adjusting this basic reduction (Sections 3.2 and 3.3). Low-precision regime So far, we have focused on the regime where both the equilibrium and the optimality gap scale as ğ—‰ğ—ˆğ—…ğ—’â¢(1/n)ğ—‰ğ—ˆğ—…ğ—’1ğ‘›\mathsf{poly}(1/n)sansserif_poly ( 1 / italic_n )â€”a common setting when it comes to equilibrium computation. No-regret learning is often employed in the so-called low-precision regime, which we identify with Ïµ,Ïµ^â‰¥1/\polylogâ¢nitalic-Ïµ^italic-Ïµ1\polylogğ‘›\epsilon,\hat{\epsilon}\geq 1/\polylog nitalic_Ïµ , over^ start_ARG italic_Ïµ end_ARG â‰¥ 1 / italic_n. In that setting, even Nash equilibria admit a quasipolynomial-time algorithm \citepLipton03:Playing, and so one cannot hope to proveâ€”barring major complexity breakthroughsâ€”\NP-hardness results. Instead, following an earlier work by \citetHazan11:How, we rely on the so-called planted clique conjecture from average-case complexity (2.5; Section 2 provides a self-contained overview). We are then able to show the following quasipolynomial lower bounds. Theorem 1.2. Assuming that 2.5 holds, the following problems require nÎ©â¢(ğ—…ğ—ˆğ—€â¢n)superscriptğ‘›Î©ğ—…ğ—ˆğ—€ğ‘›n^{\Omega(\mathsf{log}n)}italic_n start_POSTSUPERSCRIPT roman_Î© ( sansserif_log italic_n ) end_POSTSUPERSCRIPT time with respect to nÃ—nğ‘›ğ‘›n\times nitalic_n Ã— italic_n games: â€¢ OptimalSparseCCEâ¢(ğ’¢,T,(ğ—…ğ—ˆğ—€â¢n)âˆ’c,(ğ—…ğ—ˆğ—€â¢n)âˆ’c)OptimalSparseCCEğ’¢ğ‘‡superscriptğ—…ğ—ˆğ—€ğ‘›ğ‘superscriptğ—…ğ—ˆğ—€ğ‘›ğ‘\textsc{OptimalSparseCCE}({\mathcal{G}},T,(\mathsf{log}n)^{-c},(\mathsf{log}n)% ^{-c})OptimalSparseCCE ( caligraphic_G , italic_T , ( sansserif_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , ( sansserif_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) for any T=\polylogâ¢nğ‘‡\polylogğ‘›T=\polylog nitalic_T = italic_n and some constant c=câ¢(T)ğ‘ğ‘ğ‘‡c=c(T)italic_c = italic_c ( italic_T ), â€¢ OptimalSparseCCEâ¢(ğ’¢,T,c,c)OptimalSparseCCEğ’¢ğ‘‡ğ‘ğ‘\textsc{OptimalSparseCCE}({\mathcal{G}},T,c,c)OptimalSparseCCE ( caligraphic_G , italic_T , italic_c , italic_c ) for any T=Oâ¢(1)ğ‘‡ğ‘‚1T=O(1)italic_T = italic_O ( 1 ) and some constant c=câ¢(T)ğ‘ğ‘ğ‘‡c=c(T)italic_c = italic_c ( italic_T ). The first lower bound is shown by relying on our previous construction behind Theorem 1.1. The second one, which concerns the more permissive regime in which Ïµ,Ïµ^=Î˜â¢(1)italic-Ïµ^italic-ÏµÎ˜1\epsilon,\hat{\epsilon}=\Theta(1)italic_Ïµ , over^ start_ARG italic_Ïµ end_ARG = roman_Î˜ ( 1 ), adapts the reduction of \citetHazan11:How pertaining to optimal Nash equilibria. We provide the technical details in Section 4. 1.2 Further related work The notion of a sparse CCEâ€”a mixture of product distributions (Definition 2.1)â€”was recently studied by \citetFoster23:Hardness in the context of Markov (aka. stochastic) games to rule out the existence of polynomial-time no-regret algorithmsâ€”with respect to potentially non-Markovian deviations (see also the work of \citetPeng24:Complexity). This stands in contrast to games represented in normal form, where the existence of efficient no-regret algorithms has been long known tracing back to \citetBlackwell56:analog. Yet, establishing non-trivial lower bounds for sparse CCE in normal-form games remains an open problem even for sparsity T=2ğ‘‡2T=2italic_T = 2. It is worth highlighting that even though a CCE (without the sparsity constraint) can be computed exactly by solving a linear program \citepPapadimitriou08:Computing, by far the most well-studied approach in the literature revolves around no-regret learning. This can be mostly attributed to the scalability, the minimal memory footprint, as well as the amenability to a distributed implementation of the latter approach, motivating the problem of sparse CCE. Besides this connection with no-regret learning, we argue that sparse CCE is a natural notion, worth examining in its own right, and ties to a long line of work on low-rank approximation in machine learning. A related notion of sparsity imposes instead a bound on the number of nonzero elements of the distributionâ€”that is, the size of its support. Unlike Definition 2.1, that latter notion is well-studied and understood (e.g., \citepBabichenko14:Simple). It is clear that a distribution ğğ\bm{\mu}bold_italic_Î¼ with Tğ‘‡Titalic_T nonzero entries is Tğ‘‡Titalic_T-sparse per Definition 2.1, but the opposite does not hold in general. From the viewpoint of no-regret learning, proving lower bounds pertaining to distributions with small support translates to the setting where each player selects a pure strategy, while Definition 2.1 accounts for mixed strategies as well. To further elaborate on this difference, it is known that Î©â¢(ğ—…ğ—ˆğ—€â¢n/Ïµ2)Î©ğ—…ğ—ˆğ—€ğ‘›superscriptitalic-Ïµ2\Omega(\mathsf{log}n/\epsilon^{2})roman_Î© ( sansserif_log italic_n / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) nonzero elements in the support are information-theoretically necessary for even the existence of an Ïµitalic-Ïµ\epsilonitalic_Ïµ-Nash equilibrium in zero-sum games \citepFeder07:Approximating, in turn implying that Î©â¢(ğ—…ğ—ˆğ—€â¢n/Ïµ2)Î©ğ—…ğ—ˆğ—€ğ‘›superscriptitalic-Ïµ2\Omega(\mathsf{log}n/\epsilon^{2})roman_Î© ( sansserif_log italic_n / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) iterations are needed when players select pure strategies. On the other hand, a consequence of the minimax theorem is that a 1111-sparse equilibrium always exists, and can also be computed efficiently in such games via linear programming; this means that no superpolynomial computational lower bounds for no-regret learning in zero-sum games can be shown in mixed strategies. A long-standing challenge in general-sum games is equilibrium selection: there could be a multiplicity of equilibria, and some are more reasonable than others. A common antidoteâ€”albeit certainly not the only oneâ€”is to identify an equilibrium maximizing the social welfare (or some other natural objective). This can be achieved in polynomial time even in multi-player (normal-form) games represented explicitly, which motivates investigating the complexity of OptimalSparseCCEâ€”the focus of our work. However, this is no longer the case in succinct games, where maximizing welfare is typically \NP-hard \citepPapadimitriou08:Computing (cf. \citetBarman15:Finding)â€”let alone sparsity constraints. This is also the case for two-player extensive-form games (e.g., \citepZhang22:Optimal). Another motivation for proving lower bounds revolving around Tğ‘‡Titalic_T-sparse CCE is that while many techniques that accelerate equilibrium computation rely on no-regret learning dynamics, they do not strictly comply with the traditional online nature of the framework. A notable example is alternation \citepTammelin15:Solving,Wibisono22:Alternating,Cevher23:Alternation, whereby players update their strategies sequentiallyâ€”as opposed to simultaneous updates. Importantly, such techniques are captured through sparse CCE. Beyond computational considerations, it is worth pointing out an orthogonal line of work that has focused on query complexity aspects of (coarse) correlated equilibria (e.g., \citepGoldberg16:Bounds,Babichenko15:Query,Maiti23:Query,Goldberg23:Lower, and references therein)."
https://arxiv.org/html/2411.01462v2,"The Fairness of Maximum Nash Social Welfare Under Matroid Constraints and Beyondâ€ â€ thanks:This submission has been accepted by WINE 2024.This work is supported in part by the National Natural Science Foundation of China
(Nos. 12171444, 12301418, 12471306) and Natural Science Foundation of
Shandong (No. ZR2022QA014).","We study the problem of fair allocation of a set of indivisible items among agents with additive valuations, under matroid constraints and two generalizations: pğ‘pitalic_p-extendible system and independence system constraints. The objective is to find fair and efficient allocations in which the subset of items assigned to every agent satisfies the given constraint. We focus on a common fairness notion of envy-freeness up to one item (EF1) and a well-known efficient (and fair) notion of the maximum Nash social welfare (Max-NSW). By using properties of matroids, we demonstrate that the Max-NSW allocation, implying Pareto optimality (PO), achieves a tight 1/2121/21 / 2-EF1 under matroid constraints. This result resolves an open question proposed in prior literature [26]. In particular, if agents have 2-valued ({1,a}1ğ‘\{1,a\}{ 1 , italic_a }) valuations, we prove that the Max-NSW allocation admits maxâ¡{1/a2,1/2}1superscriptğ‘212\max\{1/a^{2},1/2\}roman_max { 1 / italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 1 / 2 }-EF1 and PO. Under strongly pğ‘pitalic_p-extendible system constraints, we show that the Max-NSW allocation guarantees maxâ¡{1/p,1/4}1ğ‘14\max\{1/p,1/4\}roman_max { 1 / italic_p , 1 / 4 }-EF1 and PO for identical binary valuations. Indeed, the approximation of 1/4141/41 / 4 is the ratio for independence system constraints and additive valuations. Additionally, for lexicographic preferences, we study possibly feasible allocations other than Max-NSW admitting exactly EF1 and PO under the above constraints.","Fair allocation of indivisible items among agents is a highly active problem in computational economics and artificial intelligence, due to its growing applications, e.g., Public Housing [10], Courses Allocation [6], the website of Spliddit (spliddit.org) [14], and the company Fair Outcomes (fairoutcomes.com). Central to this problem falls into two categories: fairness and efficiency. To capture fairness, envy-freeness (EF, [13]) is a compelling criterion: every agent prefers her own bundle to another oneâ€™s allocated bundle. Unfortunately, an EF allocation does not always exist even for allocating one indivisible item between two agents. This motivates a series of less stringent notions of envy-freeness, e.g., envy-freeness up to one item (EF1). For general monotone valuations, an EF1 allocation can be computed in polynomial time [21]. For finding efficient EF1 allocations, we are interested in a well-known criterion of Nash social welfare (NSW) that calculates the product of agentsâ€™ utilities. An allocation maximizing the Nash social welfare (Max-NSW) guarantees EF1 [8] and PO. While allocating indivisible items, we are more interested in relevant constraints, such as, cardinality constraints [4], budget constraints [27], scheduling constraints [20]) and conflicting constraints [17]. These categories of constraints can be formulated as special cases of independence system constraints. An independence system is a system (E,â„±)ğ¸â„±(E,\mathcal{F})( italic_E , caligraphic_F ), where Eğ¸Eitalic_E is a finite item set and â„±â„±\mathcal{F}caligraphic_F is a collection of (independent) subsets of Eğ¸Eitalic_E that has hereditary property: if Dâˆˆâ„±ğ·â„±D\in\mathcal{F}italic_D âˆˆ caligraphic_F and CâŠ†Dğ¶ğ·C\subseteq Ditalic_C âŠ† italic_D then Câˆˆâ„±ğ¶â„±C\in\mathcal{F}italic_C âˆˆ caligraphic_F. As a powerful abstraction of independence, matroid structures [22, 16, 15, 11] have played a prominent role in combinatorial optimization. An independence system (M,â„±)ğ‘€â„±(M,\mathcal{F})( italic_M , caligraphic_F ) is a matroid if â„±â„±\mathcal{F}caligraphic_F also has augmentation property: for C,Dâˆˆâ„±ğ¶ğ·â„±C,D\in\mathcal{F}italic_C , italic_D âˆˆ caligraphic_F with |C|<|D|ğ¶ğ·|C|<|D|| italic_C | < | italic_D |, there is an item xâˆˆDâˆ–Cğ‘¥ğ·ğ¶x\in D\setminus Citalic_x âˆˆ italic_D âˆ– italic_C such that C+xâˆˆâ„±ğ¶ğ‘¥â„±C+x\in\mathcal{F}italic_C + italic_x âˆˆ caligraphic_F 111The notation C+xğ¶ğ‘¥C+xitalic_C + italic_x means Câˆª{x}ğ¶ğ‘¥C\cup\{x\}italic_C âˆª { italic_x }, likewise Câˆ’xğ¶ğ‘¥C-xitalic_C - italic_x means Câˆ–{x}ğ¶ğ‘¥C\setminus\{x\}italic_C âˆ– { italic_x }.. In particular, cardinality constraints are equivalent to partition constraints [4]. Due to the flexible properties of matroid (or independence system) structures, it is challenging to explore fair and efficient allocations under matroid constraints (or more general independence system constraints). Indeed, Suksompong [26] illustrated that the existence problem of EF1 and PO allocation remained open under matroids constraints (in Section 4). In this paper, we are interested in making efforts towards this direction by Max-NSW allocations, approximate EF1 allocations, properties of matroids and other effective techniques. 1.1 Our Contribution We have strived to examine the existence of Max-NSW and approximate EF1 allocations under three prominent constraints: matroids, pğ‘pitalic_p-extendible systems, and independence systems (the relationships between the three can be seen in Figure 1). Throughout, we select a specific Max-NSW allocation guaranteeing Pareto Optimality (PO) under all three classes of constraints. The main contributions in this paper are summarized in Table LABEL:table1. 1.1.1 Matroid Constraints. (Section 3) A system (M,â„±)ğ‘€â„±(M,\mathcal{F})( italic_M , caligraphic_F ) is a matroid if Mğ‘€Mitalic_M is a finite item set, and â„±â„±\mathcal{F}caligraphic_F satisfies that i) hereditary property: if Dâˆˆâ„±ğ·â„±D\in\mathcal{F}italic_D âˆˆ caligraphic_F and CâŠ†Dğ¶ğ·C\subseteq Ditalic_C âŠ† italic_D, then Câˆˆâ„±ğ¶â„±C\in\mathcal{F}italic_C âˆˆ caligraphic_F; ii) augmentation property: if C,Dâˆˆâ„±ğ¶ğ·â„±C,D\in\mathcal{F}italic_C , italic_D âˆˆ caligraphic_F and |D|>|C|ğ·ğ¶|D|>|C|| italic_D | > | italic_C |, then there is an item xâˆˆDâˆ–Cğ‘¥ğ·ğ¶x\in D\setminus Citalic_x âˆˆ italic_D âˆ– italic_C such that C+xâˆˆâ„±ğ¶ğ‘¥â„±C+x\in\mathcal{F}italic_C + italic_x âˆˆ caligraphic_F. For general additive valuations, we illustrate that every Max-NSW allocation achieves 1/2121/21 / 2-EF1 under matroid constraints. This approximation ratio cannot be improved since we exemplify an instance that for arbitrary Îµ>0ğœ€0\varepsilon>0italic_Îµ > 0, there is no feasible Max-NSW and (1/2+Îµ)12ğœ€(1/2+\varepsilon)( 1 / 2 + italic_Îµ )-EF1 allocation under partition matroids. In particular, for identical valuations, Biswas et al. [4] have shown that an exact EF1 and PO allocation was guaranteed to exist by the Max-NSW allocation under matroid constraints. In this settings, we find an exact EF1 and PO allocation by leximin ordering. Furthermore, if all agents have binary valuations, Dror et al. [11] computed an exact EF1 and PO allocation under partition matroids. We explore the extended settings of 2-valued valuations that each itemâ€™s value falls into {1,a}1ğ‘\{1,a\}{ 1 , italic_a } with a>1ğ‘1a>1italic_a > 1 for each agent, and strikingly demonstrate that every Max-NSW allocation is maxâ¡{1/a2,1/2}1superscriptğ‘212\max\{1/a^{2},1/2\}roman_max { 1 / italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 1 / 2 }-EF1 and PO under partition matroids. 1.1.2 Beyond Matroid Constraints. (Section 4) The results focus on two general classes pğ‘pitalic_p-extendible systems and independence systems. We restrict the pğ‘pitalic_p-extendible system [22] to a strongly pğ‘pitalic_p-extendible system (M,â„±)ğ‘€â„±(M,\mathcal{F})( italic_M , caligraphic_F ) (Definition 7): if Câˆˆâ„±,Dâˆˆâ„±formulae-sequenceğ¶â„±ğ·â„±C\in\mathcal{F},D\in\mathcal{F}italic_C âˆˆ caligraphic_F , italic_D âˆˆ caligraphic_F with CâŠ‚Dğ¶ğ·C\subset Ditalic_C âŠ‚ italic_D and if Hâˆ©C=âˆ…ğ»ğ¶H\cap C=\emptysetitalic_H âˆ© italic_C = âˆ… such that CâˆªHâˆˆâ„±ğ¶ğ»â„±C\cup H\in\mathcal{F}italic_C âˆª italic_H âˆˆ caligraphic_F, then there exists a subset YâŠ†Dâˆ–Cğ‘Œğ·ğ¶Y\subseteq D\setminus Citalic_Y âŠ† italic_D âˆ– italic_C with |Y|â‰¤pâ¢|H|ğ‘Œğ‘ğ»|Y|\leq p|H|| italic_Y | â‰¤ italic_p | italic_H | such that Dâˆ–YâˆªHâˆˆâ„±ğ·ğ‘Œğ»â„±D\setminus Y\cup H\in\mathcal{F}italic_D âˆ– italic_Y âˆª italic_H âˆˆ caligraphic_F. Furthermore, we focus on strongly pğ‘pitalic_p-extendible systems, which still include all matroids. For identical binary valuations, we show that every Max-NSW allocation achieves maxâ¡{1/p,1/4}1ğ‘14\max\{1/p,1/4\}roman_max { 1 / italic_p , 1 / 4 }-EF1 and PO under strongly pğ‘pitalic_p-extendible systems. Independence systems are systems that satisfy only hereditary property. For additive valuations, every Max-NSW allocation is 1/4141/41 / 4-EF1 and the approximation is already tight. Interestingly, we further consider lexicographic preferences [24], under independence system constraints, and compute an exact EF1 and PO allocation by a greedy-method algorithm. {talltblr} [ caption=Summary of our main results. Identical, bi. and identical-bi refer to identical additive, binary additive, and identical binary additive valuations respectively. LB and UB refer to lower bounds and upper bounds respectively. â€œâ‡’â‡’\Rightarrowâ‡’ POâ€ refers to outcomes guarantee Pareto optimality., label=table1 ] width=row1-2 = gray!20, font=, hline1,Z = 1pt, hline3,4,7,8 = solid, hline2 = solid \SetCell [r=2]l,m Constraints &\SetCell[r=2]l,m Valuations \SetCell[c=2]c,m Max-NSWs (â‡’â‡’\Rightarrowâ‡’ PO) \SetCell[r=2]c,m Others (â‡’â‡’\Rightarrowâ‡’ PO) \SetCellc,m LB \SetCellc,m UB \SetCell[r=1]c,m Partition Matroids \SetCellc,m additive \SetCellc,m 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 (12+Îµ)12ğœ€(\frac{1}{2}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_Îµ )-EF1 1-EF1 (bi.)[11] \SetCell[r=3]c,m Matroids \SetCellc,m additive \SetCellc,m 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 (12+Îµ)12ğœ€(\frac{1}{2}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_Îµ )-EF1 \SetCellc,m identical \SetCellc,m 1-EF1 [4] 1-EF1(by leximin) \SetCell c,m {1,a}1ğ‘\{1,a\}{ 1 , italic_a }-valued maxâ¡{1a2,12}1superscriptğ‘212\max\{\frac{1}{a^{2}},\frac{1}{2}\}roman_max { divide start_ARG 1 end_ARG start_ARG italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG , divide start_ARG 1 end_ARG start_ARG 2 end_ARG }-EF1 Strongly pğ‘pitalic_p-Extendible Systems \SetCellc,m identical-bi maxâ¡{1p,14}1ğ‘14\max\{\frac{1}{p},\frac{1}{4}\}roman_max { divide start_ARG 1 end_ARG start_ARG italic_p end_ARG , divide start_ARG 1 end_ARG start_ARG 4 end_ARG }-EF1 (23+Îµ)23ğœ€(\frac{2}{3}+\varepsilon)( divide start_ARG 2 end_ARG start_ARG 3 end_ARG + italic_Îµ )-EF1 \SetCell[r=2]c,m Independence Systems \SetCellc,m additive \SetCellc,m 1414\frac{1}{4}divide start_ARG 1 end_ARG start_ARG 4 end_ARG-EF1 (14+Îµ)14ğœ€(\frac{1}{4}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 4 end_ARG + italic_Îµ )-EF1 \SetCellc,m lexicographic 1-EF1 (by RR alg.) 1.2 Related Work There is a vast literature on fairly and efficiently allocating indivisible items without constraints. In particular, Caragiannis et al. [7, 8] originated that a Max-NSW allocation is both strikingly EF1 and approximately Maximin share for additive valuations. Barman et al. [2] provided an efficient greedy algorithm to compute a Max-NSW allocation for binary valuations while finding Max-NSW allocations is APX-hard in general [19]. Benabbou et al. [3] showed that Max-NSW and leximin allocations both processed the EF1 property for matroid rank valuations. Amanatidis et al. [1] established that a Max-NSW allocation was always envy-freeness up to any item (EFX, [9]) for 2-valued valuations. Plaut and Roughgarden [23] EFX allocations and PO allocations were not compatible with general valuations. Recently, Feldman et al. [12] demonstrated an optimal tradeoff that for any 0â‰¤Î±â‰¤10ğ›¼10\leq\alpha\leq 10 â‰¤ italic_Î± â‰¤ 1, an Î±ğ›¼\alphaitalic_Î±-EFX allocation can guarantee 1/(Î±+1)1ğ›¼11/(\alpha+1)1 / ( italic_Î± + 1 )-Max-NSW for additive valuations. Our work is related to fair and efficient allocations in constrained settings. Wu et al. [27] showed that under budget constraints, the Max-NSW allocation achieved 1/4141/41 / 4-EF1 with tight approximation ratio. We extend this positive result to more general constraints (independence systems). Biswas and Barman [4] firstly considered special matroid constraints. They developed efficient algorithms to compute EF1 allocations under laminar matroids for identical additive valuations. If items are labeled by goods or chores, Shoshan et al. [25] provided a polynomial-time algorithm to compute feasible allocations under partition constraints guaranteed PO and EF up to one good and one chore. Dror et al. [11] demonstrated the existence of EF1 allocations by devising algorithms on the settings of heterogeneous partition matroids, and nğ‘›nitalic_n agents with binary additive valuations (or two agents with general additive valuations). Besides, more literature studied other fairness allocations (e.g., Maximin share) under matroid constraints, which can be traced back to references [18, 15, 17]. Beyond the above special settings, we will focus on central constraints of general matroids, pğ‘pitalic_p-extendible systems and even independent systems in this paper, and we further explore the efficiency of feasible allocations."
https://arxiv.org/html/2411.01217v1,Preference-CFR: Beyond Nash Equilibrium for Better Game Strategies,"Recent advancements in artificial intelligence (AI) have leveraged large-scale games as benchmarks to gauge progress, with AI now frequently outperforming human capabilities. Traditionally, this success has largely relied on solving Nash equilibrium (NE) using variations of the counterfactual regret minimization (CFR) method in games with incomplete information. However, the variety of Nash equilibria has been largely overlooked in previous research, limiting the adaptability of AI to meet diverse human preferences. To address this challenge, where AI is powerful but struggles to meet customization needs, we introduce a novel approach: Preference-CFR, which incorporates two new parameters: preference degree and vulnerability degree. These parameters allow for greater flexibility in AI strategy development without compromising convergence. Our method significantly alters the distribution of final strategies, enabling the creation of customized AI models that better align with individual user needs. Using Texas Holdâ€™em as a case study, our experiments demonstrate how Preference CFR can be adjusted to either emphasize customization, prioritizing user preferences, or to enhance performance, striking a balance between the depth of customization and strategic optimality.","In machine learning, complex gaming problems are important benchmarks for assessing artificial intelligence (AI). Prominent games such as Chess Hsu (2002), Go Silver et al. (2017, 2016, 2018), StarCraft Vinyals et al. (2019), and Texas Holdâ€™em MoravÃ­k et al. (2017); Bowling et al. (2015); Brown and Sandholm (2019b) have significantly influenced both academic research and public interest. Traditionally, research has centered on finding Nash equilibrium (NE), as it guarantees that no player can increase their expected payoff by unilaterally changing strategies. From the perspective of expected payoffs, NE represents the optimal solution in games, leading many studies to regard a game problem as solved once its NE is identified. However, maximizing expected payoffs in the worst case is not the sole criterion for evaluating a strategyâ€™s quality. Here, we introduce two additional indicators beyond expected payoffs. 1. In many games, multiple NE can exist. In economics, exploring the diversity of NE is often more valuable than simply identifying them. For example, Schellingâ€™s work on predicting the emergence of specific NE earned him the 2005 Nobel Prize in Economics. Similarly, the current development of AI demands not only optimal solutions but also diverse and flexible strategies. The goal is to move away from rigid, overly rational AI behaviors and towards strategies that exhibit more human-like characteristics. Moreover, making AI algorithms more interpretable is essential for enhancing their reliability and practical usefulness across various applications. 2. NE focuses solely on the magnitude of expected payoffs, disregarding the variability in those payoffs. However, balancing risk and reward is a crucial aspect of decision-making. In different situations, we may need to adjust this balance and choose strategies accordingly. Relying on NE alone does not provide the flexibility to accommodate varying risk preferences. Previous algorithms that have achieved success in incomplete information have not addressed the issues mentioned above. To overcome these limitations, we propose a new algorithm called Preference Counterfactual Regret Minimization (Pref-CFR). This algorithm introduces two additional parameters for strategy selection: the preference degree Î´ğ›¿\deltaitalic_Î´, which represents the playerâ€™s inclination towards a particular action, and the vulnerability degree Î²ğ›½\betaitalic_Î², which indicates the maximum level of exploitability the player is willing to accept. More importantly, by setting the preference and vulnerability degrees, Pref-CFR can achieve specific strategy styles as desired by humans (e.g., a highly aggressive play style in poker). Additionally, the implementation of Pref-CFR is straightforward, requiring only minimal code changes from the original CFR, and it remains compatible with many previous CFR variants. In the experimental section, we first illustrate the limitations of the original CFR in failing to converge to different equilibria. We then highlight the capability of our algorithm to converge to various strategy styles in Texas Holdâ€™em poker."
https://arxiv.org/html/2411.00954v1,Sample-Efficient Regret-Minimizing Double Oracle in Extensive-Form Games,"Extensive-Form Game (EFG) represents a fundamental model for analyzing sequential interactions among multiple agents and the primary challenge to solve it lies in mitigating sample complexity. Existing research indicated that Double Oracle (DO) can reduce the sample complexity dependence on the information set number |S|ğ‘†|S|| italic_S | to the final restricted game size Xğ‘‹Xitalic_X in solving EFG. This is attributed to the early convergence of full-game Nash Equilibrium (NE) through iteratively solving restricted games. However, we prove that the state-of-the-art Extensive-Form Double Oracle (XDO) exhibits exponential sample complexity of Xğ‘‹Xitalic_X, due to its exponentially increasing restricted game expansion frequency. Here we introduce Adaptive Double Oracle (AdaDO) to significantly alleviate sample complexity to polynomial by deploying the optimal expansion frequency. Furthermore, to comprehensively study the principles and influencing factors underlying sample complexity, we introduce a novel theoretical framework Regret-Minimizing Double Oracle (RMDO) to provide directions for designing efficient DO algorithms. Empirical results demonstrate that AdaDO attains the more superior approximation of NE with less sample complexity than the strong baselines including Linear CFR, MCCFR and existing DO. Importantly, combining RMDO with warm starting and stochastic regret minimization further improves convergence rate and scalability, thereby paving the way for addressing complex multi-agent tasks.","Extensive-Form Game (EFG) is one of the widely studied fundamental models in game theory (Ritzberger et al., 2016), and solving its Nash equilibrium (NE) is critical for addressing sequential decision-making problems constructed by multiple agents such as board games and auction bidding (Hart, 1992). Existing work have made strides in solving EFG, notably through a series of methods based on Counterfactual Regret Minimization (CFR) (Zinkevich et al., 2007; Farina et al., 2020; Lanctot et al., 2009). These methods aim to approximate Nash equilibrium by traversing all nodes (information sets) within the game tree to compute counterfactual regrets and update strategies. However, it is evident that the sample complexity of CFR methods heavily depends on the number of information sets, denoted by |S|ğ‘†|S|| italic_S |. Consequently, as the scale and complexity of the game increase, the resulting sample complexity by CFR methods becomes prohibitively high which significantly improves the intractability of solving EFGs. To efficiently solve EFGs, prior work have attempted to introduce Double Oracle (DO) paradigm (McMahan et al., 2003; Bosansky et al., 2014; McAleer et al., 2021; Dinh et al., 2022), which has a superior mechanism with lower complexity dependencies than CFR family. The core idea of DO is to approximate NE only by resolving an expanding restricted game where players can only choose actions from a subset of the action space. The restricted game is expanded by adding the original gameâ€™s Best Response (BR) against the NE in the restricted game (meta-NE). Since DOâ€™s restricted game typically halts its growth in the early stages before reaching the original game, DO can reduce the sample complexity dependence from |S|ğ‘†|S|| italic_S | to the final restricted game size Xğ‘‹Xitalic_X. The empirical results also demonstrate this advantage that the Extensive-Form DO (XDO) (McAleer et al., 2021) proposed based on DO framework can converge more efficiently to a less exploitable strategy than the regret minimization algorithm, and has become a state-of-the-art algorithm for solving EFGs. However, XDO iteratively executing regret minimization in restricted games until the local exploitability reaches a threshold Ïµitalic-Ïµ\epsilonitalic_Ïµ, which then will be halved. This may lead to explosive growth in sample complexity in some cases but it is unclear how to mitigate it under complexity theory guidance. This motivates the core question we aim to answer: Q: What causes high sample complexity and how to avoid them when designing more efficient extensive-form DO algorithms? Firstly, we introduce a unified framework, Regret-Minimizing Double Oracle (RMDO) to theoretically understand the sources of sample complexity within the DO framework. RMDO is a generalization of existing DO methods including DO, XDO and ODO. We derive the sample complexity for RMDO framework to reach Ïµitalic-Ïµ\epsilonitalic_Ïµ-NE: ğ’ª~â¢(kâ¢|A|â¢X3/Ïµ2+âˆ‘j=1k|A|â¢X3/Ïµ2â¢mâ¢(j)+Xâ¢mâ¢(j)),~ğ’ªğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2superscriptsubscriptğ‘—1ğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2ğ‘šğ‘—ğ‘‹ğ‘šğ‘—\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2}+\sum_{j=1}^{k}|A|X^{3}/\epsilon^{2}% m(j)+Xm(j)),over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_m ( italic_j ) + italic_X italic_m ( italic_j ) ) , (1) where jğ‘—jitalic_j is the index of restricted game, Ağ´Aitalic_A is the action space, kğ‘˜kitalic_k is the number of restricted games, Xğ‘‹Xitalic_X is the largest game size among the games constructed by the support of NEs, and mâ¢(â‹…)ğ‘šâ‹…m(\cdot)italic_m ( â‹… ) is the frequency function of computing Best Response added to expand the restricted game. By setting different mâ¢(â‹…)ğ‘šâ‹…m(\cdot)italic_m ( â‹… ), RMDO can be converted to existing existing DO methods. Based on RMDO, We have proved that even the state-of-the-art method XDO has the exponential sample complexity in kğ‘˜kitalic_k, where kğ‘˜kitalic_k represents the count of restricted games and is only bounded by the number of information sets in the final restricted game, denoted by Xğ‘‹Xitalic_X. This verified the concern about the complexity explosion of XDO. Furthermore, based on the theoretical insights of RMDO, we propose an instance of RMDO called Adaptive Double Oracle (AdaDO), which employs the theoretically optimal frequency function to alleviate concerns about exponential sample complexity. AdaDO exhibits polynomial sample complexity to reach Ïµitalic-Ïµ\epsilonitalic_Ïµ-NE, which matches the complexity lower bound of RMDO framework, and thus is more sample efficient than existing DO methods including XDO. Furthermore, to reduce the complexity caused by kğ‘˜kitalic_k by integrating with warm starting for strategy initialization when solving a new restricted game, AdaDO demonstrates a significant improvement in the speed of exploitability decreasing empirically. We also adopt stochastic regret minimizer, exemplified by Monte-Carlo Counterfactual Regret Minimization (MCCFR) (Farina et al., 2020; Lanctot et al., 2009), for the restricted game solving, and manage to reduce the power of Xğ‘‹Xitalic_X in the sample complexity of AdaDO and enhance the scalability of Double Oracle methods. We present a comprehensive summary of theoretical results in Table 1, where Periodic Double Oracle (PDO) is naive improved instance by setting a constant expansion frequency but suffering from tuning this constant hyperparameter. Stochastic PDO (SPDO) and Stochastic Adaptive Double Oracle (SADO) are the natural extension of PDO and AdaDO adopting stochastic regret minimization for restricted game solving. Table 1: Main theoretical results of sample complexities for RMDO instances to reach Ïµitalic-Ïµ\epsilonitalic_Ïµ-NE in extensive-form games. We categorize the algorithms into reaching NE by regret minimization (RM) and stochastic regret minimization (SRM). Denote |S|ğ‘†|S|| italic_S | as the number of infosets. Since Xğ‘‹Xitalic_X and kğ‘˜kitalic_k are only bounded by |S|ğ‘†|S|| italic_S |, here we display the degree of these two dominating terms kğ‘˜kitalic_k and Xğ‘‹Xitalic_X in the Sample Complexities. Besides, it is usually that kâ‰«|A|much-greater-thanğ‘˜ğ´k\gg|A|italic_k â‰« | italic_A | in theory since |A|âˆ¼ğ’ªâ¢(|S|1/H)similar-toğ´ğ’ªsuperscriptğ‘†1ğ»|A|\sim\mathcal{O}(|S|^{1/H})| italic_A | âˆ¼ caligraphic_O ( | italic_S | start_POSTSUPERSCRIPT 1 / italic_H end_POSTSUPERSCRIPT ), where Hğ»Hitalic_H is the horizon of the game, but kğ‘˜kitalic_k is merely upper bounded by Xğ‘‹Xitalic_X. Exp. in the column of degree indicates that the complexity is exponential in the corresponding factor. Reach NE via Algorithm Sample Complexity kğ‘˜kitalic_k Xğ‘‹Xitalic_X RM XODO (Dinh et al., 2022) ğ’ª~â¢(k2â¢X3/Ïµ2)~ğ’ªsuperscriptğ‘˜2superscriptğ‘‹3superscriptitalic-Ïµ2\tilde{\mathcal{O}}(k^{2}X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 2 3 XDO (McAleer et al., 2021) ğ’ª~â¢(kâ¢|A|â¢X3/Ïµ2+4kâ¢|A|â¢X3/Ïµ02)~ğ’ªğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2superscript4ğ‘˜ğ´superscriptğ‘‹3superscriptsubscriptitalic-Ïµ02\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2}+4^{k}|A|X^{3}/\epsilon_{0}^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) Exp. 3 PDO ğ’ª~â¢(kâ¢|A|â¢X3/Ïµ2)~ğ’ªğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 AdaDO ğ’ª~â¢(kâ¢|A|â¢X3/Ïµ2)~ğ’ªğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 SRM SPDO ğ’ª~â¢(kâ¢|A|â¢X3/Ïµ2)~ğ’ªğ‘˜ğ´superscriptğ‘‹3superscriptitalic-Ïµ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 SADO ğ’ª~â¢(kâ¢|A|â¢X2/Ïµ2)~ğ’ªğ‘˜ğ´superscriptğ‘‹2superscriptitalic-Ïµ2\tilde{\mathcal{O}}(k|A|X^{2}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 2 Empirical results in representative poker games and board game Sequential Blotto have demonstrated that AdaDO significantly outperforms XDO and can converge to exploitability solutions over 10101010 times less exploitable than the strong regret minimization baseline, Linear Counterfactual Regret Minimization. Notably, we observe a substantial improvement of in AdaDO with the warm starting technique, especially in a variant of Kuhn Poker, which enables DO to converge to up to 108superscript10810^{8}10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT times less exploitable solutions than DO without warm starting. In the setting of reaching NE via stochastic regret minimization, the instances of Stochastic RMDO can also generate a significantly less exploitable strategy compared to MCCFR. These results validate that AdaDO establishes a new state-of-the-art in EFG solving and provides a promising direction for addressing complex multi-agent decision-making tasks."
https://arxiv.org/html/2411.00825v1,Transparent Tagging for Strategic Social Nudges on User-Generated Misinformation,"Social network platforms (SNP), such as X and TikTok, rely heavily on user-generated content to attract users and advertisers, yet they have limited control over content provision, which leads to the proliferation of misinformation across platforms. As countermeasures, SNPs have implemented various policies, such as tweet labeling, to notify users about potentially misleading information, influencing usersâ€™ responses, either favorably or unfavorably, to the tagged contents. The population-level response creates a social nudge to the content provider that encourages it to supply more authentic content without exerting direct control over the provider. Yet, when designing such tagging policies to leverage social nudges, SNP must be cautious about the potential misdetection of misinformation (wrongly detecting factual content as misinformation and vice versa), which impairs its credibility to generic users and, hence, its ability to create social nudges. This work establishes a Bayesian persuaded branching process to study SNPâ€™s tagging policy design under misdetection. Misinformation circulation is modeled by a multi-type branching process, where users are persuaded through tagging to give positive and negative comments that influence the spread of misinformation. When translated into posterior belief space, the SNPâ€™s problem is reduced to an equality-constrained convex optimization, the optimal condition of which is given by the Lagrangian characterization. The key finding is that SNPâ€™s optimal policy is simply transparent tagging, i.e., revealing the contentâ€™s authenticity to the user, albeit midsection, which nudges the provider not to generate misinformation. We corroborate our findings using numerical simulations.","Social network platforms (SNP), such as X and TikTok, where users create and consume content, play an increasingly important role in society. These platforms rely heavily on user-generated content (UGC) to engage and retain users to maintain high-level daily activity. Since users who generate original content(â€œcontent providersâ€) are not paid workers, platforms have limited control over the UGC, including misinformation. User-generated misinformation has become a growing concern on SNPs, as false information can spread rapidly and have significant consequences [1]. For instance, false stories about candidates were shared widely through SNPs during the 2016 US presidential election; misinformation about the virus, mask-wearing policies, and vaccine concerns spread through social networks during the COVID-19 pandemic. To address this issue, SNPs have implemented policies such as labeling, tagging, or notifying to alert users to potentially false or misleading information [2, 3]. Figure 1: An illustration of the proposed persuasion model, where the misinformation distribution Î¸â¢(Î»)ğœƒğœ†\theta(\lambda)italic_Î¸ ( italic_Î» ) is affected by the content provider and remains unknown to the user. The SNPâ€™s misdetection of the underlying content is modeled by dğ‘‘ditalic_d. Previous studies have shown that these policies effectively (to some extent) curb the spread of misinformation [4]. One of the key reasons is that these platforms feature intensive social interactions among users, which can be leveraged to create social nudges in stimulating UGC supply [5]. For example, a post tagged as misleading will inflict usersâ€™ negative comments. After circulation on social networks, the population response to the post creates pressure on the content provider that discourages it from generating misinformation. This work proposes a persuasion game model to provide theoretical underpinnings for the SNPâ€™s tagging design, aiming to harness the power of social nudges to reduce user-generated misinformation. As illustrated in Figure 1, the strategic interactions among the SNP, the content provider, and the user unfold as below. The SNP designs a tagging policy whose realized tags indicate the content authenticity of an arbitrary post returned by a detection device. Of particular note is that the detection device, usually empowered by artificial intelligence methods [6, 7, 8], is often imperfect and may misclassify the postâ€™s authenticity. Such a policy does not directly control the provider or user but influences othersâ€™ behaviors through information provision. Hence, this tagging policy is referred to as the information structure [9]. Fully aware of this policy, the content provider exerts a private effort (unobservable to the SNP or user) in creating the content, assuming that the more effort exerted, the more authentic the content is. Finally, the user observes the tagging policy and the realized tags and then decides their views and comments that influence the online circulation modeled by a multi-type branching process. The proposed model differs from the seminal Bayesian persuasion game [10] in that the user cannot directly observe the prior distribution. Consequently, the user must form a conjecture about the content providerâ€™s behavior to update their beliefs. This conjecture must be consistent with the providerâ€™s equilibrium behavior, which leads to the concept of perfect Bayesian equilibrium (PBE) as the natural solution concept for our game. In our previous work [11], we addressed a special case where there was no detection error, allowing the SNP to identify misinformation in posts perfectly. However, in practical scenarios, detection errors are inevitable. In this work, the SNPâ€™s design problem considers such misdetection, which leads to the SNPâ€™s misperception of the game state that impairs taggingâ€™s credibility and effectiveness in fostering social nudges. Our key finding is that transparent tagging, where the SNP honestly discloses the detection outcome to the content provider and user, is most effective in combating misinformation generation and circulation. Although the SNP may not have direct control over content generation, it can nudge user perceptions through tagging. The collective behaviors of users, under these perceptions, determine the content providerâ€™s reputation, effectively making users the SNPâ€™s proxy in terms of incentive provision, encouraging the provider to exert the best effort in reducing misinformation generation. Our contributions are summarized below. â€¢ We propose a three-player Bayesian persuasion game that studies the SNPâ€™s tagging policy under the presence of misdetection and the content providerâ€™s intention to uphold its reputation, with misinformation circulation among users modeled as a multi-type branching process; â€¢ We identify playersâ€™ strategies under perfect Bayesian equilibrium by transforming the problem into the posterior belief space, reducing it to an equality-constrained convex optimization problem; â€¢ We characterize the optimal conditions using a Lagrangian approach, demonstrating that the SNPâ€™s optimal policy is transparent tagging despite detection errors, incentivizing the content provider to exert maximum implementable effort."
https://arxiv.org/html/2411.01794v2,Revisiting Game-Theoretic Control in Socio-Technical Networks: Emerging Design Frameworks and Contemporary Applications,"Socio-technical networks represent emerging cyber-physical infrastructures that are tightly interwoven with human networks. The coupling between human and technical networks presents significant challenges in managing, controlling, and securing these complex, interdependent systems. This paper investigates game-theoretic frameworks for the design and control of socio-technical networks, with a focus on critical applications such as misinformation management, infrastructure optimization, and resilience in socio-cyber-physical systems (SCPS). Core methodologies, including Stackelberg games, mechanism design, and dynamic game theory, are examined as powerful tools for modeling interactions in hierarchical, multi-agent environments. Key challenges addressed include mitigating human-driven vulnerabilities, managing large-scale system dynamics, and countering adversarial threats. By bridging individual agent behaviors with overarching system goals, this work illustrates how the integration of game theory and control theory can lead to robust, resilient, and adaptive socio-technical networks. This paper highlights the potential of these frameworks to dynamically align decentralized agent actions with system-wide objectives of stability, security, and efficiency.","Game theory addresses strategic interactions among decision-makers, often referred to as players or agents [1]. Each player has a distinct objective functionâ€”either a utility to maximize or a cost to minimizeâ€”which encapsulates their preferences across available alternatives. However, these preferences are interdependent, shaped by the choices made by other players, creating a need for game theory as a framework to model these strategic dynamics [2]. In non-cooperative games, where players act independently, achieving an equilibrium is a central focus. The Nash equilibrium, a key concept developed by John Nash, represents a stable state where no player can unilaterally adjust their strategy for a better outcome [3]. This equilibrium concept enables analysts to identify stable states in competitive environments. When hierarchical decision-making exists, other solution concepts like the Stackelberg equilibrium are more suitable, especially in scenarios where leaders act first and followers respond. This framework is particularly applicable in control scenarios where independent agents must coordinate within shared constraints [4]. The formalization of game theory is largely attributed to John von Neumann and Oskar Morgensternâ€™s Theory of Games and Economic Behavior [1], a pioneering text that established the fieldâ€™s foundations and generated broad, interdisciplinary interest. Nashâ€™s work on equilibrium expanded the field significantly, enabling stable solutions for non-cooperative games [3]. Additional advancements by Richard Bellman, who introduced dynamic programming [5], and Rufus Isaacs, known for differential games [6], extended game theory to dynamic and multi-stage decision-making, integrating it more deeply into control and optimization contexts. A defining moment for game theory was its integration into optimal control and decision processes, especially through the efforts of researchers at the RAND Corporation, including Bellman, Nash, and Isaacs. At RAND, these theorists developed models intersecting military strategy, economics, and control systems, catalyzing breakthroughs in multi-agent decision-making processes. Isaacsâ€™ differential games, for instance, established a framework for continuous-time strategic interactionsâ€™ foundational for adversarial scenarios like pursuit-evasion games [6]. This interdisciplinary evolution of game theory alongside advances in optimal control provided the groundwork for its application in modern networked systems, where it remains central to understanding strategic interdependencies and designing resilient control mechanisms. I-A Game Theory and Socio-Technical Systems Todayâ€™s interconnected systemsâ€”ranging from telecommunications and social networks to critical infrastructureâ€”face unique challenges as they are populated by autonomous agents, each pursuing individual objectives, but interconnected through their actions and information exchanges. Game theory is a critical tool in such environments, especially where decentralized decision-making is needed. In multi-agent systems, every agentâ€™s actions affect the networkâ€™s overall state, often creating complex dynamics that are difficult to predict and control. Game-theoretic analysis equips researchers and designers with the methods to anticipate these interactions, predict system behavior, and develop strategies that enhance stability, efficiency, and resilience across the network [7]. Moreover, these networks are often socio-technical systems, where human behavior directly influences their performance, efficiency, and resilience. Human decisions and interactions shape the functioning of many networked systems, such as transportation, energy grids, and public health infrastructure [8, 9, 10]. For example, transportation networks must account for the flexible and sometimes unpredictable nature of human routing decisions. In such settings, infrastructure planning cannot be isolated from human behavior. The well-known Braess paradox illustrates that adding roads to a network may lead to increased congestion, as drivers individually optimize their routes, often at the expense of overall efficiency [11]. Game-theoretic models help planners anticipate these outcomes, enabling the design of transportation networks that mitigate unintended consequences and improve flow [12]. In smart energy systems, where energy prosumers (both consumers and producers) decide when to buy or sell energy, individual behaviors impact the gridâ€™s supply-demand balance. To maintain grid stability, game-theoretic mechanisms can incentivize prosumers to make decisions that align personal economic interests with the systemâ€™s operational needs [13]. These control mechanisms foster a resilient and efficient energy network by balancing incentives for prosumers in ways that enhance resource allocation and minimize the risk of outages [14]. Figure 1 illustrates the nature of the control of socio-technical systems. The technical system is coupled with the human networks, and the designer can influence the coupled system through different control paradigms, including information, incentives, and network structures. Public health further exemplifies the socio-technical nature of modern systems, as seen during the COVID-19 pandemic. Individual choices, such as decisions about vaccination, mask-wearing, and social interactions, had substantial effects on the spread of the virus [15, 16, 17, 18]. In such interconnected populations, the communityâ€™s health state depends on the aggregation of personal decisions. Game-theoretic design principles offer powerful tools for crafting behavioral incentives and nudges that guide individuals toward compliance with public health measures [19]. By structuring these incentives effectively, game theory helps manage collective health outcomes, particularly during health crises, and underscores the importance of considering socio-technical dynamics in system design. By integrating game-theoretic frameworks into socio-technical systems, designers gain the ability to understand and anticipate human-driven impacts on system dynamics. Game theory provides structured approaches for designing incentives, controlling information flows, and implementing adaptive mechanisms that foster desirable behaviors. These strategies are essential for ensuring that the interactions of autonomous agentsâ€”whether they are people, machines, or a mix of bothâ€”contribute positively to network performance, resilience, and societal benefit [20]. Fig. 1: A Game-Theoretic Control Paradigm for Socio-Technical Systems: Socio-technical networks are composed of interconnected human and technical networks. Human agents interact both with one another and with technical infrastructures, including power grids, transportation systems, and cyber networks. The control of these networks can be achieved through strategic designs in information flow, network structure, and incentive mechanisms. Information design guides how agents access and process data, while network design shapes the connectivity and interaction pathways within the system. Incentive design, on the other hand, motivates desired behaviors by aligning agent actions with system-wide objectives, ensuring that human and technical interactions are coordinated to achieve resilience, efficiency, and security across the socio-technical network. I-B Game-Theoretic Control Design Game theory offers not only a framework for modeling, performance evaluation, and risk assessment but also a robust design methodology for creating decentralized agents. A key strength of game-theoretic design lies in its decentralized approach, which provides a foundational structure for building and managing complex, large-scale networks [21, 22]. In these decentralized networks, individual agents act based on personal incentives, often with limited or no knowledge of the networkâ€™s overall state. This bottom-up approach mirrors real-world systems, where centralized control may be impractical or ineffective. For human agents, game-theoretic design allows for behavior modification to align with system goals. For machine agents, it enables programming diverse agents to follow a coordinated protocol. These agents, whether human or machine, can work collectively to achieve desired outcomes associated with metrics such as efficiency, robustness, resilience, and security. By embedding game-theoretic strategies, designers can anticipate and guide agent interactions, facilitating cooperative behavior even in environments with limited information sharing or direct coordination. Figure 2 presents an agent-based perspective on socio-technical systems illustrated in Figure 1. Within this framework, human agents within human networks engage with machine agents in technical networks, while also interacting with other agents in their respective networks. Each human agent operates as a coupled system, integrating individual belief processes with action processes. Similarly, each machine agent functions as a coupled system, linking control processes with physical processes. Designers can influence various agents through targeted levers across different system components, aiming to optimize system-level performance. The design of agents is closely linked to control theory, specifically the design of controllers that manage dynamical systems to achieve desirable properties like stability and optimality. While control theory traditionally focuses on governing centralized control systems, game-theoretic agent design introduces a complementary approach that is particularly suited to large-scale socio-technical networks. In these networks, the goal is often to achieve outcomes such as optimal social welfare or collective efficiency, which align with the objectives of control theory. Game-theoretic design operates from the bottom up, creating decentralized agents that make decisions based on local information and personal incentives. This bottom-up approach enables scalability, making it ideal for vast, complex networks typical of socio-technical systems, where centralized control may be impractical. By designing agents to act independently yet cohesively, game-theoretic design facilitates adaptable, resilient, and efficient network behaviors, even in highly dynamic and large-scale environments. Modeling of the Agents For the socio-technical system illustrated in Figure 1, game theory can model diverse interactions within socio-technical networks from the ground up. These interactions can be categorized into several key types. First, interactions occur between agents within the same network, such as those between human agents in human networks or machine agents within technical networks. These intra-network interactions capture the dynamics among similar types of agents and can reveal emergent patterns within isolated sub-systems. Second, interactions take place between agents across different networks. For instance, human agents in the socio-network interact with machine agents in the technical network, bridging the socio-technical divide. These cross-network interactions are crucial for understanding how human and machine agents jointly influence system outcomes. A third category involves interactions with adversarial agents. Adversarial agents are specifically introduced to evaluate the security, robustness, and resilience of the network. These adversarial entities may be real participants within the network or artificial agents created to assess risk. By engaging human or technical agents with adversaries designed with specific intentions and capabilities, we can measure local security and resilience properties more accurately. Finally, interactions occur between agents and a designer. Here, a designer exerts influence over agents in a controlled way to guide their behavior toward achieving network-wide objectives. This interaction serves as a means of designing and controlling agent actions within the network to align with broader system goals. Each of these interactions takes on distinct forms, and the various games representing them are ultimately composed into a larger framework, referred to as a â€œmeta-game.â€ This meta-game governs the design and control of the entire socio-technical network, enabling a holistic approach to understanding and managing complex interactions within the system. Control of the Agents Agents can be controlled in various ways, depending on their nature and function, and these controls can be categorized into three primary paradigms. The first is physical control, which involves managing physical attributes like speed, direction, and other measurable quantities, as seen in robotic agents [23]. The second is cyber control, where the focus is on controlling the information received by agents, such as news broadcasts for human agents or sensor data for autonomous vehicles. The third paradigm is human control, where the objective is to influence perceptions and incentives to guide human behavior in desired directions. Across these paradigms, network structure and information design are fundamental. How agents communicate, physically interact, and gather information from observations and perceptions are critical components of effective system design [24]. A key connection between control theory and game-theoretic design emerges through the use of dynamic game frameworks to model and guide agent behavior in evolving environments [25, 26]. In dynamic games [27], agents interact over time within changing environments and face uncertainties. Agent behaviors are characterized by adaptive feedback loops, where decisions continuously adjust based on environmental conditions. Information flow becomes particularly crucial in these scenarios, as agents make real-time decisions with limited or noisy information about othersâ€™ actions. The flow and structure of information directly shape agentsâ€™ strategic choices, influencing the overall systemâ€™s resilience and robustness. Bridging control and game-theoretic design achieves a unified approach to achieving individual dynamic agents and ensuring the stability and efficiency of the entire system. On the individual level, agents must operate effectively within their local environments, maintaining stability in response to changing conditions and achieving their own performance goals. At the system level, however, the design must prioritize overall stability, resilience, and system-wide metrics [28, 29]. Fig. 2: Illustration of Interaction Between a Social Agent in the Human Network and a Machine Agent in the Technical Network: A social agent interacts with the human network and a machine agent within the technical network. Each agent is also connected to other agents within its own network. The machine agent provides specific services to the social agent, while the social agent impacts the machine agent and its network through behaviors such as consumption, usage, or demand patterns. The designer can strategically influence both networks using tools like information design and incentive structures. Information design shapes the structure of information between agents, while incentive design aligns agent actions with broader system goals, creating a coordinated and adaptive socio-technical system. I-C The Underlying Philosophy of Agent-Based Game-Theoretic Design in Socio-Technical Networks The agent-based game-theoretic design of socio-technical networks embodies a dual philosophy [30, 31]: reductionistic design and holistic control. On one side, game-theoretic design takes a reductionist approach, where the whole system is decomposed into modular components or agents. By breaking down complex, large-scale networks into manageable agents, this approach allows designers to handle intricate interdependencies and diverse functions within the system. On the other side, the design aims to achieve high-level system objectivesâ€”such as efficiency, security, and resilienceâ€”which are often prescribed at a system-wide level. The reductionist design of individual agents must, therefore, be aligned with these holistic goals, ensuring coherence between component-level actions and overall system performance. Establishing such coherence is fundamental to the principles guiding game-theoretic design in socio-technical networks. Achieving coherence between agent-level design and system-level objectives requires a framework to bridge them. Designers need to assess how individual agent behaviors impact system-wide metrics, making it essential to monitor the alignment of component actions with system goals. Game-theoretic analysis provides this bridge by offering a structured framework to predict system-level behaviors through equilibrium concepts. The equilibrium, depending on the application and structure of the network, enables designers to forecast the outcomes of individual actions within the larger system. Various solution concepts within game theory offer tools to assess and develop performance metrics. For instance, in a security context, equilibrium analysis between a defender agent and an attacker can yield risk metrics, while in robustness analysis, saddle-point equilibria between the system and external disturbances inform robustness metrics. Game theory serves as a bridge that enables reductionist designers to account for the holistic impact of individual agent designs on the systemâ€™s objectives. Meanwhile, holistic system designers must shape the architecture, including hierarchies, network structures, and resource allocations, to ensure that agent-level designs contribute to the systemâ€™s high-level goals. Frameworks such as Stackelberg games, equilibrium-constrained optimization, and mechanism design theory play a central role in achieving this alignment. Holistic designers must understand how agents respond to these structures at equilibrium and ensure that top-down control strategies foster the intended system-wide behavior. Ensuring coherence becomes more challenging under conditions of uncertainty, adaptive requirements, and emergent properties such as resilience and security. These complex requirements demand clear, quantifiable metrics to guide system and agent design. Despite these challenges, game theoryâ€”with its rich array of tools and methodologiesâ€”provides a means to develop advanced techniques that foster coherence in dynamic, complex systems. For instance, game-theoretic tools can incorporate learning and adaptation, enabling agent designs to evolve in response to an uncertain environment while staying aligned with system goals. This coherence between reductionism and holistic control, illustrated in Figure 3, is where game theory and control theory intersect, together forming the foundation for a new system design paradigm. Designing socio-technical networks requires this paradigm shift and the convergence between control and game theory to address the unique demands of these complex, interconnected systems. For example, in a smart grid, it is insufficient to simply control each subsystem, such as energy generation or distribution, in isolation. The system must account for the interplay between independent agents (e.g., consumers, generators, and grid operators) who each respond to incentives, environmental conditions, and their own objectives. By integrating game-theoretic strategies, designers can predict how these agents will behave collectively, while control theory enables the coordination of these actions to maintain grid stability, efficiency, and resilience. Fig. 3: The holistic control design must align consistently with the reductionist behaviors of individual agents. Game theory, inherently a reductionist approach, focuses on designing and analyzing individual agent behaviors, while control theory provides a holistic framework to achieve overarching system goals. Game-theoretic control offers a cohesive approach that bridges these two perspectives, integrating the detailed evaluation and synthesis tools of reductionist models with the coordination and control mechanisms of holistic design. This combined framework ensures that individual agent actions are aligned with the broader system objectives, creating a unified and adaptive socio-technical system. I-D Organization of the Letter This letter provides an overview of game-theoretic design approaches. In Section II, we explore foundational frameworks used in agent design, focusing on Stackelberg-type game frameworks and mechanism design theory, which has been widely applied to settings like auctions and market structures. Section III examines the challenges of designing socio-technical systems, addressing issues such as human behavioral dynamics, uncertainty quantification, and scalability. In Section IV, we present emerging paradigms in game-theoretic design, including mean-field design, learning-based design, population-based design, and adversarial design. These approaches are applied to critical areas such as misinformation management in social networks, resilience in industrial control systems, and congestion control in infrastructure networks. We close the letter with the concluding remarks of Section V."
https://arxiv.org/html/2411.01711v1,Nash equilibria in four-strategy quantum game extensions of the Prisonerâ€™s Dilemma,"This paper investigates Nash equilibria in pure strategies for quantum approach to the Prisonerâ€™s Dilemma. The quantization process involves extending the classical game by introducing two additional unitary strategies. We consider five classes of such quantum games, which remain invariant under isomorphic transformations of the classical game. For each class, we identify and analyze all possible Nash equilibria. Our results reveal the complexity and diversity of strategic behavior in the quantum setting, providing new insights into the dynamics of classical decision-making dilemmas. In the case of the standard Prisonerâ€™s Dilemma, the resulting Nash equilibria of quantum extensions are found to be closer to Pareto optimal solutions than those of the classical equilibrium.Keywords: game isomorphism, Eisert-Wilkens-Lewenstein scheme, quantum extended games, Nash equilibrium, Prisonerâ€™s Dilemma","A principal objective of quantum game theory is to establish a methodology for transforming classical game theory problems into a quantum mechanical framework [1, 2, 3, 4]. Subsequently, the characteristics of the resulting game are analysed using techniques from classical game theory [5, 6, 7, 8], or the quantum game is examined in terms of concepts from quantum computing [9, 10, 11, 12]. Similar to classical game theory, the fundamental problem explored in quantum game theory is the problem of finding rational strategy profiles and answering the question of whether the quantum extension of the game affects the final outcome [13, 14, 15, 16, 17]. In this context, the Nash equilibrium (NE) is a widely used solution concept [18] that is considered a necessary condition for a given strategy profile to be considered rational. A NE is defined as a strategy profile where no player can improve their payoff by changing their own strategy, assuming that all other playersâ€™ strategies remain unchanged. This solution concept is applicable in both classical and quantum games due to the way it is formulated. The Prisonerâ€™s Dilemma (PD) is a classical problem in game theory, illustrating the conflict between individual rationality and collective welfare [19]. Traditionally, the PD game is defined for two players, each having two strategies: cooperate or defect. The standard PD game has a single NE where both players choose to defect, leading to a suboptimal outcome for both. However, the introduction of quantum strategies offers new possibilities for altering this equilibrium structure, potentially allowing for outcomes that are more beneficial to all players involved [1, 20, 21]. In our previous works, we explored the quantum extensions of classical games using the Eisert-Wilkens-Lewenstein (EWL) scheme, which introduces additional unitary strategies alongside the classical strategies [22, 23]. The quantum extensions have been classified into a number of distinct categories, based on the characteristics of the admissible quantum strategies that preserve invariance with respect to isomorphic transformations of the classical game. Our focus was primarily on identifying the conditions under which these quantum games preserve the structural characteristics of the original game while extending the strategic landscape available to the players. The main goal of the present paper is to examine these extensions in more detail by identifying every NE in the pure strategy profiles of the quantum-enhanced PD. By examining the PD in its most generalized form, considering any admissible set of payoffs, the study seeks to understand under what conditions NE can be achieved for each class of extension. Specifically, the work investigates the constraints that the payoff matrix must satisfy for a given pure strategy profile to be considered a NE across all identified classes of quantum extensions. Through this comprehensive analysis, we provide a detailed characterization of strategy profiles and their corresponding NE, thereby extending the understanding of quantum strategiesâ€™ impact on traditional game-theoretical problems. The paper demonstrates that the NE obtained are more closely aligned with Pareto-optimal solutions than the classical PD. Nevertheless, the class of extensions under consideration does not encompass fully cooperative equilibria. One example of this is the so-called ""magic strategy"" [1], which, however, does not satisfy the condition of independence from isomorphic transformations of the classical game [22], which is a necessary condition for the extension to be unambiguous. This contribution not only enhances the theoretical framework of quantum game theory but also has potential applications in fields such as quantum computing and strategic decision-making [6, 24], where understanding complex interactive dynamics is crucial. The work is divided into 5 parts. In the second section we briefly define the key concepts of PD, NE, the EWL quantum game scheme, and prove that positive affine transformations of the payoffs of the classical game do not affect the preference relations of the quantum game. In the third section, we recall five classes of quantum extensions of the classical 2Ã—2222\times 22 Ã— 2 game. In these extensions, quantum players have two additional unitary strategies in addition to their initial classical strategies. The extensions are invariant to isomorphic transformations of the classical game [23]. Furthermore, we demonstrate the symmetry of quantum extensions of the symmetric game. In the fifth section, which is divided into five sub-sections, we analyse the existence of NE of successive classes of extensions. To do so, we examine each of 16 possible profiles of pure strategies. Where equilibria exist, we give the conditions that must be satisfied by the parameters of quantum strategies and PD payoffs."
https://arxiv.org/html/2411.01191v1,Prophet Secretary and Matching: the Significance of the Largest Item,"The prophet secretary problem is a combination of the prophet inequality and the secretary problem, where elements are drawn from known independent distributions and arrive in uniformly random order. In this work, we design 1) a 0.6880.6880.6880.688-competitive algorithm, that breaks the 0.6750.6750.6750.675 barrier of blind strategies (Correa, Saona, Ziliotto, 2021), and 2) a 0.6410.6410.6410.641-competitive algorithm for the prophet secretary matching problem, that breaks the 1âˆ’1/eâ‰ˆ0.63211ğ‘’0.6321-1/e\approx 0.6321 - 1 / italic_e â‰ˆ 0.632 barrier for the first time. Our second result also applies to the query-commit model of weighted stochastic matching and improves the state-of-the-art ratio (Derakhshan and Farhadi, 2023).","The study of prophet inequality dates back to the 1970s [31, 32] from optimal stopping theory. Consider nğ‘›nitalic_n items with independent random values arriving one by one in an adversarial order. The value distribution Fisubscriptğ¹ğ‘–F_{i}italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of each item iğ‘–iitalic_i is known upfront to the algorithm, but the realization of value viâˆ¼Fisimilar-tosubscriptğ‘£ğ‘–subscriptğ¹ğ‘–v_{i}\sim F_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT âˆ¼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is only revealed on the itemâ€™s arrival. After seeing the itemâ€™s identity iğ‘–iitalic_i and value visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the algorithm decides immediately whether to accept the item and collect its value; the algorithm can accept at most one item in this problem. The goal is to maximize the expected value of the accepted item and compete against the prophet, i.e., the expected maximum value ğ„â¡[maxiâ¡vi]ğ„subscriptğ‘–subscriptğ‘£ğ‘–\operatorname{\mathbf{E}}\mathchoice{\left[\max_{i}v_{i}\right]}{[\max_{i}v_{i% }]}{[\max_{i}v_{i}]}{[\max_{i}v_{i}]}bold_E [ roman_max start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ]. It is known that the optimal competitive ratio is 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG for this problem. A fundamental extension of the prophet inequality is prophet matching. Consider an underlying bipartite graph with edge weights drawn from known distributions. The vertices on one side are known upfront and those on the other side arrive online. On the arrival of an online vertex visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the weights of its incident edges are revealed and the algorithm decides whether to match visubscriptğ‘£ğ‘–v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and to which offline vertex. The classic prophet inequality is captured by this model with one offline vertex. Feldman, Gravin, and Lucier [19] gave a tight 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG competitive algorithm for the matching setting, and their result was further generalized to settings when all vertices arrive online [17]. In this work, we consider the secretary variants (a.k.a. the random order variants) of prophet inequality and prophet matching, i.e., the setting where the arrival order of items (resp. vertices) is uniformly at random. The study of prophet secretary was initiated by Esfandiari et al. [16], who designed a 1âˆ’1/eâ‰ˆ0.63211ğ‘’0.6321-1/e\approx 0.6321 - 1 / italic_e â‰ˆ 0.632 competitive algorithm and provided an upper bound of 0.750.750.750.75.111The competitive ratio of an algorithm is a number between [0,1]01[0,1][ 0 , 1 ]. A lower bound corresponds to an algorithm and an upper bound corresponds to an impossibility result. Since then, a sequence of follow-up works [3, 10, 25, 7, 23] have focused on closing the gap. The state-of-the-art lower and upper bounds are 0.6720.6720.6720.672 by Harb [25] and 0.7230.7230.7230.723 by Giambartolomei et al. [23] respectively. Less progress has been made on the prophet secretary matching problem. Ehsani et al. [15] gave a 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e competitive algorithm. Very recently, the 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e barrier was surpassed in two special cases: 1) the i.i.d. setting studied by Yan [40] and Qiu et al. [37]; and 2) the query-commit setting studied by Derakhshan and Farhadi [12]. Beating 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e for the general case of prophet secretary matching remains one of the most intriguing open questions to the online algorithms community. 1.1 Our Contributions Result for Prophet Secretary. We design a 0.6880.6880.6880.688 competitive algorithm for the prophet secretary problem. Besides the improvement over the state-of-the-art 0.6720.6720.6720.672 ratio, our result further surpasses the 0.6750.6750.6750.675 barrier of blind strategies [10], the family of algorithms that Correa et al. [10] and Harb [25] focused on. Blind strategies rely on only the distribution of the maximum value, but not the fine-grained distributional information of individual itemsâ€™ values. Intuitively, such fine-grained information must be crucial because the items are heterogeneous in the prophet secretary problem. However, it is technically challenging to incorporate such information to design and analyze item-dependent strategies: changing the strategy for one item would unavoidably affect the probability of accepting other items since we can accept only one of them. Technique: Activation-Based Algorithms. We introduce two ideas to address this difficulty. First, we change our point of view from designing acceptance probabilities to choosing activation rates. In general, an online algorithm is defined by the probability of accepting an item based on its identity iğ‘–iitalic_i, value vğ‘£vitalic_v, and the set of future items that will arrive later. Following the conventional wisdom, the current itemâ€™s arrival time tğ‘¡titalic_t is a good surrogate for aggregating information about exponentially many possible sets of future items over their random arrivals. Here, we interpret the random order as having each item arrive within a time horizon from 00 to 1111 uniformly at random. In short, algorithms are represented by the acceptance probabilities for item iğ‘–iitalic_i when it has value vğ‘£vitalic_v and arrives at time tğ‘¡titalic_t. However, it is difficult to analyze the algorithms based on this representation. By contrast, we will consider the activation rates aivâ¢(t)superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) for item iğ‘–iitalic_i when it has value vğ‘£vitalic_v and arrives at time tğ‘¡titalic_t, and the overall activation rates Aiâ¢(t)=ğ„vâˆ¼Fiâ¡[aivâ¢(t)]subscriptğ´ğ‘–ğ‘¡subscriptğ„similar-toğ‘£subscriptğ¹ğ‘–superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡A_{i}(t)=\operatorname{\mathbf{E}}_{v\sim F_{i}}\mathchoice{\left[a_{i}^{v}(t)% \right]}{[a_{i}^{v}(t)]}{[a_{i}^{v}(t)]}{[a_{i}^{v}(t)]}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_E start_POSTSUBSCRIPT italic_v âˆ¼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) ] of the item at time tğ‘¡titalic_t. We activate this item (and accept it if no item has been accepted yet) with probability: givâ¢(t)=aivâ¢(t)â‹…eâˆ’âˆ«0tAiâ¢(x)â¢dx.superscriptsubscriptğ‘”ğ‘–ğ‘£ğ‘¡â‹…superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡superscriptğ‘’superscriptsubscript0ğ‘¡subscriptğ´ğ‘–ğ‘¥differential-dğ‘¥g_{i}^{v}(t)=a_{i}^{v}(t)\cdot e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}~{}.italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) = italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) â‹… italic_e start_POSTSUPERSCRIPT - âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT . This new viewpoint offers two useful invariants. By definition, the probability that we activate item iğ‘–iitalic_i before time tğ‘¡titalic_t equals: âˆ«0tğ„vâˆ¼Fiâ¡[givâ¢(x)]â¢dx=1âˆ’eâˆ’âˆ«0tAiâ¢(x)â¢dx.superscriptsubscript0ğ‘¡subscriptğ„similar-toğ‘£subscriptğ¹ğ‘–superscriptsubscriptğ‘”ğ‘–ğ‘£ğ‘¥differential-dğ‘¥1superscriptğ‘’superscriptsubscript0ğ‘¡subscriptğ´ğ‘–ğ‘¥differential-dğ‘¥\int_{0}^{t}\operatorname{\mathbf{E}}_{v\sim F_{i}}\mathchoice{\left[g_{i}^{v}% (x)\right]}{[g_{i}^{v}(x)]}{[g_{i}^{v}(x)]}{[g_{i}^{v}(x)]}\mathrm{d}x~{}=~{}1% -e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}~{}.âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT bold_E start_POSTSUBSCRIPT italic_v âˆ¼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_x ) ] roman_d italic_x = 1 - italic_e start_POSTSUPERSCRIPT - âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT . Hence, the activation events effectively follow a Poisson process with rates Aiâ¢(t)subscriptğ´ğ‘–ğ‘¡A_{i}(t)italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ). Accordingly, the probability that we activate item iğ‘–iitalic_i with value vğ‘£vitalic_v and arrival time tğ‘¡titalic_t is: ğğ«â¡[vi=v]â‹…aivâ¢(t)â‹…eâˆ’âˆ«0tâˆ‘j=1nAjâ¢(x)â¢dâ¢xâŸ(â‹†)â¢dâ¢t.â‹…â‹…ğğ«subscriptğ‘£ğ‘–ğ‘£superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡subscriptâŸsuperscriptğ‘’superscriptsubscript0ğ‘¡superscriptsubscriptğ‘—1ğ‘›subscriptğ´ğ‘—ğ‘¥dğ‘¥â‹†dğ‘¡\operatorname{\mathbf{Pr}}\mathchoice{\left[v_{i}=v\right]}{[v_{i}=v]}{[v_{i}=% v]}{[v_{i}=v]}\cdot a_{i}^{v}(t)\cdot\underbrace{\vphantom{\big{|}}e^{-\int_{0% }^{t}\sum_{j=1}^{n}A_{j}(x)\mathrm{d}x}}_{(\star)}\mathrm{d}t~{}.bold_Pr [ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_v ] â‹… italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) â‹… underâŸ start_ARG italic_e start_POSTSUPERSCRIPT - âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT end_ARG start_POSTSUBSCRIPT ( â‹† ) end_POSTSUBSCRIPT roman_d italic_t . Note that the second part (â‹†)â‹†(\star)( â‹† ) is independent of the itemâ€™s identity iğ‘–iitalic_i and value vğ‘£vitalic_v. Therefore, we can simplify the dependence of different itemsâ€™ strategies by introducing an upper bound on âˆ‘j=1nAjâ¢(t)superscriptsubscriptğ‘—1ğ‘›subscriptğ´ğ‘—ğ‘¡\sum_{j=1}^{n}A_{j}(t)âˆ‘ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) for any time tğ‘¡titalic_t. Subject to this invariant, we can freely design the activation rates aivâ¢(t)superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) for each item iğ‘–iitalic_i and value vğ‘£vitalic_v to approximately match its contribution to the prophet benchmark. To further simplify the analysis, we focus on activation rates aivâ¢(t)superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) that are step functions that change their values at a common threshold time. We demonstrate the effectiveness of this viewpoint and such simple step activation rates in Section 2.4.2 by proving a 0.6940.6940.6940.694 competitive ratio when all items are small in the sense that each contributes only oâ¢(1)ğ‘œ1o(1)italic_o ( 1 ) to the prophet benchmark. Technique: Significance of the Largest Item. To further handle the general case of prophet secretary, we will focus on the item i0subscriptğ‘–0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT with the largest probability of being selected by the prophet. This is partly inspired by the existing hard instances (e.g., [10, 7, 23]), all of which involve one large item and many small items. The significance of the largest item is twofold: 1) we need to design a special strategy for it beyond the step-function activation rates, and 2) its characteristics provide sufficient information for selecting the invariants for the other itemsâ€™ activation rates. Why do we need a special strategy for this largest item? Consider the extreme case when it is the only item that matters. Intuitively, we would like to select it with certainty on its arrival. However, we cannot do that using the step-function activation rates. Within a time interval where the activation rates aivâ¢(t)superscriptsubscriptğ‘ğ‘–ğ‘£ğ‘¡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) remain a constant, the eâˆ’âˆ«0tAiâ¢(x)â¢dxsuperscriptğ‘’superscriptsubscript0ğ‘¡subscriptğ´ğ‘–ğ‘¥differential-dğ‘¥e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}italic_e start_POSTSUPERSCRIPT - âˆ« start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT term decreases the activation probability over time. This decrease is mild for smaller items, but could be substantial for the largest item. Remarkably, this seemingly trivial instance plays an important role of establishing the 0.6750.6750.6750.675 barrier for blind strategies [10]. Motivated by this extreme case, we let the largest itemâ€™s activation probability rather than its activation rate be piece-wise constant. While it is difficult to analyze algorithms based on the representation by activation/acceptance probabilities in general, we show that it is manageable to do that for just one largest item. This special treatment of just one largest item is sufficient for breaking the 0.6750.6750.6750.675 barrier. We will consider two characteristics of this largest item: its probability of being selected by the prophet, i.e., x0=ğğ«â¡[vi0=maxjâ¡vj]subscriptğ‘¥0ğğ«subscriptğ‘£subscriptğ‘–0subscriptğ‘—subscriptğ‘£ğ‘—x_{0}=\operatorname{\mathbf{Pr}}\mathchoice{\left[v_{i_{0}}=\max_{j}v_{j}% \right]}{[v_{i_{0}}=\max_{j}v_{j}]}{[v_{i_{0}}=\max_{j}v_{j}]}{[v_{i_{0}}=\max% _{j}v_{j}]}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = bold_Pr [ italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_max start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ], and a quantity h0subscriptâ„0h_{0}italic_h start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT that measures the extent to which item i0subscriptğ‘–0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT would be selected by the prophet with probability more than half, over the randomness of the other itemsâ€™ values. Based on just x0subscriptğ‘¥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and h0subscriptâ„0h_{0}italic_h start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, we will choose the (1) invariants âˆ‘jâ‰ i0Ajâ¢(t)subscriptğ‘—subscriptğ‘–0subscriptğ´ğ‘—ğ‘¡\sum_{j\neq i_{0}}A_{j}(t)âˆ‘ start_POSTSUBSCRIPT italic_j â‰  italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) for the activation rates of other items, (2) the shared threshold time for the step-function activation rates of other items, and (3) the three-stage step-function activation probabilities of the largest item i0subscriptğ‘–0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. It is surprising that these two characteristics of the largest item alone are sufficient for choosing all important invariants for our algorithm and analysis. Result for Prophet Secretary Matching. We design a 0.6410.6410.6410.641-competitive algorithm for the prophet secretary matching problem, breaking the 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e barrier for the first time. As a corollary of this result, we also improve the state-of-the-art ratio of the query-commit setting from 0.6330.6330.6330.633 [12] to 0.6410.6410.6410.641 through a reduction [22, 11] from the query-commit model to the secretary model. Summary of Techniques for Prophet Secretary Matching. We start by extending the activation-based framework to matching. First, let us consider a simple strategy: upon the arrival of an online vertex, assign it to an offline vertex with probability proportional to how likely the prophet would match them. We remark that the assignment is independent of the arrival of earlier vertices and their matching results. Then, from each offline vertexâ€™s viewpoint, it may treat the online vertices (more precisely, the corresponding edges) as online items in the prophet secretary problem, treating those not assigned to it as having zero values. However, the online stochastic matching literature suggests that we should not naÃ¯vely follow this approach and apply the two-stage step-function activation rates from prophet secretary, or we would miss the opportunity of exploiting second-chance (re-)assignments (a.k.a. the power of two choices). If an offline vertex is already matched, we should no longer assign online vertices to it, but instead redirect the opportunities to other unmatched offline vertices. Hence, we introduce a third stage into the activation-based algorithm, which has the same activation rates as the second stage, but takes into account the assignments redirected from the other offline vertices. This may be viewed as reinterpreting the three-stage algorithm by Yan [40] for the i.i.d. special case within the activation-based framework. By doing so, we achieve the same 0.6450.6450.6450.645 competitive ratio but more generally for all non-i.i.d. instances in which all edges are small, i.e., when each edge contributes only oâ¢(1)ğ‘œ1o(1)italic_o ( 1 ) to the prophet benchmark. On the other hand, the worst-case competitive ratio of this approach degenerates to 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e if there is a large edge adjacent to every offline vertex. To complement this scenario, we introduce a variant of the random order contention resolution scheme (RCRS) algorithm for matching [33, 21]. This may be viewed under the activation-based framework as follows. For each offline vertex uğ‘¢uitalic_u and its largest edge (u,v)ğ‘¢ğ‘£(u,v)( italic_u , italic_v ), let its adjacent edges other than (u,v)ğ‘¢ğ‘£(u,v)( italic_u , italic_v ) have constant activation rates; let edge (u,v)ğ‘¢ğ‘£(u,v)( italic_u , italic_v )â€™s activation probability be a 00-1111 step-function. This is consistent with our approach for the prophet secretary problem, but the design of activation rates and probabilities is simpler due to the complications in the analysis of the more general matching problem, and the fact that we only need to beat the 1âˆ’1e11ğ‘’1-\frac{1}{e}1 - divide start_ARG 1 end_ARG start_ARG italic_e end_ARG barrier in this case. We show that a hybrid algorithm that randomizes over the above two approaches achieves the stated 0.6410.6410.6410.641 competitive ratio. 1.2 Related Works DÃ¼tting et al. [14] studied the computational complexity of the optimal online algorithm for prophet secretary and gave a PTAS, though it does not imply any competitive ratio of the optimal online algorithm. Abolhassani et al. [1] and Liu et al. [34] studied the prophet secretary problem under small-item assumptions. They proved that if either 1) every distribution appears sufficiently many times [1, 34] or 2) every distribution has only a negligible probability of being non-zero [34], there exists a 0.7450.7450.7450.745-competitive algorithm, matching the optimal competitive ratio as in the i.i.d. setting. The order-selection prophet inequality lies between the i.i.d. setting and the secretary setting. In this variant, the algorithm is given the extra power of selecting the arrival order of the items. This is motivated by the application of prophet inequalities to sequential posted pricing mechanisms, and has been studied by [8, 5, 36, 7]. The current state-of-the-art competitive ratio is 0.7250.7250.7250.725 by Bubna and Chiplunkar [7]. Besides matching, the prophet inequality has also been generalized to other combinatorial settings, including matroids [30], combinatorial auctions [19, 13], and general downward-closed constraints [38]. Ehsani et al. [15] also studied the prophet secretary problem under matroid constraints and achieved a competitive ratio of 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e. Beating this ratio for general matroid constraints remains an important open question. Finally, the unweighted and vertex-weighted online stochastic matching problems have attracted a lot of attention in the online algorithms community [18, 4, 24, 35, 28, 6, 27, 39]. Most of these works assumed i.i.d. arrivals of online vertices, in order to surpass the optimal 1âˆ’1/e11ğ‘’1-1/e1 - 1 / italic_e competitive ratio of online (vertex-weighted) bipartite matching [29, 2]."
https://arxiv.org/html/2411.00388v1,Towards Data Valuation via Asymmetric Data Shapley,"As data emerges as a vital driver of technological and economic advancements, a key challenge is accurately quantifying its value in algorithmic decision-making. The Shapley value, a well-established concept from cooperative game theory, has been widely adopted to assess the contribution of individual data sources in supervised machine learning. However, its symmetry axiom assumes all players in the cooperative game are homogeneous, which overlooks the complex structures and dependencies present in real-world datasets. To address this limitation, we extend the traditional data Shapley framework to asymmetric data Shapley, making it flexible enough to incorporate inherent structures within the datasets for structure-aware data valuation. We also introduce an efficient kğ‘˜kitalic_k-nearest neighbor-based algorithm for its exact computation. We demonstrate the practical applicability of our framework across various machine learning tasks and data market contexts. The code is available at: https://github.com/xzheng01/Asymmetric-Data-Shapley.","Data valuation, which measures the contribution of individual data source on machine learning (ML) model performance, plays a crucial role in improving algorithmic transparency and creating incentive mechanisms for data sharing and monetization (Liu et al., 2023). Its importance is particularly evident in sectors like healthcare and finance, where explainable ML is increasingly being adopted for high-stake decision-making (Sahoh and Choksuriwong, 2023). The recent rise of data marketplaces further highlights the need for accurate data valuation (Ghorbani and Zou, 2019; Jia et al., 2019a). By integrating diverse data sources, these marketplaces enhance ML tasks and unlock significant business values (Agarwal et al., 2019). Fair compensation for data creators based on the value of their data is crucial in such contexts, making the equitable valuation of data a key issue (Altman, 2023). Data Shapley has recently gained widespread recognition for quantifying the contribution of individual data points to ML models (Ghorbani and Zou, 2019; Jia et al., 2019b). It is uniquely defined by four axioms (see Axiom 2.1-2.4 in Section 2). However, its symmetry axiom evaluates all data points equally, based solely on their content and influence on model performance, overlooking any inherent structures that exist in real-world datasets. This can lead to misleading and counterintuitive valuations in certain situations. We will further explore these counterintuitive outcomes in Section 3. To underscore the importance of incorporating the inherent structures within datasets into data valuation, we present the following examples. Example 1.1 (Valuation of Augmented Data). Data augmentation techniques expand the original training dataset to mitigate overfitting and improve performance (Shorten and Khoshgoftaar, 2019). However, since augmented data is generated from the original dataset through minor modifications, it often carries redundant information already present in the original dataset. Therefore, it is essential to assess the incremental value each augmented point contributes rather than focusing solely on its overall content. So how can we quantify the additional value each augmented data point brings to the original training set? Example 1.2 (Valuation of Sequential Data). Many modern ML applications involve data streams, where data instances arrive sequentially, one at a time (Yasumoto et al., 2016). The traditional data Shapley method treats all training data points as homogeneous players, disregarding the chronological dependencies between these points in a stream. So how can we incorporate the chronological order to quantify the incremental value of each newly arrived data point in a stream, given all previously arrived data? Example 1.3 (Fair Allocation among Dependent Entities in Data Marketplace). Traditional Shapley-based methods assume a simple market where multiple data creators fully own the training dataset (Jia et al., 2019a). However, these methods encounter challenges when data ownership is distributed across different, interdependent entities. For instance, consider a scenario where multiple data creators own the raw data, and a third-party data packager aggregates, refines the raw dataset, and sells the final model (see Figure 1). Data creators provide raw data, and the data packager adds value through processing. How, then, can we fairly allocate monetary value among the data creators and the data packager? Figure 1: Overview of the data market framework involving multiple data creators, a data packager, and a buyer. Addressing these questions necessitates incorporating inherent structures among data points into their valuation. We present the first study to use asymmetric Shapley value for data valuation in supervised machine learning. Our approach relaxes the symmetry axiom in the traditional data Shapley framework, thereby offering the flexibility to incorporate inherent structures within the sample space for structure-aware data valuation. Our contributions are summarized as follows: â€¢ We propose a novel data valuation framework called asymmetric data Shapley. Utilizing ordered partitions and weighted systems, this framework addresses the limitations of classical data Shapley by incorporating the inherent structures among data points into their valuation. â€¢ We provide a rigorous mathematical formulation for asymmetric data Shapley under general weight systems, including the intra-class uniform weight systems (ICU-WS) tailored for specific data valuation tasks. Theorems and propositions validate the class-wise efficiency of asymmetric data Shapley under ICU-WS, ensuring that the sum of data values in each social class reflects the incremental performance gain attributed to that class. â€¢ We develop two efficient algorithmsâ€”one based on a Monte Carlo approach and the other on a KNN surrogate methodâ€”for approximating and accurately computing asymmetric data Shapley. â€¢ We demonstrate the effectiveness of our approach in enhancing data valuation for tasks including augmented data valuation, sequential data valuation, and fair allocation in data marketplaces."
https://arxiv.org/html/2411.00181v1,Efficient Multi-Agent Delegated Search,"Consider a principal who wants to search through a space of stochastic solutions for one maximizing their utility. If the principal cannot conduct this search on their own, they may instead delegate this problem to an agent with distinct and potentially misaligned utilities. This is called delegated search, and the principal in such problems faces a mechanism design problem in which they must incentivize the agent to find and propose a solution maximizing the principalâ€™s expected utility. Following prior work in this area, we consider mechanisms without payments and aim to achieve a multiplicative approximation of the principalâ€™s utility when they solve the problem without delegation.In this work, we investigate a natural and recently studied generalization of this model to multiple agents and find nearly tight bounds on the principalâ€™s approximation as the number of agents increases. As one might expect, this approximation approaches 1111 with increasing numbers of agents, but, somewhat surprisingly, we show that this is largely not due to direct competition among agents.","â€œIf you want something done right, you have to do it yourselfâ€ may be little more than a catchy cliche, but it hints at an important idea in economic decision-making: when a principal delegates a task to untrusted agents, misaligned interests can lead to suboptimal outcomes. If this principal lacks the resources or ability to complete their own task, then they are faced with a mechanism design problem in which they want to select a delegation mechanism that optimizes their expected utility. In this paper, we aim to help the principal by finding multi-agent delegation mechanisms with competitive multiplicative approximations of what the principal could achieve on their own. Consider the following scenario that helps to illustrate and motivate our particular model and results. Take the perspective of a committee within a governmental body that funds scientific research through grants. You are tasked with allocating a fixed amount of resources for a single research project that benefits the nationâ€™s long-term interests, and there are several research groups from which you can receive, evaluate, and approve proposals. You are confident in your ability to evaluate proposals, but recognize that each research group has its own interests that may be misaligned with the nationâ€™s. You must try to design a grant proposal mechanism that motivates research groups to propose research projects that are most beneficial to the nation. More broadly, we consider models in which the principal faces a stochastic optimization problem where they have to find a solution maximizing the expected value of some objective function. The task of searching for solutions to this problem is then delegated to a fixed group of agents, who each have distinct utility functions. Agents propose solutions to the principal, and the principal picks a single winner who receives utility for their proposal. We focus on models of delegation in which the principalâ€™s mechanism can not make outcome-contingent payments, representing situations in which players are confined to a fixed-price contract or are not legally allowed to make transfers of value for specific outcomes. Finally, in contrast to designing optimal mechanisms, we build on recent delegation research [15, 6, 7, 12] in which the principal aims for a multiplicative approximation of their first-best expected utility, i.e. their expected utility when the problem is not delegated (alternatively, their utility when they delegate to agents with identical interests). This approximation factor, which can be called the delegation gap, tells the principal what fraction of their optimal utility they are guaranteed while delegating to arbitrary untrusted agents. 1.1 Overview of Our Models The delegation model of primary interest in this paper is strategic multi-agent delegation (Section 2) as originally defined by Hajiaghayi et al. [12]. This consists of a principal who wants to find a solution maximizing their utility over a stochastic solution space, and they must delegate the search process to kğ‘˜kitalic_k agents. Each agent is given a finite number of elements from which they can sample an outcome representing a solution along with the principalâ€™s and agentâ€™s utilities. The number of agents, number of elements per agent, and the distributions of outcomes are specified as part of the instance and common knowledge to all players. In this game, the principal starts by committing to some mechanism through which agents can communicate with the principal. Each agent then samples outcomes from their elements and sends a signal to the principal. The principal transforms these signals into an outcome which is conditionally accepted as the winner. If this outcome was not sampled by any agent, then the principal detects this â€œlieâ€ and rejects it, so all players get no utility. Otherwise, the principal and winning agent each get the utility specified by that outcome, and all other agents get nothing. One challenge posed by this model is the complexity of analyzing agentsâ€™ equilibrium strategies, how these equilibria are affected by the choice of mechanism, and how they affect the principalâ€™s utility. We also study a simplified model in which agents are assumed to act adversarially against the principal. More specifically, adversarial multi-agent delegation (Section 2) is the same as the strategic model above, except that we do not define agentsâ€™ utilities and all agents instead aim to minimize the principalâ€™s expected utility subject to maintaining a positive probability of winning. We will see that in the absence of symmetry conditions on the agents, it is difficult to make any nontrivial approximation guarantees in either model. One attempt to get around this involves the (strategic or adversarial) shuffled multi-agent delegation model (Section 2), in which elements are randomly distributed among agents. Specifically, there is a known pool of elements, each of which is given to a uniformly random agent, and the game proceeds from there as usual. Note that the principal does not learn which agent received which elements, and their expected utility is measured with respect to the random allocation of elements to agents. A perhaps more straightforward way of enforcing symmetry is the (strategic or adversarial) agent-symmetric multi-agent delegation model, in which all agents are given access to equivalent sets of elements. For these models, we consider three natural classes of mechanisms. First are single-proposal mechanisms (Section 2.1), originally defined for this multi-agent context in [12], in which the principal announces restricted sets of outcomes that they would accept, each agent proposes a single outcome to the principal, and the principal picks a winner from among them. This is perhaps one of the most natural classes of mechanisms, and can be seen implemented, for example, in the form of research grants. Specifically, an agency sets out criteria of proposals that they would be willing to accept and then receives a single proposal from each research group. Importantly, it is known that single-proposal mechanisms perform at least as well as any other kind of mechanism (Section 2.1). As a special case of single-proposal mechanisms, we consider threshold mechanisms (Section 2.1), in which the principalâ€™s acceptable sets of outcomes are defined by thresholds on their utility. Focusing on this restricted class is beneficial for vastly simplifying the complexity of describing an individual mechanism, reducing the space of mechanisms to something more manageable, and being more intuitive to a potential implementor. Although we spend little time on it, we also define a class of direct-revelation mechanisms called Myerson-type mechanisms (Section 2.1) that may be of interest for future work to expand on. As the name implies, this class is inspired by Myerson mechanisms from auction theory. In it, the principal declares a virtual value function for each element that maps the principalâ€™s true utility to a virtual value. The agent with an element of largest virtual value is declared the winner, and their favorite outcome that still has greater virtual value than all other agents is accepted by the principal. We show that these mechanisms are dominant-strategy incentive compatible (Section 2.1), and speculate whether they are optimal in an instance-by-instance sense, much like Myersonâ€™s revenue-optimal auction. 1.2 Overview of Our Results As mentioned before, our work focuses on understanding the delegation gap, which is defined as the minimum over all instances of the ratio between the principalâ€™s optimal delegated expected utility and their optimal non-delegated expected utility. For the models we study in this paper, agents have no constraints on â€œprobingâ€ elements to learn their values, so the principalâ€™s optimal non-delegated utility is simply the maximum utility among all outcomes. We start by showing that bounds on the delegation gap in the strategic case can be reduced to identical bounds in the adversarial case. This comes in two parts: the simple observation that delegating to strategic agents is at least as easy as delegating to adversarial agents (Section 3), and, less obviously, that for every adversarial instance within a central class, there is an analogous strategic instance with identical behavior from the principalâ€™s perspective (Section 3). This may be somewhat surprising, since it implies that any increase in utility from delegating to multiple agents is not, in general, attributable to strategic competition between those agents. Rather, the principalâ€™s utility seems to increase simply as a consequence of the larger pool of acceptable options afforded by a larger pool of agents. Turning our focus toward adversarial delegation, we find a harsh 1/2121/21 / 2-approximation upper bound for any number of agents that carries over from the related single-agent model. This is due to the fact that the general form of the model allows for one agent to hold all elements that contribute non-zero expected utility to the principal, so, in essence, the principal must delegate to just that one agent. However, moving beyond this impossibility, we show that when all agents have identical sets of elements, it is possible to achieve a competitive delegation gap of 1âˆ’ğ’ªâ¡(lnâ¡kk)1ğ’ªğ‘˜ğ‘˜1-\operatorname{\mathcal{O}}\left(\frac{\ln k}{k}\right)1 - caligraphic_O ( divide start_ARG roman_ln italic_k end_ARG start_ARG italic_k end_ARG ). This is done in two parts: first achieving this approximation for instances with only atomless distributions (Section 4), and then showing how to modify the strategy to deal with atoms (Section 4). Notably, this approximation uses only a threshold mechanism, so it is simple to describe. In the interest of demonstrating that other forms of symmetry also give competitive approximations, we show that the delegation gap of shuffled multi-agent delegation has the same 1âˆ’ğ’ªâ¡(lnâ¡kk)1ğ’ªğ‘˜ğ‘˜1-\operatorname{\mathcal{O}}\left(\frac{\ln k}{k}\right)1 - caligraphic_O ( divide start_ARG roman_ln italic_k end_ARG start_ARG italic_k end_ARG ) lower-bound (Section 4 and Section 4). Noting that a different symmetry assumption gives the same result, we conjecture that this is an instance of a more general phenomenon. Finally, we show that the optimal delegation gap achievable with kğ‘˜kitalic_k agents in the agent-symmetric case is upper bounded by 1âˆ’Î©â¢(1k)1Î©1ğ‘˜1-\Omega\left(\frac{1}{k}\right)1 - roman_Î© ( divide start_ARG 1 end_ARG start_ARG italic_k end_ARG ) (Section 4). We leave open for future work whether the gap between these upper and lower bounds can be closed. 1.3 Related Work There is a relatively long history of delegation research in computer science and economics, notably starting over four decades ago with the work of Holmstrom [14, 13]. We refer readers to [15, 6, 12] for a more detailed account of the followup work in delegation. A select sample includes the notable work of Alonso and Matouschek [4], Armstrong and Vickers [5], Alonso et al. [3], and the recent work of Gan et al. [11]. The last two study multi-agent delegation with two agents and no transfers, but they use different models and aim to find optimal mechanisms. The past few years have seen a small resurgence in this area, initiated by the work of Kleinberg and Kleinberg [16]. They study two models of delegation without payments, aiming for the same multiplicative approximation of the principalâ€™s optimal outcome, and show that the two problems can be reduced to known prophet inequalities and Pandoraâ€™s box problems. This work was later expanded on by that of Bechtel and Dughmi [6], who study a delegated model of stochastic probing with combinatorial constraints on the principal and agent, and Bechtel et al. [7], who explore different variants of the delegation of Pandoraâ€™s box problems. This line of work has shown that delegation has close connections to prophet inequalities [18, 19, 17, 10, 9, 20] and contention resolution schemes [8, 10, 2], among other related problems. Most similar to our work is that of Hajiaghayi et al. [12], who proposed (among other things) our main model of multi-agent delegation as a natural direction to build off of the existing work on delegation. Specifically, our strategic model is equivalent to their Bayesian mechanism multi-agent delegation with incomplete information. They show that when all agents have the same number of i.i.d. elements, the principal can achieve approximations tending to 1111 as Î±â¢kâ¢mğ›¼ğ‘˜ğ‘š\alpha kmitalic_Î± italic_k italic_m increases, where kğ‘˜kitalic_k is the number of agents, mğ‘šmitalic_m is the number of elements per agent, and Î±ğ›¼\alphaitalic_Î± is a parameter of the distributions. In contrast, we achieve an approximation tending to 1111 as kğ‘˜kitalic_k increases when agents have symmetric sets of elements (not necessarily i.i.d.), with no conditions on the distributions or number of elements per agent. They also explore and achieve competitive approximations for different settings with varying levels of power for the principal and agents."
https://arxiv.org/html/2411.00133v1,Constrained Fair and Efficient Allocations,"Fairness and efficiency have become the pillars of modern fair division research, but prior work on achieving both simultaneously is largely limited to the unconstrained setting. We study fair and efficient allocations of indivisible goods under additive valuations and various types of allocation feasibility constraints, and demonstrate the unreasonable effectiveness of the maximum Nash welfare (MNW) solution in this previously uncharted territory.Our main result is that MNW allocations are 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-envy-free up to one good (EF1) and Pareto optimal under the broad family of (arbitrary) matroid constraints. We extend these guarantees to complete MNW allocations for base-orderable matroid constraints, and to a family of non-matroidal constraints (which includes balancedness) using a novel â€œalternate worldsâ€ technique. We establish tightness of our results by providing counterexamples for the satisfiability of certain stronger desiderata, but show an improved result for the special case of goods with copies [Gafni et al., 2023]. Finally, we also establish novel best-of-both-worlds guarantees for goods with copies and balancedness.","Fair division of resources among agents is a primitive that has applications, both to multiagent systems [Chevaleyre et al., 2006] and to everyday problems such as estate division and divorce settlement [Shah, 2017]. Over the last decade, the fair division literature has undergone a dramatic transformation. The pioneering work of Caragiannis et al. [2019] established that, under additive valuations, the so-called maximum Nash welfare (MNW) allocations, which (informally) maximize the product of agent utilities, simultaneously satisfy two appealing guarantees: a fairness criterion known as envy-freeness up to one good (EF1), which demands that no agent prefer the allocation of another agent (modulo a single good) to her own, and an efficiency criterion known as Pareto optimality (PO), which demands that no alternative allocation be able to make an agent happier without making any agent worse off. These provable fairness and efficiency guarantees have been critical to their use in the real world via the not-for-profit website Spliddit.org [Shah, 2017]. Ever since then, the combination of fairness and efficiency, in the form of approximate envy-freeness and Pareto optimality, has become the guiding principle for seeking fair division solutions, e.g., for subclasses of additive valuations [Hosseini et al., 2021], for non-additive valuations [Benabbou et al., 2021, Barman and Suzuki, 2024], when addressing manipulations [Psomas and Verma, 2022], or for allocating chores [Ebadian et al., 2022, Garg et al., 2022], or for allocating public goods [Fain et al., 2018, Ebadian et al., 2024]. However, in many real-world fair division problems, there are feasibility constraints on the bundle that each agent can receive. Examples include course allocation [Budish et al., 2017], public housing assignment [Benabbou et al., 2020], or allocation of conference submissions to reviewers [Garg et al., 2010]. Unfortunately, the literature on constrained fair division has been largely limited to seeking only fairness guarantees. â€¢ Biswas and Barman [2018] show the existence of an EF1 allocation subject to cardinality constraints, where the goods are partitioned into categories and each agent must be allocated at most a prescribed maximum number of goods from each category. â€¢ Biswas and Barman [2019] extend this to any base-orderable matroid constraint, where the bundle of goods allocated to each agent must be an independent set of a given base-orderable matroid (cardinality constraints form a partition matroid, which is a special case), when agents have identical additive valuations.111Biswas and Barman [2019] incorrectly state their result for an arbitrary matroid constraint in the original paper, but later versions correctly state that the result holds for base-orderable matroids. The existence of an EF1 allocation here remains open for general matroid constraints, even for identical additive valuations. â€¢ Gafni et al. [2023] study a special case of cardinality constraints, which they refer to as goods with copies, motivated by the fact that it in turn subsumes chore division as a special case. They define an appealing strengthening of EF1, termed EF1WC, and establish its existence for restricted valuation classes. â€¢ The popular round robin algorithm yields an EF1 allocation subject to balancedness, where all agents must be assigned bundles of roughly equal cardinality (differing by at most one) [Caragiannis et al., 2019]. â€¢ A famous non-matroidal constraint is where the goods are vertices of an undirected graph, and the bundle allocated to each agent must form a connected subset; when the graph is a line, an EF1 allocation is known to exist [Igarashi, 2023], and for general graphs, a 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 allocation with up to nâˆ’1ğ‘›1n-1italic_n - 1 unallocated goods is known to exist under restricted preferences [Caragiannis et al., 2022]. In addition to the above summary of related work, we provide comparisons to other pieces of related work throughout the paper, and also refer the reader to the extensive survey on constraints in fair division by Suksompong [2021]. Quite surprisingly, the existence of an allocation that satisfies both (even approximate) EF1 and PO remains severely understudied in these constrained domains. The only exception is the work on budget constraints, where each good has a size and the total size of goods allocated to any agent must be at most a threshold. Gan et al. [2023] show that an EF1 allocation always exists, and Wu et al. [2021] show that any MNW allocation subject to such a constraint is 1/414\nicefrac{{1}}{{4}}/ start_ARG 1 end_ARG start_ARG 4 end_ARG-EF1 and PO. Our main research question is to expand on this line of work: Under which types of feasibility constraints do (approximately) fair and efficient allocations exist? 1.1 Our Results Our main result is that every MNW allocation is 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO under the broad class of (arbitrary) matroid constraints (see Section 2 for a formal definition). While these allocations are efficient, they can be incomplete, i.e., leave some goods unallocated, which may be undesirable in settings such as allocation of shifts to nurses and assignment of conference submissions to reviewers. To that end, we show that for base-orderable matroid constraints, even allocations that are MNW among the set of complete and feasible allocations are 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO. Base-orderable matroids subsume the case of cardinality constraints [Biswas and Barman, 2018]. Then, using a novel technique of constructing â€œalternate worldsâ€, we show that the 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO guarantees can be extended to MNW allocations subject to a broad class of non-matroidal constraints, which includes balancedness as a special case. We also show that certain strengthenings of EF1 and PO are unachievable in the realm of constrained allocations, but show an improvement from EF1 to EF1WC for the case of goods with copies [Gafni et al., 2023]. Finally, we expand the recent work on â€œbest of both worldsâ€ (BoBW) guarantees [Aziz et al., 2024] to the realm of constrained allocations. Building on the work of Echenique et al. [2021], we prove that randomized allocations that are ex ante EF and PO along with ex post EF11subscriptsuperscriptabsent11{}^{1}_{1}start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, Prop1, and PO exist for the case of goods with copies, and the same result except for the EF11subscriptsuperscriptabsent11{}^{1}_{1}start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT guarantee holds when adding the balancedness constraint. For formal definitions, see Section 4."
https://arxiv.org/html/2411.00707v1,"Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms","We study learning in a dynamically evolving environment modeled as a Markov game between a learner and a strategic opponent that can adapt to the learnerâ€™s strategies. While most existing works in Markov games focus on external regret as the learning objective, external regret becomes inadequate when the adversaries are adaptive. In this work, we focus on policy regret â€“ a counterfactual notion that aims to compete with the return that would have been attained if the learner had followed the best fixed sequence of policy, in hindsight. We show that if the opponent has unbounded memory or if it is non-stationary, then sample-efficient learning is not possible. For memory-bounded and stationary, we show that learning is still statistically hard if the set of feasible strategies for the learner is exponentially large. To guarantee learnability, we introduce a new notion of consistent adaptive adversaries, wherein, the adversary responds similarly to similar strategies of the learner. We provide algorithms that achieve Tğ‘‡\sqrt{T}square-root start_ARG italic_T end_ARG policy regret against memory-bounded, stationary, and consistent adversaries.","Recent years have witnessed tremendous advances in reinforcement learning for various challenging domains in AI, from the game of Go (Silver et al., 2016, 2017, 2018), real-time strategy games such as StarCraft II (Vinyals et al., 2019) and Dota (Berner et al., 2019), autonomous driving (Shalev-Shwartz et al., 2016), to socially complex games such as hide-and-seek (Baker et al., 2019), capture-the-flag (Jaderberg et al., 2019), and highly tactical games such as poker game Texas holdâ€™ em (MoravÄÃ­k et al., 2017; Brown and Sandholm, 2018). Notably, most challenging RL applications can be systematically framed as multi-agent reinforcement learning (MARL) wherein multiple strategic agents learn to act in a shared environment (Yang and Wang, 2020; Zhang et al., 2021). Despite the empirical successes, the theoretical foundations of MARL are underdeveloped, especially in settings where the learner faces adaptive opponents who can strategically adapt and react to the learnerâ€™s policies. Consider for example the optimal taxation problem in the AI economist (Zheng et al., 2020), a game that simulates dynamic economies that involve multiple actors (e.g., the government and its citizens) who strategically contribute to the game dynamics. The government agent learns to set a tax rate that optimizes for the economic equality and productivity of its citizens, whereas the citizens who perhaps have their own interests, respond adaptively to tax policies of the government agent (e.g., relocating to states that offer generous tax rates). Such adaptive behavior of participating agents is a crucial component in other applications as well, e.g., mechanism design (Conitzer and Sandholm, 2002; Balcan et al., 2005), optimal auctions (Cole and Roughgarden, 2014; DÃ¼tting et al., 2019). The question of learning against adaptive opponents has been mostly studied under the framework of external regret, wherein the agent is required to compete with the best fixed policy in hindsight (Liu et al., 2022). However, external regret is not adequate to study adaptive opponents as it does not take into account the counterfactual response of the opponents. This motivates us to study MARL using the framework of policy regret (Arora et al., 2012), a counterfactual notion that aims to compete with the return that would have been attained if the agent had followed the best fixed sequence of policy in hindsight. Even though policy regret is now a standard notion to study adaptive adversaries and has been extensively studied in online (bandit) learning (Merhav et al., 2002; Arora et al., 2012; Malik et al., 2022) and repeated games (Arora et al., 2018), it has not received much attention in a multiagent reinforcement learning setting. In this paper, we aim to fill in this gap. We consider two-player Markov games (MGs) (Shapley, 1953; Littman, 1994) as a model for MARL, wherein one agent (the learner) learns to act against an adaptive opponent. We provide a series of negative and positive results for policy regret minimization in Markov games, highlighting the fundamental limits of learning and showcasing key principles underpinning the design of efficient learning algorithms against adaptive adversaries. Fundamental barriers. We first show that any learner must incur a linear policy regret against an adaptive opponent who can adapt and remember the learnerâ€™s past policies (Theorem 1). When the opponent has a bounded memory span, any learner must require an exponential number of samples Î©â¢((Sâ¢A)H/Ïµ2)Î©superscriptğ‘†ğ´ğ»superscriptitalic-Ïµ2\Omega((SA)^{H}/{\epsilon}^{2})roman_Î© ( ( italic_S italic_A ) start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT / italic_Ïµ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to obtain an Ïµitalic-Ïµ{\epsilon}italic_Ïµ-suboptimal policy regret, even with the weakest form of memory wherein the opponent is oblivious (Theorem 2). When the memory-bounded opponentâ€™s response is stationary, i.e., the response function does not vary with episodes, learning is still statistically hard when the learnerâ€™s policy set is exponentially large, as in this case the policy regret necessarily scales polynomially with the cardinality of the learnerâ€™s policy set (Theorem 3). Efficient algorithms. Motivated by these statistical hardness results, we consider a structural condition on the response of the opponents, which we refer to as consistent behavior, wherein the opponent responds similarly to similar sequences of policies (5). We propose two algorithms OPO-OMLE (Algorithm 1) and APE-OVE (Algorithm 3) that obtain Tğ‘‡\sqrt{T}square-root start_ARG italic_T end_ARG policy regret against mğ‘šmitalic_m-memory bounded, stationary, and consistent adversaries, for m=1ğ‘š1m=1italic_m = 1 and mâ‰¥1ğ‘š1m\geq 1italic_m â‰¥ 1, respectively. â€¢ For memory length m=1ğ‘š1m=1italic_m = 1: We show that OPO-OMLE obtains a policy regret upper bound of ğ’ª~â¢(H3â¢S2â¢Aâ¢B+H5â¢Sâ¢A2â¢Bâ¢T)~ğ’ªsuperscriptğ»3superscriptğ‘†2ğ´ğµsuperscriptğ»5ğ‘†superscriptğ´2ğµğ‘‡\tilde{{\mathcal{O}}}(H^{3}S^{2}AB+\sqrt{H^{5}SA^{2}BT})over~ start_ARG caligraphic_O end_ARG ( italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT italic_S italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_B italic_T end_ARG ), when the learnerâ€™s policy set is the set of all deterministic Markov policies, where Hğ»Hitalic_H is the episode length, Sğ‘†Sitalic_S is the number of states, Ağ´Aitalic_A and BğµBitalic_B are the numbers of actions for the learner and the opponent, respectively, and Tğ‘‡Titalic_T is the number of episodes. â€¢ For general memory length mâ‰¥1ğ‘š1m\geq 1italic_m â‰¥ 1: We show that APE-OVE obtains a policy regret upper bound of ğ’ª~â¢((mâˆ’1)â¢H2â¢Sâ¢Aâ¢B+H3â¢Sâ¢Aâ¢Bâ¢(Sâ¢Aâ¢Bâ¢(H+S)+H2)â¢Tdâˆ—)~ğ’ªğ‘š1superscriptğ»2ğ‘†ğ´ğµsuperscriptğ»3ğ‘†ğ´ğµğ‘†ğ´ğµğ»ğ‘†superscriptğ»2ğ‘‡superscriptğ‘‘\tilde{{\mathcal{O}}}\left((m-1)H^{2}SAB+\sqrt{H^{3}SAB}(SAB(H+\sqrt{S})+H^{2}% )\sqrt{\frac{T}{d^{*}}}\right)over~ start_ARG caligraphic_O end_ARG ( ( italic_m - 1 ) italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_S italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S italic_A italic_B end_ARG ( italic_S italic_A italic_B ( italic_H + square-root start_ARG italic_S end_ARG ) + italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) square-root start_ARG divide start_ARG italic_T end_ARG start_ARG italic_d start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT end_ARG end_ARG ), where dâˆ—superscriptğ‘‘d^{*}italic_d start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT is an instance-dependent quantity that features the minimum positive visitation probability. We provide a summary of our main results in Table 1. Opponentâ€™s Adaptive Behavior Policy Regret Unbounded memory Î©â¢(T)Î©ğ‘‡\Omega(T)roman_Î© ( italic_T ) mğ‘šmitalic_m-memory bounded (mâ‰¥0ğ‘š0m\geq 0italic_m â‰¥ 0) Î©â¢(Tâ¢(Sâ¢A)H)Î©ğ‘‡superscriptğ‘†ğ´ğ»\Omega(\sqrt{T(SA)^{H}})roman_Î© ( square-root start_ARG italic_T ( italic_S italic_A ) start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT end_ARG ) mğ‘šmitalic_m-memory bounded + stationary (mâ‰¥1ğ‘š1m\geq 1italic_m â‰¥ 1) Î©â¢(minâ¡{T,AHâ¢S})Î©ğ‘‡superscriptğ´ğ»ğ‘†\Omega(\min\{T,A^{HS}\})roman_Î© ( roman_min { italic_T , italic_A start_POSTSUPERSCRIPT italic_H italic_S end_POSTSUPERSCRIPT } ) 1111-memory bounded + stationary + consistent ğ’ª~â¢(H3â¢S2â¢Aâ¢B+H5â¢Sâ¢A2â¢Bâ¢T)~ğ’ªsuperscriptğ»3superscriptğ‘†2ğ´ğµsuperscriptğ»5ğ‘†superscriptğ´2ğµğ‘‡\tilde{{\mathcal{O}}}(H^{3}S^{2}AB+\sqrt{H^{5}SA^{2}BT})over~ start_ARG caligraphic_O end_ARG ( italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT italic_S italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_B italic_T end_ARG ) mğ‘šmitalic_m-memory bounded + stationary + consistent ğ’ª~â¢((mâˆ’1)â¢H2â¢Sâ¢Aâ¢B+H3â¢Sâ¢Aâ¢Bâ¢(Sâ¢Aâ¢Bâ¢(H+S)+H2)â¢Tdâˆ—)~ğ’ªğ‘š1superscriptğ»2ğ‘†ğ´ğµsuperscriptğ»3ğ‘†ğ´ğµğ‘†ğ´ğµğ»ğ‘†superscriptğ»2ğ‘‡superscriptğ‘‘\tilde{{\mathcal{O}}}\left((m-1)H^{2}SAB+\sqrt{H^{3}SAB}(SAB(H+\sqrt{S})+H^{2}% )\sqrt{\frac{T}{d^{*}}}\right)over~ start_ARG caligraphic_O end_ARG ( ( italic_m - 1 ) italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_S italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S italic_A italic_B end_ARG ( italic_S italic_A italic_B ( italic_H + square-root start_ARG italic_S end_ARG ) + italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) square-root start_ARG divide start_ARG italic_T end_ARG start_ARG italic_d start_POSTSUPERSCRIPT âˆ— end_POSTSUPERSCRIPT end_ARG end_ARG ) Table 1: Summary of main results for learning against adaptive adversaries. Learnerâ€™s policy set is all deterministic Markov policies. m=0ğ‘š0m=0italic_m = 0 + stationary corresponds to standard single-agent MDPs."
https://arxiv.org/html/2411.00564v1,"A decomposition from a substitutable many-to-one matching market to a one-to-one matching marketâ€ â€ thanks:We acknowledge the financial support of UNSL through grants 03-2016 and 03-1323, and from Consejo Nacional
de Investigaciones CientÃ­ficas y TÃ©cnicas (CONICET) through grant
PIP 112-200801-00655, and from Agencia Nacional de PromociÃ³n CientÃ­fica y TecnolÃ³gica through grant PICT 2017-2355.","For a many-to-one market with substitutable preferences on the firmâ€™s side, based on the Aizerman-Malishevski decomposition, we define an associated one-to-one market. Given that the usual notion of stability for a one-to-one market does not fit well for this associated one-to-one market, we introduce a new notion of stability. This notion allows us to establish an isomorphism between the set of stable matchings in the many-to-one market and the matchings in the associated one-to-one market that meet this new stability criterion. Furthermore, we present an adaptation of the well-known deferred acceptance algorithm to compute a matching that satisfies this new notion of stability for the associated one-to-one market.JEL classification: C78, D47.Keywords: Many-to-one matchings, Aizermann-Malishevski decomposition, one-to-one matchings, deferred acceptance algorithm, stable set","Many-to-one markets have been extensively studied in the literature, starting with the college admissions problem and extending to the assignment of medical interns to hospitals, as well as applications in labor markets. A fundamental characteristic of these markets is that institutions, which we will refer to as firms, hold preferences over subsets of agents, whom we will refer to as workers. In this paper, we introduce a decomposition of a many-to-one market in which firms have substitutable preferences over subsets of workers, transforming it into an associated one-to-one market. We construct this decomposition based on the Aizerman-Malishevski decomposition of substitutable preferences (see Aizerman and Malishevski, 1981). Crawford and Kelso (1982) introduced the notion of substitutability in preferences, which is the weakest condition needed to guarantee the existence of stable matchings. A firm is said to have substitutable preferences if it continues to desire a worker even when other workers become unavailable. The Aizerman-Malishevski decomposition is well known in the choice literature (e.g., Moulin, 1985) and states that any path-independent choice rule can be represented as the union of choices derived from preference relations over individuals. Chambers and Yenmez (2017) apply the Aizerman-Malishevski decomposition to study path-independent choice rules in a matching context. They use this decomposition to develop a deferred acceptance algorithm for many-to-many matching markets with contracts and to analyze its properties. The Aizerman-Malishevski decomposition models a firm as the union of several â€œcopiesâ€ of itself, facilitating the representation of firmsâ€™ preferences in substitutable cases. A key feature of this decomposition is its capacity to transform a substitutable preference over a subset of workers into multiple, distinct linear preferences over workers. The fact that copies of the same firm have different linear preferences leads to a situation where the usual notion of stability for one-to-one markets does not apply adequately.111Recall that, in traditional one-to-one matching markets, stability requires individual rationality and the absence of blocking pairs. A matching is individually rational if each agent is assigned to an â€œacceptableâ€ partner. A matching contains a blocking pair if both agents within that pair mutually prefer each other over their current partners in the matching. In Section 2, we present Example 1, which illustrates a many-to-one market where firms have substitutable preferences, along with its corresponding Aizerman-Malishevski decomposition. In this example, we observe that in the many-to-one market, there are four stable matchings, while in the associated one-to-one market, there is only one stable matching under the usual notion of stability. This discrepancy implies that no relation (e.g., no isomorphism) can be established between the stable matchings in the many-to-one market and those in the associated one-to-one market. For this reason, we adapt the notion of stability and introduce stability* for one-to-one matchings. This new notion resembles the classical notion of stability (i.e., it is individually rational and free of blocking pairs) but is adapted to capture the substitutable preferences inherent in the original market. Building on this new notion, we can establish an isomorphism between the set of stable matchings in the substitutable many-to-one market and the set of stable* matchings in the associated one-to-one market. To highlight the difference between the usual notion and stability*, we introduce two additional conditions not typically required in one-to-one settings. First, for individual rationality* in this associated market, we impose an envy-free condition among firm-copies: no firm-copy matched to a worker should prefer another worker matched to a different copy of the same firm. Second, in the presence of blocking pairs, we require that the worker in the blocking pair is preferred by the relevant firm-copy over all workers matched to other copies of that same firm. A common approach to prove the non-emptiness of a stable set is constructive. In the seminal paper by Gale and Shapley (1962), an algorithm is presented â€”the well-known deferred acceptance algorithmâ€” which constructs a stable matching for traditional one-to-one markets. Although our isomorphism demonstrates that the set of stable* one-to-one matchings is non-empty, we adapt the deferred acceptance algorithm to the related one-to-one market, taking into account the specific characteristics of stability*. Although one-to-one markets are traditionally symmetric, our related one-to-one market is not. This is because it originates from the decomposition of a many-to-one substitutable market. Thus, we present two adapted versions of the deferred acceptance algorithm: one where firm-copies propose and another where workers propose. We show that, whether the firm-copies or the workers are the proposers, the algorithm returns a stable* matching. In this way, independently of the isomorphism, we establish that the set of stable* matchings for the related one-to-one market is non-empty. The idea of decomposing a many-to-one market into a one-to-one market has been previously studied under a more restrictive preference structure. When firmsâ€™ preferences are assumed to be responsive to an individual ranking of workersâ€”a more restrictive structure than substitutable preferencesâ€”Roth and Sotomayor (1990) demonstrate that each firm can be decomposed into identical units (or copies) according to its capacity (quotas qğ‘qitalic_q). A key distinction in this decomposition is that each of these copies shares the same individual preferences over workers (derived from responsive preferences), and workers rank all copies of a given firm above those of any other firm, preserving the same order of preferences across all copies. This decomposition transforms a many-to-one market with responsive preferences into a corresponding one-to-one market. Furthermore, Roth and Sotomayor (1990) establish an isomorphism between the stable matchings of a many-to-one market and those of an associated one-to-one market. The paper is organized as follows. In Section 2, we present the many-to-one market, the Aizerman-Malishevski decomposition, and the associated one-to-one market. For this associated one-to-one market, in Section 3, we present an adapted deferred acceptance algorithm and an isomorphism with the many-to-one market. Finally, in Section 4 some final remarks are presented."
https://arxiv.org/html/2411.00217v1,"ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testingâ€ â€ thanks:2Authors contributed equally, 1Corresponding author,Authors belong to Department of Electrical and Computer EngineeringNew York University, New York 11201, USA{hl4155, yg2047, qz494}@nyu.edu","The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.","Modern artificial intelligence (AI), such as machine learning (ML) technologies, are becoming increasingly integrated into many infrastructures, including smart transportation systems and healthcare infrastructures. In healthcare, they have shown the potential to help healthcare infrastructure in patient scheduling [1, 2], pathological analysis [3], and care management [4]. While there are significant benefits, there are concerns regarding zero-day vulnerabilities and the expanded attack surface. Penetration testing is a valuable ethical hacking method for uncovering vulnerabilities in increasingly complex infrastructures and devising remediation strategies. As these infrastructures become more complex, with millions of interconnected devices, scalability emerges as a critical challenge. It is essential to develop a distributed, modular, and automated approach that addresses device-level testing needs while considering global influences through interconnectivity. Another challenge stems from the dynamic nature of networked devices and their vulnerabilities. There is a growing need for adaptive and automated approaches to continuously update the vulnerability landscape, ensuring that threats are exhaustively identified, risks accurately assessed, and remediation measures properly applied. The third challenge arises from the integration of AI capabilities into the infrastructure. The emergence of adversarial AI/ML introduces new and evolving threat vectors, which are designed to evade detection and testing. There is a need for the development of automated and strategic approaches that can intelligently outmaneuver their evolving nature through continuous knowledge acquisition and learning. To this end, we establish a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing (ADAPT). Figure 1: The framework of the ADAPT: The upper half illustrates an online automated adaptation of penetration testing. It integrates game-theoretic and neuro-symbolic frameworks, consisting of five distinct building blocks (to be introduced in Section III). The lower half depicts an example of AI-enabled healthcare infrastructure. This AI-enabled infrastructure presents an expanded attack surface due to interconnectivity and zero-day vulnerabilities. To address the challenges in penetration testing within AI-enabled healthcare infrastructure networks, ADAPT consolidates the game-theoretic framework and the neuro-symbolic framework, shown in the Figure 1. The game-theoretic and neuro-symbolic framework consists of five building blocks. The macro-game and micro-game blocks serve as representations of the given system. Game-theoretic strategies are updated based on the selected attack models through neural learning in the online learning blocks. Different attack models are represented using game trees, which encode relevant attack and defense actions selected from the knowledge. This knowledge contains vulnerabilities of the health infrastructure that are shared among multiple stakeholders in the medical system. When new paths or vulnerabilities are discovered through exploration (e.g., automated fuzzing techniques [5]) and penetration testing, the knowledge base is generated and updated accordingly. ADAPT helps medical systems evaluate their AI-enabled network for scalability, the impact of reachability, and the exhaustiveness of risk identification, and protects the confidentiality, integrity, and availability of the AI model. The purpose of it is to ensure preparedness against continuously evolving malicious threats such as ransomware and zero-day attacks on healthcare infrastructures."
https://arxiv.org/html/2411.00025v1,Probabilistic Obstruction Temporal Logic:a Probabilistic Logic to Reason about Dynamic Models,"In this paper, we propose a novel formalism called Probabilistic Obstruction Temporal Logic (POTL), which extends Obstruction Logic (OL) by incorporating probabilistic elements. POTL provides a robust framework for reasoning about the probabilistic behaviors and strategic interactions between attackers and defenders in environments where probabilistic events influence outcomes. We explore the model checking complexity of POTL and demonstrate that it is not higher than that of Probabilistic Computation Tree Logic (PCTL), making it both expressive and computationally feasible for cybersecurity and privacy applications.","Understanding and quantifying uncertainty is essential in cybersecurity, and probability theory offers a robust framework for this purpose, making it particularly valuable for risk analysis. As digital systems grow increasingly complex and dynamic, effectively assessing and managing risks becomes more challenging. Probability theory allows organizations to model the likelihood of various cyber threats, such as hacking attempts, data breaches, and software vulnerabilities, which are inherently uncertain and variable. Cybersecurity professionals can estimate the likelihood of these threats materializing and assess their potential impact on systems by applying probabilistic and non-probabilistic formalisms. Researchers have developed various solutions over the past fifty years, with formal methods emerging as a notable success. These techniques allow for the verification of system correctness by checking if a mathematical model meets the formalized desired behavior. Notably, traditional formal approaches like model checking (Baier and Katoen 2008), initially designed for monolithic systems, have been effectively adapted to manage open and Multi-Agent Systems (MAS). In recent years, the study of MAS has garnered significant attention due to its wide-ranging applications in fields such as cybersecurity, robotics, and distributed computing. MAS consists of two or more interacting agents, each capable of making autonomous decisions. These systems often operate in dynamic and uncertain environments, necessitating robust formal verification techniques to ensure their reliability and correctness. An important logic in the context of MAS is Alternating-time Temporal Logic (ATL) (Alur, Henzinger, and Kupferman 2002). The latter extends CTL (Clarke and Emerson 1981) by introducing strategic modalities, enabling the specification of properties that involve the strategic abilities of agents. ATL can express whether a group of agents can achieve a certain goal regardless of the actions of other agents, making it a powerful tool for reasoning about cooperation and competition in MAS. Another relevant formalism in this area is Obstruction Logic (OL) (Catta, Leneutre, and Malvone 2023b), which focuses on obstructions in two-player games. In OL, one player, called the Demon, can temporarily disable edges in the graph as long as their total weight remains below a specified natural number, thereby preventing the other agent from achieving its temporal goal. As illustrated in their paper, OL can be well-suited for representing cybersecurity problems, where a defender can activate defense mechanisms (by disabling edges) and an attacker aims to access private resources through a sequence of atomic attacks. In this context, a key aspect when performing cybersecurity risk analysis is to assess the likelihood (or probability) of success of the attack scenarios. However, OL did not address this aspect, where no probabilistic concepts were introduced. For the above reasons, in this paper, we present Probabilistic Obstruction Temporal Logic (POTL), a logic that extends OL into a probabilistic context. POTL offers a comprehensive framework for analyzing the probabilistic behaviors and strategic interactions between attackers and defenders in scenarios where probabilistic events influence outcomes. We investigate the model checking complexity of POTL and show that it is comparable to that of Probabilistic Computation Tree Logic, ensuring that POTL remains both expressive and computationally practical for cybersecurity and privacy applications. Structure of the work. The contribution is structured as follows. Theoretical background is presented in Section 2. In Section 3, we present the syntax and the semantics of our new logic, called Probabilistic Obstruction Temporal Logic (POTL). In Section 4, we show our model checking algorithm and prove that the model checking problem for POTL is decidable in polyonimal-time. In section 5, we present an illustrative example related to the cybersecurity analysis. In Section 6, we compare our approach to related work. Finally, Section 7 concludes and presents possible future directions."
