URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.04391v1,Improved Maximin Share Approximations for Choresby Bin Packing,"We study fair division of indivisible chores among n𝑛nitalic_n agents with additive cost functions using the popular fairness notion of maximin share (MMS). Since MMS allocations do not always exist for more than two agents, the goal has been to improve its approximations and identify interesting special cases where MMS allocations exists. We show the existence of1-out-of-⌊911⁢n⌋911𝑛\lfloor\frac{9}{11}n\rfloor⌊ divide start_ARG 9 end_ARG start_ARG 11 end_ARG italic_n ⌋ MMS allocations, which improves the state-of-the-art factor of 1-out-of-⌊34⁢n⌋34𝑛\lfloor\frac{3}{4}n\rfloor⌊ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n ⌋.MMS allocations for factored instances, which resolves an open question posed by Ebadian et al. (2021).15/13151315/1315 / 13-MMS allocations for personalized bivalued instances, improving the state-of-the-art factor of 13/11131113/1113 / 11.We achieve these results by leveraging the HFFD algorithm of Huang and Lu (2021). Our approach also provides polynomial-time algorithms for computing an MMS allocation for factored instances and a 15/13151315/1315 / 13-MMS allocation for personalized bivalued instances.","Fair division of indivisible tasks (or chores) has garnered significant attention recently due to its applications in various multi-agent settings; see recent surveys (Amanatidis et al., 2023; Liu et al., 2024). The problem is to find a fair partition of a set ℳℳ\mathcal{M}caligraphic_M of m𝑚mitalic_m indivisible chores among n𝑛nitalic_n agents with preferences. We assume that each agent i𝑖iitalic_i has additive preferences represented by the cost functions vi(.)v_{i}(.)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( . ) such that the cost of a set of chores S𝑆Sitalic_S is given by vi⁢(S)=∑c∈Svi⁢(c)subscript𝑣𝑖𝑆subscript𝑐𝑆subscript𝑣𝑖𝑐v_{i}(S)=\sum_{c\in S}v_{i}(c)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) = ∑ start_POSTSUBSCRIPT italic_c ∈ italic_S end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ), where vi⁢(c)subscript𝑣𝑖𝑐v_{i}(c)italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) represents the cost of chore c𝑐citalic_c for agent i𝑖iitalic_i. A natural and popular fairness notion in the context of indivisible items is called maximin share (MMS), introduced by Budish (2011). It appears to be also favored by participating agents in real-life experiments (Gates et al., 2020). An agent’s MMS is defined as the minimum cost they can ensure by partitioning all the chores into n𝑛nitalic_n bundles (one for each agent) and then receiving a bundle with the highest cost. Formally, for a set S𝑆Sitalic_S of chores and an integer d𝑑ditalic_d, let Πd⁢(S)subscriptΠ𝑑𝑆\Pi_{d}(S)roman_Π start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_S ) denote the set of all partitions of S𝑆Sitalic_S into d𝑑ditalic_d bundles. Then, MMSid⁢(S):=min(S1,…,Sd)∈Πd⁢(S)⁡maxj⁡vi⁢(Sj).assignsuperscriptsubscriptMMS𝑖𝑑𝑆subscriptsubscript𝑆1…subscript𝑆𝑑subscriptΠ𝑑𝑆subscript𝑗subscript𝑣𝑖subscript𝑆𝑗\text{MMS}_{i}^{d}(S):=\min_{(S_{1},\dots,S_{d})\in\Pi_{d}(S)}\max_{j}v_{i}(S_% {j}).MMS start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ( italic_S ) := roman_min start_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_S start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ) ∈ roman_Π start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT ( italic_S ) end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) . Let us denote the MMS of an agent i𝑖iitalic_i by μisubscript𝜇𝑖\mu_{i}italic_μ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT := MMS(ℳ)in{}_{i}^{n}(\mathcal{M})start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( caligraphic_M ). In an MMS allocation, each agent’s bundle cost does not exceed their MMS. However, for more than two agents, MMS allocations are not guaranteed to exist (Aziz et al., 2017; Feige et al., 2021). Therefore, the focus shifted to exploring approximations of MMS and identifying interesting special classes where MMS allocations can be achieved. Two natural relaxations are multiplicative and ordinal approximations. α𝛼\alphaitalic_α-MMS This approach involves multiplying the MMS by a factor α>1𝛼1\alpha>1italic_α > 1 to raise each agent’s threshold. An allocation is said to be α𝛼\alphaitalic_α-MMS if the cost of each agent’s bundle is at most α𝛼\alphaitalic_α times their MMS. Research has progressed to demonstrate the existence of 13/11131113/1113 / 11-MMS allocations (Huang and Segal-Halevi, 2023). 1111-out-of-d𝑑ditalic_d-MMS Another way to adjust the threshold is by considering the MMS when the chores are divided into d<n𝑑𝑛d<nitalic_d < italic_n bundles. An allocation is 1111-out-of-d𝑑ditalic_d-MMS if each agent’s bundle cost is no more than MMS(ℳ)id{}_{i}^{d}(\mathcal{M})start_FLOATSUBSCRIPT italic_i end_FLOATSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ( caligraphic_M ). This relaxation, initially introduced in (Budish, 2011) for the case of goods, is valued for its resilience to small perturbations in chores costs; see (Hosseini et al., 2021a) for more details. The current best-known factor for which existence is established is 1-out-of-⌊34⁢n⌋34𝑛\lfloor\frac{3}{4}n\rfloor⌊ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n ⌋ (Hosseini et al., 2022). 1.1 Our contributions In this paper, we advance the state-of-the-art on all three fronts: achieving exact MMS, and exploring both multiplicative and ordinal approximations. We establish the existence of • 1-out-of-⌊911⁢n⌋911𝑛\lfloor\frac{9}{11}n\rfloor⌊ divide start_ARG 9 end_ARG start_ARG 11 end_ARG italic_n ⌋ MMS allocations for all additive instances, improving the current best-known factor of 1-out-of-⌊34⁢n⌋34𝑛\lfloor\frac{3}{4}n\rfloor⌊ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n ⌋. • MMS allocations for factored instances, where each vi⁢(c)∈{p1,p2,…,pk}subscript𝑣𝑖𝑐subscript𝑝1subscript𝑝2…subscript𝑝𝑘v_{i}(c)\in\{p_{1},p_{2},\dots,p_{k}\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) ∈ { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } such that pℓ=pℓ−1⋅qsubscript𝑝ℓ⋅subscript𝑝ℓ1𝑞p_{\ell}=p_{\ell-1}\cdot qitalic_p start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT roman_ℓ - 1 end_POSTSUBSCRIPT ⋅ italic_q for some integer q>0𝑞0q>0italic_q > 0 for each ℓ∈[k−1]ℓdelimited-[]𝑘1\ell\in[k-1]roman_ℓ ∈ [ italic_k - 1 ]. Factored instances encompass the well-studied class of weakly lexicographic preferences (Aziz et al., 2019; Hosseini et al., 2021b). This contribution also resolves an open question posed by ebadian2021fairly. • 15/13151315/1315 / 13-MMS allocations for personalized bivalued instances, where each vi⁢(c)∈{ai,bi}subscript𝑣𝑖𝑐subscript𝑎𝑖subscript𝑏𝑖v_{i}(c)\in\{a_{i},b_{i}\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) ∈ { italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } for some positive rational numbers ai,bisubscript𝑎𝑖subscript𝑏𝑖a_{i},b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. They generalize the well-studied bivalued instances, where each vi⁢(c)∈{a,b}subscript𝑣𝑖𝑐𝑎𝑏v_{i}(c)\in\{a,b\}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_c ) ∈ { italic_a , italic_b } for some positive constants a,b𝑎𝑏a,bitalic_a , italic_b, as the values of ai,bisubscript𝑎𝑖subscript𝑏𝑖a_{i},b_{i}italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT can vary between different agents. This is better than the factor of 13/11131113/1113 / 11 for general instances. We achieve these results by leveraging the Heterogeneous First Fit Decreasing (HFFD) algorithm of Huang and Lu (2021). The HFFD algorithm is a heterogeneous variant of the classic First Fit Decreasing (FFD) algorithm used in the bin packing problem (Johnson, 1973), with an approximation factor proven to be 13/11131113/1113 / 11 (Huang and Segal-Halevi, 2023). As in previous works on MMS, the algorithm is straightforward; however, the novelty and challenge lie in the intricate analysis. For our first result, we extend the analysis of HFFD algorithm in (Huang and Segal-Halevi, 2023) to the ordinal approximation of MMS, providing an improved bound. Our second result demonstrates that the HFFD algorithm is optimal for factored instances. Our third result establishes that the HFFD algorithm attains a factor of 15/13151315/1315 / 13 for personalized bivalued instances through a detailed case analysis. Additionally, our approach results in polynomial-time algorithms for the second and third contributions, enabling the computation of an MMS allocation for factored instances and a 15/13151315/1315 / 13-MMS allocation for personalized bivalued instances in polynomial time. 1.2 Further related work Given the intense study of MMS notion and its variants, we focus on closely related work here. Computing the MMS value of an agent is NP-hard, even for two agents, using a straightforward reduction from the Partition problem. However, a Polynomial Time Approximation Scheme (PTAS) exists for this computation using a PTAS for the job scheduling problem (Hochbaum and Shmoys, 1987). However, for factored instances, MMS values can be computed in polynomial time (Ebadian et al., 2021). MMS allocations are not guaranteed to exist for more than two agents (Aziz et al., 2017; Feige et al., 2021), which has motivated the exploration of approximate MMS allocations to ensure their existence. For multiplicative approximation, a series of works (Aziz et al., 2017; Barman and Krishnamurthy, 2020; Huang and Lu, 2021; Huang and Segal-Halevi, 2023) have established the current best approximation factor of 13/11131113/1113 / 11. On the other hand, for ordinal approximation, research has progressed to show the existence of 1-out-of-⌊34⁢n⌋34𝑛\lfloor\frac{3}{4}n\rfloor⌊ divide start_ARG 3 end_ARG start_ARG 4 end_ARG italic_n ⌋ MMS allocations (Aigner-Horev and Segal-Halevi, 2022; Hosseini et al., 2022). For the special case of (non-personalized) bivalued instances, MMS allocations are known to exist (Feige, 2022). Goods The MMS notion can similarly be defined for the fair division of goods. Like the case of chores, MMS allocations for goods do not always exist (Kurokawa et al., 2018). Extensive research has been dedicated to approximate MMS allocations for goods. Notable works (Amanatidis et al., 2017; Ghodsi et al., 2018; Garg and Taki, 2021; Akrami et al., 2023; Hosseini and Searns, 2021; Hosseini et al., 2021a) have led to a multiplicative approximation factor of 3/4+3/383634338363/4+3/38363 / 4 + 3 / 3836 (Akrami and Garg, 2024) and an ordinal approximation factor of 1-out-of-4⁢⌊n/3⌋4𝑛34\lfloor n/3\rfloor4 ⌊ italic_n / 3 ⌋ (Akrami et al., 2024)."
https://arxiv.org/html/2411.04204v1,Online Budgeted Matching with General Bids,"Online Budgeted Matching (OBM) is a classic problem with important applications in online advertising, online service matching, revenue management, and beyond. Traditional online algorithms typically assume a small bid setting, where the maximum bid-to-budget ratio (κ𝜅\kappaitalic_κ) is infinitesimally small. While recent algorithms have tried to address scenarios with non-small or general bids, they often rely on the Fractional Last Matching (FLM) assumption, which allows for accepting partial bids when the remaining budget is insufficient. This assumption, however, does not hold for many applications with indivisible bids. In this paper, we remove the FLM assumption and tackle the open problem of OBM with general bids. We first establish an upper bound of 1−κ1𝜅1-\kappa1 - italic_κ on the competitive ratio for any deterministic online algorithm. We then propose a novel meta algorithm, called MetaAd, which reduces to different algorithms with first known provable competitive ratios parameterized by the maximum bid-to-budget ratio κ∈[0,1]𝜅01\kappa\in[0,1]italic_κ ∈ [ 0 , 1 ]. As a by-product, we extend MetaAd to the FLM setting and get provable competitive algorithms. Finally, we apply our competitive analysis to the design learning-augmented algorithms.","Online Budgeted Matching (OBM) with general bids is a fundamental online optimization problem that generalizes to many important settings, such as online bipartite matching and Adwords with equal bids [23]. It has applications in various domains, including online advertising, online resource allocation, and revenue management among others [5, 16, 32]. OBM is defined on a bipartite graph with a set of offline nodes (bidders) and a set of online nodes (queries). The task is to select an available offline node to match with an online query in each round. When an offline node is matched to an online node, a bid value is subtracted from the budget of the offline node, and a reward equal to the consumed budget is obtained. If the remaining budget of an offline node is less than the bid value of an online query, the offline node cannot be matched to the online query. The goal is to maximize the total reward throughout the entire online matching process. OBM is challenging due to the nature of online discrete decisions. Previous works have studied this problem under one of the following two additional assumptions on bids or matching rules: • Small bids. The small-bid assumption is a special case of general bids corresponding to the maximum bid-budget ratio κ→0→𝜅0\kappa\to 0italic_κ → 0. That is, while the bid values can vary arbitrarily, the size of each individual bid is infinitely small compared to each offline node’s budget, and there is always enough budget for matching. Under this assumption, the first online algorithm was provided by [24], achieving an optimal competitive ratio of 1−1/e11𝑒1-1/e1 - 1 / italic_e [23]. This competitive ratio has also been attained by subsequent algorithms based on primal-dual techniques [4, 7]. However, the small-bid assumption significantly limits these algorithms for broader applications in practice. Take the application of matching Virtual Machines (VMs) to physical servers as an example. An online VM request typically takes up a non-negligible fraction of the total computing units in a server. • Fractional last match (FLM). Under FLM, if an offline node has an insufficient budget for an online query, the offline node can still be matched to the query, obtaining a partial reward equal to the remaining budget. Given the limitations of small bids, some recent studies [15, 29, 30] have studied competitive algorithms for OBM with general bids by making the additional assumption of FLM. For example, under FLM, the greedy algorithm (Greedy) achieves a competitive ratio of 1/2121/21 / 2, while other studies [4, 15, 29, 30] aim to achieve a competitive ratio greater than 1/2121/21 / 2 under various settings and/or using randomized algorithms. Although FLM allows fractional matching of a query to an offline node with insufficient budgets, it essentially assumes that any bids are potentially divisible. This assumption may not hold in many real applications, e.g., allocating fractional physical resources to a VM can result in significant performance issues that render the allocation unacceptable, and charging a fractional advertising fee may not be allowed in online advertising. Despite its practical relevance and theoretical importance, OBM with general bids has remained a challenging open problem in the absence of the small-bid and FLM assumptions. Specifically, an offline node may have insufficient budget and cannot be matched to a later query with a large value, potentially causing large sub-optimality in the worst case. This issue does not apply to small bids, as the small-bid setting implies that insufficient budgets will never occur. Additionally, this challenge is alleviated in the FLM setting, where fractional matching in cases of insufficient budgets can reduce sub-optimality. Indeed, removing the small-bid and FLM assumptions fundamentally changes and add significant challenges to the problem of OBM [30]. To further highlight the intrinsic difficulty of OBM with general bids, we formally prove in Proposition 4.1 an upper bound of the competitive ratio, i.e., 1−κ1𝜅1-\kappa1 - italic_κ, achieved by any deterministic online algorithm, where κ∈[0,1]𝜅01\kappa\in[0,1]italic_κ ∈ [ 0 , 1 ] is the maximum bid-budget ratio. Contributions: In this paper, we address OBM without the small-bid or FLM assumptions and design a meta algorithm called MetaAd, which adapts to different algorithms with provable competitive ratios. To our knowledge, MetaAd is the first provable competitive algorithm for general bids without the FLM assumption. Specifically, MetaAd generates a discounted score for each offline node by a general discounting function, which is then used to select the offline node. The discounting function evaluates the degree of budget insufficiency given a bid-budget ratio κ∈[0,1]𝜅01\kappa\in[0,1]italic_κ ∈ [ 0 , 1 ], addressing the challenge of infeasible matching due to insufficient budgets. Given different discounting functions, MetaAd yields concrete algorithms, and their competitive ratios are derived from Theorem 4.2, established through a novel proof technique. We show that with small bids (i.e., κ→0→𝜅0\kappa\rightarrow 0italic_κ → 0), MetaAd recovers the optimal competitive ratio of 1−1e11𝑒1-\frac{1}{e}1 - divide start_ARG 1 end_ARG start_ARG italic_e end_ARG. Furthermore, we show that MetaAd, with discounting functions from the exponential and polynomial function classes, achieves a positive competitive ratio for κ∈[0,1)𝜅01\kappa\in[0,1)italic_κ ∈ [ 0 , 1 ). As an extension, we adapt the design of MetaAd to the FLM setting, resulting in a meta-algorithm with provable competitive ratios for κ∈[0,1]𝜅01\kappa\in[0,1]italic_κ ∈ [ 0 , 1 ] (Theorem 4.3). The framework of MetaAd potentially opens an interesting direction for exploring concrete discounting function designs that yield high competitive ratios for settings both with and without FLM. Finally, we apply our competitive analysis to the design of LOBM, a learning-augmented algorithm for OBM, which enhances average performance while still guaranteeing a competitive ratio (Theorem 5.1). We validate the empirical benefits of MetaAd and LOBM through numerical experiments on the applications of an online movie matching an VM placement on physical servers."
https://arxiv.org/html/2411.03973v1,Temporal Network Creation Games:The Impact of Non-Locality and Terminals,"We live in a world full of networks where our economy, our communication, and even our social life crucially depends on them. These networks typically emerge from the interaction of many entities, which is why researchers study agent-based models of network formation. While traditionally static networks with a fixed set of links were considered, a recent stream of works focuses on networks whose behavior may change over time. In particular, Bilò et al. (IJCAI 2023) recently introduced a game-theoretic network formation model that embeds temporal aspects in networks. More precisely, a network is formed by selfish agents corresponding to nodes in a given host network with edges having labels denoting their availability over time. Each agent strategically selects local, i.e., incident, edges to ensure temporal reachability towards everyone at low cost.In this work we set out to explore the impact of two novel conceptual features: agents are no longer restricted to creating incident edges, called the global setting, and agents might only want to ensure that they can reach a subset of the other nodes, called the terminal model. For both, we study the existence, structure, and quality of equilibrium networks. For the terminal model, we prove that many core properties crucially depend on the number of terminals. We also develop a novel tool that allows translating equilibrium constructions from the non-terminal model to the terminal model. For the global setting, we show the surprising result that equilibria in the global and the local model are incomparable and we establish a high lower bound on the Price of Anarchy of the global setting that matches the upper bound of the local model. This shows the counter-intuitive fact that allowing agents more flexibility in edge creation does not improve the quality of equilibrium networks. Finally, in contrast to Bilò et al. (IJCAI 2023) where the authors restrict the model to single labels per connection, all of our results hold for the restricted case and the generalized case where every edge can have multiple labels.","Networks are an integral part of our everyday lives, playing a key role in almost every aspect of human existence. Prominent examples include transportation networks (road networks, train tracks, airplaine routes, etc.), communication networks (e.g. the Internet), neural networks (both biological and artificial), biological networks (e.g. protein-protein interaction networks) and many more. With the growing digitization of society, networks, in particular communication networks and (online) social networks, came more and more into the focus of computer science research over the last decades. Many different topics have been studied ranging from the formation of social networks over information diffusion and generating synthetic social networks with real-world properties ; to uncover their underlying geometry . To understand how social networks (and many other types of networks) emerge, one must understand the mechanisms and principles that govern the formation of networks among several non-cooperative agents . This sparked the investigation of game-theoretic network formation models like the Network Creation Game (NCG) . In this model, selfish agents act as nodes of a network which can form costly connections to others to gain a central position in the arising network. In particular, each agent can build connections only locally, i.e., via creating incident edges. Since then, many variations and extensions of this model have been formulated and studied, e.g., variants with non-uniform edge cost ; ; ; , robustness considerations ; ; ; , or geometric aspects ; ; . Although all these models aim to capture time-dependent processes of network formation, in practice, they consider networks that, once formed, are static. This is in contrast to many real-world networks in which temporal aspects play a prominent role. We highlight two motivating examples to make this more evident. One example is the commercial airline network: each time an airline company wants to serve a new route, the company also has to take into account connecting flights with their corresponding departure and arrival times. Planning the routes carefully can ensure reachability: customers can get from any airport to any other airport by taking a sequence of flights, possibly of different airlines, with ascending departure and arrival times. Here, the airlines are the selfish agents that can establish new connections to enable their customers to travel anywhere. For another example, consider the supply chain network of companies that are participating in the production of a particular product X. Assume that company A wants to make product X and sell it. Unless company A owns every part of the production chain (which is highly unlikely in today’s world), they want to have a connection to other companies in order to send materials and use their means of production that are missing from their production chain. As such, they want to guarantee that they have the logistical infrastructure to send their parts to all other companies participating. But company A may want to combine deliveries. For example, load a vehicle with parts that goes to company B, and then the vehicle loads up parts from company B and moves them to company C. In order for this behaviour to be accurately portrayed, the scheduling of the connections must happen in ascending order (time-wise). Other examples of network formation that include temporal properties are scheduling problems in which jobs have an order of preferences, neural networks where neurons forming a chain are serially activated one after the other, navigation networks in which the travel time of roads changes over time (e.g. due to traffic, or roadblocks), as well as pathways in biological networks which are series of actions among molecules in a cell that lead to a certain product or a change in the cell. These examples motivate, that understanding network formation of temporal networks is crucial. Recently, made a first step towards incorporating temporal aspects into NCGs. In their model, the game is played on an underlying temporal host network that defines the time steps in which the bought edges will be available and each agent can only build incident edges. However, this setting might not be general enough to represent real-world networks. Let us consider our two previous motivating examples again. In the airline route network, the 5th Freedom Right111https://www.icao.int/Pages/freedomsAir.aspx allows airline companies to create connections among countries that do not necessarily include the country the airline is based at. Meanwhile, a company is not interested in reaching every possible destination in other countries, but it mainly serves the hubs and cities which are in high demand for its customers. Finally, an airline company may want to have multiple connections between two countries on each day. Similarly, in the supply chain network, company A will send parts to company B for processing and then may want to use its own transport vehicles to transfer the processed parts to company C afterwards. Additionally, company A may not need to have a connection to the whole supply chain network, but only to particular other companies. Finally, company A may want to establish more than one connection between two factories during a day, due to a multitude of logistical reasons. In this work, we extend the model by to cope with the three raised issues. First, we introduce the terminal model in which nodes want to reach only a subset of the nodes, called terminals. The second addition is the global setting in which we allow each agent to build connections anywhere in the network, i.e., agents can create non-incident edges. Finally, in contrast to where the authors restrict the model to single labels per connection, we study the restricted case and also generalize to multiple labels per connection. Before giving an overview of our contribution, we introduce our model and some notation. 1.1. Model and Notation We first introduce temporal graphs, then we move on to the game-theoretic definition of our model. Temporal Graphs and Temporal Spanners A temporal graph G=(VG,EG,λG)𝐺subscript𝑉𝐺subscript𝐸𝐺subscript𝜆𝐺G=(V_{G},E_{G},\lambda_{G})italic_G = ( italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) consists of a set of nodes VGsubscript𝑉𝐺V_{G}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT, a set of undirected edges EG⊆{{u,v}⊆VG∣u≠v}subscript𝐸𝐺conditional-set𝑢𝑣subscript𝑉𝐺𝑢𝑣E_{G}\subseteq\{\{u,v\}\subseteq V_{G}\mid u\neq v\}italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ⊆ { { italic_u , italic_v } ⊆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ∣ italic_u ≠ italic_v }, and a labeling function λG:EG→P⁢(ℕ)∖∅:subscript𝜆𝐺→subscript𝐸𝐺𝑃ℕ\lambda_{G}\colon E_{G}\rightarrow P(\mathds{N})\setminus\emptysetitalic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT : italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT → italic_P ( blackboard_N ) ∖ ∅, where, for each edge e∈EH𝑒subscript𝐸𝐻e\in E_{H}italic_e ∈ italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, the term λG⁢(e)subscript𝜆𝐺𝑒\lambda_{G}(e)italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) denotes the set of time labels of e𝑒eitalic_e. Informally, the labeling function λGsubscript𝜆𝐺\lambda_{G}italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT describes the time steps in which edge e𝑒eitalic_e is available. We sometimes write λG⁢(e)+csubscript𝜆𝐺𝑒𝑐\lambda_{G}(e)+citalic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) + italic_c for some c∈ℕ𝑐ℕc\in\mathds{N}italic_c ∈ blackboard_N to denote the set {λ+c∣λ∈λG⁢(e)}conditional-set𝜆𝑐𝜆subscript𝜆𝐺𝑒\{\lambda+c\mid\lambda\in\lambda_{G}(e)\}{ italic_λ + italic_c ∣ italic_λ ∈ italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) }. We define the set ΛGsubscriptΛ𝐺\Lambda_{G}roman_Λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT of time edges as the set of tuples of edges and each of their time labels, i.e. ΛG≔{(e,λ)∣e∈EG,λ∈λG⁢(e)}≔subscriptΛ𝐺conditional-set𝑒𝜆formulae-sequence𝑒subscript𝐸𝐺𝜆subscript𝜆𝐺𝑒\Lambda_{G}\coloneqq\{(e,\lambda)\mid e\in E_{G},\lambda\in\lambda_{G}(e)\}roman_Λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ≔ { ( italic_e , italic_λ ) ∣ italic_e ∈ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_λ ∈ italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) }. For nodes u,v∈VG𝑢𝑣subscript𝑉𝐺u,v\in V_{G}italic_u , italic_v ∈ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT and a time label λ𝜆\lambdaitalic_λ, we sometimes abuse notation and write (u,v,λ)𝑢𝑣𝜆(u,v,\lambda)( italic_u , italic_v , italic_λ ) instead of ({u,v},λ)𝑢𝑣𝜆(\{u,v\},\lambda)( { italic_u , italic_v } , italic_λ ). Furthermore, we call the largest label λGm⁢a⁢x≔maxe∈EG⁡maxλ∈λG⁢(e)⁡λ≔subscriptsuperscript𝜆𝑚𝑎𝑥𝐺subscript𝑒subscript𝐸𝐺subscript𝜆subscript𝜆𝐺𝑒𝜆\lambda^{max}_{G}\coloneqq\max_{e\in E_{G}}\max_{\lambda\in\lambda_{G}(e)}\lambdaitalic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ≔ roman_max start_POSTSUBSCRIPT italic_e ∈ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_λ ∈ italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) end_POSTSUBSCRIPT italic_λ the lifetime of G𝐺Gitalic_G. If the graph G𝐺Gitalic_G is clear from context, we might omit the subscript G𝐺Gitalic_G to enhance readability. We call a temporal graph simple if there is exactly one time label on each edge. For simple graphs G𝐺Gitalic_G, we sometimes treat λG⁢(e)subscript𝜆𝐺𝑒\lambda_{G}(e)italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) as a number instead of a set for easier notation. A temporal path is a sequence of nodes v0,…,vℓ∈Vsubscript𝑣0…subscript𝑣ℓ𝑉v_{0},\dots,v_{\ell}\in Vitalic_v start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , … , italic_v start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ∈ italic_V that form a path in G𝐺Gitalic_G, such that there exists an increasing sequence of time labels λ0≤⋯≤λℓ−1subscript𝜆0⋯subscript𝜆ℓ1\lambda_{0}\leq\dots\leq\lambda_{\ell-1}italic_λ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ≤ ⋯ ≤ italic_λ start_POSTSUBSCRIPT roman_ℓ - 1 end_POSTSUBSCRIPT with λi∈λ⁢({vi,vi+1})subscript𝜆𝑖𝜆subscript𝑣𝑖subscript𝑣𝑖1\lambda_{i}\in\lambda(\{v_{i},v_{i+1}\})italic_λ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_λ ( { italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT } ) for every i=0,…,ℓ−1𝑖0…ℓ1i=0,\ldots,\ell-1italic_i = 0 , … , roman_ℓ - 1. We define ℓℓ\ellroman_ℓ to be the length of the temporal path. Note that we do not require the labels on the temporal path to increase strictly. We say that a node u∈VG𝑢subscript𝑉𝐺u\in V_{G}italic_u ∈ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT reaches v∈VG𝑣subscript𝑉𝐺v\in V_{G}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT if there is a temporal path from u𝑢uitalic_u to v𝑣vitalic_v in G𝐺Gitalic_G. Observe that, even though the edges are undirected, a temporal path from u𝑢uitalic_u to v𝑣vitalic_v does not necessarily imply the existence of a temporal path from v𝑣vitalic_v to u𝑢uitalic_u. Moreover, we define RG⁢(v)⊆VGsubscript𝑅𝐺𝑣subscript𝑉𝐺R_{G}(v)\subseteq V_{G}italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) ⊆ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT as the set of nodes that node v𝑣vitalic_v can reach in G𝐺Gitalic_G. We call the graph G𝐺Gitalic_G temporally connected if RG⁢(v)=VGsubscript𝑅𝐺𝑣subscript𝑉𝐺R_{G}(v)=V_{G}italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) = italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT for every node v∈VG𝑣subscript𝑉𝐺v\in V_{G}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. We define a temporal host graph with terminals (or host graph for short) as H=(VH,EH,λH,TH)𝐻subscript𝑉𝐻subscript𝐸𝐻subscript𝜆𝐻subscript𝑇𝐻H=(V_{H},E_{H},\lambda_{H},T_{H})italic_H = ( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ), where (VH,EH,λH)subscript𝑉𝐻subscript𝐸𝐻subscript𝜆𝐻(V_{H},E_{H},\lambda_{H})( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) is a complete temporal graph, i.e. EH={{u,v}⊆VH∣u≠v}subscript𝐸𝐻conditional-set𝑢𝑣subscript𝑉𝐻𝑢𝑣E_{H}=\{\{u,v\}\subseteq V_{H}\mid u\neq v\}italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT = { { italic_u , italic_v } ⊆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ∣ italic_u ≠ italic_v }, while TH⊆VHsubscript𝑇𝐻subscript𝑉𝐻T_{H}\subseteq V_{H}italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ⊆ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is a set of terminal nodes (or terminals), which is the same for all agents. W.l.o.g., we assume that, for every τ=1,…,λHmax𝜏1…superscriptsubscript𝜆𝐻\tau=1,\ldots,\lambda_{H}^{\max}italic_τ = 1 , … , italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT, there is an edge e∈EH𝑒subscript𝐸𝐻e\in E_{H}italic_e ∈ italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT with τ∈λH⁢(e)𝜏subscript𝜆𝐻𝑒\tau\in\lambda_{H}(e)italic_τ ∈ italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_e ).222Indeed, as long as some value of τ𝜏\tauitalic_τ, with 1≤τ≤λHmax1𝜏superscriptsubscript𝜆𝐻1\leq\tau\leq\lambda_{H}^{\max}1 ≤ italic_τ ≤ italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT, is missing, we can decrease by 1 all the edge labels that are strictly larger than τ𝜏\tauitalic_τ. A temporal subgraph of H𝐻Hitalic_H is a temporal graph G𝐺Gitalic_G such that (VG,EG)subscript𝑉𝐺subscript𝐸𝐺(V_{G},E_{G})( italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ) is a subgraph of (VH,EH)subscript𝑉𝐻subscript𝐸𝐻(V_{H},E_{H})( italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT , italic_E start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) and λG⁢(e)⊆λH⁢(e)subscript𝜆𝐺𝑒subscript𝜆𝐻𝑒\lambda_{G}(e)\subseteq\lambda_{H}(e)italic_λ start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_e ) ⊆ italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_e ) for every e∈EG𝑒subscript𝐸𝐺e\in E_{G}italic_e ∈ italic_E start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT. A terminal spanner of H𝐻Hitalic_H is a temporal subgraph G𝐺Gitalic_G of H𝐻Hitalic_H, with VG=VHsubscript𝑉𝐺subscript𝑉𝐻V_{G}=V_{H}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, where every node reaches all the terminals, i.e., TH⊆RG⁢(v)subscript𝑇𝐻subscript𝑅𝐺𝑣T_{H}\subseteq R_{G}(v)italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ⊆ italic_R start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT ( italic_v ) for every v∈VH𝑣subscript𝑉𝐻v\in V_{H}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. Note that each terminal also needs to reach all the other terminals. Furthermore, for k=n𝑘𝑛k=nitalic_k = italic_n this is the definition of a temporal spanner. Game-Theoretic Model We introduce the game-theoretic model that we study in this paper. Let H𝐻Hitalic_H be a temporal host graph with terminals that serves as a host graph for our game. Each node v∈VH𝑣subscript𝑉𝐻v\in V_{H}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT is a selfish agent whose strategy Sv⊆ΛHsubscript𝑆𝑣subscriptΛ𝐻S_{v}\subseteq\Lambda_{H}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ⊆ roman_Λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT corresponds to the set of time edges that agent v𝑣vitalic_v buys. We distinguish two settings: Global edge-buying, where agents have no restrictions on the time edges they can buy, and local edge-buying where agents can only buy incident time edges, i.e. Sv⊆{({v,u},λ)∣u∈VH∖{v}}subscript𝑆𝑣conditional-set𝑣𝑢𝜆𝑢subscript𝑉𝐻𝑣S_{v}\subseteq\{(\{v,u\},\lambda)\mid u\in V_{H}\setminus\{v\}\}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ⊆ { ( { italic_v , italic_u } , italic_λ ) ∣ italic_u ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ∖ { italic_v } }. We denote by 𝐬=⋃v∈VH{(v,Sv)}𝐬subscript𝑣subscript𝑉𝐻𝑣subscript𝑆𝑣\mathbf{s}=\bigcup_{v\in V_{H}}\{(v,S_{v})\}bold_s = ⋃ start_POSTSUBSCRIPT italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) } the strategy profile and by G⁢(𝐬)𝐺𝐬G(\mathbf{s})italic_G ( bold_s ) the temporal graph formed by the agents. Formally, the graph G⁢(𝐬)𝐺𝐬G(\mathbf{s})italic_G ( bold_s ) is a temporal subgraph of H𝐻Hitalic_H with VG=VHsubscript𝑉𝐺subscript𝑉𝐻V_{G}=V_{H}italic_V start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT = italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT and ΛG⁢(𝐬)=⋃(v,Sv)∈𝐬SvsubscriptΛ𝐺𝐬subscript𝑣subscript𝑆𝑣𝐬subscript𝑆𝑣\Lambda_{G(\mathbf{s})}=\bigcup_{(v,S_{v})\in\mathbf{s}}S_{v}roman_Λ start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT = ⋃ start_POSTSUBSCRIPT ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) ∈ bold_s end_POSTSUBSCRIPT italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT. Note that EG⁢(𝐬)subscript𝐸𝐺𝐬E_{G(\mathbf{s})}italic_E start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT and λG⁢(𝐬)subscript𝜆𝐺𝐬\lambda_{G(\mathbf{s})}italic_λ start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT are implicitly defined when ΛG⁢(𝐬)subscriptΛ𝐺𝐬\Lambda_{G(\mathbf{s})}roman_Λ start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT is known. In figures, we sometimes display edges as directed to illustrate the edge ownership. Such edges are bought by the node they originate in and can still be used in both direction for the purpose of temporal reachability. In the global setting this simplification does not always work. In this case we write onto the edge who buys it. For simple temporal graphs we sometimes talk about buying edges instead of time edges as they are equivalent in this case. Each agent v∈VH𝑣subscript𝑉𝐻v\in V_{H}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT aims at reaching all terminals while buying as few time edges as possible. Formally, agent v𝑣vitalic_v wants to minimize its costs given by cH⁢(v,𝐬)subscript𝑐𝐻𝑣𝐬\displaystyle c_{H}(v,\mathbf{s})italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ) =|Sv|+C⋅|T∖RG⁢(𝐬)⁢(v)|.absentsubscript𝑆𝑣⋅𝐶𝑇subscript𝑅𝐺𝐬𝑣\displaystyle=|S_{v}|+C\cdot|T\setminus R_{G(\mathbf{s})}(v)|.= | italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT | + italic_C ⋅ | italic_T ∖ italic_R start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT ( italic_v ) | . where C>1𝐶1C>1italic_C > 1 is a large constant ensuring that reaching any terminal is more beneficial than not buying a single edge. Indeed, as H𝐻Hitalic_H is a complete temporal graph, each agent v𝑣vitalic_v can always reach all terminals in THsubscript𝑇𝐻T_{H}italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT by buying, for example, an arbitrary time edge for each edge of the form {v,u}𝑣𝑢\{v,u\}{ italic_v , italic_u }, with u∈TH𝑢subscript𝑇𝐻u\in T_{H}italic_u ∈ italic_T start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. We call the defined models global edge-buying k𝑘kitalic_k-terminal Temporal Network Creation Game (global k𝑘kitalic_k-tNCG) and local edge-buying k𝑘kitalic_k-terminal Temporal Network Creation Game (local k𝑘kitalic_k-tNCG), respectively. Before defining the solution concepts, we need some more notation regarding strategies. Let 𝐬𝐬\mathbf{s}bold_s be a strategy profile and consider any agent v∈VH𝑣subscript𝑉𝐻v\in V_{H}italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT. We define 𝐬−v≔𝐬∖{(v,Sv)}≔subscript𝐬𝑣𝐬𝑣subscript𝑆𝑣\mathbf{s}_{-v}\coloneqq\mathbf{s}\setminus\{(v,S_{v})\}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT ≔ bold_s ∖ { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ) } as the strategy profile without the strategy of agent v𝑣vitalic_v. Now, consider an alternative strategy Sv′≠Svsuperscriptsubscript𝑆𝑣′subscript𝑆𝑣S_{v}^{\prime}\neq S_{v}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ≠ italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT for agent v𝑣vitalic_v. We denote by 𝐬−v∪Sv′subscript𝐬𝑣superscriptsubscript𝑆𝑣′\mathbf{s}_{-v}\cup S_{v}^{\prime}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT ∪ italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT the strategy profile 𝐬−v∪{(v,Sv′)}subscript𝐬𝑣𝑣superscriptsubscript𝑆𝑣′\mathbf{s}_{-v}\cup\{(v,S_{v}^{\prime})\}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT ∪ { ( italic_v , italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) }. If cH⁢(v,𝐬−v∪Sv′)<cH⁢(v,𝐬)subscript𝑐𝐻𝑣subscript𝐬𝑣superscriptsubscript𝑆𝑣′subscript𝑐𝐻𝑣𝐬c_{H}(v,\mathbf{s}_{-v}\cup S_{v}^{\prime})<c_{H}(v,\mathbf{s})italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT ∪ italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) < italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ), we say that 𝐬−v∪Sv′subscript𝐬𝑣superscriptsubscript𝑆𝑣′\mathbf{s}_{-v}\cup S_{v}^{\prime}bold_s start_POSTSUBSCRIPT - italic_v end_POSTSUBSCRIPT ∪ italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is an improving response for v𝑣vitalic_v (w.r.t. 𝐬𝐬\mathbf{s}bold_s). If additionally, the strategies Svsubscript𝑆𝑣S_{v}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT and Sv′superscriptsubscript𝑆𝑣′S_{v}^{\prime}italic_S start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT differ by at most one element (i.e. v𝑣vitalic_v either adds or removes a single time edge), we call this a greedy improving response333Note that, in the literature , a greedy improving response also allows a swap, i.e. removing one edge and adding one edge simultaneously. However, in our game, every improving response consisting of a swap also implies an improving response that only adds an edge and omits the remove part. This is because a swap is an improving response for an agent only when the number of reached terminals increases. This means, we can disregard swaps for our definition of greedy improving responses.. We call 𝐬𝐬\mathbf{s}bold_s a best response of agent v𝑣vitalic_v (resp., a greedy best response) if there is no improving response (resp., greedy improving response) for agent v𝑣vitalic_v. We can now introduce our solution concepts. A strategy profile 𝐬𝐬\mathbf{s}bold_s is a Pure Nash Equilibrium (NE) (resp., Greedy Equilibrium (GE)) if no agent has an improving response (resp., greedy improving response). As every greedy improving response is also an improving response, we have that every NE is also a GE. Furthermore, every NE (and thus every GE) guarantees pairwise disjoint strategies, since any agent can trivially remove the intersection of its strategy and some other agent’s strategy without affecting its reachability. Moreover, our definition of the cost function directly implies that the created graph G⁢(𝐬)𝐺𝐬G(\mathbf{s})italic_G ( bold_s ) must be a terminal spanner. Lastly, we introduce a measure for the well-being of all agents combined. Let H𝐻Hitalic_H be a host graph and let 𝐬𝐬\mathbf{s}bold_s be any strategy profile. The social cost of 𝐬𝐬\mathbf{s}bold_s on H𝐻Hitalic_H is then defined as SCH⁡(𝐬)=∑v∈VHcH⁢(v,𝐬).subscriptSC𝐻𝐬subscript𝑣subscript𝑉𝐻subscript𝑐𝐻𝑣𝐬\displaystyle\operatorname{SC}_{H}(\mathbf{s})=\sum_{v\in V_{H}}c_{H}(v,% \mathbf{s}).roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) = ∑ start_POSTSUBSCRIPT italic_v ∈ italic_V start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_c start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_v , bold_s ) . Note that SCH⁡(𝐬)=|ΛG⁢(𝐬)|subscriptSC𝐻𝐬subscriptΛ𝐺𝐬\operatorname{SC}_{H}(\mathbf{s})=|\Lambda_{G(\mathbf{s})}|roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) = | roman_Λ start_POSTSUBSCRIPT italic_G ( bold_s ) end_POSTSUBSCRIPT | for every NE or GE 𝐬𝐬\mathbf{s}bold_s. A strategy profile of minimum social cost for the given host graph H𝐻Hitalic_H is called social optimum and denoted as 𝐬H∗superscriptsubscript𝐬𝐻\mathbf{s}_{H}^{*}bold_s start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT. When considering the efficiency of equilibria, we will compare their social costs to the social optimum. For n,k∈ℕ𝑛𝑘ℕn,k\in\mathds{N}italic_n , italic_k ∈ blackboard_N with k≤n𝑘𝑛k\leq nitalic_k ≤ italic_n, let ℋn,ksubscriptℋ𝑛𝑘\mathcal{H}_{n,k}caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT be the set of all host graphs containing n𝑛nitalic_n nodes and k𝑘kitalic_k terminals. Furthermore, for a host graph H𝐻Hitalic_H, let 𝖭𝖤H𝗅𝗈subscriptsuperscript𝖭𝖤𝗅𝗈𝐻{\sf NE}^{\sf lo}_{H}sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, 𝖭𝖤H𝗀𝗅subscriptsuperscript𝖭𝖤𝗀𝗅𝐻{\sf NE}^{\sf gl}_{H}sansserif_NE start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT, 𝖦𝖤H𝗅𝗈subscriptsuperscript𝖦𝖤𝗅𝗈𝐻{\sf GE}^{\sf lo}_{H}sansserif_GE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT and 𝖦𝖤H𝗀𝗅subscriptsuperscript𝖦𝖤𝗀𝗅𝐻{\sf GE}^{\sf gl}_{H}sansserif_GE start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT be the sets of Nash Equilibria and Greedy Equilibria in the local edge-buying and the global edge-buying setting, respectively. We define the Price of Anarchy (PoA) for the local edge-buying setting with respect to Nash Equilibria as the ratio of the socially worst equilibrium and the social optimum 𝖯𝗈𝖠𝖭𝖤𝗅𝗈⁢(n,k)≔maxH∈ℋn,k⁡max𝐬∈𝖭𝖤H𝗅𝗈⁡SCH⁡(𝐬)SCH⁡(sH∗).≔subscriptsuperscript𝖯𝗈𝖠𝗅𝗈𝖭𝖤𝑛𝑘subscript𝐻subscriptℋ𝑛𝑘subscript𝐬subscriptsuperscript𝖭𝖤𝗅𝗈𝐻subscriptSC𝐻𝐬subscriptSC𝐻subscriptsuperscript𝑠𝐻\displaystyle{\sf PoA}^{\sf lo}_{\sf NE}(n,k)\coloneqq\max_{H\in\mathcal{H}_{n% ,k}}\max_{\mathbf{s}\in{\sf NE}^{\sf lo}_{H}}\frac{\operatorname{SC}_{H}(% \mathbf{s})}{\operatorname{SC}_{H}(s^{*}_{H})}.sansserif_PoA start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT ( italic_n , italic_k ) ≔ roman_max start_POSTSUBSCRIPT italic_H ∈ caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT bold_s ∈ sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) end_ARG start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_s start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) end_ARG . We define 𝖯𝗈𝖠𝖭𝖤𝗀𝗅subscriptsuperscript𝖯𝗈𝖠𝗀𝗅𝖭𝖤{\sf PoA}^{\sf gl}_{\sf NE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT, 𝖯𝗈𝖠𝖦𝖤𝗅𝗈subscriptsuperscript𝖯𝗈𝖠𝗅𝗈𝖦𝖤{\sf PoA}^{\sf lo}_{\sf GE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT, and 𝖯𝗈𝖠𝖦𝖤𝗀𝗅subscriptsuperscript𝖯𝗈𝖠𝗀𝗅𝖦𝖤{\sf PoA}^{\sf gl}_{\sf GE}sansserif_PoA start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT analogously. If a result holds for both settings (local and global), we omit the superscript. If a result holds for both GE and NE, we omit the subscript. Lastly, we define the Price of Stability as 𝖯𝗈𝖲𝖭𝖤𝗅𝗈⁢(n,k)≔maxH∈ℋn,k⁡min𝐬∈𝖭𝖤H𝗅𝗈⁡SCH⁡(𝐬)SCH⁡(sH∗).≔subscriptsuperscript𝖯𝗈𝖲𝗅𝗈𝖭𝖤𝑛𝑘subscript𝐻subscriptℋ𝑛𝑘subscript𝐬subscriptsuperscript𝖭𝖤𝗅𝗈𝐻subscriptSC𝐻𝐬subscriptSC𝐻subscriptsuperscript𝑠𝐻\displaystyle{\sf PoS}^{\sf lo}_{\sf NE}(n,k)\coloneqq\max_{H\in\mathcal{H}_{n% ,k}}\min_{\mathbf{s}\in{\sf NE}^{\sf lo}_{H}}\frac{\operatorname{SC}_{H}(% \mathbf{s})}{\operatorname{SC}_{H}(s^{*}_{H})}.sansserif_PoS start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT ( italic_n , italic_k ) ≔ roman_max start_POSTSUBSCRIPT italic_H ∈ caligraphic_H start_POSTSUBSCRIPT italic_n , italic_k end_POSTSUBSCRIPT end_POSTSUBSCRIPT roman_min start_POSTSUBSCRIPT bold_s ∈ sansserif_NE start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT end_POSTSUBSCRIPT divide start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( bold_s ) end_ARG start_ARG roman_SC start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ( italic_s start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT ) end_ARG . Again, we define 𝖯𝗈𝖲𝖭𝖤𝗀𝗅subscriptsuperscript𝖯𝗈𝖲𝗀𝗅𝖭𝖤{\sf PoS}^{\sf gl}_{\sf NE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT, 𝖯𝗈𝖲𝖦𝖤𝗅𝗈subscriptsuperscript𝖯𝗈𝖲𝗅𝗈𝖦𝖤{\sf PoS}^{\sf lo}_{\sf GE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_lo end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT, and 𝖯𝗈𝖲𝖦𝖤𝗀𝗅subscriptsuperscript𝖯𝗈𝖲𝗀𝗅𝖦𝖤{\sf PoS}^{\sf gl}_{\sf GE}sansserif_PoS start_POSTSUPERSCRIPT sansserif_gl end_POSTSUPERSCRIPT start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT analogously. 1.2. Our Contribution (local n𝑛nitalic_n-)TNCG local k𝑘kitalic_k-TNCG global k𝑘kitalic_k-TNCG Optimum min temporal spanner min terminal spanner min terminal spanner Equilibria λm⁢a⁢x=2::superscript𝜆𝑚𝑎𝑥2absent\lambda^{max}=2\colonitalic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree m≤6⁢n32𝑚6superscript𝑛32m\leq\sqrt{6}n^{\frac{3}{2}}italic_m ≤ square-root start_ARG 6 end_ARG italic_n start_POSTSUPERSCRIPT divide start_ARG 3 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT λm⁢a⁢x=2::superscript𝜆𝑚𝑎𝑥2absent\lambda^{max}=2\colonitalic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree [2] k=2::𝑘2absentk=2\colonitalic_k = 2 :exists [2] m≤6⁢k⁢n+n𝑚6𝑘𝑛𝑛m\leq\sqrt{6k}n+nitalic_m ≤ square-root start_ARG 6 italic_k end_ARG italic_n + italic_n [3] λm⁢a⁢x=2::superscript𝜆𝑚𝑎𝑥2absent\lambda^{max}=2\colonitalic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT = 2 :spanning tree [2] k=2::𝑘2absentk=2\colonitalic_k = 2 :exists [2] GE: exists [2.2] PoA 𝒪⁢(n)𝒪𝑛\mathcal{O}(\sqrt{n})caligraphic_O ( square-root start_ARG italic_n end_ARG ) 𝒪⁢(λm⁢a⁢x)𝒪superscript𝜆𝑚𝑎𝑥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) Ω⁢(log⁡n)Ω𝑛\Omega(\log n)roman_Ω ( roman_log italic_n ) 𝖯𝗈𝖠𝖦𝖤≤𝒪⁢(log⁡(n))⁢𝖯𝗈𝖠𝖭𝖤subscript𝖯𝗈𝖠𝖦𝖤𝒪𝑛subscript𝖯𝗈𝖠𝖭𝖤{\sf PoA}_{\sf GE}\leq\mathcal{O}(\log(n)){\sf PoA}_{\sf NE}sansserif_PoA start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT ≤ caligraphic_O ( roman_log ( italic_n ) ) sansserif_PoA start_POSTSUBSCRIPT sansserif_NE end_POSTSUBSCRIPT 𝒪⁢(k)𝒪𝑘\mathcal{O}(\sqrt{k})caligraphic_O ( square-root start_ARG italic_k end_ARG ) [3] 𝒪⁢(λm⁢a⁢x)𝒪superscript𝜆𝑚𝑎𝑥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) [3] Ω⁢(log⁡k)Ω𝑘\Omega(\log k)roman_Ω ( roman_log italic_k ) [3] 𝒪⁢(k)𝒪𝑘\mathcal{O}(k)caligraphic_O ( italic_k ) [3] 𝒪⁢(λm⁢a⁢x)𝒪superscript𝜆𝑚𝑎𝑥\mathcal{O}(\lambda^{max})caligraphic_O ( italic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT ) [3] Ω⁢(k)Ω𝑘\Omega(\sqrt{k})roman_Ω ( square-root start_ARG italic_k end_ARG ) [3] 𝖯𝗈𝖠𝖦𝖤∈Θ⁢(k)subscript𝖯𝗈𝖠𝖦𝖤Θ𝑘{\sf PoA}_{\sf GE}\in\Theta(k)sansserif_PoA start_POSTSUBSCRIPT sansserif_GE end_POSTSUBSCRIPT ∈ roman_Θ ( italic_k )[3,3] PoS ? ? 1 (for GE) [3] Table 1. An overview of our results (yellow) and comparison with the existing results from . Here, n𝑛nitalic_n is the number of nodes, m𝑚mitalic_m the number of (time) edges, k𝑘kitalic_k the number of terminals, and λm⁢a⁢xsuperscript𝜆𝑚𝑎𝑥\lambda^{max}italic_λ start_POSTSUPERSCRIPT italic_m italic_a italic_x end_POSTSUPERSCRIPT the largest label in the host graph. The main contribution of this work is the generalization of the model introduced by and its game-theoretic analysis. We introduce the concepts of terminals, global edge-buying and multiple labels. To the best of our knowledge terminals have not been considered yet on any network creation model. While the terminal version is just a generalization of the normal model, we show that the global edge-buying leads to a completely different model with an incomparable set of equilibrium graphs. Our results for the generalized model work for both single label graphs and multi label graphs. Note that our techniques can be used to extend the results of to the multi label model. Table 1 gives an overview of our results in comparison with the results of . In Section 2, we study the structure and properties of equilibria. First, we introduce a special kind of graph product, see Section 2, that allows us to take any two host networks and respective equilibria and construct a new host graph together with a new equilibrium. This can then be used to construct lower bound examples for the PoA for a wide range of numbers of nodes n𝑛nitalic_n and numbers of terminals k𝑘kitalic_k by constructing only a few initial equilibria. Additionally, we show that, in the local setting, many structural properties of equilibria and bounds on the price of anarchy derived by that seemed to be dependent on the number of nodes in the graph are actually dependent on the number of terminals instead. Moreover, we show that for two terminals in the local and global setting, Greedy and Nash Equilibria always exist. We also show that for the global setting, Greedy Equilibrium graphs are exactly the set of inclusion minimal temporal spanners. We conclude the section by showing that the set of equilibrium graphs in the global setting are incomparable to the ones from the local setting. In Section 3, we analyze the efficiency of equilibria. For the global setting, many results carry over from the local setting but there are notable differences. Our findings show that allowing the agents to buy non-incident edges does not improve the efficiency of equilibria but in fact might make them even worse. For the case of Greedy Equilibria, we show that the PoA in the global setting is in Ω⁢(k)Ω𝑘\Omega(k)roman_Ω ( italic_k ), in contrast to the upper bound of O⁢(k)𝑂𝑘O(\sqrt{k})italic_O ( square-root start_ARG italic_k end_ARG ) that exists for the local setting. We also show that for Nash Equilibria, the PoA is in 𝒪⁢(k)𝒪𝑘\mathcal{O}(\sqrt{k})caligraphic_O ( square-root start_ARG italic_k end_ARG ) in the local setting, while it is in Ω⁢(k)Ω𝑘\Omega(\sqrt{k})roman_Ω ( square-root start_ARG italic_k end_ARG ) for the global setting. While it is still possible that those bounds match asymptotically, we conjecture that the actual PoA is much closer to the lower bound of Ω⁢(log⁡k)Ω𝑘\Omega(\log k)roman_Ω ( roman_log italic_k ) in the local setting. Simple Host Graphs As mentioned before, all our results also hold for the special case where the host graph is a simple temporal graph, i.e. every edge has exactly one time label. For all results from Section 2 to Figure 2 this is true since given simple host graphs, the constructions in turn admit simple host graphs. All remaining results are either general upper bounds/statements, and therefore, they also hold for the special case of simple graphs or constructions that are already simple graphs. 1.3. Related Work As mentioned in the introduction, this paper extends the temporal network creation game proposed by , which studies the all-pairs reachability in the local edge-buying model. In particular, in , the authors first prove the existence of NE for host graphs with lifetime λHmax=2superscriptsubscript𝜆𝐻2\lambda_{H}^{\max}=2italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT = 2 and show that, for every host graph with lifetime λHmax≥2superscriptsubscript𝜆𝐻2\lambda_{H}^{\max}\geq 2italic_λ start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT start_POSTSUPERSCRIPT roman_max end_POSTSUPERSCRIPT ≥ 2, the problems of computing a best response strategy and the problem of deciding whether a strategy profile is a NE are both NP-hard. The authors then consider upper and lower bounds to the PoA w.r.t. both NE and GE. In particular, they show that the PoA w.r.t. NE is in between Ω⁢(log⁡n)Ω𝑛\Omega(\log n)roman_Ω ( roman_log italic_n ) and 𝒪⁢(n)𝒪𝑛\mathcal{O}(\sqrt{n})caligraphic_O ( square-root start_ARG italic_n end_ARG ). Moreover, they connect GE with NE by showing that the PoA w.r.t. GE is no more than a 𝒪⁢(log⁡n)𝒪𝑛\mathcal{O}(\log n)caligraphic_O ( roman_log italic_n ) factor away the PoA w.r.t. NE. Besides the paper by which, to the best of our knowledge, is the only one that combines temporal aspects with network formation games, there has been an extensive line of research on related games in the last decades. One of the earliest models which is close to our work is by , where selfish agents buy incident edges and their utility increases with the number of agents they can reach while it decreases with the number of edges bought. For the version where undirected edges are formed, the authors prove that equilibria always exist forming either stars or empty graphs, and that improving response dynamics quickly converge to such states. They also show how to efficiently compute a best response strategy as well as deciding if a given state is in equilibrium. extended this model to a setting with attacks on the formed network, where the objective is to maintain post-attack reachability. This variant is more complex, yet proved that best response strategies can still be computed efficiently. Recently, studied a variant where the attacks are probabilistic. studied the different, yet related, topology control game, where the agents are points in the plane and edge costs are proportional to the Euclidean distance between the endpoints. A similar game was studied by , with the difference that agents are points in hyperbolic space and using greedy routing. Regarding the idea of using global edge-buying in network creation games, the model by is related. There, coalitions of agents can buy costshares of any edge in the network. From a centralized algorithmic perspective, starting from the work by , a lot of research has been devoted to the problem of computing sparse spanners in temporal graphs. More precisely, temporal cliques admit sparse temporally connected spanners , even when we seek for all-pairs temporal paths of bounded length . In contrast, there exist very dense temporal graphs that are not complete whose temporal spanners are all dense . Closely related to the reachability problem, study the problem of finding the minimum number of labels required to achieve temporal connectivity in a graph."
https://arxiv.org/html/2411.03802v1,On the Decomposition of Differential Game,"To understand the complexity of the dynamic of learning in differential games, we decompose the game into components where the dynamic is well understood. One of the possible tools is Helmholtz’s theorem, which can decompose a vector field into a potential and a harmonic component. This has been shown to be effective in finite and normal-form games. However, applying Helmholtz’s theorem by connecting it with the Hodge theorem on ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT (which is the strategy space of differential game) is non-trivial due to the non-compactness of ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Bridging the dynamic-strategic disconnect through Hodge/Helmoltz’s theorem in differential games is then left as an open problem [LBR+19]. In this work, we provide two decompositions of differential games to answer this question: the first as an exact scalar potential part, a near vector potential part, and a non-strategic part; the second as a near scalar potential part, an exact vector potential part, and a non-strategic part. We show that scalar potential games coincide with potential games proposed by [MS96], where the gradient descent dynamic can successfully find the Nash equilibrium. For the vector potential game, we show that the individual gradient field is divergence-free, in which case the gradient descent dynamic may either be divergent or recurrent.","One of the most fundamental questions in game-theoretic learning is whether an uncoupled learning dynamic can ultimately achieve a stable equilibrium through repeated interactions among players. Specifically, in which games and under what conditions can players reach a stable state using learning algorithms such as gradient descent? This issue has gained significant attention, particularly as many advancements in machine learning have relied on gradient descent to optimize the parameters of neural networks, with objective functions that model non-cooperative games. Popular examples include adversarially generative networks [GPAM+20], federated learning [KMA+21, DK21], multi-agent reinforcement learning [Lit94, LWT+17], and any machine learning algorithm trained in an adversarial way. A notable result by [HMC03, HMC06] presents a negative finding, demonstrating that no uncoupled learning dynamics can converge to a Nash equilibrium in all games from any initial condition. This raises the critical question of which games a learning process can successfully converge to a Nash equilibrium and which games it cannot. In the case where the game is finite, or if the game is a normal-form game, this question can be partially answered by decomposing the game through Helmholtz’s theorem. When the number of strategies for each player is finite, or when the strategies considered are on a probability simplex, [COP10, LMP24] showed that a game can be decomposed into a potential game and a harmonic game. This decomposition categorizes finite games along a spectrum, ranging from players with fully aligned interests (represented by games containing only the potential component) to players with entirely conflicting interests (represented by games containing only the harmonic component). In potential games, where there exists a potential function to quantify how individual strategy changes affect collective utility, players can thus descent along the direction of the gradient of their utility functions, which is equivalent to collectively minimizing the potential function, to reach the Nash equilibrium. In normal form games, the harmonic game is shown to be incompressible, hence implying that common learning dynamics, such as the exponential weight, can lead to Poincaré recurrence [LMP24]. In differential games, where the strategies are assumed to be in ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT, applying Helmholtz’s theorem becomes non-straightforward. Different from the normal form games, where the utilities are multilinear and the strategies are naturally in a compact set, the utility of differential games can be much more complicated. Specifically, Helmholtz’s theorem operates in ℝ3superscriptℝ3{\mathbb{R}}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT, where the curl of the gradient field is still a vector field, which means naively applying Helmholtz’s theorem only gives a decomposition in ℝ3superscriptℝ3{\mathbb{R}}^{3}blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT. When n≥4𝑛4n\geq 4italic_n ≥ 4, the curl of the gradient field is no longer a vector field, and one then needs to leverage the Hodge Theorem to perform the decomposition on a manifold. Connecting and applying Hodge/Helmholtz decomposition on the manifolds is yet to be investigated. A direct sum decomposition, like those in finite games and normal-form games, remains open in differential games [LBR+19]. 1.1 Related works In finite games, where the number of strategies is finite for each player, [CMOP11] introduced a method to decompose a given game into a potential and harmonic component. This decomposition maps finite games into a spectrum of players having fully aligned interests (games with only the potential component), to players having completely conflicting interests (games with only the harmonic component). Follow-up works then develop different variants of decompositions for the finite games [CLZQ16, WLC17, LCH19, APSV22]. This decomposition framework is then extended to normal form games [LMP24], where classic no-regret algorithms such as exponential weights are known to be possibly chaotic [PPP17, MPP18, VGFP19]. Based on the decomposition of normal form games, [LMP24] provided a principled way to identify cycling behaviors of exponential weights. In differential games, [LBR+19] identified two classes of games based on the symmetric and skew-symmetric parts of the game’s Jacobian matrix. The games with the symmetric Jacobian matrix are identified to be potential games, while games with skew-symmetric Jacobian matrix are named Hamiltonian games, which are closely related to harmonic games. However, this is different from the direct sum decomposition results in finite and normal-form games. Specifically, given a game with individual gradient field g𝑔gitalic_g, it is impossible in general to find a potential game gpsubscript𝑔𝑝g_{p}italic_g start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT and a Hamiltonian game ghsubscript𝑔ℎg_{h}italic_g start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT such that g=gp+gh𝑔subscript𝑔𝑝subscript𝑔ℎg=g_{p}+g_{h}italic_g = italic_g start_POSTSUBSCRIPT italic_p end_POSTSUBSCRIPT + italic_g start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT. Classic gradient descent methods are known to be convergent for potential games, but they can be non-convergent for Hamiltonian games. They thus introduced symplectic gradient adjustment to find stable fixed points in differential games. They also remarked that connecting the differential-geometric Hodge/Helmholtz decomposition in differential games is left as an open problem. 1.2 Differential games We consider a differential game with M𝑀Mitalic_M players. Each player i𝑖iitalic_i has utility {ui:ℝn→ℝ}i=1Msuperscriptsubscriptconditional-setsubscript𝑢𝑖→superscriptℝ𝑛ℝ𝑖1𝑀\left\{u_{i}:\mathbb{R}^{n}\rightarrow\mathbb{R}\right\}_{i=1}^{M}{ italic_u start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → blackboard_R } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT and can play a strategy ωi∈ℝnisubscript𝜔𝑖superscriptℝsubscript𝑛𝑖\omega_{i}\in\mathbb{R}^{n_{i}}italic_ω start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT to maximize its utility. We denote the joint strategy as ω=(ω1,…,ωM)∈ℝn𝜔subscript𝜔1…subscript𝜔𝑀superscriptℝ𝑛\omega=\left(\omega_{1},\ldots,\omega_{M}\right)\in\mathbb{R}^{n}italic_ω = ( italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_ω start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ) ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT where ∑i=1Mni=nsuperscriptsubscript𝑖1𝑀subscript𝑛𝑖𝑛\sum_{i=1}^{M}n_{i}=n∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT italic_n start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_n. We also let ω−isubscript𝜔𝑖\omega_{-i}italic_ω start_POSTSUBSCRIPT - italic_i end_POSTSUBSCRIPT be the joint strategy of all players except for player i𝑖iitalic_i. To denote the individual components of ω𝜔\omegaitalic_ω, we write ω=(ω1,…,ωM)=(x1,…,xn)𝜔subscript𝜔1…subscript𝜔𝑀subscript𝑥1…subscript𝑥𝑛\omega=(\omega_{1},\ldots,\omega_{M})=(x_{1},\ldots,x_{n})italic_ω = ( italic_ω start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_ω start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ) = ( italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ). 1.3 Our contributions We identified two different inner products on the space of differential games, which allows us to apply the Helmholtz decomposition on the vector field space of the utility gradient. Similar to the decomposition of the finite games, we decompose the differential games into three parts, which enjoy different dynamic properties. However, different from the case of finite games, the differential games cannot be decomposed straightforwardly into a potential part and a harmonic part. This is due to the fact that the harmonic component is isomorphic to the de Rham cohomology of the manifold, which is zero when the differential k𝑘kitalic_k-form is with k=1𝑘1k=1italic_k = 1 and the manifold is ℝnsuperscriptℝ𝑛{\mathbb{R}}^{n}blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT. Instead, we identify a Vector Potential part of the differential games, which are similar to a harmonic game in many ways, such as the challenges it imposes on dynamical systems induced by gradient descent. Our two decompositions provide different interpretations of the space of differential games. In the first decomposition, the game is decomposed into an exact scalar potential part, a near vector potential part, and a non-strategic part. We show that the exact scalar potential part of the game is an exact potential game, and the vector potential part poses similar challenges to learning algorithms. Specifically, the standard gradient descent dynamic can exhibit non-convergent behaviors on the vector potential game. To relate the vector potential games and the Hamiltonian games, we show that a Hamiltonian game has to be a vector potential game, but not vice versa. In the second decomposition, the game is decomposed into a near scalar potential part, an exact vector potential part, and a non-strategic part. We show that the vector potential part of the game is flat on any local Nash equilibrium, which imposes significant challenges to first and second-order local Nash equilibrium finding algorithms."
https://arxiv.org/html/2411.03390v1,Six Candidates Suffice to Win a Voter Majority,"A cornerstone of social choice theory is Condorcet’s paradox which says that in an election where n𝑛nitalic_n voters rank m𝑚mitalic_m candidates it is possible that, no matter which candidate is declared the winner, a majority of voters would have preferred an alternative candidate. Instead, can we always choose a small committee of winning candidates that is preferred to any alternative candidate by a majority of voters?Elkind, Lang, and Saffidine raised this question and called such a committee a Condorcet winning set. They showed that winning sets of size 2222 may not exist, but sets of size logarithmic in the number of candidates always do. In this work, we show that Condorcet winning sets of size 6666 always exist, regardless of the number of candidates or the number of voters. More generally, we show that if α1−ln⁡α≥2k+1𝛼1𝛼2𝑘1\frac{\alpha}{1-\ln\alpha}\geq\frac{2}{k+1}divide start_ARG italic_α end_ARG start_ARG 1 - roman_ln italic_α end_ARG ≥ divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG, then there always exists a committee of size k𝑘kitalic_k such that less than an α𝛼\alphaitalic_α fraction of the voters prefer an alternate candidate. These are the first nontrivial positive results that apply for all k≥2𝑘2k\geq 2italic_k ≥ 2.Our proof uses the probabilistic method and the minimax theorem, inspired by recent work on approximately stable committee selection. We construct a distribution over committees that performs sufficiently well (when compared against any candidate on any small subset of the voters) so that this distribution must contain a committee with the desired property in its support.","Voting is a versatile model for the aggregation of individual preferences to reach a collective decision. Disparate situations, such as constituents choosing representatives, organizations hiring employees, judges choosing prize winners, and even friends choosing games to play, can all be understood as a group of voters choosing from a pool of candidates. Voting theory seeks to understand how winning candidates can be selected in a fair and representative manner. One of the longest known challenges with voting is Condorcet’s paradox, discovered by Nicolas de Condorcet around the French Revolution [dC85].111It is plausible that in early academic explorations of voting, 13th-century philosopher Ramon Llull had already discovered the possibility of this paradoxical situation [Llu83, HP00]. The paradox is that in an election where voters have ranked preferences over candidates, the preferences of the “majority” can be contradictory — no matter which candidate is declared the winner, a majority of the voters would have preferred another candidate. In fact, the contradiction can be even more dramatic, with “majority” replaced by a fraction arbitrarily close to 1. An illustrative example is when the voters have cyclic preferences as, for example, displayed in Table 1. v1subscript𝑣1v_{1}italic_v start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT v2subscript𝑣2v_{2}italic_v start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT v3subscript𝑣3v_{3}italic_v start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT v4subscript𝑣4v_{4}italic_v start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT v5subscript𝑣5v_{5}italic_v start_POSTSUBSCRIPT 5 end_POSTSUBSCRIPT v6subscript𝑣6v_{6}italic_v start_POSTSUBSCRIPT 6 end_POSTSUBSCRIPT 1 2 3 4 5 6 2 3 4 5 6 1 3 4 5 6 1 2 4 5 6 1 2 3 5 6 1 2 3 4 6 1 2 3 4 5 Table 1: An election where voters have cyclic preferences. The column headed with visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT represents the i𝑖iitalic_ith voter’s ranking of the candidates (labeled 1,2,…,612…61,2,\dots,61 , 2 , … , 6 from top to bottom). For each candidate, another candidate is preferred by every voter except one. Though it is impossible to always find a single candidate that is always preferred over the others by a majority (called a Condorcet winner), one hope is that relaxations of this condition are still possible to achieve. A natural relaxation arises in the setting of committee selection, where rather than choosing a single winner, the goal is to choose a committee of k𝑘kitalic_k winners. For example, a political system may have districts with multiple representatives, organizations may make many hires at once, and friends might play more than one game in an evening. Another view is that committee selection can be used as an filtering step in a process with more than one round, like primaries or runoffs, choosing interviewees for a position, or nominations for a prize. In this context, Elkind, Lang, and Saffidine [ELS11, ELS15] asked: is it always possible to find a small committee of candidates such that no other candidate is preferred by a majority of voters over each member of the committee? They called this committee-analogue of a Condorcet winner a Condorcet winning set, and defined the Condorcet dimension of an election as the size of its smallest Condorcet winning set. For example, the election depicted in Table 1 has Condorcet dimension 2, since any pair of diametrically opposite candidates such as {3,6}36\{3,6\}{ 3 , 6 } would be a Condorcet winning set. More generally, [ELS15] raised the following question for an arbitrary threshold of α𝛼\alphaitalic_α in place of 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG, and a target committee size k𝑘kitalic_k. Question 1 ([ELS15]). A committee S𝑆Sitalic_S is α𝛼\alphaitalic_α-undominated if for all candidates a∉S𝑎𝑆a\notin Sitalic_a ∉ italic_S, less than an α𝛼\alphaitalic_α fraction of voters prefer a𝑎aitalic_a over each member of S𝑆Sitalic_S. For what values of k∈ℤ+𝑘superscriptℤk\in\mathbb{Z}^{+}italic_k ∈ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT and α∈(0,1]𝛼01\alpha\in(0,1]italic_α ∈ ( 0 , 1 ] does every election have an α𝛼\alphaitalic_α-undominated committee of size k𝑘kitalic_k? In particular, we would like to know, for each k𝑘kitalic_k, what is the smallest α𝛼\alphaitalic_α for which α𝛼\alphaitalic_α-undominated committees of size k𝑘kitalic_k always exist (and, equivalently, for each α𝛼\alphaitalic_α, the smallest k𝑘kitalic_k such that these committees always exist). Condorcet’s paradox (or rather, its aformentioned generalization) shows that for k=1𝑘1k=1italic_k = 1 and any α𝛼\alphaitalic_α bounded away from 1, there are elections with no α𝛼\alphaitalic_α-undominated singleton candidates. For the threshold of α=12𝛼12\alpha=\frac{1}{2}italic_α = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, [ELS15] constructed instances with Condorcet dimension 3 by taking the Kronecker product of two elections with cyclic preferences (see Table 3). This construction can be easily extended to give a lower bound of 2k+12𝑘1\frac{2}{k+1}divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG on the smallest α𝛼\alphaitalic_α such that there always exists an α𝛼\alphaitalic_α-undominated committee of size k𝑘kitalic_k (see Appendix B). They also showed that an election with m𝑚mitalic_m candidates has Condorcet dimension at most ⌈log2⁡m⌉subscript2𝑚\lceil\log_{2}m\rceil⌈ roman_log start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_m ⌉; to see this, note that some candidate beats a majority of the other candidates, so we can iteratively add such a candidate to our committee and remove all the candidates that it beats. 1.1 Our Contributions We prove that every election has Condorcet dimension at most 6. This result is a corollary of our main theorem, which gives a nontrivial existence result for α𝛼\alphaitalic_α-undominated committees of size k≥2𝑘2k\geq 2italic_k ≥ 2. We note that the final result we prove (Theorem 5) is stronger, but we start with the approximation below as it is easier to get a handle on. (For a comparison, see Table 2.) Theorem 1. If α1−ln⁡α≥2k+1𝛼1𝛼2𝑘1\frac{\alpha}{1-\ln\alpha}\geq\frac{2}{k+1}divide start_ARG italic_α end_ARG start_ARG 1 - roman_ln italic_α end_ARG ≥ divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG, then in any election, there exists an α𝛼\alphaitalic_α-undominated committee of size k𝑘kitalic_k. For the specific threshold of α=12𝛼12\alpha=\frac{1}{2}italic_α = divide start_ARG 1 end_ARG start_ARG 2 end_ARG, Theorem 1 applies as long as k≥3+4⁢ln⁡2≈5.77𝑘3425.77k\geq 3+4\ln 2\approx 5.77italic_k ≥ 3 + 4 roman_ln 2 ≈ 5.77, and so any election has Condorcet dimension at most 6666 (which is not far from the lower bound of 3333). Taking k=2𝑘2k=2italic_k = 2, Theorem 1 implies that there always exists a pair of candidates such that no third candidate is preferred by more than roughly 80%percent8080\%80 % of the voters. Even replacing 80%percent8080\%80 % with 99%percent9999\%99 %, this was previously unknown. These results show that just by having a few winners instead of one, the most dramatic failures of Condorcet’s paradox are avoidable. We emphasize that these results hold for any election, regardless of the number of voters, the number of candidates, or the preferences that the voters have over candidates. Our starting point for proving Theorem 1 is the observation that 1 is closely linked to the problem of approximate stability in committee selection [JMW20]. The principle behind stability is that a subset of voters should have control over a subset of the committee of proportional size. That is, a committee of size k𝑘kitalic_k is stable (also referred to as in the core [Sca67, Fol70, FMS18]) if the fraction of voters that prefers any committee of size k′superscript𝑘′k^{\prime}italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is less than k′ksuperscript𝑘′𝑘\frac{k^{\prime}}{k}divide start_ARG italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_ARG start_ARG italic_k end_ARG. We note that in this setting, voters have preferences over committees rather than candidates. This more expressive space of preferences gives it the power to model a wide variety of preference structures, such as approval voting and participatory budgeting. Unfortunately, in many settings, stable committees do not always exist. To remedy this, [JMW20] put forth the following approximate notion of stability, and showed the surprising result that for any monotone preference structure and any k𝑘kitalic_k, a 32323232-stable committee of size k𝑘kitalic_k exists. Definition 1 (Approximately stable committees [JMW20]). A committee S𝑆Sitalic_S of k𝑘kitalic_k candidates is c𝑐citalic_c-stable if for any committee S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT of size k′superscript𝑘′k^{\prime}italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, the fraction of voters that prefers S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT over S𝑆Sitalic_S is less than c⋅k′k⋅𝑐superscript𝑘′𝑘c\cdot\frac{k^{\prime}}{k}italic_c ⋅ divide start_ARG italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_ARG start_ARG italic_k end_ARG. Consider the natural preference order over committees induced by rankings over candidates, where v𝑣vitalic_v prefers S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT over S𝑆Sitalic_S if and only if she prefers her favorite candidate in S′superscript𝑆′S^{\prime}italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT over her favorite in S𝑆Sitalic_S. A simple observation (explained more fully in Appendix A) shows that a committee of size k𝑘kitalic_k is c𝑐citalic_c-stable if and only if it is ck𝑐𝑘\frac{c}{k}divide start_ARG italic_c end_ARG start_ARG italic_k end_ARG-undominated. For this ranked preference structure, the constant of 32323232 in the result of [JMW20] can be improved to 16161616 using the existence of stable lotteries for these preferences [CJMW20]. Then, as a black box, [JMW20] implies that 16k16𝑘\frac{16}{k}divide start_ARG 16 end_ARG start_ARG italic_k end_ARG-undominated committees of size k𝑘kitalic_k always exist, which in turn implies that we can always find Condorcet winning sets of size at most 32323232. Since this conclusion follows easily from [JMW20], we attribute the first constant upper bound on the size of Condorcet winning sets to their work. One can interpret the approximately stable committee problem as a version of 1 focused on the asymptotics of α𝛼\alphaitalic_α as the committee size k𝑘kitalic_k grows large. For this purpose, [JMW20] implies a result that is optimal up to a constant factor, but it says nothing nontrivial for committees of size at most 16161616. In contrast, Theorem 1 gives results even for k=2𝑘2k=2italic_k = 2, and outperforms the bound implied by [JMW20] for k≤1.75×104𝑘1.75superscript104k\leq 1.75\times 10^{4}italic_k ≤ 1.75 × 10 start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT, despite only implying the existence of O⁢(log⁡k)𝑂𝑘O(\log k)italic_O ( roman_log italic_k )-stable committees. Nonetheless, we show that our techniques can be applied to the asymptotic setting as well, giving an improvement over [JMW20]. Theorem 2. In any election, there exists a 9.8217k9.8217𝑘\frac{9.8217}{k}divide start_ARG 9.8217 end_ARG start_ARG italic_k end_ARG-undominated committee of size k𝑘kitalic_k. As a corollary, Theorem 2 implies the existence of 9.82179.82179.82179.8217-stable committees for preferences induced by rankings over candidates. We note that Theorem 2 improves Theorem 1 for k≥496𝑘496k\geq 496italic_k ≥ 496. 1.2 Technical Overview Our approach, building on [JMW20], is to first construct a particular distribution over committees of size k𝑘kitalic_k, and then to show that by sampling from this distribution, the resulting committee is α𝛼\alphaitalic_α-undominated in expectation. In fact, [ELS15]’s proof that the existence of O⁢(log⁡m)𝑂𝑚O(\log m)italic_O ( roman_log italic_m ) size Condorcet winning committees in elections with m𝑚mitalic_m candidates can also be viewed through this framework. There, we can consider the uniform distribution over candidates. To construct the committee, we sample from this distribution, remove the candidates that are beaten, and recurse on the remaining candidates. In expectation, half of the candidates are removed in each round, so the algorithm is likely to end with a committee of O⁢(log⁡m)𝑂𝑚O(\log m)italic_O ( roman_log italic_m ) candidates. The greedy algorithm of choosing the candidate that beats the most others in each round can be viewed as derandomization via conditional expectation. In this light, a natural approach to improving the O⁢(log⁡m)𝑂𝑚O(\log m)italic_O ( roman_log italic_m ) guarantee is to find a better distribution over committees. One of the insights in [JMW20] was to construct this distribution via the equilibrium of a zero-sum game. In the game, the defender chooses a committee S𝑆Sitalic_S of size k𝑘kitalic_k, and the attacker chooses a candidate a𝑎aitalic_a. After the choices are made, the defender pays the attacker a dollar for each voter that prefers a𝑎aitalic_a over all members of S𝑆Sitalic_S. The optimal strategy for the defender is to choose a committee randomly according to some distribution, which [JMW20] call the stable lottery. Then to create a committee of size k𝑘kitalic_k, [JMW20] take a recursive approach. First, they sample a committee S𝑆Sitalic_S of size k/2𝑘2k/2italic_k / 2, and show that ignoring the 25% of voters that least like S𝑆Sitalic_S, any candidate a𝑎aitalic_a is preferred over S𝑆Sitalic_S by less than a 8k8𝑘\frac{8}{k}divide start_ARG 8 end_ARG start_ARG italic_k end_ARG fraction of the voters (which are treated as an irrevocable loss). In the next step, they recurse on the ignored voters, sample a committee of size k/4𝑘4k/4italic_k / 4, and lose less than another 4k4𝑘\frac{4}{k}divide start_ARG 4 end_ARG start_ARG italic_k end_ARG fraction of the voters against any candidate a𝑎aitalic_a. The committee size and fraction of voters we lose continue to decrease exponentially, and in the end we have a committee of size k𝑘kitalic_k such that less than 16k16𝑘\frac{16}{k}divide start_ARG 16 end_ARG start_ARG italic_k end_ARG voters prefer any candidate a𝑎aitalic_a. To prove Theorem 1, we introduce three twists into this framework. Two are part of how we set up the zero-sum game in order to construct a distribution over committees that individual candidates perform poorly against (Lemma 1), and one is in how we show that in expectation, a random committee sampled from the distribution performs well (Lemma 2 and 4). Improving the game by confining the adversary. First, we modify the setup of the game so that the adversary must choose both a candidate a𝑎aitalic_a and a subset U𝑈Uitalic_U of an α𝛼\alphaitalic_α fraction of the voters. The adversary then only gets paid for the voters in U𝑈Uitalic_U that prefer a𝑎aitalic_a over the committee S𝑆Sitalic_S. By tying the hands of the adversary in this way, we can drive down the value of the game, which gives a more favorable guarantee for the distribution over committees. Once we fix the distribution over committees (referred to by ΔΔ\Deltaroman_Δ), we measure the quality of a candidate a𝑎aitalic_a or committee S𝑆Sitalic_S with respect to a voter v𝑣vitalic_v with a crucial notion that we call the rank, denoted rankv⁡(a)subscriptrank𝑣𝑎\operatorname{rank}_{v}(a)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_a ) or rankv⁡(S)subscriptrank𝑣𝑆\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) (see Definition 3). Roughly speaking, this is simply the probability when we sample from ΔΔ\Deltaroman_Δ that we get a committee that is worse than a𝑎aitalic_a or S𝑆Sitalic_S in v𝑣vitalic_v’s preference. The activation function. The second twist is what we call the activation function g𝑔gitalic_g, which allows us freedom in how we measure each voter’s preferences for candidates and committees. This function may seem somewhat enigmatic in the proof, but here we try to give some rough intuition for the idea behind it. The initial observation is that by using versions of the zero-sum game with different committee sizes, we can construct distributions over committees of size k𝑘kitalic_k in a variety of ways. The simplest would be to take the optimal mixed strategy for the defender in the original game with committee size k𝑘kitalic_k, but we could also take the optimal strategy for size k/2𝑘2k/2italic_k / 2, sample twice from it and take the union. These different ways of constructing the distributions can actually be interpreted as attaching different activation functions to the defender’s distribution in the payoffs of the original game. For example, sampling twice from the k/2𝑘2k/2italic_k / 2 distribution is equivalent to attaching the function g⁢(x)=x𝑔𝑥𝑥g(x)=\sqrt{x}italic_g ( italic_x ) = square-root start_ARG italic_x end_ARG, and the reason corresponds to the fact that sampling two uniform reals from [0,1]01[0,1][ 0 , 1 ] and taking the max is equivalent to sampling one uniform real from [0,1]01[0,1][ 0 , 1 ] and taking the square root. In the end, thanks to the generality of the minimax theorem, the proof works for any non-constant, non-decreasing function g:[0,1]→ℝ≥0:𝑔→01subscriptℝabsent0g\colon[0,1]\to\mathbb{R}_{\geq 0}italic_g : [ 0 , 1 ] → blackboard_R start_POSTSUBSCRIPT ≥ 0 end_POSTSUBSCRIPT such that g⁢(xk)𝑔superscript𝑥𝑘g(x^{k})italic_g ( italic_x start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) is convex. These functions give a richer continuous space of options for modifying the game, some of which are not easily interpretable in terms of the intuition described above. Each choice of g𝑔gitalic_g gives a different bound for α𝛼\alphaitalic_α as a function of k𝑘kitalic_k, and so we can simply choose the function that gives the best guarantee. A one-shot approach with finer accounting of all voters. Third, we use a more precise approach for showing that some committee in the support of our distribution performs well, by diligently accounting for the contributions of each voter. In each step of [JMW20]’s recursion, when they sample committee S𝑆Sitalic_S, they consider for each voter v𝑣vitalic_v whether or not rankv⁡(S)subscriptrank𝑣𝑆\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) is above some threshold (called β𝛽\betaitalic_β, which is set to 1414\frac{1}{4}divide start_ARG 1 end_ARG start_ARG 4 end_ARG). The voters below the threshold are ignored, and then recursed on in the next iteration. There are two potential roadblocks in using this approach for small committee sizes. Intuitively, if we are aiming for a final committee size of around 6, the recursion cannot be very deep. Each iteration can only choose 2 or 3 candidates, for which the guarantee is insufficient. That is, the benefits of the recursion only kick in for sufficiently large committees, and for small committees, it is better to sample the whole committee in one shot (without recursion). Second, there is too much loss in evaluating each voter with a binary threshold, and without recursion, we need better accounting for voters with a low opinion of the committee. In Lemma 2 and 4, we give a smoother analysis, which allows us to more precisely account for the contributions of each voter. To give some rough intuition, what we would like to show is that there is some S𝑆Sitalic_S such that the total sum of rankv⁡(S)subscriptrank𝑣𝑆\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ) is large for any subset of an α𝛼\alphaitalic_α fraction of the voters. If we fix S𝑆Sitalic_S and plot each rankv⁡(S)subscriptrank𝑣𝑆\operatorname{rank}_{v}(S)roman_rank start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_S ), ordered from smallest to largest, it suffices to bound the area under the bottom α𝛼\alphaitalic_α fraction. It turns out that the worst case for these ranks (that minimizes the area for all S𝑆Sitalic_S) is not a step function with a sharp threshold, but rather a linear function with slope 1111 (akin to the cyclic preferences depicted in Table 1). Finally, to prove Theorem 2, we use our modifications in tandem with the recursive approach. In the proof of this theorem, the idea above that does the heavy lifting is the use of the activation function g𝑔gitalic_g. 1.3 Related Work Proportionality in committee selection. In the context of committee selection, the principle of proportionality says that large voter coalitions should have their preferences fairly represented — an idea that dates back to at least the 19th century [Dro81]. Since its advent, a substantial body of research has been dedicated to studying the possibility and implications of proportionality. One of the most widely studied models is approval voting, where voters express their preferences by selecting a subset of candidates they approve of. We refer the reader to a survey by Lackner and Skowron [LS23] for a detailed discussion on the topic. A key appeal of this model is that there are a wide variety of proportionality axioms such as justified representation (JR) [ABC+17] and its variants (for example, [FEL+17, BP23]) that are satisfied by natural rules (such as Proportional Approval Voting (Thiele’s rule) [Thi95, Kil10, ABC+17, PS20], Phragmén’s rule [Phr94, PS20], and the Method of Equal Shares [PS20, PPS21]). These ideas have also been impactful in practice, with for example, the historical use of Thiele’s rule and Phragmén’s rule [Jan16], and the recent successful implementation of the Method of Equal Shares for participatory budgeting in several European cities [PS]. Additionally, this line of work is driven forward by intriguing conjectures that even stronger axioms, such as core stability [ABC+17, FMS18], might be universally satisfiable as well. In comparison, proportionality in committee selection with ranked preferences is relatively under-explored. As [LS23] suggest, part of the challenge is that notions of proportionality in the approval setting do not always generalize to the ranking setting. (Or, like with core stability, the analogous axioms are not always satisfiable [CJMW20].) One particularly well studied class of rank-based committee selection rules is that of committee scoring rules [EFSS17]. These voting rules, which generalize scoring rules in the single-winner setting, capture several natural committee selection rules, and have been axiomatically characterized [FSST19, SFS19]. We refer the reader to [FSST17] for a more in-depth discussion. Committee analogues of Condorcet winners. Grappling with Condorcet’s paradox has been a major driving force in social choice theory, and naturally, other attempts have been made to extend the notion of Condorcet winners to the multi-winner setting. Fishburn [Fis81b, Fis81a] introduced the idea of a majority committee, defined as a committee preferred by a majority of voters over any other committee of the same size. The Smith set [Goo71, Smi73] S𝑆Sitalic_S is defined as the minimal committee such that for any a∉S𝑎𝑆a\notin Sitalic_a ∉ italic_S and b∈S𝑏𝑆b\in Sitalic_b ∈ italic_S, a majority of voters prefers b𝑏bitalic_b over a𝑎aitalic_a. Uncovered sets [Fis77, Mil80], bipartisan sets [LLLB93] (the support of maximal lotteries [Fis84]), and other tournament solutions [BBH16] can also be viewed as multi-winner generalizations of Condorcet winners. However, these notions face the same challenge as Condorcet winners: they either do not always exist or sometimes coincide with the entire (potentially large) set of candidates. As in the single-winner case, the goal shifts to identifying Condorcet-consistent rules, which select a Condorcet winner (or the analogous multi-winner notion) when one exists [Coe05, BC08]. In this context, Theorem 1 highlights a distinct advantage of the approach by Elkind, Lang, and Saffidine [ELS15]: small Condorcet-undominated sets are guaranteed to exist. Other explorations of 1. Lastly, we mention a few other interesting explorations of Condorcet winning sets, and more generally α𝛼\alphaitalic_α-undominated sets. [Gei14] used SAT solving to determine the largest Condorcet dimension in elections with a small number of voters and candidates. Their search did not turn up any instances with dimension larger than 3, but they found an election with just 6 voters and candidates with dimension 3, and they showed that this is the smallest possible. (We include one such instance in Table 4.) [Blo18] also explored whether elections with Condorcet dimension 4 could be constructed by exploring dominating sets in tourament graphs, but that approach did not yield any such elections. On the positive side, [LVvS24] very recently showed that in elections where the voters and candidates are embedded in a 2-dimensional space, and their preferences are defined by their distance according to the ℓ1subscriptℓ1\ell_{1}roman_ℓ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT or ℓ∞subscriptℓ\ell_{\infty}roman_ℓ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT norm, the Condorcet dimension is at most 3. In a more informal setting, a question isomorphic to 1 has also been explored from a combinatorial perspective in a series of Math Overflow posts [Pál13, Spe13, Bra13]. These posts offer an intriguing window into different approaches to resolving the problem, including why some natural approaches fall short. In their formulation [Pál13], each candidate a𝑎aitalic_a is represented by a function fa:[n]→ℕ:subscript𝑓𝑎→delimited-[]𝑛ℕf_{a}\colon[n]\to\mathbb{N}italic_f start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT : [ italic_n ] → blackboard_N, which can be thought of as a map from each voter v𝑣vitalic_v to the rank of a𝑎aitalic_a in v𝑣vitalic_v’s preference order. They ask 1, with a particular focus on the case where k=2𝑘2k=2italic_k = 2. The responses contain examples of elections with Condorcet dimension 3, including the general lower bound that α𝛼\alphaitalic_α-undominated committees of size k𝑘kitalic_k do not always exist when α<2k+1𝛼2𝑘1\alpha<\frac{2}{k+1}italic_α < divide start_ARG 2 end_ARG start_ARG italic_k + 1 end_ARG [Zba14]. One natural approach towards positive results, suggested by Speyer [Spe13], is to solve the following graph theory question. Question 2. For what choices of ℓ,k∈ℤ+ℓ𝑘superscriptℤ\ell,k\in\mathbb{Z}^{+}roman_ℓ , italic_k ∈ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT does there exist a directed graph with girth larger than ℓℓ\ellroman_ℓ such that every subset of k𝑘kitalic_k vertices has a common in-neighbor? If there does not exist such a graph for some choice of ℓℓ\ellroman_ℓ and k𝑘kitalic_k, then this implies that every election has a (1−1ℓ)11ℓ(1-\frac{1}{\ell})( 1 - divide start_ARG 1 end_ARG start_ARG roman_ℓ end_ARG )-undominated set of size k𝑘kitalic_k, by considering the graph on candidates where there is an edge (a,b)𝑎𝑏(a,b)( italic_a , italic_b ) whenever more than 1−1ℓ11ℓ1-\frac{1}{\ell}1 - divide start_ARG 1 end_ARG start_ARG roman_ℓ end_ARG fraction of the voters prefer a𝑎aitalic_a over b𝑏bitalic_b. In particular, if every triangle-free graph has a pair of vertices without a common in-neighbor (ℓ=3ℓ3\ell=3roman_ℓ = 3 and k=2𝑘2k=2italic_k = 2), then this would imply that 2323\frac{2}{3}divide start_ARG 2 end_ARG start_ARG 3 end_ARG-undominated sets of size 2222 always exist, which would resolve 1 for k=2𝑘2k=2italic_k = 2. Unfortunately, such graphs do exist. [AHL+15] gave a positive answer to 2 for every ℓ,k∈ℤ+ℓ𝑘superscriptℤ\ell,k\in\mathbb{Z}^{+}roman_ℓ , italic_k ∈ blackboard_Z start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT, using a construction based on additive combinatorics."
https://arxiv.org/html/2411.03955v1,"Large Deviations Inequalities for Unequal Probability Sampling
Without Replacement††thanks:This note answers a question posed by Noam Nisan. We thank Noam Nisan and
Benji Weiss for useful discussions and suggestions.","We provide bounds on the tail probabilities for simple procedures that generate random samples without replacement, when the probabilities of being selected need not be equal.","1 Martingale-Based Procedures It is convenient to rescale the weights so that they add to k;𝑘k;italic_k ; thus, put Δ:={x∈[0,1]n:∑i=1nxi=k},assignΔconditional-set𝑥superscript01𝑛superscriptsubscript𝑖1𝑛superscript𝑥𝑖𝑘\Delta:=\{x\in[0,1]^{n}:\sum_{i=1}^{n}x^{i}=k\},\ roman_Δ := { italic_x ∈ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT : ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_k } ,and let Δ0:={x∈{0,1}n:∑i=1nxi=k}assignsubscriptΔ0conditional-set𝑥superscript01𝑛superscriptsubscript𝑖1𝑛superscript𝑥𝑖𝑘\Delta_{0}:=\{x\in\{0,1\}^{n}:\sum_{i=1}^{n}x^{i}=k\}roman_Δ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := { italic_x ∈ { 0 , 1 } start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT : ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_k } be the set of extreme points of Δ,Δ\Delta,roman_Δ , i.e., those weight vectors that contain k𝑘kitalic_k ones and n−k𝑛𝑘n-kitalic_n - italic_k zeros. For every set A⊂[n]𝐴delimited-[]𝑛A\subset[n]italic_A ⊂ [ italic_n ] we write xA:=∑i∈Axi.assignsuperscript𝑥𝐴subscript𝑖𝐴superscript𝑥𝑖x^{A}:=\sum_{i\in A}x^{i}.italic_x start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT := ∑ start_POSTSUBSCRIPT italic_i ∈ italic_A end_POSTSUBSCRIPT italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT . A procedure that generates a random sample S𝑆Sitalic_S of size k𝑘kitalic_k such that ℙ⁢[i∈S]=xiℙdelimited-[]𝑖𝑆superscript𝑥𝑖\mathbb{P}\left[i\in S\right]=x^{i}blackboard_P [ italic_i ∈ italic_S ] = italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT for every i∈[n]𝑖delimited-[]𝑛i\in[n]italic_i ∈ [ italic_n ] is called an x𝑥xitalic_x-procedure. The vector of normalized weights (w1,…,wn)superscript𝑤1…superscript𝑤𝑛(w^{1},...,w^{n})( italic_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_w start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) yields the vector of weights x0:=k⁢w=(k⁢w1,…,k⁢wn)assignsubscript𝑥0𝑘𝑤𝑘superscript𝑤1…𝑘superscript𝑤𝑛x_{0}:=kw=(kw^{1},...,kw^{n})italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT := italic_k italic_w = ( italic_k italic_w start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_k italic_w start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ) in Δ.Δ\Delta.roman_Δ . We start with a trivial observation. Observation. Let x=∑ℓ=1Lλℓ⁢xℓ𝑥superscriptsubscriptℓ1𝐿subscript𝜆ℓsubscript𝑥ℓx=\sum_{\ell=1}^{L}\lambda_{\ell}x_{\ell}italic_x = ∑ start_POSTSUBSCRIPT roman_ℓ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT where xℓ∈Δsubscript𝑥ℓΔx_{\ell}\in\Deltaitalic_x start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ∈ roman_Δ and λℓ≥0subscript𝜆ℓ0\lambda_{\ell}\geq 0italic_λ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT ≥ 0 for each ℓℓ\ellroman_ℓ, and ∑ℓ=1Lλℓ=1superscriptsubscriptℓ1𝐿subscript𝜆ℓ1\sum_{\ell=1}^{L}\lambda_{\ell}=1∑ start_POSTSUBSCRIPT roman_ℓ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT = 1 (and thus x∈Δ𝑥Δx\in\Deltaitalic_x ∈ roman_Δ as well). If 𝔛ℓsubscript𝔛ℓ\mathfrak{X}_{\ell}fraktur_X start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT is an xℓsubscript𝑥ℓx_{\ell}italic_x start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT-procedure for each ℓ,ℓ\ell,roman_ℓ , then the procedure 𝔛𝔛\mathfrak{X}fraktur_X that with probability λℓsubscript𝜆ℓ\lambda_{\ell}italic_λ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT follows 𝔛ℓsubscript𝔛ℓ\mathfrak{X}_{\ell}fraktur_X start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT is an x𝑥xitalic_x-procedure. This is immediate by ℙ𝔛⁢[i∈S]=∑ℓ=1Lλℓ⁢ℙ𝔛ℓ⁢[i∈S].subscriptℙ𝔛delimited-[]𝑖𝑆superscriptsubscriptℓ1𝐿subscript𝜆ℓsubscriptℙsubscript𝔛ℓdelimited-[]𝑖𝑆\mathbb{P}_{\mathfrak{X}}\left[i\in S\right]=\sum_{\ell=1}^{L}\lambda_{\ell}% \mathbb{P}_{\mathfrak{X}_{\ell}}\left[i\in S\right].blackboard_P start_POSTSUBSCRIPT fraktur_X end_POSTSUBSCRIPT [ italic_i ∈ italic_S ] = ∑ start_POSTSUBSCRIPT roman_ℓ = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT italic_λ start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT blackboard_P start_POSTSUBSCRIPT fraktur_X start_POSTSUBSCRIPT roman_ℓ end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_i ∈ italic_S ] . Iterating this observation yields a martingale: a stochastic process where at each step the (conditional) expectation of the “value” of the next state equals the “value” of the current state; in our case, these “values” will be weight vectors in Δ.Δ\Delta.roman_Δ . Let thus (Xt)t=0,1,2,…subscriptsubscript𝑋𝑡𝑡012…(X_{t})_{t=0,1,2,...}( italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_t = 0 , 1 , 2 , … end_POSTSUBSCRIPT be a ΔΔ\Deltaroman_Δ-valued martingale starting with the constant X0=x0=k⁢wsubscript𝑋0subscript𝑥0𝑘𝑤X_{0}=x_{0}=kwitalic_X start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = italic_k italic_w and ending at a finite time T𝑇Titalic_T with XTsubscript𝑋𝑇X_{T}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT in Δ0subscriptΔ0\Delta_{0}roman_Δ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT (i.e., XTisuperscriptsubscript𝑋𝑇𝑖X_{T}^{i}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT is either 00 or 1111 for every i𝑖iitalic_i).333The time T𝑇Titalic_T may well be random; for simplicity, once Δ0subscriptΔ0\Delta_{0}roman_Δ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT is reached the martingale stays constant, i.e., Xt=XTsubscript𝑋𝑡subscript𝑋𝑇X_{t}=X_{T}italic_X start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT for all t≥T.𝑡𝑇t\geq T.italic_t ≥ italic_T . Since for every x𝑥xitalic_x in Δ0subscriptΔ0\Delta_{0}roman_Δ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT there is a unique x𝑥xitalic_x-procedure—namely, the deterministic choice of the sample as those i𝑖iitalic_i whose xisuperscript𝑥𝑖x^{i}italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT is 1111 (i.e., S={i:xi=1}𝑆conditional-set𝑖superscript𝑥𝑖1S=\{i:x^{i}=1\}italic_S = { italic_i : italic_x start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = 1 })—the observation above yields an x0subscript𝑥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT-procedure that uses these deterministic XTsubscript𝑋𝑇X_{T}italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT-choices. Thus, i𝑖iitalic_i belongs to the random sample S𝑆Sitalic_S if and only if XTi=1superscriptsubscript𝑋𝑇𝑖1X_{T}^{i}=1italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = 1; and, for every set A⊂[n]𝐴delimited-[]𝑛A\subset[n]italic_A ⊂ [ italic_n ], the number of elements of A𝐴Aitalic_A in the sample is |S∩A|=∑i∈AXTi=XTA.𝑆𝐴subscript𝑖𝐴superscriptsubscript𝑋𝑇𝑖superscriptsubscript𝑋𝑇𝐴|S\cap A|=\sum_{i\in A}X_{T}^{i}=X_{T}^{A}.| italic_S ∩ italic_A | = ∑ start_POSTSUBSCRIPT italic_i ∈ italic_A end_POSTSUBSCRIPT italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = italic_X start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT . The martingale constructions below are based on moving weights around as much as possible, subject to the constraint that all weights stay between 00 and 1.11.1 ."
https://arxiv.org/html/2411.03865v1,AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making,"Traditional interactive environments limit agents’ intelligence growth with fixed tasks. Recently, single-agent environments address this by generating new tasks based on agent actions, enhancing task diversity. We consider the decision-making problem in multi-agent settings, where tasks are further influenced by social connections, affecting rewards and information access. However, existing multi-agent environments lack a combination of adaptive physical surroundings and social connections, hindering the learning of intelligent behaviors. To address this, we introduce AdaSociety, a customizable multi-agent environment featuring expanding state and action spaces, alongside explicit and alterable social structures. As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake. In AdaSociety, we develop three mini-games showcasing distinct social structures and tasks. Initial results demonstrate that specific social structures can promote both individual and collective benefits, though current reinforcement learning and LLM-based algorithms show limited effectiveness in leveraging social structures to enhance performance. Overall, AdaSociety serves as a valuable research platform for exploring intelligence in diverse physical and social settings. The code is available at https://github.com/bigai-ai/AdaSociety.","Classic learning environments [55, 41, 9, 42, 34] have agents trained in small and stationary worlds, which hinders the improvement of agents’ intelligence. The learning process stagnates once the environments can no longer provide novel data for agents’ explorations. Additionally, agents trained on a fixed task set may suffer from a loss of generalization ability [13]. Single-agent environments [18, 25, 61] set out to solve this problem by constructing adaptive environments that continuously generate new tasks based on agent actions, providing a multitudinous task set. In multi-agent settings, however, the task set is determined by not only physical surroundings but also social connections among agents. Social connections dramatically impact agents’ decision-making by shaping their reward structures and information access [20], and different social structures endow the environments with radically different research problems. For example, centralized scenarios focus on issues like credit assignment and consensus establishment [21, 44], while decentralized settings require agents to address opponent modeling issues and non-stationarity [3, 21, 29, 33]. What makes the problem even more challenging is that social connections are not predefined but adaptive, which means there’s a dynamical interplay between the topology of social connections and agents’ states [23]. The adaptive nature of social connections and physical surroundings requires agents to learn continuously, reason about other agents’ policies, and balance between physical explorations and establishing social connections. While contemporary multi-agent decision-making environments [6, 2, 53, 66, 48] have achieved great progress in stimulating and testing capabilities of learning algorithms in fixed task sets, they fail to generate new tasks by concurrently considering expanding physical surroundings and adaptive social connections. To bridge this gap, we propose AdaSociety, a multi-agent environment with massive and diverse tasks generated by adaptive social connections and expanding physical surroundings, which are influenced by agents’ behavior. In particular, to the best of our knowledge, AdaSociety first introduces social states (expressed as a multi-layer directed graph) to explicitly and quantitatively describe the adaptive and dynamic connections between entities, including agents and emerged organizations. This greatly enriches the diversity of tasks, supporting the establishment of stable and long-term relations between entities and the quantitative study of social intelligence, like coalition formation and the emergence of hierarchy. In such an environment, agents need to balance the exploration of physical surroundings and the alteration of social connections, leading to multiple possible victory paths and significant decision-making challenges. To stimulate algorithm design and theoretical analysis in AdaSociety, we provide a formulation of the multi-agent decision-making problems, named Growing-MG (Sec. 3). AdaSociety serves as a platform for researchers to customize the environment for diverse research needs. Specifically, a set of fundamental elements and mechanisms can be used, and interfaces are provided to set environment attributes and hyper-parameters. Moreover, AdaSociety exhibits its characteristics by offering three mini-games, where both tensor- and LLM-based methods are tested. In summary, this paper makes three contributions. 1) We introduce a novel multi-agent general-sum environment featuring expanding physical surroundings and adaptive social connections. 2) We offer a customizable environment with three built-in mini-games, supporting both tensor- and LLM-based methods. 3) We implement RL and LLM methods in these mini-games and provide preliminary results, laying the groundwork for further research in this environment. Figure 1: An overview of AdaSociety, composed of physical component and social component. Physical Component consists of diverse resources and events on the map and heterogeneous agents’ inventories. Social Component describes the adaptive connections between agents and organizations, which shape information access and reward structure. Agents take social actions to alter their social connections. As shown in the rightmost flowchart, agents are initially independent and can establish individual connections (edges between nodes) and form groups (gray ovals)."
https://arxiv.org/html/2411.03651v1,Policy Aggregation,"We consider the challenge of AI value alignment with multiple individuals that have different reward functions and optimal policies in an underlying Markov decision process. We formalize this problem as one of policy aggregation, where the goal is to identify a desirable collective policy. We argue that an approach informed by social choice theory is especially suitable. Our key insight is that social choice methods can be reinterpreted by identifying ordinal preferences with volumes of subsets of the state-action occupancy polytope. Building on this insight, we demonstrate that a variety of methods — including approval voting, Borda count, the proportional veto core, and quantile fairness — can be practically applied to policy aggregation.","Early discussion of AI value alignment had often focused on learning desirable behavior from an individual teacher, for example, through inverse reinforcement learning [27, 1]. But, in recent years, the conversation has shifted towards aligning AI models with large groups of people or even entire societies. This shift is exemplified at a policy level by OpenAI’s “democratic inputs to AI” program [41] and Meta’s citizens’ assembly on AI governance [8], and at a technical level by the ubiquity of reinforcement learning from human feedback [30] as a method for fine-tuning large language models. We formalize the challenge of value alignment with multiple individuals as a problem that we view as fundamental — policy aggregation. Our starting point is the common assumption that the environment can be represented as a Markov decision process (MDP). While the states, actions and transition functions are shared by all agents, their reward functions — which incorporate values, priorities or subjective beliefs — may be different. In particular, each agent has its own optimal policy in the underlying MDP. Our question is this: How should we aggregate the individual policies into a desirable collective policy? A naïve answer is to define a new reward function that is the sum of the agents’ reward functions (for each state-action pair separately) and compute an optimal policy for this aggregate reward function; such a policy would guarantee maximum utilitarian social welfare. This approach has a major shortcoming, however, in that it is sensitive to affine transformations of rewards, so, for example, if we doubled one of the reward functions, the aggregate optimal policy may change. This is an issue because each agent’s individual optimal policy is invariant to (positive) affine transformations of rewards, so while it is possible to recover a reward function that induces an agent’s optimal policy by observing their actions over time,111And we assume this is done accurately, in order to focus on the essence of the policy aggregation problem. it is impossible to distinguish between reward functions that are affine transformations of each other. More broadly, economists and moral philosophers have long been skeptical about interpersonal comparisons of utility [19] due to the lack of universal scale — an issue that is especially pertinent in our context. Therefore, aggregation methods that are invariant to affine transformations are strongly preferred. Our approach. To develop such aggregation methods, we look to social choice theory, which typically deals with the aggregation of ordinal preferences. To take a canonical example, suppose agents report rankings over m𝑚mitalic_m alternatives. Under the Borda count rule, each voter gives m−k𝑚𝑘m-kitalic_m - italic_k points to the alternative they rank in the k𝑘kitalic_k’th position, and the alternative with most points overall is selected. The voting approach can be directly applied to our setting. For each agent, it is (in theory) possible to compute the value of every possible (deterministic) policy, and rank them all by value. Then, any standard voting rule, such as Borda count, can be used to aggregate the rankings over policies and single out a desirable policy. The caveat, of course, is that this method is patently impractical, because the number of policies is exponential in the number of states of the MDP. The main insight underlying our approach is that ordinal preferences over policies have a much more practical volumetric interpretation in the state-action occupancy polytope 𝒪𝒪\mathcal{O}caligraphic_O. Roughly speaking, a point in the state-action occupancy polytope represents a (stochastic) policy through the frequency it is expected to visit different state-action pairs. If a policy is preferred by an agent to a subset of policies 𝒪′superscript𝒪′\mathcal{O^{\prime}}caligraphic_O start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, its “rank” is the volume of 𝒪′superscript𝒪′\mathcal{O^{\prime}}caligraphic_O start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT as a fraction of the volume of 𝒪𝒪\mathcal{O}caligraphic_O. The “score” of a policy under Borda count, for example, can be interpreted as the sum of these “ranks” over all agents. Our results. We investigate two classes of rules from social choice theory, those that guarantee a notion of fairness and voting rules. By mapping ordinal preferences to the state-action occupancy polytope, we adapt the different rules to the policy aggregation problem. The former class is examined in Section 5. As a warm-up we start from the notion of proportional veto core; it follows from recent work by Chaudhury et al. [7] that a volumetric interpretation of this notion is nonempty and can be computed efficiently. We then turn to quantile fairness, which was recently introduced by Babichenko et al. [4]; we prove that the volumetric interpretation of this notion yields guarantees that are far better than those known for the original, discrete setting, and we design a computationally efficient algorithm to optimize those guarantees. The latter class is examined in Section 6; we focus on volumetric interpretations of α𝛼\alphaitalic_α-approval (including the ubiquitous plurality rule, which is the special case of α=1𝛼1\alpha=1italic_α = 1) and the aforementioned Borda count. In contrast to the rules studied in Section 5, existence is a nonissue for these voting rules, but computation is a challenge, and indeed we establish several computational hardness results. To overcome this obstacle, we implement voting rules for policy aggregation through mixed integer linear programming, which leads to practical solutions. Finally, our experiments in Section 7 evaluate the policies returned by different rules based on their fairness; the results identify quantile fairness as especially appealing. The experiments also illustrate the advantage of our approach over rules that optimize measures of social welfare (which are sensitive to affine transformations of the rewards)."
https://arxiv.org/html/2411.03248v2,On the Role of Constraints in the Complexityof Min-Max Optimization,"We investigate the role of constraints in the computational complexity of min-max optimization. The work of \citet*daskalakis2021complexity was the first to study min-max optimization through the lens of computational complexity, showing that min-max problems with nonconvex-nonconcave objectives are PPAD-hard. However, their proof hinges on the presence of joint constraints between the maximizing and minimizing players. The main goal of this paper is to understand the role of these constraints in min-max optimization. The first contribution of this paper is a fundamentally new proof of their main result, which improves it in multiple directions: it holds for degree 2222 polynomials, it is essentially tight in the parameters, and it is much simpler than previous approaches, clearly highlighting the role of constraints in the hardness of the problem. Second, we show that with general constraints (i.e., the min player and max player have different constraints), even convex-concave min-max optimization becomes PPAD-hard. Along the way, we also provide PPAD-membership of a general problem related to quasi-variational inequalities, which has applications beyond our problem.","The primary interest in this paper is investigating how different structures of constraints drive the computational complexity of min-max optimization problems. This class of problems plays a key role in the development of game theory \citepv1928theorie, adversarial robustness in optimization, statistics, machine learning \citepben2002robust,huber2011robust,mkadry2017towards,sinha2018certifying, and generative models such as Generative Adversarial Networks \citepgoodfellow2014generative,arjovsky2017wasserstein. In its simplest form, a min-max optimization problem can be informally written as minx∈ℝd⁡maxy∈ℝd⁡f⁢(x,y)s.t.⁢g⁢(x,y)≤0,subscript𝑥superscriptℝ𝑑subscript𝑦superscriptℝ𝑑𝑓𝑥𝑦s.t.𝑔𝑥𝑦0\begin{array}[]{l}\displaystyle\min_{x\in\mathbb{R}^{d}}\,\max_{y\in\mathbb{R}% ^{d}}\,\,f(x,y)\\ \textnormal{s.t.}\hskip 8.5359ptg(x,y)\leq 0,\end{array}start_ARRAY start_ROW start_CELL roman_min start_POSTSUBSCRIPT italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT roman_max start_POSTSUBSCRIPT italic_y ∈ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) end_CELL end_ROW start_ROW start_CELL s.t. italic_g ( italic_x , italic_y ) ≤ 0 , end_CELL end_ROW end_ARRAY (1) where f:ℝd×ℝd→ℝ:𝑓→superscriptℝ𝑑superscriptℝ𝑑ℝf:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_f : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R, and g:ℝd×ℝd→ℝ:𝑔→superscriptℝ𝑑superscriptℝ𝑑ℝg:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_g : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R. Due to the strong connection with zero-sum games, x𝑥xitalic_x and y𝑦yitalic_y are often thought of as selected by players seeking to maximize and minimize the payoff function in a game. While the benign setting in which f𝑓fitalic_f is convex-concave and g𝑔gitalic_g is convex is well understood, many fundamental questions remain open regarding more general settings. In this paper, we are specifically interested in these more general settings. Akin to regular (i.e., non-saddle-point) optimization, in nonconvex domains it is too much to ask for a global solution. Instead, local min-max solutions (also known as local equilibria) serve as the target solution concept for our investigation. Specifically, given ϵ,δ>0italic-ϵ𝛿0\epsilon,\delta>0italic_ϵ , italic_δ > 0, we will call (ϵ,δ)italic-ϵ𝛿(\epsilon,\delta)( italic_ϵ , italic_δ )-solution of Problem (1) any pair (x⋆,y⋆)superscript𝑥⋆superscript𝑦⋆(x^{\star},y^{\star})( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) such that g⁢(x⋆,y⋆)≤0𝑔superscript𝑥⋆superscript𝑦⋆0g(x^{\star},y^{\star})\leq 0italic_g ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≤ 0, and such that each player cannot improve their utility through any feasible, local, unilateral deviation, that is, f⁢(x⋆,y⋆)≤f⁢(x,y⋆)+ϵ⁢ for all ⁢x⁢ s.t. ⁢‖x−x⋆‖≤δ⁢ and ⁢g⁢(x,y⋆)≥0⁢; andf⁢(x⋆,y⋆)≥f⁢(x⋆,y)−ϵ⁢ for all ⁢y⁢ s.t. ⁢‖y−y⋆‖≤δ⁢ and ⁢g⁢(x⋆,y)≥0.𝑓superscript𝑥⋆superscript𝑦⋆𝑓𝑥superscript𝑦⋆italic-ϵ for all 𝑥 s.t. norm𝑥superscript𝑥⋆𝛿 and 𝑔𝑥superscript𝑦⋆0; and𝑓superscript𝑥⋆superscript𝑦⋆𝑓superscript𝑥⋆𝑦italic-ϵ for all 𝑦 s.t. norm𝑦superscript𝑦⋆𝛿 and 𝑔superscript𝑥⋆𝑦0\begin{array}[]{l}f(x^{\star},y^{\star})\leq f(x,y^{\star})+\epsilon\,\,% \textnormal{ for all }x\textnormal{ s.t. }\|x-x^{\star}\|\leq\delta\textnormal% { and }g(x,y^{\star})\geq 0\textnormal{; and}\\ f(x^{\star},y^{\star})\geq f(x^{\star},y)-\epsilon\,\,\textnormal{ for all }y% \textnormal{ s.t. }\|y-y^{\star}\|\leq\delta\textnormal{ and }g(x^{\star},y)% \geq 0.\end{array}start_ARRAY start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≤ italic_f ( italic_x , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) + italic_ϵ for all italic_x s.t. ∥ italic_x - italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ∥ ≤ italic_δ and italic_g ( italic_x , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≥ 0 ; and end_CELL end_ROW start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≥ italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y ) - italic_ϵ for all italic_y s.t. ∥ italic_y - italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ∥ ≤ italic_δ and italic_g ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y ) ≥ 0 . end_CELL end_ROW end_ARRAY (2) Our work is not the first to study min-max optimization beyond the convex-concave setup (see, e.g., \citepjin2020local,jin2021nonconvex,daskalakis2023stay and pointers in Section 1.3). For example, several papers have focused on nonconvex-concave objectives under constraints g𝑔gitalic_g that induce product feasible sets of the form 𝒳×𝒴𝒳𝒴\mathcal{X}\times\mathcal{Y}caligraphic_X × caligraphic_Y, where numerous algorithms find approximate solutions efficiently \citepnouiehed2019solving,lin2020gradient,lin2020near,kong2021accelerated,fiez2021global,ostrovskii2021efficient. On the other hand, in a recent landmark result, \citet*daskalakis2021complexity proved that finding solutions to Problem (2), in the case of nonconvex-concave objective, is PPAD-complete. However, such hardness result only holds in a special case in which g𝑔gitalic_g couples (i.e., correlates) the feasible sets of the minimization and maximization (the importance of these constraints was also pointed out in \citepfearnley2022complexity, babichenko2021settling, hollender2024complexity, kalogiannis2024learning). Given that the presence of joint constraints turns an otherwise manageable problem into a hard one (Figure 1, second row, first and second column), the following question arises naturally: What role does the coupling of the feasible sets play in the hardness result of \citetdaskalakis2021complexity? We provide a fundamentally new perspective on the problem, clarifying the role of these constraints and disentangling their impact on computational hardness from that of the structure of the objective function. Moreover, this is not the only setting in which we can identify a “phase change” between traceability and hardness when the generality of the constraints is increased. Indeed, as an additional instance of this phenomenon, we show that, as the complexity of constraints increases to capture more general constraints (i.e., the min player and max player have different constraints), even convex-concave optimization can become PPAD-hard (bottom-right cell of Figure 1). In turn, this has implications on the complexity of computing solutions to quasi-variational inequalities with monotone operators. Our result complements known positive results in optimization for QVIs, which either have finite-time guarantees with strong assumptions \citepnesterov2006solving or asymptotic guarantees \citepfacchinei2014solving. We discuss our contributions and their implications in more depth in the next subsection. 1.1 Contributions and Implications Structure of constraintsStructure of utilitiesBilinear Jointly convex Product Convex concave Nonconvex concave Nonconvex nonconcave Open question PPAD-complete PPAD-complete Theorem 3.4 Easy (∈\in∈ FP) [ostrovskii2021efficient] PPAD-complete\citep daskalakis2021complexity, Theorem 4.1 PPAD-complete Easy (∈\in∈ FP) (Folklore) Easy (∈\in∈ FP) (Folklore) PPAD-complete Theorem 4.2 Figure 1: Summary of known results regarding the complexity of min-max optimization for a different combination of structures of utilities and constraints. The arrows point in the direction of increased generality and thus hardness. A key factor in our taxonomy of optimization problems is the structure of the constraints. We consider the following classes of constraints, in increasing order of generality, as listed on the x-axis of Figure 1. • Product constraints: The feasible set g⁢(x,y)≤0𝑔𝑥𝑦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) ≤ 0 is equal to K1×K2subscript𝐾1subscript𝐾2K_{1}\times K_{2}italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT × italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT for some appropriate K1,K2⊂ℝdsubscript𝐾1subscript𝐾2superscriptℝ𝑑K_{1},K_{2}\subset\mathbb{R}^{d}italic_K start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_K start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ⊂ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. In other words, there is no coupling between the optimization domains of the players. • Jointly convex constraints: Constraints for both the maximizing and minimizing player are encoded by a function g𝑔gitalic_g that is jointly convex, that is, convex as a function of (x,y)𝑥𝑦(x,y)( italic_x , italic_y ). In particular, this implies that g⁢(x,y)≤0𝑔𝑥𝑦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) ≤ 0 is a convex subset of ℝd×ℝdsuperscriptℝ𝑑superscriptℝ𝑑\mathbb{R}^{d}\times\mathbb{R}^{d}blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT. We remark that for our hardness result highlighted in Figure 1, it is enough to restrict to functions g𝑔gitalic_g such that g⁢(x,y)≤0𝑔𝑥𝑦0g(x,y)\leq 0italic_g ( italic_x , italic_y ) ≤ 0 defines a convex polytope. This is the same class of constraints used in the results of \citetdaskalakis2021complexity. • Bilinear constraints: Finally, to be able to capture problems corresponding to quasi-variational inequalities, we also consider a more general setting in which the set of feasible local deviations of the players might differ, and is controlled by two constraint functions g1,g2:ℝd×ℝd→ℝ:subscript𝑔1subscript𝑔2→superscriptℝ𝑑superscriptℝ𝑑ℝg_{1},g_{2}:\mathbb{R}^{d}\times\mathbb{R}^{d}\to\mathbb{R}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT × blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R, one for each player. This leads to the modified notion of (ϵ,δ)italic-ϵ𝛿(\epsilon,\delta)( italic_ϵ , italic_δ )-solution (or local equilibrium) given as f⁢(x⋆,y⋆)≤f⁢(x,y⋆)+ϵ⁢ for all ⁢x⁢ s.t. ⁢‖x−x⋆‖≤δ⁢ and ⁢g1⁢(x,y⋆)≥0⁢; andf⁢(x⋆,y⋆)≥f⁢(x⋆,y)−ϵ⁢ for all ⁢x⁢ s.t. ⁢‖y−y⋆‖≤δ⁢ and ⁢g2⁢(x⋆,y)≥0.𝑓superscript𝑥⋆superscript𝑦⋆𝑓𝑥superscript𝑦⋆italic-ϵ for all 𝑥 s.t. norm𝑥superscript𝑥⋆𝛿 and subscript𝑔1𝑥superscript𝑦⋆0; and𝑓superscript𝑥⋆superscript𝑦⋆𝑓superscript𝑥⋆𝑦italic-ϵ for all 𝑥 s.t. norm𝑦superscript𝑦⋆𝛿 and subscript𝑔2superscript𝑥⋆𝑦0\begin{array}[]{l}f(x^{\star},y^{\star})\leq f(x,y^{\star})+\epsilon\,\,% \textnormal{ for all }x\textnormal{ s.t. }\|x-x^{\star}\|\leq\delta\textnormal% { and }g_{1}(x,y^{\star})\geq 0\textnormal{; and}\\ f(x^{\star},y^{\star})\geq f(x^{\star},y)-\epsilon\,\,\textnormal{ for all }x% \textnormal{ s.t. }\|y-y^{\star}\|\leq\delta\textnormal{ and }g_{2}(x^{\star},% y)\geq 0.\end{array}start_ARRAY start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≤ italic_f ( italic_x , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) + italic_ϵ for all italic_x s.t. ∥ italic_x - italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ∥ ≤ italic_δ and italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ( italic_x , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≥ 0 ; and end_CELL end_ROW start_ROW start_CELL italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ) ≥ italic_f ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y ) - italic_ϵ for all italic_x s.t. ∥ italic_y - italic_y start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT ∥ ≤ italic_δ and italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ( italic_x start_POSTSUPERSCRIPT ⋆ end_POSTSUPERSCRIPT , italic_y ) ≥ 0 . end_CELL end_ROW end_ARRAY (3) In particular, we are interested in the case of bilinear constraint functions g1,g2subscript𝑔1subscript𝑔2g_{1},g_{2}italic_g start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_g start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT. Due to their bilinear nature, each of this functions defines a local convex polytope of feasible local deviations for each player. We will also consider different classes of objective functions: convex-concave, nonconvex-concave, and nonconvex-nonconcave. We analyze how the problem’s complexity evolves as the structure of the constraints changes. We categorize our results into hardness and membership results. Hardness results The main contribution of this paper is the following hardness result. Theorem 1.1 (Informal version of Theorem 4.1). The problem of computing approximate local min-max equilibria with jointly convex constraints, and nonconvex-concave, G𝐺Gitalic_G-Lipschitz, and L𝐿Litalic_L-smooth utilities is PPAD-hard for ϵ=Θ⁢(δ)italic-ϵΘ𝛿\epsilon=\Theta(\delta)italic_ϵ = roman_Θ ( italic_δ ), L=O⁢(1)𝐿𝑂1L=O(1)italic_L = italic_O ( 1 ), and G=poly⁢(d)𝐺poly𝑑G=\textnormal{poly}(d)italic_G = poly ( italic_d ). This result has several implications with respect to the hardness result by \citet[Theorem 4.4]daskalakis2021complexity. First, our result holds for δ=O⁢(ϵL)𝛿𝑂italic-ϵ𝐿\delta=O\left(\frac{\epsilon}{L}\right)italic_δ = italic_O ( divide start_ARG italic_ϵ end_ARG start_ARG italic_L end_ARG ) since L𝐿Litalic_L is constant, while the hardness result by \citetdaskalakis2021complexity holds only for the regime δ≥ϵ/L𝛿italic-ϵ𝐿\delta\geq\sqrt{\epsilon/L}italic_δ ≥ square-root start_ARG italic_ϵ / italic_L end_ARG. Second, as shown in Figure 2, our reduction also shows that the problem is PPAD-hard for δ=ω⁢(ϵ/G)𝛿𝜔italic-ϵ𝐺\delta=\omega(\epsilon/G)italic_δ = italic_ω ( italic_ϵ / italic_G ) as ϵ→0→italic-ϵ0\epsilon\to 0italic_ϵ → 0, while \citetdaskalakis2021complexity proves that the problem is tractable for δ≤ϵ/G𝛿italic-ϵ𝐺\delta\leq\epsilon/Gitalic_δ ≤ italic_ϵ / italic_G. Therefore, our result pushes the hardness boundary to the point where the problem transitions from intractable to tractable, leaving open only the case in which δ=O⁢(ϵ/G)𝛿𝑂italic-ϵ𝐺\delta=O(\epsilon/G)italic_δ = italic_O ( italic_ϵ / italic_G ). δ𝛿\displaystyle\deltaitalic_δϵGitalic-ϵ𝐺\displaystyle\frac{\epsilon}{G}divide start_ARG italic_ϵ end_ARG start_ARG italic_G end_ARG2⁢ϵL2italic-ϵ𝐿\displaystyle\sqrt{\frac{2\epsilon}{L}}square-root start_ARG divide start_ARG 2 italic_ϵ end_ARG start_ARG italic_L end_ARG end_ARGω⁢(ϵG)𝜔italic-ϵ𝐺\displaystyle\omega\!\left(\frac{\epsilon}{G}\right)italic_ω ( divide start_ARG italic_ϵ end_ARG start_ARG italic_G end_ARG )ϵLitalic-ϵ𝐿\displaystyle\sqrt{\frac{\epsilon}{L}}square-root start_ARG divide start_ARG italic_ϵ end_ARG start_ARG italic_L end_ARG end_ARG00∈\in∈PPAD\citepdaskalakis2021complexity∈\in∈FPPPAD-hard [Theorem 4.1]PPAD-hard \citepdaskalakis2021complexity Figure 2: Our results nearly settle the complexity of finding local equilibria of nonconvex-nonconcave objective functions under jointly convex constraints as a function of the parameter δ𝛿\deltaitalic_δ. In Section 1.2, we give a first high-level overview of our new approach highlighting the role played by the constraints in the construction. In essence, we could say that coupled constraints enable an simple embedding of a generic vector field into Equation 2, thereby solving a variational inequality (VI) associated with this vector field. Our novel perspective on the problem suggests that characterizing the computational complexity of computing approximate local min-max equilibria for nonconvex-nonconcave objectives under product constraints remains an open challenge, and it will likely require new techniques beyond those currently at our disposal. We complement the above result by proving PPAD-hardness for the setting where the objective function is restricted to only be convex-concave, but the constraints class is made more complex by allowing bilinear constraints. This marks a second “phase change” in the complexity of the problem due to constraints since the convex-concave problem is clearly solvable with jointly convex constraints by using the monotone VI formulation of the problem. Theorem 1.2 (Informal version of Theorem 4.2). The problem of computing approximate local min-max equilibria with bilinear constraints, and convex-concave, G𝐺Gitalic_G-Lipschitz, and L𝐿Litalic_L-smooth utilities is PPAD-hard for ϵ=Θ⁢(δ)italic-ϵΘ𝛿\epsilon=\Theta(\delta)italic_ϵ = roman_Θ ( italic_δ ), L=O⁢(1)𝐿𝑂1L=O(1)italic_L = italic_O ( 1 ), G=poly⁢(d)𝐺poly𝑑G=\textnormal{poly}(d)italic_G = poly ( italic_d ). Furthermore, our reduction has an interesting consequence about the complexity of quasi-variational inequality (QVI), showing that even with linear constraints, monotone QVIs are unlikely to be polynomial-time solvable in general. Corollary 1.3 (Informal version of Corollary 4.3). The problem of computing solutions to QVIs is PPAD-hard even when the set-valued fixed-point problem encoded by the QVI constraints is linear (and thus solvable in polynomial time) and the operator is monotone. PPAD-membership results PPAD-membership for the case of jointly convex constraints is due to \citet[Theorem 5.2]daskalakis2021complexity. We look at the case of bilinear constraints. To do so, we prove PPAD-membership of a very general problem related to computing solutions to quasi-variational inequalities. A classic variational inequality (VI) problem is that of finding a point z∈Q𝑧𝑄z\in Qitalic_z ∈ italic_Q, for some convex set Q⊂ℝd𝑄superscriptℝ𝑑Q\subset\mathbb{R}^{d}italic_Q ⊂ blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT, such that F⁢(z)⊤⁢(z′−z)≥0𝐹superscript𝑧topsuperscript𝑧′𝑧0F(z)^{\top}(z^{\prime}-z)\geq 0italic_F ( italic_z ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ( italic_z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - italic_z ) ≥ 0 for all z′∈Qsuperscript𝑧′𝑄z^{\prime}\in Qitalic_z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ italic_Q, where F:ℝd→ℝd:𝐹→superscriptℝ𝑑superscriptℝ𝑑F:\mathbb{R}^{d}\to\mathbb{R}^{d}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT \citepstampacchia1964formes. VIs are a powerful framework for modeling optimization problems across diverse fields, including game theory \citeprockafellar1970monotone, economics \citepfacchinei2003finite, and machine learning \citepgoodfellow2014generative, and they generalize classical optimization problems like complementarity problems \citepcottle1968complementary. QVIs are an extension of VI in which Q𝑄Qitalic_Q is no longer a fixed set but a correspondence, which depends on the optimization variable. Then, our PPAD-membership result for local min-max equilibria follows from the connection between QVIs, fixed points of gradient descent-ascent dynamics, and approximate local min-max equilibria. Theorem 1.4 (Informal version of Theorem 3.4). The problem of finding an approximate solution to quasi-variational inequalities is in PPAD. This result may be of independent interest, as the generality of the QVI problem could enable new PPAD-membership results. For example, we can easily give PPAD membership for generalized equilibrium [rosen1965existence], which are more general than those recently considered in [filos2024ppad] (see Section 3.4). 1.2 Overview of Our Techniques This section provides a high-level overview of the primary techniques employed throughout the paper by describing the main steps of the proof of our main result (Theorem 1.2). This is a concise summary of the discussion provided in Section 4.1. Linear variational inequalities The first step in our reduction is proving the hardness of an intermediate problem related to VI with linear operators defined on the hypercube, which we call LinearVI-HC. Specifically, given an affine operator F⁢(z)=D⁢z+c𝐹𝑧𝐷𝑧𝑐F(z)=Dz+citalic_F ( italic_z ) = italic_D italic_z + italic_c the problem is to find a point z𝑧zitalic_z such that F⁢(z)⊤⁢(z′−z)≥0𝐹superscript𝑧topsuperscript𝑧′𝑧0F(z)^{\top}(z^{\prime}-z)\geq 0italic_F ( italic_z ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ( italic_z start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - italic_z ) ≥ 0. We show that LinearVI-HC is PPAD-hard through a reduction from the problem of finding Nash equilibria in polymatrix games. This choice is instrumental in obtaining a hard problem on the hypercube and strong inapproximability results. Then, we connect our problem to find fixed points of gradient descent-ascent dynamics, and we reformulate it as solving a variational inequality (VI) problem. Unfortunately, gradient descent-ascent dynamics are related to VI with a specific operator F𝐹Fitalic_F, constructed by stacking the gradients ∇xfsubscript∇𝑥𝑓\nabla_{x}f∇ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f and −∇yfsubscript∇𝑦𝑓-\nabla_{y}f- ∇ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f, which correspond to the utilities of the two players. In game theory this is sometimes called “pseudo-gradient” and we indicate it with the symbol ∇~⁢f⁢(x,y)≔(∇xf⁢(x,y),−∇yf⁢(x,y)).≔~∇𝑓𝑥𝑦subscript∇𝑥𝑓𝑥𝑦subscript∇𝑦𝑓𝑥𝑦\widetilde{\nabla}f(x,y)\coloneqq(\nabla_{x}f(x,y),-\nabla_{y}f(x,y)).over~ start_ARG ∇ end_ARG italic_f ( italic_x , italic_y ) ≔ ( ∇ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) , - ∇ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) ) . It is not hard to see that a fixed point of the gradient descent-ascent map defined on f𝑓fitalic_f is a solution of the VI instance defined with the operator ∇~⁢f~∇𝑓\widetilde{\nabla}fover~ start_ARG ∇ end_ARG italic_f (Theorem B.3). (a) Embedding of F⁢(y)=(y−13)⋅(y−23)𝐹𝑦⋅𝑦13𝑦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) ⋅ ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ) with f⁢(x,y)=x⊤⁢F⁢(y)𝑓𝑥𝑦superscript𝑥top𝐹𝑦f(x,y)=x^{\top}F(y)italic_f ( italic_x , italic_y ) = italic_x start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_F ( italic_y ). (b) Embedding of F⁢(y)=(y−13)⋅(y−23)𝐹𝑦⋅𝑦13𝑦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) ⋅ ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ) with f⁢(x,y)=(x−y)⊤⁢F⁢(y)𝑓𝑥𝑦superscript𝑥𝑦top𝐹𝑦f(x,y)=(x-y)^{\top}F(y)italic_f ( italic_x , italic_y ) = ( italic_x - italic_y ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_F ( italic_y ). Figure 3: The two embeddings of the field F:ℝd→ℝd:𝐹→superscriptℝ𝑑superscriptℝ𝑑F:\mathbb{R}^{d}\to\mathbb{R}^{d}italic_F : blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT → blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT into the pseudo-gradient of f:ℝ2⁢d→ℝ:𝑓→superscriptℝ2𝑑ℝf:\mathbb{R}^{2d}\to\mathbb{R}italic_f : blackboard_R start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT → blackboard_R. The box on the right is the field x→∇xf→𝑥subscript∇𝑥𝑓x\to\nabla_{x}fitalic_x → ∇ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f, while the one on top represents the field y→−∇yf→𝑦subscript∇𝑦𝑓y\to-\nabla_{y}fitalic_y → - ∇ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f. The embedded field is F⁢(y)=(y−13)⋅(y−23)𝐹𝑦⋅𝑦13𝑦23F(y)=\left(y-\frac{1}{3}\right)\cdot\left(y-\frac{2}{3}\right)italic_F ( italic_y ) = ( italic_y - divide start_ARG 1 end_ARG start_ARG 3 end_ARG ) ⋅ ( italic_y - divide start_ARG 2 end_ARG start_ARG 3 end_ARG ); the blue dots are in correspondence with its zeros and are inserted only for reference. In both figures we have that the x𝑥xitalic_x-projection of the pseudo-gradient field on the x=y𝑥𝑦x=yitalic_x = italic_y subspace corresponds to the field F𝐹Fitalic_F, while only in Figure 3(b), both the x𝑥xitalic_x and y𝑦yitalic_y projections are aligned with the field F𝐹Fitalic_F. Pseudo-gradient fields It is clear that if we had to deal with standard gradients, then the problem would be much easier (and PPAD-hardness would be hopeless), as any local minima would satisfy the first-order optimality conditions given by the VI. Therefore, our approach to establishing hardness results by using this point of view hinges on the distinction between “pseudo-gradient” fields (vector fields generated by applying the pseudo-gradient operator to a differentiable function f𝑓fitalic_f) and gradient fields. Pseudo-gradient fields are more general then gradient fields, and allow for more complex behavior, e.g. gradient lines might form connected paths, while for conservative vector fields the gradients lines decrease the potential. Perfect imitation and bilinear constraints Bilinear constraints offers a simple tool to implement the linear operator through imitation. Given the linear operator z↦D⁢z+cmaps-to𝑧𝐷𝑧𝑐z\mapsto Dz+citalic_z ↦ italic_D italic_z + italic_c defining the LinearVI-HC instance, we embed it into the first half components x∈[0,1]d𝑥superscript01𝑑x\in[0,1]^{d}italic_x ∈ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT of the function f𝑓fitalic_f, while using the constraints to force the y∈[0,1]d𝑦superscript01𝑑y\in[0,1]^{d}italic_y ∈ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT components to lay on a specific d𝑑ditalic_d-subdomain of [0,1]2⁢dsuperscript012𝑑[0,1]^{2d}[ 0 , 1 ] start_POSTSUPERSCRIPT 2 italic_d end_POSTSUPERSCRIPT. Specifically, if we want to embed the operator [0,1]d∋z↦F⁢(z)∈[0,1]dcontainssuperscript01𝑑𝑧maps-to𝐹𝑧superscript01𝑑[0,1]^{d}\ni z\mapsto F(z)\in[0,1]^{d}[ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT ∋ italic_z ↦ italic_F ( italic_z ) ∈ [ 0 , 1 ] start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT into a pseudo-gradient ∇~⁢f~∇𝑓\widetilde{\nabla}fover~ start_ARG ∇ end_ARG italic_f, we can consider the following function f⁢(x,y)=x⊤⁢F⁢(y)𝑓𝑥𝑦superscript𝑥top𝐹𝑦f(x,y)=x^{\top}F(y)italic_f ( italic_x , italic_y ) = italic_x start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_F ( italic_y ) and force y𝑦yitalic_y to imitate x𝑥xitalic_x (for a illustration with d=1𝑑1d=1italic_d = 1 see Figure 3(a)). Indeed, with bilinear constraint we can build instances in which y𝑦yitalic_y player must choose y∈{x}𝑦𝑥y\in\{x\}italic_y ∈ { italic_x } while the x𝑥xitalic_x player is only constrained to play in the hypercube. Now, we have that ∇xf⁢(x,y)=F⁢(y)=F⁢(x)subscript∇𝑥𝑓𝑥𝑦𝐹𝑦𝐹𝑥\nabla_{x}f(x,y)=F(y)=F(x)∇ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_y ) = italic_F ( italic_x ) and thus, if x𝑥xitalic_x is a fixed point of gradient descent-ascent, we have that F⁢(x)⊤⁢(x′−x)≥0𝐹superscript𝑥topsuperscript𝑥′𝑥0F(x)^{\top}(x^{\prime}-x)\geq 0italic_F ( italic_x ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ( italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT - italic_x ) ≥ 0, implying that x𝑥xitalic_x is a solution to LinearVI-HC. This idea is enough to prove hardness of the convex-concave case with bilinear constraints (Theorem 1.4). Approximate imitation and jointly convex constraints Attempting to apply the same construction as in the case of bilinear constraints quickly leads to seemingly insurmountable challenges. First, the function used in the previous construction was convex-concave, and equilibria for such functions are easy to compute on a jointly convex set K𝐾Kitalic_K. Therefore, we must increase the complexity of f𝑓fitalic_f to be at least quadratic in x𝑥xitalic_x or y𝑦yitalic_y. Second, the most natural way to extend the imitation gadget from bilinear constraints to jointly convex ones is to consider the set K≔{x,y:‖x−y‖∞≤Δ}≔𝐾conditional-set𝑥𝑦subscriptnorm𝑥𝑦ΔK\coloneqq\{x,y:\|x-y\|_{\infty}\leq\Delta\}italic_K ≔ { italic_x , italic_y : ∥ italic_x - italic_y ∥ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ≤ roman_Δ }, for “small” values of ΔΔ\Deltaroman_Δ. However, this comes at a high cost: we can no longer disregard player y𝑦yitalic_y and consider only the optimality condition of the x𝑥xitalic_x player. What if the solution x,y𝑥𝑦x,yitalic_x , italic_y found by solving the min-max problem is on the boundary of the set K𝐾Kitalic_K? Intuitively, we can see that the constraint {x,y:‖x−y‖∞≤Δ}conditional-set𝑥𝑦subscriptnorm𝑥𝑦Δ\{x,y:\|x-y\|_{\infty}\leq\Delta\}{ italic_x , italic_y : ∥ italic_x - italic_y ∥ start_POSTSUBSCRIPT ∞ end_POSTSUBSCRIPT ≤ roman_Δ } can only limit one player at the time and either the x𝑥xitalic_x player or the y𝑦yitalic_y player can move towards any deviation x′superscript𝑥′x^{\prime}italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT.111Formally this is not entirely accurate; we need to decompose a deviation direction into two distinct components, one corresponding to the x𝑥xitalic_x-player and the other to the y𝑦yitalic_y-player. See Section 4.1 for more details. However, now we have to design f𝑓fitalic_f to align the gradient of the y𝑦yitalic_y player to the operator F⁢(z)=D⁢z+c𝐹𝑧𝐷𝑧𝑐F(z)=Dz+citalic_F ( italic_z ) = italic_D italic_z + italic_c of the LinearVI-HC instance we are reducing from. Otherwise an optimality condition of the y𝑦yitalic_y player on f𝑓fitalic_f would be meaningless in terms of its implications for the original LinearVI-HC instance. A better embedding of an operator F⁢(z)𝐹𝑧F(z)italic_F ( italic_z ) is to consider the function f⁢(x,y)=(x−y)⊤⁢F⁢(x)𝑓𝑥𝑦superscript𝑥𝑦top𝐹𝑥f(x,y)=(x-y)^{\top}F(x)italic_f ( italic_x , italic_y ) = ( italic_x - italic_y ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_F ( italic_x ). We can see that this is a promising choice since ∇xf⁢(x,y)=F⁢(x)+JF⁢(x)⊤⁢(x−y)subscript∇𝑥𝑓𝑥𝑦𝐹𝑥subscript𝐽𝐹superscript𝑥top𝑥𝑦\nabla_{x}f(x,y)=F(x)+J_{F}(x)^{\top}(x-y)∇ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_x ) + italic_J start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ( italic_x ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ( italic_x - italic_y ), where JF⁢(x)subscript𝐽𝐹𝑥J_{F}(x)italic_J start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ( italic_x ) is the Jacobian of F𝐹Fitalic_F at x𝑥xitalic_x, and −∇yf⁢(x,y)=F⁢(x)subscript∇𝑦𝑓𝑥𝑦𝐹𝑥-\nabla_{y}f(x,y)=F(x)- ∇ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT italic_f ( italic_x , italic_y ) = italic_F ( italic_x ). Given that the constraints enforce that ‖x−y‖≤Δnorm𝑥𝑦Δ\|x-y\|\leq\Delta∥ italic_x - italic_y ∥ ≤ roman_Δ, we have that approximately both gradients are aligned with F⁢(x)𝐹𝑥F(x)italic_F ( italic_x ), and thus a solution to min-max would be a solution to the original LinearVI-HC instance (Figure 3(b)). Incidentally, the set K𝐾Kitalic_K is the same considered in the reduction by \citetdaskalakis2021complexity. We analyze the connections with their reduction in the following paragraph. Relationship with the reduction of \citetdaskalakis2021complexity Our reduction follows a completely different approach than previous works. While we reduce from a continuous optimization problem, naturally defined on the hypercube, \citetdaskalakis2021complexity reduce from a discrete optimization problem related to Sperner’s lemma. This allows us to work with simple degree-two polynomials instead of building functions that are defined by circuits of some discrete problem. This simpler construction provides stronger results, such as simpler functions, constant smoothness, and hardness for larger approximations. More in detail, the reduction of \citetdaskalakis2021complexity starts from a problem (HighD-BiSperner) related to a generalization of Sperner’s lemma \citepsperner1928neuer. They partition the d𝑑ditalic_d-dimensional hypercube in cublets and color each vertex with d𝑑ditalic_d colors out of a total of 2⁢d2𝑑2d2 italic_d colors (instead of the d+1𝑑1d+1italic_d + 1 usually used in Sperner’s lemma). This problem is shown to be PPAD-hard by a reduction from Brouwer. Then they build a function f𝑓fitalic_f such that the fixed points of gradient descent-ascent dynamics are close to panchromatic cubelets of the simplicization, in which they interpret the d𝑑ditalic_d colors of each vertex as directions of the pseudo-gradient of f𝑓fitalic_f. To do so, they give a function value and direction based on the local coloring and then interpolate the function with a high-degree smooth step function. This ingenious construction is extremely technical and requires careful techniques to ensure that no extra fixed points of gradient descent-ascent are created outside of those corresponding to panchromatic cubelets. It is precisely this last requirement that forces a coupling between the strategies of the minimizer and maximizer variables since the coefficients of the interpolation produce perturbations in the pseudo-gradient, which depend on the difference x−y𝑥𝑦x-yitalic_x - italic_y. It might seem that this issue is merely technical, and it might be corrected, for example, by using another interpolation scheme. However, our reduction, which uses completely orthogonal techniques, shows that such constraints alone are enough to make the problem hard. This suggests that, in \citetdaskalakis2021complexity, these constraints are not merely a technical detail but play a fundamental role in driving the complexity of the problem. 1.3 Further Related Work Complexity of optimization problems We contribute to the line of work that shows lower bounds of optimization problems employing tools from computational complexity. This new line of research has achieved remarkable results with significant implications across complexity theory \citepfearnley2022complexity, game theory \citepbabichenko2021settling, and machine learning \citepdaskalakis2021complexity, hollender2023computational. Optimization problems belong naturally to the class of total search problem (TFNP) \citepjohnson1988easy,megiddo1991total,papadimitriou1994complexity. The bridge between optimization and search problems is not new and, for instance, it has been the main motivation for the definition of the PLS class \citepjohnson1988easy, schaffer1991simple, krentel1989structure. \citetfearnley2022complexity showed that the problem of computing fixed points of gradient descent is complete for the class PLS∩PPADPLSPPAD{\textup{{PLS}}}\cap{\textup{{PPAD}}}PLS ∩ PPAD, and this result also proves that such class is equal to CLS. Therefore, it lies much lower in the hierarchy of TFNP problems then PPAD. Moreover, while we work inside the framework of “constrained” optimization (meaning that we work inside the hypercube rather than on the entire Euclidean space), there are some very recent works that consider the computational complexity of optimization in the unconstrained setting \citephollender2023computational, kontogiannis2024computational. Membership results There are a few recent works that give general techniques to prove PPAD-membership of TFNP problems. \citetpapadimitriou2023computational is the first to define a meaningful computational problem related to Kakutani’s theorem. Their main contribution is enabling a highly general representation of the sets (e.g., via separation oracles). Their main interest is Kakutani’s problem with application to concave games, while our focus is on QVIs, which are more general. More details about this relationship can be found in Section C.3. More recently, \citetfilos2024ppad extended the “pseudogate” technique of \citetfilos2023fixp (originally used for FIXP-membership results) to the PPAD setting. They designed a general technique, based on pseudogates, that can be used to easily prove membership of an impressive number of problems with exact rational solutions. Imitation The idea of imitation in recent years has been instrumental in various PPAD-hardness results \citepmclennan2005imitation,rubinstein2015inapproximability,babichenko2016query,babichenko2020communication,babichenko2021settling. These settings mainly focus on general-sum games, and imitation is attained through carefully designed payoffs of one (or more) player. However, our setting is zero-sum, and adding an imitation component to the payoff would discourage one player from imitating just as much as it would encourage the other. Thus, our result can be seen as enforcing imitation through constraints rather than payoffs. Solving min-max problems A substantial body of recent research has focused on developing practical first-order and low-order methods for min-max optimization problems. A wide range of works illustrate divergent or cycling behavior when extending beyond minimization problems \citepmertikopoulos2018cycles,hsieh2021limits. However, efficient algorithms are available for well-behaved objectives. In the convex-concave setup, solutions can be efficiently computed using convex programming techniques \citepkorpelevich1976extragradient,azizian2020tight,golowich2020last,mazumdar2020gradient,hamedani2021primal,daskalakis2019last,mokhtari2020unified,abernethy2021last and via algorithms for monotone VIs \citepbruck1977weak,eckstein1992douglas,tseng1995linear,nemirovski2004prox,chen2017accelerated,gorbunov2022extragradient. Nonconvex-concave problems with “simple” constraints can also be solved efficiently \citepdaskalakis2018training,nouiehed2019solving,lin2020gradient,lin2020near,kong2021accelerated,ostrovskii2021efficient. In the nonconvex-nonconcave setting, motivated by the complexity results of \citepdaskalakis2021complexity, research has focused on identifying structural assumptions on the objective (e.g., assuming the weak Minty variational inequality holds) that can help overcome the computational hardness barriers \citepdiakonikolas2021efficient,pethick2022escaping, and identifying different notions of local solutions and studying convergence to these points \citepjin2020local,mangoubi2021greedy,keswani2022convergent. Finally, a more recent stream of works considers different notions of stationarity, such as Goldstein’s stationarity to handle nonsmooth objectives \citepzhang2020complexity,jordan2022complexity,kornowski2024hardness."
https://arxiv.org/html/2411.02942v1,Constant Approximation for Weighted Nash Social Welfare with Submodular Valuations,"We study the problem of assigning items to agents so as to maximize the weighted Nash Social Welfare (NSW) under submodular valuations. The best-known result for the problem is an O⁢(n⁢wmax)𝑂𝑛subscript𝑤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT )-approximation due to Garg, Husic, Li, Vega, and Vondrak [13], where wmaxsubscript𝑤w_{\max}italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum weight over all agents. Obtaining a constant approximation algorithm is an open problem in the field that has recently attracted considerable attention.We give the first such algorithm for the problem, thus solving the open problem in the affirmative. Our algorithm is based on the natural Configuration LP for the problem, which was introduced recently by Feng and Li [11] for the additive valuation case. Our rounding algorithm is similar to that of Li [25] developed for the unrelated machine scheduling problem to minimize weighted completion time. Roughly speaking, we designate the largest item in each configuration as a large item and the remaining items as small items. So, every agent gets precisely 1 fractional large item in the configuration LP solution. With the rounding algorithm in [25], we can ensure that in the obtained solution, every agent gets precisely 1 large item, and the assignments of small items are negatively correlated.","We study the problem of allocating a set M𝑀Mitalic_M of indivisible items among a set N𝑁Nitalic_N of agents, where each agent i∈N𝑖𝑁i\in Nitalic_i ∈ italic_N has a monotone non-negative submodular valuation vi:2M→ℝ≥0:subscript𝑣𝑖→superscript2𝑀subscriptℝabsent0v_{i}:2^{M}\to\mathbb{R}_{\geq 0}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT : 2 start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT → blackboard_R start_POSTSUBSCRIPT ≥ 0 end_POSTSUBSCRIPT and a weight wi∈(0,1)subscript𝑤𝑖01w_{i}\in(0,1)italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ ( 0 , 1 ) with ∑i∈Nwi=1subscript𝑖𝑁subscript𝑤𝑖1\sum_{i\in N}w_{i}=1∑ start_POSTSUBSCRIPT italic_i ∈ italic_N end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1. The weighted Nash Social Welfare (NSW) problem under submodular valuations asks for partition 𝒮:=(Si)i∈Nassign𝒮subscriptsubscript𝑆𝑖𝑖𝑁{\cal S}:=(S_{i})_{i\in N}caligraphic_S := ( italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i ∈ italic_N end_POSTSUBSCRIPT of M𝑀Mitalic_M that maximizes the weighted geometric mean of the agents’ valuations: 𝖭𝖲𝖶⁢(𝒮)=∏i∈N(vi⁢(Si))wi.𝖭𝖲𝖶𝒮subscriptproduct𝑖𝑁superscriptsubscript𝑣𝑖subscript𝑆𝑖subscript𝑤𝑖\mathsf{NSW}({\cal S})=\prod_{i\in N}\left(v_{i}(S_{i})\right)^{w_{i}}.sansserif_NSW ( caligraphic_S ) = ∏ start_POSTSUBSCRIPT italic_i ∈ italic_N end_POSTSUBSCRIPT ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) start_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT . The case when all wisubscript𝑤𝑖w_{i}italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT’s are equal to 1/n1𝑛1/n1 / italic_n is called the unweighted Nash Social Welfare problem. As usual, we assume we are given a value oracle for each visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT. W.l.o.g, we assume vi⁢(∅)=0subscript𝑣𝑖0v_{i}(\emptyset)=0italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( ∅ ) = 0 for every agent i∈N𝑖𝑁i\in Nitalic_i ∈ italic_N 111If vi⁢(∅)>0subscript𝑣𝑖0v_{i}(\emptyset)>0italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( ∅ ) > 0 for some i∈N𝑖𝑁i\in Nitalic_i ∈ italic_N, we can create a “private” item jisubscript𝑗𝑖j_{i}italic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT for i𝑖iitalic_i which has 00-value to all agents other than i𝑖iitalic_i. We replace the valuation of i𝑖iitalic_i with vi′subscriptsuperscript𝑣′𝑖v^{\prime}_{i}italic_v start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, which is defined as follows: vi′⁢(S):=vi⁢(S)−vi⁢(∅)assignsubscriptsuperscript𝑣′𝑖𝑆subscript𝑣𝑖𝑆subscript𝑣𝑖v^{\prime}_{i}(S):=v_{i}(S)-v_{i}(\emptyset)italic_v start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) := italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) - italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( ∅ ) if ji∉Ssubscript𝑗𝑖𝑆j_{i}\notin Sitalic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∉ italic_S and vi′⁢(S)=vi⁢(S∖ji)subscriptsuperscript𝑣′𝑖𝑆subscript𝑣𝑖𝑆subscript𝑗𝑖v^{\prime}_{i}(S)=v_{i}(S\setminus j_{i})italic_v start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) = italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ∖ italic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) if ji∈Ssubscript𝑗𝑖𝑆j_{i}\in Sitalic_j start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_S.. Fair and efficient allocation of resources is a central problem in computer science, game theory, and social choices, with applications across diverse domains [1, 3, 4, 22, 27, 31, 32, 37]. Three distinct communities independently discovered the notation of Nash social welfare: as a solution to the bargaining problem in classical game theory [28], as a well-established concept of proportional fairness in networking [23], and as the celebrated notion of competitive equilibrium with equal incomes in economics [35]. The unweighted case for the problem was introduced by Nash [28], and it was later extended to the weighted case [17, 21]. This extension has since been widely studied and applied across various fields, such as bargaining theory [7, 24, 34], water allocation [9, 19], climate agreements [38], and more. One of the most important features of the NSW objective is that it offers a tradeoff between the frequently conflicting demands of fairness and efficiency. A special case for the valuations visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is when they are additive. The unweighted NSW problem with additive valuations is an important topic in optimization and has received considerable interest. Barman, Krishnamurthy, and Vaish [2] developed a (𝖾1/𝖾≈1.445)superscript𝖾1𝖾1.445(\mathsf{e}^{1/\mathsf{e}}\approx 1.445)( sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT ≈ 1.445 )-approximation algorithm that finds an allocation that is both Pareto-efficient and envy-free up to one item (EF1). They showed that this problem can be reduced to the case of identical valuations, where any EF1 allocation can achieve an approximation ratio of 𝖾1/𝖾≈1.445superscript𝖾1𝖾1.445\mathsf{e}^{1/\mathsf{e}}\approx 1.445sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT ≈ 1.445. On the negative side, Garg, Hoefer, and Mehlhorn [12] established a hardness of 8/787\sqrt{8/7}square-root start_ARG 8 / 7 end_ARG. For the weighted case with additive valuations, Brown, Laddha, Pittu, and Singh [5] introduced an approximation algorithm with a ratio of 5⋅exp⁢(2⁢log⁡n+2⁢∑i∈Awi⁢log⁡wi)⋅5exp2𝑛2subscript𝑖𝐴subscript𝑤𝑖subscript𝑤𝑖5\cdot\text{exp}(2\log n+2\sum_{i\in A}w_{i}\log w_{i})5 ⋅ exp ( 2 roman_log italic_n + 2 ∑ start_POSTSUBSCRIPT italic_i ∈ italic_A end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_log italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ). Later, Feng and Li [11] presented an elegant (𝖾1/𝖾+ϵ)superscript𝖾1𝖾italic-ϵ(\mathsf{e}^{1/\mathsf{e}}+\epsilon)( sansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_ϵ )-approximation algorithm for the weighted case, using their novel configuration LP and the Shmoys-Tardos rounding procedure developed in the context of unrelated machine scheduling. The approximation ratio matches the best-known ratio for the unweighted case. When the n𝑛nitalic_n valuation functions are additive and identical, Nguyen and Rothe [29] developed a PTAS for the unweighted NSW problem. Later, Inoue and Kobayashi [20] gave an additive PTAS for the problem, i.e., a polynomial-time algorithm that maximizes the Nash social welfare within an additive error of ϵ⁢vmaxitalic-ϵsubscript𝑣\epsilon v_{\max}italic_ϵ italic_v start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT, where vmaxsubscript𝑣v_{\max}italic_v start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT is the maximum utility of an item. Li and Vondrak [26] developed the first constant approximation algorithm for unweighted NSW with submodular valuations using convex programming. The ratio has been improved by Garg, Husic, Li, Vega, and Vondrak [13] to (4+ϵ)4italic-ϵ(4+\epsilon)( 4 + italic_ϵ ) using an elegant local-search-based algorithm. When additionally n=O⁢(1)𝑛𝑂1n=O(1)italic_n = italic_O ( 1 ), by guessing the value and the O⁢(1)𝑂1O(1)italic_O ( 1 ) largest items for each agent, and using the multilinear extension of submodular functions, a 𝖾/(𝖾−1)𝖾𝖾1\mathsf{e}/(\mathsf{e}-1)sansserif_e / ( sansserif_e - 1 )-approximation can be achieved [16]. In the same paper, [16] proved that unweighted NSW with submodular valuations is hard to approximate within 𝖾/(𝖾−1)−ϵ𝖾𝖾1italic-ϵ\mathsf{e}/(\mathsf{e}-1)-\epsilonsansserif_e / ( sansserif_e - 1 ) - italic_ϵ. The hardness holds even for the case n=O⁢(1)𝑛𝑂1n=O(1)italic_n = italic_O ( 1 ). For the weighted NSW problem with submodular valuations, [13] showed that the approximation ratio of the local search algorithm becomes O⁢(n⁢wmax)𝑂𝑛subscript𝑤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT ), where wmax:=maxi∈[n]⁡wiassignsubscript𝑤subscript𝑖delimited-[]𝑛subscript𝑤𝑖w_{\max}:=\max_{i\in[n]}w_{i}italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT := roman_max start_POSTSUBSCRIPT italic_i ∈ [ italic_n ] end_POSTSUBSCRIPT italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is the maximum weight over the agents. In the new version [15] of the paper, the authors presented a (6⁢𝖾+ϵ)6𝖾italic-ϵ(6\mathsf{e}+\epsilon)( 6 sansserif_e + italic_ϵ )-approximation algorithm with running time 2O⁢(n⁢log⁡n)⁢poly⁢(m,1/ϵ)superscript2𝑂𝑛𝑛poly𝑚1italic-ϵ2^{O(n\log n)}\mathrm{poly}(m,1/\epsilon)2 start_POSTSUPERSCRIPT italic_O ( italic_n roman_log italic_n ) end_POSTSUPERSCRIPT roman_poly ( italic_m , 1 / italic_ϵ ), which is polynomial when n=O⁢(1)𝑛𝑂1n=O(1)italic_n = italic_O ( 1 ). For the more general setting where the valuations are subadditive, Dobzinski, Li, Rubinstein, and Vondrák [10] recently proposed a constant approximation algorithm when agents are unweighted, provided that we have access to demand oracles for the valuation functions. Our Result. In this paper, we give the first polynomial-time O⁢(1)𝑂1O(1)italic_O ( 1 )-approximation algorithm for weighted Nash social welfare under the submodular valuations. The best result prior to this work was the O⁢(n⁢wmax)𝑂𝑛subscript𝑤O(nw_{\max})italic_O ( italic_n italic_w start_POSTSUBSCRIPT roman_max end_POSTSUBSCRIPT )-approximation due to Garg, Husic, Li, Vega, and Vondrak [13]. Theorem 1.1. For any ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0, there is a randomized (233+ϵ)233italic-ϵ(233+\epsilon)( 233 + italic_ϵ )-approximation algorithm for the weighted Nash social welfare problem with submodular valuations, with running time polynomial in the size of the input and 1ϵ1italic-ϵ\frac{1}{\epsilon}divide start_ARG 1 end_ARG start_ARG italic_ϵ end_ARG. For convenience, we list the known approximation results for the NSW problem in table 1. Additive Submodular Subadditive LB UB LB UB LB UB Unweighted 8787\sqrt{\frac{8}{7}}square-root start_ARG divide start_ARG 8 end_ARG start_ARG 7 end_ARG end_ARG [12] 𝖾1/𝖾+ϵsuperscript𝖾1𝖾italic-ϵ\mathsf{e}^{1/\mathsf{e}}+\epsilonsansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_ϵ [2] 𝖾𝖾−1𝖾𝖾1\frac{\mathsf{e}}{\mathsf{e}-1}divide start_ARG sansserif_e end_ARG start_ARG sansserif_e - 1 end_ARG [16] 4+ϵ4italic-ϵ4+\epsilon4 + italic_ϵ [13] O⁢(1)∗𝑂superscript1O(1)^{*}italic_O ( 1 ) start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT [10] Weighted 𝖾1/𝖾+ϵsuperscript𝖾1𝖾italic-ϵ\mathsf{e}^{1/\mathsf{e}}+\epsilonsansserif_e start_POSTSUPERSCRIPT 1 / sansserif_e end_POSTSUPERSCRIPT + italic_ϵ [11] 233+ϵ233italic-ϵ233+\epsilon233 + italic_ϵ (theorem 1.1) Table 1: Known Results for Nash social welfare. LB and UB stand for lower and upper bounds, respectively. The result with ∗ requires demand oracles for valuation functions. When the function is identical additive, the upper bound for the unweighted case is PTAS [20, 29]. When n=O⁢(1)𝑛𝑂1n=O(1)italic_n = italic_O ( 1 ), the upper bounds for unweighted and weighted NSW with submodular valuations are respectively 𝖾/(𝖾−1)𝖾𝖾1\mathsf{e}/(\mathsf{e}-1)sansserif_e / ( sansserif_e - 1 ) [16] and 6⁢𝖾+ϵ6𝖾italic-ϵ6\mathsf{e}+\epsilon6 sansserif_e + italic_ϵ [15]. 1.1 Overview of Our Techniques Our algorithm leverages the configuration LP introduced in [11] for the additive valuation case. For each agent i∈N𝑖𝑁i\in Nitalic_i ∈ italic_N and subset of items S⊆M𝑆𝑀S\subseteq Mitalic_S ⊆ italic_M, we define a variable yi,Ssubscript𝑦𝑖𝑆y_{i,S}italic_y start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT to indicate whether the set of items assigned to i𝑖iitalic_i is precisely S𝑆Sitalic_S. The objective of this LP is to minimize ∑i,Syi,S⋅wi⋅ln⁡vi⁢(S)subscript𝑖𝑆⋅subscript𝑦𝑖𝑆subscript𝑤𝑖subscript𝑣𝑖𝑆\sum_{i,S}y_{i,S}\cdot w_{i}\cdot\ln v_{i}(S)∑ start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT ⋅ italic_w start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ⋅ roman_ln italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ), the logarithm of the NSW objective. After solving the LP, we apply the rounding procedure from [25], developed for the weighted completion time minimization problem in the unrelated machine scheduling setting. Then we prove concentration bounds for the values obtained by each agent, using arguments developed for pipage rounding. To build intuition, let us focus on the unweighted case. For the special case where |M|=|N|𝑀𝑁|M|=|N|| italic_M | = | italic_N |, the problem reduces to a maximum-weight bipartite matching problem with weights given by the logarithm of values. So, any general algorithm for the problem must capture the maximum weight of the bipartite matching algorithm as a special case. Interestingly, previous results showed that if one is given the largest (i.e., the most valuable) item assigned to every agent, then an O⁢(1)𝑂1O(1)italic_O ( 1 )-approximation algorithm is easy to obtain using local search [13] or LP rounding [14, 26]. For example, with this idea, Garg, Husic, Li, Vega, and Vondrak [13] designed an elegant 4-approximation local search algorithm. They first compute an initial matching of one item to every agent so as to maximize the NSW objective, then assign the remaining items using local search with an endowed valuation function, and finally rematch the initially assigned items to agents to maximize the final Nash social welfare. Unfortunately, their algorithm fails to give an O⁢(1)𝑂1O(1)italic_O ( 1 )-approximation when the agents are weighted. Our algorithm implements the idea of “matching largest items to agents” using the configuration LP solution as a guide. We achieve a per-client guarantee, allowing us to give an O⁢(1)𝑂1O(1)italic_O ( 1 )-approximation for the weighted NSW problem with submodular valuations. After obtaining an LP solution (yi,S∗)i,Ssubscriptsubscriptsuperscript𝑦𝑖𝑆𝑖𝑆(y^{*}_{i,S})_{i,S}( italic_y start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT, for each agent i𝑖iitalic_i and configuration S𝑆Sitalic_S, we designate the largest item in S𝑆Sitalic_S as a “large” item for i𝑖iitalic_i, while treating the remaining items as “small”. This creates a fractional assignment in which each agent receives exactly one fractional large item. While maintaining marginal probabilities in our rounding algorithm, we ensure that each agent gets exactly one large item, and the assignment of small items are negatively correlated. That is, we select a random matching for large items. If the large and small items were disjoint, the rounding algorithm would be straightforward. However, complications arise when an item may be large for one agent and small for another — or even for the same agent in different configurations. This necessitates a correlated assignment strategy for large and small items. This is where we employ the iterative rounding procedure of [25]. We construct a bipartite multi-graph between agents and items, with two edge types: marked edges for large items and unmarked edges for small items. During iterative rounding, we identify either a simple cycle of marked edges or a pseudo-marked path – a simple path of marked edges with two unmarked edges at the ends – and apply rotation or shifting operations on the cycle or path in each iteration. This process ultimately yields an integral assignment. To analyze the approximation ratio, we focus on each agent i𝑖iitalic_i and analyze 𝔼⁢[ln⁡(vi⁢(T))]𝔼delimited-[]subscript𝑣𝑖𝑇\mathbb{E}[\ln(v_{i}(T))]blackboard_E [ roman_ln ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T ) ) ], where T𝑇Titalic_T is the set of items assigned to i𝑖iitalic_i. Note that T𝑇Titalic_T includes exactly one large item, respecting the marginal probabilities. Let TSsuperscript𝑇ST^{\mathrm{S}}italic_T start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT denote the remaining items, i.e., the small items assigned to i𝑖iitalic_i. The assignments of the large item and the small items may be positively correlated, so we analyze the worst-case scenario for this correlation. However, the assignments of the small items are negatively correlated; more precisely, they are determined through a pipage-rounding procedure. Using the concave pessimistic estimator technique from [18] and the submodularity of the function visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, we can establish concentration bounds for vi⁢(TS)subscript𝑣𝑖superscript𝑇Sv_{i}(T^{\mathrm{S}})italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T start_POSTSUPERSCRIPT roman_S end_POSTSUPERSCRIPT ). With the bounds, we can lower bound 𝔼⁢[ln⁡(vi⁢(T))]𝔼delimited-[]subscript𝑣𝑖𝑇\mathbb{E}[\ln(v_{i}(T))]blackboard_E [ roman_ln ( italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_T ) ) ] by ∑Syi,S∗⁢ln⁡vi⁢(S)−O⁢(1)subscript𝑆subscriptsuperscript𝑦𝑖𝑆subscript𝑣𝑖𝑆𝑂1\sum_{S}y^{*}_{i,S}\ln v_{i}(S)-O(1)∑ start_POSTSUBSCRIPT italic_S end_POSTSUBSCRIPT italic_y start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_S end_POSTSUBSCRIPT roman_ln italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_S ) - italic_O ( 1 ). Organization. The rest of the paper is organized as follows. We introduce some preliminaries in section 2, describe our algorithm in section 3, and give its analysis in section 4. For a smoother flow in the main text, we defer some proofs to the appendix."
https://arxiv.org/html/2411.02661v1,Pricing and Competition for Generative AI,"Compared to classical machine learning (ML) models, generative models offer a new usage paradigm where (i) a single model can be used for many different tasks out-of-the-box; (ii) users interact with this model over a series of natural language prompts; and (iii) the model is ideally evaluated on binary user satisfaction with respect to model outputs. Given these characteristics, we explore the problem of how developers of new generative AI software can release and price their technology. We first develop a comparison of two different models for a specific task with respect to user cost-effectiveness. We then model the pricing problem of generative AI software as a game between two different companies who sequentially release their models before users choose their preferred model for each task. Here, the price optimization problem becomes piecewise continuous where the companies must choose a subset of the tasks on which to be cost-effective and forgo revenue for the remaining tasks. In particular, we reveal the value of market information by showing that a company who deploys later after knowing their competitor’s price can always secure cost-effectiveness on at least one task, whereas the company who is the first-to-market must price their model in a way that incentivizes higher prices from the latecomer in order to gain revenue. Most importantly, we find that if the different tasks are sufficiently similar, the first-to-market model may become cost-ineffective on all tasks regardless of how this technology is priced.","The recent explosion of generative artificial intelligence (AI) has introduced new machine learning (ML) frameworks for applications from chatbots to robotics (Wu et al., 2023; Nasiriany et al., 2024). Whereas in classical ML, a user interacted with a single model designed for a specific predictive task (e.g., classification) via input data and output predictions, a single generative AI model can solve a variety of tasks for a user out-of-the-box (Brown et al., 2020). Moreover, users interact with the generative model over a universal interface of natural language prompting (Arora et al., 2022). The prompt-based paradigm has fostered two recent human-AI interaction trends. First, prompting facilitates such a wide distribution of tasks (i.e., user inputs and model outputs) that conventional metrics for evaluating models have become insufficient, leaving the most effective evaluation metric to be a binary score of whether the user is satisfied with the model output (Li et al., 2024; Chiang et al., 2024). For example, Ziegler et al. (2024) empirically analyzed the GitHub Copilot software to reveal that the frequency of generated code approved by a user ‘is a better predictor of perceived [user] productivity than alternative measures.’ Second, if a user does not receive a satisfactory output, they can try again in another prompting round by inputting to the model additional information (Castro et al., 2023). For instance, the Anthropic HH and the Chatbot Arena datasets report on average 2.3 and 1.3 prompting rounds per conversation, respectively (Bai et al., 2022; Chiang et al., 2024). In this work, we study the impact of these interaction characteristics on the pricing of generative AI technology. While classical ML products can be priced by analyzing the user demand for a model that can achieve a given performance metric on a specific task (Gurkan and de Véricourt, 2022; Mahmood et al., 2022), a generative AI model is priced per user prompt 111 In practice, generative AI models are typically priced-per-token. In Appendix B, we show that all our results extend to the price-per-token setting with a minor change of variables. For a list of prices for current generative AI prices, see: https://docsbot.ai/tools/gpt-openai-api-pricing-calculator.. This set price determines the user cost for multiple different tasks and variable number of prompting rounds, e.g., the cost of using GPT-4 for math reasoning or code generation depends only on the per-token price, and the length and number of prompts. Thus, developers of a generative AI product must factor the demand for all potential use-case tasks of the technology when setting a price. This pricing problem becomes further challenging when considering the rapidly growing marketplace of competing generative AI models, since companies must also ensure that their products do not become unattractive to users as soon as a competitor develops a newer and better model. We first characterize when, for a given task, a user will prefer one generative AI model versus another. We argue that users minimize their total cost, measured by the cost-per-prompt times the number of prompting rounds needed for the model to produce a satisfactory output; this leads to a comparison of price-performance competitiveness between AI models. We then study a game with two firms developing competing models used for a set of tasks. Both firms know each other’s model’s performance on the tasks. The first firm deploys their product and sets a price, followed by the second firm with their product and price. Finally, a user decides which models to use for each task. Both firms seek to maximize revenue, but the first firm acts without knowledge of their competitor’s price. Figure 1 summarizes the problem setting and insights. Our key observations include: 1. The pricing problem reduces to a piecewise optimization problem, where firms price their model to be competitive on a subset of the tasks while forgoing revenue from the others. This subset can be determined by ranking the tasks on the competitive ratio between the two models for each task and selecting the most competitive tasks. 2. A firm who deploys late always obtains revenue from at least one task by leveraging the available market information. In contrast, the first-to-market must strategically set their prices to encourage the latecomer to set higher prices and focus on fewer tasks. 3. Under certain conditions on model performance and user demand, the first-to-market may acquire zero revenue regardless of their price. In these settings, the latecomer naturally maximizes their revenue by being competitive for all tasks. Thus, developers that are first should have a minimum model performance before deploying their product. Figure 1: Overview of the competitive pricing problem for generative AI models."
https://arxiv.org/html/2411.02654v1,Fair and Welfare-EfficientConstrained Multi-matchings under Uncertainty,"We study fair allocation of constrained resources, where a market designer optimizes overall welfare while maintaining group fairness. In many large-scale settings, utilities are not known in advance, but are instead observed after realizing the allocation. We therefore estimate agent utilities using machine learning. Optimizing over estimates requires trading-off between mean utilities and their predictive variances. We discuss these trade-offs under two paradigms for preference modeling – in the stochastic optimization regime, the market designer has access to a probability distribution over utilities, and in the robust optimization regime they have access to an uncertainty set containing the true utilities with high probability. We discuss utilitarian and egalitarian welfare objectives, and we explore how to optimize for them under stochastic and robust paradigms. We demonstrate the efficacy of our approaches on three publicly available conference reviewer assignment datasets. The approaches presented enable scalable constrained resource allocation under uncertainty for many combinations of objectives and preference models.","Constrained resource allocation without money underpins many important systems, including reviewer assignment for peer review (our primary example throughout the paper) [31, 54, 45, 16, 4], assigning resources to homeless populations [5, 49, 34], distributing emergency response resources [51, 56, 57], and more [53, 44, 1]. In these settings we assign resources to agents. Agents and resources are constrained; each agent has bounds on the minimum or maximum number of items they receive from different categories, and each item has required minimums and limited total capacity. Each agent has a valuation for every item, and we optimize a welfare function of the agent-item valuations. In the case of reviewer assignment, the reviewer-paper valuations measure the alignment between reviewers and papers, papers must receive a certain number of reviews from unique reviewers, reviewers have upper limits on the number of papers they can review, and conflicts of interest prevent some reviewers from being assigned to certain papers. A crucial factor in all of the above settings is the presence of uncertainty. Uncertainty often stems from the fact that agents’ valuations for resources depend on future outcomes. In reviewer assignment, a reviewer-paper pair’s match quality is observed only after the reviewer submits his or her review. Uncertainty may also stem from our limited ability to collect data; for example, in deciding where to target lead pipe mitigation projects based on number of school-aged children per neighborhood, we may have access to imperfect school enrollment records, allowing only an approximate model of the impacts of mitigation on children in each neighborhood [53]. We adopt two possible stances towards uncertainty, depending on the information available. When we have access to a probability distribution over preferences, we optimize the conditional expectation of the distribution at percentiles of interest [50, 33]. When we have access to a set of possible preferences, we adopt the robust approach, which is related to the minimax regret objective used in solving robust assignment problems [3, 10, 11, 32]. Uncertainty-aware optimization approaches can often result in significantly different allocations from the default of optimizing for welfare over a central estimate (see Example 2.1 for an intuitive explanation for this phenomenon). Typically, we maximize the sum of agent utilities. However, in many of these settings, we are also concerned with fairness to individuals or groups of agents. Groups of agents may represent subject areas of papers in reviewer assignment, demographic groups in poverty alleviation campaigns, or regional groupings of computational resources in bandwidth allocation. Fairness to these groups may be legally required in some cases; in others it is an ethical choice by the decision maker. Although groups are often first-class objects worthy of receiving fair treatment, group fairness is often the smallest granularity of fairness achievable under uncertainty – in a large dataset uncertainty will always cause some individuals to have vanishing welfare, but group welfare can still be upheld. Although there is much literature on combinatorial optimization under uncertainty [33, 3, 10, 11, 32], to our knowledge it has not addressed the intersection of fairness and uncertainty in the constrained multi-matching problem. 1.1 Our Contributions We study the broad problem of fair and efficient constrained multi-matchings under uncertainty about agents’ valuations. We optimize for welfare while simultaneously accounting for the uncertainty inherent in real-world resource allocation problems. Specifically, we develop methods to efficiently optimize the utilitarian and egalitarian welfare objectives using the robust approach [26, 8, 7] and the CVaRCVaR\operatorname{CVaR}roman_CVaR approach [50]. Our results are summarized in Table 1. For robust optimization, we construct an uncertainty set containing the true preferences with high probability (Section 3). This model is appropriate when building a predictor with statistical error bounds, but without making any assumptions on the full probability distribution over valuations. For utilitarian and egalitarian welfare functions, we robustly maximize welfare over such uncertainty sets. When the uncertainty sets are linear we can efficiently compute the exact optimal allocations for both utilitarian and egalitarian welfare in polynomial time (Corollaries 3.2 and 3.6). Under a single ellipsoidal uncertainty set, we can apply an iterated quadratic programming approach (Corollaries 3.3 and 3.7), while a projected subgradient ascent approach is needed when uncertainty sets consist of multiple ellipsoids (Propositions 3.1 and 3.5). Under general monotonic, concave welfare functions and arbitrary convex uncertainty sets, we apply the relatively expensive adversarial projected subgradient ascent algorithm of Cousins et al. [16]. When the market designer can construct a full probability distribution over preferences or sample from such a distribution, we consider stochastic optimization using the concept of Conditional Value at Risk, or CVaRCVaR\operatorname{CVaR}roman_CVaR [50]. This approach, laid out in Section 4, selects an allocation that maximizes the conditional expectation of welfare over the left tail of the welfare distribution. We often approximate CVaRCVaR\operatorname{CVaR}roman_CVaR objectives using sampling, then solve the resulting linear program or LP (as in Propositions 4.1 and H.3). However, in the case of utilitarian welfare and Gaussian-distributed valuations we present a simple reformulation of the CVaRCVaR\operatorname{CVaR}roman_CVaR objective (Proposition 4.3). Optimizing CVaRCVaR\operatorname{CVaR}roman_CVaR for general monotonic, concave welfare functions can require solving arbitrary concave optimization problems, even after sampling. We also compare these optimization approaches empirically in Section 5 on reviewer assignment data from AAMAS 2015201520152015, 2016201620162016, and 2021202120212021. 1.2 Related work We discuss the history of prior work on robust and CVaRCVaR\operatorname{CVaR}roman_CVaR optimization in Appendix A. Some existing work applies stochastic or robust optimization to fair division problems. A line of work studies the minimax regret objective in combinatorial optimization problems, such as constrained resource allocation [3, 10, 11, 32]. This work does not explicitly consider multi-matching problems like those considered here, nor does it address the robust egalitarian welfare problem. Pujol et al. [48] study fair division problems with parameters noised for differential privacy, showing that the noise can cause unfair allocations; they propose a Monte Carlo approach to mitigate the unfairness with high probability. Peters et al. [46] study envy-free rent division under probabilistic uncertainty. A central mechanism divides rooms and sets room prices for the items to minimize envy. We study a setting without money, both utilitarian and egalitarian objectives, and robust optimization in addition to stochastic optimization. Cousins et al. [16] study robust optimization under the utilitarian objective. They propose an adversarial projected subgradient ascent method which requires solving a two quadratic programs (one for the adversary and one for the projection) at each iteration for a large number of iterations. Our empirical analysis in Section 5 demonstrates the inefficiency of this method. Fair machine learning algorithms [43, 23, 17, 59, 22] often employ similar adversarial optimization techniques over an uncertainty set in a machine learning context. Other fair allocation research has studied the case where agent demand or item availability are uncertain but preferences are known [14, 21, 27, 2]. In our case demand and availability are known but preferences are not. Devic et al. [20] consider fair two-sided matching where the fairness constraint is defined with respect to unknown parameters; we assume knowledge of the parameters that define the fairness constraint (i.e., group identities)."
https://arxiv.org/html/2411.02377v1,Two-Sided Learning in Decentralized Matching Markets,"Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications. In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups. However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another. In this work, we design completely uncoupled and uncoordinated policies that use an agent’s limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences. In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets. Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy. We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group. To the best of the authors’ knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty.","Two-sided matching markets are a fundamental feature of various socioeconomic and engineered systems. In a two-sided market, agents from two distinct groups interact to form mutually beneficial partnerships. From college admissions to online dating, such markets arise ubiquitously. However, the ways in which matchings—sets of partnerships between agents—emerge can vary significantly depending on the market. Consider, for example, the American residency admissions process. Every year, residency applicants and hospitals submit their rankings of one another to the National Resident Matching Program (NRMP), the organization that assigns a matching between the two groups (Figure 1, left). Then, the NRMP employs an algorithm that uses these rankings to identify a stable matching, characterized by the property that no applicant and hospital prefer one another to their assigned partner. Identifying stable matchings is of paramount importance, as it ensures notions of fairness and efficiency in the resulting assignment. Providentially, at least one stable matching is guaranteed to exist in every two-sided matching market Gale and Shapley (1962), and a number of celebrated algorithms such as the one utilized in the NRMP have been developed to identify them Gale and Shapley (1962); Vate (1989); Roth et al. (1993); Roth and Peranson (1997). Importantly, because this process is centralized (i.e., the matching is assigned by the NRMP), one can always ensure that the resulting matching is stable. In contrast, in decentralized matching markets, there is no centralized entity that assigns the partnerships between agents. Instead, there is typically an active group of agents that iteratively seeks out, or proposes to, a passive group of agents that receives, or accepts, these proposals. This situation often arises in labor markets, where workers repeatedly attempt to win over desirable clients, and clients accept their most attractive offer from a worker. Depending on the agents’ policies (i.e., how they choose to make and accept proposals), a variety of matchings may arise in decentralized markets. However, in the case where agents know their own preferences over the other side of the market a priori, a number of natural policies are known to result in a matching that is stable Gale and Shapley (1962); Roth and Vate (1990); Blum et al. (1997); Ackermann et al. (2008), preserving the guarantees of fairness and efficiency ingrained in the centralized setting. However, in many practical decentralized markets, the assumption that agents know their own preferences does not hold. For example, in labor markets with massive numbers of workers and clients, it can be challenging for every worker to rank all of the clients and vice versa, making it difficult or impossible for agents to follow any kind of policy that uses their rankings. Motivated by these kinds of decentralized markets, several recent works have made significant progress in designing novel policies whereby agents simultaneously and independently learn their own preferences while forming matchings, with the added guarantee that the matchings resulting from these policies are stable Liu et al. (2020, 2021); Basu et al. (2021); Jagadeesan et al. (2021); Cen and Shah (2022); Maheshwari et al. (2022); Kong and Li (2023); Hosseini et al. (2024). In the case of one-sided learning, where the proposing agents do not know their own preferences, but the accepting agents do, a handful of completely decentralized and uncoordinated policies have recently been shown to guarantee different notions of probabilistic convergence to stable matchings Etesami and Srikant (2024); Shah et al. (2024). In the case of two-sided learning, where no agent knows their own preferences (Figure 1, right), a few works have designed algorithms with similar guarantees, but they require some form of centralized communication or coordination between the agents that may not be possible in practical scenarios Das and Kamenica (2005); Pagare and Ghosh (2023); Pokharel and Das (2023). Thus, the challenge of designing completely decentralized and uncoordinated policies for the two-sided setting that guarantee convergence to stability remains unresolved. Figure 1. A two-sided matching market with 3 proposers and 3 acceptors. In a centralized environment with full information (left), an algorithm uses the agents’ known preferences to assign a matching. In a decentralized environment with two-sided uncertainty (right), agents learn their own preferences over one another as they interact and form matchings. In this work, we aim to design policies for both the one- and two-sided learning settings that do not require agents to communicate or coordinate with one another. To this end, we consider trial-and-error learning, a type of policy that enables agents to learn their preferences over partners through structured yet random exploration. In our preliminary results (Theorem 1), we demonstrate that a simple form of trial-and-error learning guarantees a notion of probabilistic convergence to stable matchings in the case of one-sided learning. Then, in our first main contribution (Theorem 2), we show that the same result holds true in the case of two-sided learning. Inspired by similar questions of strategyproofness in matching markets Dubins and Freedman (1981); Gale and Sotomayor (1985), we then ask whether one group of agents can strategically improve their outcome when the other group of agents continues to follow simple trial-and-error learning. In our second main contribution (Theorem 3), we constructively answer this question in the affirmative, demonstrating that if the accepting group of agents follows a more advanced version of trial-and-error learning, then the process will converge to their most preferable stable matching. To the best of the authors’ knowledge, these are the first completely decentralized and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized matching markets with two-sided uncertainty. These policies are inspired by results on learning in games, a subfield of game theory concerned with the design of policies that ensure probabilistic convergence to desirable configurations such as Nash equilibria or Pareto efficient action profiles Young (1993); Fudenberg and Levine (1998); Marden et al. (2009); Pradelski and Young (2012); Marden et al. (2014). By adapting these ideas to the realm of two-sided matching markets, we are able to provide fundamental results regarding the existence of simple policies that guarantee convergence to stability in the presence of uncertainty."
https://arxiv.org/html/2411.02308v1,Nash Equilibria via Stochastic Eigendecomposition,"This work proposes a novel set of techniques for approximating a Nash equilibrium in a finite, normal-form game. It achieves this by constructing a new reformulation as solving a parameterized system of multivariate polynomials with tunable complexity. In doing so, it forges an itinerant loop from game theory to machine learning and back. We show a Nash equilibrium can be approximated with purely calls to stochastic, iterative variants of singular value decomposition and power iteration, with implications for biological plausibility. We provide pseudocode and experiments demonstrating solving for all equilibria of a general-sum game using only these readily available linear algebra tools.","Nash equilibrium (NE) is the central solution concept for finite, normal-form games. Unfortunately, unless PPAD ⊆\subseteq⊆ P, no fully polynomial time algorithm exists to approximate it in generic, general-sum games (Daskalakis et al., 2009; Chen and Deng, 2006; Daskalakis, 2013). Nevertheless, it is important to develop a variety of techniques, for instance, tailored to different restricted game classes or honed to select out equilibria with particular properties. No-regret or gradient-based approaches are particularly lightweight and have been effective in certain applications although they come with no NE-convergence guarantees beyond 2222-player, zero-sum (Facchinei and Pang, 2007; Gordon et al., 2008; Blackwell et al., 1956; Vlatakis-Gkaragkounis et al., 2020). Homotopy methods have been designed to select out specific equilibria (Lemke and Howson, 1964; Govindan and Wilson, 2003, 2004; Harsanyi et al., 1988; Perolat et al., 2020), some with the additional characteristic of modelling players with bounded rationality (McKelvey and Palfrey, 1995, 1998; Turocy, 2005; Eibelshäuser and Poensgen, 2019; Gemp et al., 2022). The primary measure of approximation for NEs is exploitability, the maximum any player can gain by deviating from an approximate equilibrium profile. Hence, there exists a line of work that directly attempts to minimize exploitability using an optimization formulation (Shoham and Leyton-Brown, 2009; Sandholm et al., 2005; Gemp et al., 2023). Similarly, the property that no player can gain by deviating can be viewed as a constraint. Constraint satisfaction approaches were found to be effective empirically (Porter et al., 2008); other methods also take a search-tree approach (Berg and Sandholm, 2017; Gemp et al., 2023). Figure 1. (An Itinerant Loop) We identify a series of bridges—some new, some old, and some a mix—that connects the problem of approximating Nash equilibria in normal-form games to problems in algebraic geometry, linear algebra, machine learning, and back again to finite games (albeit not precisely where the loop began). The boundaries between these families are not strict: search-based approaches mix with optimization, gradient based with homotopy-based approaches, etc. Of particular relevance to this work is the family of approaches that view the NE problem (NEP) as solving for the common roots of a system of multivariate polynomials subject to some constraints. For instance, an NEP can be represented as a polynomial complementarity problem (PCP) (Wilson, 1971): for each player, either an action is played with zero probability at an NE or it achieves the maximum payoff possible at the NE. Probabilities can be recovered from the unconstrained solutions to the PCP via normalization. An NEP can also be represented as a multivariate polynomial problem (MVP) with simplex constraints (Sturmfels, 2002, Section 6.3). Assuming a fully-mixed NE (i.e., one that lies in the interior of the simplex) exists, it can be solved for via a similar approach as above. Sturmfels (2002) demonstrates solving for these equilibria via PHCpack (Verschelde, 1999), a software package to solve polynomial systems by homotopy continuation methods. Unsurprisingly, these and other methods (Li, 1997) have parallels with the homotopy methods for approximating Nash equilibria mentioned above. Recently, renewed interest in numerical methods for solving polynomial systems via eigendecompositions has surged. While knowledge of these techniques has existed for some time, the goal of new research is to make these techniques more accessible to non-experts (Dreesen et al., 2012; Williams, 2010) as well as further developing the techniques (Vermeersch, 2023). These techniques generally assume access to linear algebra routines that make few assumptions on the matrices of interest. Contrast that with machine learning (ML) (Allen-Zhu and Li, 2017), where singular value decomposition (SVD) has received the bulk of the community’s interest, and whose underlying eigenvalue problem assumes a symmetric, positive semi-definite matrix. The focus here has been scaling to large matrices and reducing memory requirements by leveraging stochastic access to matrix entries. In this work, we develop a novel formulation of the approximate Nash equilibrium problem as a multivariate polynomial problem. Central to this formulation is the regularization of the game with Tsallis entropy (Gemp et al., 2022). Similar to other frameworks of bounded rationality such as logit equilibria (McKelvey and Palfrey, 1995), we can show this Tsallis regularized game is equivalent to a game where the log of the payoffs are perturbed by Gumbel(0,τ0𝜏0,\tau0 , italic_τ) noise (see Appendix B). Critically, given an approximate equilibrium x(τ)superscript𝑥𝜏x^{(\tau)}italic_x start_POSTSUPERSCRIPT ( italic_τ ) end_POSTSUPERSCRIPT of the transformed game, we also provide bounds on the exploitability of x(τ)superscript𝑥𝜏x^{(\tau)}italic_x start_POSTSUPERSCRIPT ( italic_τ ) end_POSTSUPERSCRIPT as measured in the original game similar to prior work (Gemp et al., 2023). Our MVP formulation is different from prior work and exhibits a distinct advantage. Whereas prior work results in MVPs that are at least quadratic, an NP-hard problem (Courtois et al., 2002), ours results in an MVP that is linear for the class of 2222-player, general-sum games and for a specific setting of the Tsallis entropy parameter τ𝜏\tauitalic_τ. Therefore, this new formulation can provide fast approximate solutions to 2222-player, general-sum games via a simple least squares solver. For the wider class of N𝑁Nitalic_N-player, general-sum games, we show how to solve for NEs using only access to stochastic singular value decomposition (SVD) and power iteration (Golub and Van Loan, 2013). Lastly, given SVD’s recent reformulation as a Nash equilibrium problem, specifically an EigenGame (Gemp et al., 2021a), we explain a mapping from the original NE problem to a sequence of NE problems on larger, albeit strategically simpler games (see Figure 1). All but the final step of our approach that uses power iteration can be interpreted as a new normal-form game thereby establishing a tree of NE problems (see Figure 6)."
https://arxiv.org/html/2411.01810v1,A Polynomial-Time Algorithm for Fair and Efficient Allocation with a Fixed Number of Agents,"We study the problem of fairly and efficiently allocating indivisible goods among agents with additive valuation functions. Envy-freeness up to one good (EF1) is a well-studied fairness notion for indivisible goods, while Pareto optimality (PO) and its stronger variant, fractional Pareto optimality (fPO), are widely recognized efficiency criteria. Although each property is straightforward to achieve individually, simultaneously ensuring both fairness and efficiency is challenging. Caragiannis et al. [CKM+19] established the surprising result that maximizing Nash social welfare yields an allocation that is both EF1 and PO; however, since maximizing Nash social welfare is NP-hard, this approach does not provide an efficient algorithm. To overcome this barrier, Barman, Krishnamurthy, and Vaish [BKV18] designed a pseudo-polynomial time algorithm to compute an EF1 and PO allocation, and showed the existence of EF1 and fPO allocations. Nevertheless, the latter existence proof relies on a non-constructive convergence argument and does not directly yield an efficient algorithm for finding EF1 and fPO allocations. Whether a polynomial-time algorithm exists for finding an EF1 and PO (or fPO) allocation remains an important open problem.In this paper, we propose a polynomial-time algorithm to compute an allocation that achieves both EF1 and fPO under additive valuation functions when the number of agents is fixed. Our primary idea is to avoid processing the entire instance at once; instead, we sequentially add agents to the instance and construct an allocation that satisfies EF1 and fPO at each step.","The fair division problem has been a central research topic across various fields, including mathematics, economics and computer science, since it was formally introduced by Steinhaus [Ste49]. This problem aims to allocate resources among agents in a fair and efficient manner. It has various real-world applications, including rent division [ES99], course allocation [BCKO17, OSB10], pilot-to-plane assignment for airlines, allocation of tasks to workers, articles to reviewers, and fair recommender systems. Early studies primarily focused on divisible goods, resulting in extensive literature on fair division in mathematics and economics [BT96, RW98, Mou04, BCE+16]. A widely accepted standard of fairness is envy-freeness (EF) [Fol66], which requires that each agent prefers their own bundle to that of any other agent. On the other hand, Pareto optimality (PO) is a fundamental efficiency criterion: an allocation is Pareto optimal if no allocation exists that makes an agent better off without making any other agent worse off. Pareto optimality is independent of fairness, and is widely used to evaluate whether allocations are efficient and free of waste. Varian [Var74] notably showed that, for divisible goods, there always exists an envy-free and Pareto optimal allocation. Furthermore, it can be computed in polynomial time under additive valuation functions [EG59, DPSV08, Orl10, Vég12]. In contrast, for indivisible goods, where each good must be allocated to a single agent, envy-free allocations are not guaranteed to exist. For instance, even in the simple case of distributing a single good between two agents, no envy-free allocation is possible. This limitation implies that classical fairness concepts and algorithms are often inapplicable to indivisible goods, motivating research into new fairness concepts and algorithms specifically suited to discrete fair division problems. For an overview of recent advances in this area, we refer the reader to recent surveys [AAB+23, Wal21]. To address the fair division problem with indivisible goods, several relaxed fairness notions have been proposed. One well-studied fairness notion is Envy-Freeness up to one good (EF1), introduced by Budish [Bud11]. EF1 requires that each agent prefers their own bundle to that of any other agent after removing at most one good from the latter’s bundle. Under monotone valuation functions, it has been shown that an EF1 allocation always exists and can be computed in polynomial time [LMMS04]. Achieving EF1 or PO individually is straightforward; however, whether EF1 and PO can be attained simultaneously is a key question. Caragiannis et al. [CKM+19] established the surprising result that, under additive 111Additivity implies that each agent’s valuation for a set of goods equals the sum of their valuations for each individual good within that set. valuations, maximizing Nash social welfare [Nas50, KN79], defined as the geometric mean of the agents’ valuations, results in an allocation that is both EF1 and PO. However, since maximizing Nash social welfare is NP-hard [NNRR14] and even APX-hard [Lee17], this approach does not directly yield an efficient algorithm. To overcome this barrier, Barman, Krishnamurthy, and Vaish [BKV18] proposed a pseudo-polynomial time algorithm that computes an EF1 and PO allocation and proved that an EF1 and fractionally Pareto optimal (fPO) allocation always exists. An allocation is fractionally Pareto optimal (fPO) if no fractional allocation exists that makes an agent better off without making any other agent worse off. Nevertheless, their existence proof relies on a non-constructive convergence argument and does not directly yield an algorithm for computing such an allocation. Clearly, fPO is a stronger efficiency criterion than PO. In addtion, fPO allocations offer another advantage over PO allocations: Given an allocation, fPO can be verified efficiently [SSH22], whereas verifying whether an allocation is PO is coNP-complete [DKBKZ09]. This efficient verification is particularly advantageous when a centralized authority conducts the allocation since all participants can verify that the allocation is fPO (and therefore also PO). However, this efficient verification is not feasible for PO allocations. Whether a polynomial-time algorithm exists for finding an EF1 and PO (or fPO) allocation remains an important open problem. 1.1 Related Work Fair and efficient allocation for indivisible goods Caragiannis et al. [CKM+19] established that, under additive valuations, maximizing Nash social welfare [Nas50, KN79] yields an allocation that is both EF1 and PO. An approach commonly used to find allocations that satisfy both fairness and PO uses the connection between fair division and market equilibrium in Fisher markets [Bud11]. Barman, Krishnamurthy, and Vaish [BKV18] developed a pseudo-polynomial time algorithm to compute an allocation that is both EF1 and PO. They further showed the existence of an EF1 and fPO allocation. Barman and Krishnamurthy [BK19] developed a strongly polynomial-time algorithm that computes a PROP1 and fPO allocation, where PROP1 (Proportionality up to one good) is a fairness notion that is weaker than EF1 under additive valuation functions. Garg and Murhekar [GM24] proposed a pseudo-polynomial time algorithm for computing EF1 and fPO allocations. However, due to significant issues in their proof, we were unable to verify its correctness (see Appendix B for details). They also reported that when the number of agents is fixed, there exists a polynomial-time algorithm to compute an EF1 and PO allocation. Garg and Murhekar [GM23] showed that under additive, bi-valued valuation functions, an EFX (envy-free up to any good) and fPO allocation exists and can be computed in polynomial time. They also established that EFX and PO are incompatible in instances with three distinct values. Here, EFX, which is a stronger fairness notion than EF1, requires that each agent prefers their own bundle to that of any other agent after removing any single good from the latter’s bundle. Freeman et al. [FSVX19] showed that if all values are positive, an EQX+PO allocation always exists; however, they also showed that when values may be zero, an EQ1+PO allocation does not exist. Here, EQ1 (equitability up to one good) and EQX (equitability up to any good) refer to equitability criteria. Fair and efficient allocation for indivisible chores The fair division problem for chores (items with negative value) is also an important research topic. In this context, concepts such as EF1 and PO can be defined analogously to their counterparts in the case of goods. However, unlike for indivisible goods, the existence of an EF1 and PO allocation for chores under additive valuations remains an open problem. To address this issue, several studies have focused on restricted instances. The existence and polynomial-time computability of EF1 and fPO allocations for chores are known in the following cases: bi-valued instances [EPS22, GMQ22]; instances with two types of chores [ALRS23]; instances with three agents [GMQ23]; and instances with two types of agents [GMQ23]. Approximating Nash social welfare The development of approximation algorithms for maximizing Nash social welfare has been an active research topic in theoretical computer science in recent years, as maximum Nash social welfare (MNW) allocations satisfy both EF1 and PO [CKM+19]. For additive valuation functions, the first constant-factor approximation algorithm, achieving a ratio of 2⋅e1/e≈2.88⋅2superscripte1e2.882\cdot\mathrm{e}^{1/\mathrm{e}}\approx 2.882 ⋅ roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT ≈ 2.88, was proposed by Cole and Gkatzelis [CG18]. This factor was subsequently improved to ee\mathrm{e}roman_e [AOGSS17], further refined to 2 [CDG+17], and currently stands at the best-known approximation ratio of e1/e+ϵ≈1.45superscripte1eitalic-ϵ1.45\mathrm{e}^{1/\mathrm{e}}+\epsilon\approx 1.45roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT + italic_ϵ ≈ 1.45 [BKV18]. Although approximating MNW is itself an interesting research topic, it is worth noting that an approximate MNW allocation does not necessarily satisfy EF1 or PO. In contrast, the 1.45-approximation algorithm by [BKV18] notably provides guarantees of approximate EF1 and PO, a significant achievement in this context. In addition, similar approximation guarantees have been established for more general market models, such as piecewise-linear concave valuations [AMGV18], budget-additive valuations [GHM18], submodular valuations [GKK23], and multi-unit markets [BGHM17]. 1.2 Our Contributions The main contribution of this paper lies in proposing a polynomial-time algorithm to compute an allocation that achieves both EF1 and fPO under additive valuation functions when the number of agents is fixed. Theorem 1.1. When each agent has an additive valuation function and the number of agents is fixed, an EF1 and fPO allocation can be computed in polynomial time. Moreover, our approach directly contributes to the Nash social welfare maximization problem. As mentioned above, Barman, Krishnamurthy, and Vaish [BKV18] developed a 1.45-approximation algorithm for maximizing Nash social welfare that achieves approximate EF1 and PO. We show that similar results hold: the EF1 and fPO allocation produced by our algorithm also serves as an e1/e≈1.444superscripte1𝑒1.444\mathrm{e}^{1/e}\approx 1.444roman_e start_POSTSUPERSCRIPT 1 / italic_e end_POSTSUPERSCRIPT ≈ 1.444-approximation algorithm for the Nash social welfare maximization problem. Note that the Nash social welfare maximization problem is NP-hard even when there are only two agents. This result is significant as it provides theoretical guarantees for both fairness and efficiency while also approximating Nash social welfare. Theorem 1.2. When each agent has an additive valuation function and the number of agents is fixed, there exists a polynomial-time e1/esuperscripte1e\mathrm{e}^{1/\mathrm{e}}roman_e start_POSTSUPERSCRIPT 1 / roman_e end_POSTSUPERSCRIPT-approximation algorithm for the Nash social welfare maximization problem. Furthermore, the resulting allocation satisfies both EF1 and fPO. 1.3 Our Techniques Our approach builds on the techniques introduced by Barman, Krishnamurthy, and Vaish [BKV18]. We begin by briefly outlining their method. They developed a pseudo-polynomial time algorithm to compute an allocation that is both EF1 and PO. Their algorithm first perturbs valuations to a desirable form, then computes an EF1 and fPO allocation for this perturbed instance. This resulting allocation is approximately EF1 and PO with respect to the original instance and becomes EF1 and PO if the perturbation is sufficiently small. Specifically, their algorithm maintains an integral allocation and prices for goods at each step, ensuring they correspond to an equilibrium outcome in a Fisher market. This equilibrium guarantees fPO by the first welfare theorem. The algorithm adjusts the allocation and prices iteratively by reallocating goods and increasing prices to approach a fairer allocation. The algorithm stops once the current allocation and prices achieve approximate price envy-freeness up to one good (pEF1). Here, pEF1 requires that the spending of each agent is at least as high as that of any other agent after removing the most expensive good in the latter’s bundle. Requiring the spending to be balanced in this manner yields EF1 for the corresponding fair division instance. Our primary idea is to avoid processing the entire instance at once; instead, we sequentially add agents to the instance and construct an allocation that satisfies EF1 and fPO at each step. In the k𝑘kitalic_k-th iteration of the algorithm, we start with an EF1 and fPO allocation for an instance of k−1𝑘1k-1italic_k - 1 agents, add the k𝑘kitalic_k-th agent to the instance, and find a new allocation that satisfies EF1 and fPO for k𝑘kitalic_k agents. To do this, the algorithm maintains an allocation and prices for goods that correspond to an equilibrium outcome in a Fisher market. In the k𝑘kitalic_k-th iteration, the algorithm achieves a PEF1 allocation by reallocating goods and adjusting prices. During this process, the allocation remains EF1 and fPO for the existing k−1𝑘1k-1italic_k - 1 agents, while the reallocating and price increase are designed to eliminate the dissatisfaction of the newly added k𝑘kitalic_k-th agent. Our approach differs from previous methods in several notable respects. First, we do not perturb the instance; rather, we compute an allocation that directly satisfies EF1 and fPO for the given instance. Second, in each iteration of our algorithm, we ensure that the minimum spender, who is the agent with the lowest spending, is always the newly added agent k𝑘kitalic_k. In previous algorithms, the minimum spender may change during reallocation, but our algorithm consistently operates to eliminate the dissatisfaction of k𝑘kitalic_k-th agent. This introduces a “direction” for achieving fairness and enables new techniques to bound the number of iterations. Third, in the k𝑘kitalic_k-th iteration, since we need to maintain EF1 and fPO for the existing k−1𝑘1k-1italic_k - 1 agents, we allow for simultaneous exchanges of multiple goods. As far as we know, this approach is novel in the context of constructing fair and efficient allocations. 1.4 Organization In Section 2, we introduce the fair division model and the relevant notions of fairness and efficiency. We also present the Fisher market framework and define key notions such as price envy-freeness, minimum spenders, maximum violators, and the MBB graph. Section 3 gives a detailed description of the algorithms we propose. In Section 4, we analyze our algorithms and prove Theorem 1.1. Finally, in Section 5, we summarize our results and suggest directions for future research. Additionally, in Appendix A, we provide the proof of Theorem 1.2, and in Appendix B, we discuss an error of the proof in [GM24]."
https://arxiv.org/html/2411.01721v1,Computational Lower Bounds for Regret Minimizationin Normal-Form Games,"A celebrated connection in the interface of online learning and game theory establishes that players minimizing swap regret converge to correlated equilibria (CE)—a seminal game-theoretic solution concept. Despite the long history of this problem and the renewed interest it has received in recent years, a basic question remains open: how many iterations are needed to approximate an equilibrium under the usual normal-form representation? In this paper, we provide evidence that existing learning algorithms, such as multiplicative weights update, are close to optimal. In particular, we prove lower bounds for the problem of computing a CE that can be expressed as a uniform mixture of T𝑇Titalic_T product distributions—namely, a uniform T𝑇Titalic_T-sparse CE; such lower bounds immediately circumscribe (computationally bounded) regret minimization algorithms in games. Our results are obtained in the algorithmic framework put forward by Kothari and Mehta (STOC 2018) in the context of computing Nash equilibria, which consists of the sum-of-squares (SoS) relaxation in conjunction with oracle access to a verification oracle; the goal in that framework is to lower bound either the degree of the SoS relaxation or the number of queries to the verification oracle. Here, we obtain two such hardness results, precluding computing i) uniform log⁡n𝑛\log nroman_log italic_n-sparse CE when ϵ=poly⁢(1/log⁡n)italic-ϵpoly1𝑛\epsilon=\mathrm{poly}(1/\log n)italic_ϵ = roman_poly ( 1 / roman_log italic_n ) and ii) uniform n1−o⁢(1)superscript𝑛1𝑜1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT-sparse CE when ϵ=poly⁢(1/n)italic-ϵpoly1𝑛\epsilon=\mathrm{poly}(1/n)italic_ϵ = roman_poly ( 1 / italic_n ).","A celebrated line of research in the interface of algorithmic game theory and online learning revolves around the repeated interaction of multiple players in a game. Much of this theory stems from the realization that players engaging rationally—in that their behavior is consistent with some notion of hindsight rationality or no-regret—converge to a certain game-theoretic solution concept known as (coarse) correlated equilibrium (CE) \citepHart00:Simple,Foster97:Calibrated. From an algorithmic standpoint, perhaps the most pressing question emerging from that connection pertains to the number of iterations needed to approximate an equilibrium. One answer put forward in the online learning literature postulates that each player is facing an adversarial environment, a regime which is by now well-understood commencing from some early influential work \citepLittlestone94:Weighted,Littlestone87:Learning. When learning in games, however, players instead interact with other learning algorithms; the obvious concern thus is that the predictions of the traditional no-regret framework are overly pessimistic. Indeed, it turns out that barriers ingrained in the adversarial regime can be circumvented when specialized algorithms are in place (e.g., \citepSyrgkanis15:Fast,Rakhlin13:Optimization,Daskalakis15:Near,Daskalakis21:Near,Erez23:Regret,Daskalakis22:Fast,Cai24:Near). As a notable example, \citetDaskalakis21:Near showed that a simple variant of the celebrated multiplicative weights update algorithm guarantees (external) regret growing only as O⁢(log4⁡T⁢log⁡n)𝑂superscript4𝑇𝑛O(\log^{4}T\log n)italic_O ( roman_log start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT italic_T roman_log italic_n ) after T𝑇Titalic_T repetitions of any game with a constant number of players, where n𝑛nitalic_n here and throughout represents the number of actions of each player; this is a significant improvement over the Ω⁢(T⁢log⁡n)Ω𝑇𝑛\Omega(\sqrt{T\log n})roman_Ω ( square-root start_ARG italic_T roman_log italic_n end_ARG ) information-theoretic barrier when facing an adversary \citepCesa-Bianchi06:Prediction. Practical experience also suggests a considerable gap between existing theoretical predictions and observed behavior for no-regret dynamics, manifested in attaining remarkable performance even in enormous games \citepBowling15:Heads. It is worth stressing that even though a correlated equilibrium can be computed exactly via linear programming \citepPapadimitriou08:Computing, no-regret dynamics are in many ways more appealing from a computational standpoint, mostly attributed to their scalability and their decentralized nature; it has also been argued that they constitute more plausible models of learning \citepSandholm10:Population. Despite the rich history of this foundational problem, the number of iterations needed for no-regret learners to approximate an equilibrium remains an outstanding open problem. In this paper, we study the complexity of no-regret learning in games from a computational perspective, under the premise that learners employ polynomial-time algorithms to update their strategies. At first glance, it might be unclear why and how computation circumscribes no-regret learning. This can be grasped by considering first an extreme case: what prevents both learners from incurring small regret after a single iteration? The answer is that this would result in a Nash equilibrium (NE) of the underlying game—a stronger notion than correlated equilibria, which can be immediately ruled out in light of well-known computational barriers in general-sum games \citepRubinstein16:Settling,Chen09:Settling,Daskalakis08:Complexity,Boodaghians20:Smoothed,Deligkas22:Pure,Etessami07:Complexity,Kothari18:Sum. But can those lower bounds be extended for multiple iterations of no-regret learning? To address this question, we investigate the complexity of computing a correlated equilibrium under the additional constraint that it can be expressed as a uniform mixture of T𝑇Titalic_T product distributions—henceforth, uniform T𝑇Titalic_T-sparse CE (Definition 1.2). Intractability concerning sparse CE immediately lower bounds the number of iterations for computationally bounded no-regret learners. Further, a compelling aspect of this approach is that, unlike other lower bounds based on query complexity (discussed in Section 1.4), it applies even if the players know the game upfront and can coordinate prior to the learning phase. This program has been followed with success starting from the work of \citetFoster23:Hardness in the context of Markov (aka. stochastic) games, and continued by \citetPeng24:Complexity targeting games with imperfect information. Yet, no progress has been made in understanding the complexity of sparse CE in normal-form games, which constitutes the canonical representation treated in the literature. It is worth stressing here that although computing 2222-sparse CE appears to be a similar problem to computing NE (that is, 1111-sparse CE), adapting existing reductions based on the latter to the former turns out to be particularly challenging; relaxing players’ independence—as in Nash equilibria—immediately introduces considerable technical obstacles. Our contribution here is to tackle those challenges and provide strong evidence for the intractability of computing sparse CE in normal-form games. In particular, we extend the sum-of-squares (SoS)-based lower bounds of \citetKothari18:Sum from Nash equilibria to sparse CE under a broad sparsity regime. The algorithmic framework We operate in the algorithmic framework put forward by \citetKothari18:Sum revolving around SoS, a sequence of increasingly more powerful semidefinite programs (SDPs). The SoS hierarchy has proven to be a remarkably effective technique for algorithm design in many fundamental problems from diverse areas (e.g., \citepArora15:Subexponential,Barak11:Rounding,Ma16:Polynomial,Harrow16:Tight,Barak15:Dictionary,Barak14:Rounding,Arora09:Expander,Kothari22:Polynomial,Barak14:Sum). As a result, in light of the power of the framework, an SoS lower bound serves as strong evidence for the intractability of a problem. Such a lower bound typically manifests itself in the form of an integrality gap, precluding approximating a certain objective function without ascending excessively high in the SoS hierarchy. When it comes to equilibrium computation, however, there is no underlying objective; and the decision version of the problem is also of little use since, by virtue of its totality, a solution always exists. \citetKothari18:Sum propose to address such issues by instead relying on what they refer to as rounding gaps. The idea here is as follows. An SoS relaxation will output a relaxed solution with respect to our problem of interest—namely, T𝑇Titalic_T-sparse CE. Such a relaxation will generally not be a legitimate solution, so an additional step—known as rounding—is required so as to identify an actual equilibrium. Now, for this approach to be meaningful, it is necessary to impose constraints on how the rounding algorithm operates, for otherwise it can simply ignore the relaxed solution and compute an equilibrium from scratch by accessing the game; proving lower bounds against such algorithms is precisely what we set out for in the first place. Following \citetFeige16:Oblivious, \citetKothari18:Sum address this issue by restricting the rounding algorithm to be oblivious, in that the true solution can only depend on the relaxed one. This algorithmic framework, although restricted, is powerful enough to capture several famous algorithms \citepFeige16:Oblivious, including threshold rounding for vertex cover \citepHochbaum82:Approximation; randomized rounding for set cover \citepRaghavan87:Randomized; random hyperplane rounding for maximum cut \citepGoemans95:Improved; and welfare maximization for fractionally subadditive (XOS) and submodular valuations \citepFeige09:Maximizing,Feige10:Submodular. To strengthen the rounding algorithm and capture more existing techniques, \citetKothari18:Sum also allow it to adaptively produce a list of candidate solutions—instead of a single one—by checking whether one of them is indeed a solution through a verification oracle; this enables capturing enumeration techniques over a restricted search space, which have been successful in equilibrium computation problems—most notably, by \citetLipton03:Playing. A lower bound in this framework consists of proving that either the level—aka. the degree—in the SoS hierarchy is high—thereby rendering the corresponding SDP out of reach—or the number of queries to the verification oracle is prohibitively large. 1.1 Preliminaries To describe our results, we first need to formally introduce the problem of interest and the algorithmic framework outlined above; further background is provided later in Section 2. The familiar reader can mostly skim the upcoming paragraphs leading to Section 1.2 for our notation. Two-player games We consider two-player games represented in normal form. (Since we are aiming to prove lower bounds, concentrating on two-player games will only make the results stronger.) Here, each player has a finite set of available actions; without any loss of generality, we may and will assume that the set of actions of each player is [n]≔{1,2,…,n}≔delimited-[]𝑛12…𝑛[n]\coloneqq\{1,2,\dots,n\}[ italic_n ] ≔ { 1 , 2 , … , italic_n }. Under a pair of actions (i,j)∈[n]×[n]𝑖𝑗delimited-[]𝑛delimited-[]𝑛(i,j)\in[n]\times[n]( italic_i , italic_j ) ∈ [ italic_n ] × [ italic_n ], the utility of the players is given by 𝐑i,jsubscript𝐑𝑖𝑗\mathbf{R}_{i,j}bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT and 𝐂i,jsubscript𝐂𝑖𝑗\mathbf{C}_{i,j}bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT, respectively, where 𝐑,𝐂∈ℝn×n𝐑𝐂superscriptℝ𝑛𝑛\mathbf{R},\mathbf{C}\in{\mathbb{R}}^{n\times n}bold_R , bold_C ∈ blackboard_R start_POSTSUPERSCRIPT italic_n × italic_n end_POSTSUPERSCRIPT are the payoff matrices of the game given as part of the input; by convention, we will refer to the players as Player x𝑥xitalic_x (for the “row player”) and Player y𝑦yitalic_y (for the “column player”), respectively. 𝒢≔(𝐑,𝐂)≔𝒢𝐑𝐂\mathcal{G}\coloneqq(\mathbf{R},\mathbf{C})caligraphic_G ≔ ( bold_R , bold_C ) will sometimes be referred to as an n×n𝑛𝑛n\times nitalic_n × italic_n game. Players can randomize by selecting as strategy a probability distribution, a point in Δn≔{𝒙∈ℝ≥0n:∑i=1n𝒙i=1}≔superscriptΔ𝑛conditional-set𝒙subscriptsuperscriptℝ𝑛absent0superscriptsubscript𝑖1𝑛subscript𝒙𝑖1\Delta^{n}\coloneqq\{\bm{x}\in{\mathbb{R}}^{n}_{\geq 0}:\sum_{i=1}^{n}\bm{x}_{% i}=1\}roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ≔ { bold_italic_x ∈ blackboard_R start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT ≥ 0 end_POSTSUBSCRIPT : ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = 1 }. The expected utility under a pair of mixed strategies (𝒙,𝒚)∈Δn×Δn𝒙𝒚superscriptΔ𝑛superscriptΔ𝑛(\bm{x},\bm{y})\in\Delta^{n}\times\Delta^{n}( bold_italic_x , bold_italic_y ) ∈ roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT × roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT is given by 𝔼(i,j)∼(𝒙,𝒚)⁢𝐑i,j=⟨𝒙,𝐑⁢𝒚⟩subscript𝔼similar-to𝑖𝑗𝒙𝒚subscript𝐑𝑖𝑗𝒙𝐑𝒚{\mathbb{E}}_{(i,j)\sim(\bm{x},\bm{y})}\mathbf{R}_{i,j}=\langle\bm{x},\mathbf{% R}\bm{y}\rangleblackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ ( bold_italic_x , bold_italic_y ) end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = ⟨ bold_italic_x , bold_R bold_italic_y ⟩ and 𝔼(i,j)∼(𝒙,𝒚)⁢𝐂i,j=⟨𝒙,𝐂⁢𝒚⟩subscript𝔼similar-to𝑖𝑗𝒙𝒚subscript𝐂𝑖𝑗𝒙𝐂𝒚{\mathbb{E}}_{(i,j)\sim(\bm{x},\bm{y})}\mathbf{C}_{i,j}=\langle\bm{x},\mathbf{% C}\bm{y}\rangleblackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ ( bold_italic_x , bold_italic_y ) end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = ⟨ bold_italic_x , bold_C bold_italic_y ⟩ for Player x𝑥xitalic_x and Player y𝑦yitalic_y, respectively. Correlated equilibria and sparsity We next recall the notion of a correlated equilibrium (CE) \citepAumann74:Subjectivity. Central to this definition is the set of swap deviations ΦswapsubscriptΦswap\Phi_{\text{swap}}roman_Φ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT, which contains all functions mapping [n]delimited-[]𝑛[n][ italic_n ] to [n]delimited-[]𝑛[n][ italic_n ]. Even though there are nnsuperscript𝑛𝑛n^{n}italic_n start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT such functions, there is still an efficient algorithm minimizing ΦswapsubscriptΦswap\Phi_{\text{swap}}roman_Φ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT-regret \citepBlum07:From. In fact, we will show that lower bounds persist even if one considers a certain subset of deviations Φ⊆ΦswapΦsubscriptΦswap\Phi\subseteq\Phi_{\text{swap}}roman_Φ ⊆ roman_Φ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT with polynomial (in n𝑛nitalic_n) size (defined later in Section 2.1). Definition 1.1. A distribution 𝝁𝝁\bm{\mu}bold_italic_μ on [n]×[n]delimited-[]𝑛delimited-[]𝑛[n]\times[n][ italic_n ] × [ italic_n ] is an ϵitalic-ϵ\epsilonitalic_ϵ-correlated equilibrium (ϵitalic-ϵ\epsilonitalic_ϵ-CE) if for any deviations ϕx∈Φsubscriptitalic-ϕ𝑥Φ\phi_{x}\in\Phiitalic_ϕ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ∈ roman_Φ and ϕy∈Φsubscriptitalic-ϕ𝑦Φ\phi_{y}\in\Phiitalic_ϕ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ∈ roman_Φ, 𝔼(i,j)∼𝝁⁢𝐑i,j≥𝔼(i,j)∼𝝁⁢𝐑ϕx⁢(i),j−ϵand𝔼(i,j)∼𝝁⁢𝐂i,j≥𝔼(i,j)∼𝝁⁢𝐂i,ϕy⁢(j)−ϵ.formulae-sequencesubscript𝔼similar-to𝑖𝑗𝝁subscript𝐑𝑖𝑗subscript𝔼similar-to𝑖𝑗𝝁subscript𝐑subscriptitalic-ϕ𝑥𝑖𝑗italic-ϵandsubscript𝔼similar-to𝑖𝑗𝝁subscript𝐂𝑖𝑗subscript𝔼similar-to𝑖𝑗𝝁subscript𝐂𝑖subscriptitalic-ϕ𝑦𝑗italic-ϵ{\mathbb{E}}_{(i,j)\sim\bm{\mu}}\mathbf{R}_{i,j}\geq{\mathbb{E}}_{(i,j)\sim\bm% {\mu}}\mathbf{R}_{\phi_{x}(i),j}-\epsilon\quad\text{and}\quad{\mathbb{E}}_{(i,% j)\sim\bm{\mu}}\mathbf{C}_{i,j}\geq{\mathbb{E}}_{(i,j)\sim\bm{\mu}}\mathbf{C}_% {i,\phi_{y}(j)}-\epsilon.blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ bold_italic_μ end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ≥ blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ bold_italic_μ end_POSTSUBSCRIPT bold_R start_POSTSUBSCRIPT italic_ϕ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( italic_i ) , italic_j end_POSTSUBSCRIPT - italic_ϵ and blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ bold_italic_μ end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ≥ blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ bold_italic_μ end_POSTSUBSCRIPT bold_C start_POSTSUBSCRIPT italic_i , italic_ϕ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( italic_j ) end_POSTSUBSCRIPT - italic_ϵ . (1) Coarse correlated equilibria (CCE) relax CE by instead imposing (1) only for external deviations Φext≔{ϕ∈Φswap:∃i′∈[n]⁢ s.t. ⁢ϕ⁢(i)=i′⁢ ⁢∀i∈[n]}≔subscriptΦextconditional-setitalic-ϕsubscriptΦswapsuperscript𝑖′delimited-[]𝑛 s.t. italic-ϕ𝑖superscript𝑖′ for-all𝑖delimited-[]𝑛\Phi_{\text{ext}}\coloneqq\{\phi\in\Phi_{\text{swap}}:\exists i^{\prime}\in[n]% \text{ s.t. }\phi(i)=i^{\prime}\text{ }\forall i\in[n]\}roman_Φ start_POSTSUBSCRIPT ext end_POSTSUBSCRIPT ≔ { italic_ϕ ∈ roman_Φ start_POSTSUBSCRIPT swap end_POSTSUBSCRIPT : ∃ italic_i start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ [ italic_n ] s.t. italic_ϕ ( italic_i ) = italic_i start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∀ italic_i ∈ [ italic_n ] }. Interestingly, our lower bound does not seem to apply to CCE; as we shall see in the sequel, employing certain non-external deviations is crucial for the argument. This brings us to the notion of a sparse distribution, introduced below. Definition 1.2 (Sparse distribution). We say that a (correlated) distribution 𝝁𝝁\bm{\mu}bold_italic_μ on [n]×[n]delimited-[]𝑛delimited-[]𝑛[n]\times[n][ italic_n ] × [ italic_n ] is uniform T𝑇Titalic_T-sparse if there exist 𝒙(1),…,𝒙(T)∈Δnsuperscript𝒙1…superscript𝒙𝑇superscriptΔ𝑛\bm{x}^{(1)},\dots,\bm{x}^{(T)}\in\Delta^{n}bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ∈ roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and 𝒚(1),…,𝒚(T)∈Δnsuperscript𝒚1…superscript𝒚𝑇superscriptΔ𝑛\bm{y}^{(1)},\dots,\bm{y}^{(T)}\in\Delta^{n}bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ∈ roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT such that 𝝁=1T⁢∑t=1T𝒙(t)⊗𝒚(t)𝝁1𝑇superscriptsubscript𝑡1𝑇tensor-productsuperscript𝒙𝑡superscript𝒚𝑡\bm{\mu}=\frac{1}{T}\sum_{t=1}^{T}\bm{x}^{(t)}\otimes\bm{y}^{(t)}bold_italic_μ = divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ⊗ bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT. (Above, we denote by 𝒙⊗𝒚≔𝒙⁢𝒚⊤≔tensor-product𝒙𝒚𝒙superscript𝒚top\bm{x}\otimes\bm{y}\coloneqq\bm{x}\bm{y}^{\top}bold_italic_x ⊗ bold_italic_y ≔ bold_italic_x bold_italic_y start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT the outer (tensor) product of 𝒙𝒙\bm{x}bold_italic_x and 𝒚𝒚\bm{y}bold_italic_y.) In words, a sparse distribution is one that can be expressed as a uniform mixture of T∈ℕ𝑇ℕT\in{\mathbb{N}}italic_T ∈ blackboard_N product distributions. As we explained earlier, a Nash equilibrium can be equivalently thought of as a 1111-sparse CE. A key connection that motivates Definition 1.2 is that T𝑇Titalic_T iterations of no-regret learning produces, by definition, a uniform T𝑇Titalic_T-sparse distribution whose CE gap grows with the players’ ΦΦ\Phiroman_Φ-regret (Proposition 2.1). Social welfare The (expected) social welfare of a correlated distribution 𝝁𝝁\bm{\mu}bold_italic_μ on [n]×[n]delimited-[]𝑛delimited-[]𝑛[n]\times[n][ italic_n ] × [ italic_n ] is defined as 𝖲𝖶⁡(𝝁)≔𝔼(i,j)∼𝝁⁢[𝐑i,j+𝐂i,j]≔𝖲𝖶𝝁subscript𝔼similar-to𝑖𝑗𝝁delimited-[]subscript𝐑𝑖𝑗subscript𝐂𝑖𝑗\operatorname{\mathsf{SW}}(\bm{\mu})\coloneqq{\mathbb{E}}_{(i,j)\sim\bm{\mu}}[% \mathbf{R}_{i,j}+\mathbf{C}_{i,j}]sansserif_SW ( bold_italic_μ ) ≔ blackboard_E start_POSTSUBSCRIPT ( italic_i , italic_j ) ∼ bold_italic_μ end_POSTSUBSCRIPT [ bold_R start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT + bold_C start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ]; under a product distribution induced by (𝒙,𝒚)𝒙𝒚(\bm{x},\bm{y})( bold_italic_x , bold_italic_y ), we will write 𝖲𝖶⁡(𝒙⊗𝒚)=⟨𝒙,(𝐑+𝐂)⁢𝒚⟩𝖲𝖶tensor-product𝒙𝒚𝒙𝐑𝐂𝒚\operatorname{\mathsf{SW}}(\bm{x}\otimes\bm{y})=\langle\bm{x},(\mathbf{R}+% \mathbf{C})\bm{y}\ranglesansserif_SW ( bold_italic_x ⊗ bold_italic_y ) = ⟨ bold_italic_x , ( bold_R + bold_C ) bold_italic_y ⟩. SoS and pseudo-equilibria The sum-of-squares (SoS) hierarchy is a sequence of increasingly tighter semidefinite programs (SDPs), parameterized by a degree d∈ℕ𝑑ℕd\in{\mathbb{N}}italic_d ∈ blackboard_N, for the solution of a system of polynomial inequalities. Central to the SoS framework is the notion of a pseudo-distribution, which is a generalization of the usual notion of a probability distribution. Definition 1.3 (Pseudo-distribution). A degree-d𝑑ditalic_d pseudo-distribution is a discrete signed measure μ~~𝜇\tilde{\mu}over~ start_ARG italic_μ end_ARG on ℝmsuperscriptℝ𝑚{\mathbb{R}}^{m}blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT such that the associated linear functional (namely, the pseudo-expectation) 𝔼~μ~:f↦𝔼~μ~⁢[f]=∑𝒛:μ~⁢(𝒛)≠0μ~⁢(𝒛)⁢f⁢(𝒛):subscript~𝔼~𝜇maps-to𝑓subscript~𝔼~𝜇delimited-[]𝑓subscript:𝒛~𝜇𝒛0~𝜇𝒛𝑓𝒛\tilde{{\mathbb{E}}}_{\tilde{\mu}}:f\mapsto\tilde{{\mathbb{E}}}_{\tilde{\mu}}[% f]=\sum_{\bm{z}:\tilde{\mu}(\bm{z})\neq 0}\tilde{\mu}(\bm{z})f(\bm{z})over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_μ end_ARG end_POSTSUBSCRIPT : italic_f ↦ over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_μ end_ARG end_POSTSUBSCRIPT [ italic_f ] = ∑ start_POSTSUBSCRIPT bold_italic_z : over~ start_ARG italic_μ end_ARG ( bold_italic_z ) ≠ 0 end_POSTSUBSCRIPT over~ start_ARG italic_μ end_ARG ( bold_italic_z ) italic_f ( bold_italic_z ), where f:ℝm→ℝ:𝑓→superscriptℝ𝑚ℝf:{\mathbb{R}}^{m}\to{\mathbb{R}}italic_f : blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT → blackboard_R, has the following properties: 1. normalization: 𝔼~μ~⁢[1]=1subscript~𝔼~𝜇delimited-[]11\tilde{{\mathbb{E}}}_{\tilde{\mu}}[1]=1over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_μ end_ARG end_POSTSUBSCRIPT [ 1 ] = 1, and 2. positivity: 𝔼~μ~⁢[p2]≥0subscript~𝔼~𝜇delimited-[]superscript𝑝20\tilde{{\mathbb{E}}}_{\tilde{\mu}}[p^{2}]\geq 0over~ start_ARG blackboard_E end_ARG start_POSTSUBSCRIPT over~ start_ARG italic_μ end_ARG end_POSTSUBSCRIPT [ italic_p start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] ≥ 0 for every polynomial p𝑝pitalic_p on ℝmsuperscriptℝ𝑚{\mathbb{R}}^{m}blackboard_R start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT with degree at most d/2𝑑2d/2italic_d / 2. In this context, following \citetKothari18:Sum, we introduce a relaxation of uniform T𝑇Titalic_T-sparse CE based on the notion of a constrained pseudo-distribution (Definition 2.3), which we refer to as uniform T𝑇Titalic_T-sparse pseudo-CE (a 1111-sparse pseudo-CE will also be called pseudo-NE). Definition 1.4. For a game (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ), a degree-d𝑑ditalic_d, uniform T𝑇Titalic_T-sparse pseudo-CE is a degree-d𝑑ditalic_d pseudo-distribution on (𝒙(1),…,𝒙(T),𝒚(1),…,𝒚(T))superscript𝒙1…superscript𝒙𝑇superscript𝒚1…superscript𝒚𝑇(\bm{x}^{(1)},\dots,\bm{x}^{(T)},\bm{y}^{(1)},\dots,\bm{y}^{(T)})( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT , bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ) that satisfies 𝒙(1),…,𝒙(T),𝒚(1),…,𝒚(T)∈Δnsuperscript𝒙1…superscript𝒙𝑇superscript𝒚1…superscript𝒚𝑇superscriptΔ𝑛\bm{x}^{(1)},\dots,\bm{x}^{(T)},\bm{y}^{(1)},\dots,\bm{y}^{(T)}\in\Delta^{n}bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT , bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ∈ roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT and for all (ϕx,ϕy)∈Φ×Φsubscriptitalic-ϕ𝑥subscriptitalic-ϕ𝑦ΦΦ(\phi_{x},\phi_{y})\in\Phi\times\Phi( italic_ϕ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_ϕ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ) ∈ roman_Φ × roman_Φ the system of quadratic inequalities 1T⁢∑t=1T⟨𝒙(t),𝐑⁢𝒚(t)⟩≥1T⁢∑t=1T⟨ϕx⁢(𝒙(t)),𝐑⁢𝒚(t)⟩⁢ and ⁢1T⁢∑t=1T⟨𝒙(t),𝐂⁢𝒚(t)⟩≥1T⁢∑t=1T⟨𝒙(t),𝐂⁢ϕy⁢(𝒚(t))⟩.1𝑇superscriptsubscript𝑡1𝑇superscript𝒙𝑡𝐑superscript𝒚𝑡1𝑇superscriptsubscript𝑡1𝑇subscriptitalic-ϕ𝑥superscript𝒙𝑡𝐑superscript𝒚𝑡 and 1𝑇superscriptsubscript𝑡1𝑇superscript𝒙𝑡𝐂superscript𝒚𝑡1𝑇superscriptsubscript𝑡1𝑇superscript𝒙𝑡𝐂subscriptitalic-ϕ𝑦superscript𝒚𝑡\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{R}\bm{y}^{(t)}\rangle\geq% \frac{1}{T}\sum_{t=1}^{T}\langle\phi_{x}(\bm{x}^{(t)}),\mathbf{R}\bm{y}^{(t)}% \rangle\text{ and }\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{C}\bm{% y}^{(t)}\rangle\geq\frac{1}{T}\sum_{t=1}^{T}\langle\bm{x}^{(t)},\mathbf{C}\phi% _{y}(\bm{y}^{(t)})\rangle.divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⟨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_R bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ⟩ ≥ divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⟨ italic_ϕ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) , bold_R bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ⟩ and divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⟨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_C bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ⟩ ≥ divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⟨ bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT , bold_C italic_ϕ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT ( bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ) ⟩ . (2) (We clarify that ϕx,ϕy:Δn→Δn:subscriptitalic-ϕ𝑥subscriptitalic-ϕ𝑦→superscriptΔ𝑛superscriptΔ𝑛\phi_{x},\phi_{y}:\Delta^{n}\to\Delta^{n}italic_ϕ start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT , italic_ϕ start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT : roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT → roman_Δ start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT are linear functions, and so (2) above is indeed quadratic.) Definition 1.4 constitutes the natural SoS relaxation for computing uniform T𝑇Titalic_T-sparse CE. An ϵitalic-ϵ\epsilonitalic_ϵ-pseudo-CE incorporates an additive slackness ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0 in (2). Oblivious rounding with a verification oracle We first state the definition of an oblivious rounding algorithm \citepFeige16:Oblivious. Definition 1.5 (Oblivious rounding algorithm). A degree-d𝑑ditalic_d oblivious rounding algorithm for a game 𝒢𝒢{\mathcal{G}}caligraphic_G takes as input a degree-d𝑑ditalic_d, uniform T𝑇Titalic_T-sparse ϵitalic-ϵ\epsilonitalic_ϵ-pseudo-CE per Definition 1.4, and has to output a uniform T𝑇Titalic_T-sparse ϵitalic-ϵ\epsilonitalic_ϵ-CE of 𝒢𝒢{\mathcal{G}}caligraphic_G. As explained earlier, it is desirable to also capture rounding algorithms endowed with the ability to adaptively produce a list of candidate solutions by checking whether one of them is indeed a solution through a verification oracle. Definition 1.6 (Verification oracle). A verification oracle with respect to a game 𝒢𝒢{\mathcal{G}}caligraphic_G takes as input a candidate solution, in the form of (𝒙(1),…,𝒙(T))superscript𝒙1…superscript𝒙𝑇(\bm{x}^{(1)},\dots,\bm{x}^{(T)})( bold_italic_x start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_x start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ) and (𝒚(1),…,𝒚(T))superscript𝒚1…superscript𝒚𝑇(\bm{y}^{(1)},\dots,\bm{y}^{(T)})( bold_italic_y start_POSTSUPERSCRIPT ( 1 ) end_POSTSUPERSCRIPT , … , bold_italic_y start_POSTSUPERSCRIPT ( italic_T ) end_POSTSUPERSCRIPT ), and outputs Accept if 𝝁=1T⁢∑t=1T𝒙(t)⊗𝒚(t)𝝁1𝑇superscriptsubscript𝑡1𝑇tensor-productsuperscript𝒙𝑡superscript𝒚𝑡\bm{\mu}=\frac{1}{T}\sum_{t=1}^{T}\bm{x}^{(t)}\otimes\bm{y}^{(t)}bold_italic_μ = divide start_ARG 1 end_ARG start_ARG italic_T end_ARG ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT bold_italic_x start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT ⊗ bold_italic_y start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT is an ϵitalic-ϵ\epsilonitalic_ϵ-CE of 𝒢𝒢{\mathcal{G}}caligraphic_G and Reject otherwise. We are now ready to introduce the general class of rounding algorithms captured by the upcoming lower bounds. Definition 1.7. A degree-d𝑑ditalic_d, q𝑞qitalic_q-query oblivious rounding algorithm with verification oracle (OV rounding algorithm) is a degree-d𝑑ditalic_d oblivious rounding algorithm that can additionally access a verification oracle for the underlying game at most q𝑞qitalic_q times. Lower bounds within this algorithmic framework boil down to proving that any OV rounding algorithm either requires high degree or must otherwise submit a large number of (potentially adaptive) queries. 1.2 Our results As expected based on existing upper bounds, the lower bounds we obtain with respect to the sparsity parameter of Definition 1.2 crucially depend on the desired precision of the approximation (per Definition 1.1). In particular, we present results on two different regimes: ϵ=poly⁢(1/n)italic-ϵpoly1𝑛\epsilon=\mathrm{poly}(1/n)italic_ϵ = roman_poly ( 1 / italic_n ) and ϵ=poly⁢(1/log⁡n)italic-ϵpoly1𝑛\epsilon=\mathrm{poly}(1/\log n)italic_ϵ = roman_poly ( 1 / roman_log italic_n ); we shall refer to those as high and low precision, respectively. We begin with the high-precision regime. Here, our main result is summarized below. Theorem 1.8. Suppose that there is a degree-d𝑑ditalic_d, q𝑞qitalic_q-query OV rounding algorithm for uniform n1−o⁢(1)superscript𝑛1𝑜1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT-sparse ϵitalic-ϵ\epsilonitalic_ϵ-CE, with ϵ=n−citalic-ϵsuperscript𝑛𝑐\epsilon=n^{-c}italic_ϵ = italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT for some constant c𝑐citalic_c. Then, either d=2Ω⁢(log⁡n⁢log⁡log⁡n)𝑑superscript2Ω𝑛𝑛d=2^{\Omega(\sqrt{\log n\log\log n})}italic_d = 2 start_POSTSUPERSCRIPT roman_Ω ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT or q=2Ω⁢(n)𝑞superscript2Ω𝑛q=2^{\Omega(n)}italic_q = 2 start_POSTSUPERSCRIPT roman_Ω ( italic_n ) end_POSTSUPERSCRIPT. It is worth noting here that there is a tradeoff between the sparsity and the degree precluded by Theorem 1.8; one can elevate the degree at the cost of reducing the sparsity—the extreme case being the result of \citetKothari18:Sum in which T=1𝑇1T=1italic_T = 1 and d=Ω⁢(n)𝑑Ω𝑛d=\Omega(n)italic_d = roman_Ω ( italic_n ). To put Theorem 1.8 into better context, we point out that an exact CE can be computed in polynomial time via a linear program, and every distribution can be expressed as a mixture—albeit not necessarily uniform per Definition 1.2—of n𝑛nitalic_n product distributions; that is, modulo the use of non-uniform mixtures, the sparsity ruled out by Theorem 1.8 is the best one can hope for. Turning to the low-precision regime, our result mirrors Theorem 1.8 but with quantitatively weaker bounds on d𝑑ditalic_d and q𝑞qitalic_q. Theorem 1.9. Suppose that there is a degree-d𝑑ditalic_d, q𝑞qitalic_q-query OV rounding algorithm for uniform log⁡n𝑛\log nroman_log italic_n-sparse ϵitalic-ϵ\epsilonitalic_ϵ-CE, with ϵ=(log⁡n)−citalic-ϵsuperscript𝑛𝑐\epsilon=(\log n)^{-c}italic_ϵ = ( roman_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT for some constant c𝑐citalic_c. Then, either d=Ω⁢(log⁡nlog⁡log⁡n)𝑑Ω𝑛𝑛d=\Omega(\frac{\log n}{\log\log n})italic_d = roman_Ω ( divide start_ARG roman_log italic_n end_ARG start_ARG roman_log roman_log italic_n end_ARG ) or q=nΩ⁢(log⁡n)𝑞superscript𝑛Ω𝑛q=n^{\Omega(\log n)}italic_q = italic_n start_POSTSUPERSCRIPT roman_Ω ( roman_log italic_n ) end_POSTSUPERSCRIPT. A few remarks are again in order. First, even when T=1𝑇1T=1italic_T = 1, there is a quasipolynomial-time algorithm due to \citetLipton03:Playing based on exhaustive enumeration on a carefully constructed search space. Further, since ΦΦ\Phiroman_Φ contains a polynomial number of deviations, there are (efficient) no-regret dynamics producing an O⁢(log⁡n/ϵ2)𝑂𝑛superscriptitalic-ϵ2O(\log n/\epsilon^{2})italic_O ( roman_log italic_n / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )-sparse CE (e.g., via the algorithm of \citetGordon08:No). In particular, in the regime of Theorem 1.9, there is a polynomial-time algorithm for computing logO⁢(1)⁡nsuperscript𝑂1𝑛\log^{O(1)}nroman_log start_POSTSUPERSCRIPT italic_O ( 1 ) end_POSTSUPERSCRIPT italic_n-sparse CE, thereby matching the sparsity precluded by Theorem 1.9 up to a constant in the exponent; as in Theorem 1.8, optimizing the dependence on ϵitalic-ϵ\epsilonitalic_ϵ (as a function of n𝑛nitalic_n) was not our focus. In fact, by virtue of recent breakthrough results \citepDagan24:From,Peng24:Fast, it is worth noting that polylogarithmic sparsity is also attainable with respect to the entire set of swap deviations when ϵ=Θ⁢(1)italic-ϵΘ1\epsilon=\Theta(1)italic_ϵ = roman_Θ ( 1 ). 1.3 Technical overview The proof of Theorems 1.8 and 1.9 follows the blueprint of \citetKothari18:Sum but with certain important twists and modifications, which are the subject of this subsection. The overarching goal is to establish Theorems 1.10 and 1.11, which we state and discuss below. Theorem 1.10. Let T=n1−o⁢(1)𝑇superscript𝑛1𝑜1T=n^{1-o(1)}italic_T = italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT. There is a family of 2Ω⁢(n)superscript2Ω𝑛2^{\Omega(n)}2 start_POSTSUPERSCRIPT roman_Ω ( italic_n ) end_POSTSUPERSCRIPT games {𝒢k}ksubscriptsubscript𝒢𝑘𝑘\{\mathcal{G}_{k}\}_{k}{ caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that 1. there is a degree-2Ω⁢(log⁡n⁢log⁡log⁡n)superscript2Ω𝑛𝑛2^{\Omega(\sqrt{\log n\log\log n})}2 start_POSTSUPERSCRIPT roman_Ω ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT, uniform T𝑇Titalic_T-sparse pseudo-CE for every 𝒢ksubscript𝒢𝑘{\mathcal{G}}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT simultaneously, 2. for every k≠k′𝑘superscript𝑘′k\neq k^{\prime}italic_k ≠ italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, if 𝝁𝝁\bm{\mu}bold_italic_μ and 𝝁′superscript𝝁′\bm{\mu}^{\prime}bold_italic_μ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT are uniform T𝑇Titalic_T-sparse poly⁢(1/n)poly1𝑛\mathrm{poly}(1/n)roman_poly ( 1 / italic_n )-CE of 𝒢ksubscript𝒢𝑘\mathcal{G}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and 𝒢k′subscript𝒢superscript𝑘′\mathcal{G}_{k^{\prime}}caligraphic_G start_POSTSUBSCRIPT italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, 𝝁≠𝝁′𝝁superscript𝝁′\bm{\mu}\neq\bm{\mu}^{\prime}bold_italic_μ ≠ bold_italic_μ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Theorem 1.10 immediately implies Theorem 1.8. Indeed, suppose that one selects a game from the family described in Theorem 1.10, unbeknownst to the underlying algorithm. By the first property (Item 1), a degree-2Ω⁢(log⁡n⁢log⁡log⁡n)superscript2Ω𝑛𝑛2^{\Omega(\sqrt{\log n\log\log n})}2 start_POSTSUPERSCRIPT roman_Ω ( square-root start_ARG roman_log italic_n roman_log roman_log italic_n end_ARG ) end_POSTSUPERSCRIPT, uniform T𝑇Titalic_T-sparse pseudo-CE could not provide any information to discern the game from the class. An OV rounding algorithm is thus left with only query access to the verification oracle. But, by the second property (Item 2), each query can eliminate only a single game at a time, thereby leading to Theorem 1.8. The counterpart of Theorem 1.10 in the low-precision regime is stated below. Theorem 1.11. Let T=log⁡n𝑇𝑛T=\log nitalic_T = roman_log italic_n. There is a family of nΩ⁢(log⁡n)superscript𝑛Ω𝑛n^{\Omega(\log n)}italic_n start_POSTSUPERSCRIPT roman_Ω ( roman_log italic_n ) end_POSTSUPERSCRIPT games {𝒢k}ksubscriptsubscript𝒢𝑘𝑘\{\mathcal{G}_{k}\}_{k}{ caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT such that 1. there is a degree-Ω⁢(log⁡nlog⁡log⁡n)Ω𝑛𝑛\Omega(\frac{\log n}{\log\log n})roman_Ω ( divide start_ARG roman_log italic_n end_ARG start_ARG roman_log roman_log italic_n end_ARG ), uniform T𝑇Titalic_T-sparse pseudo-CE for every 𝒢ksubscript𝒢𝑘{\mathcal{G}}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT simultaneously, 2. for every k≠k′𝑘superscript𝑘′k\neq k^{\prime}italic_k ≠ italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT, if 𝝁𝝁\bm{\mu}bold_italic_μ and 𝝁′superscript𝝁′\bm{\mu}^{\prime}bold_italic_μ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT are uniform T𝑇Titalic_T-sparse poly⁢(1/log⁡n)poly1𝑛\mathrm{poly}(1/\log n)roman_poly ( 1 / roman_log italic_n )-CE of 𝒢ksubscript𝒢𝑘\mathcal{G}_{k}caligraphic_G start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT and 𝒢k′subscript𝒢superscript𝑘′\mathcal{G}_{k^{\prime}}caligraphic_G start_POSTSUBSCRIPT italic_k start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT, 𝝁≠𝝁′𝝁superscript𝝁′\bm{\mu}\neq\bm{\mu}^{\prime}bold_italic_μ ≠ bold_italic_μ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT. Establishing Theorems 1.10 and 1.11 can be in turn divided into three key steps, which are treated separately in what follows. SoS hardness for the welfare maximization variant The first one revolves around establishing SoS lower bounds for uniform T𝑇Titalic_T-sparse CE but under an additional welfare maximization constraint; of course, the final problem of interest does not involve any welfare constraint, but this focus will be justified in the next part of the argument. Starting from the high-precision regime, let us first consider the special case where T=1𝑇1T=1italic_T = 1 (that is, Nash equilibria). With a slight modification to the construction of \citetGilboa89:Nash, \citetKothari18:Sum observed that there is a reduction from (the decision variant of) the independent set problem to deciding whether there is a Nash equilibrium exceeding a certain welfare threshold. In conjunction with the SoS hardness result for the independent set problem due to \citetTulsiani09:CSP, they were able to construct a game such that there is a pseudo-NE exceeding a certain welfare threshold, while in reality all NE attain welfare considerably below it; such a game is referred to as SoSHard. For the more challenging problem of uniform T𝑇Titalic_T-sparse CE (still subject to maximizing welfare), the question is to understand how the sparsity constraint interacts with such reductions. We show that uniform T𝑇Titalic_T-sparse CE can still be accounted for by starting from a gap-amplified (PCP-type) version of independent set. In particular, our starting point is a recent lower bound for welfare-optimal sparse coarse correlated equilibria \citepAnonymous24:Barriers. Even though a uniform T𝑇Titalic_T-sparse CE is a stronger notion than uniform T𝑇Titalic_T-sparse CCE, hardness results for the latter do not readily carry over because of the underlying welfare constraint. Indeed, it turns out that in their reduction any CE obtains lower welfare than the welfare-optimal CCE. As a result, we observe that a direct adaptation of their approach to sparse CE necessitates a gap of Θ⁢(T2)Θsuperscript𝑇2\Theta(T^{2})roman_Θ ( italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) (Lemma 3.6). One of our key contributions is to appropriately leverage internal deviations so as to reduce the gap of the reduction to Θ⁢(T)Θ𝑇\Theta(T)roman_Θ ( italic_T ) (Lemma 3.8); our reduction for sparse CE presents several interesting geometric features, discussed in detail in Section 3. Now, crucially, the result of \citetTulsiani09:CSP can support a gap up to n1−o⁢(1)superscript𝑛1𝑜1n^{1-o(1)}italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT (Theorem 3.9), and this is precisely why the sparsity bound T=n1−o⁢(1)𝑇superscript𝑛1𝑜1T=n^{1-o(1)}italic_T = italic_n start_POSTSUPERSCRIPT 1 - italic_o ( 1 ) end_POSTSUPERSCRIPT appears in Theorem 1.10. In particular, this leads to an SoSHard game with respect to uniform T𝑇Titalic_T-sparse CE (per Definition 3.1), as we formalize in Theorem 3.11. The argument in the low-precision regime has a similar flavor (Theorem 3.13), but instead relies on SoS lower bounds for the planted clique problem \citepPang21:SOS. It is worth noting that \citetKothari18:Sum had to follow a different path since Pang’s result was not available at the time—and earlier integrality gaps \citepBarak19:Nearly were not quite suited for such purposes. Hardness for enumeration algorithms The second step is to provide (information-theoretic) lower bounds against algorithms that access the game only through a verification oracle—oblivious algorithms in the parlance of \citetDaskalakis09:Oblivious; the rationale behind this consideration is that an OV rounding algorithm that obtains no meaningful information from the SoS relaxation is thereby reduced to an oblivious algorithm. This problem is well-understood for Nash equilibria since the work of \citetDaskalakis09:Oblivious. The basic idea is that one can construct a large family of games whose set of ϵitalic-ϵ\epsilonitalic_ϵ-Nash equilibria are pairwise disjoint (as in Item 2 we saw earlier); deriving sharp bounds requires a careful construction, discussed in Section 4. In Theorems 4.2 and 4.9, we show that such bounds carry over to coarse correlated equilibria as well (no matter the sparsity). The simple observation here is that the existing lower bounds for Nash equilibria against oblivious algorithms are based on (modulo strictly dominated actions that can be easily accounted for) constant-sum games; in such games, CCE and NE are tantamount—in the precise sense of 4.3. We call such a family EnumHard games (Definition 4.1). Combining the games The final crucial piece in the construction shows how to appropriately combine such games to arrive at Theorems 1.10 and 1.11. In particular, let (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) be SoSHard: a game such that there is a degree-d𝑑ditalic_d, uniform T𝑇Titalic_T-sparse pseudo-CE in which both players obtain utility at least δ𝛿\deltaitalic_δ, while all uniform T𝑇Titalic_T-sparse CE attain welfare at most 2⁢δ−2⁢ϵ2𝛿2italic-ϵ2\delta-2\epsilon2 italic_δ - 2 italic_ϵ. Consider further a family of EnumHard games {(𝐑S,𝐂S)}S∈𝒮subscriptsuperscript𝐑𝑆superscript𝐂𝑆𝑆𝒮\{(\mathbf{R}^{S},\mathbf{C}^{S})\}_{S\in\mathcal{S}}{ ( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_S ∈ caligraphic_S end_POSTSUBSCRIPT. The idea is to consider the game 𝐑′=(𝐑−k⁢𝟏n×nδ⁢𝟏n×n𝐑S)and𝐂′=(𝐂δ⁢𝟏n×n−k⁢𝟏n×n𝐂S),formulae-sequencesuperscript𝐑′matrix𝐑𝑘subscript1𝑛𝑛𝛿subscript1𝑛𝑛superscript𝐑𝑆andsuperscript𝐂′matrix𝐂𝛿subscript1𝑛𝑛𝑘subscript1𝑛𝑛superscript𝐂𝑆\mathbf{R}^{\prime}=\begin{pmatrix}\mathbf{R}&-k\mathbf{1}_{n\times n}\\ \delta\mathbf{1}_{n\times n}&\mathbf{R}^{S}\end{pmatrix}\quad\text{and}\quad% \mathbf{C}^{\prime}=\begin{pmatrix}\mathbf{C}&\delta\mathbf{1}_{n\times n}\\ -k\mathbf{1}_{n\times n}&\mathbf{C}^{S}\end{pmatrix},bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( start_ARG start_ROW start_CELL bold_R end_CELL start_CELL - italic_k bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL italic_δ bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT end_CELL start_CELL bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ) and bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( start_ARG start_ROW start_CELL bold_C end_CELL start_CELL italic_δ bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT end_CELL end_ROW start_ROW start_CELL - italic_k bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT end_CELL start_CELL bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT end_CELL end_ROW end_ARG ) , where 𝟏n×nsubscript1𝑛𝑛\mathbf{1}_{n\times n}bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT denotes the all-ones n×n𝑛𝑛n\times nitalic_n × italic_n matrix and k≫1much-greater-than𝑘1k\gg 1italic_k ≫ 1. We first want to argue that uniform T𝑇Titalic_T-sparse CE in (𝐑′,𝐂′)superscript𝐑′superscript𝐂′(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) are close to uniform T𝑇Titalic_T-sparse CE in (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ). Indeed, the crucial role of the −k⁢𝟏n×n𝑘subscript1𝑛𝑛-k\mathbf{1}_{n\times n}- italic_k bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT term in the off-diagonal of 𝐑′+𝐂′superscript𝐑′superscript𝐂′\mathbf{R}^{\prime}+\mathbf{C}^{\prime}bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT + bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT is that it forces any product distribution comprising a T𝑇Titalic_T-sparse (C)CE in (𝐑′,𝐂′)superscript𝐑′superscript𝐂′(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) to be either supported only on (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) or only (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT )—up to some probability mass that decays when k𝑘kitalic_k is large (Lemma 5.2). The goal is to prove that actually only the second case can arise: each product is essentially only supported on (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), at which point it readily follows that a uniform T𝑇Titalic_T-sparse CE in (𝐑′,𝐂′)superscript𝐑′superscript𝐂′(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) must be a uniform T𝑇Titalic_T-sparse CE in (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) as well (with roughly the same solution quality). To prove the former assertion, we show that in the contrary case, the conditional distribution on (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) must be a uniform T𝑇Titalic_T-sparse CE for that game (Lemma 5.3). This argument carefully hinges on using a richer set of deviations than external ones. The basic reason is that we want to apply a different mapping when on (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) compared to when being on (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), a functionality not supported by external deviations. To explain this point further, an external deviation for Player x𝑥xitalic_x to an action in 𝐑𝐑\mathbf{R}bold_R could result in an overwhelmingly negative utility due to the −k⁢𝟏n×n𝑘subscript1𝑛𝑛-k\mathbf{1}_{n\times n}- italic_k bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT term: for every component supported on (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ), such a deviation inevitable incurs −k𝑘-k- italic_k. It is thus unclear how to argue about deviations in (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) starting from (𝐑′,𝐂′)superscript𝐑′superscript𝐂′(\mathbf{R}^{\prime},\mathbf{C}^{\prime})( bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ). This is no longer a concern when players are able to deviate differently on different components of the game. Continuing from Lemma 5.3, we now reach a contradiction: uniform T𝑇Titalic_T-sparse CE of (𝐑,𝐂)𝐑𝐂(\mathbf{R},\mathbf{C})( bold_R , bold_C ) attain welfare considerably lower than 2⁢δ2𝛿2\delta2 italic_δ (by the property of the SoSHard game), and at the same time, there is a suitable deviation that takes advantage of the δ⁢𝟏n×n𝛿subscript1𝑛𝑛\delta\mathbf{1}_{n\times n}italic_δ bold_1 start_POSTSUBSCRIPT italic_n × italic_n end_POSTSUBSCRIPT term in 𝐑′superscript𝐑′\mathbf{R}^{\prime}bold_R start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT and 𝐂′superscript𝐂′\mathbf{C}^{\prime}bold_C start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT (Lemma 5.4); this contradicts the assumption that we started from a CE. What remains to show is that there is a degree-d𝑑ditalic_d, uniform T𝑇Titalic_T-sparse pseudo-CE shared among the games no matter the selection of (𝐑S,𝐂S)superscript𝐑𝑆superscript𝐂𝑆(\mathbf{R}^{S},\mathbf{C}^{S})( bold_R start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT , bold_C start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT ) from the family of EnumHard games. This is a fairly straightforward exercise, similar to the completeness proof for Nash equilibria (Lemma 5.1). 1.4 Related work Related to sparsity per Definition 1.2, it is worth pointing out here a notion of sparsity which instead imposes a bound on the support—the number of nonzero elements—of the correlated distribution 𝝁𝝁\bm{\mu}bold_italic_μ. The latter is clearly more stringent, and has been the subject of much investigation in the past (e.g., \citepBabichenko14:Simple,Feder07:Approximating,Althofer94:Sparse). From the perspective of regret minimization, lower bounds on the support of 𝝁𝝁\bm{\mu}bold_italic_μ have been successfully employed so as to preclude fast convergence of no-regret dynamics when players select pure strategies, while the more permissive notion we study here accounts for mixed strategies as well. One crucial difference between the two is that there are no such information-theoretic barriers surrounding Definition 1.2, in that a 1111-sparse CE always exists \citepNash50:Non; this is precisely why we need to resort to computational lower bounds. \citet Foster23:Hardness recently introduced Definition 1.2 in the context of Markov games (see also \citepPeng24:Complexity), and showed that—under standard complexity assumptions—no polynomial sparsity can be attained in such games; this stands in stark contrast to normal-form games. Unfortunately, directly translating such lower bounds to normal-form games appears to be of little use as it does not result in a polynomial-time reduction. Yet, it is worth noting that certain lower bounds have been documented for restricted classes of algorithms, such as multiplicative weights update \citepPeng24:Complexity. Besides those recent works, sparsity played a key role in the celebrated ellipsoid against hope algorithm of \citetPapadimitriou08:Computing (cf. \citepJiang11:Polynomial,Farina24:Polynomial). Indeed, that algorithm outputs a CE that is a convex combination of polynomially many product distributions, and is able to compute a correlated equilibrium even in many succinctly represented multi-player games; a correlated distribution in such games is in general an exponential object, but sparsity crucially provides a succinct representation. Beyond the computational perspective, a rather orthogonal approach to proving lower bounds for no-regret dynamics is to resort to query or communication complexity (e.g., \citepMaiti23:Query,Conitzer04:Communication,Goldberg16:Bounds,Goldberg23:Lower,Babichenko15:Query,Fearnley16:Finding,Goos23:Near,Hadiji23:Towards). One compelling aspect of the former compared to the latter approach is that computational lower bounds apply even in the centralized model of computation where the entire game is known in advance. This is crucial given that no-regret learning is consistently part of the best known algorithms for equilibrium computation problems. Further, query or communication lower bounds are quite brittle depending on how the game is accessed and information is distributed among the players. On the other hand, it has to be noted that the model we operate in is so permissive that no meaningful lower bounds can be established in, for example, (two-player) zero-sum games."
https://arxiv.org/html/2411.01720v1,Barriers to Welfare Maximization withNo-Regret Learning,"A celebrated result in the interface of online learning and game theory guarantees that the repeated interaction of no-regret players leads to a coarse correlated equilibrium (CCE)—a natural game-theoretic solution concept. Despite the rich history of this foundational problem and the tremendous interest it has received in recent years, a basic question still remains open: how many iterations are needed for no-regret players to approximate an equilibrium? In this paper, we establish the first computational lower bounds for that problem in two-player (general-sum) games under the constraint that the CCE reached approximates the optimal social welfare (or some other natural objective). From a technical standpoint, our approach revolves around proving lower bounds for computing a near-optimal T𝑇Titalic_T-sparse CCE—a mixture of T𝑇Titalic_T product distributions, thereby circumscribing the iteration complexity of no-regret learning even in the centralized model of computation. Our proof proceeds by extending a classical reduction of Gilboa and Zemel [1989] for optimal Nash to sparse (approximate) CCE. In particular, we show that the inapproximability of maximum clique precludes attaining any non-trivial sparsity in polynomial time. Moreover, we strengthen our hardness results to apply in the low-precision regime as well via the planted clique conjecture.","One of the most influential results in the interface of algorithmic game theory and online learning is the realization that repeated play under no-regret—a basic notion of hindsight rationality— leads to a natural game-theoretic solution concept known as coarse correlated equilibrium (CCE) \citepHart00:Simple,Foster97:Calibrated. Many ubiquitous algorithms guarantee the no-regret property, including (online) gradient descent and multiplicative weights update, and so one should expect CCE to arise from the repeated interaction of rational players—as it has been corroborated empirically \citepNekipelov15:Econometrics,Kolumbus22:Auctions. From an algorithmic standpoint, perhaps the most well-studied question that emerged from that connection concerns the number of iterations needed to approximate an equilibrium. Remarkably, although this problem traces back to the early pioneering works of \citetBlackwell56:analog and \citetRobinson51:iterative in the 1950s, it remains poorly understood. This stands in contrast to the so-called adversarial regime, wherein a learner engages repeatedly with an adversarial environment acting so as to maximize the player’s regret; in that setting, the minimax regret of the learner has long been resolved in the online learning literature \citepLittlestone94:Weighted. Yet, it turns out that substantially improved guarantees are possible when the learner is instead competing against other learning players, as witnesses by a flurry of recent results (e.g., \citepDaskalakis15:Near,Syrgkanis15:Fast,Rakhlin13:Optimization,Daskalakis21:Near,Piliouras22:Beyond). Indeed, such learning dynamics have emerged as a key component in practical equilibrium computation \citepBrown19:Superhuman,Bowling15:Heads,Bakhtin22:Human,Perolat22:Mastering, proving to be more scalable than traditional linear programming-based approaches. In this paper, we study the iteration-complexity of no-regret learning in games under the constraint that the equilibrium reached approximates the optimal social welfare (or some other natural objective); henceforth, we will simply refer to such equilibria as near-optimal. Taking a step back, there has been tremendous interest in understanding the performance of no-regret learning in terms of welfare, primarily stemming from the price of anarchy literature (e.g., \citepRoughgarden15:Intrinsic,Blum08:Regret), but here we ask an entirely different but equally fundamental question: How many iterations are needed so that no-regret players converge to a near-optimal (approximate) equilibrium? In terms of proving a lower bound, one natural approach revolves around the premise that players initially possess no information about the game, and in each iteration they receive only some limited utility feedback. We argue that there are certain caveats to such an approach. First, it does not apply to the usual centralized model of computation where the underlying game is given as part of the input. Furthermore, even in decentralized settings there is often a centralized party endeavoring to intervene and guide players to desirable outcomes \citepMguni19:Coordinating,Kempe20:Inducing,Li20:End,Liu22:Inducing,Balcan13:Circumventing,Balcan14:Near. Many models have been proposed that differ based on the amount of information gathered by the centralized party, as well as the way communication occurs between the different entities; each such model is arguably reasonable depending on the application. The question thus is how to come up with a lower bound that is not brittle to assumptions regarding the way information is distributed, and thereby applies to all such settings. We address this by resorting to computational lower bounds, thereby ruling out fast convergence to a near-optimal equilibrium even when the entire game is known in advance—subsuming the so-called full feedback setting (recalled in Section 2)—and players can fully coordinate; at first glance, it might seem counterintuitive that non-trivial lower bounds can be established under such permissive assumptions. In particular, we focus on perhaps the simplest class of games for which such questions become meaningful: two-player (general-sum) games represented in normal form; since we are aiming to prove lower bounds, concentrating on a simple class of games only makes the result stronger. 1.1 Our results We establish tight computational lower bounds for the number of iterations needed for no-regret players to reach a near-optimal equilibrium in two-player games. To do so, a key observation that drives our approach is that no-regret learning produces, essentially by definition, a CCE with a particular structure: one expressed as a mixture (that is, a convex combination) of product distributions. In particular, T𝑇Titalic_T rounds of learning results in a mixture of T𝑇Titalic_T product distributions. We call such a distribution T𝑇Titalic_T-sparse (Definition 2.1). In this context, our main contribution is to prove hardness results for the problem of computing a near-optimal T𝑇Titalic_T-sparse CCE, which—by virtue of the observation above—immediately circumscribes the number of iterations for no-regret learning as well, even in the centralized model of computation. Even though this is a fundamental problem, to our knowledge, we are the first to examine its computational complexity as a function of T𝑇Titalic_T. One special case of this problem is well-understood: a near-optimal 1111-sparse CCE is nothing other than a near-optimal Nash equilibrium, treated in the seminal work of \citetGilboa89:Nash (and subsequently extended by \citetConitzer08:New and \citetKothari18:Sum), and shown to be \NP\NP\NP-complete. On the other end of the spectrum, assuming that each player has n𝑛nitalic_n available actions, it is easy to see that any correlated distribution—and in particular any CCE—is n𝑛nitalic_n-sparse. In light of the well-known fact that the optimal CCE can be computed in polynomial time via a linear program (Proposition 2.3), we see that there is a phase transition dictated by the sparsity parameter. In fact, our first main result shows that attaining non-trivial sparsity in polynomial time is impossible (subject to ¶≠\NP¶\NP\P\neq\NP¶ ≠). Below, for an n×n𝑛𝑛n\times nitalic_n × italic_n two-player game 𝒢𝒢{\mathcal{G}}caligraphic_G, we denote by OptimalSparseCCE⁢(𝒢,T,ϵ,ϵ^)OptimalSparseCCE𝒢𝑇italic-ϵ^italic-ϵ\textsc{OptimalSparseCCE}({\mathcal{G}},T,\epsilon,\hat{\epsilon})OptimalSparseCCE ( caligraphic_G , italic_T , italic_ϵ , over^ start_ARG italic_ϵ end_ARG ) the problem of computing a T𝑇Titalic_T-sparse CCE with equilibrium gap at most ϵitalic-ϵ\epsilonitalic_ϵ (in an additive sense; see Definition 2.2) and welfare at least 𝖮𝖯𝖳−ϵ^𝖮𝖯𝖳^italic-ϵ\mathsf{OPT}-\hat{\epsilon}sansserif_OPT - over^ start_ARG italic_ϵ end_ARG, where 𝖮𝖯𝖳𝖮𝖯𝖳\mathsf{OPT}sansserif_OPT is the welfare attained by the optimal T𝑇Titalic_T-sparse CCE. (Further background is given later in Section 2.) Theorem 1.1. OptimalSparseCCE⁢(𝒢,n1−ϵ,n−c,n−c)OptimalSparseCCE𝒢superscript𝑛1italic-ϵsuperscript𝑛𝑐superscript𝑛𝑐\textsc{OptimalSparseCCE}({\mathcal{G}},n^{1-\epsilon},n^{-c},n^{-c})OptimalSparseCCE ( caligraphic_G , italic_n start_POSTSUPERSCRIPT 1 - italic_ϵ end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) with respect to n×n𝑛𝑛n\times nitalic_n × italic_n games is \NP\NP\NP-hard for any constant ϵ>0italic-ϵ0\epsilon>0italic_ϵ > 0 and some constant c𝑐citalic_c. This means that roughly n𝑛nitalic_n iterations are needed for (computationally bounded) no-regret learners to converge to a CCE with 𝗉𝗈𝗅𝗒⁢(1/n)𝗉𝗈𝗅𝗒1𝑛\mathsf{poly}(1/n)sansserif_poly ( 1 / italic_n ) equilibrium and optimality gap; that is, the trivial upper bound of n𝑛nitalic_n is essentially the best one can hope for. Further, a slightly stronger complexity assumption precludes even a sparsity of n/2(𝗅𝗈𝗀⁢n)1−γ𝑛superscript2superscript𝗅𝗈𝗀𝑛1𝛾n/2^{(\mathsf{log}n)^{1-\gamma}}italic_n / 2 start_POSTSUPERSCRIPT ( sansserif_log italic_n ) start_POSTSUPERSCRIPT 1 - italic_γ end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT for some constant γ>0𝛾0\gamma>0italic_γ > 0 (Corollary 3.3). It is worth noting that T≔n≔𝑇𝑛T\coloneqq nitalic_T ≔ italic_n iterations also represent a natural information-theoretic threshold: in the full feedback setting, to which our lower bounds readily apply, there is a trivial exploration protocol that enables each player to fully determine its own payoff matrix (by simply iterating over all rows or columns)—trivializing the problem at least in (two-player) zero-sum games. In addition, Theorem 1.1 establishes a complexity separation between OptimalSparseCCE and SparseCCE—the latter problem lifts the welfare constraint imposed by the former. Namely, since SparseCCE⁢(𝒢,T,0)SparseCCE𝒢𝑇0\textsc{SparseCCE}({\mathcal{G}},T,0)SparseCCE ( caligraphic_G , italic_T , 0 ) is in \PPAD\PPAD\PPAD even for T=1𝑇1T=1italic_T = 1 \citepPapadimitriou94:On, OptimalSparseCCE is harder (subject to \coNP≠\NP\coNP\NP\coNP\neq\NP≠ \citepJohnson88:How) for any sparsity T≤n1−ϵ𝑇superscript𝑛1italic-ϵT\leq n^{1-\epsilon}italic_T ≤ italic_n start_POSTSUPERSCRIPT 1 - italic_ϵ end_POSTSUPERSCRIPT. Moreover, we strengthen Theorem 1.1 in two key aspects. First, we show that it applies under a broad class of objectives, beyond (utilitarian) welfare, which additionally includes the egalitarian social welfare and each player’s (individual) utility (Corollaries 3.13 and 3.12). Second, \NP-hardness persists for any multiplicative approximation to the objective (Corollary 3.14). The key construction behind those results, Theorem 3.11, implies similar hardness results for two other natural problems pertaining to sparse CCE: deciding uniqueness (Theorem 3.9), and determining existence after excluding certain (joint) action profiles (Theorem 3.10); those two latter problems do not hinge on any underlying objective. Technical approach Compared to Nash equilibria, the crux in proving lower bounds for sparse CCE lies in introducing correlation between the players. Many natural reductions designed for Nash equilibria are of little use even for sparsity T=2𝑇2T=2italic_T = 2, which partly explains why the complexity of sparse CCE remains poorly understood. The key challenge is to identify a basic construction that handles near-optimal T𝑇Titalic_T-sparse CCE even when T≫1much-greater-than𝑇1T\gg 1italic_T ≫ 1. In this context, to prove Theorem 1.1, we extend the reduction of \citetGilboa89:Nash who proved \NP\NP\NP-hardness only when T=1𝑇1T=1italic_T = 1. In particular, they came up with a reduction from the decision version of the maximum clique problem (MaxClique) to OptimalSparseCCE⁢(𝒢,1,0,0)OptimalSparseCCE𝒢100\textsc{OptimalSparseCCE}({\mathcal{G}},1,0,0)OptimalSparseCCE ( caligraphic_G , 1 , 0 , 0 ). We establish a natural generalization of their reduction (Algorithm 1); namely, we show that computing a 2⁢T2𝑇2T2 italic_T-approximation to MaxClique polynomially reduces to OptimalSparseCCE⁢(𝒢,T,n−c,n−c)OptimalSparseCCE𝒢𝑇superscript𝑛𝑐superscript𝑛𝑐\textsc{OptimalSparseCCE}({\mathcal{G}},T,n^{-c},n^{-c})OptimalSparseCCE ( caligraphic_G , italic_T , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , italic_n start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) (Theorem 3.1). That is, the sparsity of the underlying CCE translates to a degradation in the resulting approximation factor. We are then able to rely on the celebrated inapproximability of MaxClique \citepZuckerman07:Linear (Theorem 2.4) to arrive at Theorem 1.1. The overall reduction has various new technical aspects, discussed in Section 3.1. The refinements to Theorem 1.1 described earlier are established by suitably adjusting this basic reduction (Sections 3.2 and 3.3). Low-precision regime So far, we have focused on the regime where both the equilibrium and the optimality gap scale as 𝗉𝗈𝗅𝗒⁢(1/n)𝗉𝗈𝗅𝗒1𝑛\mathsf{poly}(1/n)sansserif_poly ( 1 / italic_n )—a common setting when it comes to equilibrium computation. No-regret learning is often employed in the so-called low-precision regime, which we identify with ϵ,ϵ^≥1/\polylog⁢nitalic-ϵ^italic-ϵ1\polylog𝑛\epsilon,\hat{\epsilon}\geq 1/\polylog nitalic_ϵ , over^ start_ARG italic_ϵ end_ARG ≥ 1 / italic_n. In that setting, even Nash equilibria admit a quasipolynomial-time algorithm \citepLipton03:Playing, and so one cannot hope to prove—barring major complexity breakthroughs—\NP-hardness results. Instead, following an earlier work by \citetHazan11:How, we rely on the so-called planted clique conjecture from average-case complexity (2.5; Section 2 provides a self-contained overview). We are then able to show the following quasipolynomial lower bounds. Theorem 1.2. Assuming that 2.5 holds, the following problems require nΩ⁢(𝗅𝗈𝗀⁢n)superscript𝑛Ω𝗅𝗈𝗀𝑛n^{\Omega(\mathsf{log}n)}italic_n start_POSTSUPERSCRIPT roman_Ω ( sansserif_log italic_n ) end_POSTSUPERSCRIPT time with respect to n×n𝑛𝑛n\times nitalic_n × italic_n games: • OptimalSparseCCE⁢(𝒢,T,(𝗅𝗈𝗀⁢n)−c,(𝗅𝗈𝗀⁢n)−c)OptimalSparseCCE𝒢𝑇superscript𝗅𝗈𝗀𝑛𝑐superscript𝗅𝗈𝗀𝑛𝑐\textsc{OptimalSparseCCE}({\mathcal{G}},T,(\mathsf{log}n)^{-c},(\mathsf{log}n)% ^{-c})OptimalSparseCCE ( caligraphic_G , italic_T , ( sansserif_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT , ( sansserif_log italic_n ) start_POSTSUPERSCRIPT - italic_c end_POSTSUPERSCRIPT ) for any T=\polylog⁢n𝑇\polylog𝑛T=\polylog nitalic_T = italic_n and some constant c=c⁢(T)𝑐𝑐𝑇c=c(T)italic_c = italic_c ( italic_T ), • OptimalSparseCCE⁢(𝒢,T,c,c)OptimalSparseCCE𝒢𝑇𝑐𝑐\textsc{OptimalSparseCCE}({\mathcal{G}},T,c,c)OptimalSparseCCE ( caligraphic_G , italic_T , italic_c , italic_c ) for any T=O⁢(1)𝑇𝑂1T=O(1)italic_T = italic_O ( 1 ) and some constant c=c⁢(T)𝑐𝑐𝑇c=c(T)italic_c = italic_c ( italic_T ). The first lower bound is shown by relying on our previous construction behind Theorem 1.1. The second one, which concerns the more permissive regime in which ϵ,ϵ^=Θ⁢(1)italic-ϵ^italic-ϵΘ1\epsilon,\hat{\epsilon}=\Theta(1)italic_ϵ , over^ start_ARG italic_ϵ end_ARG = roman_Θ ( 1 ), adapts the reduction of \citetHazan11:How pertaining to optimal Nash equilibria. We provide the technical details in Section 4. 1.2 Further related work The notion of a sparse CCE—a mixture of product distributions (Definition 2.1)—was recently studied by \citetFoster23:Hardness in the context of Markov (aka. stochastic) games to rule out the existence of polynomial-time no-regret algorithms—with respect to potentially non-Markovian deviations (see also the work of \citetPeng24:Complexity). This stands in contrast to games represented in normal form, where the existence of efficient no-regret algorithms has been long known tracing back to \citetBlackwell56:analog. Yet, establishing non-trivial lower bounds for sparse CCE in normal-form games remains an open problem even for sparsity T=2𝑇2T=2italic_T = 2. It is worth highlighting that even though a CCE (without the sparsity constraint) can be computed exactly by solving a linear program \citepPapadimitriou08:Computing, by far the most well-studied approach in the literature revolves around no-regret learning. This can be mostly attributed to the scalability, the minimal memory footprint, as well as the amenability to a distributed implementation of the latter approach, motivating the problem of sparse CCE. Besides this connection with no-regret learning, we argue that sparse CCE is a natural notion, worth examining in its own right, and ties to a long line of work on low-rank approximation in machine learning. A related notion of sparsity imposes instead a bound on the number of nonzero elements of the distribution—that is, the size of its support. Unlike Definition 2.1, that latter notion is well-studied and understood (e.g., \citepBabichenko14:Simple). It is clear that a distribution 𝝁𝝁\bm{\mu}bold_italic_μ with T𝑇Titalic_T nonzero entries is T𝑇Titalic_T-sparse per Definition 2.1, but the opposite does not hold in general. From the viewpoint of no-regret learning, proving lower bounds pertaining to distributions with small support translates to the setting where each player selects a pure strategy, while Definition 2.1 accounts for mixed strategies as well. To further elaborate on this difference, it is known that Ω⁢(𝗅𝗈𝗀⁢n/ϵ2)Ω𝗅𝗈𝗀𝑛superscriptitalic-ϵ2\Omega(\mathsf{log}n/\epsilon^{2})roman_Ω ( sansserif_log italic_n / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) nonzero elements in the support are information-theoretically necessary for even the existence of an ϵitalic-ϵ\epsilonitalic_ϵ-Nash equilibrium in zero-sum games \citepFeder07:Approximating, in turn implying that Ω⁢(𝗅𝗈𝗀⁢n/ϵ2)Ω𝗅𝗈𝗀𝑛superscriptitalic-ϵ2\Omega(\mathsf{log}n/\epsilon^{2})roman_Ω ( sansserif_log italic_n / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) iterations are needed when players select pure strategies. On the other hand, a consequence of the minimax theorem is that a 1111-sparse equilibrium always exists, and can also be computed efficiently in such games via linear programming; this means that no superpolynomial computational lower bounds for no-regret learning in zero-sum games can be shown in mixed strategies. A long-standing challenge in general-sum games is equilibrium selection: there could be a multiplicity of equilibria, and some are more reasonable than others. A common antidote—albeit certainly not the only one—is to identify an equilibrium maximizing the social welfare (or some other natural objective). This can be achieved in polynomial time even in multi-player (normal-form) games represented explicitly, which motivates investigating the complexity of OptimalSparseCCE—the focus of our work. However, this is no longer the case in succinct games, where maximizing welfare is typically \NP-hard \citepPapadimitriou08:Computing (cf. \citetBarman15:Finding)—let alone sparsity constraints. This is also the case for two-player extensive-form games (e.g., \citepZhang22:Optimal). Another motivation for proving lower bounds revolving around T𝑇Titalic_T-sparse CCE is that while many techniques that accelerate equilibrium computation rely on no-regret learning dynamics, they do not strictly comply with the traditional online nature of the framework. A notable example is alternation \citepTammelin15:Solving,Wibisono22:Alternating,Cevher23:Alternation, whereby players update their strategies sequentially—as opposed to simultaneous updates. Importantly, such techniques are captured through sparse CCE. Beyond computational considerations, it is worth pointing out an orthogonal line of work that has focused on query complexity aspects of (coarse) correlated equilibria (e.g., \citepGoldberg16:Bounds,Babichenko15:Query,Maiti23:Query,Goldberg23:Lower, and references therein)."
https://arxiv.org/html/2411.01462v2,"The Fairness of Maximum Nash Social Welfare Under Matroid Constraints and Beyond††thanks:This submission has been accepted by WINE 2024.This work is supported in part by the National Natural Science Foundation of China
(Nos. 12171444, 12301418, 12471306) and Natural Science Foundation of
Shandong (No. ZR2022QA014).","We study the problem of fair allocation of a set of indivisible items among agents with additive valuations, under matroid constraints and two generalizations: p𝑝pitalic_p-extendible system and independence system constraints. The objective is to find fair and efficient allocations in which the subset of items assigned to every agent satisfies the given constraint. We focus on a common fairness notion of envy-freeness up to one item (EF1) and a well-known efficient (and fair) notion of the maximum Nash social welfare (Max-NSW). By using properties of matroids, we demonstrate that the Max-NSW allocation, implying Pareto optimality (PO), achieves a tight 1/2121/21 / 2-EF1 under matroid constraints. This result resolves an open question proposed in prior literature [26]. In particular, if agents have 2-valued ({1,a}1𝑎\{1,a\}{ 1 , italic_a }) valuations, we prove that the Max-NSW allocation admits max⁡{1/a2,1/2}1superscript𝑎212\max\{1/a^{2},1/2\}roman_max { 1 / italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 1 / 2 }-EF1 and PO. Under strongly p𝑝pitalic_p-extendible system constraints, we show that the Max-NSW allocation guarantees max⁡{1/p,1/4}1𝑝14\max\{1/p,1/4\}roman_max { 1 / italic_p , 1 / 4 }-EF1 and PO for identical binary valuations. Indeed, the approximation of 1/4141/41 / 4 is the ratio for independence system constraints and additive valuations. Additionally, for lexicographic preferences, we study possibly feasible allocations other than Max-NSW admitting exactly EF1 and PO under the above constraints.","Fair allocation of indivisible items among agents is a highly active problem in computational economics and artificial intelligence, due to its growing applications, e.g., Public Housing [10], Courses Allocation [6], the website of Spliddit (spliddit.org) [14], and the company Fair Outcomes (fairoutcomes.com). Central to this problem falls into two categories: fairness and efficiency. To capture fairness, envy-freeness (EF, [13]) is a compelling criterion: every agent prefers her own bundle to another one’s allocated bundle. Unfortunately, an EF allocation does not always exist even for allocating one indivisible item between two agents. This motivates a series of less stringent notions of envy-freeness, e.g., envy-freeness up to one item (EF1). For general monotone valuations, an EF1 allocation can be computed in polynomial time [21]. For finding efficient EF1 allocations, we are interested in a well-known criterion of Nash social welfare (NSW) that calculates the product of agents’ utilities. An allocation maximizing the Nash social welfare (Max-NSW) guarantees EF1 [8] and PO. While allocating indivisible items, we are more interested in relevant constraints, such as, cardinality constraints [4], budget constraints [27], scheduling constraints [20]) and conflicting constraints [17]. These categories of constraints can be formulated as special cases of independence system constraints. An independence system is a system (E,ℱ)𝐸ℱ(E,\mathcal{F})( italic_E , caligraphic_F ), where E𝐸Eitalic_E is a finite item set and ℱℱ\mathcal{F}caligraphic_F is a collection of (independent) subsets of E𝐸Eitalic_E that has hereditary property: if D∈ℱ𝐷ℱD\in\mathcal{F}italic_D ∈ caligraphic_F and C⊆D𝐶𝐷C\subseteq Ditalic_C ⊆ italic_D then C∈ℱ𝐶ℱC\in\mathcal{F}italic_C ∈ caligraphic_F. As a powerful abstraction of independence, matroid structures [22, 16, 15, 11] have played a prominent role in combinatorial optimization. An independence system (M,ℱ)𝑀ℱ(M,\mathcal{F})( italic_M , caligraphic_F ) is a matroid if ℱℱ\mathcal{F}caligraphic_F also has augmentation property: for C,D∈ℱ𝐶𝐷ℱC,D\in\mathcal{F}italic_C , italic_D ∈ caligraphic_F with |C|<|D|𝐶𝐷|C|<|D|| italic_C | < | italic_D |, there is an item x∈D∖C𝑥𝐷𝐶x\in D\setminus Citalic_x ∈ italic_D ∖ italic_C such that C+x∈ℱ𝐶𝑥ℱC+x\in\mathcal{F}italic_C + italic_x ∈ caligraphic_F 111The notation C+x𝐶𝑥C+xitalic_C + italic_x means C∪{x}𝐶𝑥C\cup\{x\}italic_C ∪ { italic_x }, likewise C−x𝐶𝑥C-xitalic_C - italic_x means C∖{x}𝐶𝑥C\setminus\{x\}italic_C ∖ { italic_x }.. In particular, cardinality constraints are equivalent to partition constraints [4]. Due to the flexible properties of matroid (or independence system) structures, it is challenging to explore fair and efficient allocations under matroid constraints (or more general independence system constraints). Indeed, Suksompong [26] illustrated that the existence problem of EF1 and PO allocation remained open under matroids constraints (in Section 4). In this paper, we are interested in making efforts towards this direction by Max-NSW allocations, approximate EF1 allocations, properties of matroids and other effective techniques. 1.1 Our Contribution We have strived to examine the existence of Max-NSW and approximate EF1 allocations under three prominent constraints: matroids, p𝑝pitalic_p-extendible systems, and independence systems (the relationships between the three can be seen in Figure 1). Throughout, we select a specific Max-NSW allocation guaranteeing Pareto Optimality (PO) under all three classes of constraints. The main contributions in this paper are summarized in Table LABEL:table1. 1.1.1 Matroid Constraints. (Section 3) A system (M,ℱ)𝑀ℱ(M,\mathcal{F})( italic_M , caligraphic_F ) is a matroid if M𝑀Mitalic_M is a finite item set, and ℱℱ\mathcal{F}caligraphic_F satisfies that i) hereditary property: if D∈ℱ𝐷ℱD\in\mathcal{F}italic_D ∈ caligraphic_F and C⊆D𝐶𝐷C\subseteq Ditalic_C ⊆ italic_D, then C∈ℱ𝐶ℱC\in\mathcal{F}italic_C ∈ caligraphic_F; ii) augmentation property: if C,D∈ℱ𝐶𝐷ℱC,D\in\mathcal{F}italic_C , italic_D ∈ caligraphic_F and |D|>|C|𝐷𝐶|D|>|C|| italic_D | > | italic_C |, then there is an item x∈D∖C𝑥𝐷𝐶x\in D\setminus Citalic_x ∈ italic_D ∖ italic_C such that C+x∈ℱ𝐶𝑥ℱC+x\in\mathcal{F}italic_C + italic_x ∈ caligraphic_F. For general additive valuations, we illustrate that every Max-NSW allocation achieves 1/2121/21 / 2-EF1 under matroid constraints. This approximation ratio cannot be improved since we exemplify an instance that for arbitrary ε>0𝜀0\varepsilon>0italic_ε > 0, there is no feasible Max-NSW and (1/2+ε)12𝜀(1/2+\varepsilon)( 1 / 2 + italic_ε )-EF1 allocation under partition matroids. In particular, for identical valuations, Biswas et al. [4] have shown that an exact EF1 and PO allocation was guaranteed to exist by the Max-NSW allocation under matroid constraints. In this settings, we find an exact EF1 and PO allocation by leximin ordering. Furthermore, if all agents have binary valuations, Dror et al. [11] computed an exact EF1 and PO allocation under partition matroids. We explore the extended settings of 2-valued valuations that each item’s value falls into {1,a}1𝑎\{1,a\}{ 1 , italic_a } with a>1𝑎1a>1italic_a > 1 for each agent, and strikingly demonstrate that every Max-NSW allocation is max⁡{1/a2,1/2}1superscript𝑎212\max\{1/a^{2},1/2\}roman_max { 1 / italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , 1 / 2 }-EF1 and PO under partition matroids. 1.1.2 Beyond Matroid Constraints. (Section 4) The results focus on two general classes p𝑝pitalic_p-extendible systems and independence systems. We restrict the p𝑝pitalic_p-extendible system [22] to a strongly p𝑝pitalic_p-extendible system (M,ℱ)𝑀ℱ(M,\mathcal{F})( italic_M , caligraphic_F ) (Definition 7): if C∈ℱ,D∈ℱformulae-sequence𝐶ℱ𝐷ℱC\in\mathcal{F},D\in\mathcal{F}italic_C ∈ caligraphic_F , italic_D ∈ caligraphic_F with C⊂D𝐶𝐷C\subset Ditalic_C ⊂ italic_D and if H∩C=∅𝐻𝐶H\cap C=\emptysetitalic_H ∩ italic_C = ∅ such that C∪H∈ℱ𝐶𝐻ℱC\cup H\in\mathcal{F}italic_C ∪ italic_H ∈ caligraphic_F, then there exists a subset Y⊆D∖C𝑌𝐷𝐶Y\subseteq D\setminus Citalic_Y ⊆ italic_D ∖ italic_C with |Y|≤p⁢|H|𝑌𝑝𝐻|Y|\leq p|H|| italic_Y | ≤ italic_p | italic_H | such that D∖Y∪H∈ℱ𝐷𝑌𝐻ℱD\setminus Y\cup H\in\mathcal{F}italic_D ∖ italic_Y ∪ italic_H ∈ caligraphic_F. Furthermore, we focus on strongly p𝑝pitalic_p-extendible systems, which still include all matroids. For identical binary valuations, we show that every Max-NSW allocation achieves max⁡{1/p,1/4}1𝑝14\max\{1/p,1/4\}roman_max { 1 / italic_p , 1 / 4 }-EF1 and PO under strongly p𝑝pitalic_p-extendible systems. Independence systems are systems that satisfy only hereditary property. For additive valuations, every Max-NSW allocation is 1/4141/41 / 4-EF1 and the approximation is already tight. Interestingly, we further consider lexicographic preferences [24], under independence system constraints, and compute an exact EF1 and PO allocation by a greedy-method algorithm. {talltblr} [ caption=Summary of our main results. Identical, bi. and identical-bi refer to identical additive, binary additive, and identical binary additive valuations respectively. LB and UB refer to lower bounds and upper bounds respectively. “⇒⇒\Rightarrow⇒ PO” refers to outcomes guarantee Pareto optimality., label=table1 ] width=row1-2 = gray!20, font=, hline1,Z = 1pt, hline3,4,7,8 = solid, hline2 = solid \SetCell [r=2]l,m Constraints &\SetCell[r=2]l,m Valuations \SetCell[c=2]c,m Max-NSWs (⇒⇒\Rightarrow⇒ PO) \SetCell[r=2]c,m Others (⇒⇒\Rightarrow⇒ PO) \SetCellc,m LB \SetCellc,m UB \SetCell[r=1]c,m Partition Matroids \SetCellc,m additive \SetCellc,m 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 (12+ε)12𝜀(\frac{1}{2}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_ε )-EF1 1-EF1 (bi.)[11] \SetCell[r=3]c,m Matroids \SetCellc,m additive \SetCellc,m 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 (12+ε)12𝜀(\frac{1}{2}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 2 end_ARG + italic_ε )-EF1 \SetCellc,m identical \SetCellc,m 1-EF1 [4] 1-EF1(by leximin) \SetCell c,m {1,a}1𝑎\{1,a\}{ 1 , italic_a }-valued max⁡{1a2,12}1superscript𝑎212\max\{\frac{1}{a^{2}},\frac{1}{2}\}roman_max { divide start_ARG 1 end_ARG start_ARG italic_a start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG , divide start_ARG 1 end_ARG start_ARG 2 end_ARG }-EF1 Strongly p𝑝pitalic_p-Extendible Systems \SetCellc,m identical-bi max⁡{1p,14}1𝑝14\max\{\frac{1}{p},\frac{1}{4}\}roman_max { divide start_ARG 1 end_ARG start_ARG italic_p end_ARG , divide start_ARG 1 end_ARG start_ARG 4 end_ARG }-EF1 (23+ε)23𝜀(\frac{2}{3}+\varepsilon)( divide start_ARG 2 end_ARG start_ARG 3 end_ARG + italic_ε )-EF1 \SetCell[r=2]c,m Independence Systems \SetCellc,m additive \SetCellc,m 1414\frac{1}{4}divide start_ARG 1 end_ARG start_ARG 4 end_ARG-EF1 (14+ε)14𝜀(\frac{1}{4}+\varepsilon)( divide start_ARG 1 end_ARG start_ARG 4 end_ARG + italic_ε )-EF1 \SetCellc,m lexicographic 1-EF1 (by RR alg.) 1.2 Related Work There is a vast literature on fairly and efficiently allocating indivisible items without constraints. In particular, Caragiannis et al. [7, 8] originated that a Max-NSW allocation is both strikingly EF1 and approximately Maximin share for additive valuations. Barman et al. [2] provided an efficient greedy algorithm to compute a Max-NSW allocation for binary valuations while finding Max-NSW allocations is APX-hard in general [19]. Benabbou et al. [3] showed that Max-NSW and leximin allocations both processed the EF1 property for matroid rank valuations. Amanatidis et al. [1] established that a Max-NSW allocation was always envy-freeness up to any item (EFX, [9]) for 2-valued valuations. Plaut and Roughgarden [23] EFX allocations and PO allocations were not compatible with general valuations. Recently, Feldman et al. [12] demonstrated an optimal tradeoff that for any 0≤α≤10𝛼10\leq\alpha\leq 10 ≤ italic_α ≤ 1, an α𝛼\alphaitalic_α-EFX allocation can guarantee 1/(α+1)1𝛼11/(\alpha+1)1 / ( italic_α + 1 )-Max-NSW for additive valuations. Our work is related to fair and efficient allocations in constrained settings. Wu et al. [27] showed that under budget constraints, the Max-NSW allocation achieved 1/4141/41 / 4-EF1 with tight approximation ratio. We extend this positive result to more general constraints (independence systems). Biswas and Barman [4] firstly considered special matroid constraints. They developed efficient algorithms to compute EF1 allocations under laminar matroids for identical additive valuations. If items are labeled by goods or chores, Shoshan et al. [25] provided a polynomial-time algorithm to compute feasible allocations under partition constraints guaranteed PO and EF up to one good and one chore. Dror et al. [11] demonstrated the existence of EF1 allocations by devising algorithms on the settings of heterogeneous partition matroids, and n𝑛nitalic_n agents with binary additive valuations (or two agents with general additive valuations). Besides, more literature studied other fairness allocations (e.g., Maximin share) under matroid constraints, which can be traced back to references [18, 15, 17]. Beyond the above special settings, we will focus on central constraints of general matroids, p𝑝pitalic_p-extendible systems and even independent systems in this paper, and we further explore the efficiency of feasible allocations."
https://arxiv.org/html/2411.01217v1,Preference-CFR: Beyond Nash Equilibrium for Better Game Strategies,"Recent advancements in artificial intelligence (AI) have leveraged large-scale games as benchmarks to gauge progress, with AI now frequently outperforming human capabilities. Traditionally, this success has largely relied on solving Nash equilibrium (NE) using variations of the counterfactual regret minimization (CFR) method in games with incomplete information. However, the variety of Nash equilibria has been largely overlooked in previous research, limiting the adaptability of AI to meet diverse human preferences. To address this challenge, where AI is powerful but struggles to meet customization needs, we introduce a novel approach: Preference-CFR, which incorporates two new parameters: preference degree and vulnerability degree. These parameters allow for greater flexibility in AI strategy development without compromising convergence. Our method significantly alters the distribution of final strategies, enabling the creation of customized AI models that better align with individual user needs. Using Texas Hold’em as a case study, our experiments demonstrate how Preference CFR can be adjusted to either emphasize customization, prioritizing user preferences, or to enhance performance, striking a balance between the depth of customization and strategic optimality.","In machine learning, complex gaming problems are important benchmarks for assessing artificial intelligence (AI). Prominent games such as Chess Hsu (2002), Go Silver et al. (2017, 2016, 2018), StarCraft Vinyals et al. (2019), and Texas Hold’em Moravík et al. (2017); Bowling et al. (2015); Brown and Sandholm (2019b) have significantly influenced both academic research and public interest. Traditionally, research has centered on finding Nash equilibrium (NE), as it guarantees that no player can increase their expected payoff by unilaterally changing strategies. From the perspective of expected payoffs, NE represents the optimal solution in games, leading many studies to regard a game problem as solved once its NE is identified. However, maximizing expected payoffs in the worst case is not the sole criterion for evaluating a strategy’s quality. Here, we introduce two additional indicators beyond expected payoffs. 1. In many games, multiple NE can exist. In economics, exploring the diversity of NE is often more valuable than simply identifying them. For example, Schelling’s work on predicting the emergence of specific NE earned him the 2005 Nobel Prize in Economics. Similarly, the current development of AI demands not only optimal solutions but also diverse and flexible strategies. The goal is to move away from rigid, overly rational AI behaviors and towards strategies that exhibit more human-like characteristics. Moreover, making AI algorithms more interpretable is essential for enhancing their reliability and practical usefulness across various applications. 2. NE focuses solely on the magnitude of expected payoffs, disregarding the variability in those payoffs. However, balancing risk and reward is a crucial aspect of decision-making. In different situations, we may need to adjust this balance and choose strategies accordingly. Relying on NE alone does not provide the flexibility to accommodate varying risk preferences. Previous algorithms that have achieved success in incomplete information have not addressed the issues mentioned above. To overcome these limitations, we propose a new algorithm called Preference Counterfactual Regret Minimization (Pref-CFR). This algorithm introduces two additional parameters for strategy selection: the preference degree δ𝛿\deltaitalic_δ, which represents the player’s inclination towards a particular action, and the vulnerability degree β𝛽\betaitalic_β, which indicates the maximum level of exploitability the player is willing to accept. More importantly, by setting the preference and vulnerability degrees, Pref-CFR can achieve specific strategy styles as desired by humans (e.g., a highly aggressive play style in poker). Additionally, the implementation of Pref-CFR is straightforward, requiring only minimal code changes from the original CFR, and it remains compatible with many previous CFR variants. In the experimental section, we first illustrate the limitations of the original CFR in failing to converge to different equilibria. We then highlight the capability of our algorithm to converge to various strategy styles in Texas Hold’em poker."
https://arxiv.org/html/2411.00954v1,Sample-Efficient Regret-Minimizing Double Oracle in Extensive-Form Games,"Extensive-Form Game (EFG) represents a fundamental model for analyzing sequential interactions among multiple agents and the primary challenge to solve it lies in mitigating sample complexity. Existing research indicated that Double Oracle (DO) can reduce the sample complexity dependence on the information set number |S|𝑆|S|| italic_S | to the final restricted game size X𝑋Xitalic_X in solving EFG. This is attributed to the early convergence of full-game Nash Equilibrium (NE) through iteratively solving restricted games. However, we prove that the state-of-the-art Extensive-Form Double Oracle (XDO) exhibits exponential sample complexity of X𝑋Xitalic_X, due to its exponentially increasing restricted game expansion frequency. Here we introduce Adaptive Double Oracle (AdaDO) to significantly alleviate sample complexity to polynomial by deploying the optimal expansion frequency. Furthermore, to comprehensively study the principles and influencing factors underlying sample complexity, we introduce a novel theoretical framework Regret-Minimizing Double Oracle (RMDO) to provide directions for designing efficient DO algorithms. Empirical results demonstrate that AdaDO attains the more superior approximation of NE with less sample complexity than the strong baselines including Linear CFR, MCCFR and existing DO. Importantly, combining RMDO with warm starting and stochastic regret minimization further improves convergence rate and scalability, thereby paving the way for addressing complex multi-agent tasks.","Extensive-Form Game (EFG) is one of the widely studied fundamental models in game theory (Ritzberger et al., 2016), and solving its Nash equilibrium (NE) is critical for addressing sequential decision-making problems constructed by multiple agents such as board games and auction bidding (Hart, 1992). Existing work have made strides in solving EFG, notably through a series of methods based on Counterfactual Regret Minimization (CFR) (Zinkevich et al., 2007; Farina et al., 2020; Lanctot et al., 2009). These methods aim to approximate Nash equilibrium by traversing all nodes (information sets) within the game tree to compute counterfactual regrets and update strategies. However, it is evident that the sample complexity of CFR methods heavily depends on the number of information sets, denoted by |S|𝑆|S|| italic_S |. Consequently, as the scale and complexity of the game increase, the resulting sample complexity by CFR methods becomes prohibitively high which significantly improves the intractability of solving EFGs. To efficiently solve EFGs, prior work have attempted to introduce Double Oracle (DO) paradigm (McMahan et al., 2003; Bosansky et al., 2014; McAleer et al., 2021; Dinh et al., 2022), which has a superior mechanism with lower complexity dependencies than CFR family. The core idea of DO is to approximate NE only by resolving an expanding restricted game where players can only choose actions from a subset of the action space. The restricted game is expanded by adding the original game’s Best Response (BR) against the NE in the restricted game (meta-NE). Since DO’s restricted game typically halts its growth in the early stages before reaching the original game, DO can reduce the sample complexity dependence from |S|𝑆|S|| italic_S | to the final restricted game size X𝑋Xitalic_X. The empirical results also demonstrate this advantage that the Extensive-Form DO (XDO) (McAleer et al., 2021) proposed based on DO framework can converge more efficiently to a less exploitable strategy than the regret minimization algorithm, and has become a state-of-the-art algorithm for solving EFGs. However, XDO iteratively executing regret minimization in restricted games until the local exploitability reaches a threshold ϵitalic-ϵ\epsilonitalic_ϵ, which then will be halved. This may lead to explosive growth in sample complexity in some cases but it is unclear how to mitigate it under complexity theory guidance. This motivates the core question we aim to answer: Q: What causes high sample complexity and how to avoid them when designing more efficient extensive-form DO algorithms? Firstly, we introduce a unified framework, Regret-Minimizing Double Oracle (RMDO) to theoretically understand the sources of sample complexity within the DO framework. RMDO is a generalization of existing DO methods including DO, XDO and ODO. We derive the sample complexity for RMDO framework to reach ϵitalic-ϵ\epsilonitalic_ϵ-NE: 𝒪~⁢(k⁢|A|⁢X3/ϵ2+∑j=1k|A|⁢X3/ϵ2⁢m⁢(j)+X⁢m⁢(j)),~𝒪𝑘𝐴superscript𝑋3superscriptitalic-ϵ2superscriptsubscript𝑗1𝑘𝐴superscript𝑋3superscriptitalic-ϵ2𝑚𝑗𝑋𝑚𝑗\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2}+\sum_{j=1}^{k}|A|X^{3}/\epsilon^{2}% m(j)+Xm(j)),over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_m ( italic_j ) + italic_X italic_m ( italic_j ) ) , (1) where j𝑗jitalic_j is the index of restricted game, A𝐴Aitalic_A is the action space, k𝑘kitalic_k is the number of restricted games, X𝑋Xitalic_X is the largest game size among the games constructed by the support of NEs, and m⁢(⋅)𝑚⋅m(\cdot)italic_m ( ⋅ ) is the frequency function of computing Best Response added to expand the restricted game. By setting different m⁢(⋅)𝑚⋅m(\cdot)italic_m ( ⋅ ), RMDO can be converted to existing existing DO methods. Based on RMDO, We have proved that even the state-of-the-art method XDO has the exponential sample complexity in k𝑘kitalic_k, where k𝑘kitalic_k represents the count of restricted games and is only bounded by the number of information sets in the final restricted game, denoted by X𝑋Xitalic_X. This verified the concern about the complexity explosion of XDO. Furthermore, based on the theoretical insights of RMDO, we propose an instance of RMDO called Adaptive Double Oracle (AdaDO), which employs the theoretically optimal frequency function to alleviate concerns about exponential sample complexity. AdaDO exhibits polynomial sample complexity to reach ϵitalic-ϵ\epsilonitalic_ϵ-NE, which matches the complexity lower bound of RMDO framework, and thus is more sample efficient than existing DO methods including XDO. Furthermore, to reduce the complexity caused by k𝑘kitalic_k by integrating with warm starting for strategy initialization when solving a new restricted game, AdaDO demonstrates a significant improvement in the speed of exploitability decreasing empirically. We also adopt stochastic regret minimizer, exemplified by Monte-Carlo Counterfactual Regret Minimization (MCCFR) (Farina et al., 2020; Lanctot et al., 2009), for the restricted game solving, and manage to reduce the power of X𝑋Xitalic_X in the sample complexity of AdaDO and enhance the scalability of Double Oracle methods. We present a comprehensive summary of theoretical results in Table 1, where Periodic Double Oracle (PDO) is naive improved instance by setting a constant expansion frequency but suffering from tuning this constant hyperparameter. Stochastic PDO (SPDO) and Stochastic Adaptive Double Oracle (SADO) are the natural extension of PDO and AdaDO adopting stochastic regret minimization for restricted game solving. Table 1: Main theoretical results of sample complexities for RMDO instances to reach ϵitalic-ϵ\epsilonitalic_ϵ-NE in extensive-form games. We categorize the algorithms into reaching NE by regret minimization (RM) and stochastic regret minimization (SRM). Denote |S|𝑆|S|| italic_S | as the number of infosets. Since X𝑋Xitalic_X and k𝑘kitalic_k are only bounded by |S|𝑆|S|| italic_S |, here we display the degree of these two dominating terms k𝑘kitalic_k and X𝑋Xitalic_X in the Sample Complexities. Besides, it is usually that k≫|A|much-greater-than𝑘𝐴k\gg|A|italic_k ≫ | italic_A | in theory since |A|∼𝒪⁢(|S|1/H)similar-to𝐴𝒪superscript𝑆1𝐻|A|\sim\mathcal{O}(|S|^{1/H})| italic_A | ∼ caligraphic_O ( | italic_S | start_POSTSUPERSCRIPT 1 / italic_H end_POSTSUPERSCRIPT ), where H𝐻Hitalic_H is the horizon of the game, but k𝑘kitalic_k is merely upper bounded by X𝑋Xitalic_X. Exp. in the column of degree indicates that the complexity is exponential in the corresponding factor. Reach NE via Algorithm Sample Complexity k𝑘kitalic_k X𝑋Xitalic_X RM XODO (Dinh et al., 2022) 𝒪~⁢(k2⁢X3/ϵ2)~𝒪superscript𝑘2superscript𝑋3superscriptitalic-ϵ2\tilde{\mathcal{O}}(k^{2}X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 2 3 XDO (McAleer et al., 2021) 𝒪~⁢(k⁢|A|⁢X3/ϵ2+4k⁢|A|⁢X3/ϵ02)~𝒪𝑘𝐴superscript𝑋3superscriptitalic-ϵ2superscript4𝑘𝐴superscript𝑋3superscriptsubscriptitalic-ϵ02\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2}+4^{k}|A|X^{3}/\epsilon_{0}^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT + 4 start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) Exp. 3 PDO 𝒪~⁢(k⁢|A|⁢X3/ϵ2)~𝒪𝑘𝐴superscript𝑋3superscriptitalic-ϵ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 AdaDO 𝒪~⁢(k⁢|A|⁢X3/ϵ2)~𝒪𝑘𝐴superscript𝑋3superscriptitalic-ϵ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 SRM SPDO 𝒪~⁢(k⁢|A|⁢X3/ϵ2)~𝒪𝑘𝐴superscript𝑋3superscriptitalic-ϵ2\tilde{\mathcal{O}}(k|A|X^{3}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 3 SADO 𝒪~⁢(k⁢|A|⁢X2/ϵ2)~𝒪𝑘𝐴superscript𝑋2superscriptitalic-ϵ2\tilde{\mathcal{O}}(k|A|X^{2}/\epsilon^{2})over~ start_ARG caligraphic_O end_ARG ( italic_k | italic_A | italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) 1 2 Empirical results in representative poker games and board game Sequential Blotto have demonstrated that AdaDO significantly outperforms XDO and can converge to exploitability solutions over 10101010 times less exploitable than the strong regret minimization baseline, Linear Counterfactual Regret Minimization. Notably, we observe a substantial improvement of in AdaDO with the warm starting technique, especially in a variant of Kuhn Poker, which enables DO to converge to up to 108superscript10810^{8}10 start_POSTSUPERSCRIPT 8 end_POSTSUPERSCRIPT times less exploitable solutions than DO without warm starting. In the setting of reaching NE via stochastic regret minimization, the instances of Stochastic RMDO can also generate a significantly less exploitable strategy compared to MCCFR. These results validate that AdaDO establishes a new state-of-the-art in EFG solving and provides a promising direction for addressing complex multi-agent decision-making tasks."
https://arxiv.org/html/2411.00825v1,Transparent Tagging for Strategic Social Nudges on User-Generated Misinformation,"Social network platforms (SNP), such as X and TikTok, rely heavily on user-generated content to attract users and advertisers, yet they have limited control over content provision, which leads to the proliferation of misinformation across platforms. As countermeasures, SNPs have implemented various policies, such as tweet labeling, to notify users about potentially misleading information, influencing users’ responses, either favorably or unfavorably, to the tagged contents. The population-level response creates a social nudge to the content provider that encourages it to supply more authentic content without exerting direct control over the provider. Yet, when designing such tagging policies to leverage social nudges, SNP must be cautious about the potential misdetection of misinformation (wrongly detecting factual content as misinformation and vice versa), which impairs its credibility to generic users and, hence, its ability to create social nudges. This work establishes a Bayesian persuaded branching process to study SNP’s tagging policy design under misdetection. Misinformation circulation is modeled by a multi-type branching process, where users are persuaded through tagging to give positive and negative comments that influence the spread of misinformation. When translated into posterior belief space, the SNP’s problem is reduced to an equality-constrained convex optimization, the optimal condition of which is given by the Lagrangian characterization. The key finding is that SNP’s optimal policy is simply transparent tagging, i.e., revealing the content’s authenticity to the user, albeit midsection, which nudges the provider not to generate misinformation. We corroborate our findings using numerical simulations.","Social network platforms (SNP), such as X and TikTok, where users create and consume content, play an increasingly important role in society. These platforms rely heavily on user-generated content (UGC) to engage and retain users to maintain high-level daily activity. Since users who generate original content(“content providers”) are not paid workers, platforms have limited control over the UGC, including misinformation. User-generated misinformation has become a growing concern on SNPs, as false information can spread rapidly and have significant consequences [1]. For instance, false stories about candidates were shared widely through SNPs during the 2016 US presidential election; misinformation about the virus, mask-wearing policies, and vaccine concerns spread through social networks during the COVID-19 pandemic. To address this issue, SNPs have implemented policies such as labeling, tagging, or notifying to alert users to potentially false or misleading information [2, 3]. Figure 1: An illustration of the proposed persuasion model, where the misinformation distribution θ⁢(λ)𝜃𝜆\theta(\lambda)italic_θ ( italic_λ ) is affected by the content provider and remains unknown to the user. The SNP’s misdetection of the underlying content is modeled by d𝑑ditalic_d. Previous studies have shown that these policies effectively (to some extent) curb the spread of misinformation [4]. One of the key reasons is that these platforms feature intensive social interactions among users, which can be leveraged to create social nudges in stimulating UGC supply [5]. For example, a post tagged as misleading will inflict users’ negative comments. After circulation on social networks, the population response to the post creates pressure on the content provider that discourages it from generating misinformation. This work proposes a persuasion game model to provide theoretical underpinnings for the SNP’s tagging design, aiming to harness the power of social nudges to reduce user-generated misinformation. As illustrated in Figure 1, the strategic interactions among the SNP, the content provider, and the user unfold as below. The SNP designs a tagging policy whose realized tags indicate the content authenticity of an arbitrary post returned by a detection device. Of particular note is that the detection device, usually empowered by artificial intelligence methods [6, 7, 8], is often imperfect and may misclassify the post’s authenticity. Such a policy does not directly control the provider or user but influences others’ behaviors through information provision. Hence, this tagging policy is referred to as the information structure [9]. Fully aware of this policy, the content provider exerts a private effort (unobservable to the SNP or user) in creating the content, assuming that the more effort exerted, the more authentic the content is. Finally, the user observes the tagging policy and the realized tags and then decides their views and comments that influence the online circulation modeled by a multi-type branching process. The proposed model differs from the seminal Bayesian persuasion game [10] in that the user cannot directly observe the prior distribution. Consequently, the user must form a conjecture about the content provider’s behavior to update their beliefs. This conjecture must be consistent with the provider’s equilibrium behavior, which leads to the concept of perfect Bayesian equilibrium (PBE) as the natural solution concept for our game. In our previous work [11], we addressed a special case where there was no detection error, allowing the SNP to identify misinformation in posts perfectly. However, in practical scenarios, detection errors are inevitable. In this work, the SNP’s design problem considers such misdetection, which leads to the SNP’s misperception of the game state that impairs tagging’s credibility and effectiveness in fostering social nudges. Our key finding is that transparent tagging, where the SNP honestly discloses the detection outcome to the content provider and user, is most effective in combating misinformation generation and circulation. Although the SNP may not have direct control over content generation, it can nudge user perceptions through tagging. The collective behaviors of users, under these perceptions, determine the content provider’s reputation, effectively making users the SNP’s proxy in terms of incentive provision, encouraging the provider to exert the best effort in reducing misinformation generation. Our contributions are summarized below. • We propose a three-player Bayesian persuasion game that studies the SNP’s tagging policy under the presence of misdetection and the content provider’s intention to uphold its reputation, with misinformation circulation among users modeled as a multi-type branching process; • We identify players’ strategies under perfect Bayesian equilibrium by transforming the problem into the posterior belief space, reducing it to an equality-constrained convex optimization problem; • We characterize the optimal conditions using a Lagrangian approach, demonstrating that the SNP’s optimal policy is transparent tagging despite detection errors, incentivizing the content provider to exert maximum implementable effort."
https://arxiv.org/html/2411.01794v2,Revisiting Game-Theoretic Control in Socio-Technical Networks: Emerging Design Frameworks and Contemporary Applications,"Socio-technical networks represent emerging cyber-physical infrastructures that are tightly interwoven with human networks. The coupling between human and technical networks presents significant challenges in managing, controlling, and securing these complex, interdependent systems. This paper investigates game-theoretic frameworks for the design and control of socio-technical networks, with a focus on critical applications such as misinformation management, infrastructure optimization, and resilience in socio-cyber-physical systems (SCPS). Core methodologies, including Stackelberg games, mechanism design, and dynamic game theory, are examined as powerful tools for modeling interactions in hierarchical, multi-agent environments. Key challenges addressed include mitigating human-driven vulnerabilities, managing large-scale system dynamics, and countering adversarial threats. By bridging individual agent behaviors with overarching system goals, this work illustrates how the integration of game theory and control theory can lead to robust, resilient, and adaptive socio-technical networks. This paper highlights the potential of these frameworks to dynamically align decentralized agent actions with system-wide objectives of stability, security, and efficiency.","Game theory addresses strategic interactions among decision-makers, often referred to as players or agents [1]. Each player has a distinct objective function—either a utility to maximize or a cost to minimize—which encapsulates their preferences across available alternatives. However, these preferences are interdependent, shaped by the choices made by other players, creating a need for game theory as a framework to model these strategic dynamics [2]. In non-cooperative games, where players act independently, achieving an equilibrium is a central focus. The Nash equilibrium, a key concept developed by John Nash, represents a stable state where no player can unilaterally adjust their strategy for a better outcome [3]. This equilibrium concept enables analysts to identify stable states in competitive environments. When hierarchical decision-making exists, other solution concepts like the Stackelberg equilibrium are more suitable, especially in scenarios where leaders act first and followers respond. This framework is particularly applicable in control scenarios where independent agents must coordinate within shared constraints [4]. The formalization of game theory is largely attributed to John von Neumann and Oskar Morgenstern’s Theory of Games and Economic Behavior [1], a pioneering text that established the field’s foundations and generated broad, interdisciplinary interest. Nash’s work on equilibrium expanded the field significantly, enabling stable solutions for non-cooperative games [3]. Additional advancements by Richard Bellman, who introduced dynamic programming [5], and Rufus Isaacs, known for differential games [6], extended game theory to dynamic and multi-stage decision-making, integrating it more deeply into control and optimization contexts. A defining moment for game theory was its integration into optimal control and decision processes, especially through the efforts of researchers at the RAND Corporation, including Bellman, Nash, and Isaacs. At RAND, these theorists developed models intersecting military strategy, economics, and control systems, catalyzing breakthroughs in multi-agent decision-making processes. Isaacs’ differential games, for instance, established a framework for continuous-time strategic interactions’ foundational for adversarial scenarios like pursuit-evasion games [6]. This interdisciplinary evolution of game theory alongside advances in optimal control provided the groundwork for its application in modern networked systems, where it remains central to understanding strategic interdependencies and designing resilient control mechanisms. I-A Game Theory and Socio-Technical Systems Today’s interconnected systems—ranging from telecommunications and social networks to critical infrastructure—face unique challenges as they are populated by autonomous agents, each pursuing individual objectives, but interconnected through their actions and information exchanges. Game theory is a critical tool in such environments, especially where decentralized decision-making is needed. In multi-agent systems, every agent’s actions affect the network’s overall state, often creating complex dynamics that are difficult to predict and control. Game-theoretic analysis equips researchers and designers with the methods to anticipate these interactions, predict system behavior, and develop strategies that enhance stability, efficiency, and resilience across the network [7]. Moreover, these networks are often socio-technical systems, where human behavior directly influences their performance, efficiency, and resilience. Human decisions and interactions shape the functioning of many networked systems, such as transportation, energy grids, and public health infrastructure [8, 9, 10]. For example, transportation networks must account for the flexible and sometimes unpredictable nature of human routing decisions. In such settings, infrastructure planning cannot be isolated from human behavior. The well-known Braess paradox illustrates that adding roads to a network may lead to increased congestion, as drivers individually optimize their routes, often at the expense of overall efficiency [11]. Game-theoretic models help planners anticipate these outcomes, enabling the design of transportation networks that mitigate unintended consequences and improve flow [12]. In smart energy systems, where energy prosumers (both consumers and producers) decide when to buy or sell energy, individual behaviors impact the grid’s supply-demand balance. To maintain grid stability, game-theoretic mechanisms can incentivize prosumers to make decisions that align personal economic interests with the system’s operational needs [13]. These control mechanisms foster a resilient and efficient energy network by balancing incentives for prosumers in ways that enhance resource allocation and minimize the risk of outages [14]. Figure 1 illustrates the nature of the control of socio-technical systems. The technical system is coupled with the human networks, and the designer can influence the coupled system through different control paradigms, including information, incentives, and network structures. Public health further exemplifies the socio-technical nature of modern systems, as seen during the COVID-19 pandemic. Individual choices, such as decisions about vaccination, mask-wearing, and social interactions, had substantial effects on the spread of the virus [15, 16, 17, 18]. In such interconnected populations, the community’s health state depends on the aggregation of personal decisions. Game-theoretic design principles offer powerful tools for crafting behavioral incentives and nudges that guide individuals toward compliance with public health measures [19]. By structuring these incentives effectively, game theory helps manage collective health outcomes, particularly during health crises, and underscores the importance of considering socio-technical dynamics in system design. By integrating game-theoretic frameworks into socio-technical systems, designers gain the ability to understand and anticipate human-driven impacts on system dynamics. Game theory provides structured approaches for designing incentives, controlling information flows, and implementing adaptive mechanisms that foster desirable behaviors. These strategies are essential for ensuring that the interactions of autonomous agents—whether they are people, machines, or a mix of both—contribute positively to network performance, resilience, and societal benefit [20]. Fig. 1: A Game-Theoretic Control Paradigm for Socio-Technical Systems: Socio-technical networks are composed of interconnected human and technical networks. Human agents interact both with one another and with technical infrastructures, including power grids, transportation systems, and cyber networks. The control of these networks can be achieved through strategic designs in information flow, network structure, and incentive mechanisms. Information design guides how agents access and process data, while network design shapes the connectivity and interaction pathways within the system. Incentive design, on the other hand, motivates desired behaviors by aligning agent actions with system-wide objectives, ensuring that human and technical interactions are coordinated to achieve resilience, efficiency, and security across the socio-technical network. I-B Game-Theoretic Control Design Game theory offers not only a framework for modeling, performance evaluation, and risk assessment but also a robust design methodology for creating decentralized agents. A key strength of game-theoretic design lies in its decentralized approach, which provides a foundational structure for building and managing complex, large-scale networks [21, 22]. In these decentralized networks, individual agents act based on personal incentives, often with limited or no knowledge of the network’s overall state. This bottom-up approach mirrors real-world systems, where centralized control may be impractical or ineffective. For human agents, game-theoretic design allows for behavior modification to align with system goals. For machine agents, it enables programming diverse agents to follow a coordinated protocol. These agents, whether human or machine, can work collectively to achieve desired outcomes associated with metrics such as efficiency, robustness, resilience, and security. By embedding game-theoretic strategies, designers can anticipate and guide agent interactions, facilitating cooperative behavior even in environments with limited information sharing or direct coordination. Figure 2 presents an agent-based perspective on socio-technical systems illustrated in Figure 1. Within this framework, human agents within human networks engage with machine agents in technical networks, while also interacting with other agents in their respective networks. Each human agent operates as a coupled system, integrating individual belief processes with action processes. Similarly, each machine agent functions as a coupled system, linking control processes with physical processes. Designers can influence various agents through targeted levers across different system components, aiming to optimize system-level performance. The design of agents is closely linked to control theory, specifically the design of controllers that manage dynamical systems to achieve desirable properties like stability and optimality. While control theory traditionally focuses on governing centralized control systems, game-theoretic agent design introduces a complementary approach that is particularly suited to large-scale socio-technical networks. In these networks, the goal is often to achieve outcomes such as optimal social welfare or collective efficiency, which align with the objectives of control theory. Game-theoretic design operates from the bottom up, creating decentralized agents that make decisions based on local information and personal incentives. This bottom-up approach enables scalability, making it ideal for vast, complex networks typical of socio-technical systems, where centralized control may be impractical. By designing agents to act independently yet cohesively, game-theoretic design facilitates adaptable, resilient, and efficient network behaviors, even in highly dynamic and large-scale environments. Modeling of the Agents For the socio-technical system illustrated in Figure 1, game theory can model diverse interactions within socio-technical networks from the ground up. These interactions can be categorized into several key types. First, interactions occur between agents within the same network, such as those between human agents in human networks or machine agents within technical networks. These intra-network interactions capture the dynamics among similar types of agents and can reveal emergent patterns within isolated sub-systems. Second, interactions take place between agents across different networks. For instance, human agents in the socio-network interact with machine agents in the technical network, bridging the socio-technical divide. These cross-network interactions are crucial for understanding how human and machine agents jointly influence system outcomes. A third category involves interactions with adversarial agents. Adversarial agents are specifically introduced to evaluate the security, robustness, and resilience of the network. These adversarial entities may be real participants within the network or artificial agents created to assess risk. By engaging human or technical agents with adversaries designed with specific intentions and capabilities, we can measure local security and resilience properties more accurately. Finally, interactions occur between agents and a designer. Here, a designer exerts influence over agents in a controlled way to guide their behavior toward achieving network-wide objectives. This interaction serves as a means of designing and controlling agent actions within the network to align with broader system goals. Each of these interactions takes on distinct forms, and the various games representing them are ultimately composed into a larger framework, referred to as a “meta-game.” This meta-game governs the design and control of the entire socio-technical network, enabling a holistic approach to understanding and managing complex interactions within the system. Control of the Agents Agents can be controlled in various ways, depending on their nature and function, and these controls can be categorized into three primary paradigms. The first is physical control, which involves managing physical attributes like speed, direction, and other measurable quantities, as seen in robotic agents [23]. The second is cyber control, where the focus is on controlling the information received by agents, such as news broadcasts for human agents or sensor data for autonomous vehicles. The third paradigm is human control, where the objective is to influence perceptions and incentives to guide human behavior in desired directions. Across these paradigms, network structure and information design are fundamental. How agents communicate, physically interact, and gather information from observations and perceptions are critical components of effective system design [24]. A key connection between control theory and game-theoretic design emerges through the use of dynamic game frameworks to model and guide agent behavior in evolving environments [25, 26]. In dynamic games [27], agents interact over time within changing environments and face uncertainties. Agent behaviors are characterized by adaptive feedback loops, where decisions continuously adjust based on environmental conditions. Information flow becomes particularly crucial in these scenarios, as agents make real-time decisions with limited or noisy information about others’ actions. The flow and structure of information directly shape agents’ strategic choices, influencing the overall system’s resilience and robustness. Bridging control and game-theoretic design achieves a unified approach to achieving individual dynamic agents and ensuring the stability and efficiency of the entire system. On the individual level, agents must operate effectively within their local environments, maintaining stability in response to changing conditions and achieving their own performance goals. At the system level, however, the design must prioritize overall stability, resilience, and system-wide metrics [28, 29]. Fig. 2: Illustration of Interaction Between a Social Agent in the Human Network and a Machine Agent in the Technical Network: A social agent interacts with the human network and a machine agent within the technical network. Each agent is also connected to other agents within its own network. The machine agent provides specific services to the social agent, while the social agent impacts the machine agent and its network through behaviors such as consumption, usage, or demand patterns. The designer can strategically influence both networks using tools like information design and incentive structures. Information design shapes the structure of information between agents, while incentive design aligns agent actions with broader system goals, creating a coordinated and adaptive socio-technical system. I-C The Underlying Philosophy of Agent-Based Game-Theoretic Design in Socio-Technical Networks The agent-based game-theoretic design of socio-technical networks embodies a dual philosophy [30, 31]: reductionistic design and holistic control. On one side, game-theoretic design takes a reductionist approach, where the whole system is decomposed into modular components or agents. By breaking down complex, large-scale networks into manageable agents, this approach allows designers to handle intricate interdependencies and diverse functions within the system. On the other side, the design aims to achieve high-level system objectives—such as efficiency, security, and resilience—which are often prescribed at a system-wide level. The reductionist design of individual agents must, therefore, be aligned with these holistic goals, ensuring coherence between component-level actions and overall system performance. Establishing such coherence is fundamental to the principles guiding game-theoretic design in socio-technical networks. Achieving coherence between agent-level design and system-level objectives requires a framework to bridge them. Designers need to assess how individual agent behaviors impact system-wide metrics, making it essential to monitor the alignment of component actions with system goals. Game-theoretic analysis provides this bridge by offering a structured framework to predict system-level behaviors through equilibrium concepts. The equilibrium, depending on the application and structure of the network, enables designers to forecast the outcomes of individual actions within the larger system. Various solution concepts within game theory offer tools to assess and develop performance metrics. For instance, in a security context, equilibrium analysis between a defender agent and an attacker can yield risk metrics, while in robustness analysis, saddle-point equilibria between the system and external disturbances inform robustness metrics. Game theory serves as a bridge that enables reductionist designers to account for the holistic impact of individual agent designs on the system’s objectives. Meanwhile, holistic system designers must shape the architecture, including hierarchies, network structures, and resource allocations, to ensure that agent-level designs contribute to the system’s high-level goals. Frameworks such as Stackelberg games, equilibrium-constrained optimization, and mechanism design theory play a central role in achieving this alignment. Holistic designers must understand how agents respond to these structures at equilibrium and ensure that top-down control strategies foster the intended system-wide behavior. Ensuring coherence becomes more challenging under conditions of uncertainty, adaptive requirements, and emergent properties such as resilience and security. These complex requirements demand clear, quantifiable metrics to guide system and agent design. Despite these challenges, game theory—with its rich array of tools and methodologies—provides a means to develop advanced techniques that foster coherence in dynamic, complex systems. For instance, game-theoretic tools can incorporate learning and adaptation, enabling agent designs to evolve in response to an uncertain environment while staying aligned with system goals. This coherence between reductionism and holistic control, illustrated in Figure 3, is where game theory and control theory intersect, together forming the foundation for a new system design paradigm. Designing socio-technical networks requires this paradigm shift and the convergence between control and game theory to address the unique demands of these complex, interconnected systems. For example, in a smart grid, it is insufficient to simply control each subsystem, such as energy generation or distribution, in isolation. The system must account for the interplay between independent agents (e.g., consumers, generators, and grid operators) who each respond to incentives, environmental conditions, and their own objectives. By integrating game-theoretic strategies, designers can predict how these agents will behave collectively, while control theory enables the coordination of these actions to maintain grid stability, efficiency, and resilience. Fig. 3: The holistic control design must align consistently with the reductionist behaviors of individual agents. Game theory, inherently a reductionist approach, focuses on designing and analyzing individual agent behaviors, while control theory provides a holistic framework to achieve overarching system goals. Game-theoretic control offers a cohesive approach that bridges these two perspectives, integrating the detailed evaluation and synthesis tools of reductionist models with the coordination and control mechanisms of holistic design. This combined framework ensures that individual agent actions are aligned with the broader system objectives, creating a unified and adaptive socio-technical system. I-D Organization of the Letter This letter provides an overview of game-theoretic design approaches. In Section II, we explore foundational frameworks used in agent design, focusing on Stackelberg-type game frameworks and mechanism design theory, which has been widely applied to settings like auctions and market structures. Section III examines the challenges of designing socio-technical systems, addressing issues such as human behavioral dynamics, uncertainty quantification, and scalability. In Section IV, we present emerging paradigms in game-theoretic design, including mean-field design, learning-based design, population-based design, and adversarial design. These approaches are applied to critical areas such as misinformation management in social networks, resilience in industrial control systems, and congestion control in infrastructure networks. We close the letter with the concluding remarks of Section V."
https://arxiv.org/html/2411.01711v1,Nash equilibria in four-strategy quantum game extensions of the Prisoner’s Dilemma,"This paper investigates Nash equilibria in pure strategies for quantum approach to the Prisoner’s Dilemma. The quantization process involves extending the classical game by introducing two additional unitary strategies. We consider five classes of such quantum games, which remain invariant under isomorphic transformations of the classical game. For each class, we identify and analyze all possible Nash equilibria. Our results reveal the complexity and diversity of strategic behavior in the quantum setting, providing new insights into the dynamics of classical decision-making dilemmas. In the case of the standard Prisoner’s Dilemma, the resulting Nash equilibria of quantum extensions are found to be closer to Pareto optimal solutions than those of the classical equilibrium.Keywords: game isomorphism, Eisert-Wilkens-Lewenstein scheme, quantum extended games, Nash equilibrium, Prisoner’s Dilemma","A principal objective of quantum game theory is to establish a methodology for transforming classical game theory problems into a quantum mechanical framework [1, 2, 3, 4]. Subsequently, the characteristics of the resulting game are analysed using techniques from classical game theory [5, 6, 7, 8], or the quantum game is examined in terms of concepts from quantum computing [9, 10, 11, 12]. Similar to classical game theory, the fundamental problem explored in quantum game theory is the problem of finding rational strategy profiles and answering the question of whether the quantum extension of the game affects the final outcome [13, 14, 15, 16, 17]. In this context, the Nash equilibrium (NE) is a widely used solution concept [18] that is considered a necessary condition for a given strategy profile to be considered rational. A NE is defined as a strategy profile where no player can improve their payoff by changing their own strategy, assuming that all other players’ strategies remain unchanged. This solution concept is applicable in both classical and quantum games due to the way it is formulated. The Prisoner’s Dilemma (PD) is a classical problem in game theory, illustrating the conflict between individual rationality and collective welfare [19]. Traditionally, the PD game is defined for two players, each having two strategies: cooperate or defect. The standard PD game has a single NE where both players choose to defect, leading to a suboptimal outcome for both. However, the introduction of quantum strategies offers new possibilities for altering this equilibrium structure, potentially allowing for outcomes that are more beneficial to all players involved [1, 20, 21]. In our previous works, we explored the quantum extensions of classical games using the Eisert-Wilkens-Lewenstein (EWL) scheme, which introduces additional unitary strategies alongside the classical strategies [22, 23]. The quantum extensions have been classified into a number of distinct categories, based on the characteristics of the admissible quantum strategies that preserve invariance with respect to isomorphic transformations of the classical game. Our focus was primarily on identifying the conditions under which these quantum games preserve the structural characteristics of the original game while extending the strategic landscape available to the players. The main goal of the present paper is to examine these extensions in more detail by identifying every NE in the pure strategy profiles of the quantum-enhanced PD. By examining the PD in its most generalized form, considering any admissible set of payoffs, the study seeks to understand under what conditions NE can be achieved for each class of extension. Specifically, the work investigates the constraints that the payoff matrix must satisfy for a given pure strategy profile to be considered a NE across all identified classes of quantum extensions. Through this comprehensive analysis, we provide a detailed characterization of strategy profiles and their corresponding NE, thereby extending the understanding of quantum strategies’ impact on traditional game-theoretical problems. The paper demonstrates that the NE obtained are more closely aligned with Pareto-optimal solutions than the classical PD. Nevertheless, the class of extensions under consideration does not encompass fully cooperative equilibria. One example of this is the so-called ""magic strategy"" [1], which, however, does not satisfy the condition of independence from isomorphic transformations of the classical game [22], which is a necessary condition for the extension to be unambiguous. This contribution not only enhances the theoretical framework of quantum game theory but also has potential applications in fields such as quantum computing and strategic decision-making [6, 24], where understanding complex interactive dynamics is crucial. The work is divided into 5 parts. In the second section we briefly define the key concepts of PD, NE, the EWL quantum game scheme, and prove that positive affine transformations of the payoffs of the classical game do not affect the preference relations of the quantum game. In the third section, we recall five classes of quantum extensions of the classical 2×2222\times 22 × 2 game. In these extensions, quantum players have two additional unitary strategies in addition to their initial classical strategies. The extensions are invariant to isomorphic transformations of the classical game [23]. Furthermore, we demonstrate the symmetry of quantum extensions of the symmetric game. In the fifth section, which is divided into five sub-sections, we analyse the existence of NE of successive classes of extensions. To do so, we examine each of 16 possible profiles of pure strategies. Where equilibria exist, we give the conditions that must be satisfied by the parameters of quantum strategies and PD payoffs."
https://arxiv.org/html/2411.01191v1,Prophet Secretary and Matching: the Significance of the Largest Item,"The prophet secretary problem is a combination of the prophet inequality and the secretary problem, where elements are drawn from known independent distributions and arrive in uniformly random order. In this work, we design 1) a 0.6880.6880.6880.688-competitive algorithm, that breaks the 0.6750.6750.6750.675 barrier of blind strategies (Correa, Saona, Ziliotto, 2021), and 2) a 0.6410.6410.6410.641-competitive algorithm for the prophet secretary matching problem, that breaks the 1−1/e≈0.63211𝑒0.6321-1/e\approx 0.6321 - 1 / italic_e ≈ 0.632 barrier for the first time. Our second result also applies to the query-commit model of weighted stochastic matching and improves the state-of-the-art ratio (Derakhshan and Farhadi, 2023).","The study of prophet inequality dates back to the 1970s [31, 32] from optimal stopping theory. Consider n𝑛nitalic_n items with independent random values arriving one by one in an adversarial order. The value distribution Fisubscript𝐹𝑖F_{i}italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT of each item i𝑖iitalic_i is known upfront to the algorithm, but the realization of value vi∼Fisimilar-tosubscript𝑣𝑖subscript𝐹𝑖v_{i}\sim F_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT is only revealed on the item’s arrival. After seeing the item’s identity i𝑖iitalic_i and value visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the algorithm decides immediately whether to accept the item and collect its value; the algorithm can accept at most one item in this problem. The goal is to maximize the expected value of the accepted item and compete against the prophet, i.e., the expected maximum value 𝐄⁡[maxi⁡vi]𝐄subscript𝑖subscript𝑣𝑖\operatorname{\mathbf{E}}\mathchoice{\left[\max_{i}v_{i}\right]}{[\max_{i}v_{i% }]}{[\max_{i}v_{i}]}{[\max_{i}v_{i}]}bold_E [ roman_max start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ]. It is known that the optimal competitive ratio is 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG for this problem. A fundamental extension of the prophet inequality is prophet matching. Consider an underlying bipartite graph with edge weights drawn from known distributions. The vertices on one side are known upfront and those on the other side arrive online. On the arrival of an online vertex visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT, the weights of its incident edges are revealed and the algorithm decides whether to match visubscript𝑣𝑖v_{i}italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT and to which offline vertex. The classic prophet inequality is captured by this model with one offline vertex. Feldman, Gravin, and Lucier [19] gave a tight 1212\frac{1}{2}divide start_ARG 1 end_ARG start_ARG 2 end_ARG competitive algorithm for the matching setting, and their result was further generalized to settings when all vertices arrive online [17]. In this work, we consider the secretary variants (a.k.a. the random order variants) of prophet inequality and prophet matching, i.e., the setting where the arrival order of items (resp. vertices) is uniformly at random. The study of prophet secretary was initiated by Esfandiari et al. [16], who designed a 1−1/e≈0.63211𝑒0.6321-1/e\approx 0.6321 - 1 / italic_e ≈ 0.632 competitive algorithm and provided an upper bound of 0.750.750.750.75.111The competitive ratio of an algorithm is a number between [0,1]01[0,1][ 0 , 1 ]. A lower bound corresponds to an algorithm and an upper bound corresponds to an impossibility result. Since then, a sequence of follow-up works [3, 10, 25, 7, 23] have focused on closing the gap. The state-of-the-art lower and upper bounds are 0.6720.6720.6720.672 by Harb [25] and 0.7230.7230.7230.723 by Giambartolomei et al. [23] respectively. Less progress has been made on the prophet secretary matching problem. Ehsani et al. [15] gave a 1−1/e11𝑒1-1/e1 - 1 / italic_e competitive algorithm. Very recently, the 1−1/e11𝑒1-1/e1 - 1 / italic_e barrier was surpassed in two special cases: 1) the i.i.d. setting studied by Yan [40] and Qiu et al. [37]; and 2) the query-commit setting studied by Derakhshan and Farhadi [12]. Beating 1−1/e11𝑒1-1/e1 - 1 / italic_e for the general case of prophet secretary matching remains one of the most intriguing open questions to the online algorithms community. 1.1 Our Contributions Result for Prophet Secretary. We design a 0.6880.6880.6880.688 competitive algorithm for the prophet secretary problem. Besides the improvement over the state-of-the-art 0.6720.6720.6720.672 ratio, our result further surpasses the 0.6750.6750.6750.675 barrier of blind strategies [10], the family of algorithms that Correa et al. [10] and Harb [25] focused on. Blind strategies rely on only the distribution of the maximum value, but not the fine-grained distributional information of individual items’ values. Intuitively, such fine-grained information must be crucial because the items are heterogeneous in the prophet secretary problem. However, it is technically challenging to incorporate such information to design and analyze item-dependent strategies: changing the strategy for one item would unavoidably affect the probability of accepting other items since we can accept only one of them. Technique: Activation-Based Algorithms. We introduce two ideas to address this difficulty. First, we change our point of view from designing acceptance probabilities to choosing activation rates. In general, an online algorithm is defined by the probability of accepting an item based on its identity i𝑖iitalic_i, value v𝑣vitalic_v, and the set of future items that will arrive later. Following the conventional wisdom, the current item’s arrival time t𝑡titalic_t is a good surrogate for aggregating information about exponentially many possible sets of future items over their random arrivals. Here, we interpret the random order as having each item arrive within a time horizon from 00 to 1111 uniformly at random. In short, algorithms are represented by the acceptance probabilities for item i𝑖iitalic_i when it has value v𝑣vitalic_v and arrives at time t𝑡titalic_t. However, it is difficult to analyze the algorithms based on this representation. By contrast, we will consider the activation rates aiv⁢(t)superscriptsubscript𝑎𝑖𝑣𝑡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) for item i𝑖iitalic_i when it has value v𝑣vitalic_v and arrives at time t𝑡titalic_t, and the overall activation rates Ai⁢(t)=𝐄v∼Fi⁡[aiv⁢(t)]subscript𝐴𝑖𝑡subscript𝐄similar-to𝑣subscript𝐹𝑖superscriptsubscript𝑎𝑖𝑣𝑡A_{i}(t)=\operatorname{\mathbf{E}}_{v\sim F_{i}}\mathchoice{\left[a_{i}^{v}(t)% \right]}{[a_{i}^{v}(t)]}{[a_{i}^{v}(t)]}{[a_{i}^{v}(t)]}italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ) = bold_E start_POSTSUBSCRIPT italic_v ∼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) ] of the item at time t𝑡titalic_t. We activate this item (and accept it if no item has been accepted yet) with probability: giv⁢(t)=aiv⁢(t)⋅e−∫0tAi⁢(x)⁢dx.superscriptsubscript𝑔𝑖𝑣𝑡⋅superscriptsubscript𝑎𝑖𝑣𝑡superscript𝑒superscriptsubscript0𝑡subscript𝐴𝑖𝑥differential-d𝑥g_{i}^{v}(t)=a_{i}^{v}(t)\cdot e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}~{}.italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) = italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) ⋅ italic_e start_POSTSUPERSCRIPT - ∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT . This new viewpoint offers two useful invariants. By definition, the probability that we activate item i𝑖iitalic_i before time t𝑡titalic_t equals: ∫0t𝐄v∼Fi⁡[giv⁢(x)]⁢dx=1−e−∫0tAi⁢(x)⁢dx.superscriptsubscript0𝑡subscript𝐄similar-to𝑣subscript𝐹𝑖superscriptsubscript𝑔𝑖𝑣𝑥differential-d𝑥1superscript𝑒superscriptsubscript0𝑡subscript𝐴𝑖𝑥differential-d𝑥\int_{0}^{t}\operatorname{\mathbf{E}}_{v\sim F_{i}}\mathchoice{\left[g_{i}^{v}% (x)\right]}{[g_{i}^{v}(x)]}{[g_{i}^{v}(x)]}{[g_{i}^{v}(x)]}\mathrm{d}x~{}=~{}1% -e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}~{}.∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT bold_E start_POSTSUBSCRIPT italic_v ∼ italic_F start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_g start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_x ) ] roman_d italic_x = 1 - italic_e start_POSTSUPERSCRIPT - ∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT . Hence, the activation events effectively follow a Poisson process with rates Ai⁢(t)subscript𝐴𝑖𝑡A_{i}(t)italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_t ). Accordingly, the probability that we activate item i𝑖iitalic_i with value v𝑣vitalic_v and arrival time t𝑡titalic_t is: 𝐏𝐫⁡[vi=v]⋅aiv⁢(t)⋅e−∫0t∑j=1nAj⁢(x)⁢d⁢x⏟(⋆)⁢d⁢t.⋅⋅𝐏𝐫subscript𝑣𝑖𝑣superscriptsubscript𝑎𝑖𝑣𝑡subscript⏟superscript𝑒superscriptsubscript0𝑡superscriptsubscript𝑗1𝑛subscript𝐴𝑗𝑥d𝑥⋆d𝑡\operatorname{\mathbf{Pr}}\mathchoice{\left[v_{i}=v\right]}{[v_{i}=v]}{[v_{i}=% v]}{[v_{i}=v]}\cdot a_{i}^{v}(t)\cdot\underbrace{\vphantom{\big{|}}e^{-\int_{0% }^{t}\sum_{j=1}^{n}A_{j}(x)\mathrm{d}x}}_{(\star)}\mathrm{d}t~{}.bold_Pr [ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_v ] ⋅ italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) ⋅ under⏟ start_ARG italic_e start_POSTSUPERSCRIPT - ∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT end_ARG start_POSTSUBSCRIPT ( ⋆ ) end_POSTSUBSCRIPT roman_d italic_t . Note that the second part (⋆)⋆(\star)( ⋆ ) is independent of the item’s identity i𝑖iitalic_i and value v𝑣vitalic_v. Therefore, we can simplify the dependence of different items’ strategies by introducing an upper bound on ∑j=1nAj⁢(t)superscriptsubscript𝑗1𝑛subscript𝐴𝑗𝑡\sum_{j=1}^{n}A_{j}(t)∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) for any time t𝑡titalic_t. Subject to this invariant, we can freely design the activation rates aiv⁢(t)superscriptsubscript𝑎𝑖𝑣𝑡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) for each item i𝑖iitalic_i and value v𝑣vitalic_v to approximately match its contribution to the prophet benchmark. To further simplify the analysis, we focus on activation rates aiv⁢(t)superscriptsubscript𝑎𝑖𝑣𝑡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) that are step functions that change their values at a common threshold time. We demonstrate the effectiveness of this viewpoint and such simple step activation rates in Section 2.4.2 by proving a 0.6940.6940.6940.694 competitive ratio when all items are small in the sense that each contributes only o⁢(1)𝑜1o(1)italic_o ( 1 ) to the prophet benchmark. Technique: Significance of the Largest Item. To further handle the general case of prophet secretary, we will focus on the item i0subscript𝑖0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT with the largest probability of being selected by the prophet. This is partly inspired by the existing hard instances (e.g., [10, 7, 23]), all of which involve one large item and many small items. The significance of the largest item is twofold: 1) we need to design a special strategy for it beyond the step-function activation rates, and 2) its characteristics provide sufficient information for selecting the invariants for the other items’ activation rates. Why do we need a special strategy for this largest item? Consider the extreme case when it is the only item that matters. Intuitively, we would like to select it with certainty on its arrival. However, we cannot do that using the step-function activation rates. Within a time interval where the activation rates aiv⁢(t)superscriptsubscript𝑎𝑖𝑣𝑡a_{i}^{v}(t)italic_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ( italic_t ) remain a constant, the e−∫0tAi⁢(x)⁢dxsuperscript𝑒superscriptsubscript0𝑡subscript𝐴𝑖𝑥differential-d𝑥e^{-\int_{0}^{t}A_{i}(x)\mathrm{d}x}italic_e start_POSTSUPERSCRIPT - ∫ start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT italic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ( italic_x ) roman_d italic_x end_POSTSUPERSCRIPT term decreases the activation probability over time. This decrease is mild for smaller items, but could be substantial for the largest item. Remarkably, this seemingly trivial instance plays an important role of establishing the 0.6750.6750.6750.675 barrier for blind strategies [10]. Motivated by this extreme case, we let the largest item’s activation probability rather than its activation rate be piece-wise constant. While it is difficult to analyze algorithms based on the representation by activation/acceptance probabilities in general, we show that it is manageable to do that for just one largest item. This special treatment of just one largest item is sufficient for breaking the 0.6750.6750.6750.675 barrier. We will consider two characteristics of this largest item: its probability of being selected by the prophet, i.e., x0=𝐏𝐫⁡[vi0=maxj⁡vj]subscript𝑥0𝐏𝐫subscript𝑣subscript𝑖0subscript𝑗subscript𝑣𝑗x_{0}=\operatorname{\mathbf{Pr}}\mathchoice{\left[v_{i_{0}}=\max_{j}v_{j}% \right]}{[v_{i_{0}}=\max_{j}v_{j}]}{[v_{i_{0}}=\max_{j}v_{j}]}{[v_{i_{0}}=\max% _{j}v_{j}]}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT = bold_Pr [ italic_v start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT = roman_max start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ], and a quantity h0subscriptℎ0h_{0}italic_h start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT that measures the extent to which item i0subscript𝑖0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT would be selected by the prophet with probability more than half, over the randomness of the other items’ values. Based on just x0subscript𝑥0x_{0}italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT and h0subscriptℎ0h_{0}italic_h start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT, we will choose the (1) invariants ∑j≠i0Aj⁢(t)subscript𝑗subscript𝑖0subscript𝐴𝑗𝑡\sum_{j\neq i_{0}}A_{j}(t)∑ start_POSTSUBSCRIPT italic_j ≠ italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_A start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ( italic_t ) for the activation rates of other items, (2) the shared threshold time for the step-function activation rates of other items, and (3) the three-stage step-function activation probabilities of the largest item i0subscript𝑖0i_{0}italic_i start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT. It is surprising that these two characteristics of the largest item alone are sufficient for choosing all important invariants for our algorithm and analysis. Result for Prophet Secretary Matching. We design a 0.6410.6410.6410.641-competitive algorithm for the prophet secretary matching problem, breaking the 1−1/e11𝑒1-1/e1 - 1 / italic_e barrier for the first time. As a corollary of this result, we also improve the state-of-the-art ratio of the query-commit setting from 0.6330.6330.6330.633 [12] to 0.6410.6410.6410.641 through a reduction [22, 11] from the query-commit model to the secretary model. Summary of Techniques for Prophet Secretary Matching. We start by extending the activation-based framework to matching. First, let us consider a simple strategy: upon the arrival of an online vertex, assign it to an offline vertex with probability proportional to how likely the prophet would match them. We remark that the assignment is independent of the arrival of earlier vertices and their matching results. Then, from each offline vertex’s viewpoint, it may treat the online vertices (more precisely, the corresponding edges) as online items in the prophet secretary problem, treating those not assigned to it as having zero values. However, the online stochastic matching literature suggests that we should not naïvely follow this approach and apply the two-stage step-function activation rates from prophet secretary, or we would miss the opportunity of exploiting second-chance (re-)assignments (a.k.a. the power of two choices). If an offline vertex is already matched, we should no longer assign online vertices to it, but instead redirect the opportunities to other unmatched offline vertices. Hence, we introduce a third stage into the activation-based algorithm, which has the same activation rates as the second stage, but takes into account the assignments redirected from the other offline vertices. This may be viewed as reinterpreting the three-stage algorithm by Yan [40] for the i.i.d. special case within the activation-based framework. By doing so, we achieve the same 0.6450.6450.6450.645 competitive ratio but more generally for all non-i.i.d. instances in which all edges are small, i.e., when each edge contributes only o⁢(1)𝑜1o(1)italic_o ( 1 ) to the prophet benchmark. On the other hand, the worst-case competitive ratio of this approach degenerates to 1−1/e11𝑒1-1/e1 - 1 / italic_e if there is a large edge adjacent to every offline vertex. To complement this scenario, we introduce a variant of the random order contention resolution scheme (RCRS) algorithm for matching [33, 21]. This may be viewed under the activation-based framework as follows. For each offline vertex u𝑢uitalic_u and its largest edge (u,v)𝑢𝑣(u,v)( italic_u , italic_v ), let its adjacent edges other than (u,v)𝑢𝑣(u,v)( italic_u , italic_v ) have constant activation rates; let edge (u,v)𝑢𝑣(u,v)( italic_u , italic_v )’s activation probability be a 00-1111 step-function. This is consistent with our approach for the prophet secretary problem, but the design of activation rates and probabilities is simpler due to the complications in the analysis of the more general matching problem, and the fact that we only need to beat the 1−1e11𝑒1-\frac{1}{e}1 - divide start_ARG 1 end_ARG start_ARG italic_e end_ARG barrier in this case. We show that a hybrid algorithm that randomizes over the above two approaches achieves the stated 0.6410.6410.6410.641 competitive ratio. 1.2 Related Works Dütting et al. [14] studied the computational complexity of the optimal online algorithm for prophet secretary and gave a PTAS, though it does not imply any competitive ratio of the optimal online algorithm. Abolhassani et al. [1] and Liu et al. [34] studied the prophet secretary problem under small-item assumptions. They proved that if either 1) every distribution appears sufficiently many times [1, 34] or 2) every distribution has only a negligible probability of being non-zero [34], there exists a 0.7450.7450.7450.745-competitive algorithm, matching the optimal competitive ratio as in the i.i.d. setting. The order-selection prophet inequality lies between the i.i.d. setting and the secretary setting. In this variant, the algorithm is given the extra power of selecting the arrival order of the items. This is motivated by the application of prophet inequalities to sequential posted pricing mechanisms, and has been studied by [8, 5, 36, 7]. The current state-of-the-art competitive ratio is 0.7250.7250.7250.725 by Bubna and Chiplunkar [7]. Besides matching, the prophet inequality has also been generalized to other combinatorial settings, including matroids [30], combinatorial auctions [19, 13], and general downward-closed constraints [38]. Ehsani et al. [15] also studied the prophet secretary problem under matroid constraints and achieved a competitive ratio of 1−1/e11𝑒1-1/e1 - 1 / italic_e. Beating this ratio for general matroid constraints remains an important open question. Finally, the unweighted and vertex-weighted online stochastic matching problems have attracted a lot of attention in the online algorithms community [18, 4, 24, 35, 28, 6, 27, 39]. Most of these works assumed i.i.d. arrivals of online vertices, in order to surpass the optimal 1−1/e11𝑒1-1/e1 - 1 / italic_e competitive ratio of online (vertex-weighted) bipartite matching [29, 2]."
https://arxiv.org/html/2411.00388v1,Towards Data Valuation via Asymmetric Data Shapley,"As data emerges as a vital driver of technological and economic advancements, a key challenge is accurately quantifying its value in algorithmic decision-making. The Shapley value, a well-established concept from cooperative game theory, has been widely adopted to assess the contribution of individual data sources in supervised machine learning. However, its symmetry axiom assumes all players in the cooperative game are homogeneous, which overlooks the complex structures and dependencies present in real-world datasets. To address this limitation, we extend the traditional data Shapley framework to asymmetric data Shapley, making it flexible enough to incorporate inherent structures within the datasets for structure-aware data valuation. We also introduce an efficient k𝑘kitalic_k-nearest neighbor-based algorithm for its exact computation. We demonstrate the practical applicability of our framework across various machine learning tasks and data market contexts. The code is available at: https://github.com/xzheng01/Asymmetric-Data-Shapley.","Data valuation, which measures the contribution of individual data source on machine learning (ML) model performance, plays a crucial role in improving algorithmic transparency and creating incentive mechanisms for data sharing and monetization (Liu et al., 2023). Its importance is particularly evident in sectors like healthcare and finance, where explainable ML is increasingly being adopted for high-stake decision-making (Sahoh and Choksuriwong, 2023). The recent rise of data marketplaces further highlights the need for accurate data valuation (Ghorbani and Zou, 2019; Jia et al., 2019a). By integrating diverse data sources, these marketplaces enhance ML tasks and unlock significant business values (Agarwal et al., 2019). Fair compensation for data creators based on the value of their data is crucial in such contexts, making the equitable valuation of data a key issue (Altman, 2023). Data Shapley has recently gained widespread recognition for quantifying the contribution of individual data points to ML models (Ghorbani and Zou, 2019; Jia et al., 2019b). It is uniquely defined by four axioms (see Axiom 2.1-2.4 in Section 2). However, its symmetry axiom evaluates all data points equally, based solely on their content and influence on model performance, overlooking any inherent structures that exist in real-world datasets. This can lead to misleading and counterintuitive valuations in certain situations. We will further explore these counterintuitive outcomes in Section 3. To underscore the importance of incorporating the inherent structures within datasets into data valuation, we present the following examples. Example 1.1 (Valuation of Augmented Data). Data augmentation techniques expand the original training dataset to mitigate overfitting and improve performance (Shorten and Khoshgoftaar, 2019). However, since augmented data is generated from the original dataset through minor modifications, it often carries redundant information already present in the original dataset. Therefore, it is essential to assess the incremental value each augmented point contributes rather than focusing solely on its overall content. So how can we quantify the additional value each augmented data point brings to the original training set? Example 1.2 (Valuation of Sequential Data). Many modern ML applications involve data streams, where data instances arrive sequentially, one at a time (Yasumoto et al., 2016). The traditional data Shapley method treats all training data points as homogeneous players, disregarding the chronological dependencies between these points in a stream. So how can we incorporate the chronological order to quantify the incremental value of each newly arrived data point in a stream, given all previously arrived data? Example 1.3 (Fair Allocation among Dependent Entities in Data Marketplace). Traditional Shapley-based methods assume a simple market where multiple data creators fully own the training dataset (Jia et al., 2019a). However, these methods encounter challenges when data ownership is distributed across different, interdependent entities. For instance, consider a scenario where multiple data creators own the raw data, and a third-party data packager aggregates, refines the raw dataset, and sells the final model (see Figure 1). Data creators provide raw data, and the data packager adds value through processing. How, then, can we fairly allocate monetary value among the data creators and the data packager? Figure 1: Overview of the data market framework involving multiple data creators, a data packager, and a buyer. Addressing these questions necessitates incorporating inherent structures among data points into their valuation. We present the first study to use asymmetric Shapley value for data valuation in supervised machine learning. Our approach relaxes the symmetry axiom in the traditional data Shapley framework, thereby offering the flexibility to incorporate inherent structures within the sample space for structure-aware data valuation. Our contributions are summarized as follows: • We propose a novel data valuation framework called asymmetric data Shapley. Utilizing ordered partitions and weighted systems, this framework addresses the limitations of classical data Shapley by incorporating the inherent structures among data points into their valuation. • We provide a rigorous mathematical formulation for asymmetric data Shapley under general weight systems, including the intra-class uniform weight systems (ICU-WS) tailored for specific data valuation tasks. Theorems and propositions validate the class-wise efficiency of asymmetric data Shapley under ICU-WS, ensuring that the sum of data values in each social class reflects the incremental performance gain attributed to that class. • We develop two efficient algorithms—one based on a Monte Carlo approach and the other on a KNN surrogate method—for approximating and accurately computing asymmetric data Shapley. • We demonstrate the effectiveness of our approach in enhancing data valuation for tasks including augmented data valuation, sequential data valuation, and fair allocation in data marketplaces."
https://arxiv.org/html/2411.00181v1,Efficient Multi-Agent Delegated Search,"Consider a principal who wants to search through a space of stochastic solutions for one maximizing their utility. If the principal cannot conduct this search on their own, they may instead delegate this problem to an agent with distinct and potentially misaligned utilities. This is called delegated search, and the principal in such problems faces a mechanism design problem in which they must incentivize the agent to find and propose a solution maximizing the principal’s expected utility. Following prior work in this area, we consider mechanisms without payments and aim to achieve a multiplicative approximation of the principal’s utility when they solve the problem without delegation.In this work, we investigate a natural and recently studied generalization of this model to multiple agents and find nearly tight bounds on the principal’s approximation as the number of agents increases. As one might expect, this approximation approaches 1111 with increasing numbers of agents, but, somewhat surprisingly, we show that this is largely not due to direct competition among agents.","“If you want something done right, you have to do it yourself” may be little more than a catchy cliche, but it hints at an important idea in economic decision-making: when a principal delegates a task to untrusted agents, misaligned interests can lead to suboptimal outcomes. If this principal lacks the resources or ability to complete their own task, then they are faced with a mechanism design problem in which they want to select a delegation mechanism that optimizes their expected utility. In this paper, we aim to help the principal by finding multi-agent delegation mechanisms with competitive multiplicative approximations of what the principal could achieve on their own. Consider the following scenario that helps to illustrate and motivate our particular model and results. Take the perspective of a committee within a governmental body that funds scientific research through grants. You are tasked with allocating a fixed amount of resources for a single research project that benefits the nation’s long-term interests, and there are several research groups from which you can receive, evaluate, and approve proposals. You are confident in your ability to evaluate proposals, but recognize that each research group has its own interests that may be misaligned with the nation’s. You must try to design a grant proposal mechanism that motivates research groups to propose research projects that are most beneficial to the nation. More broadly, we consider models in which the principal faces a stochastic optimization problem where they have to find a solution maximizing the expected value of some objective function. The task of searching for solutions to this problem is then delegated to a fixed group of agents, who each have distinct utility functions. Agents propose solutions to the principal, and the principal picks a single winner who receives utility for their proposal. We focus on models of delegation in which the principal’s mechanism can not make outcome-contingent payments, representing situations in which players are confined to a fixed-price contract or are not legally allowed to make transfers of value for specific outcomes. Finally, in contrast to designing optimal mechanisms, we build on recent delegation research [15, 6, 7, 12] in which the principal aims for a multiplicative approximation of their first-best expected utility, i.e. their expected utility when the problem is not delegated (alternatively, their utility when they delegate to agents with identical interests). This approximation factor, which can be called the delegation gap, tells the principal what fraction of their optimal utility they are guaranteed while delegating to arbitrary untrusted agents. 1.1 Overview of Our Models The delegation model of primary interest in this paper is strategic multi-agent delegation (Section 2) as originally defined by Hajiaghayi et al. [12]. This consists of a principal who wants to find a solution maximizing their utility over a stochastic solution space, and they must delegate the search process to k𝑘kitalic_k agents. Each agent is given a finite number of elements from which they can sample an outcome representing a solution along with the principal’s and agent’s utilities. The number of agents, number of elements per agent, and the distributions of outcomes are specified as part of the instance and common knowledge to all players. In this game, the principal starts by committing to some mechanism through which agents can communicate with the principal. Each agent then samples outcomes from their elements and sends a signal to the principal. The principal transforms these signals into an outcome which is conditionally accepted as the winner. If this outcome was not sampled by any agent, then the principal detects this “lie” and rejects it, so all players get no utility. Otherwise, the principal and winning agent each get the utility specified by that outcome, and all other agents get nothing. One challenge posed by this model is the complexity of analyzing agents’ equilibrium strategies, how these equilibria are affected by the choice of mechanism, and how they affect the principal’s utility. We also study a simplified model in which agents are assumed to act adversarially against the principal. More specifically, adversarial multi-agent delegation (Section 2) is the same as the strategic model above, except that we do not define agents’ utilities and all agents instead aim to minimize the principal’s expected utility subject to maintaining a positive probability of winning. We will see that in the absence of symmetry conditions on the agents, it is difficult to make any nontrivial approximation guarantees in either model. One attempt to get around this involves the (strategic or adversarial) shuffled multi-agent delegation model (Section 2), in which elements are randomly distributed among agents. Specifically, there is a known pool of elements, each of which is given to a uniformly random agent, and the game proceeds from there as usual. Note that the principal does not learn which agent received which elements, and their expected utility is measured with respect to the random allocation of elements to agents. A perhaps more straightforward way of enforcing symmetry is the (strategic or adversarial) agent-symmetric multi-agent delegation model, in which all agents are given access to equivalent sets of elements. For these models, we consider three natural classes of mechanisms. First are single-proposal mechanisms (Section 2.1), originally defined for this multi-agent context in [12], in which the principal announces restricted sets of outcomes that they would accept, each agent proposes a single outcome to the principal, and the principal picks a winner from among them. This is perhaps one of the most natural classes of mechanisms, and can be seen implemented, for example, in the form of research grants. Specifically, an agency sets out criteria of proposals that they would be willing to accept and then receives a single proposal from each research group. Importantly, it is known that single-proposal mechanisms perform at least as well as any other kind of mechanism (Section 2.1). As a special case of single-proposal mechanisms, we consider threshold mechanisms (Section 2.1), in which the principal’s acceptable sets of outcomes are defined by thresholds on their utility. Focusing on this restricted class is beneficial for vastly simplifying the complexity of describing an individual mechanism, reducing the space of mechanisms to something more manageable, and being more intuitive to a potential implementor. Although we spend little time on it, we also define a class of direct-revelation mechanisms called Myerson-type mechanisms (Section 2.1) that may be of interest for future work to expand on. As the name implies, this class is inspired by Myerson mechanisms from auction theory. In it, the principal declares a virtual value function for each element that maps the principal’s true utility to a virtual value. The agent with an element of largest virtual value is declared the winner, and their favorite outcome that still has greater virtual value than all other agents is accepted by the principal. We show that these mechanisms are dominant-strategy incentive compatible (Section 2.1), and speculate whether they are optimal in an instance-by-instance sense, much like Myerson’s revenue-optimal auction. 1.2 Overview of Our Results As mentioned before, our work focuses on understanding the delegation gap, which is defined as the minimum over all instances of the ratio between the principal’s optimal delegated expected utility and their optimal non-delegated expected utility. For the models we study in this paper, agents have no constraints on “probing” elements to learn their values, so the principal’s optimal non-delegated utility is simply the maximum utility among all outcomes. We start by showing that bounds on the delegation gap in the strategic case can be reduced to identical bounds in the adversarial case. This comes in two parts: the simple observation that delegating to strategic agents is at least as easy as delegating to adversarial agents (Section 3), and, less obviously, that for every adversarial instance within a central class, there is an analogous strategic instance with identical behavior from the principal’s perspective (Section 3). This may be somewhat surprising, since it implies that any increase in utility from delegating to multiple agents is not, in general, attributable to strategic competition between those agents. Rather, the principal’s utility seems to increase simply as a consequence of the larger pool of acceptable options afforded by a larger pool of agents. Turning our focus toward adversarial delegation, we find a harsh 1/2121/21 / 2-approximation upper bound for any number of agents that carries over from the related single-agent model. This is due to the fact that the general form of the model allows for one agent to hold all elements that contribute non-zero expected utility to the principal, so, in essence, the principal must delegate to just that one agent. However, moving beyond this impossibility, we show that when all agents have identical sets of elements, it is possible to achieve a competitive delegation gap of 1−𝒪⁡(ln⁡kk)1𝒪𝑘𝑘1-\operatorname{\mathcal{O}}\left(\frac{\ln k}{k}\right)1 - caligraphic_O ( divide start_ARG roman_ln italic_k end_ARG start_ARG italic_k end_ARG ). This is done in two parts: first achieving this approximation for instances with only atomless distributions (Section 4), and then showing how to modify the strategy to deal with atoms (Section 4). Notably, this approximation uses only a threshold mechanism, so it is simple to describe. In the interest of demonstrating that other forms of symmetry also give competitive approximations, we show that the delegation gap of shuffled multi-agent delegation has the same 1−𝒪⁡(ln⁡kk)1𝒪𝑘𝑘1-\operatorname{\mathcal{O}}\left(\frac{\ln k}{k}\right)1 - caligraphic_O ( divide start_ARG roman_ln italic_k end_ARG start_ARG italic_k end_ARG ) lower-bound (Section 4 and Section 4). Noting that a different symmetry assumption gives the same result, we conjecture that this is an instance of a more general phenomenon. Finally, we show that the optimal delegation gap achievable with k𝑘kitalic_k agents in the agent-symmetric case is upper bounded by 1−Ω⁢(1k)1Ω1𝑘1-\Omega\left(\frac{1}{k}\right)1 - roman_Ω ( divide start_ARG 1 end_ARG start_ARG italic_k end_ARG ) (Section 4). We leave open for future work whether the gap between these upper and lower bounds can be closed. 1.3 Related Work There is a relatively long history of delegation research in computer science and economics, notably starting over four decades ago with the work of Holmstrom [14, 13]. We refer readers to [15, 6, 12] for a more detailed account of the followup work in delegation. A select sample includes the notable work of Alonso and Matouschek [4], Armstrong and Vickers [5], Alonso et al. [3], and the recent work of Gan et al. [11]. The last two study multi-agent delegation with two agents and no transfers, but they use different models and aim to find optimal mechanisms. The past few years have seen a small resurgence in this area, initiated by the work of Kleinberg and Kleinberg [16]. They study two models of delegation without payments, aiming for the same multiplicative approximation of the principal’s optimal outcome, and show that the two problems can be reduced to known prophet inequalities and Pandora’s box problems. This work was later expanded on by that of Bechtel and Dughmi [6], who study a delegated model of stochastic probing with combinatorial constraints on the principal and agent, and Bechtel et al. [7], who explore different variants of the delegation of Pandora’s box problems. This line of work has shown that delegation has close connections to prophet inequalities [18, 19, 17, 10, 9, 20] and contention resolution schemes [8, 10, 2], among other related problems. Most similar to our work is that of Hajiaghayi et al. [12], who proposed (among other things) our main model of multi-agent delegation as a natural direction to build off of the existing work on delegation. Specifically, our strategic model is equivalent to their Bayesian mechanism multi-agent delegation with incomplete information. They show that when all agents have the same number of i.i.d. elements, the principal can achieve approximations tending to 1111 as α⁢k⁢m𝛼𝑘𝑚\alpha kmitalic_α italic_k italic_m increases, where k𝑘kitalic_k is the number of agents, m𝑚mitalic_m is the number of elements per agent, and α𝛼\alphaitalic_α is a parameter of the distributions. In contrast, we achieve an approximation tending to 1111 as k𝑘kitalic_k increases when agents have symmetric sets of elements (not necessarily i.i.d.), with no conditions on the distributions or number of elements per agent. They also explore and achieve competitive approximations for different settings with varying levels of power for the principal and agents."
https://arxiv.org/html/2411.00133v1,Constrained Fair and Efficient Allocations,"Fairness and efficiency have become the pillars of modern fair division research, but prior work on achieving both simultaneously is largely limited to the unconstrained setting. We study fair and efficient allocations of indivisible goods under additive valuations and various types of allocation feasibility constraints, and demonstrate the unreasonable effectiveness of the maximum Nash welfare (MNW) solution in this previously uncharted territory.Our main result is that MNW allocations are 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-envy-free up to one good (EF1) and Pareto optimal under the broad family of (arbitrary) matroid constraints. We extend these guarantees to complete MNW allocations for base-orderable matroid constraints, and to a family of non-matroidal constraints (which includes balancedness) using a novel “alternate worlds” technique. We establish tightness of our results by providing counterexamples for the satisfiability of certain stronger desiderata, but show an improved result for the special case of goods with copies [Gafni et al., 2023]. Finally, we also establish novel best-of-both-worlds guarantees for goods with copies and balancedness.","Fair division of resources among agents is a primitive that has applications, both to multiagent systems [Chevaleyre et al., 2006] and to everyday problems such as estate division and divorce settlement [Shah, 2017]. Over the last decade, the fair division literature has undergone a dramatic transformation. The pioneering work of Caragiannis et al. [2019] established that, under additive valuations, the so-called maximum Nash welfare (MNW) allocations, which (informally) maximize the product of agent utilities, simultaneously satisfy two appealing guarantees: a fairness criterion known as envy-freeness up to one good (EF1), which demands that no agent prefer the allocation of another agent (modulo a single good) to her own, and an efficiency criterion known as Pareto optimality (PO), which demands that no alternative allocation be able to make an agent happier without making any agent worse off. These provable fairness and efficiency guarantees have been critical to their use in the real world via the not-for-profit website Spliddit.org [Shah, 2017]. Ever since then, the combination of fairness and efficiency, in the form of approximate envy-freeness and Pareto optimality, has become the guiding principle for seeking fair division solutions, e.g., for subclasses of additive valuations [Hosseini et al., 2021], for non-additive valuations [Benabbou et al., 2021, Barman and Suzuki, 2024], when addressing manipulations [Psomas and Verma, 2022], or for allocating chores [Ebadian et al., 2022, Garg et al., 2022], or for allocating public goods [Fain et al., 2018, Ebadian et al., 2024]. However, in many real-world fair division problems, there are feasibility constraints on the bundle that each agent can receive. Examples include course allocation [Budish et al., 2017], public housing assignment [Benabbou et al., 2020], or allocation of conference submissions to reviewers [Garg et al., 2010]. Unfortunately, the literature on constrained fair division has been largely limited to seeking only fairness guarantees. • Biswas and Barman [2018] show the existence of an EF1 allocation subject to cardinality constraints, where the goods are partitioned into categories and each agent must be allocated at most a prescribed maximum number of goods from each category. • Biswas and Barman [2019] extend this to any base-orderable matroid constraint, where the bundle of goods allocated to each agent must be an independent set of a given base-orderable matroid (cardinality constraints form a partition matroid, which is a special case), when agents have identical additive valuations.111Biswas and Barman [2019] incorrectly state their result for an arbitrary matroid constraint in the original paper, but later versions correctly state that the result holds for base-orderable matroids. The existence of an EF1 allocation here remains open for general matroid constraints, even for identical additive valuations. • Gafni et al. [2023] study a special case of cardinality constraints, which they refer to as goods with copies, motivated by the fact that it in turn subsumes chore division as a special case. They define an appealing strengthening of EF1, termed EF1WC, and establish its existence for restricted valuation classes. • The popular round robin algorithm yields an EF1 allocation subject to balancedness, where all agents must be assigned bundles of roughly equal cardinality (differing by at most one) [Caragiannis et al., 2019]. • A famous non-matroidal constraint is where the goods are vertices of an undirected graph, and the bundle allocated to each agent must form a connected subset; when the graph is a line, an EF1 allocation is known to exist [Igarashi, 2023], and for general graphs, a 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 allocation with up to n−1𝑛1n-1italic_n - 1 unallocated goods is known to exist under restricted preferences [Caragiannis et al., 2022]. In addition to the above summary of related work, we provide comparisons to other pieces of related work throughout the paper, and also refer the reader to the extensive survey on constraints in fair division by Suksompong [2021]. Quite surprisingly, the existence of an allocation that satisfies both (even approximate) EF1 and PO remains severely understudied in these constrained domains. The only exception is the work on budget constraints, where each good has a size and the total size of goods allocated to any agent must be at most a threshold. Gan et al. [2023] show that an EF1 allocation always exists, and Wu et al. [2021] show that any MNW allocation subject to such a constraint is 1/414\nicefrac{{1}}{{4}}/ start_ARG 1 end_ARG start_ARG 4 end_ARG-EF1 and PO. Our main research question is to expand on this line of work: Under which types of feasibility constraints do (approximately) fair and efficient allocations exist? 1.1 Our Results Our main result is that every MNW allocation is 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO under the broad class of (arbitrary) matroid constraints (see Section 2 for a formal definition). While these allocations are efficient, they can be incomplete, i.e., leave some goods unallocated, which may be undesirable in settings such as allocation of shifts to nurses and assignment of conference submissions to reviewers. To that end, we show that for base-orderable matroid constraints, even allocations that are MNW among the set of complete and feasible allocations are 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO. Base-orderable matroids subsume the case of cardinality constraints [Biswas and Barman, 2018]. Then, using a novel technique of constructing “alternate worlds”, we show that the 1/212\nicefrac{{1}}{{2}}/ start_ARG 1 end_ARG start_ARG 2 end_ARG-EF1 and PO guarantees can be extended to MNW allocations subject to a broad class of non-matroidal constraints, which includes balancedness as a special case. We also show that certain strengthenings of EF1 and PO are unachievable in the realm of constrained allocations, but show an improvement from EF1 to EF1WC for the case of goods with copies [Gafni et al., 2023]. Finally, we expand the recent work on “best of both worlds” (BoBW) guarantees [Aziz et al., 2024] to the realm of constrained allocations. Building on the work of Echenique et al. [2021], we prove that randomized allocations that are ex ante EF and PO along with ex post EF11subscriptsuperscriptabsent11{}^{1}_{1}start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT, Prop1, and PO exist for the case of goods with copies, and the same result except for the EF11subscriptsuperscriptabsent11{}^{1}_{1}start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT guarantee holds when adding the balancedness constraint. For formal definitions, see Section 4."
https://arxiv.org/html/2411.00707v1,"Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms","We study learning in a dynamically evolving environment modeled as a Markov game between a learner and a strategic opponent that can adapt to the learner’s strategies. While most existing works in Markov games focus on external regret as the learning objective, external regret becomes inadequate when the adversaries are adaptive. In this work, we focus on policy regret – a counterfactual notion that aims to compete with the return that would have been attained if the learner had followed the best fixed sequence of policy, in hindsight. We show that if the opponent has unbounded memory or if it is non-stationary, then sample-efficient learning is not possible. For memory-bounded and stationary, we show that learning is still statistically hard if the set of feasible strategies for the learner is exponentially large. To guarantee learnability, we introduce a new notion of consistent adaptive adversaries, wherein, the adversary responds similarly to similar strategies of the learner. We provide algorithms that achieve T𝑇\sqrt{T}square-root start_ARG italic_T end_ARG policy regret against memory-bounded, stationary, and consistent adversaries.","Recent years have witnessed tremendous advances in reinforcement learning for various challenging domains in AI, from the game of Go (Silver et al., 2016, 2017, 2018), real-time strategy games such as StarCraft II (Vinyals et al., 2019) and Dota (Berner et al., 2019), autonomous driving (Shalev-Shwartz et al., 2016), to socially complex games such as hide-and-seek (Baker et al., 2019), capture-the-flag (Jaderberg et al., 2019), and highly tactical games such as poker game Texas hold’ em (Moravčík et al., 2017; Brown and Sandholm, 2018). Notably, most challenging RL applications can be systematically framed as multi-agent reinforcement learning (MARL) wherein multiple strategic agents learn to act in a shared environment (Yang and Wang, 2020; Zhang et al., 2021). Despite the empirical successes, the theoretical foundations of MARL are underdeveloped, especially in settings where the learner faces adaptive opponents who can strategically adapt and react to the learner’s policies. Consider for example the optimal taxation problem in the AI economist (Zheng et al., 2020), a game that simulates dynamic economies that involve multiple actors (e.g., the government and its citizens) who strategically contribute to the game dynamics. The government agent learns to set a tax rate that optimizes for the economic equality and productivity of its citizens, whereas the citizens who perhaps have their own interests, respond adaptively to tax policies of the government agent (e.g., relocating to states that offer generous tax rates). Such adaptive behavior of participating agents is a crucial component in other applications as well, e.g., mechanism design (Conitzer and Sandholm, 2002; Balcan et al., 2005), optimal auctions (Cole and Roughgarden, 2014; Dütting et al., 2019). The question of learning against adaptive opponents has been mostly studied under the framework of external regret, wherein the agent is required to compete with the best fixed policy in hindsight (Liu et al., 2022). However, external regret is not adequate to study adaptive opponents as it does not take into account the counterfactual response of the opponents. This motivates us to study MARL using the framework of policy regret (Arora et al., 2012), a counterfactual notion that aims to compete with the return that would have been attained if the agent had followed the best fixed sequence of policy in hindsight. Even though policy regret is now a standard notion to study adaptive adversaries and has been extensively studied in online (bandit) learning (Merhav et al., 2002; Arora et al., 2012; Malik et al., 2022) and repeated games (Arora et al., 2018), it has not received much attention in a multiagent reinforcement learning setting. In this paper, we aim to fill in this gap. We consider two-player Markov games (MGs) (Shapley, 1953; Littman, 1994) as a model for MARL, wherein one agent (the learner) learns to act against an adaptive opponent. We provide a series of negative and positive results for policy regret minimization in Markov games, highlighting the fundamental limits of learning and showcasing key principles underpinning the design of efficient learning algorithms against adaptive adversaries. Fundamental barriers. We first show that any learner must incur a linear policy regret against an adaptive opponent who can adapt and remember the learner’s past policies (Theorem 1). When the opponent has a bounded memory span, any learner must require an exponential number of samples Ω⁢((S⁢A)H/ϵ2)Ωsuperscript𝑆𝐴𝐻superscriptitalic-ϵ2\Omega((SA)^{H}/{\epsilon}^{2})roman_Ω ( ( italic_S italic_A ) start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT / italic_ϵ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) to obtain an ϵitalic-ϵ{\epsilon}italic_ϵ-suboptimal policy regret, even with the weakest form of memory wherein the opponent is oblivious (Theorem 2). When the memory-bounded opponent’s response is stationary, i.e., the response function does not vary with episodes, learning is still statistically hard when the learner’s policy set is exponentially large, as in this case the policy regret necessarily scales polynomially with the cardinality of the learner’s policy set (Theorem 3). Efficient algorithms. Motivated by these statistical hardness results, we consider a structural condition on the response of the opponents, which we refer to as consistent behavior, wherein the opponent responds similarly to similar sequences of policies (5). We propose two algorithms OPO-OMLE (Algorithm 1) and APE-OVE (Algorithm 3) that obtain T𝑇\sqrt{T}square-root start_ARG italic_T end_ARG policy regret against m𝑚mitalic_m-memory bounded, stationary, and consistent adversaries, for m=1𝑚1m=1italic_m = 1 and m≥1𝑚1m\geq 1italic_m ≥ 1, respectively. • For memory length m=1𝑚1m=1italic_m = 1: We show that OPO-OMLE obtains a policy regret upper bound of 𝒪~⁢(H3⁢S2⁢A⁢B+H5⁢S⁢A2⁢B⁢T)~𝒪superscript𝐻3superscript𝑆2𝐴𝐵superscript𝐻5𝑆superscript𝐴2𝐵𝑇\tilde{{\mathcal{O}}}(H^{3}S^{2}AB+\sqrt{H^{5}SA^{2}BT})over~ start_ARG caligraphic_O end_ARG ( italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT italic_S italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_B italic_T end_ARG ), when the learner’s policy set is the set of all deterministic Markov policies, where H𝐻Hitalic_H is the episode length, S𝑆Sitalic_S is the number of states, A𝐴Aitalic_A and B𝐵Bitalic_B are the numbers of actions for the learner and the opponent, respectively, and T𝑇Titalic_T is the number of episodes. • For general memory length m≥1𝑚1m\geq 1italic_m ≥ 1: We show that APE-OVE obtains a policy regret upper bound of 𝒪~⁢((m−1)⁢H2⁢S⁢A⁢B+H3⁢S⁢A⁢B⁢(S⁢A⁢B⁢(H+S)+H2)⁢Td∗)~𝒪𝑚1superscript𝐻2𝑆𝐴𝐵superscript𝐻3𝑆𝐴𝐵𝑆𝐴𝐵𝐻𝑆superscript𝐻2𝑇superscript𝑑\tilde{{\mathcal{O}}}\left((m-1)H^{2}SAB+\sqrt{H^{3}SAB}(SAB(H+\sqrt{S})+H^{2}% )\sqrt{\frac{T}{d^{*}}}\right)over~ start_ARG caligraphic_O end_ARG ( ( italic_m - 1 ) italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_S italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S italic_A italic_B end_ARG ( italic_S italic_A italic_B ( italic_H + square-root start_ARG italic_S end_ARG ) + italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) square-root start_ARG divide start_ARG italic_T end_ARG start_ARG italic_d start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT end_ARG end_ARG ), where d∗superscript𝑑d^{*}italic_d start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT is an instance-dependent quantity that features the minimum positive visitation probability. We provide a summary of our main results in Table 1. Opponent’s Adaptive Behavior Policy Regret Unbounded memory Ω⁢(T)Ω𝑇\Omega(T)roman_Ω ( italic_T ) m𝑚mitalic_m-memory bounded (m≥0𝑚0m\geq 0italic_m ≥ 0) Ω⁢(T⁢(S⁢A)H)Ω𝑇superscript𝑆𝐴𝐻\Omega(\sqrt{T(SA)^{H}})roman_Ω ( square-root start_ARG italic_T ( italic_S italic_A ) start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT end_ARG ) m𝑚mitalic_m-memory bounded + stationary (m≥1𝑚1m\geq 1italic_m ≥ 1) Ω⁢(min⁡{T,AH⁢S})Ω𝑇superscript𝐴𝐻𝑆\Omega(\min\{T,A^{HS}\})roman_Ω ( roman_min { italic_T , italic_A start_POSTSUPERSCRIPT italic_H italic_S end_POSTSUPERSCRIPT } ) 1111-memory bounded + stationary + consistent 𝒪~⁢(H3⁢S2⁢A⁢B+H5⁢S⁢A2⁢B⁢T)~𝒪superscript𝐻3superscript𝑆2𝐴𝐵superscript𝐻5𝑆superscript𝐴2𝐵𝑇\tilde{{\mathcal{O}}}(H^{3}S^{2}AB+\sqrt{H^{5}SA^{2}BT})over~ start_ARG caligraphic_O end_ARG ( italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 5 end_POSTSUPERSCRIPT italic_S italic_A start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_B italic_T end_ARG ) m𝑚mitalic_m-memory bounded + stationary + consistent 𝒪~⁢((m−1)⁢H2⁢S⁢A⁢B+H3⁢S⁢A⁢B⁢(S⁢A⁢B⁢(H+S)+H2)⁢Td∗)~𝒪𝑚1superscript𝐻2𝑆𝐴𝐵superscript𝐻3𝑆𝐴𝐵𝑆𝐴𝐵𝐻𝑆superscript𝐻2𝑇superscript𝑑\tilde{{\mathcal{O}}}\left((m-1)H^{2}SAB+\sqrt{H^{3}SAB}(SAB(H+\sqrt{S})+H^{2}% )\sqrt{\frac{T}{d^{*}}}\right)over~ start_ARG caligraphic_O end_ARG ( ( italic_m - 1 ) italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_S italic_A italic_B + square-root start_ARG italic_H start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT italic_S italic_A italic_B end_ARG ( italic_S italic_A italic_B ( italic_H + square-root start_ARG italic_S end_ARG ) + italic_H start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ) square-root start_ARG divide start_ARG italic_T end_ARG start_ARG italic_d start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT end_ARG end_ARG ) Table 1: Summary of main results for learning against adaptive adversaries. Learner’s policy set is all deterministic Markov policies. m=0𝑚0m=0italic_m = 0 + stationary corresponds to standard single-agent MDPs."
https://arxiv.org/html/2411.00564v1,"A decomposition from a substitutable many-to-one matching market to a one-to-one matching market††thanks:We acknowledge the financial support of UNSL through grants 03-2016 and 03-1323, and from Consejo Nacional
de Investigaciones Científicas y Técnicas (CONICET) through grant
PIP 112-200801-00655, and from Agencia Nacional de Promoción Científica y Tecnológica through grant PICT 2017-2355.","For a many-to-one market with substitutable preferences on the firm’s side, based on the Aizerman-Malishevski decomposition, we define an associated one-to-one market. Given that the usual notion of stability for a one-to-one market does not fit well for this associated one-to-one market, we introduce a new notion of stability. This notion allows us to establish an isomorphism between the set of stable matchings in the many-to-one market and the matchings in the associated one-to-one market that meet this new stability criterion. Furthermore, we present an adaptation of the well-known deferred acceptance algorithm to compute a matching that satisfies this new notion of stability for the associated one-to-one market.JEL classification: C78, D47.Keywords: Many-to-one matchings, Aizermann-Malishevski decomposition, one-to-one matchings, deferred acceptance algorithm, stable set","Many-to-one markets have been extensively studied in the literature, starting with the college admissions problem and extending to the assignment of medical interns to hospitals, as well as applications in labor markets. A fundamental characteristic of these markets is that institutions, which we will refer to as firms, hold preferences over subsets of agents, whom we will refer to as workers. In this paper, we introduce a decomposition of a many-to-one market in which firms have substitutable preferences over subsets of workers, transforming it into an associated one-to-one market. We construct this decomposition based on the Aizerman-Malishevski decomposition of substitutable preferences (see Aizerman and Malishevski, 1981). Crawford and Kelso (1982) introduced the notion of substitutability in preferences, which is the weakest condition needed to guarantee the existence of stable matchings. A firm is said to have substitutable preferences if it continues to desire a worker even when other workers become unavailable. The Aizerman-Malishevski decomposition is well known in the choice literature (e.g., Moulin, 1985) and states that any path-independent choice rule can be represented as the union of choices derived from preference relations over individuals. Chambers and Yenmez (2017) apply the Aizerman-Malishevski decomposition to study path-independent choice rules in a matching context. They use this decomposition to develop a deferred acceptance algorithm for many-to-many matching markets with contracts and to analyze its properties. The Aizerman-Malishevski decomposition models a firm as the union of several “copies” of itself, facilitating the representation of firms’ preferences in substitutable cases. A key feature of this decomposition is its capacity to transform a substitutable preference over a subset of workers into multiple, distinct linear preferences over workers. The fact that copies of the same firm have different linear preferences leads to a situation where the usual notion of stability for one-to-one markets does not apply adequately.111Recall that, in traditional one-to-one matching markets, stability requires individual rationality and the absence of blocking pairs. A matching is individually rational if each agent is assigned to an “acceptable” partner. A matching contains a blocking pair if both agents within that pair mutually prefer each other over their current partners in the matching. In Section 2, we present Example 1, which illustrates a many-to-one market where firms have substitutable preferences, along with its corresponding Aizerman-Malishevski decomposition. In this example, we observe that in the many-to-one market, there are four stable matchings, while in the associated one-to-one market, there is only one stable matching under the usual notion of stability. This discrepancy implies that no relation (e.g., no isomorphism) can be established between the stable matchings in the many-to-one market and those in the associated one-to-one market. For this reason, we adapt the notion of stability and introduce stability* for one-to-one matchings. This new notion resembles the classical notion of stability (i.e., it is individually rational and free of blocking pairs) but is adapted to capture the substitutable preferences inherent in the original market. Building on this new notion, we can establish an isomorphism between the set of stable matchings in the substitutable many-to-one market and the set of stable* matchings in the associated one-to-one market. To highlight the difference between the usual notion and stability*, we introduce two additional conditions not typically required in one-to-one settings. First, for individual rationality* in this associated market, we impose an envy-free condition among firm-copies: no firm-copy matched to a worker should prefer another worker matched to a different copy of the same firm. Second, in the presence of blocking pairs, we require that the worker in the blocking pair is preferred by the relevant firm-copy over all workers matched to other copies of that same firm. A common approach to prove the non-emptiness of a stable set is constructive. In the seminal paper by Gale and Shapley (1962), an algorithm is presented —the well-known deferred acceptance algorithm— which constructs a stable matching for traditional one-to-one markets. Although our isomorphism demonstrates that the set of stable* one-to-one matchings is non-empty, we adapt the deferred acceptance algorithm to the related one-to-one market, taking into account the specific characteristics of stability*. Although one-to-one markets are traditionally symmetric, our related one-to-one market is not. This is because it originates from the decomposition of a many-to-one substitutable market. Thus, we present two adapted versions of the deferred acceptance algorithm: one where firm-copies propose and another where workers propose. We show that, whether the firm-copies or the workers are the proposers, the algorithm returns a stable* matching. In this way, independently of the isomorphism, we establish that the set of stable* matchings for the related one-to-one market is non-empty. The idea of decomposing a many-to-one market into a one-to-one market has been previously studied under a more restrictive preference structure. When firms’ preferences are assumed to be responsive to an individual ranking of workers—a more restrictive structure than substitutable preferences—Roth and Sotomayor (1990) demonstrate that each firm can be decomposed into identical units (or copies) according to its capacity (quotas q𝑞qitalic_q). A key distinction in this decomposition is that each of these copies shares the same individual preferences over workers (derived from responsive preferences), and workers rank all copies of a given firm above those of any other firm, preserving the same order of preferences across all copies. This decomposition transforms a many-to-one market with responsive preferences into a corresponding one-to-one market. Furthermore, Roth and Sotomayor (1990) establish an isomorphism between the stable matchings of a many-to-one market and those of an associated one-to-one market. The paper is organized as follows. In Section 2, we present the many-to-one market, the Aizerman-Malishevski decomposition, and the associated one-to-one market. For this associated one-to-one market, in Section 3, we present an adapted deferred acceptance algorithm and an isomorphism with the many-to-one market. Finally, in Section 4 some final remarks are presented."
https://arxiv.org/html/2411.00217v1,"ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing††thanks:2Authors contributed equally, 1Corresponding author,Authors belong to Department of Electrical and Computer EngineeringNew York University, New York 11201, USA{hl4155, yg2047, qz494}@nyu.edu","The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.","Modern artificial intelligence (AI), such as machine learning (ML) technologies, are becoming increasingly integrated into many infrastructures, including smart transportation systems and healthcare infrastructures. In healthcare, they have shown the potential to help healthcare infrastructure in patient scheduling [1, 2], pathological analysis [3], and care management [4]. While there are significant benefits, there are concerns regarding zero-day vulnerabilities and the expanded attack surface. Penetration testing is a valuable ethical hacking method for uncovering vulnerabilities in increasingly complex infrastructures and devising remediation strategies. As these infrastructures become more complex, with millions of interconnected devices, scalability emerges as a critical challenge. It is essential to develop a distributed, modular, and automated approach that addresses device-level testing needs while considering global influences through interconnectivity. Another challenge stems from the dynamic nature of networked devices and their vulnerabilities. There is a growing need for adaptive and automated approaches to continuously update the vulnerability landscape, ensuring that threats are exhaustively identified, risks accurately assessed, and remediation measures properly applied. The third challenge arises from the integration of AI capabilities into the infrastructure. The emergence of adversarial AI/ML introduces new and evolving threat vectors, which are designed to evade detection and testing. There is a need for the development of automated and strategic approaches that can intelligently outmaneuver their evolving nature through continuous knowledge acquisition and learning. To this end, we establish a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing (ADAPT). Figure 1: The framework of the ADAPT: The upper half illustrates an online automated adaptation of penetration testing. It integrates game-theoretic and neuro-symbolic frameworks, consisting of five distinct building blocks (to be introduced in Section III). The lower half depicts an example of AI-enabled healthcare infrastructure. This AI-enabled infrastructure presents an expanded attack surface due to interconnectivity and zero-day vulnerabilities. To address the challenges in penetration testing within AI-enabled healthcare infrastructure networks, ADAPT consolidates the game-theoretic framework and the neuro-symbolic framework, shown in the Figure 1. The game-theoretic and neuro-symbolic framework consists of five building blocks. The macro-game and micro-game blocks serve as representations of the given system. Game-theoretic strategies are updated based on the selected attack models through neural learning in the online learning blocks. Different attack models are represented using game trees, which encode relevant attack and defense actions selected from the knowledge. This knowledge contains vulnerabilities of the health infrastructure that are shared among multiple stakeholders in the medical system. When new paths or vulnerabilities are discovered through exploration (e.g., automated fuzzing techniques [5]) and penetration testing, the knowledge base is generated and updated accordingly. ADAPT helps medical systems evaluate their AI-enabled network for scalability, the impact of reachability, and the exhaustiveness of risk identification, and protects the confidentiality, integrity, and availability of the AI model. The purpose of it is to ensure preparedness against continuously evolving malicious threats such as ransomware and zero-day attacks on healthcare infrastructures."
https://arxiv.org/html/2411.00025v1,Probabilistic Obstruction Temporal Logic:a Probabilistic Logic to Reason about Dynamic Models,"In this paper, we propose a novel formalism called Probabilistic Obstruction Temporal Logic (POTL), which extends Obstruction Logic (OL) by incorporating probabilistic elements. POTL provides a robust framework for reasoning about the probabilistic behaviors and strategic interactions between attackers and defenders in environments where probabilistic events influence outcomes. We explore the model checking complexity of POTL and demonstrate that it is not higher than that of Probabilistic Computation Tree Logic (PCTL), making it both expressive and computationally feasible for cybersecurity and privacy applications.","Understanding and quantifying uncertainty is essential in cybersecurity, and probability theory offers a robust framework for this purpose, making it particularly valuable for risk analysis. As digital systems grow increasingly complex and dynamic, effectively assessing and managing risks becomes more challenging. Probability theory allows organizations to model the likelihood of various cyber threats, such as hacking attempts, data breaches, and software vulnerabilities, which are inherently uncertain and variable. Cybersecurity professionals can estimate the likelihood of these threats materializing and assess their potential impact on systems by applying probabilistic and non-probabilistic formalisms. Researchers have developed various solutions over the past fifty years, with formal methods emerging as a notable success. These techniques allow for the verification of system correctness by checking if a mathematical model meets the formalized desired behavior. Notably, traditional formal approaches like model checking (Baier and Katoen 2008), initially designed for monolithic systems, have been effectively adapted to manage open and Multi-Agent Systems (MAS). In recent years, the study of MAS has garnered significant attention due to its wide-ranging applications in fields such as cybersecurity, robotics, and distributed computing. MAS consists of two or more interacting agents, each capable of making autonomous decisions. These systems often operate in dynamic and uncertain environments, necessitating robust formal verification techniques to ensure their reliability and correctness. An important logic in the context of MAS is Alternating-time Temporal Logic (ATL) (Alur, Henzinger, and Kupferman 2002). The latter extends CTL (Clarke and Emerson 1981) by introducing strategic modalities, enabling the specification of properties that involve the strategic abilities of agents. ATL can express whether a group of agents can achieve a certain goal regardless of the actions of other agents, making it a powerful tool for reasoning about cooperation and competition in MAS. Another relevant formalism in this area is Obstruction Logic (OL) (Catta, Leneutre, and Malvone 2023b), which focuses on obstructions in two-player games. In OL, one player, called the Demon, can temporarily disable edges in the graph as long as their total weight remains below a specified natural number, thereby preventing the other agent from achieving its temporal goal. As illustrated in their paper, OL can be well-suited for representing cybersecurity problems, where a defender can activate defense mechanisms (by disabling edges) and an attacker aims to access private resources through a sequence of atomic attacks. In this context, a key aspect when performing cybersecurity risk analysis is to assess the likelihood (or probability) of success of the attack scenarios. However, OL did not address this aspect, where no probabilistic concepts were introduced. For the above reasons, in this paper, we present Probabilistic Obstruction Temporal Logic (POTL), a logic that extends OL into a probabilistic context. POTL offers a comprehensive framework for analyzing the probabilistic behaviors and strategic interactions between attackers and defenders in scenarios where probabilistic events influence outcomes. We investigate the model checking complexity of POTL and show that it is comparable to that of Probabilistic Computation Tree Logic, ensuring that POTL remains both expressive and computationally practical for cybersecurity and privacy applications. Structure of the work. The contribution is structured as follows. Theoretical background is presented in Section 2. In Section 3, we present the syntax and the semantics of our new logic, called Probabilistic Obstruction Temporal Logic (POTL). In Section 4, we show our model checking algorithm and prove that the model checking problem for POTL is decidable in polyonimal-time. In section 5, we present an illustrative example related to the cybersecurity analysis. In Section 6, we compare our approach to related work. Finally, Section 7 concludes and presents possible future directions."
