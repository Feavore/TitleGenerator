URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10429v1,"Private Counterfactual Retrieval With 
Immutable Features","In a classification task, counterfactual explanations provide the minimum change needed for an input to be classified into a favorable class. We consider the problem of privately retrieving the exact closest counterfactual from a database of accepted samples while enforcing that certain features of the input sample cannot be changed, i.e., they are immutable. An applicant (user) whose feature vector is rejected by a machine learning model wants to retrieve the sample closest to them in the database without altering a private subset of their features, which constitutes the immutable set. While doing this, the user should keep their feature vector, immutable set and the resulting counterfactual index information-theoretically private from the institution. We refer to this as immutable private counterfactual retrieval (I-PCR) problem which generalizes PCR to a more practical setting. In this paper, we propose two I-PCR schemes by leveraging techniques from private information retrieval (PIR) and characterize their communication costs. Further, we quantify the information that the user learns about the database and compare it for the proposed schemes.","The right to explanations mandates that any black box machine learning model making crucial decisions in high-stakes applications should provide the user, i.e., the applicant, with a suitable explanation for its decision [1]. In this regard, counterfactual explanations have grown as an effective means to deliver the minimum perturbation required at the user’s end to alter the model’s decision to a favorable outcome [2]. For instance, in the case of a bank loan rejection, a user might receive a counterfactual recommendation to increase their income by 10K to get accepted. Numerous works have focused on generating counterfactuals with different properties, namely, proximity to the user’s input [3], robustness to model changes [4, 5, 6, 7], feasibility under user’s constraints [8, 9], sparsity in the attributes to be changed [3, 9], and diversity of the counterfactuals [9]. We refer the reader to [10, 11, 12] for a comprehensive survey on different methods. Providing an appropriate counterfactual poses serious privacy concerns, both for the user asking for a counterfactual and for the institution delivering it. Existing works such as [13, 14, 15, 16] focus on preserving data privacy from the institution’s side, while [17, 18, 19] focus on the extraction of the model by querying for multiple counterfactual explanations. However, preserving privacy from the user’s side has rarely received attention. We are particularly interested in the scenario where a user would like to obtain a counterfactual explanation without revealing their input feature vector to the institution. The user may be reluctant to share their feature vector with the institution for several reasons, e.g., if they have a limited number of attempts to apply, or if they wish to preserve their data privacy until they improve their chances of acceptance. Figure 1: System model where y_{1}, y_{2}, y_{5}, y_{7} have the same values for the immutable features as x, i.e., are viable counterfactuals for x. The first work that focuses on user’s privacy in retrieving counterfactual explanations is [20] where the private counterfactual retrieval (PCR) problem is introduced and formulated. This work leverages techniques from private information retrieval (PIR), which is a subject of independent interest, to obtain the index of the nearest counterfactual. In PIR [21], a user wishes to retrieve one message out of K replicated messages in N servers without leaking any information about their required message index. The capacity of PIR, i.e., the maximum ratio between the number of the required message symbols and the total downloaded symbols, is found in [22]. In symmetric PIR (SPIR), an extra requirement is considered where the user cannot get any information about message symbols aside from their required message. The capacity for such a model is found in [23]. Other important variants can be found in [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]. Notably, the PCR strategy proposed in [20] allows all features of the user’s input to be altered while obtaining a counterfactual on the accepted side. However, this assumption is unsuitable for practical settings where certain attributes (e.g., nationality, place of birth, gender) are immutable for a user, restricting the set of attainable counterfactuals. In this paper, we allow the user to fix a subset of their features as immutable, i.e., their values should not be altered in their corresponding counterfactual. The immutable set is user-specific and should be kept private from the institution. With this additional constraint, we propose immutable PCR (I-PCR) wherein the user retrieves their counterfactual index from a database of accepted feature vectors. To obtain the counterfactual vector, the user simply runs an SPIR protocol with this index after I-PCR. We present two achievable schemes, namely, a two-phase and a single-phase I-PCR, and compare their communication and computation costs through runtime analyses on real datasets. Although these schemes guarantee information theoretic privacy for the user, the leakage from the database is non-zero. We find that the single-phase scheme incurs lower communication cost than the two-phase one, while causing more database leakage. We evaluate this leakage numerically for both schemes. Further, we account for user actionability which guarantees preferential change of certain attributes compared to the rest. We demonstrate that our schemes can be modified to include private user actionability on the mutable attributes without compromising the privacy of the immutable attributes."
https://arxiv.org/html/2411.10082v1,Jointly Optimizing Power Allocation and Device Association for Robust IoT Networks under Infeasible Circumstances,"Jointly optimizing power allocation and device association is crucial in Internet-of-Things (IoT) networks to ensure devices achieve their data throughput requirements. Device association, which assigns IoT devices to specific access points (APs), critically impacts resource allocation. Many existing works often assume all data throughput requirements are satisfied, which is impractical given resource limitations and diverse demands. When requirements cannot be met, the system becomes infeasible, causing congestion and degraded performance. To address this problem, we propose a novel framework to enhance IoT system robustness by solving two problems, comprising maximizing the number of satisfied IoT devices and jointly maximizing both the number of satisfied devices and total network throughput. These objectives often conflict under infeasible circumstances, necessitating a careful balance. We thus propose a modified branch-and-bound (BB)-based method to solve the first problem. An iterative algorithm is proposed for the second problem that gradually increases the number of satisfied IoT devices and improves the total network throughput. We employ a logarithmic approximation for a lower bound on data throughput and design a fixed-point algorithm for power allocation, followed by a coalition game-based method for device association. Numerical results demonstrate the efficiency of the proposed algorithm, serving fewer devices than the BB-based method but with faster running time and higher total throughput.","The Internet of Things (IoT) has transformed how we interact with the world, connecting billions of devices to the Internet and enabling seamless information exchange and automation across sectors such as healthcare, agriculture, transportation, and smart cities [1]. This progress, driven by advances in sensor technology, wireless communication, cloud computing, and data analytics, has made IoT networks integral to modern infrastructure. However, as IoT networks expand, managing the network to maintain a high quality of service poses several challenges [2, 3], especially interference management among connected devices, which weakens wireless signals, compromises data transmission, and leads to unreliable connections. Therefore, effective interference management [4] is crucial for maintaining signal quality, reducing packet loss, minimizing latency, and ensuring reliable communication, particularly in critical applications like healthcare monitoring [5], industrial automation [6], and smart grid systems [1]. IoT networks, typically composed of diverse devices utilizing various wireless technologies and communication protocols [7], require robust interference management techniques to ensure smooth and seamless operation [8, 9, 10]. Moreover, interference increases energy consumption as devices contend with competing signals, making advanced power control and interference avoidance mechanisms essential for extending networks’ lifespan [11, 12]. A large number of researches has been conducted to manage interference and enhance IoT networks performance [4, 13, 14, 15, 10]. Approaches such as non-orthogonal multiple access (NOMA) [14, 15] have focused on optimizing data throughput but rely on successive interference cancellation (SIC), which demands significant energy and computational resources, making it less practical for many IoT scenarios. Alternatively, a fixed-point power control algorithm was proposed in [13] to find the minimum power allocation, enabling users to overcome interference and ensure an acceptable connection. Despite these advances, many studies assumed sufficient resources to meet the data rate requirements for all IoT devices simultaneously [16, 17, 18]. This assumption is often invalid in practice due to power and data rate constraints. When the system cannot meet these requirements, we define this circumstance as “infeasible”. Once infeasible issues happen, existing approaches designed for feasible conditions become inapplicable, rendering the system unresponsive. This can lead to congestion, transmission delays, and degraded performance [19]. Moreover, IoT networks often face restricted resources and intense interference [1], which increases the likelihood of encountering infeasible conditions. Addressing the infeasible issue is crucial to ensuring the practical viability and scalability of IoT deployments, especially for critical applications like healthcare and traffic management [20]. For example, at a parking place with IoT devices like cameras and parking sensors, encountering infeasible circumstances could prevent the system from serving users, causing disruptions in traffic management and safety operations. To avoid such disruptions, it is essential to strategically address infeasibility by serving a subset of IoT devices to maintain critical services. This paper introduces an innovative framework aimed at enhancing the robustness of IoT systems under infeasible circumstances. Specifically, we examine an IoT network where multiple APs communicate with IoT devices in the downlink utilizing the same frequency resource. Each AP transmits signals to multiple IoT devices, while an IoT device receives data from one AP only. We assume perfect channel state information (CSI) is available, similar to many other related works in the literature such as [10, 17, 18, 21, 22, 23, 24, 25, 26, 27]. This assumption, while idealistic, is essential for developing a robust framework addressing the infeasible issue. By first establishing a baseline performance under these ideal conditions, we lay the groundwork for future research that will relax these assumptions and explore more realistic scenarios, including imperfect CSI. The system information is processed centrally to manage resources effectively, with an IoT device’s QoS requirement considered satisfied when its data throughput exceeds its demand. A critical aspect of this framework is the joint optimization of AP-IoT device associations and power allocation. Properly associating IoT devices with APs and allocating power resources efficiently are keys to optimizing signal strength, coverage, and interference management [28]. However, to the best of our knowledge, there was no literature investigating the effect of AP-IoT device association under infeasible circumstances. In particular, we divide the IoT devices into two sets. The first set comprises IoT devices that the system can satisfy the QoS requirement, and the second set consists of the remaining IoT devices. We aim to maximize the number of IoT devices in the satisfied set and serve them first, with the remaining devices being served later. By doing so, the system handles potentially infeasible situations more effectively, maintaining system functionality and efficient resource allocation. We then consider two optimization problems for power allocation and AP-IoT device association: the first is to maximize the number of satisfied IoT devices, and the second is a dual-objective optimization problem to optimize both the number of satisfied IoT devices and the total network throughput. The first problem is solved by utilizing a modified BB algorithm. This method provides a straightforward approach for maximizing the number of satisfied IoT devices while also offering a simple mechanism to assess system infeasibility. For the dual-objective problem, we recognize a conflict between the objectives: increasing the number of satisfied devices can reduce overall network throughput due to stretched resources, while prioritizing network throughput may decrease the number of satisfied devices. To resolve this problem, our approach prioritizes optimizing the number of satisfied IoT devices. We propose an iterative algorithm to find and add IoT devices into the satisfied set. This is achieved by alternately optimizing power allocation and AP-IoT device association. The method effectively increases the number of IoT devices meeting their QoS requirements by reallocating resources strategically, ensuring that more devices are served under the system’s constraints. The non-convex structure of the data rate formula is managed using the log-approximation method [29]. Extensive simulations demonstrate that the modified BB algorithm can serve more IoT devices but with a lower total network throughput and a higher running time. These limitations motivate future work to improve the algorithm’s computational efficiency and scalability for better performance in large-scale IoT networks. Besides, compared with the equal power allocation scheme, the proposed power allocation algorithm can improve QoS satisfaction by approximately 50%. Our main contributions can be summarized as follows: • We propose a novel framework to address the challenges of infeasible circumstances in IoT networks where it is impossible to satisfy the requirements of all IoT devices simultaneously. Our framework introduces two optimization problems: maximizing the number of satisfied IoT devices and a dual-objective problem that optimizes both device satisfaction and total network throughput. This approach ensures efficient operation under challenging conditions, optimizing both individual device satisfaction and overall network performance. • We develop a branch-and-bound-based algorithm to address the number of satisfied IoT device maximization problems and identify infeasible circumstances. For the dual-objective problem, we proposed an iterative algorithm that increases the number of satisfied devices by solving total data throughput maximization problems with respect to the power allocation and AP-IoT device association. We introduce a low-complexity dual fixed-point algorithm based on the Karush-Kuhn-Tucker conditions for power allocation and a coalition game model to determine the optimal device association strategy. • We conduct extensive simulations and benchmark comparisons to validate the efficiency of the proposed framework and provide deeper insights. The results reveal that branch-and-bound can provide services to more IoT devices when the requirements from IoT devices are not too large, albeit with higher running time. For the dual-objective problem, the proposed AP-IoT device association outperforms the geometrical-based AP association, which assigns each IoT device to the closest AP. Additionally, the proposed power allocation surpasses the fixed power allocation, where equal power is distributed to all devices. Paper Organization: The rest of the paper is organized as follows. Related works are reviewed in II. In Section III, we describe the system model and formulate the optimization problem with respect to the power allocation and the AP-IoT device association. In Section IV, we propose an efficient algorithm that obtains the solution to the considered optimization problem by exploiting the Lagrangian and standard interference function. Numerical results are obtained and discussed in Section V. Finally, Section VI concludes the paper. Notation: We use boldface lowercase letters and boldface uppercase letters to denote vectors and matrices, respectively. Let \mathbf{a}^{T} denote the transpose of vector \bm{a}. We define the circularly symmetric complex Gaussian distribution with zero mean and variance \sigma^{2} by \mathcal{CN}(0,\sigma^{2})."
https://arxiv.org/html/2411.09866v1,Power Allocation for Compute-and-Forward over Fading Channels,"Compute-and-forward (CF) is a relaying strategy which allows the relay to decode a linear combination of the transmitted messages. This work studies the optimal power allocation problem for the CF scheme in fast fading channels for maximizing the symmetric computation rate, which is a non-convex optimization problem with no simple analytical or numerical solutions. In the first part of the paper, we investigate the problem when there are finitely many channel states (discrete case). We establish several important properties of the optimal solutions and show that if all users share the same power allocation policy (symmetric policy), the optimal solution takes the form of a water-filling type when the power constraint exceeds a certain threshold. However, if asymmetric policies are allowed, the optimal solution does not take this form for any power constraint. We propose a low-complexity order-based algorithm for both scenarios and compare its performance with baseline algorithms. In the second part of the paper, we state relevant results when the channel coefficients are modelled as continuous random variables (continuous case) and propose a similar low-complexity iterative algorithm for the symmetric policy scenario. Numerical results are provided for both discrete and continuous cases. It is shown that in general our proposed algorithm finds good suboptimal solutions with low complexity, and for some examples considered, finds an exact optimal solution.","In a wireless network, the signal sent by a transmitter is not only received by the intended receiver but also by surrounding nodes due to the broadcast nature of the medium. In the same way, the received signal at a node will include both the desired message and the unwanted interference signal. Traditionally, orthogonal transmission schemes are applied to avoid interference so that the receiver only receive the transmitted signal from the desired transmitter. However, these methods will suffer from a diminishing rate, especially when many nodes want to send messages simultaneously [1]. If the transmitters and the receivers cannot communicate with each other directly, some intermediate nodes can be used as relays to help their communication. Conventional relay strategies include amplify-and-forward and decode-and-forward where either a simple analog operation is used, or the messages from different transmitters are treated ”separately” in a decoding process. The discovery of network coding[2] shows that the traditional relay strategies are not sufficient to achieve optimal throughput. To address the same problem over noisy channels, physical-layer network coding (PNC) was proposed in [3]. It is a non-orthogonal approach which exploits the physical nature of the electromagnetic waves. The relays will recover a set of functions of the signals from multiple transmitters and then learn the desired messages from the functions. Compute-and-forward (CF) is a linear PNC scheme proposed in [4]. It allows the relay to decode an integer linear combination of the messages from multiple transmitters, and either forward it to the next receiver or combine it with other linear combinations to recover individual messages. To achieve this, nested lattice codes are used to guarantee that any integer linear combination of the codewords is still a codeword. Due to the favourable algebraic property of lattice codes, the idea of CF has been applied to different AWGN network models and results in good performances that cannot be achieved otherwise[4, 5, 6, 7, 8, 9, 10]. Due to the difference between the channel coefficients and the integer coefficients of the linear combinations, the achievable computation rate to decode the linear combination will have a loss. One can allocate different transmission powers to different transmitters in order to match the channel coefficients to the integers if the channel state information (CSI) is known to the transmitters. When considering fading channels, where the channel coefficients are modelled as random variables (RV), one should further decide judiciously whether the transmission should happen and how much power should be allocated for different channel states to maximize the average transmission rate. However, since the rate expression of the CF scheme is non-smooth and non-convex, the resulting optimization problem is thus non-convex. In this paper, we will explore the characteristics of the optimal solutions to this non-convex problem and discuss several low-complexity algorithms. I-A Related work There is a rich collection of work on physical-layer network coding and the compute-and-forward scheme in many network scenarios. It has been shown in [3] that for a two-user two-way relay network, the PNC scheme has nearly twice the throughput of the orthogonal scheme. It is achieved by decoding the sum of the transmitted signals at the relay and sending out the sum. Since both users know their own messages, they can learn the message of the other user using the sum. By using the CF scheme, the relay will recover the integer linear combination of the transmitted signals. After collecting enough independent combinations, the receiver can recover all the individual messages. Following this idea, the integer forcing linear receiver has been proposed in [9]. This linear receiver has low complexity and significantly outperforms conventional linear architectures such as zero forcing. It can also apply to the multiple-input multiple-output (MIMO) channel with no coding across transmit antennas while still achieving the optimal diversity-multiplexing tradeoff. The original CF scheme is expanded in [6, 5], which allows unequal rates among the transmitters. In both papers, the authors show that their proposed low-complexity scheme can achieve the channel capacity for the Gaussian multiple-access channels (MAC) given high signal-to-noise ratio (SNR). Apart from the Gaussian MAC, CF is also applied to the random access Gaussian channel with a relatively large number of active users[8]. It is shown that the energy-per-bit required by each user is significantly smaller than the popular solutions such as treating interference as noise. Moreover, the reverse-CF scheme has been proposed for the Gaussian broadcast channels as the duality of the MAC[7, 10]. In this scheme, a precoded process is required at the base station. In [11], a CF-based joint coding scheme for Gaussian fast fading multiple access channels with CSIR only has been proposed and its ergodic capacity achievability has been discussed. To fully exploit the advantage of the CF scheme, the coefficients of the decoded linear combinations should be determined carefully. For example, to recover the messages with the same amount of linear combinations as the amount of users, we should decide all the combinations are linearly independent. The integer coefficients should also be adapted to the channel state. Optimizing these coefficients is a Shortest Lattice Vector (SLV) problem. In [12], the authors design the coefficients by Fincke-Pohst-based candidate set searching algorithm and network coding system matrix constructing algorithm, with which the transmission rate of the multi-source multi-relay system is maximized. It has also been shown in [13] that this SLV problem from the CF scheme can be solved in low polynomial complexity and an explicit deterministic algorithm that is guaranteed to find the optimal solution has been proposed. Another aspect of this CF scheme is to understand the power allocation among the different users in the network. As discussed in the previous subsection, if CSI is available at the transmitters, allocating the transmitted powers can match the channel state with the integer coefficients, which will give a better rate. To this end, the authors in [14] propose an iterative method to optimize the achievable rate over the integer coefficients and the power allocation alternatively in a multi-user multi-relay network with the CF scheme. However, in the power allocation phase, the Lagrange method is applied, which is a sub-optimal approach for the non-convex problem. We will see the gap between the optimal approach and this approach in the later sections. Another network model is considered in[15], which includes two users, a single relay and one receiver. The relay helps the transmission from the users to the receiver while there are direct links between both users and the receiver. The CF scheme is applied at both the relay and the receiver. Then the receiver will learn a linear combination directly from both users and receive another linear combination from the relay. The power allocation problem over the users is then addressed. The authors formulate the problem by approximated geometric programming, which is sub-optimal due to the approximation. Another power allocation problem involving CF discussed in [16] applies a time division protocol in a relay network, where only the first phase applies the CF scheme. The optimization problem focuses on the time fraction and the power allocation among the relays. Among all the CF power allocation papers, the optimal solutions are not discussed in detail. More importantly, none of the existing papers studies the CF model with multiple transmitters and one receiver in a fading scenario, which is the basic building block in any CF-based schemes. Under the traditional orthogonal scheme, the classical water-filling algorithm provides an optimal power allocation policy over fading channels [17]. However, as we will show later, more complex power allocation policies are required to optimize the computation rate under the CF scheme. In particular, the optimization problem is in general a non-convex problem with a non-smooth objective function. As a result, most off-the-shelf optimization algorithms (for example, fmincon in MATLAB) are strictly sub-optimal. The problem does not admit a simple optimal solution either numerically or analytically, which might explain why there is no prior work on this particular problem although the CF scheme has received a lot of attention in the field. I-B Paper contributions In this paper, we consider a multiple access fading channel, where the receiver requires a linear combination of the messages with predetermined equation coefficients. To the best of our knowledge, this is the first paper that discusses the power allocation problem for CF over both users and fading channels. We formulate the power allocation problem under the original CF scheme where users are equipped with lattice codes of the same rate. In general, the problem is nontrivial to solve due to its non-convexity. The main contributions of this paper are as follows. • For the case with finitely many channel states, we establish several important properties of the optimal solutions of this non-convex problem. • A simplified power allocation scheme where all users share the same allocation policy (called symmetric policy) is studied. It is shown that when the power constraint exceeds a certain threshold, the optimal symmetric policy takes the form of a water-filling type solution. We propose a low complexity order-based algorithm to calculate the power allocation scheme for all values of power constraints. • We extend the proposed algorithm to calculate a general power allocation policy where different users can have different power allocation policies. • We state relevant results for the problem when the channel coefficients are modelled as continuous random variables (continuous case). We propose a similar low-complexity iterative algorithm for the symmetric policy for the continuous case. • Numerical results are provided for both discrete case and continuous case. The performance of the proposed algorithms is compared with several baseline algorithms, including an off-the-shelf algorithm (fmincon in MATLAB). In general, our proposed algorithm finds good suboptimal solutions with low complexity, and for some examples, it finds an exact optimal solution."
https://arxiv.org/html/2411.09803v1,"Using a Single-Parity-Check to reduce the Guesswork of
Guessing Codeword Decoding","Guessing Codeword Decoding (GCD) is a recently proposed soft-input forward error correction decoder for arbitrary linear forward error correction codes. Inspired by recent proposals that leverage binary linear codebook structure to reduce the number of queries made by Guessing Random Additive Noise Decoding (GRAND), for binary linear codes that include one full single parity-check (SPC) bit, we show that it is possible to reduce the number of queries made by GCD by a factor of up to 2 without impacting decoding precision. The greatest guesswork reduction is realized at lower SNRs, where the decoder output is usually correct but guesswork is most burdensome. Codes without a SPC can be modified to include one by swapping a column of the generator matrix for an all-ones column to obtain a decoding complexity advantage, and we demonstrate that this can often be done without losing decoding precision. To practically avail of the complexity advantage, a noise effect pattern generator capable of producing sequences for given Hamming weights, such as the one underlying ORBGRAND, is necessary.","Forward error correction decoding algorithms that can function with any code construction have been a focus of research in recent years. Such decoding strategies primarily rely on sequentially querying the impact of putative noise on hard-decision symbols. Noise effect guesswork over the entire received symbol vector, as in GRAND [1], supports decoding any code that has an efficient codebook membership test, including binary linear codes [2], nonlinear codes [3], codes in higher-order fields, and codes based on length constraints [4], in both hard and soft detection settings. Soft detection informed noise effect queries on the message section of a systematic linear code forms the basis of development of GCD [5, 6], which supports arbitrary linear code structures. GRAND operates by guessing noise effects in decreasing order of likelihood based on statistical knowledge of the channel or soft information, as they impact the hard-decision demodulation of the received signal. Each noise effect is inverted against the received signal according to the channel model, and the codebook is checked for the resulting putative transmission. If the putative transmission is a valid codeword, because noise sequences were generated in decreasing likelihood order, then the first codeword generated in this manner is the maximum-likelihood (ML) codeword. Similarly, a list of codewords generated in this way will also be ordered by decreasing likelihood. GCD operates by guessing noise effects as inverted from the information set of the codeword, usually the message bits of a systematic code. The resulting putative message sequence is re-encoded by the receiver to determine the total likelihood of the information set corresponding to the guessed noise effect. When the likelihood cost of a putative message noise effect outweighs the likelihood cost of the best codeword noise effect already found, guesswork can be stopped. Then the most likely codeword already found can be output as the ML decoding. GCD leverages the efficient encoding feature of codes with linear structure to reduce guesswork. Inspired by proposals that exploit the structure of binary linear codebooks to reduce GRAND guesswork [7, 8, 9], this paper introduces a simple variant of GCD to reduce the amount of guesswork required for decoding with GCD for binary linear codes that contain one full parity check bit, which results in an even sub-code. Exploitation of that even sub-code property requires a soft input noise effect query generator capable of solely generating patterns of given Hamming weights. Thus equipped, the result is that low-likelihood guesswork is pushed later in the guesswork order, allowing GCD to reach its stopping condition with less guesswork without skipping potentially likely codeword guesses. The parity constraint on the message bits can be thought of as concatenating an arbitrary linear code with a SPC code, so we refer to the proposed technique as single-parity-check aided GCD (SA-GCD). To identify true \AcML decodings in soft detection settings, both GCD and GRAND require that putative noise effect sequences for received hard-decision bits can be generated in decreasing order of likelihood from channel log-likelihood ratios. For practical implementation, however, approximations are necessary. In particular, Ordered Reliability Bits GRAND (ORBGRAND) develops a guesswork generator based on a statistical approximation that reduces the ordered guesswork generation problem to an integer-partition problem. This approximation has little impact on the block error rate (BLER) [10, 11] and results in a decoder that is almost capacity achieving [12], but which is readily implementable in circuits, e.g. [13, 14, 15, 16]. Moreover, the pattern generator introduced in [11] and implemented in hardware in [16] has the desired property of being able to create sequences of given Hamming weight. We refer to this error pattern generator as the ORBGRAND generator. Note that previous work on GCD have directly employed ORBGRAND’s generator without availing of this additional property, e.g. [5, 17]. We refer to a direct GCD implementation based on the ORBGRAND generator as ORB-GCD. Because the ORBGRAND generator can be configured to produce putative noise effect sequences of given Hamming weight, certain codes allow an ORBGRAND decoder to skip guesswork without affecting BLER. The even code proposal explored in [7, 9, 8] describes a strategy for accelerating ORBGRAND with an even code: for any code in which all valid codewords have even parity, noise sequences with parity that mismatches that of the hard-decision received bits can be skipped. The ORBGRAND generator can be configured to skip generating putative noise effects with Hamming weights that fail this criterion. Extensions of this strategy derived from segmenting the code into even subcodes are also explored. Skipping guesswork is an encouraging idea for GCD. The serial list Viterbi algorithm (SLVA) has been explored for GRAND [18] to accelerate decoding by skipping guesswork. One disadvantage of the SLVA is that it requires extra computation to determine what guesswork to skip. By comparison, the guesswork skipping proposed in [7] requires a single parity computation on the received hard-decision bits, with no other online computation. The power consumption for ORBGRAND with even codes (and therefore SA-GCD) is therefore lower than for a SLVA-driven technique for skipping guesswork. \Ac SA-GCD exploits codebook structure to execute GCD with no BLER degradation and no extra power consumption from SLVA computation. It reduces GCD guesswork by up to a factor of 2 at signal-to-noise ratios where complexity is high, and it operates with the power-efficient, integer-operation-based ORBGRAND generator. The proposal can be read as an analogy to the even code proposal in [7]. This work’s primary contribution beyond mixing ideas from [5] and [7] is the deeper understanding that comes from a perspective in which the code is jointly decoded by ORBGRAND and GCD on components of a concatenated code. This work is organized as follows: Section II describes the setting and code structure in which SA-GCD offers gains over ORB-GCD. Section III describes SA-GCD and explains why the complexity gains arise. Section IV provides numerical results for experiments in which SA-GCD is directly compared to the basic ORB-GCD. Section V summarizes this work and suggests a natural future research direction."
https://arxiv.org/html/2411.10385v1,"Low-Latency Task-Oriented Communications with Multi-Round, Multi-Task Deep Learning","In this paper, we address task-oriented (or goal-oriented) communications where an encoder at the transmitter learns compressed latent representations of data, which are then transmitted over a wireless channel. At the receiver, a decoder performs a machine learning task, specifically for classifying the received signals. The deep neural networks corresponding to the encoder-decoder pair are jointly trained, taking both channel and data characteristics into account. Our objective is to achieve high accuracy in completing the underlying task while minimizing the number of channel uses determined by the encoder’s output size. To this end, we propose a multi-round, multi-task learning (MRMTL) approach for the dynamic update of channel uses in multi-round transmissions. The transmitter incrementally sends an increasing number of encoded samples over the channel based on the feedback from the receiver, and the receiver utilizes the signals from a previous round to enhance the task performance, rather than only considering the latest transmission. This approach employs multi-task learning to jointly optimize accuracy across varying number of channel uses, treating each configuration as a distinct task. By evaluating the confidence of the receiver in task decisions, MRMTL decides on whether to allocate additional channel uses in multiple rounds. We characterize both the accuracy and the delay (total number of channel uses) of MRMTL, demonstrating that it achieves the accuracy close to that of conventional methods requiring large numbers of channel uses, but with reduced delay by incorporating signals from a prior round. We consider the CIFAR-10 dataset, convolutional neural network architectures, and AWGN and Rayleigh channel models for performance evaluation. We show that MRMTL significantly improves the efficiency of task-oriented communications, balancing accuracy and latency effectively.","In the rapidly advancing field of NextG communication systems, there is an increasing focus on task-oriented (or goal-oriented) communications. This approach is gaining prominence as it addresses the specific needs of various applications by ensuring that the transmission process is aligned with the ultimate objective of the task at hand [1, 2, 3, 4, 5, 6, 7, 8, 9]. Unlike traditional communication paradigms that focus on delivering raw data, task-oriented communications (TOC) aims to transmit only the information necessary to accomplish a specific task. Deep learning plays a crucial role in optimizing the encoding and decoding processes for TOC, allowing for efficient and effective transmission of information that directly contributes to the task’s success. By leveraging deep learning-driven TOC, NextG communication systems can achieve significant improvements in both performance and resource utilization [10, 11, 12], making them well-suited for the demands of modern applications such as the Internet of Things (IoT), augmented reality/virtual reality (AR/VR), and vehicle-to-everything (V2X) network systems. In IoT networks, sensors generate vast amounts of data that need to be processed and analyzed to make real-time decisions, such as in smart cities and industrial automation. TOC can significantly reduce the communication overhead by transmitting only the essential information required for decision-making, rather than the raw sensor data. Similarly, in AR/VR applications, low latency and high accuracy are critical to delivering immersive experiences. TOC can help achieve this by optimizing the transmission of visual and sensory data to meet the application’s specific needs. In V2X systems, vehicles need to communicate with each other and with infrastructure to ensure safe and efficient transportation. TOC can enhance these interactions by focusing on the transmission of critical information, such as collision warnings and traffic updates, thereby improving response times and reducing network congestion. One of the primary challenges in TOC is balancing task accuracy and latency objectives and requirements. To that end, the age of task information for TOC was studied in [13]. Achieving high accuracy often requires transmitting a large amount of data, which can lead to increased delay (measured by the number of channel uses) and higher bandwidth usage. Conversely, minimizing delay and bandwidth usage can compromise accuracy. This accuracy-delay tradeoff is a significant hurdle that needs to be addressed to realize the full potential of TOC. We propose a novel multi-round, multi-task learning (MRMTL) approach to address this challenge by dynamically updating the number of channel uses in iterative transmissions of TOC. MRMTL involves an encoder at the transmitter that learns compressed latent representations of input data (e.g., images), which are transmitted over a wireless channel. At the receiver, a decoder performs a machine learning task, specifically classifying the received signals. MRMTL is different from the autoencoder-based communications, where the typical setting has the source-coded data symbols as the input and the reconstruction of those symbols as the output [14]. On the other hand, MRMTL starts with (raw) input data and performs a machine learning task such as classification. The deep neural networks (DNNs) corresponding to the encoder-decoder pair are jointly trained, considering both channel and data characteristics to achieve high task accuracy with minimal channel uses. MRMTL introduces a dynamic update mechanism where the transmitter incrementally sends an increasing number of encoded samples over the channel. The receiver utilizes signals from a previous round to enhance task performance, rather than relying solely on the latest transmissions. The multi-round process utilizes multi-task learning that jointly optimizes accuracy across multiple rounds, with each configuration treated as a distinct task performed with a different number of channel uses. When the receiver’s confidence in the task decisions is low, it can then allocate additional channel uses to improve task accuracy. We demonstrate that MRMTL achieves the accuracy of conventional methods with single-round, single-task learning (SRSTL) for TOC that requires a large number of channel uses, but with significantly reduced delay by incorporating signals from a prior round. To evaluate MRMTL, we consider the CIFAR-10 dataset as the input, convolutional neural network (CNN) architectures as the DNNs, and AWGN and Rayleigh channel models. Our results show that MRMTL significantly improves the efficiency of TOC, effectively balancing accuracy and delay. This study represents a significant step forward in the development of efficient and effective TOC systems for NextG networks. The MRMTL approach can be extended to incorporate semantic communications [15] and integrated sensing and communications [16, 17] by adding tasks of reconstruction and sensing, respectively. The remainder of the paper is organized as follows. Section II describes SRSTL for TOC. Section III presents MRMTL for TOC. Section IV introduces the MRMTL’s process of dynamic initiation of multiple rounds in TOC. Figure 1: System model of SRSTL for TOC."
https://arxiv.org/html/2411.10228v1,Path Assignment in Mesh Networks at the Edge of Wireless Networks,"We consider a mesh network at the edge of a wireless network that connects users with the core network via multiple base stations. For this scenario we present a novel tree-search based algorithm that determines the optimal communication path to the core network for each user by maximizing the signal-to-noise-plus-interference ratio (SNIR) for each chosen path. We show that for three mesh networks with differing sizes, our algorithm chooses paths whose minimum SNIR is 3 dB to 18 dB better than that obtained via an algorithm that disregards the effect of interference within the network, 16 dB to 20 dB better than a random algorithm that chooses the paths randomly, and 0.5 dB to 7 dB better compared to a recently introduced genetic algorithm (GA). Furthermore, we show that our algorithm has a lower complexity compared to the GA in networks where its performance is within 2 dB.","Higher throughput and latency demands drive the need for an increased signal dimensions, which either are provided by using a larger number of antennas to exploit the spatial dimension or by increasing the signal bandwidth [1]. Large signal bandwidth is typically made available by moving to higher carrier frequencies. High carrier frequencies in this context means upper mm-wave band and beyond. The challenge at higher carrier frequencies is an increased signal path-loss and that it is becoming more difficult to generate the output power required for long distances wireless links [2]. If higher frequencies are going to be used, both ends of a communication link have to be moved closer to each other. For applications where coverage is important this ultimately leads to network densification. Densification of wireless networks therefore drive a need for efficient roll-out and backhaul to keep the deployment and cost of ownership low. Different solutions to address this problem of last-mile backhaul have been investigated and introduced into standards such as self-backhaul [3]. Self-backhaul has the advantage that hardware can be re-used between access and backhaul, but has the disadvantage that backhaul and access compete for the the same frequency resources. In this paper we investigate a network topology, where backhaul and access operate on different carrier frequencies. The underlying assumption is that the access-link operates at a lower carrier frequency while the backhaul operates at a higher carrier frequency where larger bandwidth is available. For the backhaul network we consider a mesh network topology, which is particularly attractive from a network roll-out and deployment perspective. The network can easily be expanded by adding new micro base stations (BSs) without a need to add more fiber or macro BS sites for backhaul. In the investigated concept each BS can serve as an access-node for users, as well as a forwarding node in the backhaul network. This system solution simplifies roll-out and densification, but increases complexity in the network layer where routing path through the mesh have to be chosen. Routing in wired mesh networks have been well studied. However, in contrast to wired mesh networks, optimization of wireless networks is more challenging since the cost of different links in the mesh is inter-dependent due to interference between different backhaul links. Routing choices impact interference levels and vice versa. This paper aims to solve this problem by introducing a tree based algorithm that finds the optimal route for each user in a mesh network by considering aforementioned interference present within the network. Furthermore, the algorithm can trade off between performance and scalability, depending on the requirement of the network operator. Significant research efforts to optimize the network have been undertaken in [4, 5, 6, 7, 8, 9]. While [4] and [5] employ algorithms rooted in numerical optimization principles, [6, 7] present innovative approaches hinging on machine learning techniques. In [8], the authors study the problem of topology optimization and routing for integrated access and backhaul networks. They optimize the network using a genetic algorithm. In [9] topology optimization is made through considering latency gain and maximum number of hops in a mmWave, full-duplex backhaul network. In contrast to the above works, this paper introduces a novel tree search based algorithm. Notably, our algorithm stands out by taking network interference into careful consideration as compared to [4, 6]. Unlike [5], where interference mitigation is largely associated with building reflections in urban scenarios, our algorithm considers the impact of interference when BSs communicate amongst each other. Moreover, our algorithm is versatile, accommodating networks with any number of BSs that are connected to the core network, while [6], [7] and [9] exclusively focus on scenarios involving a single core BS. Furthermore, different to [7], we do not assume that the BSs communicate at fixed times."
https://arxiv.org/html/2411.10179v1,Explicit constructions of optimal blocking sets and minimal codes,"A strong s-blocking set in a projective space is a set of points that intersects each codimension-s subspace in a spanning set of the subspace. We present an explicit construction of such sets in a (k-1)-dimensional projective space over \mathbb{F}_{q} of size O_{s}(q^{s}k), which is optimal up to the constant factor depending on s. This also yields an optimal explicit construction of affine blocking sets in \mathbb{F}_{q}^{k} with respect to codimension-(s+1) affine subspaces, and of s-minimal codes. Our approach is motivated by a recent construction of Alon, Bishnoi, Das, and Neri of strong 1-blocking sets, which uses expander graphs with a carefully chosen set of vectors as their vertex set. The main novelty of our work lies in constructing specific hypergraphs on top of these expander graphs, where tree-like configurations correspond to strong s-blocking sets. We also discuss some connections to size-Ramsey numbers of hypergraphs, which might be of independent interest.","A blocking set in a finite projective or affine space is a set of points that intersects every subspace of a given dimension non-trivially. In graph terminology, these are vertex covers of the hypergraphs whose vertex sets are points of the finite space and edges are the subspaces of the fixed dimension. These objects have been studied extensively in finite geometry [11, 13], and many connections have been found with related areas like coding theory. A natural strengthening of this object, that incorporates more geometrical structure, is a strong s-blocking set: a set B of points in the projective space \mathrm{PG}(k-1,q), that meets every subspace S of codimension-s in a set of points that spans S. We can also think of B as a collection of pairwise linearly independent vectors in \mathbb{F}_{q}^{k} such that the span \langle B\cap S\rangle is equal to S for every vector subspace S of (vector) dimension k-s. For s=1, these objects are simply known as strong blocking sets [15, 20], and they have also been studied under the names of cutting blocking sets [1, 12] and generating sets [17, 18]. Finding the smallest size of a strong blocking set is a major open problem in finite geometry, whose importance has increased significantly in the last few years due to its connection to finding short minimal codes [1, 29]. More recently, it has been shown in [10] that strong blocking sets of size n over \mathbb{F}_{3}^{k} are equivalent to linear trifferent codes of length n and dimension k, thus tying them to another important open problem in information theory, the trifference problem. In [10, Lemma 1.2], it was shown that a strong s-blocking set of size n in the projective space \mathrm{PG}(k-1,q) gives rise to an affine blocking set of size (q-1)n+1 in \mathbb{F}_{q}^{k} with respect to the (k-s-1)-dimensional affine subspaces. An application of the polynomial method [13], combined with a geometric argument [7, Section 3], then implies that a strong s-blocking set in \mathrm{PG}(k-1,q) must be of size at least (q^{s+1}-1)(k-s)/(q-1). For s=1, this lower bound was improved in [10, Theorem 1.4] to c_{q}(q+1)(k-1) for a constant c_{q}>1 that does not have a closed formula, but it can be computed by solving an equation involving the q-ary entropy function and the linear-programming bound from coding theory. The best upper bounds are obtained by taking a random collection of s-dimensional (projective) subspaces [10, Remark 3.4] and they are of the order (q^{s+1}-1)((s+1)(k-s-1))/(q-1), which is roughly s+1 times the lower bound. Therefore, it is still an open problem to determine the smallest size of a strong s-blocking set for every s\geq 1. As the random construction suggests, a useful way of constructing strong s-blocking sets is by using a collection of s-dimensional projective subspaces in \mathrm{PG}(k-1,\mathbb{F}), for an arbitrary field \mathbb{F}, whose union meets every codimension-s subspace in a spanning set; this is also known as a ‘higgledy-piggledy’ arrangement of subspaces [18] and it has connections with subspace designs [19]. Over characteristic 0 fields, or finite fields of sufficiently large size with respect to the dimension, we know an explicit construction of such higgledy-piggledy subspaces [18], and thus strong s-blocking sets, which is a constant factor away (for a fixed s and k) from the lower bound. The main challenge is then to give constructions in \mathrm{PG}(k-1,q) where both q and s are fixed, and k\rightarrow\infty. This is also the setting that is more interesting from a coding-theoretic point of view where we need a fixed alphabet size. In [4], an explicit construction of size O(qk) was obtained for strong 1-blocking sets in \mathrm{PG}(k-1,q) using constant-degree expander graphs. This solved the main open problem on constructing short minimal codes because of their known equivalence with strong blocking sets [1, 29]. Here, a linear code C\leq\mathbb{F}_{q}^{n} is called minimal if there are no two linearly independent codewords x,y in C for which the support of x is a subset of the support of y. A natural generalization of this, called s-minimal code, is a linear code C that contains no two distinct s-dimensional subspaces U,V for which the support of U is contained in the support of V. Here, the support of a vector subspace is the set of coordinate positions where at least one vector in the subspace has a non-zero entry. 1.1 Our results We give the first explicit constructions of strong s-blocking sets, whose size is optimal as a function of both q and k for s>1. In particular, we explicitly construct strong s-blocking sets of size O_{s}(q^{s}k) in PG(k-1,q). This is indeed optimal up to the dependence of the constant factor on s by the aforementioned lower bound (q^{s+1}-1)(k-s)/(q-1). The main idea behind our construction is as follows. We define an (s+1)-uniform hypergraph H, whose vertex set is a set of O_{s}(k) vectors in \mathbb{F}_{q}^{k} in ‘general position’. Then our strong s-blocking set B is collection of 1-dimensional subspaces, that is, points of \mathrm{PG}(k-1,q), that are contained in the union of the (s+1)-dimensional subspaces spanned by the edges of H. We build H on top of expander graphs of degree O_{s}(1), which ensures that H has O_{s}(k) edges, and thus B has O_{s}(q^{s}k) elements. We discuss expander graphs and the notion of ‘general position’ in Section 2. Given an codimension-s subspace L, the intersection of B and L naturally gives rise to a certain subhypergraph in H. We argue that the existence of large tree-like configurations in this hypergraph ensures that L\cap B spans L. These tree-like configurations and their relationship to spanning sets is discussed in Section 3. First, we present a construction for s=2 to illustrate the core of our ideas, which can be found in Section 4.1. Then, in Section 4.2, we explore connections of strong blocking sets to a popular topic of extremal combinatorics, known as size-Ramsey numbers. We use recent results of Letzter, Pokrovskiy and Yepremyan [23] about the size-Ramsey numbers of tight paths to construct strong s-blocking sets of size O_{s}(q^{s}k) for large prime powers q with respect to s. Here, unfortunately, the constant hidden by the O_{s}(.) notation is astronomical as a function of s. We improve this in Section 4.3, where we present a self-contained construction of strong s-blocking sets of size at most 2^{O(s^{2}\log s)}q^{s}k for every prime power q sufficiently large with respect to s. Finally, we treat small prime powers q separately in Section 4.4, where we provide explicit constructions of size at most q^{O(s^{2})}k (which is of the promised form O_{s}(q^{s}k) assuming q is bounded by a function of s). Finally, by a known duality between strong s-blocking sets and s-minimal codes (see Example 3.2 in [32]), these also provide the first explicit constructions of asymptotically optimal s-minimal codes. For completeness, we also discuss this relationship between strong s-blocking sets and s-minimal codes in Section 2.2."
https://arxiv.org/html/2411.10067v1,The Interference Channel with Entangled Transmitters,"This paper explores communication over a two-sender, two-receiver classical interference channel, enhanced by the availability of entanglement resources between transmitters. The central contribution are an inner and outer bound on the capacity region for a general interference channel with entangled transmitters. It addresses the persistent challenge of the lack of a general capacity formula, even in the purely classical case, and highlights the striking similarities in achievable rate expressions when assessing quantum advantages. Through a concrete example, it is shown that entanglement can significantly boost performance in certain types of channels.","In the context of 6G research, there is a growing vision to enhance classical networks by integrating a quantum layer [1]. This quantum layer is designed to improve communication performance, enabling higher data rates, enhanced security, and lower latency. Early studies have already shown notable improvements in specific scenarios. However, much of the research has focused on point-to-point connections [2][3] or smaller, simpler networks such as the MAC [4, 5, 6, 7, 8] or broadcast channels [9][10]. In contrast, this work addresses the interference channel, a more complex model involving two senders and two receivers. The interference channel (IC) is a key model in network information theory. Previous strategies involving additional resources, such as transmitter cooperation, have demonstrated potential for improving communication rates [11]. This raises the question of whether shared entanglement between transmitters alone — while keeping the rest of the model fully classical — can also provide a meaningful advantage in communication rates. In [12], Quek and Shor demonstrated the advantages of using entangled transmitters by analyzing the separation of rates. They presented a specific instance of an IC based on the CHSH game [13], but primarily focused on the analysis of superquantum non-local correlations derived from the PR-box model proposed by Popescu and Rohrlich [14]. Later, Leditzky et al. [5] explored a related scenario involving multiple access channels (MAC) and concluded that any channel model derived from non-local games [15] exhibits a capacity advantage when entanglement is shared among transmitters. Non-local games, including the CHSH game, are special cooperative games in which two distant parties can show that they are able to utilize shared entanglement in a strategy to increase the probability of winning above any classical strategy that does not employ any communication [15]. Concurrently, Nötzel [6] examined MACs in which non-zero communication rates can only be achieved with the assistance of entanglement. Recently, further analysis on the MAC with entangled transmitters was conducted in [8], providing bounds on the capacity region. In this paper, we explore the effect of entanglement shared among the transmitters in the IC. The structure of this paper is as follows: In Section II, we provide basic definitions and introduce the system model. Section III discusses bounds on the capacity of the classical IC, as established in the literature. Section IV presents our primary findings regarding the classical IC with entangled transmitters. An illustrative example is discussed in Section V. Sections VI to VIII contain the proofs related to our findings. Finally, Section IX offers a summary and discussion of our results and outlines potential directions for further research."
https://arxiv.org/html/2411.09720v1,Early-Scheduled Handover Preparation in 5G NR Millimeter-Wave Systems,"The handover (HO) procedure is one of the most critical functions in a cellular network driven by measurements of the user channel of the serving and neighboring cells. The success rate of the entire HO procedure is significantly affected by the preparation stage. As massive Multiple-Input Multiple-Output (MIMO) systems with large antenna arrays allow resolving finer details of channel behavior, we investigate how machine learning can be applied to time series data of beam measurements in the Fifth Generation (5G) New Radio (NR) system to improve the HO procedure. This paper introduces the Early-Scheduled Handover Preparation scheme designed to enhance the robustness and efficiency of the HO procedure, particularly in scenarios involving high mobility and dense small cell deployments. Early-Scheduled Handover Preparation focuses on optimizing the timing of the HO preparation phase by leveraging machine learning techniques to predict the earliest possible trigger points for HO events. We identify a new early trigger for HO preparation and demonstrate how it can beneficially reduce the required time for HO execution reducing channel quality degradation. These insights enable a new HO preparation scheme that offers a novel, user-aware, and proactive HO decision making in MIMO scenarios incorporating mobility.","1 INTRODUCTION \IEEEPARstart To ensure seamless user mobility between neighboring cells, the handover (HO) mechanism is defined in the 3GPP specification 38.300 [1], from the First Generation (1G) onward. Reliable communication during the mobility of user equipment (UE) is crucial, and HO management is a key capability [2]. During HO, control messages are exchanged between the UE and the serving Base Station (BS) under predefined conditions. However, since these messages are sent over the air interface, they may be initiated when the radio link faces severe attenuation and various propagation issues such as noise and interference. A robust HO mechanism is essential to maintain user mobility under these conditions; otherwise, user mobility is compromised. To address these challenges, each generation of cellular networks has refined the HO procedure while maintaining its core functionality, which consists of three phases: preparation, execution, and completion. The preparation phase, as the initial step of the HO procedure, typically occurs when the signal quality of the serving cell is low and interference from neighboring cells is high. This makes the UE exposed to Handover Failure (HOF) and Radio Link Failure (RLF), therefore, among the three phases, HO preparation is the most vulnerable [3]. The existing event-driven 5G HO procedure requires the participation of both UE and BS during its preparation phase. In the initial part of this phase, the UE is primarily responsible for measuring the quality of the channel of the serving and neighboring cells and reporting when a measurement event is fulfilled. More precisely, an offset value and a hysteresis value, jointly called the HO margin (HOM), determine when an entry criterion of a measurement event is fulfilled, depicted as Step 2 in Fig. 1, where the intrinsic delay of the Time-to-Trigger (TTT) timer bridges Steps 2 and 3. The HOM is the most significant parameter to control the HO decision [4]. The TTT timer and HOM comprise a tightly coupled setting named HO Control Parameters (HCP) which determine when an HO event (HE) is fulfilled, depicted as step 3 in Fig. 1, and thus impact the initial timing of an HO preparation phase. For optimal initiation of the HO preparation phase, it is essential to adjust the HO timing to each user’s specific mobility pattern and current radio conditions. Fig. 1 also illustrates how the traditional HO preparation mechanism assigns a passive and disadvantageous role to the BS, making it unaware of imminent HO events and thus prone to initiate an HO too late. Figure 1: Interplay between UE and NW during the handover HO preparation phase. 1.1 A3 Handover Event In this section, we examine the core components of an HO event-triggered mechanism, as specified in 3GPP 36.133 [4], and clarify how HCPs interact. 1.1.1 Handover Control Parameters The A3 and A5 events, illustrated in Fig. 2 and 3, embody the signal quality of the serving cell and neighboring cells using the reference signal received power (RSRP) metric. Event A5 provides a handover triggering mechanism based on absolute measurement results. Only the A3 event evaluates a relative comparison between the signal quality of the serving cell and that of neighboring cells, making it adaptable to varying network conditions. As we focus on an intra-frequency HO scenario, we chose the most widely used A3 event whose entry criterion fulfillment, hereafter referred to as T0, is given by the inequality (1) where RSRP_{Target} and RSRP_{Serving} are long-term averaged Layer3-filtered measurements from the serving and neighboring cells, respectively. Figure 2: A3 Event. The quality of neighboring cells exceeds the quality of the serving cell by an offset value. A3 event entry criterion fulfillment (T0) throughout the TTT duration (A3). Figure 3: A5 Event. Only when both entry criteria are satisfied, the UE reports event A5 to gNB. RSRP_{Target}>RSRP_{Serving}+HOM. (1) 1.1.2 Handover Margin Any inappropriate HOM settings between low and high may lead to a ping-pong effect or high Radio Link Failure rate. The HOM setting is set at the cell level, which means that all users within the cell will apply the same HOM. Preferably, the adjustment of the HOM settings shall be adapted individually concerning each user’s context such as velocity, mobility pattern etc [5]. Even though the HOM determines the T0 fulfillment it can not be entirely decoupled from the TTT functionality in the context of event-triggered HO optimizations. 1.1.3 Time-To-Trigger Upon T0 fulfillment, the UE awaits TTT expiry before reporting HE fulfillment to the BS, hereafter referred to as A3, and as illustrated in Fig. 2. The TTT timer has been introduced in previous generations of cellular networks and inherently introduces a time delay. If the TTT value is too large, it may cause connection interruption and an HOF. Conversely, too small a value can prevent long delays but lead to an increased HO ping-pong or unnecessary HO. Given the discussed background, sub-optimal HCP settings can negatively impact the optimal timing for HE and reduce the overall HO success rate. 1.2 Related Work The HCP parameters heavily influence the timing of the HO preparation phase, and numerous techniques have been developed to ensure that the HO is initiated at the most optimal moment. The number of potential HO regions inevitably increases in dynamic mmWave environments characterized by reduced cell coverage and multi-beam architecture requiring smaller cell sizes. An HO region is the distance between the HO event trigger point and the Physical Downlink Control Channel (PDCCH) outage point [6]. The handover failure (HOF) rate is directly proportional to the UE mobility speed and inversely proportional to the size of the HO region. The HOF rate can be reduced by expanding the hypothetical HO region through careful tuning of HCP parameters, which must account for varying network deployments, cell sizes, user velocities, and mobility patterns. Unlike previous research, we dissect the event-triggered mechanism and explain how to distinguish it into two chronological occurrences, advancing the timing of the HO preparation phase. Our machine learning (ML)-assisted method decouples these events by predicting the earliest T0 based on changes in the signal patterns of the UE beam measurements. From a network perspective, our solution claims insights into steps 2-3 illustrated in Fig. 1. We briefly shed light on the strengths and limitations of two key optimization techniques that represent the most relevant related research, namely Conditional Handover and Mobility Robustness Optimization. Conditional Handover (Conditional HO), introduced by 3GPP in 5G Release 16 [1] decouples the base station (BS) preparation and HO execution phases, reducing the number of HOFs by allowing the UE to decide when to initiate the HO. Unlike baseline 5G HO schemes, Conditional HO employs early HO preparation to mitigate the risk of a critical signal quality drop between the UE and the BS. The authors of [7] propose an improved conditional HO scheme that uses trajectory prediction to prepare the BSs along the path of the UE. In contrast, [8] explores ways to improve early preparation success by predicting the next BS during Conditional HO. These techniques aim to optimize the timing of the HO preparation phase by shifting the responsibility entirely to the UE. However, Conditional HO introduces significant signaling overhead during the HO preparation phase, particularly in dense cell deployments with high HO frequency [9]. However, the Conditional HO technique has some disadvantages and challenges that must be addressed. Signalling Overhead: Conditional HO requires the network to pre-configure multiple target cells for a potential handover, which adds complexity to network management. HO Decision-Making: The decision logic for triggering a handover becomes more complex, as the UE has to monitor multiple candidate cells and decide which one is optimal under changing conditions. Mobility Robustness Optimization (MRO) approaches fall under the HO self-optimization technique family, which aims to automate HCP settings with minimal human intervention. Approaches include optimizing HCP parameters individually, considering trade-offs, or treating them as a unified entity [11] - [30]. Studies like [31, 32] emphasize the need to adapt HCPs in millimeter-wave (mmWave) deployments with dense small cells. These studies propose algorithms to adjust HCPs based on RSRP and UE velocity, continuously refining these parameters after each measurement report. However, despite improvements in performance metrics, these solutions present notable challenges. Signalling Overhead: MRO requires ongoing adjustments to HCPs based on real-time network conditions, which can occasionally result in HO failures or unnecessary HOs. Additionally, MRO solutions often rely on generalized approaches that may overlook the specific UE context such as mobility patterns or velocity, leading to suboptimal performance in certain scenarios. HO Decision-Making: The self-optimization process could lead to either too aggressive or too conservative HO decisions, further contributing to handover failures or an increase in unnecessary handovers. Inaccurate Handover Predictions: MRO algorithms rely on predictive models to optimize handovers. If user mobility patterns or network conditions change suddenly or unpredictably, the system might make inaccurate predictions. It is evident that optimizing the timing of the HO preparation phase is a recurring focus in much of the research conducted in this area. In the following sections, we explain how the proposed Early-Scheduled Handover Preparation (ESHOP) scheme addresses the advantages above and limitations identified in related research, as well as those within the ESHOP framework itself. Regarding MRO techniques, continuous adjustment of HCPs requires frequent signaling in the downlink via measurement radio resource reconfiguration, which significantly increases power consumption on the UE side [33]. This issue becomes particularly pronounced at high UE velocities and in small cell deployments with frequent HOs. Furthermore, these solutions assume that the UE’s velocity is known, a parameter that is typically not tracked by cellular networks. Our solution also relies on dedicated signaling toward the UE and is sensitive to sudden and unpredictable changes in UE mobility patterns. Unlike traditional approaches, however, our solution can learn from measurement data, improving handover robustness even in the face of unexpected events. When optimizing the HO preparation phase, Conditional HO complicates decision-making by triggering multiple target cells. In contrast, our study employs a different approach to optimize the timing of the HO preparation phase and reduce signaling overhead. Instead of explicitly estimating individual UE paths or velocities using conventional wireless channel modeling, we utilize a technique that associates a series of radio channel measurements with physical locations through channel fingerprinting. These fingerprinted features, based on each user’s trajectory and velocity, enable us to analyze the time series of relationships between these variables, forming the foundation of our study. This approach allows the ESHOP scheme to trigger HO preparation in a just-in-time manner. 1.3 Contributions • Predictive Timing: By accurately predicting the timing of the T0 fulfillment, the ESHOP scheme allows the network to initiate HO preparation in advance and ensures that the preparation phase begins at the most appropriate time. This proactive approach contrasts with traditional reactive methods that wait for the subsequent A3 fulfillment to be met and reported by UE before initiating HO preparation. • Enhanced HO Regions: The proposed ESHOP scheme proactively expands the hypothetical HO region by initiating the preparation phase earlier. This expansion allows for more time to manage the HO process, thereby minimizing the risk of users experiencing signal degradation or loss of connectivity during the HO. This is particularly beneficial in dynamic mmWave environments characterized by small-cell deployments. • Dynamic HO Preparation: The ESHOP scheme dynamically adjusts the timing of the HO preparation phase. This user-centric approach enables flexibility in accommodating rapid changes in the radio environment, thereby enhancing the robustness of the HO process."
https://arxiv.org/html/2411.09600v1,Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control,"The rapid advancement of low Earth orbit (LEO) satellite communication systems has significantly enhanced global connectivity, offering high-capacity, low-latency services crucial for next-generation applications. However, the dense configuration of LEO constellations poses challenges in resource allocation optimization and interference management, complicating coexistence with other communication systems. To address these limitations, this paper proposes a novel framework for optimizing the beam scheduling and resource allocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic demand, a hybrid beam pattern is employed to enhance the downlink quality of service and minimize the transmission latency from LEO satellites to ground user terminals. Additionally, a dynamic co-channel interference (CCI) control mechanism is developed to mitigate inter-beam interference within the LEO constellation and limit cross-system interference affecting protected users from other networks. The problem of user-beam-frequency allocation with power optimization is formulated as a mixed-integer dynamic programming model and solved using a low-complexity neural network-based graph generation algorithm. Simulation results show that the proposed approach outperforms the baseline methods of full frequency reuse and single-channel transmission, and highlights the potential for further performance improvement with multi-user transmissions.","Low Earth orbit (LEO) satellite systems have attracted increasing attention due to the continued deployment of mega-constellations, such as Starlink and Oneweb [1]. With hundreds to thousands of satellites in orbit, each equipped with multiple antennas supporting high-gain beams, LEO constellations can efficiently deliver seamless and global coverage with high-capacity communication service. Recent advancements in satellite technology with decreased launch costs enable LEO constellations as a cost-effective and scalable solution for extending broadband internet access to underserved and remote regions, as well as complementing existing terrestrial networks with enhanced coverage, resilience, and capacity [2]. On the user side, as demand for real-time applications like video conferencing and autonomous systems continues to grow, low-latency and high-throughput communication becomes increasingly critical. Despite their advantages, LEO satellite systems still experience a higher round-trip latency (typically in tens of milliseconds), compared to ground-based networks based on optical fiber. However, since the signal propagation speed in free space is approximately 47\% faster than in fiber-optic cables, LEO satellites have the theoretical potential to achieve a lower latency in long-distance communications [3]. Therefore, there exists a clear opportunity for technological innovations to close the performance gap and optimize LEO constellation systems for latency-sensitive applications. The proliferation of LEO satellite systems also introduces a major challenge due to the increased interference from dense satellite deployments. Under International Telecommunication Union (ITU) regulations, LEO satellites must avoid interference with geostationary (GEO) networks by maintaining the equivalent power flux density (EPFD) within specified limits, which necessitates frequent beam adjustments or band-switching to prevent disruption [4]. Beyond GEO interference, LEO systems can also impact radio telescopes and astronomical systems that rely on detecting faint signals. These passive users are highly sensitive to overlapping frequencies or harmonics, despite certain frequency bands being dedicated for radio astronomy. Furthermore, ground cellular networks face similar issues, as LEO satellites can operate in overlapping frequency bands, and the growing interest in integrated terrestrial-space communication systems complicates the interference landscape [3]. To address these challenges, dynamic spectrum management and real-time beam control are essential to reduce interference and support harmonious coexistence among communication networks. Various aspects of interference control and performance optimization for LEO communications have been explored in [2] and [5, 6, 7, 8, 9]. The authors in [2] analyze the performance of multi-beam satellite communications by characterizing the received powers of both desired and interference signals, and [5] proposed a beam shut-off algorithm to avoid co-channel interference (CCI) between multiple satellites. To efficiently allocate communication resources, [6] focused on the beam hopping scheduling to meet uneven terrestrial traffic demands, while [8] examined the non-orthogonal multiple access scheme to support a large number of ground devices distributed over a large area. However, most existing works considered the downlink data rate or transmit power as prime performance metrics, neglecting the importance of latency in the quality of service (QoS). Although [7] and [9] jointly considered the resource allocation and latency optimization for LEO satellites, the coexistence challenge of LEO systems with other communication networks is not addressed in their beam pattern designs. This paper aims to optimize the resource allocation and beam scheduling in multi-beam LEO satellite systems with dynamic interference control. To support efficient transmissions, a hybrid pattern combining a wide beam with multiple spot beams is employed to minimize the downlink latency from each LEO satellite to ground user terminals (UTs). Additionally, dynamic CCI control not only considers inter-beam interference within LEO constellations, but also evaluates the impact on protected users from other communication systems. To address the mixed integer dynamic programming problem for the latency optimization, we decompose the task into two steps: beam-UT association and beam-channel allocation. Then, a graph generation algorithm based on neural networks is proposed to find the optimal resource allocation scheme with low-computational complexity and minimize the expected latency of LEO downlink communications. Simulation results show that the proposed approach outperforms other reference schemes."
https://arxiv.org/html/2411.09495v1,ISAC Super-Resolution Receiver via Lifted Atomic Norm Minimization,"This paper introduces an off-the-grid estimator for integrated sensing and communication (ISAC) systems, utilizing lifted atomic norm minimization (LANM). The key challenge in this scenario is that neither the transmit signals nor the radar-and-communication channels are known. We prove that LANM can simultaneously achieve localization of radar targets and decoding of communication symbols, when the number of observations is proportional to the degrees of freedom in the ISAC systems. Despite the inherent ill-posed nature of the problem, we employ the lifting technique to initially encode the transmit signals. Then, we leverage the atomic norm to promote the structured low-rankness for the ISAC channel. We utilize a dual technique to transform the LANM into an infinite-dimensional search over the signal domain. Subsequently, we use semidefinite relaxation (SDR) to implement the dual problem. We extend our approach to practical scenarios where received signals are contaminated by additive white Gaussian noise (AWGN) and jamming signals. Furthermore, we derive the computational complexity of the proposed estimator and demonstrate that it is equivalent to the conventional pilot-aided ANM for estimating the channel parameters. Our simulation experiments demonstrate the ability of the proposed LANM approach to estimate both communication data and target parameters with a performance comparable to traditional radar-only super-resolution techniques.","In recent years, there has been a significant interest in addressing the challenge of communication and radar spectrum sharing (CRSS) [1]. In general, CRSS research is divided into two main directions, radar-communication coexistence and integrated sensing and communication (ISAC) system designs [2, 3]. First focuses on developing effective interference management techniques using a control center to coordinate two functions without causing unwanted interference [4, 5, 6]. ISAC techniques [7, 8], however, concentrate on creating integrated systems capable of simultaneous performance of both wireless communication and remote sensing without the need of a control center. ISAC design offers advantages in both sensing and signaling operations through real-time cooperation. This line of work has been expanded to various innovative applications, such as vehicular networks, indoor positioning, and covert communications [9, 10, 11, 12]. ISAC systems aim to unify the operations of sensing and communication, seeking not only mutual performance enhancements but also a deeper integration paradigm where these functions are co-designed rather than perceived as distinct end-goals [13, 14]. ISAC significantly enhances spectral and energy efficiencies while simultaneously reducing hardware and signaling costs [15] [16]. This is because of the fact that in the ISAC systems both sensing and communication operations are done with a unified system, in contrast with conventional communication and radar systems that exploit various resources. Figure 1: System model. The difficult challenge in ISAC reception is that both the transmit signals and the radar response and communication channels are not known, which makes classical communications-only and radar-only approaches inapplicable. The main goal of ISAC receiver design is to concurrently estimate both the target parameters and the communication data of a remotely located transmitter from the echo signals reflected off the targets [1]. Accordingly, traditional approaches need to be adapted towards this goal. In terms of radar-only approaches, various methods have been proposed for traditional direction of arrival (DOA) estimation, including multiple signal classification (MUSIC) [17] and estimating signal parameters via rotational invariance techniques (ESPRIT) [18]. These methods utilize noise and signal subspaces, respectively. However, in highly correlated or coherent target scenarios, the performance of subspace decomposition methods is significantly diminished. These methods require prior knowledge of the number of targets, which is difficult to determine in advance in practice. Additionally, the performance of subspace decomposition methods is highly degraded in the presence of noise jamming. Pioneered by [19], compressed sensing (CS) emerged as a promising approach to solve the classical DOAs problem, reducing implementation complexity and improving detection resolution by utilizing the signal sparsity in the spatial domain. In [20, 21], the authors demonstrated that random antenna arrays can achieve nearly identical performance compared to the unitary linear array (ULA) implementation. However, the main assumption of CS for the DOA problem is that the DOAs are located on a fine grid, which contradicts practical scenarios where DOAs can be anywhere in the target area. Thus, a mismatch between inherent and estimated DOAs is undeniable, leading to a significant reduction in reconstruction performance [22]. To address the aforementioned basis mismatch, a novel off-the-grid CS approach, known as atomic norm minimization (ANM), has been developed to promote the sparsity of signals within a continuous dictionary [23, 24]. More precisely, the ANM can be considered as a continuous version of the \ell_{1} norm minimization, which is able to minimize the number of atoms required for the construction of the signal of interest over a continuous dictionary [25]. This method has found application in various communication and signal processing problems, including MIMO radar [26], line spectral estimation [27], the elimination of impulsive noise in OFDM systems [28], and super-resolution problem [24]. For instance, in [26], the authors employed ANM to estimate the spatial characteristics of radar channels in a continuous domain, demonstrating its superior performance compared to conventional estimators. The ANM in [29] has been used to recover the continuous delay-Doppler pairs and corresponding attenuation factors under some mild minimum separation constraints. The work in [30] also showed that the ANM can be used to detect the continuous angle-delay-Doppler triplets and the corresponding attenuation factors. On the other hand, a lifted technique has been exploited for blind detection in the super-resolution problem, where simultaneous estimation of both the sparse spikes in signals and the point spread function (PSF) is required [31], which is particularly relevant in fields like radar, sonar, and communications. By leveraging atomic norm minimization and lifting techniques, the authors in [31] provide performance guarantees under certain assumptions about the signal and the PSF. However, the method is limited to solving the one-dimensional problem and can only be applied to estimate delays. This makes it suitable for specific applications like radar and communication problems where delay estimation is critical, but not for more practical scenarios such as MIMO systems. The authors in [32] solved the blind super-resolution problem when the received signal is contaminated with additive white Gaussian noise (AWGN). In [4], the authors used the LANM to distinguish the pulse radar signal from communication messages at the same bandwidth, in the context of communications-radar spectrum co-existence. From a communication perspective, accurately estimating the transmit signal is crucial for decoding digital messages. Consider a bistatic radar scenario where two access points are located at different positions compared to the expected target distance, as illustrated in Fig. 1. The first access point transmits signals, and the second one receives echoes from K targets. The problem is to simultaneously detect the parameters of the targets and estimate the transmitted signals carrying communication data. Generally speaking, this is a bilinear problem, which is challenging to solve. Traditionally, it is commonly assumed that there is a link for exchanging reference signaling between the transmitter and receiver or pilot signals, significantly wasting bandwidth. The estimated signal might contain demodulation errors, leading to a significant reduction in estimation performance [33]. Moreover, a physical obstruction might block the radio waves from the transmitter to the receiver, consequently, the direct link might not be available. To address these issues, we propose a novel approach based on the lifted ANM (LANM) to concurrently estimate radar parameters and communication data. While the work in [31] addresses the super-resolution problem for off-the-grid points, our approach utilizes LANM within the context of ISAC systems in a MIMO setting to concurrently estimate four parameters—delay, Doppler shift, angle of arrival, and angle of departure. This approach is particularly significant for ISAC systems in 5G and beyond, as it enhances the capability to manage complex, multi-dimensional environments using multiple antennas systems. Initially, we assume that the transmitted signals lie on a low-dimensional random dictionary, known by both the transmitter and receiver. Subsequently, we convert the received signal into a sparse combination of low-rank matrices, facilitating the identification of the minimum number of low-rank matrices in the form of LANM. We propose the dual of LANM to construct the dual certificate, proving that our proposed problem can have an exact solution when the number of observations is proportional to the degrees of freedom and under certain mild conditions on the minimum separation of the targets. Although the proposed dual problem is convex, it requires an infinite-dimensional search over the delay-Doppler and angular domains. To tackle this issue, we leverage the results of the trigonometric polynomial theory (TPT) [34] to develop linear matrix inequalities in terms of semidefinite relaxation (SDR). We then generalize our problem for practical scenarios where the received signal is contaminated by AWGN noise and jammer signals. Then, we investigate the computational complexity of the proposed estimator and show that it is equivalent to the pilot-aided ANM. This demonstrates that our approach can be applied to ISAC systems with the same implementation cost as the pilot-aided scenario. Finally, we conduct numerical simulations to evaluate the performance of our approach against state-of-the-art methods. Here, we introduce the notation used in this paper. Vectors and matrices are denoted by boldface lowercase and uppercase letters, respectively and scalars or entries are non-bold lowercase. The \|\cdot\|_{1} and \|\cdot\|_{2} are \ell_{1} and \ell_{2} norms, respectively. The operators \mathrm{tr}(\cdot) and (\cdot)^{H} are trace of a matrix, hermitian of a vector, respectively."
https://arxiv.org/html/2411.09460v1,Analysis Methodology for Age of Information under Sequence Based Scheduling,"We focus on the Age of Information (AoI) performance in a system where each user generates packets periodically to send to a common access point (AP) for status updating. To avoid heavy overhead, we assume that channel sensing, feedback information from the AP, and time synchronization are not available in the system. We adopt a multi-access scheme called the sequence scheme, where each user is assigned a periodic binary sequence to schedule their transmissions. In our previous work [18], we have thoroughly studied the AoI performance under sequence scheme when the period of schedule sequences, L, is equal to the status generating period, T. The results can be extended to the case where T>L. However, the case of T<L is not covered by [18]. Therefore, in this paper, we concentrate on analyzing the AoI performance in the case of T<L, which is more challenging and requires different approaches. We conduct in-depth analysis on this case and develop a mathematical tool based on integer partitions to facilitate the analysis. We derive low-complexity closed-form expressions for two scenarios under T<L. Based on the obtained analytical results, we propose an algorithm to optimize the construction parameters of the sequence scheme. Finally, we compare our proposed sequence scheme with two commonly used baselines, and show that our proposed scheme outperforms the baselines in terms of AoI performance while consuming less energy.","The proliferation of IoT devices has significantly boosted the demand for time-critical information updates in a broad range of applications, such as real-time traffic data exchange for autonomous-driving vehicles and instantaneous user utility profiles for smart grid control. The Age of Information (AoI) metric was first proposed by [3] to capture the information timeliness in real-time systems. It is defined as the time elapsed since the generation time of the latest received status update at the receiver side. Complementing conventional performance metrics such as throughput and latency, such a definition highlights the importance of keeping information available at the receiver side as fresh as possible. Extensive research on AoI has been conducted under various network settings [28, 29, 30]. In this paper, we consider an application scenario in which multiple users are required to send periodically generated status packets to a common access point (AP) by sharing a single channel. The generation period for status packets, referred to as the frame length, is denoted by T. This model is frequently encountered in practical applications. For example, in industrial manufacturing, sensors deployed in factories periodically report the operating status of equipment to a control center to enhance production efficiency [33, 34]. Similar scenarios can be observed in periodic wireless sensor networks (PWSNs) [2, 35], vehicle-to-infrastructure (V2I) communications [32], and other domains. The AoI performance of users is significantly affected by how multi-accessing is handled. Carrier sense multiple access (CSMA), in which users listen for carrier signals before transmitting their own data to avoid collisions, is a popular choice [6, 8, 26]. However, carrier sensing may cause high overhead, especially for small packet transmission. As pointed out in [24, 25], control packets in CSMA, such as RTS, CTS, and ACK, may contribute up to 40% of the total overhead costs. Therefore, we are motivated to consider systems that do not employ carrier sensing. There are also many multi-access schemes relying on the availability of feedback information from the AP [1, 2]. Despite potential performance improvement, feedback transmission usually relies on a dedicated control channel, which can become a bottleneck in heavy traffic situations and is not suitable for energy-constrained networks such as sensor networks. Thus, we also assume that there is no such feedback from the AP in our model. Additionally, we assume that time synchronization among the users is not available in the system to further reduce overhead. Although probabilistic multi-access schemes are still available under these constraints, in this paper, we mainly focus on deterministic schemes. We view deterministic schemes as being defined through sequences, wherein each user is pre-assigned a transmission schedule represented by a periodic binary sequence of length L. At each time slot, each user reads its current sequence value and takes an action accordingly, either transmitting through the channel or remaining silent. The sequence schemes are designed to operate without relying on channel monitoring or feedback information from the AP. This simplicity in implementation is particularly advantageous under our model assumptions. Moreover, as indicated in the literature, [36, 14], there exist schedule sequence sets that can guarantee at least one collision-free transmission within a sequence period for all asynchronous users. In contrast, many other well-known methods fail to offer this guarantee due to their probabilistic nature. Our earlier paper [18] provides the first analysis for AoI under sequence scheme without time synchronization. In that work, we derived an explicit formula for average AoI under the assumption that the status updating period and the sequence period are identical, that is, T=L. Additionally, we characterized critical sequence properties that are essential for AoI optimization. This paper extends our former results in two key aspects: First, we remove the restriction on the sequence period. In our previous work, we mainly concentrated on the T=L case. Although extension to the T>L case is relatively straightforward as observed in [18], the T<L case, which is the main focus of this work, cannot be covered by [18]. We note that this case is more challenging to analyze and requires approaches that are quite different from those in [18]. This is because when T\geq L, the transmission patterns within different frames are identical for a given sequence. However, when T<L, the transmission pattern varies from frame to frame, making the analysis more complex. Second, the optimization analysis in [18] focused on selecting the optimal cyclical shift parameter after sequence construction. In this work, we extend our optimization consideration to include parameter selection before sequence construction. The significance of studying the T<L case can be attributed to two primary factors: 1) Since sequence length L is typically quadratic with respect to the number of users, in systems with frequent status updates, it is more likely that the status generation period T falls within the range [1,L-1] rather than [L,\infty). This makes the T<L case more common in practical applications. 2) By studying the T<L scenario, we fill a gap in the literature and provide a holistic view of the AoI performance under sequence schemes for general values of T. Our study offers valuable insights and guidance for system design and optimization across various configurations. The main contributions of this paper are summarized below. 1. We conduct analysis on AoI under the sequence scheme for the case where T<L, in the context of time asynchronization. This covers a different parameter range compared to our previous work in [18] which is on T\geq L. Using direct definition (shown in (1)) to compute the average AoI for arbitrary starting time offsets causes prohibitively high computation complexity. To address this challenge, we derive two new formulas (shown in (6), (7)) to improve the computational efficiency. Besides, we develop a new mathematical approach based on integer partitions, to evaluate complex statistical expressions that arise in the AoI calculation. 2. We conduct an in-depth study for two specific cases: 1) T and L are co-prime, and 2) each frame contains at most one transmission slot. For these cases, our proposed approach leads to closed-form expressions with significantly lower complexity, O(N^{4}). The formulas are consistent with the simulation results. 3. Our analytical results provide valuable insights in understanding the AoI performance of the system. Based on these results, we propose an optimization method for parameter selection in sequence construction to minimize the average AoI. 4. We compare the sequence scheme with two commonly used baselines, slotted ALOHA and framed ALOHA, by numerical study. Results show that the sequence scheme achieves enhanced AoI performance. Moreover, we evaluate the energy consumption of the schemes and find that the sequence scheme outperforms the baselines in terms of energy efficiency. The rest of this paper is organized as follows. Related works on AoI study are introduced in Section II. After describing the system model in Section III, we present preliminary technical details for sequence design in Section IV to prepare for subsequent discussions. We conduct analysis on average AoI and develop mathematical tools in Section V. Low-complexity closed-form expressions for two special cases are derived in Section VI. Based on the analytical results, we propose AoI optimization algorithm in Section VII. The simulation results are shown in Section VIII. Finally, we conclude the paper in Section IX."
https://arxiv.org/html/2411.09440v1,Evaluation of RIS-Enabled B5G/6G Indoor Positioning and Mapping using Ray Tracing Models,"A Reconfigurable Intelligent Surface (RIS) can significantly enhance network positioning and mapping, acting as an additional anchor point in the reference system and improving signal strength and measurement diversity through the generation of favorable scattering conditions and virtual line-of-sight paths. In this paper, we present a comprehensive framework aimed at user localization and scatterer position estimation in an indoor environment with multipath effects. Our approach leverages beam sweeping through codebook-based beamforming at an 1-bit RIS to scan the environment, applies signal component extraction mechanisms, and utilizes a super-resolution algorithm for angle-based positioning of both connected users and scatterers. To validate the system’s effectiveness, accurate 3D ray tracing models are employed, ensuring the robustness and effectiveness of the proposed approach in practical scenarios.","The evolution of wireless networks has led to the development of new Internet of Things (IoT) services and applications, including smart cities, autonomous vehicles, transforming healthcare, process automation, and extended reality [1, 2, 3, 4]. These applications demand precise localization of both active network nodes and passive elements, like obstacles and scatterers. Achieving such high performance localization and mapping requires sufficient infrastructure coverage, the ability to resolve different signal paths, and accurate estimation of geometric parameters for each identifiable path. Currently, this estimation problem is solved using various radio technologies, such as Global Navigation Satellite Systems (GNSS) [5, 6] and Ultra-WideBand (UWB) [6]. However, since GNSS is restricted to outdoor usage and UWB to short-range applications, new technologies are anticipated to bridge this gap by offering enhanced capabilities across different environments [6]. Starting from 4-th Generation (4G) networks, localization is achieved using multiple anchors, such as Access Points (APs), which exchange signals with User Equipment (UE) to determine the Time Difference of Arrival (TDoA) [7] and pinpoint UE locations. In 5G networks, the use of multiple antennas at both APs and UEs has enabled the estimation of the Angles of Arrival (AoAs) and Angles of Departure (AoDs), facilitating environmental sensing and mapping [8, 9, 10]. Despite these advancements, current techniques face limitations in accuracy and reliability, particularly in multipath, interference-heavy, and Non-Line-of-Sight (NLoS) environments. To overcome some of these challenges, the use of Reconfigurable Intelligent Surfaces (RISs) has been proposed for 6G [11, 12, 13]. RISs can enhance localization by providing higher angular resolution through their large physical apertures, and by addressing NLoS limitations when optimally placed [14, 15]. By controlling the wireless propagation environment [16, 17, 18], RISs facilitate the extraction of accurate channel parameter estimation, making the localization and mapping problem over-determined, and thus, easier to solve [14, 19]. The potential of RIS-aided indoor localization and mapping is lately attracting various research investigations [14, 19, 15, 20, 21, 22, 23, 24, 25]. RIS optimization is crucial in this field and various methods are being explored. Approaches include RIS phase optimization tailored for fingerprinting solutions based on Received Signal Strength (RSS) measurements at the UE [26], and beam sweeping or hierarchical codebook strategies to scan the environment [27, 28, 29, 30]. Furthermore, techniques for separating direct components from those generated by RIS reflections, as presented in [31], are vital for indoor and sub-6 GHz scenarios. Regarding the problem of mapping, Zhang et al. [32] proposed a novel approach for scatterer position estimation using a MUltiple SIgnal Classification (MUSIC) based algorithm. Taha et al. [33] introduced an innovative framework for estimating the depth map of the surrounding environment using a monostatic RIS-aided wireless sensing system, as well as an RIS codebook to create a sensing grid of reflected beams. In addition, Tong et al. [34] discretized the space and estimated the channel to identify scatterers in each sub-space, facilitating accurate environment estimation. In this paper, a protocol for RIS-aided UE and scatterer positioning is presented. The proposed approach integrates codebook-based beamforming at the RIS, combined with a geometry-based method that facilitates angle-based positioning. Also, signal component extraction mechanisms are derived to distinguish direct signals from those received from reflections at a scatterer, and final results are validated using 3D Ray Tracing (RT) channel models. Unlike [32], which overlooks the RIS node in UE positioning and relies on the LoS conditions between the AP and UE, this work utilizes the RIS node and its reflection properties to compensate for the absence of the direct LoS AP-UE path. In addition, [32] assumed continuous phase shifters at the RIS, whereas this work employs a practical and low-resolution 1-bit RIS [35]; making the positioning problem more realistic and challenging. The remainder of the paper is organized as follows: Section II describes the system model, while Sections III and IV present the protocol and the proposed estimation method for user and scatterer positioning, respectively. Section V includes the simulation results and Section VI concludes the paper."
https://arxiv.org/html/2411.09154v1,"STAR-RIS Enabled ISAC Systems:
Joint Rate Splitting and Beamforming Optimization","This paper delves into an integrated sensing and communication (ISAC) system bolstered by a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). Within this system, a base station (BS) is equipped with communication and radar capabilities, enabling it to communicate with ground terminals (GTs) and concurrently probe for echo signals from a target of interest. Moreover, to manage interference and improve communication quality, the rate splitting multiple access (RSMA) scheme is incorporated into the system. The signal-to-interference-plus-noise ratio (SINR) of the received sensing echo signals is a measure of sensing performance. We formulate a joint optimization problem of common rates, transmit beamforming at the BS, and passive beamforming vectors of the STAR-RIS. The objective is to maximize sensing SINR while guaranteeing the communication rate requirements for each GT. We present an iterative algorithm to address the non-convex problem by invoking Dinkelbach’s transform, semidefinite relaxation (SDR), majorization-minimization, and sequential rank-one constraint relaxation (SROCR) theories. Simulation results manifest that the performance of the studied ISAC network enhanced by the STAR-RIS and RSMA surpasses other benchmarks considerably. The results evidently indicate the superior performance improvement of the ISAC system with the proposed RSMA-based transmission strategy design and the dynamic optimization of both transmission and reflection beamforming at STAR-RIS.","I-A Background Recently, a large number of new intelligent applications have emerged, such as autonomous vehicles, smart industry, and cellular networks for 5G and beyond, which have increasingly stringent communication requirements for high bandwidth and high transmission capacity, as well as perception requirements for high-precision and high-resolution [1] [2]. Meanwhile, because of the restricted accessibility of spectrum resources coupled with the communication performance progressively nearing its theoretical limit, the research into integrated sensing and communication (ISAC) systems has consistently gained momentum, attracting strong attention from both academic and industrial sectors [3, 4, 5]. Precisely, the key idea of ISAC is to integrate both communication and sensing functionalities over shared time-frequency-power-hardware resources in one single system [6]. By leveraging a unified signal processing framework, spectrum, and hardware platform, ISAC technology has the potential to boost spectral and energy efficiencies, thereby tackling spectrum congestion and resource wastage issues, while simultaneously reducing hardware and signalling costs [7]. Thus, the ISAC technology is meaningful for supporting diverse applications to access wireless networks and meet their high-quality wireless communications and high-accuracy sensing requirements [8]. Furthermore, as the number of ground terminals (GTs), such as autonomous vehicles and intelligent robots increases, inter-user interference emerges as a substantial factor that inhibits communication performance. Fortunately, rate-splitting multiple access (RSMA) has been proposed, which is widely recognized as a promising manner for achieving robust interference management and communication enhancement [9]. Using the RSMA scheme at the transmitter, the information streams are selectively encoded into a shared common stream and individual private streams by means of linear precoded rate-splitting [10]. Particularly, the common stream should be decoded by all receivers, while the private streams are required to be encoded independently and decoded by the corresponding receivers with successive interference cancellation (SIC) [11]. By this way, the RSMA scheme can alleviate the tensions arising from the scarcity of wireless resources and multi-user communication requirements, thereby improving the performance of communication systems including ISAC [12]. On the other hand, sensing performance is also an important indicator for ISAC systems, which may be restricted by severe path loss fading. In this regard, reconfigurable intelligent surface (RIS) can construct additional transmission links and enhance the signal strength of desired directions by simultaneously manipulating the amplitudes and phases of reflective elements [13]. Thus, RIS can assist in signal enhancement for sensing direction and provide new degrees of freedom (DoF) for ISAC system designs [14]. However, since the general reflecting-only and transmitting-only RISs can only provide half-space coverage of 180^{\circ}, GTs distributed on one side of the RIS only be isolated due to the geographical restriction. So far, relying on the superiority of the simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) for providing full-space signal coverage of 360^{\circ}, it has been devolved into different networks [15]. In particular, the STAR-RIS possesses the ability to bifurcate the incident signal, simultaneously directing one segment as transmitted signals and another as reflected signals thereby providing services to users on both sides of STAR-RIS [16]. Therefore, compared with traditional RISs, STAR-RIS has superior versatility in network deployment due to its comprehensive spatial coverage, and can also provide enhanced signal propagation towards sensing targets and GTs with a higher DoF [17]. I-B Related Work Recently, considerable efforts have been devoted to developing ISAC systems empowered by RIS and RSMA. In [18], a RIS-assisted MIMO ISAC system was taken into account, where the waveform and passive beamforming were collaboratively designed with the goal of elevating the SINR of radar, while mitigating multi-user interference during communication. In [19], the RIS-aided ISAC system was studied, focusing on the investigation of robust beamforming and RIS phase shifts design with the aim of maximizing radar mutual information. However, in [18, 19], only the traditional RISs were considered instead of STAR-IRS, the achievable system performance gain is limited. At present, STAR-RIS with full spatial coverage has been integrated into ISAC systems in many studies. In [20], the communication rate and sensing power were concurrently maximized for the STAR-RIS assisted ISAC system. In [21], in pursuit of attaining the optimal sensing SINR of ISAC network, they simultaneously refined the transmit beamforming at the base station (BS) and meticulously adjusted the transmission and reflection beamforming configurations of the STAR-RIS. In [22], the STAR-RIS was utilized to assist communication capability, while the passive RIS was leveraged to improve sensing functionality, where the weighted sum-rate of communication users were maximized by jointly optimizing the beamforming at ISAC BS, and phase shift vector of STAR-RIS and passive RIS. However, the transmission scheme based on space division multiple access (SDMA) was adopted in [20, 21, 22], which is difficult to provide effective interference suppression when the number of users increases. Meanwhile, driven by RSMA’s capability to mitigate interference, certain studies have delved into integrating RSMA into the ISAC system. In [23], the cooperative ISAC system with RSMA transmission scheme was investigated, where the performance region built on the system sum rate and the boundary limit of positioning error for radar target were characterized. In [24], the uplink RSMA enabled ISAC system was studied, where the transmitted and received beamforming were jointly optimized to realize the optimal sensing SINR, at the same time guaranteeing the fulfillment of users’ rate demands. In [25], the dual-functional radar-communication system assisted by RSMA approach was contemplated, where the message splitting, precoders for communication streams, and radar sequences were collaboratively devised to optimize the weighted sum rate and minimize the mean square error in radar beampattern approximation. In [26], a RSMA-powered ISAC system was researched, emphasizing the minimization of the Cram¨¦r-Rao lower bound (CRLB) with respect to the sensing response matrix, which was achieved through the design of RSMA structure and associated parameters. In [27], the RIS-aided ISAC system incorporating the RSMA approach was analyzed, where the sensing SNR was elevated through meticulous design of rate splitting coupled with precise adjustments of beamforming at BS and STAR-RIS, respectively. Nevertheless, in [23, 24, 25, 26, 27], the STAR-RISs with both reflecting and transmission functionalities was not involved. I-C Motivation and Contributions In this paper, the BS assisted by STAR-RIS provides communication services for GTs based on the RSMA transmission scheme, and concurrently performs target sensing through the beamforming design. Specifically, the STAR-RIS employs the energy splitting (ES) mode to partition the incident signal, directing a portion into the transmission space for sensing the target and another portion into the reflection space for communicating with GTs. The contributions are outlined as follows. • Regarding the STAR-RIS-enhanced ISAC system incorporating the RSMA scheme, the SINR of the received sensing echo signals is treated as a measure of sensing performance. We formulate an optimization problem aimed at maximizing the sensing SINR by jointly optimizing the rate splitting for the common stream, the transmit beamforming at BS, and the passive beamforming at STAR-RIS, respectively. To the best of our knowledge, this is the first work integrating RSMA and STAR-RIS in an ISAC system. • The considered optimized problem involves signal coordination, interference management, and amplitude adjustment, and the optimization variables are coupled together. This leads to the formulated problem being non-convex and difficult to handle. To address this, firstly, the primary problem is decomposed into two sub-problems. Secondly, the variable substitution, semidefinite relaxation (SDR), first-order Taylor expansion, dinkelbach’s transform, and the sequential rank-one constraint relaxation (SROCR) are introduced to deal with the first sub-problem. Through this approach, the optimized transmit beamforming of the BS and common-stream rate allocation are obtained. Thirdly, the SDR and SROCR methods are also used to tackle the second sub-problem, and the optimized transmission and reflection beamforming matrices of STAR-RIS are obtained. Ultimately, by iteratively alternating and solving two sub-problems, we can obtain the solution of the original problem. • Simulation results demonstrate the efficacy of the proposed algorithm in addressing the non-convex problem. It also reveals that the transmission and reflection beamforming design of STAR-RIS and RSMA-based scheme play an important role in enhancing the performance of the ISAC system. Besides, we discover that in the examined ISAC network encompassing a single target, the sensing SINR in the case of transmitting communication signals only is the same as that in the case of transmitting both communication and sensing signals simultaneously. That’s to say, from the perspective of sensing SINR, dedicated sensing waveforms are not always necessary. This finding significantly simplifies the implementation complexity of the network under investigation. The remainder of this paper is structured as follows. Section II puts forward the STAR-RIS enabled ISAC system model. Section III formulates an optimization problem for maximizing the sensing SINR, and proposes an iterative algorithm for solving the formulated problem. Section IV analyzes the simulation results. Section V concludes this work."
https://arxiv.org/html/2411.09146v1,"Secrecy Energy Efficiency Maximization in IRS-Assisted VLC MISO Networks with RSMA:
A DS-PPO approach","This paper investigates intelligent reflecting surface (IRS)-assisted multiple-input single-output (MISO) visible light communication (VLC) networks utilizing the rate-splitting multiple access (RSMA) scheme. In these networks, an eavesdropper (Eve) attempts to eavesdrop on communications intended for legitimate users (LUs). To enhance information security and energy efficiency simultaneously, we formulate a secrecy energy efficiency (SEE) maximization problem. In the formulated problem, beamforming vectors, RSMA common rates, direct current (DC) bias, and IRS alignment matrices are jointly optimized subject to constraints on total power budget, quality of service (QoS) requirements, linear operating region of light emitting diodes (LEDs), and common information rate allocation. Due to the non-convex and NP-hard nature of the formulated problem, we propose a deep reinforcement learning (DRL)-based dual-sampling proximal policy optimization (DS-PPO) approach. The approach leverages dual sample strategies and generalized advantage estimation (GAE). In addition, to further simplify the design, we adopt the maximum ratio transmission (MRT) and zero-forcing (ZF) as beamforming vectors in the action space. Simulation results show that the proposed DS-PPO approach outperforms traditional baseline approaches in terms of achievable SEE and significantly improves convergence speed compared to the original PPO approach. Moreover, implementing the RSMA scheme and IRS contributes to overall system performance, achieving approximately 19.67\% improvement over traditional multiple access schemes and 25.74\% improvement over networks without IRS deployment.","I-A Background WITH the continuous evolution of communication technologies and the Internet-of-Things (IoT), wireless data traffic and network services are experiencing exponential growth, leading to a serious shortage of spectrum resources in traditional radio frequency (RF) communications. Consequently, it is imperative to explore available frequency spectrums and diverse access technologies [1, 2, 3]. Moreover, it is estimated that by 2025, indoor wireless data traffic will constitute at least 78\% of the total traffic, further exacerbating pressure on already crowded indoor RF communications[4]. To satisfy the stringent demand for massive frequency spectrum in next generation wireless networks, light emitting diode (LED)-based visible light communication (VLC), which exploits visible light waves for data transmission, has been recognized as a promising complementary technology to traditional RF[5, 6]. As a dual-purpose technology for communication and illumination, VLC offers green, ubiquitous, and cost-effective access method for wireless communications in future networks. In fact, extensive studies have demonstrated that VLC is superior to RF in several key metrics, such as bandwidth and data transmission rate[7]. However, practical VLC channels are more sensitive to shadowing and blockages than RF channels due to the shorter wavelength of VLC, which could lead to discontinuous signal coverage (i.e., a skip-zone situation) and inferior quality of service (QoS)[8]. Meanwhile, intelligent reflecting surface (IRS) has attracted increasing both academic and industrial sectors due to its ability to reconfigure the wireless propagation channel proactively. Specifically, an optical IRS is composed of numerous passive reflecting elements that can independently adjust the reflection of incident signals, thereby altering characteristics of the wireless channel and increasing the degrees of freedom (DoF) in wireless communications[9]. Leveraging the highly controllable and intelligent signal reflection capabilities of IRS, the skip-zone situation in VLC can be effectively addressed, significantly improving overall system performance. On the other hand, owing to the broadcast nature of VLC signals and the requirement of line-of-sight (LoS) links, confidential messages intended for legitimate users (LUs) are vulnerable to intercepting by potential eavesdroppers (Eves) within the network, especially in public areas[10]. Fortunately, physical layer security (PLS) has attracted extensive attention from both academia and industry, and has been regarded as a promising technology to guarantee highly secure communication[10]. In particular, IRS also plays an important role in strengthening PLS by meticulously reshaping the wireless channel environment. Thus, with the assistance of IRS, not only the spectral efficiency but also the information security can benefit[11, 12, 13]. Despite the rich potential performance enhancement, the implementation of IRS will also introduce more transmission links, which results in more severe inter-user interference (IUI) in multi-user scenarios. In response to this critical challenge, rate-splitting multiple access (RSMA) has been widely regarded as a promising multiple access scheme. In particular, RSMA serves as a generalized framework bridging spatial division multiple access (SDMA) and non-orthogonal multiple access (NOMA)[14]. In RSMA, each user’s message is split into a common part and a private part. Specifically, the common parts are encoded jointly into a common stream, while the private parts are separately encoded into private streams. At the users’ side, the common stream is first decoded and removed by successive interference cancellation (SIC), allowing each user to decode their respective private stream[15, 16, 17]. I-B Related Work In recent years, research on IRS-assisted RSMA networks has proliferated in RF communications [18, 19, 20, 21]. For instance, in [18], a downlink IRS-assisted half-duplex cooperative network was investigated, where the total power consumption of the network was minimized. Also, in [19], an IRS-assisted uplink RSMA system was studied, where the transmit power of each user and the passive beamforming at the IRS were jointly optimized to explore the performance limits of uplink system throughput. Besides, [20] investigated a simultaneous transmitting and reflecting (STAR)-IRS-aided networks, proposing a PPO-based approach to maximize the sum rate of the system under QoS threshold and power budget constraints. Furthermore, a fair transmission strategy for IRS-assisted RSMA systems was designed in [21], where the power allocation, beamforming, and decoding order were jointly optimized by alternating optimization (AO) algorithm. However, due to the non-negative and real-valued nature of visible light signals, as well as the distinct channel models between VLC and RF systems, the obtained results from the aforementioned studies cannot be directly applied to VLC systems[22]. TABLE I: Comparison of the Proposed Work With Other Existing Works in VLC Networks Reference IRS Security Beam- forming Access scheme Objective function DRL-based approach TDMA NOMA RSMA Sum rate Secrecy rate Harvested energy EE SEE [23] ✓ ✓ ✓ [24] ✓ ✓ ✓ [25] ✓ ✓ ✓ [26] ✓ ✓ ✓ [27] ✓ ✓ [28] ✓ ✓ ✓ [29] ✓ ✓ [30] ✓ ✓ ✓ [31] ✓ ✓ ✓ [32] ✓ ✓ ✓ [33] ✓ ✓ ✓ ✓ [34] ✓ ✓ ✓ ✓ Proposed work ✓ ✓ ✓ ✓ ✓ ✓ To date, the significant potential of deploying IRS to enhance VLC system performance has sparked extensive research. For example, [23] investigated an IRS-assisted VLC NOMA system, where the achievable sum rate was maximized by optimizing the passive beamforming at the IRS. Also, in [24], the spectral efficiency of an IRS-assisted VLC system was iteratively maximized through the frozen variable algorithm and minorization-maximization algorithm, while considering practical constraints on power budget, QoS threshold, and illumination. Moreover, in [25], a two-stage resource management framework was proposed to maximize the user fairness under the total power consumption and QoS constraints. Besides, an IRS-assisted VLC secure system was modeled in [26], and the IRS configuration matrix was optimized by the iterative Kuhn-Munkres algorithm to maximize the secrecy sum rate. Furthermore, in [27], an IRS-assisted simultaneous lightwave information and power transfer (SLIPT) VLC system was investigated, where the amount of harvested energy was maximized while ensuring QoS requirements. However, the aforementioned studies, i.e., [23, 24, 25, 26, 27], only investigated the combination of IRS and VLC without incorporating RSMA. As a matter of fact, the RSMA’s ability to efficiently manage interference has spurred scholarly interest in RSMA-based VLC networks. For instance, [28] investigated a RSMA-based SLIPT VLC system, where the precoding matrix and DC bias vector were jointly optimized to maximize the minimum harvested energy of IoT devices. Also, in [30], the energy efficiency of the single-cell and the multi-cell RSMA-based VLC systems was maximized exploiting a two-layer Dinkelbach’s algorithm in an iterative manner, respectively. Besides, in [29], the superiority of RSMA to SDMA and NOMA in MISO VLC systems was discussed, where the rate splitting factor and the beamforming vectors were jointly optimized to maximize the weighted sum rate. I-C Motivation and Contributions Although the potential of IRS and RSMA in VLC systems has been explored to some extent in the aforementioned literatures, e.g., [23, 24, 25, 26, 27, 28, 30, 29], these two technologies were separately investigated. Indeed, the benefits achieved by integrating IRS and RSMA in a VLC network have not been systematically and thoroughly explored. Moreover, as discussed above, due to the broadcast nature of VLC channels, there exists a serious risk of potential information leakage in IRS-assisted VLC RSMA systems. As such, a crucial issue faced by the networks is how to design wireless resource allocation scheme to enhance information security. Therefore, this paper focuses on PLS in IRS-assisted VLC RSMA networks. To the best of the authors’ knowledge, PLS in IRS-assisted VLC networks with RSMA have not been thoroughly investigated thus far. Besides, results from the increasingly prominent issue of power consumption in wireless communication systems, energy efficiency (EE) has already been regarded as an important performance metric in designing resource allocation scheme[30, 31]. Thus, to enhance the information security and EE performance simultaneously, in this paper, we adopt the secrecy energy efficiency (SEE) as the performance metric to design IRS-assisted VLC RSMA networks. Table I highlights the significance of our work compared with existing studies. The contributions of this paper are summarized as follows: \bullet To enhance the SEE of the IRS-assisted VLC network with RSMA, we formulate an optimization problem to maximize the SEE by jointly optimizing the beamforming vectors, the DC bias, the RSMA common rates, and the alignment matrices of IRS elements. The problem has constraints on the QoS threshold, the total power budget, the common information rate allocation, and the linear operating region of LEDs. \bullet Since the formulated problem is a mixed-integer nonlinear programming (MINLP) problem involving binary programming and mixed variables, it represents a tremendous challenge to traditional convex optimization methods. Thus, we adopt deep reinforcement learning (DRL) to address the problem given its efficiency in tackling complex problems. Specifically, we first transform the optimization problem into a Markov decision process (MDP). Then, we propose a new dual-sampling proximal policy optimization (DS-PPO) approach. Moreover, the beamforming design in the action space is determined by exploiting the maximum ratio transmission (MRT) and zero-forcing (ZF) methods. \bullet Simulation results demonstrate that the proposed DS-PPO algorithm exhibits excellent convergence performance. Compared with existing baseline methods, DS-PPO significantly improves the SEE performance with a relatively low time cost. Moreover, the effects of varying parameters, such as the number of IRS elements, the QoS threshold, the total power budget, and the number of LUs, on system performance are explored. These findings provide valuable insights for the design of IRS-assisted VLC systems with RSMA. The structure of the paper is organized as follows. Section II describes the system model of the considered IRS-assisted VLC network with RSMA. Section III formulates the SEE maximization problem. Then, a DRL-based DS-PPO approach is presented and analysed in Section IV. Subsequently, simulation results are provided and discussed in Section V. Finally, the paper is concluded in Section VI. Notations: In this paper, a, \boldsymbol{a}, \boldsymbol{A}, and \mathcal{A} denote the scalars, the vectors, the matrices, and the defined set, respectively. Specially, \boldsymbol{0} and \boldsymbol{1} represent the all-zero vector and the all-one vector, respectively. The superscript {\rm T} represents the transpose operation. \mathbb{R}^{x\times y} and \{a_{i}\} denote the set of x\times y real-valued matrix and the set of a_{i}, respectively. Additionally, \|\cdot\|_{\rm F}, \|\cdot\|, |\cdot|, \lfloor\cdot\rfloor, \mathbb{E}[\cdot], \nabla, and \odot denote the Frobenius norm operator, the Euclidean norm operation, the absolute value operation, the floor function, the expectation operator, the gradient operator, and the Hadamard product operator, respectively. \mathcal{N}(\mu,\sigma^{2}) represents the distribution of a real-valued Gaussian noise with mean \mu and variance \sigma^{2}. Moreover, [\cdot]^{+}=\max\{\cdot,0\} and {\rm mod}(\cdot) are the positive function and the modulus operator, respectively."
https://arxiv.org/html/2411.09128v1,Performance Analysis of uRLLC in scalable Cell-free RAN System,"As an essential part of mobile communication systems that beyond the fifth generation (B5G) and sixth generation (6G), ultra reliable low latency communication (uRLLC) places strict requirements on latency and reliability. In recent years, with the improvement of mobile communication network performance, centralized and distributed processing of cell-free mMIMO has been widely studied, and wireless access networks (RAN) have also become a widely studied topic in academia. This paper analyzes the performance of a novel scalable cell-free RAN (CF-RAN) architecture with multiple edge distributed units (EDUs) in the scenario of finite block length. The upper and lower bounds on its spectral efficiency (SE) performance are derived, and the complete set’s formula and distributed processing can be used as their two exceptional cases, respectively. Secondly, the paper further considers the distribution of users and large-scale fading models and studies the position distribution of remote radio units (RRUs). It is found that a uniform distribution of RRUs is beneficial for improving the SE of finite block length under specific error rate performance, and RRUs need to be interwoven as much as possible under multiple EDUs. This is different from traditional multi-node clustering centralized collaborative processing. The paper compares the performance of Monte Carlo simulation and multi-RRU clustering group collaborative processing. At the same time, this article verifies the accuracy of the space-time exchange theory in the CF-RAN scenario. Through scalable EDU deployment, a trade-off between latency and reliability can be achieved in practical systems and exchanged with spatial degrees of freedom. This implementation can be seen as a distributed and scalable implementation of the space-time exchange theory.","I INTRODUCTION With the continuous development of communication technology and the increasing demand for data transmission, the fifth-generation mobile communication system (5G) has been widely promoted. The main characteristics of 5G are higher data transmission speed, lower transmission latency, higher reliability, and a significantly higher number of connections compared to the fourth generation systems (4G). Specifically, 5G regards low latency and high-reliability communication (uRLLC) as one of the three essential application scenarios [1]. URLLC must meet the requirements for transmission reliability and low latency. The work around uRLLC is mainly based on the research in citepolyanskiy2010channel for the scenario of finite blocklength. The channel capacity analyzed in traditional communication systems is based on infinite block length. In finite block length, the traditional Shannon capacity based on the law of large numbers is no longer applicable [2]. 5G has adopted various technologies to achieve low latency and high reliability, among which is Multi TRP, one of the most important. In the long-term evolution of the fourth-generation mobile communication system (4G-LTE), multi-point transmission (CoMP) is also used for multi-point transmission and reception. Multi TRP and CoMP are critical technologies for improving spectrum efficiency, peak rate, and reliability, which can collaboratively process signals between multiple base stations, thereby improving network performance. Although CoMP was proposed in 4G LTE, it was not until the R16 version of 5G-NR that a standardized implementation of incoherent multi-TRP was provided and widely used in commercial systems [3, 4]. Now, the standard is being developed for Multi TRP Coherent Joint Transmission (CJT), which will further improve the network’s performance [5]. Currently, academia and industry have begun to research the sixth-generation mobile communication system (6G) technology to meet higher communication needs in the future [6]. Compared to 5G, 6G requires higher reliability and lower transmission latency [7, 8], which requires more advanced technology. In recent research work, [9] pointed out several critical limitations of uRLLC in the current 5G system and pointed out that scalability will be one of the key technical indicators for eXtreme ultra-reliable and low-latency communication (xURLLC) in 6G. [10] provided a comprehensive review of existing 5G uRLLC technology, shedding light on their associated risks and challenges in the context of future 6G communication systems and pointed out that understanding the core principles and navigating the tradeoffs in vital quality of service requirements of 6G xURLLC remains a complex challenge. Various types of interference challenges in uRLLC were discussed in [11] and classified according to their deployment, design, technology, usage, and propagation characteristics, and extreme throughput performance under very low latency and up to 10^{-9} percentile success probability applications were evaluated. [12] provided a comprehensive review and comparison of different candidate decoding techniques for uRLLC regarding their error-rate performance and computational complexity for structured and random short codes. The concept of spatiotemporal exchangeability was novelly proposed in [13], and a specific implementation scheme was proposed in [14]. In the 15dB signal-to-noise ratio (SNR) scenario, the capacity collapse effect caused by finite block length can be compensated by increasing the number of streams in the system with the deployment in the spatial domain. By appropriately selecting the code rate, block length, and the number of codewords in the time and spatial domains, the coding scheme proposed in [14] can achieve a good tradeoff between transmission delay and reliability. In subsequent work, [15] proved the exchangeability theory, deriving a closed expression for channel dispersion in massive MIMO scenarios. Compact and explicit performance bounds of finite blocklength coded MIMO were formed to explore the relationship between blocklength, decoding error probability, rate, and DoF in different coding modes [16]. The above point-to-point work thoroughly and rigorously verified the idea of increasing the spatial degrees of freedom (DoF) to compensate for the shortcomings of finite block length. Compact and explicit performance bounds of finite blocklength coded MIMO were formed to explore the relationship between blocklength, decoding error probability, rate and DoF in different coding modes in In 6G, cell-free massive multi-input multi-output technology (CF-mMIMO) will be an important research direction. CF-mMIMO is a more revolutionary technology that can break the traditional cellular architecture and achieve cell-free communication with more flexible and efficient network coverage. There have been many studies on cell-free systems in 5G [17, 18], but the research in 6G will be more in-depth and extensive. [2] pointed out that multi-antenna MIMO is a more general extension of classical Shannon information theory. Suppose channel state information (CSI) is globally known. In that case, channel models and capacity analysis in complex application scenarios such as single-user, multi-user, or multi-base station joint processing can be described in a unified form. The spatial freedom of MIMO channels can be artificially increased by increasing the antenna configuration at the transmitting and receiving ends. Under specific theoretical assumptions, future mobile communication systems have no so-called performance limit [19]. Researching how to utilize cell-free architecture to implement uRLLC in 6G systems is worthwhile. [20] pointed out that cell-free architecture with a large number of distributed antennas has macro-diversity and spatial sparsity characteristics, which can further improve the performance of uRLLC. [21] and [22] derived a rate closed-form lower bound with imperfect CSI based on different precoding and combining schemes. By jointly optimizing pilot power and payload power, the global optimal pilot power was derived, and using successive convex approximation (SCA), the non-convex problem was transformed into a series of sub-problems for processing. By deploying more access points (APs), the quality of uRLLC services will benefit. [23] investigated the potential of CFmMIMO to multiplex uRLLC and other services by exploiting the sole spatial diversity through network slicing and adopting greedy pilot allocation to minimize pilot contamination. A particular type of conjugate beamforming (CB) was proposed in [24] that only required local CSI, and a new path-following algorithm was developed to optimize uRLLC rates and CFmMIMO energy efficiency. [25] proposed a general framework to characterize the achievable grouping error probability in the CF-mMIMO. Based on saddlepoint approximation and scaling-based random coding union (RCUs), the performance of CF-mMIMO supporting finite block length under the high-reliability target required by uRLLC is analyzed. [26] investigated the resource allocation problem of CF-mMIMO assisted uRLLC systems, derived a closed form rate lower bound with imperfect CSI and pilot contamination, proposed a new pilot allocation scheme that balances the ratio of pilot length to payload, and jointly optimized pilot and payload power, balancing estimated channel gain and pilot contamination. In the deployment of CF-mMIMO supporting uRLLC, some challenges still need to be solved. Firstly, CF-mMIMO requires more antennas to achieve lower transmission latency and higher reliability. For multi-user scenario processing, traditional centralized processing complexity will be very high. The cell-free deployment must face the problem of scalability. Secondly, more efficient architecture deployment and advanced correlation algorithms are needed to support the complexity of distributed cell-free systems. Therefore, the research on CF-mMIMO is still in the theoretical stage. Currently, a lot of work is focused on the scalability of CFmMIMO correlation and the distribution of AP positions. [27] introduced the classification method of CF-mMIMO with four different implementation levels, from fully centralized to fully distributed, and analyzed the spectral efficiency (SE) performance of spatially correlated fading and different combining schemes. Starting from the scalability of CF-mMIMO, [28] investigated the cell-free radio access network (CF-RAN) under the O-RAN architecture and investigated the uplink and downlink SE of CF-mMIMO and user association based on artificial intelligence. [29] considered the CF-MIMO, where the AP position satisfies the Poisson point process (PPP) and derives the downlink coverage probability and achievable rate. [30] assumed that the distribution of APs is random based on PPP, simulating the actual behavior of APs on mobile networks. Considering the maximum ratio combining (MRC) and minimum mean square error (MMSE) combining at the AP receiver to estimate channel statistics, they derived the uplink SE of CF-MIMO and proved the relationship between AP density/distribution and system SE. The approximate achievable rates of several linear pre-encoders and detectors were considered in the uplink and downlink of non-cooperative multi-cellular time division systems. [31] investigated the performance of channel hardening and confidence propagation in real-world random AP deployment in CF-mMIMO systems. [32] derived two approximate values for the reachable uplink rate with perfect/imperfect CSI in CF-mMIMO, and all these approximate values converge to the classical boundaries implemented in traditional massive MIMO systems where the BS antenna is located at the same position. [33] compared the asymptotic rate performance of downlink multi-user systems with multiple BS antennas, which are either located in the same location or uniformly distributed within the cell. Two representative linear precoding schemes, Maximum Ratio Transmission (MRT) and zero-forcing (ZF) beamforming, were considered to characterize the impact of BS antenna layout on rate performance. [34] derived the lower capacity limits for MRC, ZF, and MMSE detection in a centralized processing scenario. [35] proposed a scalable architecture for CF-mMIMO systems through distributed transceivers and scalable collaborative transmission, which can further improve the network’s performance. Based on this, potential vital technologies such as channel information acquisition, transceiver design, dynamic user and access point association, and new duplex were introduced, and the performance of distributed receiver design was evaluated. However, we have noticed several shortcomings in the current research: (1) Existing work on the cell-free implementation of uRLLC mostly failed to consider the scalability and implementability of the system; (2) Considering the actual deployment of cell-free APs, many studies analyzed the SE based on stochastic geometry architecture; The precoding and combining schemes have not fully utilized the collaborative characteristics of cell-free, and there is little research on collaborative transceivers based on interference suppression; (3) The research on scalable cell-free was nearly all based on infinite blocklength, without considering the impact of finite blocklength on system performance, which cannot meet the uRLLC requirement. Therefore, in response to the above issues, relying on the currently validated spatiotemporal exchangeability theory [15] in point-to-point transmission, this paper will implement uRLLC for scalable cell-free systems. The main contributions of this paper are as follows: • Analyzing the SE of a new scalable cell-free RAN with multiple edge distributed units (EDUs) under finite block length. • A modified graph coloring algorithm for interleaving correlation is used to analyze the correlation performance of remote radio units (RRUs) under multiple EDUs that can improve the system SE under latency and reliability constraints. • By deploying scalable EDUs, a compromise between reliability and latency is exchanged with spatial DoF, further expanding and verifying the accuracy of the distributed space-time exchangeability theory. Organization: Notation: bold uppercase \mathbf{A} (bold lowercase \mathbf{a}) denotes a matrix (a vector). {{\mathbf{I}}_{N}} and {{\mathbf{0}}_{M,N}} denote the N\times N dimensional identity matrix and the M\times N dimensional all-zero matrix, respectively. {\left(\cdot\right)^{H}}, {\left(\cdot\right)^{T}} , {\left(\cdot\right)^{*}}, {\left(\cdot\right)^{-1}} and {\left(\cdot\right)^{\dagger}} stand for the conjugate transpose, transpose, conjugate, inverse and pseudo-inverse, respectively. {\mathrm{diag}}\left\{{\mathbf{a}}\right\}, {\mathrm{diag}}\left\{{\mathbf{A}}\right\} and {\mathrm{blkdiag}}\left\{{\mathbf{A}_{1}},\cdots,{\mathbf{A}_{N}}\right\} represent a diagonal matrix with \mathbf{a} along its main diagonal, a vector constructed by the main diagonal of the matrix \mathbf{A}, a block diagonal matrix , respectively. \otimes denotes the Kronecker product of two matrices. \ell_{0} , \ell_{1} and \ell_{2} norm of vectors are denoted by \left\|\cdot\right\|_{0}, \left\|\cdot\right\|_{1} and \left\|\cdot\right\|_{2}, respectively. {\mathcal{CN}}\left(\bm{\mu},\mathbf{R}\right) denotes the complex Gaussian distribution with mean \bm{\mu} and covariance matrix \mathbf{R}. {\mathbb{E}}\left\{\cdot\right\} is the expectation operator. Finally, \backslash denotes the set subtraction operation."
https://arxiv.org/html/2411.08924v1,The Geometry of Codes for Random Access in DNA Storage,"Effective and reliable data retrieval is critical for the feasibility of DNA storage, and the development of random access efficiency plays a key role in its practicality and reliability. In this paper, we study the Random Access Problem, which asks to compute the expected number of samples one needs in order to recover an information strand. Unlike previous work, we took a geometric approach to the problem, aiming to understand which geometric structures lead to codes that perform well in terms of reducing the random access expectation (Balanced Quasi-Arcs). As a consequence, two main results are obtained. The first is a construction for k=3 that outperforms previous constructions aiming to reduce the random access expectation. The second, exploiting a result from [1], is the proof of a conjecture from [2] for rate 1/2 codes in any dimension.","As the amount of data produced globally continues to rise exponentially, the demand for efficient, durable, and scalable storage solutions has become critical [3]. Traditional storage technologies struggle to keep up with this growth, both in terms of physical space and energy efficiency. DNA storage has emerged as a promising alternative [4, 5, 6, 7, 8, 9, 10], attracting significant attention due to its potential for extreme data density and long-term stability [11, 12]. This alternative approach to data storage has attracted growing interest across fields such as biology, chemistry, computer science, electrical engineering and also mathematics. However, despite its promise, DNA storage still faces significant challenges and presents many open questions [13, 14, 11]. The DNA storage process generally involves three main steps: DNA synthesis, storage, and sequencing. Digital data, typically represented as a string of bits, is first encoded into sequences over the DNA alphabet \{A,C,G,T\}. This encoded string is divided into blocks, and then synthesized into actual DNA strands. These strands are stored in a container, where each strand exists in numerous copies, but in a completely unordered manner. When a user wants to access the stored data, sequencing technology retrieves a multiset of “reads” – copies of the strands that may contain errors. By obtaining enough reads, users can reconstruct the original data. The number of reads required for accurate data retrieval is called coverage depth, and reducing this depth is crucial for lowering sequencing costs and improving retrieval speed [15]. To reduce the cost of DNA synthesis and sequencing, which is one of the main drawbacks of using synthesized DNA as a storage solution, error-correcting codes have been used to make the process more efficient, through reducing the number of strands needed for data retrieval. In this paper, we focus on a specific problem arising in DNA storage systems known as the Random Access Problem, initially introduced in [2]. This problem concerns the scenario in which a user wants to retrieve only one specific information strand from a storage system. Assuming error-free synthesis and sequencing, we aim to study and determine error-correcting codes that reduce the expected number of reads necessary to access this target strand. To achieve this, we build on results from both [2] and [1] to gain a deeper understanding of which properties of codes play a crucial role in reducing the expected number of reads required for reliable data retrieval. In our approach, we look at this problem from a geometric perspective, which provides new insights into what properties of codes play a role for them to perform well in terms of the random access problem in DNA storage systems. Moreover, studying this problem from this new viewpoint allows us to derive clean formulas for computing the random access expectation, for certain classes of codes. In contrast, previous work often involved formulas that were challenging to handle or analyze explicitly. This paper is organized as follows. Section 2 provides the definitions used throughout the paper, formally introduces the Random Access Problem, and offers a brief overview of existing results on the topic. In Section 3, we introduce a geometric object in the projective plane, which we call a balanced quasi-arc. Intuitively, a balanced quasi-arc is a set of projective points in which three specific points, referred to as fundamental points, are in the span of many subsets of other points in the set, more so than any of the non-fundamental points. This characteristic of the set of points increases the likelihood of recovering these fundamental points when sampling uniformly at random from the set, ultimately leading to codes that perform well regarding the Random Access Problem. To the best of our knowledge, the codes we obtain based on this construction outperform any of the existing constructions of codes in terms of the Random Access Problem. All of this will be discussed in detail in Section 4. In Section 5, we investigate the parameters of a class of codes with a rate of 1/2, first constructed in [2], that have a random access expectation strictly smaller than their dimension k. By closely examining these parameters, we are able to resolve a conjecture proposed in [2] that states the ratio of their random access expectation to k is strictly smaller than 0.9456k as k tends to infinity. The approach we take is inspired by a result from [1] and it gives a new way of showing that the random access expectation is smaller than k. Finally, in Section 6 we conclude the paper and propose some possible directions for future research."
https://arxiv.org/html/2411.08918v1,Wireless Federated Learning over UAV-enabled Integrated Sensing and Communication,"This paper studies a new latency optimization problem in unmanned aerial vehicles (UAVs)-enabled federated learning (FL) with integrated sensing and communication. In this setup, distributed UAVs participate in model training using sensed data and collaborate with a base station (BS) serving as FL aggregator to build a global model. The objective is to minimize the FL system latency over UAV networks by jointly optimizing UAVs’ trajectory and resource allocation of both UAVs and the BS. The formulated optimization problem is troublesome to solve due to its non-convexity. Hence, we develop a simple yet efficient iterative algorithm to find a high-quality approximate solution, by leveraging block coordinate descent and successive convex approximation techniques. Simulation results demonstrate the effectiveness of our proposed joint optimization strategy under practical parameter settings, saving the system latency up to 68.54% compared to benchmark schemes.","Unmanned aerial vehicles (UAVs), commonly referred to as drones, have been revolutionizing next-generation wireless networks with their versatile capabilities including line-of-sight (LoS) connections, 3D mobility, and flexibility. UAVs can function as airborne base stations (BSs) for delivering communication, computation, and caching services to overcome traditional infrastructure limitations, while can also serve as mobile users for tasks like remote sensing, delivery services, target tracking, and virtual reality support. More recently, UAVs have been integrated with machine learning (ML) to deliver intelligent services such as classification of aerial images captured by UAV’s cameras. To ensure data privacy during ML model training in UAV networks, federated learning (FL) has been recently employed where UAVs can train an ML model and only share the trained model updates to a cloud server without data exchange. Previous studies have mainly focused on implementing conventional FL architectures with UAVs, where UAVs typically serve as FL clients with pre-stored datasets or as aerial base stations responsible for model aggregation. More recent research, such as [1, 2], has integrated UAV deployment into the FL system, enabling UAVs to function as relays for efficient data collection from other devices or as aggregators with adaptive positioning to improve FL performance. Furthermore, much of the prior work in this domain has primarily concentrated on communication and/or computation aspects, assuming that the data for training is readily available without accounting for the data sensing process. This assumption overlooks a critical factor, as the sensing process competes with communication and computation for limited resources, which can significantly affect overall learning performance. In FL, sensing, computation, and communication are highly coupled and must be seamlessly integrated to fully unlock its potential. This has given rise to the increasingly prominent research field of integrated sensing and communication (ISAC) [3]. Several studies have explored FL-UAV, FL-ISAC networks. In [4], the authors investigated a UAV-FL system for image classification in area exploration scenarios, while [5] proposed UAV-empowered wireless power transfer to enable sustainable FL-based wireless networks. The works in [6], [7], [8] studied FL-ISAC frameworks where they focus on jointly optimizing sensing, communication, and computation resource allocation. Despite these research efforts, the problem of latency minimization in UAV-enabled FL system with ISAC remains under-explored. Given UAV’s limited computational power and battery capacity, optimizing the round-trip ML model training latency, such as ML model training and ML model communication, is crucial to achieve efficient and timely FL while preserving UAVs’ resources. Hence, this paper studies a new latency minimization problem for UAV-enabled FL with ISAC. The contributions of this paper are two-fold: (1) We formulate a new latency minimization problem for UAV-enabled FL with ISAC, by jointly optimizing resource allocation and trajectory of UAVs along with resource allocation of the BS (Section II); (2) This latency minimization problem is computationally challenging, thus we propose a new iterative optimization approach to obtain the optimal solutions by applying block coordinate descent (BCD) and successive convex approximation (SCA) techniques (Section III). Numerical simulations show the superior performance of our joint optimization method compared to baseline approaches (Section IV)."
https://arxiv.org/html/2411.08916v1,Enhanced Secure Transmission of Medical Images through OFDM using Hyperchaotic Systems,"Orthogonal Frequency Division Multiplexing (OFDM) is a popular modulation technique for transmitting digital data over wireless radio channels, including medical images due to its high transmission capacity, low interference, bandwidth efficiency, and scalability. However, the security of medical images is a major concern, and combining OFDM with encryption techniques such as chaos-based image encryption can enhance security measures. This study proposes a secure medical image transmission system that combines OFDM, 6D hyperchaotic system, and Fibonacci Q-matrix and analyzes its impact on image transmission quality using simulation results obtained through MATLAB. The study examines the Q-PSK constellation diagram, fast Fourier transform (IFFT) signal, cyclic prefix (CP) techniques, NIST, signal noise ratio (SNR), and bit error rate (BER). The results provide insights into the effectiveness of OFDM in securely transmitting high-quality medical images.","In recent years, data security has become increasingly important for data transmission. Medical images are commonly used in various processes [1], and different methods and technologies such as data hiding [2], steganography [3], and encryption [4] have been developed to protect digital images. Among these methods, image encryption is the most straightforward because it converts meaningful images into unrecognizable noise-like images, making them unintelligible to the human eye [5]. Chaos theory is often used in cryptography due to its unique properties such as periodicity, sensitivity to initial conditions, and random-like behavior which meet the requirements of cryptography [5]. As a result, a huge number of chaos-based encryption techniques have been proposed such as the logistic-sine map proposed by Chen and Hu [6] for medical image encryption, the memristive chaotic system implemented by Chai et al. [7], and the image encryption using a hyperchaotic system proposed by Hosney et al. [4]. In addition, the evolution of technology has led to the development of OFDM as the suggested method for transmitting digital data over a wireless radio channel due to its high transmission capacity, bandwidth efficiency, reduced interference, system flexibility, and scalability [8]. OFDM splits transmissions into sub-channels, enabling high bit rates and spectrum efficiency [9]. In [10], the authors applied the OFDM system in combination with chaotic baker chart permutation to transmit encrypted images. In [8, 11], the method of encrypting direct QAM symbols is discussed in terms of security. In [12], the authors developed a method of encryption and scrambling on both sides for an OFDM system. The authors [1] have suggested an AWGN crypto-OFDM system for secure transmission. In [13], the transmission of secure images has been discussed regarding the logistic sine cosine algorithm through the OFDM communication system. Motivated by the discussions above, in this paper, we present a study focusing on a secure medical image transmission system that uses the OFDM modulation method. This system incorporates a six-dimension (6-D) hyperchaotic system to combat the effects of multipath and enhance medical image transmission security. As a result, the proposed system can use OFDM modulation for the secure transmission of medical images providing a reliable and secure method for transmitting sensitive patient data. By employing strong encryption algorithms and channel coding techniques, medical professionals can ensure that patient data remains confidential and secure during transmission. The structure of the paper is as follows: In the next section, we provide a brief explanation of OFDM modulation. In Section 3, we describe the proposed 6-D hyperchaotic system for the encryption of medical images. In Section 4, we present the results and discussion to demonstrate the effectiveness of the proposed method. Finally, we provide some conclusions in Section 5."
https://arxiv.org/html/2411.08895v1,"Performance-Complexity-Latency Trade-offs of Concatenated
RS-SDBCH Codes","Concatenated bit-interleaved and multilevel coded modulation with outer Reed–Solomon codes, inner Chase-algorithm-based soft-decision-decoded Bose–Ray-Chaudhuri–Hocquenghem codes, and four-level pulse amplitude modulation is considered. A semi-analytical formula is derived for estimating the decoded frame error rate (FER) at the output the additive white Gaussian noise channel, obviating the need for time-consuming Monte Carlo simulations. The formula is used to search a large space of codes (including the KP4 code) to find those achieving good trade-offs among performance (measured by the gap to the constrained Shannon limit at 10^{-13} FER), complexity (measured by the number of elementary decoder operations), and latency (measured by overall block length).","This paper examines the performance-complexity-latency trade-offs achieved by coded modulation schemes based on four-level pulse amplitude modulation (PAM4) using concatenated outer Reed–Solomon (RS) outer codes and soft-decision (SD) Bose–Ray-Chaudhuri–Hocquenghem (BCH) inner codes. Bit-interleaved coded modulation (BICM) and multilevel coded (MLC) modulation are both considered. The use of RS-SDBCH codes is motivated by potential applications in short-reach high-throughput optical communication systems, such as data center interconnects, where low-complexity low-latency forward error correction (FEC) is essential. The two-level non-return-to-zero (NRZ) modulation scheme has in recent years been supplanted by PAM4 in many optical transmission systems due to its higher bit rate and spectral efficiency [2, 3, 4, 5, 6], and indeed PAM4 is the recommended transmission format in various Ethernet standards at transmission rates of up to 400 Gb/s per lane [7, 8, 9]. In a short-haul applications, PAM4 demonstrates lower propagation penalties than NRZ with only a modest increase in the optical power [10], which makes PAM4 modulation scheme attractive for data center interconnects. In transmission systems involving higher-order modulation, coded modulation schemes are often employed. Two generic coded modulation architectures that we will consider in this paper are bit-interleaved coded modulation (BICM) [11, 12] and multilevel coding (MLC) [13, 14, 15]. In BICM, all FEC bits are interleaved prior to being mapped (usually according to a Gray code) to transmitted constellation points. Though not generally capacity-achieving [12], BICM is often considered the pragmatic choice in many applications [16]. MLC, on the other hand, can in principle achieve capacity by separately coding each of the bit-level channels induced by a specific constellation labelling, using multi-stage decoding (MSD) in keeping with the chain rule of mutual information to avoid information loss [13]. The need to implement multiple decoders, and the latency and potential error-propagation induced by MSD are often seen as major drawbacks of MLC schemes [13, 14]. A PAM4 constellation, however, has only two bit levels, and it becomes possible to consider MLC schemes with a natural binary labelling in which only the least significant bit (LSB) level is protected by an inner FEC while the most significant bit (MSB) level is left uncoded (though still conditionally demapped, thereby benefitting from a 6 dB effective signal-to-noise-ratio enhancement) [17, 18, 19]. Errors in the MSB channel caused by channel noise or resulting from a propagation of errors remaining in the LSB channel after inner decoding are then passed to the outer code. Since only a fraction of transmitted bits must be decoded by the inner code, such an MLC scheme may offer complexity benefits compared with BICM. In our previous work [20], we have studied performance-complexity-latency trade-offs of concatenated RS outer and hard-decision BCH inner codes over the binary symmetric channel. Here we expand upon this previous work by considering the use of soft-decision inner BCH codes using PAM4 with BICM and MLC coded modulation scheme over the additive white Gaussian noise (AWGN) channel. We consider the Chase (or Chase-II) decoder [21] to decode the inner BCH codes. Concatenated RS-SDBCH codes have been used or considered in many transmission schemes [22, 23, 24]. These papers consider schemes using the so-called KP4 code, an RS(544, 514) code, as the outer code, as this code is embedded in the electrical interface in many Ethernet and data center interconnects [25, 26, 27]. While we pay close attention to the performance-complexity-latency tradeoffs achievable when the KP4 code is chosen as the outer code, in this paper we consider also (many) other possible choices of outer RS code. Figure 1: Example of an RS-SDBCH concatenation with M=4 RS codewords and m=5 BCH codewords with the “card-dealing” interleaving scheme. Each square represents one (B-bit) RS symbol and the number in each square represents the RS codeword index from which that symbol originates. Here, K=3, N=5, k=4B. The remainder of this paper is organized as follows. In Sec. II, we describe the class of RS-SDBCH concatenated coding schemes considered in this paper and in Sec. III we describe how such schemes can be used in conjunction PAM4 modulation according to the BICM and MLC architectures. In Sec. IV we provide a semi-analytical formula for estimating the post-FEC frame error rate (FER) of such schemes. We used this formula to search a large space of codes to find parameter-combinations achieving good performance-complexity-latency trade-offs. The results of this search are given in Sec. V and also posted online [28]. Throughout this paper, for any positive integer n, we let [n]=\{0,1,\ldots,n-1\}, with [0]=\varnothing. The finite field with q elements is denoted as \mathbb{F}_{q}. The notation \mathcal{C}(n,k,t) refers to a linear code \mathcal{C} with block length n, dimension k, and error-correcting radius t. Finally, “\oplus” denotes the bit-wise XOR operator."
https://arxiv.org/html/2411.09173v1,Correction of circuit faults in a stacked quantum memory using rank-metric codes,"We introduce a model for a stacked quantum memory made with multi-qubit cells, inspired by multi-level flash cells in classical solid-state drive, and we design quantum error correction codes for this model by generalizing rank-metric codes to the quantum setting. Rank-metric codes are used to correct faulty links in classical communication networks. We propose a quantum generalization of Gabidulin codes, which is one of the most popular family of rank-metric codes, and we design a protocol to correct faults in Clifford circuits applied to a stacked quantum memory based on these codes. We envision potential applications to the optimization of stabilizer states and magic states factories, and to variational quantum algorithms. Further work is needed to make this protocol practical. It requires a hardware platform capable of hosting multi-qubit cells with low crosstalk between cells, a fault-tolerant syndrome extraction circuit for rank-metric codes and an associated efficient decoder.","To reach large-scale applications a quantum computer must be built around a quantum error correction scheme, responsible for the correction of faults occurring during the computation [1]. In this work, we consider a model for quantum computation based on a stacked memory with \ell layers of n qubits, represented on Fig. 1. Qubits are grouped in cells containing \ell qubits. We use the term cell to emphasize the resemblance with multi-level flash memories, widely adopted for classical storage, which encode multiple bits per cell [2, 3, 4]. In the quantum setting, one could consider designing a cell using the energy levels of an atom or a quantum harmonic oscillator. Qudits with 5, 7, and 13 levels have been demonstrated experimentally with ions [5, 6, 7]. High fidelity 3-level and 4-level systems have been realized recently using harmonic oscillators [8]. Alternatively, a cell could be an entire module of a quantum computer, connected to other modules through interconnects. A quantum circuit is executed simultaneously on each layer of the stacked memory, with potentially distinct inputs. Stacked memories could find applications in fault-tolerant quantum computing, to improve the throughput of the factories used to produce many copies of quantum states consumed during the computation, e.g. logical zero states, logical plus states or logical Bell states consumed by Steane-style or Knill-style error correction [9, 10, 11] or magic states used to implement logical gates [12]. Below, we design a stacked version of the standard circuit noise model, incorporating the fact that a fault on a qubit is likely to affect other qubits in the same cell. To correct these faults, we encode together the \ell n qubits of the stacked memory. Figure 1: Abstract representation of a 5\times 4 stacked memory. The first ingredient of our protocol is Lemma 2 proving that w faults occurring during the stacked implementation of a Clifford circuit result in a Pauli error on the stacked memory which can be interpreted as a matrix with rank at most 4w. This key lemma suggests encoding the stacked memory in such a way that low-rank errors can be detected. This is precisely what classical rank-metric codes are designed for. The second ingredient is the introduction of the quantum version of a popular family of classical rank-metric codes, the so-called Gabidulin codes, and the computation of their parameters. In the remainder of this paper, Sections II and III introduce a classical version of our protocol, making the rest of the paper easier to follow, and Section IV reviews classical Gabidulin codes. Section V introduces the stacked memory model. Quantum Gabidulin codes are introduced in Section VI and they are applied to the correction of faults in the stacked implementation. In conclusion, we discuss the main limitations of our protocol, related experimental results, and its potential applications."
https://arxiv.org/html/2411.08919v1,A Machine Learning based Hybrid Receiver for 5G NR PRACH,"Random Access is a critical procedure using which a User Equipment (UE) identifies itself to a Base Station (BS). Random Access starts with the UE transmitting a random preamble on the Physical Random Access Channel (PRACH). In a conventional BS receiver, the UE’s specific preamble is identified by correlation with all the possible preambles. The PRACH signal is also used to estimate the timing advance which is induced by propagation delay. Correlation-based receivers suffer from false peaks and missed detection in scenarios dominated by high fading and low signal-to-noise ratio. This paper describes the design of a hybrid receiver that consists of an AI/ML model for preamble detection followed by conventional peak detection for the Timing Advance estimation. The proposed receiver combines the Power Delay Profiles of correlation windows across multiple antennas and uses the combination as input to a Neural Network model. The model predicts the presence or absence of a user in a particular preamble window, after which the timing advance is estimated by peak detection. Results show superior performance of the hybrid receiver compared to conventional receivers both for simulated and real hardware-captured datasets.","5G use cases such as Massive Machine Type Communications, have to support a wide range and a large number of UE devices, including mobile phones and various IoT devices. Each of these devices has to attach to a BS, upon turning on. In 5G systems, the BS continuously transmits broadcast signals, which the UE has to detect in order to trigger its initial attachment procedure. The procedure starts with the UE selecting a Random Access Preamble Index (RAPID) which it uses to rotate a known base sequence. Since the BS has limited knowledge about the UE’s location and channel conditions, it uses a correlation-based receiver to decode the RAPID and estimate the propagation delay induced by the channel. Delay estimates fed back to the UE can be used to advance future uplink transmissions. Henceforth, we refer to this delay as Timing Advance (TA). Initially, the UE transmits on the PRACH with a low power and ramps it by 3/6 dB in the subsequent transmissions if the previous reception fails. PRACH decoding failures, in the form of false peaks and missed detections are common in correlation-based receivers, particularly in high fading and low Signal-to-Noise Ratio (SNR) scenarios. Note that each retransmission on the PRACH causes a wastage of radio and power resources and increases the latency of attachment. To improve the robustness of PRACH decoding (and therefore reduction in PRACH retransmissions), in this paper, we show the design of a hybrid receiver that relies on an AI/ML model and a peak detection module. The input to the model is the Power Delay Profile (PDP) of the correlation, combined across multiple antennas. We have shown that this hybrid receiver performs better than both conventional correlation-based approaches as well as other AI/ML-based approaches. The main contributions of this paper are: • Design of a hybrid receiver for PRACH, which outperforms correlation-based receivers. This work is a lower complexity enhancement of our previous work which relied on large Neural Network (NN) models [1]. • Performance analysis of the proposed receiver with Multiple Input Multiple Output (MIMO). • Performance analysis of the proposed receiver on real data. • Explainability insights on the decision making of the model using Shapley Additive Explanations."
https://arxiv.org/html/2411.08872v1,Large Wireless Model (LWM): A Foundation Model for Wireless Channels,"This paper presents the Large Wireless Model (LWM)—the world’s first foundation model for wireless channels. Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems. Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets. Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets. This LWM’s ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems.","Current and future wireless communication and sensing systems feature important trends that promise substantial performance gains [2, 3, 4]. For example, these systems are rapidly relying on the use of large antenna arrays, the operation over high frequency bands in mid-band, millimeter wave (mmWave), and sub-terahertz, the support of massive number of communicating and sensing devices of various quality of service requirements, and the densification of network infrastructure nodes. Further, these wireless communication and sensing systems increasingly interact with each other, from coordination and integration to assisting each other. Achieving the high potential of these new trends, however, requires overcoming critical challenges in high-dimensional signal processing, complex optimization problems, massive wireless overhead requirements, and intricate network management among others. All that motivates the development of novel approaches for the modeling, optimizing, and operation of next-generation wireless communication and sensing systems. Traditional modeling techniques, such as statistical models and optimization-based approaches, struggle to address these challenges effectively. These methods often rely on simplified models or scenario-specific features, failing to generalize across the diverse and dynamic environments of future wireless communication and sensing networks. For instance, they may not capture complex interference patterns in dense small-cell networks or scale poorly to high-dimensional MIMO systems. Deep learning has emerged as a promising alternative, offering data-driven (model-based or model-free) solutions for optimizing network performance, resource allocation, and signal processing [5, 6, 7, 8, 9]. However, deep learning approaches also face significant limitations. First, they typically require large labeled datasets, which are often scarce in wireless networks and are typically expensive and hard to collect. Second, traditional deep learning models like convolutional neural networks (CNNs) and recurrent neural networks (RNNs) struggle with specific aspects of wireless communication and sensing tasks. CNNs may not capture temporal dependencies efficiently [10, 11], while RNNs often struggle with long-term dependencies and real-time computational efficiency [12, 1]. These limitations underscore the need for a more robust and adaptable framework for leveraging and deploying deep learning in wireless communication and sensing networks. To address these challenges, we propose Large Wireless Model (LWM), a foundation model specifically designed for wireless communication and sensing channels. LWM introduces a task-agnostic framework with pre-training on large-scale synthetic data. As a task-agnostic model, LWM serves as a universal feature extractor for multiple downstream tasks, facilitating complex problem-solving with limited labeled data. It leverages transformer models with multi-head attention mechanisms to capture complex spatial and temporal relationships in wireless channel data. Inspired by advancements in natural language processing (NLP) [1, 13, 14, 15, 16], audio processing [17, 18, 19], and computer vision [20, 21, 22], LWM learns rich, context-aware embeddings that can be utilized for various downstream wireless tasks, such as channel estimation, beamforming, and interference management. LWM is pre-trained on extensive wireless channel datasets, covering a wide range of wireless scenarios. This approach enables the model to capture fundamental properties of wireless propagation and network dynamics, which can be transferred to real-world scenarios, even with limited task-specific data. Through these innovations, LWM addresses the key challenges of limited labeled data, complex spatial-temporal dependencies, and the need for generalization across diverse wireless environments. The key contributions can be summarized as follows: • We introduce the world’s first foundation model for wireless channel embeddings, capable of extracting universal, rich, and context-aware features from complex wireless channels and in diverse environments. • We demonstrate the LWM’s effectiveness across multiple downstream tasks, showcasing its ability to generalize to various wireless scenarios with limited task-specific data. • We provide a comprehensive analysis of the LWM’s performance compared to conventional approaches that use raw wireless channels, highlighting its advantages in feature extraction and generalization. This work introduces a new framework for leveraging and deploying deep learning in wireless communication and sensing systems by leveraging the power of foundation models to address key modeling, design, and deployment challenges in wireless systems. The pre-trained LWM model, scripts, datasets, demo, and instructions are available on the Wireless Intelligence Lab’s Hugging Face page 111Available on Hugging Face: https://huggingface.co/wi-lab, allowing researchers to incorporate them into their projects."
https://arxiv.org/html/2411.08680v1,Integrated Precoder and Trajectory Design for MIMO UAV-Assisted Relay System With Finite-Alphabet Inputs,"Unmanned aerial vehicles (UAVs) are gaining widespread use in wireless relay systems due to their exceptional flexibility and cost-effectiveness. This paper focuses on the integrated design of UAV trajectories and the precoders at both the transmitter and UAV in a UAV-assisted relay communication system, accounting for transmit power constraints and UAV flight limitations. Unlike previous works that primarily address multiple-input single-output (MISO) systems with Gaussian inputs, we investigate a more realistic scenario involving multiple-input multiple-output (MIMO) systems with finite-alphabet inputs. To tackle the challenging and inherently non-convex problem, we propose an efficient solution algorithm that leverages successive convex approximation and alternating optimization techniques. Simulation results validate the effectiveness of the proposed algorithm, demonstrating its capability to optimize system performance.","Thanks to their cost-effectiveness and exceptional maneuverability, unmanned aerial vehicles (UAVs) are witnessing growing demand in wireless communication systems [1, 2]. UAVs can support communication tasks in emergency situations, bypass obstacles to extend communication range, and enhance overall communication quality – capabilities that align perfectly with the requirements of wireless relay communication systems [3, 4]. To enhance the information rate from the source to the destination in UAV-assisted relay communication systems, precoding (beamforming) is often employed[5, 6]. In [7], the authors aimed to maximize spectrum efficiency (SE) and energy efficiency (EE) in a UAV-assisted relay system incorporating an intelligent reflecting surface (IRS). They developed effective schemes using successive convex approximation (SCA) and block coordinate descent (BCD) to jointly optimize active beamforming, passive beamforming, and UAV trajectory. Studies such as [8] and [9] have explored the integrated design of UAV trajectory and beamforming for secure UAV-assisted relay systems. Specifically, [8] proposed a location-based beamforming approach to improve system security performance, grounded on the secrecy outage probability expression. In contrast, [9] focused on maximizing secure energy efficiency in an IRS-assisted UAV relay system, utilizing SCA and BCD techniques to derive sub-optimal solutions for the UAV trajectory, IRS phase shifts, user association, and transmit power. These prior studies predominantly focused on multiple-input single-output (MISO) systems with Gaussian input signals [5, 7, 6, 8, 9, 10, 11]. However, practical communication systems typically use signals drawn from finite-alphabet constellation sets, such as phase shift keying (PSK) and quadrature amplitude modulation (QAM), which do not follow a Gaussian distribution. Furthermore, multiple-input multiple-output (MIMO) systems represent a more common and practical communication scenario. Therefore, unlike existing works, this study targets the transmission design for a MIMO UAV-assisted relay system with finite-alphabet inputs. Our goal is to maximize the average information rate from source to destination by jointly optimizing the UAV trajectory and the precoders at both the transmitter and the UAV, subject to transmit power constraints and UAV flight limitations. This optimization problem is inherently challenging and non-convex, making it difficult to solve directly. Nevertheless, we propose an effective solution algorithm leveraging alternating optimization (AO) and successive convex approximation (SCA) methods, demonstrating its efficacy through extensive simulations. The main contributions of this work are summarized below: • Unlike existing studies that primarily focus on MISO UAV-assisted relay communication systems with Gaussian inputs, which often diverge from real-world scenarios, this paper investigates a MIMO UAV-assisted relay communication system with finite-alphabet inputs, addressing the problem of maximizing the average information rate from source to destination. To the best of our knowledge, this is the first study to explore this particular scenario, filling a critical gap in the literature. • The overall optimization problem is challenging due to the complex form of the objective function and the coupling of variables, rendering it non-convex. To address this, we propose an effective solution algorithm based on theoretical analysis. Specifically, we decouple the overall problem into a precoder optimization sub-problem and a UAV trajectory optimization sub-problem using an AO approach. By deriving convex approximations for these sub-problems through rigorous theoretical analysis, we are able to solve them independently, providing an efficient pathway to optimize the system performance."
https://arxiv.org/html/2411.08549v1,A Framework for Robust Lossy Compression of Heavy-Tailed Sources,"We study the rate-distortion problem for both scalar and vector memoryless heavy-tailed \alpha-stable sources (0<\alpha<2). Using a recently defined notion of “strength” as a power measure, we derive the rate-distortion function for \alpha-stable sources subject to a constraint on the strength of the error, and show it to be logarithmic in the strength-to-distortion ratio. We showcase how our framework paves the way to finding optimal quantizers for \alpha-stable sources and more generally to heavy-tailed ones. In addition, we study high-rate scalar quantizers and show that uniform ones are asymptotically optimal under the strength measure. We compare uniform Gaussian and Cauchy quantizers and show that more representation points for the Cauchy source are required to guarantee the same quantization quality. Our findings generalize the well-known rate-distortion and quantization results of Gaussian sources (\alpha=2) under a quadratic distortion measure.","In 1959, Shannon introduced source coding with a fidelity criterion [22], also known as rate-distortion theory or lossy data compression. At its core, rate-distortion theory investigates the optimal trade-off between a given source’s compression rate and the incurred distortion between that source and its reconstructed version. In his paper [22], Shannon studied discrete alphabets and posited that everything could be extended to continuous alphabets with appropriate adjustments. Subsequently, a more elaborate treatment of the rate-distortion theory for continuous alphabets was made in [2] and more recently in [20]. Naturally, rate-distortion theory proves beneficial across various domains when one has certain continuous measurements, as it aids in determining the attainability of a given rate of compression under some prescribed distortion, and vice versa. Applications include for example identifying the fundamental limit on how much a machine learning model can be compressed [10]. Another application can be found in [15] where the authors show how several stimulus-response curves that are frequently observed in biological signaling pathways arise naturally as the optimal decision strategy based on rate-distortion theory. Beyond these applications, rate-distortion theory is tightly related to the concept of quantization in communications and signal processing, a process in which an analog source is represented by digital values. When quantizing any analog source, the goal is to find the minimum number of representation levels required to describe the source while maintaining the resulting distortion below some threshold level. It is therefore clear that rate-distortion theory provides the fundamental limits on achievable compression rates and hence the quantizer’s size in bits given some distortion target and vice versa. Naturally, quantization finds applications in image processing, robotics, sensor networks, and machine learning, where it aids in the representation and transmission of continuous data [6, 18, 12]. Additionally, new quantization techniques are constantly developed and implemented to improve the efficiency of systems having hardware and storage capacity restrictions [14, 4, 23]. The Gaussian distribution has predominantly been used as a model for the continuous source in communications and information theory due to its unparalleled analytical tractability; the fact that it maximizes entropy among all distributions having finite second moments; and the Central Limit Theorem (CLT). However, Gaussian sources are not universal source models: for example, Gaussian models are not appropriate whenever the source is better characterized by heavy-tailed statistics. In fact, power law distributions111A density function f(x) is said to have a right (resp. left) tail power law if \lim f(x)|x|^{\alpha+1}=k for some k>0, as x\rightarrow+\infty (resp. -\infty). occur in many real-world data sets [5]. Under such scenarios, a family of probability distributions known as the \alpha-stable distributions222\alpha-stable distributions are power laws with 0<\alpha<2. represent a natural extension of the Gaussian law [1]. For instance, in [11], it is demonstrated that room noise is best represented by an \alpha-stable source, rather than a Gaussian one. Similarly, in [13], the noise for room acoustic channels is modeled as an \alpha-stable variable. The \alpha-stable distributions appear to provide a more suitable model than the Gaussian in various cases, making them reasonable candidates to investigate across different setups. The fact that \alpha-stable distributions possess infinite second moments [21] raises the following natural questions: What is an appropriate distortion measure when considering an \alpha-stable source in the rate-distortion problem? How can one choose the optimal quantization points when quantizing an \alpha-stable random source? The absence of a finite second moment for \alpha-stable distributions makes it inappropriate to use the Mean Square Error (MSE) as a distortion measure. Numerical attempts are nevertheless made as in [16] where the rate-distortion function for \alpha-stable sources is approximated using the Blahut-Arimoto algorithm [3]. Alternative metrics to the MSE such as Mean Square Root Absolute Error (MSRAE) and Mean Absolute Error (MAE) are used as distortion measures for quantizing \alpha-stable sources in the range \alpha\in[1,2] in [24]. However, these distortion measures exhibit limitations: 1- They are valid for certain ranges of \alpha (MAE is applicable when \alpha\geq 1 and MSRAE is valid for \alpha>0.5) 2- These metrics suffer from a discontinuity property; the MAE metric for example changes from being finite for \alpha=1-\epsilon, for some \epsilon>0, to infinite for \alpha=1+\epsilon. This is not natural as the source statistics remain “approximately” the same. Up to our knowledge, the literature lacks a unified theoretical analysis of the rate-distortion function of heavy-tailed sources. In this paper, we answer these questions by employing a strength quantity on the error as a distortion measure, a notion that was introduced in [8], and adopted later for the specific example of the Cauchy variable in [25] where the author investigated the rate-distortion function of a scalar Cauchy source. A key ingredient in the proof of [25] was in showing that the strength is convex for Cauchy mixtures. Unfortunately, the proof was not presented with sufficient details and is tightly related to the closed-form expression of the Cauchy Probability Density Function (PDF). Our main contributions are four-fold: • First, we generalize the Gaussian and Cauchy rate-distortion results to the family of symmetric \alpha-stable distributions by adopting a generic approach, one that does not rely on a “potential” convexity of the strength measure. This possible convexity is challenging to analyze given the general non closed-form expressions of the symmetric \alpha-stable PDFs. • Second, we provide rate-distortion results for \alpha-stable vector sources including the Cauchy case, where both the “sub-Gaussian” and independent \alpha-stable vectors are considered. • Third, we showcase that our proposed framework enables a systematic approach to quantizing not only \alpha-stable sources but also any heavy-tailed source; one that overcomes the drawbacks of using fractional lower order moments like the MAE and the MSRAE. Using our framework, we present an algorithm for designing a strength-optimal quantizer. We analyze the properties of such a quantizer and we apply the proposed algorithm to find a strength optimal quantizer for a Cauchy source. • Finally, we conduct an analytical analysis of the performance of uniform scalar quantizers in the high-rate regime under the strength measure. We conclude that, similarly to standard quantizers, there is little advantage in considering non-uniform quantizers over uniform ones at high rate. We further show that, for a specific strength labeled as the Cauchy-Based (CB)-strength, uniform quantization is asymptotically optimal. Through an example, we quantify the extra cost in terms of the number of representation points needed to achieve the same quantization quality for a Cauchy source compared to a Gaussian one. The rest of this paper is organized as follows: In Section 2 we present stable distributions and the notion of strength. The scalar rate-distortion result is presented in Section 3 where we derive the rate-distortion function of all stable sources under a strength constraint on the error. Extensions to the vector case in addition to the proofs of the results are deferred to Section 7. Section 4 is dedicated to finding strength-optimal quantizers and Section 5 discusses the performance of uniform quantizers in the high-rate regime. In Section 6, we consider the CB-strength and analyze the performance of both the uniform and non-uniform quantizers. Finally, Section 8 concludes the paper. Notations: Lowercase regular font symbols \{x,y,\cdots\} represent scalar deterministic quantities whereas uppercase ones \{X,Y,\cdots\} are scalar Random Variables (RV)s. Lowercase bold font characters \{{\bf x},{\bf y},\cdots\} are reserved for deterministic vector quantities and their uppercase counterparts \{\mathbf{X},\mathbf{Y},\cdots\} are random vectors. We denote by \textbf{X}^{n} a sequence of n vectors, i.e. \textbf{X}^{n} = (\textbf{X}_{1},\cdots,\textbf{X}_{n}), where each \textbf{X}_{k} is a vector in \mathbb{R}^{d}. We write \textbf{X}\overset{d}{=}{\bf Y} whenever they have identical probability laws."
https://arxiv.org/html/2411.08520v1,On the Design of Variable Modulation and Adaptive Modulation for Uplink Sparse Code Multiple Access,"Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme for enabling massive connectivity in next generation wireless networks. However, current SCMA codebooks are designed with the same size, leading to inflexibility of user grouping and supporting diverse data rates. To address this issue, we propose a variable modulation SCMA (VM-SCMA) that allows users to employ codebooks with different modulation orders. To guide the VM-SCMA design, a VM matrix (VMM) that assigns modulation orders based on the SCMA factor graph is first introduced. We formulate the VM-SCMA design using the proposed average inverse product distance and the asymptotic upper bound of sum-rate, and jointly optimize the VMM, VM codebooks, power and codebook allocations. The proposed VM-SCMA not only enables diverse date rates but also supports different modulation order combinations for each rate. Leveraging these distinct advantages, we further propose an adaptive VM-SCMA (AVM-SCMA) scheme which adaptively selects the rate and the corresponding VM codebooks to adapt to the users’ channel conditions by maximizing the proposed effective throughput. Simulation results show that the overall designs are able to simultaneously achieve a high-level system flexibility, enhanced error rate results, and significantly improved throughput performance, when compared to conventional SCMA schemes.","Non-orthogonal multiple access (NOMA) has been envisioned as a promising multiple access technique for future wireless networks, such as the beyond fifth generation (B5G) and sixth-generation (6G) networks, to address the increasing demand for high spectral efficiency and massive connectivity [1, 2, 3]. Unlike the conventional orthogonal multiple access (OMA) technologies, such as time division multiple access (TDMA) and orthogonal frequency division multiple access (OFDMA), NOMA users are allowed communicate simultaneously over the same radio resources, i.e., time and frequency resources [4]. Sparse code multiple access (SCMA), combines both modulation and spreading procedures, has been considered as a key candidate of the code-domain NOMA (CD-NOMA), and consequently has attracted a sustained research attention from both academia and industry [5, 6, 7, 8, 9]. Based on the well designed codebooks, the incoming message bits from SCMA users are directly mapped to multi-dimensional codewords [6], which are intentionally sparse so as to reduce the decoding complexity by employing the message passing algorithm (MPA). I-A Related Works Designing efficient sparse codebooks is considered as a fundamental approach to enhance the spectrum efficiency in SCMA. In [6], a multi-stage process for efficient codebook design was developed, consisting of the mother constellation (MC) and the user-specific constellations (e.g., shuffling, rotation angles) designs. In [10], the Star-QAM (quadrature amplitude modulation) signal constellation was employed to design the MC. In contrast, the golden angle modulated signals were utilized to design the MC with lower peak-to-average power ratio in [11]. Near-optimal codebook designs for SCMA schemes were investigated for different channel environments in [12]. Unlike the above works where the minimum Euclidean distance (MED) or minimum product distance (MPD) is employed to aid the codebook design, the codebooks reported in [13] and [14] were obtained by maximizing the constellation constrained input channel capacity and mutual information, respectively. More recently, a novel class of low-projection SCMA codebooks for ultra-low decoding complexity in downlink Ricain fading channels were proposed in [15]. It is noted that the above works mainly design SCMA codebooks based on a regular structure with same codebook size. Nevertheless, this implicitly assumes that the SCMA users sharing the same radio resources have a similar quality of service (QoS) requirement and channel condition [16], which may not be realistic in practical scenarios. To meet the diverse QoS requirements of SCMA users, an alternative approach is to perform user grouping and resource allocation at the base station (BS) [16, 17, 18], where a sum-rate is generally considered as the optimization metric. However, it is noted that the achievable sum-rate of SCMA systems relies heavily on the sparse codebooks [16]. Moreover, when the QoS requirement or channel condition of a SCMA user changes, the BS needs to re-allocate resources or re-group the users if the codebook with same codebook size is employed, which can result in excessive signaling overhead and unaffordable complexity at the BS. In a nutshell, current SCMA codebooks with the same modulation order pose a challenge for user-grouping and supporting diverse data rates. Adaptive modulation (AM) is an effective method for enhancing the spectral efficiency of SCMA by dynamically selecting the codebook with a suitable size (modulation order) based on the users’ channel conditions or service needs. The AM technique has been widely applied to wireless communication systems [19]. A systematic study on the improvement in spectral efficiency obtained by optimally varying combinations of the modulation order, power, and instantaneous bit-error rate (BER) was conducted in [19]. Recently, the AM schemes have been extensively studied in power-domain NOMA (PD-NOMA) systems [20, 21, 22]. For example, the joint adaptive M-quadrature amplitude modulation (M-QAM) and power adaptation for a downlink two-user PD-NOMA network was investigated in [21]. In contrast, an asymmetric AM framework is introduced in [22] for uplink PD-NOMA systems, where the closed-form BER expressions were derived. Despite the widespread investigation of SCMA in the literature, to the best of the authors’ knowledge, very little work has considered the spectral efficiency maximization problem for SCMA systems using AM technique. I-B Motivations and Contributions Despite the extensive literature on SCMA system designs, a few core issues have yet to be properly addressed. Firstly, existing SCMA systems treat all users equally and employ the codebook with the same modulation order, leading to inflexibility of supporting diverse data rates. Hence, it is pivotal to design a class of more flexible SCMA codebooks that enable diverse modulation orders whilst improving the error rate performance. Secondly, most resource management schemes on SCMA are based on Shannon theory, without placing any restrictions on the practical codebooks. Thirdly, the amalgamation of SCMA and AM is considered as a disruptive approach to further facilitate the system spectral efficiency. It is, however, challenging to investigate an adaptive codebook allocation scheme since the performance of the SCMA users are mutually coupled. To tackle the above issues, we first propose a novel SCMA scheme, called variable modulation SCMA (VM-SCMA) where SCMA users are allowed to employ codebooks with different codebook sizes (modulation orders). Hence, a fundamental problem in VM-SCMA is how to design efficient VM sparse codebooks. It is noted that the traditional MPD and MED based codebook design metrics may not be applicable since they are derived based on regular structure with the same modulation order [10, 11, 12, 15, 23]. In this paper, the sum-rate and pair-wise error probability (PEP) are employed to guide the VM codebook design. Considering the fairness of different users, we propose to minimize the error rate performance of the worst user. In addition, we consider a more realistic scenario where users are located at different locations within a cell. Accordingly, the near-far effect is taken into account in the design of VM-SCMA. Since the proposed VM-SCMA enables different modulation orders for a given overall date rate R_{b}, a fundamental problem naturally arises, i.e., how to adaptively select the R_{b} and the optimal VM codebooks according to the users’ statistical channel conditions. To this end, we propose to maximize the effective throughput of VM-SCMA systems subject to a reliable error rate constraint, which is referred to as adaptive VM-SCMA (AVM-SCMA) system. To summarize, the main contributions of this work are as follows: • We propose a novel uplink VM-SCMA system with randomly deployed users, which serves as a general framework and subsumes the existing SCMA systems as special cases. The average inverse product distance (AIPD) of a codebook and a symbiotic sum rate upper bound are derived to guide the VM-SCMA design. • We develop a VM matrix (VMM) that involves the modulation order assignment based on a factor graph to facilitate the VM codebook design. Moreover, low complexity solutions are developed for the design of VMM, near-optimal MCs, power allocation and codebook allocation. • To further enhance spectrum efficiency, we propose an AVM-SCMA, which adaptively chooses the VM codebooks based on users’ statistical signal-to-noise ratios (SNRs). An error rate performance model based on the received statistical SNRs is proposed to reduce the prohibitively high computational complexity of calculating the effective throughput of VM-SCMA. • We conduct extensive numerical experiments to show the superiority of the proposed VM-SCMA and AVM-SCMA schemes. The simulations demonstrate that the overall designs are able to simultaneously provide a high-level flexibility of supporting diverse data rates, and significantly improve error rate performance and throughput compared to conventional SCMA schemes. I-C Organization The remainder of this paper is organized as follows. Section II presents the SCMA system model with randomly deployed users. Section III presents the basic concepts of the proposed VM-SCMA. The sum-rate and error rate performance of VM-SCMA are investigated. Accordingly, the design of VM-SCMA is formulated. Next, the detailed design of VM-SCMA is presented in Section IV. Section V introduces the proposed AVM-SCMA by maximizing the effective throughput. Numerical results are presented in Section VI to validate the performance the proposed algorithms. Finally, concluding remarks are drawn in Section VII. I-D Notation The n-dimensional complex and binary vector spaces are denoted as \mathbb{C}^{n} and \mathbb{B}^{n}, respectively. Similarly, \mathbb{C}^{k\times n} and \mathbb{B}^{k\times n} denote the (k\times n)-dimensional complex and binary matrix spaces, respectively. {{\mathbf{I}}_{n}} denotes an n\times n-dimensional identity matrix. \text{tr}(\mathbf{X}) denotes the trace of a square matrix \mathbf{X}. \text{diag}(\mathbf{x}) gives a diagonal matrix with the diagonal vector of \mathbf{x}. (\cdot)^{\mathcal{T}}, (\cdot)^{\dagger} , (\cdot)^{\mathcal{H}} and \mathbb{E}(\cdot) denote the transpose, the conjugate, the Hermitian transpose, and expectation operation, respectively. \mathcal{CN}(0,1) denotes the standard Gaussian distribution with zero mean and unit variance. \|\mathbf{x}\|_{2} and |x| return the Euclidean norm of vector \mathbf{x} and the absolute value of x, respectively."
https://arxiv.org/html/2411.08509v2,Sum Rate Maximization for Movable Antenna-Aided Downlink RSMA Systems,"Rate splitting multiple access (RSMA) is regarded as a crucial and powerful physical layer (PHY) paradigm for next-generation communication systems. Particularly, users employ successive interference cancellation (SIC) to decode part of the interference while treating the remainder as noise. However, conventional RSMA systems rely on fixed-position antenna arrays, limiting their ability to fully exploit spatial diversity. This constraint reduces beamforming gain and significantly impairs RSMA performance. To address this problem, we propose a movable antenna (MA)-aided RSMA scheme that allows the antennas at the base station (BS) to dynamically adjust their positions. Our objective is to maximize the system sum rate of common and private messages by jointly optimizing the MA positions, beamforming matrix, and common rate allocation. To tackle the formulated non-convex problem, we apply fractional programming (FP) and develop an efficient two-stage, coarse-to-fine-grained searching (CFGS) algorithm to obtain high-quality solutions. Numerical results demonstrate that, with optimized antenna adjustments, the MA-enabled system achieves substantial performance and reliability improvements in RSMA over fixed-position antenna setups.","Multiple-input multiple-output (MIMO) technology, extensively studied and foundational to next-generation communication systems [1], relies on beamforming as a key technique. Beamforming, a critical technology in MIMO systems, leverages spatial domain freedom to achieve precise angular selectivity, effectively compensating for significant path loss. This spatial manipulation enhances signal quality and system performance by directing energy toward desired directions and minimizing interference. However, traditional antenna arrays are fixed in position, limiting their adaptability to dynamic channel conditions. As a result, they may struggle to maintain optimal performance in rapidly changing environments, underscoring the need for more flexible solutions. To overcome the limitations of fixed-position antennas (FPAs) and fully utilize spatial degrees of freedom (DoFs), the movable antenna (MA) and the fluid antenna (FA) have been introduced [2, 3, 4, 5]. By dynamically adjusting the antenna positions within the feasible regions to change the phases across various propagation paths, MAs and FAs can enhance the performance of wireless communication. Specifically, in [6], a base station (BS) served both a communication user and a sensing target, with fluid antennas equipped at both the BS and the communication user. This system enhanced the downlink communication rate by meeting sensing beam pattern gain requirements. As presented in [7], the authors investigated a full-duplex integrated sensing and communication (FD-ISAC) system assisted by MAs. They verified that an MA-aided flexible beamforming reduced self-interference and enhanced sensing and communication performance. As reported in [8], MAs sufficiently alleviated beam squint under a wideband multiple-input-single-output (MISO) scenario. In [9], an MA-aided ISAC system was enhanced with a reconfigurable intelligent surface (RIS) to improve communication and sensing performance in dead zones. In [10], the authors studied the utility of movable antennas in multiple-input single-output (MISO) interference channels, proposing an iterative algorithm to optimize MA positions and beamforming, enhancing performance and reducing transmitter complexity. On the other hand, rate splitting multiple access (RSMA) has emerged as a flexible and effective PHY-layer transmission paradigm for non-orthogonal transmission, interference management, and multiple access strategies envisioned for 6G [11]. By fully leveraging rate splitting (RS), beamforming, and successive interference cancellation (SIC), RSMA enables partial interference decoding while treating the remaining interference as noise.[12] proposed a robust beamforming and rate optimization algorithm to enhance spectral efficiency and transmission robustness in RIS-aided symbiotic radio systems using RSMA. In [13], a full-duplex cooperative rate-splitting scheme was proposed for downlink multicast, where cell-center users assisted cell-edge users via distributed beamforming and power-splitting for energy efficiency. [14] was the first work to propose an RSMA-based DFRC architecture. This approach maximized communication rates and improved radar sensing, achieving superior performance over SDMA-based DFRC without requiring additional radar sequences, simplifying the architecture, and enhancing system performance. However, a critical challenge remains, particularly in overloaded scenarios, where the limited beamforming gains from conventional fixed-position antenna arrays restrict RSMA’s performance potential. Inspired by these promising methods, we are motivated to investigate effective configuration strategies for MAs to fully leverage the spatial DoFs and enhance the RSMA system performance. Notably, no prior work has examined the integration of RSMA with MAs. To fill this gap, our work focuses on a downlink MA-aided RSMA system to maximize the sum rate. Our objective is to maximize the users’ sum rate by jointly optimizing beamforming matrices, splitting rates, and the positions of MAs. We employ an Alternating Optimization (AO) method to handle the coupled parameters. Specifically, to solve this non-convex problem, we use the Fractional Programming (FP) method from [15] to optimize the beamforming matrix and adopt a coarse-to-fine-grained searching (CFGS) method to identify high-quality sub-optimal antenna positions. Our contributions are summarized as follows. • To the best of our knowledge, this is the first study to examine the performance of MAs within an RSMA system. We formulate an optimization problem to maximize the sum rates of all users by jointly optimizing the beamforming matrix, common rate splitting, and antenna positions. • An FP framework is utilized to reformulate the objective function. We apply an AO method to handle the coupled optimization parameters, decomposing the problem into four sub-problems. Specifically, we propose an efficient algorithm based on a CFGS approach to update the antenna positions, leading to substantial performance improvements. • Numerical results demonstrate that the proposed MA-aided RSMA system outperforms the FPA configuration, achieving superior performance with our algorithm. Furthermore, our algorithm exhibits robustness across varying power budgets and user antenna configurations. Notations: \mathbf{x}(n), \mathbf{x}^{T}, \mathbf{x}^{*}, \text{Tr}(\mathbf{X})and (\mathbf{X})^{-1} denote the n^{th} entry of \mathbf{x}, the transpose of \mathbf{x}, the conjugate of \mathbf{x}, the trace of \mathbf{X} and the inverse of \mathbf{X}, respectively. Figure 1: System model of an MA-aided RSMA system."
https://arxiv.org/html/2411.08481v1,Variable-Length Feedback Codes via Deep Learning,"Variable-length feedback coding has the potential to significantly enhance communication reliability in finite block length scenarios by adapting coding strategies based on real-time receiver feedback. Designing such codes, however, is challenging. While deep learning (DL) has been employed to design sophisticated feedback codes, existing DL-aided feedback codes are predominantly fixed-length and suffer performance degradation in the high code rate regime, limiting their adaptability and efficiency. This paper introduces deep variable-length feedback (DeepVLF) code, a novel DL-aided variable-length feedback coding scheme. By segmenting messages into multiple bit groups and employing a threshold-based decoding mechanism for independent decoding of each bit group across successive communication rounds, DeepVLF outperforms existing DL-based feedback codes and establishes a new benchmark in feedback channel coding.","Channel coding in the presence of feedback has been a pivotal research area in information and coding theory for decades [1, 2, 3, 4, 5]. The classical feedback channel model, established by Shannon [1], involves data transmission from a transmitter to a receiver over a memoryless noisy channel, with the receiver providing real-time feedback to aid the forward channel coding. Although feedback does not increase the forward channel capacity, it significantly enhances communication reliability in the finite block length regime. A seminal example is the Schalkwijk-Kailath (SK) scheme [2], which achieves a double exponential decay of the block error rate with respect to the block length, underscoring the profound impact of feedback on error performance. Designing feedback channel codes is considerably more intricate than designing forward channel codes due to the necessity for real-time adjustments based on the receiver’s state [4, 5]. In forward channel coding, the coding strategy is fixed and depends only on the message, simplifying the code design. In contrast, feedback codes must dynamically adapt to the feedback, optimizing performance under varying channel conditions and receiver states. This complexity poses significant challenges in developing efficient and reliable feedback coding schemes. In recent years, deep learning (DL) has emerged as a promising approach for designing sophisticated communication systems, including feedback channel codes [6, 7, 8, 9, 10, 11, 12, 13]. DL models can learn complex encoding and decoding structures directly from data, capturing intricate patterns and dependencies inherent in the communication and feedback processes. A pioneering effort in this domain is DeepCode [6], where the authors proposed a framework utilizing bit-by-bit passive feedback – the receiver feeds back raw, noise-contaminated symbols without processing them. In DeepCode, recurrent neural networks (RNNs) at both the encoder and decoder create and exploit correlations among source bits and receiver feedback, improving decoding performance. AttentionCode [8] introduced attention mechanism-based deep neural networks (DNNs) to replace RNNs, enabling the creation of longer-range correlations among source bits and feedback. In conjunction with a bit alignment mechanism, AttentionCode achieved significantly lower block error rates (BLERs) compared to DeepCode. The state-of-the-art was improved significantly with the introduction of Generalized Block Attention Feedback (GBAF) codes [9], which partition message bits into small groups and perform group-level encoding and decoding using a sequence-to-sequence transformer architecture. This strategy efficiently reduces the input length to the DNN, thereby simplifying the learning process. Subsequent work [10] extended GBAF to active feedback scenarios, where the receiver processes the received signal before feeding it back to the transmitter. Additionally, LightCode [11] was proposed as a lightweight coding architecture that achieves performance comparable to GBAF but with significantly fewer learning parameters. Despite these advancements, existing DL-aided feedback codes are predominantly fixed-length, which limits their adaptability and may prevent them from fully exploiting the benefits of feedback. Moreover, these codes perform well in the low code rate regime – typically lower than 1/3 – but their performance deteriorates significantly as the code rate increases, where fewer channel uses are available for transmission. Contributions: To address these challenges, this paper introduces a novel DL-aided variable-length feedback code, termed deep variable-length feedback (DeepVLF) code. DeepVLF leverages multi-round feedback to achieve adaptive code rates with bit-group-level granularity, allowing the transmitter to adjust the amount of information transmitted based on the feedback. By dividing the message into bit groups and employing a threshold-based decoding strategy, each bit group can be decoded independently across different communication rounds. This approach reduces the total number of channel uses required to achieve the same performance as fixed-rate codes, particularly in high rate regimes. To jointly optimize the encoder and decoder, we develop a two-phase training strategy with a custom-designed loss function tailored to minimize the error rate of bit groups while adhering to power constraints. Numerical experiments demonstrate that DeepVLF sets a new state-of-the-art in feedback channel coding, especially in the high code rate regime."
https://arxiv.org/html/2411.08473v1,Fractional Fourier Domain PAPR Reduction,"High peak-to-average power ratio (PAPR) has long posed a challenge for multi-carrier systems, impacting amplifier efficiency and overall system performance. This paper introduces dynamic angle fractional Fourier division multiplexing (DA-FrFDM), an innovative multi-carrier system that effectively reduces PAPR for both QAM and Gaussian signals with minimal signaling overhead. DA-FrFDM leverages the fractional Fourier domain to balance PAPR characteristics between the time and frequency domains, achieving significant PAPR reduction while preserving signal quality. Furthermore, DA-FrFDM refines signal processing and enables one-tap equalization in the fractional Fourier domain through the simple multiplication of time-domain signals by a quadratic phase sequence. Our results show that DA-FrFDM not only outperforms existing PAPR reduction techniques but also retains efficient inter-carrier interference (ICI) mitigation capabilities in doubly dispersive channels.","Multi-carrier communication systems, such as orthogonal frequency division multiplexing (OFDM), are renowned for their high spectral efficiency and robustness against multi-path fading, making them a cornerstone in modern broadband wireless systems [1, 2, 3]. By dividing the available spectrum into several orthogonal subcarriers, these systems effectively handle high data rate transmissions over hostile wireless channels. This technique also simplifies the equalization process at the receiver end, which is crucial for maintaining signal integrity in multipath channels. Despite the numerous advantages, multi-carrier systems face a notable drawback: high peak-to-average power ratio (PAPR) [2]. High PAPR in the transmitted signal not only complicates the amplifier design but also forces the use of expensive and power-inefficient linear power amplifiers to avoid non-linear distortion. This issue is particularly critical as it directly impacts the energy efficiency and operational cost of wireless communication systems, making PAPR reduction a pivotal area of research [2, 4]. The emergence of new communication paradigms, such as joint source-channel coding (JSCC) [5], semantic communication [6, 7], and optical communications [8, 9], has introduced discrete-time Gaussian-amplitude signals, which are even more sensitive to PAPR-related issues. Consequently, these advancements amplify the need for more efficient and robust PAPR reduction techniques. In addressing the high PAPR in multi-carrier systems, a variety of reduction techniques have been developed [2, 10]. Traditional methods include clipping and filtering [11], which, while straightforward, can cause notable signal distortion. Selective Mapping (SLM) [12] and Partial Transmitted Sequence (PTS) [13] offer more controlled approaches by manipulating the phase of the signal to minimize PAPR. Coding techniques [14], on the other hand, provide a trade-off between bandwidth efficiency and system complexity. Other strategies, such as tone reservation[15] and tone injection[16], focus on utilizing reserved subcarriers to adjust the peak amplitude, potentially reducing the spectral efficiency or necessitating substantial additional signaling. Contributions: In this paper, we introduce dynamic angle fractional Fourier division multiplexing (DA-FrFDM), a novel multi-carrier system that significantly reduces PAPR for both QAM and Gaussian signals with minimal signaling overhead. The core insight driving our approach is that PAPR is mainly determined by the maximum amplitude of the signal within a given domain at a certain average power level. The PAPR characteristics of a signal generally exhibit a dual relationship between the time and frequency domains. Efforts to minimize PAPR in one domain often result in an increase in the other. For example, while QAM signals demonstrate advantageous PAPR properties in the time domain, they perform suboptimally in the frequency domain. This inherent duality has steered our exploration towards an intermediate domain – the fractional Fourier domain – which lies between the time and frequency domains. This novel approach opens up a more effective avenue for optimizing PAPR performance, harnessing the unique properties of the discrete fractional Fourier transform (DFrFT) [17, 18]. Our DA-FrFDM system presents three key advantages: • Low PAPR. DA-FrFDM achieves substantial PAPR reduction, outperforming existing techniques like clipping, PTS, and SLM, and efficiently handles both QAM and Gaussian signals. • Simple equalization. Unlike existing DFrFT-based systems that require complex channel manipulation, DA-FrFDM supports one-tap equalization in the fractional Fourier domain by simply multiplying the time-domain samples with a quadratic phase sequence. • Effective inter-carrier interference (ICI) mitigation in doubly dispersive channels. DA-FrFDM offers an inherent advantage over traditional OFDM systems by effectively mitigating ICI in frequency-selective and fast fading channels. We demonstrate that DA-FrFDM is capable of reducing PAPR without compromising its ICI mitigation capability."
https://arxiv.org/html/2411.08411v2,"Modeling and Optimization for Rotatable Antenna
Enabled Wireless Communication","Fluid antenna system (FAS)/movable antenna (MA) has emerged as a promising technology to fully exploit the spatial degrees of freedom (DoFs). In this paper, we propose a new rotatable antenna (RA) model, as a simplified implementation of six-dimensional movable antenna (6DMA), to improve the performance of wireless communication systems. Different from conventional fixed-position antenna (FPA), the proposed RA system can independently and flexibly change the three-dimensional (3D) orientation of each antenna by adjusting its declination angles to achieve desired channel realizations. Specifically, we study an RA-enabled uplink communication system, where the receive beamforming and the declination angles of all RAs are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal declination angles are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the base station (BS). In the general multi-user and multi-path setup, we propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the declination angles in an iterative manner. Simulation results are provided to demonstrate that the proposed RA-enabled system can significantly outperform other benchmark schemes.","In the rapidly evolving landscape of global information and communications technology (ICT), the forthcoming sixth-generation (6G) wireless network is envisioned to support even more densely-connected users and devices across more diverse applications and services, thus demanding superior communication and sensing performance beyond the current fifth-generation (5G) wireless network [1]. To further improve transmission rate and spectrum efficiency, wireless network tends to adopt drastically more antennas and more advanced multiple-input-multiple-output (MIMO) technologies at both the base stations (BSs) and user/device terminals [2]. Although larger-scale MIMO can offer more substantial array and spatial multiplexing gains, it comes at the expense of higher hardware cost and power consumption. Furthermore, increasing the number of antennas cannot fully exploit the spatial degrees of freedom (DoFs) since the traditional fixed-position antennas (FPAs) cannot change their positions or orientations flexibly once deployed. To overcome this limitation, fluid antenna system (FAS)/movable antenna (MA) has been proposed to enable the local movement of antennas in a specified region through different antenna movement mechanisms [3, 4, 5, 6, 7]. As compared to FPA, FAS/MA can proactively transform the wireless channels into a more favorable condition and thus achieve higher capacity without increasing the number of antennas. However, FAS/MA mainly adjusts the positions of antennas with their rotations fixed, and its practical implementation is constrained by the response time or movement speed of the antennas. Recently, six-dimensional movable antenna (6DMA) has been proposed to flexibly adjust both the three-dimensional (3D) position and 3D rotation of distributed antennas/arrays based on the user spatial distribution [8, 9]. Although 6DMA provides a general model for position and rotation adjustable antennas, its implementation requires drastic changes of current antenna architectures of existing BSs and thus may be practically cost-prohibitive. Motivated by the above, we propose in this paper a new antenna architecture, namely rotatable antenna (RA), as a simplified implementation of 6DMA to improve the performance of wireless communications. In the RA system, the declination angles of each antenna/array can be independently adjusted to change its 3D orientation while its 3D position is kept constant to reduce the hardware cost and time/energy overhead for antenna position changes in 6DMA. Under this new model, we investigate an RA-enabled uplink multi-user communication system. Specifically, we aim to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users by jointly optimizing the receive beamforming and the declination angles of all RAs. For the special single-user and free-space propagation setup, the maximum-ratio combining (MRC) beamformer is applied and the optimal declination angles are derived in closed form to maximize the channel power gain. For the general multi-user and multi-path setup, an alternating optimization (AO) algorithm is proposed to alternately optimize the receive beamforming and the declination angles in an iterative way. In particular, the subproblem that optimizes the declination angles is transformed into a pointing vector optimization problem, which is then solved by the successive convex optimization (SCA) technique to obtain a high-quality suboptimal solution with low complexity. Simulation results show that our proposed RA-enabled system with optimized declination angles can achieve a much higher SINR as compared to various benchmark schemes."
https://arxiv.org/html/2411.08284v1,Dynamic Thresholding Algorithm with Memory for Linear Inverse Problems,"The relaxed optimal k-thresholding pursuit (ROTP) is a recent algorithm for linear inverse problems. This algorithm is based on the optimal k-thresholding technique which performs vector thresholding and error metric reduction simultaneously. Although ROTP can be used to solve small to medium-sized linear inverse problems, the computational cost of this algorithm is high when solving large-scale problems. By merging the optimal k-thresholding technique and iterative method with memory as well as optimization with sparse search directions, we propose the so-called dynamic thresholding algorithm with memory (DTAM), which iteratively and dynamically selects vector bases to construct the problem solution. At every step, the algorithm uses more than one or all iterates generated so far to construct a new search direction, and solves only the small-sized quadratic subproblems at every iteration. Thus the computational complexity of DTAM is remarkably lower than that of ROTP-type methods. It turns out that DTAM can locate the solution of linear inverse problems if the matrix involved satisfies the restricted isometry property. Experiments on synthetic data, audio signal reconstruction and image denoising demonstrate that the proposed algorithm performs comparably to several mainstream thresholding and greedy algorithms, and it works much faster than the ROTP-type algorithms especially when the sparsity level of signal is relatively low.","A typical linear inverse problem is to reconstruct unknown data d\in\mathbb{R}^{n} via some linear measurements y\in\mathbb{R}^{m} subject to noise effects: \displaystyle y=Bd+\nu, (1.1) where B\in\mathbb{R}^{m\times n} is a given measurement matrix with m\ll n, and \nu\in\mathbb{R}^{m} is a noise vector. This problem arises in many scenarios, where the number of measurements m is much smaller than the length of the target vector d. For instance, when using CT for medical diagnosis, it is expected to use as little radiation dose as possible in order to reduce the impact of radiation on the patient. Also, in the same and many other application scenarios, the target signal often admits certain special structure that makes it possible to reconstruct the signal from the underdetermined system (1.1). In fact, many natural signals and images can be sparsely represented under some orthogonal linear transforms (e.g., discrete wavelet transforms). As a result, we may assume that the target data d can be represented as d=\Phi^{T}x, where \Phi\in\mathbb{R}^{n\times n} is a transform matrix and the vector x\in\mathbb{R}^{n} is sparse (or compressible in the sense that it can be approximated by a sparse vector). In such cases, reconstructing d via solving the linear inverse problem (1.1) amounts to recovering a sparse (or compressible) vector x through the following system: \displaystyle y=Ax+\nu, (1.2) where A=B\Phi^{T}\in\mathbb{R}^{m\times n} is still called the measurement matrix. As the solution x of this problem is sparse, the problem above can be referred to as a sparse linear inverse problem. This problem has a wide range of applications in such areas as image processing [25, 42], wireless communication [6, 11, 26], sensor networks [9, 10], to name a few. The system (1.2) can be reformulated as the sparse optimization problem \displaystyle\underset{x\in\mathbb{R}^{n}}{\min}\{{\left\|y-Ax\right\|}_{2}^{2% }:\left\|x\right\|_{0}\leq k\}, (1.3) where k is a given integer number reflecting the sparsity level of x, and \left\|\cdot\right\|_{0} denotes the number of nonzero entries of a vector. For the convenience of discussion, we list the main abbreviations used in the paper in Table 1. Table 1: List of Abbreviations Abbreviation Full Name DTAM Dynamic thresholding algorithm with memory DWT Discrete wavelet transform EDOMP Enhanced dynamic orthogonal matching pursuit [49] gOMP Generalized orthogonal matching pursuit [40] NTP Natural thresholding pursuit [48] OMP Orthogonal matching pursuit [18, 38] PGROTP Partial gradient relaxed optimal k-thresholding pursuit [32] PSNR Peak signal-to-noise ratio RIC Restricted isometry constant RIP Restricted isometry property ROTP Relaxed optimal k-thresholding pursuit [45] ROTP\omega ROTP with \omega times of data compression at each iteration [45] SNR Signal-to-noise ratio SP Subspace pursuit [12] StOMP Stagewise orthogonal matching pursuit [16] Thresholding is a large class of widely used algorithms for sparse optimization problems (1.3). This class of algorithms includes the hard thresholding [4, 5, 19, 24, 30, 36, 41], optimal k-thresholding [31, 32, 37, 45, 47], soft thresholding [3, 6, 13, 15, 17, 28, 44], and the recent natural thresholding pursuit [48]. Although the hard thresholding selecting indices of a few largest magnitudes of a vector can guarantee the iterates generated by the algorithm are feasible to (1.3), it is generally not an optimal thresholding approach from the viewpoint of minimizing the error metric \|y-Ax\|_{2}^{2}, as pointed out in [45]. Thus a more sophisticated data compression method called the optimal k-thresholding was first introduced in [45], based on which the family of optimal k-thresholding algorithms, termed ROTP\omega, were proposed in [45], where \omega reflects the times of data compression in every iteration. Although ROTP\omega is generally more stable and robust for solving linear inverse problems than hard thresholding and greedy algorithms [45, 47], its computational cost remains high since the algorithm needs to solve quadratic optimization subproblems in the course of iteration. To reduce the cost, some modifications of ROTP\omega using acceleration or linearization techniques have been proposed recently [21, 32, 37, 48]. For instance, PGROTP [32] and the heavy-ball-based ROTP [37] were developed by incorporating the partial gradient and heavy-ball acceleration into ROTP (ROTP\omega with \omega=1), respectively. Numerical results indicate that PGROTP can be faster than ROTP2 [32]. However, PGROTP is still time-consuming when solving large-scale problems. It is worth mentioning that the natural thresholding pursuit (NTP) in [48], using linearization of quadratic subproblem, remarkably reduces the complexity of ROTP-type algorithms. In addition, the stochastic counterpart of NTP was recently developed in [21] for sparse optimization problems. Except for thresholding algorithms, the greedy methods are also a popular class of algorithms for solving sparse linear inverse problems. OMP is one of such greedy algorithms [18, 38] which gradually identifies the support of solution to the problem by selecting only one index in each iteration. The index selected by OMP corresponds to the largest absolute component of the gradient of error metric, i.e., the objective function in (1.3). The OMP and its modified versions were analyzed in such references as [8, 14, 34]. However, theoretical and numerical results indicate that OMP tends to be inefficient as the sparsity level k becomes large. The main reason for this might be that when k is relatively large and when the large magnitudes are close to each other, there is no guarantee for a correct index being selected by the OMP procedure, and many significant indices corresponding to large magnitudes in gradient are completely discarded at every iteration. This means most useful information conveyed by the gradient of the current iterate is ignored in OMP procedure. Motivated by this observation, several modifications of OMP with different index selection criteria were introduced, including gOMP [40], StOMP [16], EDOMP [49] and SP [12]. For instance, at every iteration, gOMP picks a fixed number, K, of the largest magnitudes of gradient. However, such a selection rule might result in a wrong index set especially when the gradient is s-sparse with s<K since in such a case the algorithm have to pick more indices than necessary. On the contrary, StOMP and EDOMP adopt certain dynamic index selection criteria whose purpose is to efficiently use the information of significant gradient components. EDOMP is generally stable, robust and efficient for sparse signal recovery, although the convergence of EDOMP has not yet established at present [49]. Inspired by the dynamic index selection strategies in StOMP [16] and EDOMP [49] and iterative methods with memory [1, 27, 35], we propose a new algorithm called dynamic thresholding algorithm with memory (DTAM) in this paper. The algorithm is different from existing ones in three aspects: (i) The iterative search direction in this method is a combination of the gradients of more than one or all iterates generated so far by the algorithm instead of the only gradient for the current iterate. (ii) The index selection in this algorithm is dynamic according to a rule defined by a generalized mean function [46] evaluated at the current search direction with memory. It should be pointed out that the generalized mean function is used for the first time to serve such a purpose. (iii) The algorithm adopts a novel dimensionality reduction strategy based on the sparsity of iterative point and search direction. The key idea here is to reduce a high-dimensional quadratic optimization problem to a low-dimensional one whose dimension is at most twice of the sparsity level of the solution to the linear inverse problem. We also carry out a rigorous analysis of DTAM to establish an error bound which measures the distance between the solution of the problem and iterates generated by the algorithm. The error bound is established under the restricted isometry property (RIP). It implies that DTAM is guaranteed to locate the k-sparse solution of linear inverse problem if the matrix satisfies the RIP of order 3k. Moreover, as a byproduct of our analysis, the convergence of PGROTP with \bar{q}=k is also obtained in this paper for the first time, which is given in Corollary 3.9. The numerical performances of DTAM and several existing algorithms including PGROTP [32], NTP [48], StOMP [16], SP [12] and OMP [18, 38] are compared through experiments on threes types of sparse linear inverse problems: The problems with synthetic data, practical audio signal reconstruction and image denoising. Numerical results indicate that the proposed algorithm does perform very well for solving linear inverse problems compared with several existing algorithms, and it works faster than PGROTP. The paper is organized as follows. In Section 2, we introduce some useful inequalities, generalized mean functions, the PGROTP algorithm, and the new algorithm DTAM. The analysis of DTAM is performed in Section 3. Numerical results are reported in Section 4, and the conclusions are given in last section."
https://arxiv.org/html/2411.08258v1,Efficient encoding and decoding algorithm for a class of perfect single-deletion-correcting permutation codes,"A permutation code is a nonlinear code whose codewords are permutation of a set of symbols. We consider the use of permutation code in the deletion channel, and consider the symbol-invariant error model, meaning that the values of the symbols that are not removed are not affected by the deletion. In 1992, Levenshtein gave a construction of perfect single-deletion-correcting permutation codes that attain the maximum code size. Furthermore, he showed in the same paper that the set of all permutations of a given length can be partitioned into permutation codes so constructed. This construction relies on the binary Varshamov-Tenengolts codes. In this paper we give an independent and more direct proof of Levenshtein’s result that does not depend on the Varshamov-Tenengolts code. Using the new approach, we devise efficient encoding and decoding algorithms that correct one deletion.","A permutation code over an alphabet of size n is a code in which each codeword contains all elements in the alphabet once and exactly once. The basic properties of permutation codes, with the use of the Hamming distance as a design metric, have been documented in prior works [1, 2]. Moreover, a table of permutation codes with their Hamming distances can be found in [3]. One key feature of permutation codes is that all symbols are used equally often, and thus can be used to combat jamming. As a result, permutation codes have found use in frequency-hopping digital communication systems, such as power-line communication [4]. More recently, permutation codes have also been applied in wireless communication with short block lengths [5, 6]. Another important application of permutation codes is in the context of Flash memory [7]. In Flash memory, data is encoded using the relative voltage levels between memory cells, rather than the absolute voltage levels, due to the difficulty in controlling the latter with high accuracy. This naturally leads to the use of permutation codes, as each codeword corresponds to a unique arrangement of the voltage levels. For this application, distance measures such as the Ulam distance and the Kendall’s \tau distance can model the system more accurately than the Hamming distance. In the literature, deletions in permutation codes can be classified into two categories: stable deletion and unstable deletion [8]. In the case of stable deletion, the values of the intact symbols are not affected by the deleted symbol. If the codeword is a permutation, the receiver knows which symbols are missing, but does not know the locations where the deletions occurred. This error model has applications in DNA-based storage, for example. An excellent introduction to single-permutation-correcting permutation codes can be found in [9]. In the second, “unstable” model, the receiver does not have information about the absolute values of the remaining symbols, but only knows their relative values. Consequently, the channel output is a permutation with a shorter block length. This paper will focus on permutation codes designed for the correction of stable deletions. In the context of combinatorics, permutation codes can be interpreted as directed t-designs and directed t-packings [10]. This connection stems from the fact that a permutation code can correct any d deletions if and only if all subsequences of the codewords of length n-d are distinct. A directed t-packing consists of a ground set \mathcal{X} and a collection \mathcal{B} of ordered k-subsets of \mathcal{X}, where every ordered t-subset appears in at most one ordered subset in \mathcal{B}. When |\mathcal{X}|=n=k, this is equivalent to a permutation code that can correct n-t deletions. Furthermore, if every ordered t-subset appears in exactly one ordered k-subset in \mathcal{B}, then we have a directed t-design, or a directed t-Steiner system. The corresponding permutation code is also said to be perfect [11]. In [12], Levenshtein studied perfect permutation codes that can correct a single deletion [12]. His construction was based on the binary Varshamov–Tenengolts (VT) code [13]. In this paper, we provide a more direct proof of the correctness of this construction, and devise fast encoding and decoding algorithms that do not rely on the VT code. We review the basic definitions of the VT code below. A binary VT code of length n is a set of binary vectors (b_{1},b_{2},\ldots,b_{n}) that satisfy the equation \sum_{j=1}^{n}jb_{j}=k\bmod(n+1) for some constant k. The VT code was originally introduced in [13] to combat asymmetric bit errors. Later, Levenshtein showed in [14] that the VT code can also correct a single deletion, and provided an efficient decoding method. A fast encoding algorithm for the VT code was later given by Abdel-Ghaffar and Ferreira in [15]. Building on the VT code, Tenengolts introduced a non-binary version and provided a linear-time decoding algorithm [16]. Leveraging this non-binary VT code, Levenshtein proved in [12] that by restricting the codewords to permutations, the result is a perfect 1-deletion permutation code. We will refer to this construction as the Levenshtein’s permutation code in this paper. Given a vector (x_{0},x_{1},\ldots,x_{n-1}), where x_{j} are integers between 0 and n-1, the signature of this vector is defined as a binary vector of length n-1, where the j-th component is 1 if x_{j}\geq x_{j-1}, and 0 if x_{j}<x_{j-1}, for j=1,2,\ldots,n-1. Levenshtein proved in [12] that the set of all permutations of length n whose signatures are codewords in a VT code of length n-1 forms a permutation code that can correct a single deletion. Furthermore, Levenshtein also showed in the same paper that the set of all permutations of length n can be partitioned into n perfect 1-deletion permutation codes. We will see that this latter result also follows from the new approach proposed in this paper. While Levenshtein’s permutation code construction is well-studied, efficient encoding and decoding algorithms have not been readily available until recently. The work in [17] provided a linear-time encoding algorithm, but the corresponding decoding algorithm may take O(n^{2}) time. In this paper, we present both encoding and decoding algorithms that have fast implementations. Encoding can be done in O(n^{1+\epsilon}) time, where n is the length of the permutation, and \epsilon>0 is a constant. The time complexity of recovering the data from a deleted codeword is O(n\log n). So, both encoding and decoding have quasi-linear time complexity. For encoding and decoding algorithms for other nonlinear codes that can correct deletions and insertions, we refer the readers to in [18, 19] for more information. The extension from permutation codes to multi-permutation codes is a rapidly growing area of research. Motivated by applications in DNA storage, codes that can correct burst deletions are of great practical interest. A codeword in a multi-permutation code contains all the symbols a constant number of times, thus enabling more flexibility in code design in compare to permutation codes. Burst-deletion-correcting permutation and multi-permutation codes have been studied extensively in recent works [20, 21, 22, 17, 23]. Constructions of codes that can correct both deletions and substitutions have also been investigated [24, 25]. This paper is organized as follows. In Sections 2 and 3, we review the preliminaries for permutations, the symmetric group, and permutation codes. Using a representation of permutations described in Section 4, we then give an alternate description of Levenshtein’s permutation code construction in Section 5. The main theorem of this paper is presented in Section 6, and the proof of a technical theorem is given in Section 7. Finally, in Section 8, we describe efficient encoding and decoding algorithms for Levenshtein’s permutation code."
https://arxiv.org/html/2411.08233v1,Improved Constructions of Skew-Tolerant Gray Codes,"We study skew-tolerant Gray codes, which are Gray codes in which changes in consecutive codewords occur in adjacent positions. We present the first construction of asymptotically non-vanishing skew-tolerant Gray codes, offering an exponential improvement over the known construction. We also provide linear-time encoding and decoding algorithms for our codes. Finally, we extend the definition to non-binary alphabets, and provide constructions of complete m-ary skew-tolerant Gray codes for every base m\geqslant 3.","Ever since their introduction [6], Gray codes have been of great interest both for their practical applications in data communications and storage, and for the theoretical problems that arise from their study. In their original forms, Gray codes are listings of all binary n-tuples, without repetitions, and with the added restrictions that consecutive tuples differ by a single bit flip. Multiple variants have been extensively investigated, and are still today, such as snake-in-the-box codes [12, 19, 1], circuit codes [13, 15, 8, 10], and single-track Gray codes [7, 5, 18, 8, 10], to name a few. Moreover, Gray codes have inspired the idea of finding listings of combinatorial objects such that there is only a small change from one element to the next. They have thus been extended to codes over subspaces [17, 2], permutations [27, 11, 29, 9, 30, 24, 28], and a multitude of other structures. We refer the reader to the classical survey [16] and the more recent survey [14] for a comprehensive review of Gray codes. In [26], Wilson and Blaum defined skew-tolerant Gray codes as Gray codes such that changes in consecutive codewords occur in adjacent positions. Their motivation behind this definition was to allow for better performance in mechanical encoder systems where the reading head might be skewed. In Figure 1(a), a surface contains distinct binary vectors of length 4 written as rows of a matrix. Four sensors are mounted on a reading head (denoted by \otimes), and the head moves vertically. By reading the binary vector beneath it, it can deduce its position. However, if it attempts to do so in-between two rows, each sensor may independently read the bit below or above it. If more than one bit is in question, the resulting reading may be neither the vector immediately below the head’s position, nor the one immediately above it. This may result in a location error. To avoid this, the rows form a binary Gray code, namely, a single bit changes between any two consecutive rows. Thus, even if getting a reading in-between rows, the resulting reading is the entire vector immediately above or below the reading-head location. When the reading head is mounted with a skew, even if we use a (general) binary Gray code, more than one sensor may see a bit change at some moment, as seen in Figure 1(b). As [26] shows, by using a skew-tolerant Gray code, the skew angle at which the system operates without any location error is maximized. Another major advantage of skew-tolerant Gray codes is that they can be easily compressed, as they are completely determined by the first codeword, the position of the first bit flip, and a sequence of directions (right, left) that indicate the next change position. Thus, only \Theta(1) bits per codeword are needed for storage. \begin{overpic}[scale={0.3}]{sktgc1.pdf} \put(60.0,52.5){$\otimes$} \put(27.0,-5.0){\scriptsize{(a)}} \put(10.0,47.0){\scriptsize$\begin{array}[]{cccc}0&0&0&0\\ 0&0&0&1\\ 0&0&1&1\\ 0&0&1&0\\ 0&1&1&0\\ 0&1&1&1\\ 0&1&0&1\\ 0&1&0&0\\ 1&1&0&0\\ 1&1&0&1\\ 1&1&1&1\\ 1&1&1&0\\ 1&0&1&0\\ 1&0&1&1\\ 1&0&0&1\\ 1&0&0&0\\ \end{array}$} \end{overpic} \begin{overpic}[scale={0.3}]{sktgc2.pdf} \put(60.0,57.5){$\otimes$} \put(27.0,-5.0){\scriptsize{(b)}} \put(10.0,49.0){\scriptsize$\begin{array}[]{cccc}0&0&0&0\\ 0&0&0&1\\ 0&0&1&1\\ 0&0&1&0\\ 0&1&1&0\\ 0&1&1&1\\ 0&1&0&1\\ 0&1&0&0\\ 1&1&0&0\\ 1&1&0&1\\ 1&1&1&1\\ 1&1&1&0\\ 1&0&1&0\\ 1&0&1&1\\ 1&0&0&1\\ 1&0&0&0\\ \end{array}$} \end{overpic} Figure 1: Reading heads mounted over a surface (a) without a skew, and (b) with a skew. Wilson and Blaum’s definition is equivalent to the \overline{P_{n}}-compatible Gray codes defined previously by Slater in [20] and [21], where P_{n} represents the path graph of n vertices. Several other works have studied Gray codes compatible with more general graphs, like trees with infinite diameter [25], hypercubes [4] and complete multipartite graphs [3]. The only attempt at constructing large skew-tolerant Gray codes that we know of is that of [26]. The size of the known codes of n bits is of the order of (\sqrt{3})^{n} codewords, which is exponentially smaller than the theoretical bound of 2^{n} codewords, namely, a complete code. Slater [21] conjectured that no complete skew-tolerant (\overline{P_{n}}-compatible) Gray code exists for n\geqslant 7. This leaves open the question: what is the largest possible skew-tolerant Gray code with length of n bits? The main contribution of this work is to present a construction of asymptotically non-vanishing skew-tolerant Gray codes. More precisely, we present codes of length n and size \approx c\cdot 2^{n} with c a constant that depends on the parity of n. For n even, c>0.76, and for n odd c>0.84. Thus, our codes offer an exponential improvement over the codes of [26]. We also study the generalization of these codes to larger alphabets, and show that for any alphabet size m\geqslant 3, there are complete skew-tolerant Gray codes. This work is organized as follows: in Section II we introduce the definition of k-skew-tolerant Gray codes (k-SkTGCs), as well as necessary notations used throughout the paper. In Section III we start by studying 3-SkTGCs and 2-SkTGCs, showing that complete codes are possible. By using a similar approach, we then construct asymptotically non-vanishing 1-SkTGCs. We also provide linear-time encoding and decoding algorithms for all constructed binary codes. Finally, in Section IV we generalize the definition of skew-tolerant Gray codes to non-binary alphabets, and we show that it is always possible to construct complete m-ary skew-tolerant Gray codes of any length."
https://arxiv.org/html/2411.07600v1,Decision Feedback In-Context Symbol Detection over Block-Fading Channels,"Pre-trained Transformers, through in-context learning (ICL), have demonstrated exceptional capabilities to adapt to new tasks using example prompts without model update. Transformer-based wireless receivers, where prompts consist of the pilot data in the form of transmitted and received signal pairs, have shown high estimation accuracy when pilot data are abundant. However, pilot information is often costly and limited in practice. In this work, we propose the DEcision Feedback IN-ContExt Detection (DEFINED) solution as a new wireless receiver design, which bypasses channel estimation and directly performs symbol detection using the (sometimes extremely) limited pilot data. The key innovation in DEFINED is the proposed decision feedback mechanism in ICL, where we sequentially incorporate the detected symbols into the prompts to improve the detections for subsequent symbols. Extensive experiments across a broad range of wireless communication settings demonstrate that DEFINED achieves significant performance improvements, in some cases only needing a single pilot pair.","Wireless receiver symbol detection focuses on identifying the transmitted symbols over fading channels with varying signal-to-noise ratios (SNRs). Traditional methods typically follow a two-step process: first estimating the channel using, e.g., the Minimum Mean Square Error (MMSE) estimator, and then performing symbol detection using the estimated channel. However, this approach can be computationally intensive and is impacted by the channel estimation quality. Data-driven approaches, such as deep learning models that directly learn channel estimators and symbol detectors, offer an alternative. Recurrent Neural Networks (RNNs)[1] and Convolutional Neural Networks (CNNs)[2] have been investigated for this task. However, deep neural networks (DNNs) require large amount of data and often perform poorly in the low-data regime. Moreover, adapting pre-trained DNNs to new wireless conditions remains a challenge [3]. Advances in Transformer models, particularly decoder-only architectures like GPT [4], have demonstrated impressive performance across various fields. Recent result [5] shows that pre-trained Transformers can adapt to new tasks during inference through prompt pairs, without requiring explicit model updates. Given an input of the form (y_{1},f(y_{1}),\ldots,y_{n},f(y_{n}),y_{\text{query}}), a pre-trained Transformer can approximate f(y_{\text{query}}) based on the provided context, where (y_{1},\ldots,y_{n},y_{\text{query}}) represents features and f can represent various classes of functions [6]. Wireless symbol detection, which involves estimating transmitted symbols from noisy received signals, aligns well with the Transformer capabilities. [7] introduced Transformers for this task using in-context learning, framing it as a regression problem with MSE loss and achieving near-MMSE performance. Later works expanded this framework: [8] extended it to MIMO systems, and [9] demonstrated robustness in multi-user MIMO environments. Meanwhile, [10] used language models to reformulate detection as a linguistic task. These advances highlight Transformers as a powerful tool for addressing wireless communication challenges. Despite these successes, prior studies face limitations. Most approaches treat detection as a regression task, requiring MSE-based objectives and post-processing to map continuous outputs to discrete symbols. Additionally, many require ample pilot pairs, which may not be possible in practice, and large models increase inference costs, limiting real-world feasibility. Inspired by decision feedback in wireless communication (e.g., decision feedback equalizer over multi-path fading channels), we enhance the prompt design by incorporating decision pairs, combining current signals with model detections to improve subsequent detection. Our DEFINED model uses a carefully designed mixture training process to achieve high performance with limited pilots (sometimes only a single pilot) and maintain accuracy with sufficient pilots. Extensive experiments across modulation schemes validate our approach’s effectiveness. To summarize, our main contributions include: • We develop a Transformer model that jointly performs channel estimation and symbol detection, departing from prior work that separates these tasks. Our key innovation is the incorporation of decision feedback to improve accuracy and adaptability. • We design a mixed training process that achieves high performance with limited pilots and strong accuracy with abundant pilots, enhancing model practicality for deployment. • We validate our approach with experiments across multiple modulation schemes."
https://arxiv.org/html/2411.07558v2,"Discrete-Valued Signal Estimation 
via Low-Complexity Message Passing Algorithm

for Highly Correlated Measurements","This paper considers a discrete-valued signal estimation scheme based on a low-complexity Bayesian optimal message passing algorithm (MPA) for solving massive linear inverse problems under highly correlated measurements. Gaussian belief propagation (GaBP) can be derived by applying the central limit theorem (CLT)-based Gaussian approximation to the sum-product algorithm (SPA) operating on a dense factor graph (FG), while matched filter (MF)-expectation propagation (EP) can be obtained based on the EP framework tailored for the same FG. Generalized approximate message passing (GAMP) can be found by applying a rigorous approximation technique for both of them in the large-system limit, and these three MPAs perform signal detection using MF by assuming large-scale uncorrelated observations. However, each of them has a different inherent self-noise suppression mechanism, which makes a significant difference in the robustness against the correlation of the observations when we apply an annealed discrete denoiser (ADD) that adaptively controls its nonlinearity with the inverse temperature parameter corresponding to the number of iterations. In this paper, we unravel the mechanism of this interesting phenomenon, and further demonstrate the practical applicability of the low-complexity Bayesian optimal MPA with ADD under highly correlated measurements.","Consider a discrete-valued signal estimation from a noisy linear measurement expressed as \bm{y}=\bm{A}\bm{x}+\bm{w}, (1) where \bm{x}\triangleq\left[x_{1},x_{2},\ldots,x_{M}\right]^{\mathsf{T}}\in\mathcal{% X}^{M\times 1} denotes an unknown discrete-valued signal vector, each element of which is selected independently from a finite countable set \mathcal{X}, \bm{A}\in\mathbb{C}^{N\times M} denotes a known measurement matrix, and \bm{w} denotes a complex circularly symmetric111 A random variable X is circularly symmetric when X and Xe^{\mathrm{j}\theta} follow the same distribution for all \theta\in[0,2\pi) [1]. independent and identically distributed (i.i.d.) additive white Gaussian noise (AWGN) vector, each element of which has zero mean and variance \sigma_{\mathrm{w}}^{2}. Many estimation problems in various engineering fields, such as physical layer signal processing in wireless communications [2, 3, 4, 5, 6, 7, 8] and digital image processing [9, 10, 11], can be formulated as discrete-valued signal estimation problems based on (1). Our goal in this paper is to estimate the unknown discrete-valued vector \bm{x} based on perfect knowledge of \bm{y},\,\bm{A},\,\sigma_{\mathrm{w}}^{2}, and a prior probability distribution of \bm{x}. As is well known, the optimal discrete-valued signal estimation scheme is based on the maximum a posteriori probability (MAP) or minimum mean square error (MMSE) criterion, which are, however, practically infeasible in a large system since these methods are essentially equivalent to an exhaustive search over the entire space of \mathcal{X}^{M\times 1} and lead to an exponentially growing computational complexity, i.e., \mathcal{O}\left(|\mathcal{X}|^{M}\right). In contrast, linear filters, such as matched filter (MF) and linear MMSE (LMMSE) filter, are often employed as naive low-complexity detection schemes, but they can achieve favorable performance only in sufficiently overdetermined (i.e., N\gg M) systems and when N and M are of the same order, their performance inevitably degrades [5]. In order to achieve large-scale linear inference (i.e., M,N\gg 1) with low-complexity and high-accuracy, various message passing algorithms (MPAs) have been investigated [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]. Among these, approximate message passing (AMP) [14] and its extension to general linear observations, i.e., generalized AMP (GAMP) [15], have attracted considerable attention from both theoretical and practical perspectives. The remarkable advantage of AMP is its ability to asymptotically converge to the Bayesian optimal (i.e., MMSE) solution in the large-system limit for arbitrary prior distributions with minimal computational complexity of \mathcal{O}(MN) per iteration, provided that \bm{A} is composed of i.i.d. Gaussian random variables with mean zero and its state evolution (SE) has a unique fixed point [23, 24, 25]. The most well-known derivation of AMP is a method for approximating the sum-product algorithm (SPA) operating on a dense factor graph (FG) in the large-system limit222 The idealized system assumption, where the input and output dimensions, M and N, respectively, are infinity for a given compression ratio \xi\triangleq N/M. [23]. According to [26]333This conference paper is an earlier version of this paper, which was presented at the IEEE ICC 2022., the derivation process can be divided into 1) a Gaussian approximation of the message based on the central limit theorem (CLT) and 2) a large-system limit approximation of the message moments, and the MPA obtained by completing step 1) is equivalent to the very well-known naive belief propagation (BP) algorithm called approximate belief propagation (ABP) [12] or Gaussian belief propagation (GaBP) [13]. In other words, GaBP is found as an intermediate step in deriving AMP from SPA, and AMP can be systematically derived in the large-system limit of GaBP under the ideal statistical assumption. Expectation propagation (EP) [27, 28, 29] is another well-known framework that derives AMP differently from BP. EP is one of the approximate inference frameworks first proposed in [27]. It approximates the true posterior distribution of an unknown signal with a tractable distribution belonging to the exponential distribution family by minimizing their Kullback-Leibler divergence (KLD). A plethora of MPAs based on EP have been proposed [16, 17, 18, 20, 30, 31], including orthogonal AMP (OAMP) [32] and vector AMP (VAMP) [19], and rigorous theoretical analyses of their dynamics have been provided [33, 34]. According to these results, the EP algorithm operating on a dense FG can also be interpreted as approximated BP with the minimal complexity order, and their message update rules are derived by projecting the posterior distribution of the unknown signal onto the Gaussian distribution based on moment matching (MM) technique. Henceforth, we will refer to this algorithm as matched filter EP (MF-EP) so as to distinguish it from the LMMSE-based EP algorithm where the latter guarantees Bayesian optimality for unitarily invariant observations[19, 20]. It is worth noting here that, as expected, AMP can be rigorously derived by applying a large-system limit approximation to MF-EP [17]. Under the ideal statistical assumption of i.i.d. zero-mean Gaussian measurements, all Bayesian optimal MPAs with the minimal complexity order of \mathcal{O}(MN) converge to a unique form of (G)AMP in the large-system limit[23, 24, 25]. Bayesian optimal MPA always has a mechanism to suppress (decouple) the self-noise feedback due to its iterative structure, which enables convergence to the optimal solution through the exchange of extrinsic information across iterations. The key difference among GaBP, MF-EP, and GAMP lies in the method of generating this extrinsic information. GaBP inherits the algorithmic structure of SPA, where each of the nodes comprising the FG generates extrinsic information by combining the likelihood information excluding feedback components from its own nodes [12, 13]. In MF-EP, in contrast to GaBP, each node fully combines all propagated likelihood information, including its own, and after projecting it into a tractable distribution, the extrinsic information is generated by a division operation on the resulting message domain [17]. In the large-system limit condition, these two mechanisms for suppressing self-noise feedback converge on a mechanism called Onsager correction, which predicts and decouples the effect of self-noise feedback across iterations in GAMP [14, 15]. As would be expected from their Bayesian optimality, these three algorithms exhibit similar behavior and achieve comparable estimation accuracy under conditions of (nearly ideal) large-scale uncorrelated observations. Nevertheless, many practical systems do not preserve such ideal conditions, and thus their behaviors become analytically less tractable. In fact, due to their unique self-noise suppression mechanisms, these MPAs exhibit substantially different levels of robustness against correlated observations as we demonstrate in this paper. Based on the study on this intriguing phenomenon, we aim to propose an advanced and effective strategy for achieving accurate discrete-valued signal estimation with minimal complexity even under highly correlated measurements, challenging the conventional understanding that low-complexity MPAs only work under the idealized and limited condition. To assist the generation of extrinsic information under non-ideal conditions, the key technique used in this work is belief scaling [13]. The reason why the performance of these MPAs deteriorates significantly under highly correlated measurements is that when the estimated (Gaussian) distribution of the propagated messages (i.e., beliefs) cannot sufficiently describe the actual stochastic behavior of the effective noise, the accuracy of the conditional expectation (i.e., soft replicas) computed by a denoiser deteriorates due to model errors [35, 36, 37]. In particular, for discrete-valued signal estimation, the denoiser has nonlinearity due to the discrete constraints of the unknown signal, but if the shape (softness of the denoiser curve) deviates from an appropriate value due to the model error of the beliefs, severe error propagation occurs in the early iterations, considerably hindering the exchange of proper extrinsic information and resulting in low estimation accuracy. As a highly effective solution to mitigate such potential issues, belief scaling has been proposed in the context of multi-input multi-output (MIMO) detections [13], which controls the convergence speed by adaptively adjusting the nonlinearity of the denoiser using parameters according to belief variance (i.e., instantaneous reliability) and to the predetermined number of iterations. This methodology has been shown to be highly effective for improving poor convergence properties caused by finite-sized practical system configurations [38, 39, 40, 41], and/or a mild correlation in observations [42, 43], and is generalized in this paper as an annealed discrete denoiser (ADD) that is independent of the discrete prior of the unknown signal and/or the employed MPA. Based on the above, in this paper, we consider the comparative study of the performance differences among GaBP, MF-EP, and GAMP adopting ADD in the estimation of discrete-valued signal under highly correlated measurements, both theoretically and numerically. Surprisingly, numerical simulations show that both MF-EP and GAMP with ADD significantly improve the performance in highly correlated measurements, comparable to or even superior to LMMSE-EP, which requires iterative LMMSE filtering. It is worth noting here that such a dramatic improvement is not seen in GaBP, which means that these three MPAs, whose structures asymptotically converge under the idealized large-system limit condition, exhibit completely different robustness against measurement correlations when using ADD. This astonishing performance improvement observed in MF-EP and GAMP is due to their potential ability to exchange accurate extrinsic information even under correlated observations with the aid of ADD. To unravel the mechanism of this interesting phenomenon, we will formulate a theoretical hypothesis based on the algorithmic structure, and then verify it by introducing a matrix that visualizes the statistical correlation structure between the propagated beliefs, and by studying its dynamics across iterations, as well as the actual behavior of beliefs. The contributions of this paper are summarized as follows: • Assuming that each element of \bm{A} follows a circularly symmetric distribution, we describe the detailed process of deriving GAMP from GaBP for an arbitrary (not limited to discrete-valued) unknown vector \bm{x}. The derivation process presented here is an extension of the derivation in [26], which assumes a real-valued system, to a complex-valued one using the Wirtinger derivative and Taylor expansion. A similar derivation approach is presented in [44] for the real-valued system, and in [38, 45] for bilinear inference, but to the best of our knowledge, there is no direct derivation from GaBP to GAMP in general complex-valued systems, which would provide a theoretical basis for elucidating the relationship among GaBP, MF-EP, and GAMP. • By interpreting the scaling parameter as an inverse temperature parameter corresponding to the number of iterations, the belief scaling method proposed in the context of GaBP-based MIMO detection [13] can be generalized as the ADD that is independent of the discrete prior of the unknown signal and/or the employed MPA. Furthermore, we compare the discrete-valued signal estimation performance of GaBP, MF-EP, and GAMP using ADD in a simulation of correlated massive MIMO detection, and the results reveal that 1) the performance of the three algorithms is quite different and 2) MF-EP and GAMP achieve better performance than LMMSE-EP even in highly correlated measurements. • In order to elucidate the differences in signal detection performance and the dramatic performance improvements observed in the above simulations, we analyze the behavior of each algorithm in terms of the self-noise suppression mechanism and perform numerical studies to verify the hypothesis derived from this analysis. The numerical analysis of the algorithm dynamics reveals that the timing of self-noise suppression in the iterative process, i.e., the relative position with respect to (w.r.t.) the denoiser, significantly changes the correlation structure between beliefs, allowing to describe the dramatic performance improvement in MF-EP and GAMP due to ADD. Notation: Sets of real and complex numbers are denoted by \mathbb{R} and \mathbb{C}. Vectors and matrices are denoted in lower- and upper-case bold-face fonts, respectively. The conjugate and transpose are denoted by (\cdot)^{*} and (\cdot)^{\mathsf{T}}, respectively. The real and imaginary parts of a complex quantity are denoted by \Re[\cdot] and \Im[\cdot], and the imaginary unit by \mathrm{j}\triangleq\sqrt{-1}. The K\times K identity matrix is denoted by \bm{I}_{K}. For any countable finite set \mathcal{A}, the number of elements in \mathcal{A} is denoted by |\mathcal{A}|. The i-th element of a vector \bm{a} and the (i,j)-th element of a matrix \bm{A} are denoted by [\bm{a}]_{i} and [\bm{A}]_{i,j}, respectively. The complex circularly symmetric Gaussian distribution with a mean vector \bm{\mu} and a covariance matrix \bm{\varLambda} is denoted by \mathcal{CN}\left(\bm{\mu},\bm{\varLambda}\right). The notation a\sim\mathcal{P} indicates a random variable a follows a probability distribution \mathcal{P}. The probability mass function (PMF), probability density function (PDF), and expectation w.r.t. random variable a are denoted by P_{\mathsf{a}}[\cdot],\,p_{\mathsf{a}}(\cdot), and \mathbb{E}_{\mathsf{a}}[\cdot], respectively. In addition, the conditional PDF and expectation w.r.t. a given the realized value b^{\prime} of random variable b are denoted by p_{\mathsf{a}\mid\mathsf{b}}(\cdot\mid b^{\prime}) and \mathbb{E}_{\mathsf{a}\mid\mathsf{b}=b^{\prime}}[\cdot], respectively. For brevity, we use the notation \sum_{i\neq j}^{I}a_{i}\triangleq\sum_{i=1}^{I}a_{i}-a_{j}, \prod_{i\neq j}^{I}a_{i}\triangleq\left(\prod_{i=1}^{I}a_{i}\right)/a_{j}, and \int f(\bm{a})\,\mathrm{d}\bm{a}_{\backslash j}\triangleq\int\cdots\int f(\bm{% a})\,\prod_{i\neq j}^{I}\mathrm{d}a_{i} for a multiple integral of any function f:\mathbb{C}^{I\times 1}\to\mathbb{R} w.r.t. all the elements in vector \bm{a}=[a_{1},a_{2},\ldots,a_{I}]^{\mathsf{T}}\in\mathbb{C}^{I\times 1} except for a_{j}. Finally, the notation \mathcal{O}(\cdot) denotes the complexity order unless otherwise specified."
https://arxiv.org/html/2411.07473v1,Nearly-Linear Time Seeded Extractors with Short Seeds,"Seeded extractors are fundamental objects in pseudorandomness and cryptography, and a deep line of work has designed polynomial-time seeded extractors with nearly-optimal parameters. However, existing constructions of seeded extractors with short seed length and large output length run in time \Omega(n\log(1/\varepsilon)) and often slower, where n is the input source length and \varepsilon is the error of the extractor. Since cryptographic applications of extractors require \varepsilon to be small, the resulting runtime makes these extractors unusable in practice.Motivated by this, we explore constructions of strong seeded extractors with short seeds computable in nearly-linear time O(n\log^{c}n), for any error \varepsilon. We show that an appropriate combination of modern condensers and classical approaches for constructing seeded extractors for high min-entropy sources yields strong extractors for n-bit sources with any min-entropy k and any target error \varepsilon with seed length d=O(\log(n/\varepsilon)) and output length m=(1-\eta)k for an arbitrarily small constant \eta>0, running in nearly-linear time, after a reasonable one-time preprocessing step (finding a primitive element of \mathds{F}_{q} with q=\operatorname{poly}(n/\varepsilon) a power of 2) that is only required when k<2^{C\log^{*}\!n}\cdot\log^{2}(n/\varepsilon), for a constant C>0 and \log^{*}\! the iterated logarithm, and which can be implemented in time \operatorname{polylog}(n/\varepsilon) under mild conditions on q. As a second contribution, we give an instantiation of Trevisan’s extractor that can be evaluated in truly linear time in the RAM model, as long as the number of output bits is at most \frac{n}{\log(1/\varepsilon)\operatorname{polylog}(n)}. Previous fast implementations of Trevisan’s extractor ran in \widetilde{O}(n) time in this setting. In particular, these extractors directly yield privacy amplification protocols with the same time complexity and output length, and communication complexity equal to their seed length.","Seeded randomness extractors are central objects in the theory of pseudorandomness. A strong (k,\varepsilon)-seeded extractor is a deterministic function \mathsf{Ext}\colon\mathopen{}\mathclose{{}\left\{{0,1}}\right\}^{n}\times% \mathopen{}\mathclose{{}\left\{{0,1}}\right\}^{d}\to\mathopen{}\mathclose{{}% \left\{{0,1}}\right\}^{m} that receives as input an n-bit source of randomness X with k bits of min-entropy111A random variable X has k bits of min-entropy if \Pr[X=x]\leq 2^{-k} for all x. Min-entropy has been the most common measure for the quality of a weak source of randomness since the work of Chor and Goldreich [CG88]. and a d-bit independent and uniformly random seed Y, and outputs an m-bit string \mathsf{Ext}(X,Y) that is \varepsilon-close in statistical distance to the uniform distribution over \mathopen{}\mathclose{{}\left\{{0,1}}\right\}^{m}, where \varepsilon is an error term, even when the seed Y is revealed. Besides their most direct application to the generation of nearly-perfect randomness from imperfect physical sources of randomness (and their inaugural applications to derandomizing space-bounded computation [NZ96] and privacy amplification [BBCM95]), seeded extractors have also found many other surprising applications throughout computer science, particularly in cryptography. For most applications, it is important to minimize the seed length of the extractor. A standard application of the probabilistic method shows the existence of strong (k,\varepsilon)-seeded extractors with seed length d=\log(n-k)+2\log(1/\varepsilon)+O(1) and output length m=k-2\log(1/\varepsilon)-O(1), and we also know that these parameters are optimal up to the O(1) terms [RT00]. This motivated a deep line of research devising explicit constructions of seeded extractors with seed length as small as possible spanning more than a decade (e.g., [NZ96, SZ99, NT99, Tre01, TZS06, SU05]) and culminating in extractors with essentially optimal seed length [LRVW03, GUV09]. In particular, the beautiful work of Guruswami, Umans, and Vadhan [GUV09] gives explicit strong extractors with order-optimal seed length d=O(\log(n/\varepsilon)) and output length m=(1-\eta)k for any constant \delta>0, and follow-up work [DKSS13, TU12] further improved the entropy loss k+d-m. The extractors constructed in these works are explicit, in the sense that there is an algorithm that given x and y computes the corresponding output \mathsf{Ext}(x,y) in time polynomial in the input length. A closer look shows that the short-seed constructions presented in the literature all run in time \Omega(n\log(1/\varepsilon)), and often significantly slower. In cryptographic applications of extractors we want the error guarantee \varepsilon to be small, which means that implementations running in time \Omega(n\log(1/\varepsilon)) are often impractical. If we insist on nearly-linear runtime for arbitrary error \varepsilon, we can use strong seeded extractors based on universal hash functions that can be implemented in O(n\log n) time (e.g., see [HT16]), have essentially optimal output length, but have the severe drawback of requiring a very large seed length d=\Omega(m). These limitations have been noted in a series of works studying concrete implementations of seeded extractors, with practical applications in quantum cryptography in mind [MPS12, FWE+23, FYEC24]. For example, Foreman, Yeung, Edgington, and Curchod [FYEC24] implement a version of Trevisan’s extractor [Tre01, RRV02] with its standard instantiation of Reed–Solomon codes concatenated with the Hadmadard code, and emphasize its excessive running time as a major reason towards non-adoption.222The reason why these works focus on Trevisan’s extractor is that this is the best seeded extractor (in terms of asymptotic seed length) that is known to be secure against quantum adversaries [DPVR12]. Instead, they have to rely on extractors based on universal hash functions, which, as mentioned above, are fast but require very large seeds. This state of affairs motivates the following question, which is the main focus of this work: Can we construct strong (k,\varepsilon)-seeded extractors with seed length d=O(\log(n/\varepsilon)) and output length m=(1-\eta)k computable in nearly-linear time, for arbitrary error \varepsilon? Progress on this problem would immediately lead to faster implementations of many cryptographic protocols that use seeded extractors. 1.1 Our Contributions We make progress on the construction of nearly-linear time extractors. Seeded extractors with order-optimal seed length and large output length. We construct nearly-linear time strong seeded extractors with order-optimal seed length and large output length for any k and \varepsilon, with the caveat that they require a one-time preprocessing step whenever k=O(\log^{2}(n/\varepsilon)). This preprocessing step corresponds to finding primitive elements of finite fields \mathds{F}_{q} with q=\operatorname{poly}(n/\varepsilon), which, as we discuss below, is reasonable in practical applications. More precisely, we have the following result. Theorem 1. For any constant \eta>0 there exists a constant C>0 such that the following holds. For any positive integers n and k\leq n and any \varepsilon>0 satisfying k\geq C\log(n/\varepsilon) there exists a strong (k,\varepsilon)-seeded extractor \mathsf{Ext}\colon\{0,1\}^{n}\times\{0,1\}^{d}\to\{0,1\}^{m} with seed length d\leq C\log(n/\varepsilon) and output length m\geq(1-\eta)k. Furthermore, • if k\geq 2^{C\log^{*}\!n}\cdot\log^{2}(n/\varepsilon), then \mathsf{Ext} is computable in time \widetilde{O}(n), where \widetilde{O}(\cdot) hides polylogarithmic factors in its argument and \log^{*}\! denotes the iterated logarithm; • if k<2^{C\log^{*}\!n}\cdot\log^{2}(n/\varepsilon), then \mathsf{Ext} is computable in time \widetilde{O}(n) after a preprocessing step, corresponding to finding a primitive element of \mathds{F}_{q} with q=\operatorname{poly}(n/\varepsilon) a power of 2.333In full rigor, the preprocessing step corresponds to finding primitive elements of O(\log\log n) fields \mathds{F}_{q} with orders q\leq\operatorname{poly}(n/\varepsilon), each a power of 2. This O(\log\log n) term has negligible influence on the complexity of this preprocessing step. Note that we can find such a primitive element in time \operatorname{polylog}(n/\varepsilon) if q\leq\operatorname{poly}(n/\varepsilon) is a power of 2 and we know the factorization of q-1, but we do not know how to do that in time \widetilde{O}(\log q). More precisely, given the factorization of q-1 we can test whether a given \alpha\in\mathds{F}_{q} is primitive in time \operatorname{polylog}(q) by checking whether \alpha^{\frac{q-1}{p}}\neq 1 for all prime factors p of q-1. We can exploit this in various ways. If we are fine with using randomness in the one-time preprocessing stage, then we can sample an element of \mathds{F}_{q} uniformly at random, test whether it is primitive, and repeat if not. If we insist on a deterministic algorithm, then we can combine the testing procedure with algorithms of Shoup [Sho90] or Shparlinski [Shp92] which identify in time \operatorname{polylog}(q) a subset of size \operatorname{polylog}(q) in \mathds{F}_{q} that is guaranteed to contain a primitive element. For an alternative faster randomized algorithm, see [DD06]. 1 follows from combining modern condensers with short seeds (namely, the lossless condenser of Kalev and Ta-Shma [KT22] and the lossy Reed-Solomon-based condenser of Guruswami, Umans, and Vadhan [GUV09]) with a careful combination and instantiation of classical recursive approaches developed by Srinivasan and Zuckerman [SZ99] and in [GUV09]. It readily implies, among other things, an \widetilde{O}(n)-time privacy amplification protocol where only O(\log(n/\varepsilon)) bits need to be communicated over the one-way authenticated public channel and almost all the min-entropy can be extracted (after a reasonable one-time preprocessing step if the min-entropy bound k is very small). A new non-recursive construction. As a conceptual contribution which may be of independent interest, we present a new “non-recursive” construction of extractors with seed length O(\log(n/\varepsilon)) and output length (1-\eta)k that is computable in nearly-linear time when k>\operatorname{polylog}(1/\varepsilon) and avoids the complicated recursive procedures from [SZ99, GUV09]. We believe this to be a conceptually better approach towards constructing seeded extractors, and we discuss it in more detail in the technical overview. Faster instantiations of Trevisan’s extractor. One of the most widely-used explicit seeded extractors is Trevisan’s extractor [Tre01, RRV02]. While by now we have extractors with better parameters, one of its main advantages is that it is one of the few examples of extractors, and in a sense the best one, which are known to be quantum proof.444An extractor is quantum proof if its output is close to uniform even in the presence of a quantum adversary that has some (bounded) correlation with X. A bit more formally, \mathsf{Ext} is quantum-proof if for all classical-quantum state \rho_{XE} (where E is a quantum state correlated with X) with H_{\infty}(X|E)\geq k, and a uniform seed Y, it holds that \rho_{\mathsf{Ext}(X,Y)YE}\approx_{\varepsilon}\rho_{U_{m}}\otimes\rho_{Y}% \otimes\rho_{E}. See [DPVR12] for more details. Trevisan’s extractor uses two basic primitives: combinatorial designs (when more than one output bit is desired), and binary list-decodable codes. A standard instantiation of such suitable codes goes by concatenating a Reed-Solomon code with a Hadamard code, and this is also what is considered in [FWE+23, FYEC24]. As they also observe, this gives a nearly-linear time construction when the output length m=1. In fact, by leveraging fast multipoint evaluation, one can also get a nearly-linear time construction for any output length m\leq\frac{n}{\log(1/\varepsilon)}, although this was not noted in previous works.555For a rigorous statement on fast multipoint evaluation, see Lemma 2.1. Our main contribution in this direction is an alternative instantiation of Trevisan’s extractor that can be computed in truly linear time on a RAM in the logarithmic cost model, for any output length m\leq\frac{n}{\log(1/\varepsilon)\cdot\operatorname{polylog}(n)}. Theorem 2. There exists an instantiation of Trevisan’s extractor, set to extract m bits with any error \varepsilon>0, that is computable in: 1. Time O(n)+m\log(1/\varepsilon)\cdot\operatorname{polylog}(n) after a preprocessing step running in time \widetilde{O}(m\log(n/\varepsilon)), on a RAM in the logarithmic cost model. In particular, there exists a universal constant c, such that whenever m\leq\frac{n}{\log(1/\varepsilon)\cdot\log^{c}(n)}, the instantiation runs in time O(n), without the need for a preprocessing step. 2. Time \widetilde{O}(n+m\log(1/\varepsilon)) in the Turing model. We note that one interesting instantiation of the above theorem is when Trevisan’s extractor is set to output k^{\Omega(1)} bits for k=n^{\Omega(1)}. In this setting, Trevisan’s extractor requires a seed of length O\mathopen{}\mathclose{{}\left(\frac{\log^{2}(n/\varepsilon)}{\log(1/% \varepsilon)}}\right), and, as long as \varepsilon is not too tiny, we get truly-linear runtime. 1.2 Other Related Work Besides the long line of work focusing on improved constructions of explicit seeded extractors and mentioned in the introduction above, other works have studied randomness extraction in a variety of restricted computational models. These include extractors computable by streaming algorithms [BRST02], local algorithms [Lu02, Vad04, BG13, CL18], AC0 circuits [GVW15, CL18, CW24], AC0 circuits with a layer of parity gates [HIV22], NC1 circuits [CW24], and low-degree polynomials [ACG+22, AGMR24, GGH+24]. Moreover, implementations in various restricted computational models of other fundamental pseudorandomness primitives such as k-wise and \varepsilon-biased generators, that often play a key role in constructions of various types of extractors, have also been independently studied (see [HV06, Hea08, CRSW13, MRRR14] for a very partial list). As mentioned briefly above, some works have also focused on constructing seeded extractors computable in time O(n\log n) motivated by applications in privacy amplification for quantum key distribution. Such constructions are based on hash functions, and are thus far restricted to \Omega(m) seed length. The work of Hayashi and Tsurumaru [HT16] presents an extensive discussion of such efforts. We also mention that nearly-linear time extractors with very short seed, in the regime k=n^{\Omega(1)} and \varepsilon=n^{-o(1)}, were given in [DMOZ22], with applications in derandomization. 1.3 Technical Overview In a nutshell, we obtain 1 by following two standard high-level steps: 1. We apply a randomness condenser with small seed length O(\log(n/\varepsilon)) to the original n-bit weak source X to obtain an output X^{\prime} that is \varepsilon-close to a high min-entropy source. 2. We apply a seeded extractor tailored to high min-entropy sources with small seed length O(\log(n/\varepsilon)) to X^{\prime} to obtain a long output that is \varepsilon-close to uniform. To realize this approach, we need to implement each of these steps in nearly-linear time \widetilde{O}(n) (possibly after a reasonable one-time preprocessing step). We briefly discuss how we achieve this, and some pitfalls we encounter along the way. Observations about nearly-linear time condensers. In order to implement Item 1, we need to use fast condensers with short seeds. Luckily for us, some existing state-of-the-art constructions of condensers already satisfy this property, although, to the best of our knowledge, this has not been observed before. We argue this carefully in Section 3.3. For example, the “lossy Reed-Solomon condenser” from [GUV09] interprets the source as a polynomial f\in\mathds{F}_{q}[x] of degree d\leq n/\log q and the seed y as an element of \mathds{F}_{q}, and outputs \mathsf{RSCond}(f,y)=(f(y),f(\zeta y),\dots,f(\zeta^{m^{\prime}}y)), for an appropriate m^{\prime} and field size q, with \zeta a primitive element of \mathds{F}_{q}. Evaluating \mathsf{RSCond}(f,y) corresponds to evaluating the same polynomial f on multiple points in \mathds{F}_{q}. This is an instance of the classical problem of multipoint evaluation in computational algebra, for which we know fast and practical algorithms (e.g., see [vzGG13, Chapter 10] or Lemma 2.1) running in time \widetilde{O}((d+m^{\prime})\log q)=\widetilde{O}(n), since d\leq n/\log q and if m^{\prime}\leq n/\log q. A downside of this condenser is that it requires knowing a primitive element \zeta of \mathds{F}_{q} with q=\operatorname{poly}(n/\varepsilon). As discussed above, if we know the factorization of q-1 and q is a power of 2, then we can find such a primitive element in time \operatorname{polylog}(q). Beyond that, having access to such primitive elements, which only need to be computed once independently of the source and seed, is reasonable in practice. Therefore, we may leave this as a one-time preprocessing step. The lossless “KT condenser” from [KT22] has a similar flavor. It interprets the source as a polynomial f\in\mathds{F}_{q}[x] and the seed y as an evaluation point, and outputs \mathsf{KTCond}(f,y)=(f(y),f^{\prime}(y),\dots,f^{(m^{\prime})}(y)), for some appropriate m^{\prime}. The problem of evaluating several derivatives of the same polynomial f on the same point y (sometimes referred to as Hermite evaluation) is closely related to the multipoint evaluation problem above, and can also be solved in time \widetilde{O}(n).666Interestingly, recent works used other useful computational properties of the KT condenser. Cheng and Wu [CW24] crucially use the fact that the KT condenser can be computed in NC1. Doron and Tell [DT23] use the fact that the KT condenser is logspace computable for applications in space-bounded derandomization. Evaluating the KT condenser does not require preprocessing. On the other hand, it only works when the min-entropy k\geq C\log^{2}(n/\varepsilon) for a large constant C>0, where n is the source length and \varepsilon the target error of the condenser. The “ideal” approach to seeded extraction from high min-entropy sources. We have seen that there are fast condensers with short seeds. It remains to realize Item 2. Because of the initial condensing step, we may essentially assume that our n-bit weak source X has min-entropy k\geq(1-\delta)n, for an arbitrarily small constant \delta>0. In this case, we would like to realize in time \widetilde{O}(n) and with overall seed length O(\log(n/\varepsilon)) what we see as the most natural approach to seeded extraction from high min-entropy sources: 1. Use a fresh short seed to transform X into a block source Z=Z_{1}\circ Z_{2}\circ\cdots\circ Z_{t} with geometrically decreasing blocks, where \circ denotes string concatenation. A block source has the property that each block Z_{i} has good min-entropy even conditioned on the values of blocks Z_{1},\dots,Z_{i-1}. 2. Perform block source extraction on Z using another fresh short seed. Due to its special structure, we can extract a long random string from Z using only the (small) seed length associated with extracting randomness from the smallest block Z_{t}, which has length O(\log(n/\varepsilon)). The classical approach to Item 2 where we iteratively apply extractors based on universal hash functions with increasing output lengths to the blocks of Z from right to left is easily seen to run in time \widetilde{O}(n) and requires a seed of length O(\log(n/\varepsilon)) if, e.g., we use the practical extractors of [TSSR11, HT16]. Therefore, we only need to worry about realizing Item 1. A standard approach to Item 1 would be to use an averaging sampler to iteratively sample subsequences of X as the successive blocks of the block source Z, following a classical strategy of Nisan and Zuckerman [NZ96] (improved by [RSW06, Vad04]). We do know averaging samplers running in time \widetilde{O}(n) (such as those based on random walks on a carefully chosen expander graph). However, this approach requires a fresh seed of length \Theta(\log(n/\varepsilon)) per block of Z. Since Z will have roughly \log n blocks, this leads to an overall seed of length \Theta(\log^{2}n+\log(1/\varepsilon)), which is too much for us. Instead, we provide a new analysis of a sampler based on bounded independence, that runs in time \widetilde{O}(n) and only requires a seed of length O(\log(n/\varepsilon)) to create the entire desired block source. We give the construction, which may be of independent interest, in Section 3.2. The caveat of this “block source creator” is that it only works as desired when the target error \varepsilon\geq 2^{-k^{c}} for some small constant c>0. Combining these realizations of Items 1 and 2 yields the desired \widetilde{O}(n)-time extractor with order-optimal seed length O(\log(n/\varepsilon)) and output length (1-\eta)n for arbitrary constant \eta>0, provided that \varepsilon\geq 2^{-k^{c}}. See Theorem 5.1 for the formal statement. Getting around the limitation of the ideal approach. We saw above that combining the ideal approach to seeded extraction from high min-entropy sources with the new analysis of the bounded independence sampler yields a conceptually simple construction with the desired properties when the error is not too small (or alternatively, whenever the entropy guarantee is large enough). However, we would like to have \widetilde{O}(n)-time seeded extraction with O(\log(n/\varepsilon)) seed length and large output length for all ranges of parameters. To get around this limitation of our first construction, it is natural to turn to other classical approaches for constructing nearly-optimal extractors for high min-entropy sources, such as those of Srinivasan and Zuckerman [SZ99] or Guruswami, Umans, and Vadhan [GUV09]. These approaches consist of intricate recursive procedures combining a variety of combinatorial objects, and require a careful analysis.777In our view, these approaches are much less conceptually appealing than the “ideal” approach above. We believe that obtaining conceptually simpler constructions of fast nearly-optimal extractors that work for all errors is a worthwhile research direction, even if one does not improve on the best existing parameters. However, we could not find such an approach that works as is, even when instantiated with \widetilde{O}(n)-time condensers and \widetilde{O}(n)-time hash-based extractors. In particular: • The GUV approach [GUV09] gives explicit seeded extractors with large output length and order-optimal seed length for any min-entropy requirement k and error \varepsilon. However, its overall runtime is significantly larger than \widetilde{O}(n) whenever \varepsilon is not extremely small (for example, \varepsilon=2^{-k^{\alpha}} for some \alpha\in(0,1/2) is not small enough). • The SZ approach [SZ99] can be made to run in time \widetilde{O}(n) and have large output length when instantiated with fast condensers, samplers, and hash-based extractors, but it is constrained to error \varepsilon\geq 2^{-ck/\log^{*}\!n}, where \log^{*} is the iterated logarithm. Fortunately, the pros and cons of the GUV and SZ approaches complement each other. Therefore, we can obtain our desired result by applying appropriately instantiated versions of the GUV and SZ approaches depending on the regime of \varepsilon we are targeting. 1.4 Future Work We list here some directions for future work: • Remove the preprocessing step that our constructions behind 1 require when k<C\log^{2}(n/\varepsilon). • On the practical side, develop concrete implementations of seeded extractors with near-optimal seed length and large output length. In particular, we think that our non-recursive construction in Section 5.1 holds promise in this direction. 1.5 Acknowledgements Part of this research was done while the authors were visiting the Simons Institute for the Theory of Computing, supported by DOE grant # DE-SC0024124. D. Doron’s research was also supported by Instituto de Telecomunicações (ref. UIDB/50008/2020) with the financial support of FCT - Fundação para a Ciência e a Tecnologia and by NSF-BSF grant #2022644. J. Ribeiro’s research was also supported by Instituto de Telecomunicações (ref. UIDB/50008/2020) and NOVA LINCS (ref. UIDB/04516/2020) with the financial support of FCT - Fundação para a Ciência e a Tecnologia."
https://arxiv.org/html/2405.05369v2,Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory,"Counterfactual explanations provide ways of achieving a favorable model outcome with minimum input perturbation. However, counterfactual explanations can also be leveraged to reconstruct the model by strategically training a surrogate model to give similar predictions as the original (target) model. In this work, we analyze how model reconstruction using counterfactuals can be improved by further leveraging the fact that the counterfactuals also lie quite close to the decision boundary. Our main contribution is to derive novel theoretical relationships between the error in model reconstruction and the number of counterfactual queries required using polytope theory. Our theoretical analysis leads us to propose a strategy for model reconstruction that we call Counterfactual Clamping Attack (CCA) which trains a surrogate model using a unique loss function that treats counterfactuals differently than ordinary instances. Our approach also alleviates the related problem of decision boundary shift that arises in existing model reconstruction approaches when counterfactuals are treated as ordinary instances. Experimental results demonstrate that our strategy improves fidelity between the target and surrogate model predictions on several datasets.","Counterfactual explanations (also called counterfactuals) have emerged as a burgeoning area of research (Wachter et al., 2017; Guidotti, 2022; Barocas et al., 2020; Verma et al., 2022; Karimi et al., 2022) for providing guidance on how to obtain a more favorable outcome from a machine learning model, e.g., increase your income by 10K to qualify for the loan. Interestingly, counterfactuals can also reveal information about the underlying model, posing a nuanced interplay between model privacy and explainability (Aïvodji et al., 2020; Wang et al., 2022). Our work provides the first theoretical analysis between the error in model reconstruction using counterfactuals and the number of counterfactuals queried for, through the lens of polytope theory. Model reconstruction using counterfactuals can have serious implications in Machine Learning as a Service (MLaaS)platforms that allow users to query a model for a specified cost (Gong et al., 2020). An adversary may be able to “steal” the model by querying for counterfactuals and training a surrogate model to provide similar predictions as the target model, a practice also referred to as model extraction. On the other hand, model reconstruction could also be beneficial for preserving applicant privacy, e.g., if an applicant wishes to evaluate their chances of acceptance from crowdsourced information before formally sharing their own application information with an institution, often due to resource constraints or having a limited number of attempts to apply (e.g., applying for credit cards reduces the credit score (Capital One, 2024)). Our goal is to formalize how faithfully can one reconstruct an underlying model given a set of counterfactual queries. Figure 1: Decision boundary shift when counterfactuals are treated as ordinary labeled points. An existing approach for model reconstruction is to treat counterfactuals as ordinary labeled points and use them for training a surrogate model (Aïvodji et al., 2020). While this may work for a well-balanced counterfactual queries from the two classes lying roughly equidistant to the decision boundary, it is not the same for unbalanced datasets. The surrogate decision boundary might not always overlap with that of the target model (see Fig. 1), a problem also referred to as a decision boundary shift. This is due to the learning process where the boundary is kept far from the training examples (margin) for better generalization (Shokri et al., 2021). The decision boundary shift is aggravated when the system provides only one-sided counterfactuals, i.e., counterfactuals only for queries with unfavorable predictions. If one were allowed to query for two-sided counterfactuals, the decision boundary shift may be tackled by querying for the counterfactual of the counterfactual (Wang et al., 2022). However, such strategies cannot be applied when only one-sided counterfactuals are available, which is more common and also a more challenging use case for model reconstruction, e.g., counterfactuals are only available for the rejected applicants to get accepted for a loan but not the other way. In this work, we analyze how model reconstruction using counterfactuals can be improved by leveraging the fact that the counterfactuals are quite close to the decision boundary. We provide novel theoretical analysis for model reconstruction using polytope theory, addressing an important knowledge gap in the existing literature. We demonstrate reconstruction strategies that alleviate the decision-boundary-shift issue for one-sided counterfactuals. In contrast to existing strategies Aïvodji et al. (2020) and Wang et al. (2022) which require the system to provide counterfactuals for queries from both sides of the decision boundary, we are able to reconstruct using only one-sided counterfactuals, a problem that we also demonstrate to be theoretically more challenging than the two-sided case (see Corollary 3.8). In summary, our contributions can be listed as follows: Fundamental guarantees on model reconstruction using counterfactuals: We derive novel theoretical relationships between the error in model reconstruction and the number of counterfactual queries (query complexity) under three settings: (i) Convex decision boundaries and closest counterfactuals (Theorem 3.2): We rely on convex polytope approximations to derive an exact relationship between expected model reconstruction error and query complexity; (ii) ReLU networks and closest counterfactuals (Theorem 3.6): Relaxing the convexity assumption, we provide probabilistic guarantees on the success of model reconstruction as a function of number of counterfactual queries; and (iii) Beyond closest counterfactuals: We provide approximate guarantees for a broader class of models, including ReLU networks and locally-Lipschitz continuous models (Theorem 3.10). Model reconstruction strategy with unique loss function: We devise a reconstruction strategy – that we call Counterfactual Clamping Attack (CCA) – that exploits only the fact that the counterfactuals lie reasonably close to the decision boundary, but need not be exactly the closest. Empirical validation: We conduct experiments on both synthetic datasets, as well as, four real-world datasets, namely, Adult Income (Becker and Kohavi, 1996), COMPAS (Angwin et al., 2016), DCCC (Yeh, 2016), and HELOC (FICO, 2018). Our strategy outperforms the existing baseline (Aïvodji et al., 2020) over all these datasets (Section 4) using one-sided counterfactuals, i.e., counterfactuals only for queries from the unfavorable side of the decision boundary. We also include additional experiments to observe the effects of model architecture, Lipschitzness, and other types of counterfactual generation methods as well as ablation studies with other loss functions. A python-based implementation is available at: https://github.com/pasandissanayake/model-reconstruction-using-counterfactuals. Related Works: A plethora of counterfactual-generating mechanisms has been suggested in existing literature (Guidotti, 2022; Barocas et al., 2020; Verma et al., 2022; Karimi et al., 2022, 2020; Mothilal et al., 2020; Dhurandhar et al., 2018; Deutch and Frost, 2019; Mishra et al., 2021). Related works that focus on leaking information about the dataset from counterfactual explanations include membership inference attacks (Pawelczyk et al., 2023) and explanation-linkage attacks (Goethals et al., 2023). Shokri et al. (2021) examine membership inference from other types of explanations, e.g., feature-based. Model reconstruction (without counterfactuals) has been the topic of a wide array of studies (see surveys Gong et al. (2020) and Oliynyk et al. (2023)). Various mechanisms such as equation solving (Tramèr et al., 2016) and active learning have been considered (Pal et al., 2020). Model inversion (Gong et al., 2021; Struppek et al., 2022; Zhao et al., 2021) is another form of extracting information about a black box model, under limited access to the model aspects. In contrast to model extraction where the goal is to replicate the model itself, in model inversion an adversary tries to extract the representative attributes of a certain class with respect to the target model. In this regard, Zhao et al. (2021) focuses on exploiting explanations for image classifiers such as saliency maps to improve model inversion attacks. Struppek et al. (2022) proposes various methods based on Generative Adversarial Networks to make model inversion attacks robust (for instance, to distributional shifts) in the domain of image classification. Milli et al. (2019) looks into model reconstruction using other types of explanations, e.g., gradients. Yadav et al. (2023) explore algorithmic auditing using counterfactual explanations, focusing on linear classifiers and decision trees. Using counterfactual explanations for model reconstruction has received limited attention, with the notable exceptions of Aïvodji et al. (2020) and Wang et al. (2022). Aïvodji et al. (2020) suggest using counterfactuals as ordinary labeled examples while training the surrogate model, leading to decision boundary shifts, particularly for unbalanced query datasets (one-sided counterfactuals). Wang et al. (2022) introduces a strategy of mitigating this issue by further querying for the counterfactual of the counterfactual. However, both these methods require the system to provide counterfactuals for queries from both sides of the decision boundary. Nevertheless, a user with a favorable decision may not usually require a counterfactual explanation, and hence a system providing one-sided counterfactuals might be more common, wherein lies our significance. While model reconstruction (without counterfactuals) has received interest from a theoretical perspective (Tramèr et al., 2016; Papernot et al., 2017; Milli et al., 2019), model reconstruction involving counterfactual explanations lack such a theoretical understanding. Our work theoretically analyzes model reconstruction using polytope theory and proposes novel strategies thereof, also addressing the decision-boundary shift issue."
https://arxiv.org/html/2411.07179v1,"Joint Age-State Belief is All You Need: 
Minimizing AoII via Pull-Based Remote Estimation","Age of incorrect information (AoII) is a recently proposed freshness and mismatch metric that penalizes an incorrect estimation along with its duration. Therefore, keeping track of AoII requires the knowledge of both the source and estimation processes. In this paper, we consider a time-slotted pull-based remote estimation system under a sampling rate constraint where the information source is a general discrete-time Markov chain (DTMC) process. Moreover, packet transmission times from the source to the monitor are non-zero which disallows the monitor to have perfect information on the actual AoII process at any time. Hence, for this pull-based system, we propose the monitor to maintain a sufficient statistic called belief which stands for the joint distribution of the age and source processes to be obtained from the history of all observations. Using belief, we first propose a maximum a posteriori (MAP) estimator to be used at the monitor as opposed to existing martingale estimators in the literature. Second, we obtain the optimality equations from the belief-MDP (Markov decision process) formulation. Finally, we propose two belief-dependent policies one of which is based on deep reinforcement learning, and the other one is a threshold-based policy based on the instantaneous expected AoII.","Age of information (AoI) metric has recently been proposed to capture information freshness in remote estimation problems [1]. The AoI metric quantifies information freshness by a monitor which keeps track of how long ago the latest received information packet in the system had been generated. However, it is argued in [2] that AoI may fall short of capturing freshness in certain estimation problems since it does not consider the dynamics of the sampled process since even though the latest received packet may have been generated a long time ago, it is possible that the source may not have changed since then, and therefore, the packet can still be fresh. Similarly, a recently received packet may contain stale information if the source has already changed its state after the packet was generated. Stemming from this drawback of AoI, [2] proposes an alternative freshness metric, namely age of incorrect information (AoII) that penalizes the mismatch between the source and its estimation over time, and regardless of when it is sampled, it defines the estimation as fresh if it is the same as the source. Another interesting feature of AoII in contrast to AoI is that the monitor is not required to get a new sample to bring the age down to zero since the mismatch condition between the source and the monitor may as well be brought to end with a transition of the source to the estimated value at the monitor. In this paper, we consider the following AoII minimization problem in which an information source observes a DTMC process, and a remote monitor estimates the process from the updates received by the monitor from the source. We consider a pull-based scheme such that the source transmits its current state whenever a pull request arrives at the source, and the transmission is completed in the next time slot. The monitor updates its estimation by considering the source dynamics with the MAP estimator. Notice that the monitor does not have full information on AoII including the very same time slot the most recent update is received. Additionally, we consider a sampling rate constraint on the monitor that limits the average number of pull requests it can send. Therefore, we aim to find an AoII-minimizing policy at the monitor with the timely generation of pull requests based on partial observations. Generally, AoII is investigated for symmetric Markov chains, and a single threshold policy is proposed to minimize the average AoII [2, 3, 4]. Additionally, in these works, the latest received information is used, termed as the martingale estimator [5], since it would be optimum only if the source were a martingale. On the other hand, in our previous works [6, 7, 8], we have shown that if the source process is a general asymmetric Markov chain, a simple threshold policy would not be guaranteed to perform optimally. More specifically, in [7, 8] it is shown that the optimum transmission policy should take into account all the estimation, source, and age values. Similarly, it was shown in [6] that the monitor can reduce the average AoII value if the pull request rates are allowed to be dependent on the latest received information. However, in that work, we have considered a preemption mechanism at the transmitter which aborts the transmission of the current information packet if the source process changes before the packet is received. Similarly, the pull-based AoII minimization problem in [4] considers an immediate transmission that allows the monitor to keep track of AoII. On the other hand, in the system model here, the decision maker (the monitor) has no direct information on the source process and hence the current AoII. In this paper, a sufficient statistic corresponding to their joint probability distribution under the MAP estimation rule is derived. Therefore, this paper motivates to obtain policies based on this distribution. The closest MDP formulation to our problem is the partially observable Markov decision process (POMDP) formulation that considers states which are not observable directly, but their probability distributions can be obtained with observations using partial information [9]; this distribution is called belief. The main assumption of this formulation is that an MDP can be defined from the unobserved states, and the expected reward of the system can be calculated from this distribution. Because of the curse of dimensionality of the underlying POMDP formulation, exact solutions [10, 11] for POMDPs are not tractable for problems with large state and action spaces. An approximate solution is the so-called myopic policy which selects the action that minimizes the expected reward by ignoring its effects on future rewards [12, 13]. In [12], it is shown that a myopic policy is optimum for POMDPs under certain conditions. Similarly, the Whittle index approach can be adapted for POMDPs to obtain an index policy [14, 15]. Because of the dependency of the estimator on the belief, it is no longer straightforward to use the POMDP formulation for the problem of interest. However, we can formulate our problem as a belief-MDP such that the belief in unobserved states is viewed as a fully-observable continuous-valued state of the belief-MDP, and its equivalence to a POMDP is shown in [11]. In some cases [16, 15], the belief-MDP can further be converted to an MDP with observable and finite states, and optimum policies can be obtained accordingly. Deep reinforcement learning (DRL) has recently gained popularity for solving MDPs using the exploration-exploitation trade-off [17]. Indeed, the value function for a POMDP can be approximated from the belief using DRL [18], or from the observation [19], and the action that minimizes the value function is applied as a sub-optimal policy. POMDP formulation has been used to minimize AoI in several works [15, 20, 16, 21, 22, 23, 24]. In [15, 20, 24, 22], system models involving multiple sensors and a single monitor have been studied for different scenarios. In these works, the monitor is only aware of the AoI of the sensor that successfully transmits at that time slot and estimates the AoI of other sensors based on its previous observations. In [15], [24] and [22], sub-optimal policies are obtained via the index policy, the myopic policy, and the particle filter, respectively. On the other hand, the authors of [22] convert the POMDP into a fully-observable discrete space MDP problem, and obtain an optimum policy. A similar system model has been studied in [25]. In that work, an entropy-based metric, namely uncertainty of information, is minimized by employing an index policy. Additionally, the AoI minimization problems in [21, 23, 16] consider failure status, channel availability, and the battery level as unobservable states, respectively. Under the assumption that each update includes a timestamp of the generation time, the monitor can access the correct AoI value for the time slot the update is received. On the other hand, when the delay on the channel is considered, the source process may change before the update arrives, thus no updates guarantee resetting AoII and the monitor never has the correct AoII value including the time slot an update arrives. Additionally, AoII metric depends on the dynamics of the source process, and it is upper bounded even if there is no sampling. These aspects make AoII problems different and more challenging from AoI-based formulations. The contribution of this paper can be summarized as follows: i) We propose a MAP estimator to be used at the monitor in place of the simple martingale estimator, for which the monitor updates its estimation with the MAP rule. ii) We derive a sufficient statistic, namely belief, that corresponds to the joint distribution of AoII and source state, for general asymmetric Markov chains. iii) We propose two belief-dependent policies, one of which is based on DRL, and we compare these two policies against two baseline belief-agnostic policies."
https://arxiv.org/html/2411.06690v1,Polarization Aware Movable Antenna,"This paper presents a polarization-aware movable antenna (PAMA) framework that integrates polarization effects into the design and optimization of movable antennas (MAs). While MAs have proven effective at boosting wireless communication performance, existing studies primarily focus on phase variations caused by different propagation paths and leverage antenna movements to maximize channel gains. This narrow focus limits the full potential of MAs. In this work, we introduce a polarization-aware channel model rooted in electromagnetic theory, unveiling a defining advantage of MAs over other wireless technologies such as precoding: the ability to optimize polarization matching. This new understanding enables PAMA to extend the applicability of MAs beyond radio-frequency, multipath-rich scenarios to higher-frequency bands, such as mmWave, even with a single line-of-sight (LOS) path. Our findings demonstrate that incorporating polarization considerations into MAs significantly enhances efficiency, link reliability, and data throughput, paving the way for more robust and efficient future wireless networks.","The relentless pursuit of high-speed and reliable wireless communication has become a cornerstone of modern technological advancement. Emerging applications such as autonomous vehicles, the artificial intelligence of things, and augmented reality demand seamless connectivity with unprecedented data rates and minimal latency[1, 2]. These evolving requirements are pushing the boundaries of existing wireless communication systems, necessitating innovative solutions to address challenges like spectrum scarcity, signal degradation, and dynamic environmental conditions. One promising technique that has emerged to meet these challenges is the use of movable antennas (MAs) [3, 4, 5, 6], also known as fluid antenna systems (FAS) [7, 8, 9, 10, 11]. By dynamically adjusting the position and orientation of antennas, it is possible to achieve enhanced signal-to-noise ratio (SNR), wider coverage, and adaptability to changing environments and user locations, without solely relying on traditional methods like increasing transmission power, beamforming, or deploying additional infrastructure[12, 13, 14, 15, 16, 17]. Figure 1: Movable antennas with the capability for 3D translation and rotation. Previous research has explored the applications of MAs and FAS in radio frequency bands characterized by rich multipath environments [3, 7]. In these settings, antenna movement is leveraged to exploit spatial diversity arising from amplitude fluctuations caused by multipath propagation. In [7], the authors propose FAS that allows the receiving antenna to move to positions to capture the strongest signal. Analysis of outage probability demonstrates that, within a movement range of 0.2\lambda, FAS can achieve performance comparable to a maximal ratio combining system with five antennas spanning 2\lambda. This flexibility in antenna positioning offers significant advantages, especially in scenarios requiring massive connectivity. It allows each user to find an optimal position where instantaneous interference is minimized, effectively creating deep nulls. This spatial multiplexing gain facilitates multi-user access, a concept introduced as Fluid Antenna Multiple Access (FAMA) in [8]. Building upon this concept, [9] extends FAS to a two-dimensional (2D) implementation and discusses reconfigurable pixel technologies as a practical approach for realization. Additionally, [18] introduces a continuous FAS (CFAS) architecture, demonstrating that CFAS outperforms discrete FAS with limited ports, particularly at medium to high threshold levels. The MA system presented in [3] exhibits additional phase variations due to antenna translation, significantly surpassing fixed-position antennas in both deterministic and stochastic channels. The system’s performance further improves with increased positioning accuracy, larger movement ranges, and enhanced multipath effects. Building on 2D MA system, advancements in six-dimensional (6D) systems, such as those discussed in [4], enable simultaneous three-dimensional (3D) translation and rotation, enhancing the system’s directional capabilities. By imposing spatial constraints on surfaces equipped with 6D movable antennas (6DMA), user interference is reduced, improving the signal-to-interference-plus-noise ratio (SINR). In [5], the 6DMA model is simplified by integrating conventional fixed-position antenna arrays with 6DMA surfaces capable of rotating along a circular path. By limiting the degrees of freedom for surface movement to the azimuth angle along the circular track, computational complexity is significantly reduced while enhancing the system’s maximum capacity. Despite these advancements, the impact of polarization changes due to antenna movement and rotation has been largely overlooked. Polarization is a fundamental characteristic of electromagnetic waves, describing the orientation of the electric field vector as the wave propagates through space [19, 20, 21, 22, 23]. In wireless communication systems, proper alignment of polarization between transmitting and receiving antennas is crucial for efficient signal transmission and reception. When polarizations are properly aligned, the receiving antenna can maximally capture the transmitted energy, resulting in stronger signal strength, improved SNR, and enhanced overall system performance. Conversely, polarization mismatch occurs when there is a misalignment between the polarization orientations of the transmitting and receiving antennas, leading to significant signal attenuation as the misaligned component of the electromagnetic wave is effectively lost. Neglecting polarization effects can lead to incomplete system models and suboptimal performance assessments, hindering a full understanding of the impact and advantages of MAs. This oversight is particularly critical as communication systems move towards higher frequency bands, such as the millimeter-wave (mmWave) spectrum [24, 25]. At these higher frequencies, signal propagation becomes more directional with reduced diffraction around obstacles, often resulting in a single line-of-sight (LOS) link between transmitter and receiver [26]. Previously, it was believed that MAs offer no gains in such LOS scenarios due to the lack of multipath diversity [7, 3]. However, our formulation incorporating polarization effects indicates otherwise – MAs can achieve significant performance gains even in LOS scenarios by facilitating polarization matching. As such, there is a clear gap in current research: the need to incorporate polarization effects into the design and optimization of MA systems, especially as the wireless industry advances towards higher frequency bands to achieve greater bandwidths and data rates. To fill the gap, this paper makes the following main contributions: • We introduce a polarization-aware movable antenna (PAMA) framework, which incorporates polarization effects into the design and optimization of antenna movement and rotation. PAMA uncovers a previously overlooked, but defining benefit of antenna movement – facilitating optimal polarization matching between the transmitter and receiver. By accounting for the impact of polarization changes due to movement and rotation, PAMA provides a more refined system model and deepens our understanding of the dynamic capabilities of MAs. • Building upon the electromagnetic theory, we develop a polarization-aware channel model that describes the impact of 3D movement and rotation of antennas on the channel gains. Grounded in Maxwell’s equations, this model allows for precise characterization of how antenna positioning and orientation affect polarization alignment and, consequently, signal reception quality. By integrating these factors into the system design, we enable the optimization of antenna movements to maintain polarization alignment, thereby maximizing the sum rate of the communication system. • Contrary to prior beliefs that MAs are more effective in low-frequency, multipath-rich environments, our PAMA framework demonstrates that MAs are highly effective in higher frequency bands such as the mmWave band, even with a single LOS link. The smaller size of antennas at higher frequencies makes them easier to move and rotate, facilitating practical implementation of PAMA systems in these bands. This new understanding extends the potential and application of MA to next-generation wireless communication systems that demand higher bandwidths. Organization: The remainder of this paper is structured as follows. Section II introduces the system model and essential geometric concepts used throughout the work. Section III presents our PAMA framework and the polarization-aware channel model. Section IV explores the impacts of 3D antenna translation and rotation on the PAMA channel gains. Section V demonstrates the potential of PAMA through a sum-rate optimization problem. Finally, Section VI concludes the paper. Notations: We use boldface lowercase letters to denote column vectors (e.g., \bm{h}, \bm{w}) and boldface uppercase letters to denote matrices (e.g., \bm{H}, \bm{P}). For a vector or matrix, (\cdot)^{\top} denotes the transpose, (\cdot)^{*} denotes the complex conjugate, and (\cdot)^{H} denotes the conjugate transpose. \mathbb{C} stand for the sets of complex values. The imaginary unit is represented by j. The Euclidean norm of a vector \bm{p} is denoted by |\bm{p}|. For two vectors \bm{a} and \bm{b}, \langle\bm{a},\bm{b}\rangle denotes the angle between them, and \bm{a}\cdot\bm{b} denotes their inner product."
https://arxiv.org/html/2411.06339v1,Probabilistic Shaped Multilevel Polar Coding for Wiretap Channel,"A wiretap channel is served as the fundamental model of physical layer security techniques, where the secrecy capacity of the Gaussian wiretap channel is proven to be achieved by Gaussian input. However, there remains a gap between the Gaussian secrecy capacity and the secrecy rate with conventional uniformly distributed discrete constellation input, e.g. amplitude shift keying (ASK) and quadrature amplitude modulation (QAM). In this paper, we propose a probabilistic shaped multilevel polar coding scheme to bridge the gap. Specifically, the input distribution optimization problem for maximizing the secrecy rate with ASK/QAM input is solved. Numerical results show that the resulting sub-optimal solution can still approach the Gaussian secrecy capacity. Then, we investigate the polarization of multilevel polar codes for the asymmetric discrete memoryless wiretap channel, and thus propose a multilevel polar coding scheme integration with probabilistic shaping. It is proved that the scheme can achieve the secrecy capacity of the Gaussian wiretap channel with discrete constellation input, and satisfies the reliability condition and weak security condition. A security-oriented polar code construction method to natively satisfies the leakage-based security condition is also investigated. Simulation results show that the proposed scheme achieves more efficient and secure transmission than the uniform constellation input case over both the Gaussian wiretap channel and the Rayleigh fading wiretap channel.","As a complement or an alternative to classical cryptographic techniques, the physical layer security (PLS) techniques provide an additional layer of security for future wireless communication networks by exploiting the inherent randomness of wireless channels [1]. The wiretap channel model was first proposed by Wyner [2] in 1975 and has become the fundamental scenario in PLS researches. Wyner showed that a secure transmission with positive rate is possible by applying appropriate coding and signal processing scheme, and derived the secrecy capacity of the discrete memoryless wiretap channel (DMWC). In [3], the authors extended the concept of secrecy capacity to the Gaussian wiretap channel, and proved that the secrecy capacity is achieved by the Gaussian codebook. Under finite complex constellation input constraints, the secrecy capacity of the Gaussian wiretap channel was also studied in [4]. Moreover, the secrecy capacity of the fading wiretap channel has been considered [5, 6]. In addition to the information theoretic research on secrecy capacity introduced above, some practical wiretap codes are required to guarantee secure communication. The work in [7] presented a wiretap coding scheme based on low-density parity-check (LDPC) codes and shown that it achieves secrecy capacity in some cases. In [8], the authors proposed a secrecy capacity achieving polar coding scheme for the binary-input symmetric DMWC and proved that the scheme satisfies the reliability condition and the weak security condition. To avoid the measure of information theoretic secrecy metric like the security condition, a bit error rate (BER) based secrecy metric named security gap was suggested in [9] and has become one of the criteria for wiretap code design [9, 10, 11, 12, 13]. The secrecy metrics for fading wiretap channel were investigated in [14]. Moreover, with the popularity of artificial intelligence technologies in recent years, the wiretap code design via autoencoder has attracted the attention of researchers [15, 16]. Furthermore, to achieve a higher transmission rate, it is necessary to use a high-order discrete modulation. For instance, [17] optimized bit-labeling of bit-interleaved coded modulation (BICM) systems for the Gaussian wiretap channel, and [18] proposed a multilevel coding (MLC) scheme based on the punctured LDPC codes for physical layer security. Nevertheless, for the Gaussian wiretap channel with standard uniformly distributed constellation input, such as conventional amplitude shift keying (ASK) constellations and quadrature amplitude modulation (QAM) constellations, there remains a gap between the achievable secrecy rate and the Gaussian secrecy capacity [4], and none of the existing works have considered bridging the gap. Inspired by constellation shaping techniques, such as geometric shaping (GS) and probabilistic shaping (PS), which are commonly performed in point-to-point communication systems to achieve a Gaussian-like input distribution, we may leverage constellation shaping to narrow the gap. The GS designs non-equidistant constellations with uniformly distributed constellation points, e.g., constellations for ATSC 3.0 [19], but their performance is worse than PS under the same modulation order [20]. The PS, on the other hand, generates constellation points from a standard constellation with non-uniform probability, e.g., trellis shaping [21], shell mapping [22], probabilistic amplitude shaping (PAS) [23] and Honda-Yamamoto (HY) scheme [24]. Particularly, PAS and the HY scheme can implement PS with lower complexity and more flexible transmission rate. The PAS scheme concatenates a distribution matcher (DM) with a systematic forward error correction (FEC) code to perform PS and channel coding [23], and is proved to achieve the capacity of additive white Gaussian noise (AWGN) channel [25]. Alternatively, [24] revealed the polarization of polar codes for the binary-input asymmetric DMC111For asymmetric settings, the capacity achieving input distribution of the codewords is not always uniform. and thus proposed a polar coding scheme to achieve the asymmetric capacity. With HY scheme, the PS and FEC can be jointly implemented by just performing a polar decoder. Furthermore, the HY scheme has been extended to higher-order modulations by using the MLC structure [26, 27]. However, it does not mean that constellation shaping can be directly applied for transmission over the Gaussian wiretap channel, since achieving the secrecy capacity not only requires an optimal input distribution, but also implies that the amount of information leaked to the eavesdropper should tend to zero. More specifically, although a desired distribution can be achieved through constellation shaping, many wiretap codes, like [9, 10, 11, 12, 13, 17, 18], are designed merely to impose high BER at Eve, without providing any promise of information theoretic security. Moreover, some shaping schemes, e.g. GS and PAS, need to work with a BICM structure and/or a DM, which makes the analysis of information leakage challenging. Due to the above considerations, we turn to multilevel polar coding since polar codes have shown the ability to achieve the secrecy capacity of binary-input symmetric DMWC [8] and the capacity of constellation-input asymmetric DMC [27]. In this paper, we propose a probabilistic shaped multilevel polar coding scheme achieving the secrecy capacity of the Gaussian wiretap channel with discrete constellation input. We investigate the polarization for the asymmetric DMWC with constellation input, leading to a random bit set and a shaping bit set in addition to the information bit set and frozen bit set in conventional polar codes. These two additional sets are considered separately in [8] and [27], respectively. Hence, we need to take into account the simultaneous introduction of the two sets and re-establish the conclusions on capacity achieving, reliability, and security, following the basic ideas in [8] and [27]. Furthermore, since the secrecy capacity achieving input distribution is the one that maximizes the secrecy rate rather than the mutual information as in conventional shaping schemes, an input distribution optimization problem for the Gaussian wiretap channel should be solved. To enable secure transmission, a practical code construction method under security condition constraint should also be investigated. The main contributions of this paper are detailed as follows. 1. We formulate the problem of optimizing the input distribution to maximize the secrecy rate of the Gaussian wiretap channel under discrete constellation input constraints, and simplify the problem by adopting the Maxwell-Boltzmann (MB) distribution. Specifically, given an ASK/QAM constellation input, a sub-optimal solution can be found by traversing the feasible interval. Numerical results show that the sub-optimal solution achieves a secrecy rate close to the Gaussian secrecy capacity with negligible gap. 2. We propose a probabilistic shaped multilevel polar coding scheme. For the asymmetric DMWC with discrete constellation input, we show that the bit positions of a multilevel polar code will asymptotically polarize into four sets, which are placed with frozen bits, message bits, random bits and shaping bits, respectively. Such a polar code is proven to be secrecy capacity achieving and to satisfy the reliability condition and the weak security condition as code length goes to infinity. We also remark that the above conclusions apply to the degraded Gaussian wiretap channel. 3. We propose a security-oriented polar code construction method for the proposed coding scheme at finite block length regimes, which natively satisfies the leakage-based security condition given a desired security gap. For completeness, the encoding and decoding procedures and complexity analysis are also provided. 4. Simulation results show that the proposed scheme can achieve more efficient and secure transmission than the uniform input case over both the Gaussian wiretap channel and the Rayleigh fading (RF) wiretap channel, and the results corroborate the theoretical conclusions. The rest of the paper is organized as follows. Section II introduces some essential preliminaries. In Section III, we solve the input distribution optimization problem for maximizing the secrecy rate. The probabilistic shaped multilevel polar coding scheme is proposed in Section IV. Section V introduces the coding procedure and code construction method. Section VI presents our simulation results. Finally, Section VII concludes this paper. Notations: Random variables are denoted by uppercase letters, e.g., X, while their realizations are denoted by lowercase letters, e.g., x. We denote P_{X} and E[X] by the probability distribution and expectation of X, respectively. Vectors are denoted by bold symbols, e.g., \bm{X}. The notations H(X), H(X|Y) and I(X;Y) indicate the entropy of X, the entropy of X conditioned on Y and the mutual information (MI) of X and Y, respectively. The probability of an event is written as \mathrm{Pr}\{\cdot\}. Sets like alphabet are denoted by calligraphic letters, e.g., \mathcal{X}. \mathcal{X}^{C} and |\mathcal{X}| are the complement and cardinality of \mathcal{X}, respectively. The set difference is defined as \mathcal{X}\setminus\mathcal{Y}=\mathcal{X}\cap\mathcal{Y}^{C}. We denote the real field, positive integer set and binary field by \mathbb{R}, \mathbb{N} and \mathbb{F}_{2}, respectively. The empty set is denoted by \emptyset. An index set \{1,2,\cdots,N\} is abbreviated as [\![N]\!], and particularly [\![0]\!] is equal to \emptyset. Given a vector \bm{x} of length N and \mathcal{A}\subseteq[\![N]\!], we write \bm{x}_{\mathcal{A}} to denote the sub-vector [x_{i}]_{i\in\mathcal{A}}."
https://arxiv.org/html/2411.06309v1,"Physics-Compliant Modeling and Scaling Laws of
Multi-RIS Aided MIMO Systems","Reconfigurable intelligent surface (RIS) enables the control of wireless channels to improve coverage. To further extend coverage, multi-RIS aided systems have been explored, where multiple RISs steer the signal via a multi-hop path. However, deriving a physics-compliant channel model for multi-RIS aided systems is still an open problem. In this study, we fill this gap by modeling multi-RIS aided systems through multiport network theory, and deriving a channel model accounting for impedance mismatch, mutual coupling, and structural scattering. The derived physics-compliant model differs from the model widely used in literature, which omits the RIS structural scattering. To quantify this difference, we derive the channel gain scaling laws of the two models under line-of-sight (LoS) and multipath channels. Theoretical insights, validated by numerical results, show an important discrepancy between the physics-compliant and the widely used models, increasing with the number of RISs and multipath richness. In a multi-hop system aided by four 128-element RISs with multipath channels, optimizing the RISs using the widely used model and applying their solutions to the physics-compliant model achieves only 7% of the maximum channel gain. This highlights how severely mismatched channel models can be, calling for more accurate models in communication theory.","Reconfigurable intelligent surface (RIS) has emerged as a technology enabling dynamic control over the electromagnetic (EM) propagation environment in wireless networks [2]. RIS technology leverages surfaces made of elements with programmable scattering properties to manipulate impinging EM signals, thereby enhancing the channel strength and extending coverage. While most of the literature on RIS focuses on systems aided by a single RIS, multi-RIS aided systems, also known as multi-hop RIS-aided systems, have attracted attention as they can further enhance coverage. Initial studies considered the optimization and power scaling analysis of double-RIS aided systems [3, 4], where the signal reaches the receiver following a double-hop path. The capacity maximization problem for double-RIS aided systems has been tackled in [5, 6]. In addition, a channel estimation protocol for double-RIS systems has been presented in [7], while a geometry-based stochastic channel model has been proposed in [8]. As a generalization of double-RIS aided systems, multi-RIS aided systems have been studied, where multiple cooperative RISs are deployed to drive the EM signal towards the intended location through a multi-hop path [9, 10]. In these systems, multiple RISs can boost the channel strength in harsh propagation conditions, with consequent coverage extension [11]. Other benefits of multi-RIS aided systems include the ability to artificially create multipath beams in single-user systems [12], and to maximize the sum rate in multi-user systems by mitigating interference [13, 14]. Works [3]-[14] deployed multiple reflective RISs to extend the coverage, each of them covering half-space and characterized by a diagonal phase shift matrix. Given its mathematical constraint, we refer to this conventional RIS architecture as diagonal RIS (D-RIS). Besides, to further extend the coverage of RIS-aided systems, more flexible RIS architectures have been proposed under the umbrella term of beyond diagonal RIS (BD-RIS), which are characterized by a matrix allowed to have non-zero off-diagonal entries [15]. BD-RIS offers two ways to improve the coverage. First, reflective BD-RISs can improve coverage and performance through their advanced flexibility, allowing for more versatile manipulation of the signal. Efficient reflective BD-RIS architectures have been proposed, such as fully- and group-connected RISs [16, 17], and tree- and forest-connected RISs [18]. Second, BD-RIS enables the signal impinging in one element to be irradiated by other elements, allowing the transmission of the signal through the RIS. Thus, BD-RIS architectures with transmissive capabilities have been proposed to reach a 360∘ coverage, such as by using simultaneously transmitting and reflecting RIS (STAR-RIS) [19], and the more general hybrid BD-RIS and multi-sector BD-RIS architectures [20, 21]. In [22], multiple transmissive RISs have been used to serve mobile users through a multi-hop path. Accurate modeling of RIS-aided wireless channels is crucial for designing and optimizing RIS-aided systems, including a single or multiple RISs implemented through D-RIS or BD-RIS architectures. To rigorously model wireless channels in the presence of a single RIS, multiport network theory has been successfully utilized [23, 24, 16]. Specifically, previous works used multiport network theory to derive physics-compliant RIS-aided channel models accounting for the impedance mismatch and mutual coupling effects at the transmitter, receiver, and RIS. Different models have been proposed based on three equivalent formalisms, i.e., impedance (or Z) parameters [23], admittance (or Y) parameters [24], and scattering (or S) parameters [16]. The relationship between impedance and scattering parameters has been more recently analyzed in [25, 26, 27, 28], and a universal framework has been derived in [29] highlighting the connection between impedance, admittance, and scattering parameters. While substantial effort has been devoted to system-level optimization of multi-RIS aided systems, the rigorous modeling of multi-RIS aided channels is still an open issue. Channel models conventionally used in previous works on multi-RIS have not been derived by first physics principles, hence they are hard to validate and their limit of validity is unclear. To fill this gap, in this study, we model the channel of multi-RIS aided multiple-input multiple-output (MIMO) systems through multiport network theory. We derive the expression of a physics-compliant channel model and the scaling law of the achievable channel gain, under line-of-sight (LoS) and multipath channels. Contributions: The contributions of this study are as follows. First, we derive a physics-compliant channel model for multi-RIS aided MIMO systems by using multiport network theory, clarifying its underlying assumptions. The derived channel model accounts for the impedance mismatch and mutual coupling at the transmitter, receiver, and RISs, the effects of all the channels between the transmitter/receiver and the RISs, and the structural scattering of the RISs111In antenna theory, the structural scattering is a component of the field scattered by an antenna [30, Chapter 2]. In the context of RIS, the structural scattering of a RIS results in a specular reflection at the RIS independent from the RIS reconfiguration [28].. As these effects are commonly neglected in related literature, our channel model is crucial to better understand multi-hop communication links enabled by multi-RIS aided systems. Second, we simplify the derived channel model by assuming perfect matching and no mutual coupling at the transmitter, receiver, and RISs for the sake of tractability. The obtained simplified channel model is aligned with the model widely used in literature, while it introduces a slight variation to incorporate the structural scattering of the RISs, which is typically ignored in the literature. Third, we analyze the effect of hybrid and multi-sector BD-RISs working in transmissive mode on the multi-RIS aided channel expression. Interestingly, we show that the structural scattering of RISs working in transmissive mode does not impact the channel model. Thus, the widely used channel model is physics-compliant in the case of multi-RIS aided systems where all the RISs are used in transmissive mode. Fourth, we compare the derived physics-compliant channel model with the widely used one, when all the RISs are used in reflective mode and assuming LoS channels. To this end, we provide the scaling laws of the achievable channel gains for the two models. Theoretical insights, supported by numerical simulations, show that the relative difference between the two channel gains grows with the number of RISs and decreases with the number of RIS elements. In a system aided by four RISs with 128 elements each, this difference is higher than 80%, and by optimizing the RISs based on the widely used model it can be achieved only 56% of the maximum channel gain of the physics-compliant model. Fifth, we analyze the physics-compliant and widely used channel models under multipath channels. Specifically, we propose an algorithm to maximize the channel gain by optimizing D-RIS and BD-RIS architectures, and derive closed-form upper bounds on the channel gains. Numerical results, supported by theoretical intuition, show that the discrepancy between the physics-compliant and widely used channel models is more severe under multipath channels compared to LoS channels. In a system aided by four RISs with 128 elements each, the relative difference between the two channel gains is higher than 1000% with Rayleigh channels. Consequently, by optimizing the RISs based on the widely used model, only 7% of the maximum channel gain of the physics-compliant model can be achieved. An important takeaway message from this work to the communication society is to encourage the integration of more accurate, physics-based, channel models derived from first EM principles into communication theoretic analysis. Organization: In Section II, we characterize multi-RIS aided systems with multiport network theory. In Section III, we derive a physics-compliant model of multi-RIS aided systems accounting for impedance mismatch and mutual coupling. In Section IV, we simplify the model and show that it differs from the widely used channel model. In Section V, we model multi-RIS aided systems in the presence of both reflective and transmissive RISs. In Sections VI and VII, we maximize the channel gain of the physics-compliant and widely used models, under LoS and multipath channels, respectively. In Section VIII, we provide numerical results to validate the theoretical insights. In Section IX, we conclude this work. Notation: Vectors and matrices are denoted with bold lower and bold upper letters, respectively. Scalars are represented with letters not in bold font. \Re\{a\}, \Im\{a\}, |a|, and arg(a) refer to the real part, imaginary part, absolute value, and phase of a complex scalar a, respectively. \mathbf{a}^{T}, [\mathbf{a}]_{i}, and \|\mathbf{a}\| refer to the transpose, ith element, and l_{2}-norm of a vector \mathbf{a}, respectively. \mathbf{A}^{T}, [\mathbf{A}]_{i,j}, \|\mathbf{A}\|, and \|\mathbf{A}\|_{F} refer to the transpose, (i,j)th element, spectral norm, and Frobenius norm of a matrix \mathbf{A}, respectively. \mathbb{R} and \mathbb{C} denote real and complex number sets, respectively. j=\sqrt{-1} denotes the imaginary unit. \mathbf{0} and \mathbf{I} denote an all-zero matrix and an identity matrix with appropriate dimensions, respectively. \mathcal{CN}(\mathbf{0},\mathbf{I}) denotes the distribution of a circularly symmetric complex Gaussian random vector with mean vector \mathbf{0} and covariance matrix \mathbf{I} and \sim stands for “distributed as”. diag(a_{1},\ldots,a_{N}) refers to a diagonal matrix with diagonal elements being a_{1},\ldots,a_{N}. diag(\mathbf{A}_{1},\ldots,\mathbf{A}_{N}) refers to a block diagonal matrix with blocks being \mathbf{A}_{1},\ldots,\mathbf{A}_{N}."
https://arxiv.org/html/2411.06193v2,Large Language Models and Artificial Intelligence Generated Content Technologies Meet Communication Networks,"Artificial intelligence generated content (AIGC) technologies, with a predominance of large language models (LLMs), have demonstrated remarkable performance improvements in various applications, which have attracted great interests from both academia and industry. Although some noteworthy advancements have been made in this area, a comprehensive exploration of the intricate relationship between AIGC and communication networks remains relatively limited. To address this issue, this paper conducts an exhaustive survey from dual standpoints: firstly, it scrutinizes the integration of LLMs and AIGC technologies within the domain of communication networks; secondly, it investigates how the communication networks can further bolster the capabilities of LLMs and AIGC. Additionally, this research explores the promising applications along with the challenges encountered during the incorporation of these AI technologies into communication networks. Through these detailed analyses, our work aims to deepen the understanding of how LLMs and AIGC can synergize with and enhance the development of advanced intelligent communication networks, contributing to a more profound comprehension of next-generation intelligent communication networks.","Large language models (LLMs) and artificial intelligence generated content (AIGC) technologies have recently advanced rapidly and are playing critical roles in a wide range of applications. For instance, ChatGPT, a groundbreaking example of LLMs, can generate valuable response content based on user input prompts and multiple conversations, providing a remarkable solution for multilingual machine translation, code debugging, text generation and recommendation systems, and so on [1]. Its distinctive advantage lies in the powerful complex reasoning abilities, which facilitate harnessing extensive high-level knowledge derived from the backstage corpora. As opposed to traditional human-generated content such as user generated content (UGC) and professional generated content (PGC) [2], AIGC technologies refers to a new automated paradigm in content generation, which uses generative artificial intelligence (GAI) models to produce multimedia digital content automatically. In state-of-the-art prompt-based GAI models, users can influence the output of the model by providing personalized descriptions. Currently, LLMs are emerging as one of the most important classes of GAI models. Compared to other small-scale GAI models like generative adversarial networks (GANs) and diffusion models, LLMs excel in two aspects. On the one hand, LLMs are powerful text generation models and the training process usually integrates with reinforcement learning from human feedback (RLHF)[3] to further enhance the model understanding of user intent, enabling the realization of more authentic and realistic conversations. On the other hand, LLMs exhibit a larger parameter scale, capable of reaching several hundred to even over a thousand billion parameters. This substantial increase of model scale results in a significant enhancement in performance, commonly referred to as emergent capability [4], thereby yielding high-quality textual outputs and showing potential to serve as a generalist agent[5]. TABLE I: Contribution comparisons between existing relevant surveys and our paper. Research Field Year/Ref. Topic Focus Contributions GAI 2023/[6] ChatGPT Overview of ChatGPT history and key technologies. Present the benefits and drawbacks of ChatGPT, as well as prospective challenges and developments in its application. 2023/[7] AIGC Survey on the evolution of generative AI models and recent advances including LLMs. Introduce relevant models and applications from the uni-modal and multi-modal perspectives. 2023/[8] LLMs Present a summary of existing LLMs by timeline, and summarize the characteristics of LLMs in four areas: pre-training, adaptation tuning, utilization, and evaluation. 2022/[9] LLMs, reasoning capabilities Survey on the reasoning capabilities of LLMs, outline the current state, relevant techniques, and assessment methods. 2023/[10] LLMs, evaluation strategy Survey on the evaluating LLMs and summarize what, where, and how they are evaluated. 2023/[11] LLMs, recommender systems Summarize where and how to combine LLMs with recommender systems and present three key challenges. 2023/[12] LLMs, software testing Summarize the distribution of testing tasks using LLMs, and analyze commonly used models, prompt types, and model inputs from the perspective of LLMs. 2023/[13] LLMs, NLP Summarize the availability, limitations, and challenges of using LLMs for various NLP downstream tasks and the influencing factors when deploying them. Communication Networks 2019/[14]"
https://arxiv.org/html/2411.05987v1,Multiuser Commitment over Noisy Channels,"We consider multi-user commitment models that capture the problem of enabling multiple bidders to simultaneously submit auctions to verifiers while ensuring that i) verifiers do not obtain information on the auctions until bidders reveal them at a later stage; and, ii) bidders cannot change their auction once committed. Specifically, we assume that bidders and verifiers have access to a noiseless channel as well as a noisy multiple-access channel or broadcast channel, where inputs are controlled by the bidders and outputs are observed by verifiers. In the case of multiple bidders and a single verifier connected by a non-redundant multiple-access channel, we characterize the commitment capacity region when bidders are not colluding. When the bidders are colluding, we derive an achievable region and a tight converse for the sum rate. In both cases our proposed achievable commitment schemes are constructive. In the case of a single bidder and multiple verifiers connected by a non-redundant broadcast channel, in which verifiers could drop out of the network after auctions are committed, we also characterize the commitment capacity region. Our results demonstrate how commitment schemes can benefit from multi-user protocols, and develop resilience when some verifiers may become unavailable.","Commitment without the need for a trusted third party can be traced back to Blum’s coin-flipping problem [2]. More generally, a two-party commitment problem involves a bidder, Alice, and a verifier, Bob, and operates in two phases. In the first phase, called the commit phase, Alice sends Bob information to commit to a message M, representing a bid in an auction that must remain concealed from Bob. In the second phase, called the reveal phase, Alice reveals a message M^{\prime} to Bob, who must determine whether M^{\prime} is the message that Alice committed to in the commit phase. The protocol must be binding in the sense that, in the reveal phase, Alice cannot make Bob believe that she committed to a message M^{\prime}\neq M. It is well-known that information-theoretic concealment guarantees cannot be achieved over noiseless communication channels, e.g., [3]. However, when a noisy channel is available as a resource, both concealment and binding requirements can be obtained under information-theoretic guarantees, i.e., when Alice and Bob are not assumed to be computationally limited, for some class of noisy channels called non-redundant [4]. Most of the literature on information-theoretic commitments focuses on two-party scenarios that involve a single bidder and a single verifier, e.g., [5, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], characterizing commitment capacity under increasingly complex channel models. We study here instead two specific multi-user commitment settings: one in which a verifier interacts with L bidders, each committing to individual messages, and another in which a bidder commits to B verifiers, some of whom may drop out after the commit phase. The motivation for our first setting is to explore whether a multi-bidder protocol can outperform single-bidder protocols and time-sharing when multiple bidders wish to commit to individual messages. Our motivation to consider multiple verifiers in our second setting, is to ensure positive commitment rates even if a verifier drops out of the network after the commit phase, which would be impossible with a single verifier. In our first setting, L bidders and the verifier have access to a noiseless public communication channel and a noisy discrete memoryless multiple-access channel with L inputs. Each input of the multiple-access channel is controlled by a distinct bidder and the verifier observes the output of the channel. Similar to a two-party setting, the protocol consists of a commit phase and a reveal phase. Here, the concealment requirement is that the verifier must not learn, in an information-theoretic sense, information about any message of any bidder after the commit phase. The protocol must also be information-theoretically binding in the sense that, during the reveal phase, a bidder cannot make the verifier believe that it committed to another message than the one committed to in the commit phase. For this setting, we consider both the cases of colluding and non-colluding bidders. The non-colluding bidders case corresponds to a scenario in which the bidders do not trust each other and do not want to exchange information with one another. For instance, this would be the case when the bidders commit to messages sent to an auctioneer. Under a non-redundancy condition on the multiple-access channel, we derive the capacity region for the non-colluding bidders case, and an achievable region and the sum-rate capacity for the colluding bidders case. In both cases, our achievability scheme is constructive and relies on distributing hashing with two-universal hash functions [16] for the concealment guarantees. The bindingness of our achievability scheme hinges on the non-redundancy property of the multiple access channel akin to the two-party commitment in [4]. The characterization of the sum-rate capacity relies on the polymatroidal properties of our achievability region. Additionally, we demonstrate through a numerical example that, for some channels, using a multi-bidder protocol can outperform using single-bidder protocols, e.g., [4], and time-sharing. In our second setting, a single bidder can interact with B verifiers through a noiseless public communication channel and a noisy discrete memoryless broadcast channels with B outputs. The input of the channel is controlled by the bidder and each output is observed by a verifier. Similar to our first setting, the protocol consists of a commit phase and a reveal phase, and must guarantee information-theoretic bindingness and concealment. Our results demonstrate that introducing multiple verifiers can mitigate situations in which verifiers could drop out of the network after the commit phase, as long as one verifier is available during the reveal phase to validate the committed message. For this setting, we derive the commitment capacity under a non-redundancy property of the channel. As a byproduct of independent interest, we show a simple sufficient condition, in terms of injectivity of the transition probability matrix of the channel, to guarantee channel non-redundancy. Additionally, we prove that, for channels whose input alphabet is at most three, our sufficient condition is also necessary, and thus equivalent to the non-redundancy characterization in [4]. The remainder of the paper is organized as follows. After a review of notation in Section II, we develop an auxiliary result in Section III, offering a sufficient condition to guarantee non-redundancy and an alternative characterization of non-redundant channels with input alphabet of cardinality at most three. We formally introduce our multiuser commitment models in Section IV along with the associated results. We delegate the proofs to Section V and Section VI to streamline the presentation. Finally, we provide concluding remark in Section VII."
https://arxiv.org/html/2411.07160v1,An Efficient Error Estimation Method in Quantum Key Distribution,"Error estimation is an important step for error correction in quantum key distribution. Traditional error estimation methods require sacrificing a part of the sifted key, forcing a trade-off between the accuracy of error estimation and the size of the partial sifted key to be used and discarded. In this paper, we propose a hybrid approach that aims to preserve the entire sifted key after error estimation while preventing Eve from gaining any advantage. The entire sifted key, modified and extended by our proposed method, is sent for error estimation in a public channel. Although accessible to an eavesdropper, the modified and extended sifted key ensures that the number of attempts to crack it remains the same as when no information is leaked. The entire sifted key is preserved for subsequent procedures, indicating the efficient utilization of quantum resources.","Quantum key distribution (QKD) was introduced as an alternative key distribution method to achieve information-theoretic security. QKD protocols are typically classified based on the use of discrete variables or continuous variables to encode information, resulting in discrete variable QKD (DV-QKD), such as BB84 [1], and continuous variable QKD (CV-QKD), such as GG02 [2]. In general, in a QKD protocol, the sender Alice prepares the raw key and encodes it into quantum information. The raw key is transmitted through a quantum channel and measured by Bob with a sequence of randomly selected measuring bases for DV-QKD or quadrature measurements for CV-QKD. After exchanging the information of the measuring sequence, Alice and Bob are able to agree on a pair of sifted keys. Considering the presence of noise, such as imperfections in the channel, the efficiency of the equipment and the possibility of eavesdropping, the pair of sifted keys cannot be guaranteed to be identical. In practice, Alice and Bob usually exchange a portion of their initial sifted keys to assess parameters such as the quantum bit error ratio (QBER) [3, 4, 5], determining the presence of eavesdropping, and determining whether the channel noise meets the requirements, in order to decide whether to proceed to the next step, key distillation, or not. We propose a hybrid method for error estimation, where the sender introduces an additional bit flipping rate to the sifted key and wraps the partially flipped sifted key with random bits. This ‘seasoned’ sifted key is sent through a classical channel to the receiving party. The receiver attempts to estimate the QBER through computation using the received ‘seasoned’ sifted key and the local sifted key. Meanwhile, even if Eve intercepts this ‘seasoned’ sifted key, she cannot reconstruct the original sifted key. The entire original sifted key is thus preserved for the following procedures."
https://arxiv.org/html/2411.06681v1,WDMoE: Wireless Distributed Mixture of Experts for Large Language Models,"Large Language Models (LLMs) have achieved significant success in various natural language processing tasks, but the role of wireless networks in supporting LLMs has not been thoroughly explored. In this paper, we propose a wireless distributed Mixture of Experts (WDMoE) architecture to enable collaborative deployment of LLMs across edge servers at the base station (BS) and mobile devices in wireless networks. Specifically, we decompose the MoE layer in LLMs by placing the gating network and the preceding neural network layer at BS, while distributing the expert networks among the devices. This deployment leverages the parallel inference capabilities of expert networks on mobile devices, effectively utilizing the limited computing and caching resources of these devices. Accordingly, we develop a performance metric for WDMoE-based LLMs, which accounts for both model capability and latency. To minimize the latency while maintaining accuracy, we jointly optimize expert selection and bandwidth allocation based on the performance metric. Moreover, we build a hardware testbed using NVIDIA Jetson kits to validate the effectiveness of WDMoE. Both theoretical simulations and practical hardware experiments demonstrate that the proposed method can significantly reduce the latency without compromising LLM performance.","The exciting advancements in large language models (LLMs) have sparked a new wave of AI innovation. LLMs, exemplified by ChatGPT[2], have demonstrated emergent abilities[3], including better generalization, nuanced meaning comprehension, and remarkable reasoning and generation capabilities. These advancements have led to widespread applications across various fields, illuminating the vision of artificial general intelligence (AGI)[4]. In the field of 6G wireless networks, LLMs have been used for wireless network resource allocation[5, 6, 7], and applied in internet of vehicles[8] and immersive communications[9]. The emergent abilities of LLMs stem from extensive computation, a large number of model parameters, and massive training datasets[3, 10, 11]. The vast number of model parameters poses significant challenges for training, inference, and deployment. The training phase of LLMs involves significant costs in time and computational power for most individuals and organizations. Regarding LLMs inference and deployment, they also require fast responses and ample memory. In this paper, we mainly focus on LLMs inference and deployment. Currently, LLMs can be classified into cloud-based LLMs and on-device LLMs based on their deployment characteristics. Cloud servers with numerous graphics processing units (GPUs) and sufficient power supply are responsible for the majority of model inference and deployment. Due to concerns over latency and data privacy, the potential of on-device LLMs is gaining increasing attention[12]. Researchers compress LLMs through pruning[13], quantization[14], and distillation[15] to meet the memory, computation, and energy requirements of mobile devices. Limited by generation speed and model capabilities, even a company as strong as Apple has not been able to deploy a fully satisfactory LLM on mobile devices. On the latest iPhone 16 Pro series, only simple tasks are completed locally by a model with around 3 billion parameters, whereas complex tasks are still handled by cloud-based models like ChatGPT[16, 17]. Although in practical LLMs application transformer’s KV cache[18] can speed up the inference, it will cause considerable memory overhead, which presents an obstacle for on-device LLMs. In light of the rapid advancements of LLMs and the widespread adoption of 5G/6G wireless networks, a natural question arises: can wireless networks support LLMs? If so, how? The answer lies in fully leveraging the multidimensional resources of wireless networks, incorporating computing, communications, and caching (3C) to support LLMs and enhance user experience [19]. As a key technology of 5G, mobile edge computing (MEC) has been thoroughly studied to improve the quality of service for various network applications. Recently, edge-cloud collaborative training and fine-tuning are also researched[20, 21]. However, there is a lack of specialized optimization research tailored to the characteristics of LLMs in the scenario of distributed deployment in wireless networks. To address this issue, this paper aims to bridge the gap by proposing a distributed deployment of LLMs powered by mixture of experts (MoE), modeling and optimizing the latency during the inference phase, which can efficiently utilize the 3C resources at both the MEC server and mobile devices. The core idea of MoE architecture is to sparsify the neural networks (NNs) based on the observation of sparse activation of NNs and allow each expert to specialize in their specific tasks, reducing the floating point operations (FLOPs) to achieve acceleration and increasing model capacity[22]. Transformer with MoE111In this paper, MoE refers to Transformer with MoE unless otherwise specified.[23] replaces the original single dense feedforward neural network (FFN) with a gating network and multiple smaller expert networks, which often have the same structure and different hidden layer dimensions. The expert networks within the same MoE layer operate in parallel and independently, providing high fault tolerance and making it well-suited for wireless distributed deployment. Besides, we find during the inference phase of MoE-based LLMs, decreasing the number of participating experts will not degrade model performance, showcasing the robustness of MoE. Capitalizing on these attributes, we can deploy the gating network at MEC server and each expert network in an MoE layer on diverse mobile devices. Furthermore, due to the diversity of computing capabilities among the mobile devices and communication qualities between the base station (BS) and the mobile devices, how to achieve a good balance between the inference accuracy and latency also requires careful consideration. I-A Related Work Current mainstream LLMs utilize Transformer architecture[24]. LLMs based on the Transformer architecture can be categorized into three types: encoder-decoder, decoder-only, and encoder-only. For encoder-decoder structure, in the vanilla Transformer[24], the multi-head attention mechanism fully replaces traditional recurrent neural networks, making the architecture more suitable for parallel computing. For decoder-only structure, in [25], a decoder-only Transformer is utilized with the optimization objective of standard language modeling. This work achieves state of the art performance, and the model is named GPT. For the encoder-only structure, [26] designs Bidirectional Encoder Representations from Transformers (BERT) and applies the training paradigm of pre-training and fine-tuning to language model. BERT includes a base model with 110 million parameters, similar to GPT and a large model with 340 million parameters. The work [25] and [26] lay the foundation for the model architecture, training paradigm, and development direction of large language models. GPT-2 is a scaled-up version of GPT with 1.5 billion parameters, focusing on zero-shot performance in [27]. The work [10] proposes the scaling law of transformer-based language models and suggests that larger models trained on more data tend to perform better, supporting the later development of large language models. GPT-3 is released in [28] with 175 billion parameters and was the largest language model at that time. It is applied without fine-tuning and achieves state-of-the-art performance on various benchmarks. Following the scaling law, an increasing number of large language models have appeared with more parameters, and the largest open source model is Llama 3.1, with 405 billion parameters, based on a dense Transformer[29]. Large model size makes the training and inference computationally expensive. Various methods of training and inference have been proposed to improve model performance without excessive computational costs[22], among which the MoE architecture has been well-researched. The basic MoE layer consists of a gating network and a number of experts, which are simple feed-forward neural networks[30]. The work [22] introduces a Sparsely-Gated MoE and expands the LSTM-based language model to a configuration with 137 billion parameters. In the Transformer era, [23] replaces all Feed-forward layers in the model with MoE layers and achieves enhanced model capacity while substantially reducing the training time. Mistral AI successively releases two open-source MoE large language models, Mixtral-8x7B and Mixtral-8x22B, both achieving the state-of-the-art performance among open-source large models at the time of their release[31]. The work [32] introduces an adaptive MoE framework, AdaMV-MoE, designed for multi-task vision recognition. Unlike conventional MoE approaches with a fixed number of experts, AdaMV-MoE dynamically adjusts the number of active experts per task based on training dynamics, eliminating the need for manual tuning of model capacity. Based on the idea that harder tasks need more experts, the work [33] develops a method for dynamically adjusting the number and selection of experts to reduce computational costs for simple tasks while enhancing model performance for complex ones. Advance in MoE models have unlocked the potential of model capability and computational efficiency. On-device LLMs have been extensively researched as a promising solution for personal assistants. By running LLMs directly on devices such as smartphones or edge servers, they offer enhanced privacy, lower latency, and reduced dependence on cloud servers. The work [34] devises a KV cache compression and swapping method with accuracy tolerance awareness, significantly reducing the context switching latency and extending the capacity of active contexts. In [35], a highly efficient computation and memory framework named Edge-LLM is proposed, reducing computation and memory overhead through layer-wise unified compression and adaptive backpropagation depth reduction. MobileLLM is a model family with sub-billion parameters that surpasses previous sub-billion models on mainstream benchmarks by adopting deep and thin network architectures, embedding sharing, and a grouped-query attention mechanism[36]. With privacy considerations, [37] employs derivative-free optimization to update the local LLM’s parameters during on-device fine-tuning phase under the resource-constrained circumstances. (a) (b) Figure 1: (a) MoE-based LLMs architecture[23]; (b) The proposed WDMoE-based LLMs system model. I-B Contributions Motivated by the above, we explore a wireless distributed deployment architecture for LLMs with MoE, define and model key performance metrics of LLMs within the framework, and optimize resource allocation and expert selection to improve the LLMs service capabilities within the wireless network. The main contributions of this paper are summarized as follows: • We propose a novel wireless distributed MoE architecture, WDMoE, for LLMs. The fundamental principle of the WDMoE architecture is to leverage the independence and parallelism of expert networks by deploying them on multiple mobile devices, thereby utilizing the resource advantages of wireless networks to facilitate distributed deployment of large models. This architecture places the computationally intensive and memory-demanding multi-head attention mechanism on the MEC servers at BS. Through collaborative token processing between BS and mobile devices, the wireless network can support a large number of LLMs service requests, addressing the challenges of limited memory on a single device and data privacy concerns in cloud-based LLMs deployment. • We establish latency-aware performance metrics of the WDMoE-based LLMs. By analyzing the attention mechanism, we find that, during the wireless distributed deployment of LLMs with MoE, the latency for expert networks on different mobile devices to process tokens and return them to the BS varies. This discrepancy can cause earlier-arriving tokens to wait at the attention module. We model this latency, referred to as attention waiting latency, and design a bilevel optimization problem where the upper-level objective is to minimize this latency while ensuring model capabilities at the lower level, thereby reducing latency without compromising model performance. In addition, we propose an innovative metric, the weight latency ratio (WLR), to comprehensively consider the output weights of the MoE gating network and the attention waiting latency of each device. • We develop an expert selection policy to improve the performance. Based on the defined WLR, the expert selection policy can process tokens by considering the processing time and weight of each mobile device for allocated tokens. It dynamically adjusts the number of experts per token, thereby reducing network transmission and computational load. • We build a hardware testbed using NVIDIA Jetson kits to validate the effectiveness of the proposed WDMoE. We use three NVIDIA Jetson kits and one personal computer (PC) with an NVIDIA RTX 4070 Ti, serving as four mobile devices, each running one expert for each layer, and communicating with the server via WiFi. Both simulation results and hardware experiment results show that the proposed WDMoE architecture and expert selection policy effectively reduce the latency experienced by users. For example, compared to vanilla expert selection, the proposed WDMoE reduces latency by 45.75% on average on the PIQA dataset without model capability deterioration. The rest of this paper is organized as follows. The WDMoE-based LLM architecture is introduced in Section II. The system model and problem formulation are presented in Section III. The WDMoE expert selection policy and bandwidth allocation algorithm are introduced in Sections IV. Section V shows extensive simulation results. Finally, the hardware testbed experiments are presented in Section VI, and conclusions are drawn in Section VII."
https://arxiv.org/html/2411.06642v1,Antenna Coding Empowered by Pixel Antennas,"Pixel antennas, based on discretizing a continuous radiation surface into small elements called pixels, are a flexible reconfigurable antenna technology. By controlling the connections between pixels via switches, the characteristics of pixel antennas can be adjusted to enhance the wireless channel. Inspired by this, we propose a novel technique denoted antenna coding empowered by pixel antennas. We first derive a physical and electromagnetic based communication model for pixel antennas using microwave multiport network theory and beamspace channel representation. With the model, we optimize the antenna coding to maximize the channel gain in a single-input single-output (SISO) pixel antenna system and develop a codebook design for antenna coding to reduce the computational complexity. We analyze the average channel gain of SISO pixel antenna system and derive the corresponding upper bound. In addition, we jointly optimize the antenna coding and transmit signal covariance matrix to maximize the channel capacity in a multiple-input multiple-output (MIMO) pixel antenna system. Simulation results show that using pixel antennas can enhance the average channel gain by up to 5.4 times and channel capacity by up to 3.1 times, demonstrating the significant potential of pixel antennas as a new dimension to design and optimize wireless communication systems.","Antennas play a significant role in wireless communication systems. Utilizing multiple antennas, multiple-input multiple-output (MIMO) systems have been one of the most celebrated wireless communication technologies over the past few decades. It has evolved from point-to-point MIMO in the third generation (3G) to multiuser MIMO in the fourth generation (4G) and massive MIMO in the fifth generation (5G), and will still be a dominating technology in the upcoming sixth generation (6G) [1]. However, the antennas utilized in conventional MIMO technologies have fixed configurations and characteristics such as operating frequency, radiation pattern, and polarization, which are not involved in the signal processing and system optimization in wireless communications. As 6G mobile communication strives to push the performance to extreme levels far beyond current 5G mobile communications, it is necessary to seek a paradigm shift in antenna technology to achieve a new degree of freedom in designing and optimizing wireless communication systems, so as to break through the current performance limit. Pixel antennas are a flexible antenna technology to design highly reconfigurable antennas and dates back to 2004 [2]. The concept of the pixel antenna is based on discretizing a continuous radiation surface into small elements, which are referred to as pixels, and connecting adjacent pixels through hardwires or RF switches [3], [4], [5], [6] and [7]. By controlling the connections between pixels, various antenna topologies can be formed so that the pixel antenna can be reconfigured to achieve a wide range of distinct antenna characteristics such as operating frequency, radiation pattern, and polarization. For example, frequency-reconfigurable pixel antennas, which can reconfigure the operating frequency from 1.56 GHz to 3.3 GHz and from PCS band to UMTS band, have been designed in [3] and [4], and pattern-reconfigurable pixel antennas, which can reconfigure the radiation pattern to implement 360\text{\textdegree} single- or multi-beam steering, have been designed in [5], [6], and [7]. Moreover, various pixel antennas have been designed for different applications. In [8], a reconfigurable intelligent surface with pixelated elements, which can reconfigure the phase shift of reflected waves, has been designed. In [9], [10], and [11], multiport pixel rectennas, which can maximize the output dc power for ambient RF energy harvesting, have been developed. In [12], MIMO antennas with pixelated surface, which provide low mutual coupling and spatial correlation to maximize the ergodic capacity, have been developed. In [13], defected ground structures with pixelated grid, which suppress cross-polarization and achieve circular polarization, have been designed. While these works [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13] have designed pixel antennas with significant performance enhancement, the investigations are limited at the level of antenna hardware design and do not consider the impact on wireless communications at the level of the system. Thus, it is necessary to explore using pixel antennas to design and optimize wireless communication systems. In parallel with the development of pixel antennas, the concept of the fluid antenna system (FAS) has also been proposed and introduced in 2020 [14]. FAS originated from the emergence of mechanically flexible antennas such as liquid antennas based on liquid metals or ionized solutions [15], which enables a single antenna freely switching the position in a small linear space. Moreover, FAS can be implemented by any appropriate reconfigurable technique including electronically flexible pixel antennas, where the pixels can be turned on-and-off instantly so that several pixels can be turned on to form an antenna port in a particular position. One of the first pixel antenna designs for an FAS has been demonstrated in [16] to show that a single pixel antenna can mimic switching positions in a small linear space and be useful for FAS. Leveraging the position-switchable property, FAS can select the optimal position in a given space to adapt to fading channels [17] and thus enhance the system performance such as level crossing rate [14], diversity gain [18], and outage probability [19]. FAS has also been utilized to assist MIMO communication systems [20], [21], [22], [23]. Specifically, the capacity, diversity-multiplexing tradeoff, spectral efficiency, and energy efficiency for MIMO-FAS have been investigated in [20], [21], [22] and the rate maximization for MIMO-FAS based on statistical channel state information (CSI) has been studied in [23]. In addition, a novel multiple access based on FAS, denoted as fluid antenna multiple access (FAMA), has been proposed in [24], and FAMA can be categorized into fast FAMA [25] and slow FAMA [26], Moreover, FAS has been investigated to enhance emerging areas such as secret communications [27] and full duplex communications [28]. While the emergence and development of FAS [14], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28] has preliminarily demonstrated the potential of pixel antennas for designing and optimizing wireless communication system, there is much further potential for pixel antennas to be exploited in wireless communication. For example, utilizing the individual pixels inside a pixel antenna, and the connections between them, can open up new possibilities for their use in wireless communication. To fully exploit the potential of pixel antennas for wireless communication, there remains two open problems: 1) how to derive a physical and electromagnetic (EM) based communication model for pixel antennas, and 2) how to efficiently utilize the flexibility of pixel antennas to enhance wireless communications. In this paper, we propose using pixel antennas to enhance wireless communication systems with an EM based model and a systematic and efficient approach. In comparison with conventional wireless communication systems using antennas with fixed configuration, using pixel antennas allows designing and optimizing wireless communication systems in a new dimension through adjusting the antenna configuration, and thus the wireless communication systems performance can be significantly enhanced. The contributions of the paper are summarized as follows. First, we propose a novel technique called antenna coding empowered by pixel antennas to enhance wireless communication systems. By adjusting the connections between adjacent pixels through switches, the characteristics of the pixel antenna such as impedance, radiation pattern, and polarization can be controlled. Inspired by this, we propose antenna coding, which is a technique to control antenna configuration and characteristics through binary codes representing switches for enhancing wireless systems. With antenna coding, wireless systems can be optimized with a new dimension and thus achieve enhanced performance compared to conventional systems with fixed antenna configuration. Second, we derive a physical and EM based model for pixel antennas. Using microwave multiport network theory, we analyze the pixel antenna and model its configuration and characteristics such as radiation pattern as functions of a binary vector referred to as the antenna coder which represents the switch on and off states. Further, using the beamspace channel representation, we incorporate radiation patterns into the channel to derive a communication model for pixel antennas, where the channel can be controlled by antenna coder, allowing antenna coding optimization to enhance wireless systems. Third, we optimize the antenna coding to maximize the channel gain in single-input single-output (SISO) pixel antenna systems. The antenna coding optimization is a binary optimization problem and can be solved by a successive exhaustive Boolean optimization approach. To reduce the computational complexity for optimization, we propose a codebook design for antenna coding and optimize the antenna coder by searching the codebook. Fourth, we analyze the average channel gain of SISO pixel antenna systems and find that the upper bound of average channel gain is the effective aerial degrees-of-freedom of pixel antennas which can be found by singular value decomposition of the open-circuit radiation pattern matrix. Fifth, we jointly optimize the antenna coding and transmit signal covariance matrix to maximize the channel capacity in MIMO pixel antenna systems by using exhaustive Boolean optimization approach and searching of the codebook design. Sixth, we evaluate the performance of SISO and MIMO pixel antenna systems compared to conventional SISO and MIMO systems using antennas with fixed configuration. The simulation results show that using pixel antennas can enhance the average channel gain by up to 5.4 times and the channel capacity by up to 3.1 times, demonstrating the significant potential of pixel antennas in wireless communication systems. Organization: Section II introduces the pixel antenna model and antenna coding. Section III presents the SISO pixel antenna system and antenna coding design for channel gain maximization. Section IV presents the MIMO pixel antenna system and antenna coding design for capacity maximization. Section V provides performance evaluation for the SISO and MIMO pixel antenna system. Section VI concludes this work. Notation: Bold lower and upper case letters represent vectors and matrices, respectively. A symbol without bold font denotes a scalar. \mathbb{R} and \mathbb{C} represent real and complex number sets, respectively. \mathbb{E}\left[\cdotp\right] denotes the expectation. \left(\cdotp\right)^{+}denotes the positive part. a^{\ast} and \left|a\right| denote the conjugate and modulus of a complex number a, respectively. \left[\mathbf{a}\right]_{i} and \left\|\mathbf{a}\right\| denote the ith element and l_{2}-norm of a vector \mathbf{a}, respectively. \mathbf{A}^{T}, \mathbf{A}^{H}, \left[\mathbf{A}\right]_{:,i}, \left[\mathbf{A}\right]_{i,j}, \left|\mathbf{A}\right|, and \textrm{Tr}\left(\mathbf{A}\right) denote the transpose, conjugate transpose, ith column, \left(i,j\right)th element, determinant, and trace of a matrix \mathbf{A}, respectively. \mathcal{CN}(\boldsymbol{0},\boldsymbol{\Sigma}) denotes the circularly symmetric complex Gaussian distribution with mean 0 and covariance matrix \boldsymbol{\Sigma}. \text{diag}\left(a_{1},...,a_{N}\right) denotes a diagonal matrix with entries a_{1},...,a_{N}. \mathbf{I} denotes an identity matrix."
https://arxiv.org/html/2411.06578v1,Enabling ISAC in Real World: Beam-Based User Identification with Machine Learning,"Leveraging perception from radar data can assist multiple communication tasks, especially in highly-mobile and large-scale MIMO systems. One particular challenge, however, is how to distinguish the communication user (object) from the other mobile objects in the sensing scene. This paper formulates this user identification problem and develops two solutions, a baseline model-based solution that maps the objects angles from the radar scene to communication beams and a scalable deep learning solution that is agnostic to the number of candidate objects. Using the DeepSense 6G dataset, which have real-world measurements, the developed deep learning approach achieves more than 93.4\% communication user identification accuracy, highlighting a promising path for enabling integrated radar-communication applications in the real world.","Employing large antenna arrays in millimeter wave (mmWave) communication systems is essential to provide sufficient beamforming gains and receive power. Minimizing the beam training overhead, however, is a challenging task especially in highly-mobile applications. Towards addressing this challenge, integrated sensing and communications (ISAC) can be a keystone, where wireless communications are aided by radar sensing information. This information can be utilized to build perception about the environment and the target objects that affect the communication channels. One main challenge in this framework, however, is that the objects determined in both the sensing and communication domains need to be matched to facilitate accurate sensing aid to communication in scenarios with multiple mobile objects in the sensing scenes. We term this problem user identification. In this paper, we investigate how to solve the user identification problem in the radar sensing scenes via the use of selected beam information and evaluate the feasibility using a real-world demonstration. Various types of sensing information, e.g., camera images [1], and radar [2, 3, 4, 5], have been considered for aiding communication objectives. In [1], images captured by an RGB camera attached to the basestation are considered for the beam prediction and blockage prediction tasks. Similarly, the measurements from an out-of-band radar have been studied for beam prediction [2, 3] and blockage prediction tasks [4]. To realize radar-aided systems in the real world, however, there are many major questions to be answered. To this end, although [3, 4] included an evaluation in a real-world setup, they were mainly limited to the single-target scenarios, and the identification of the user has not been considered. In the joint sensing and communication literature, where the sensing and communication antennas are common, there has been some work for the user identification [5, 6, 7], where the users are identified based on Euclidean distance [5] and Kullback-Leibler divergence [7] of the radar/communication estimated positions, and GPS positions [6]. These works, however, did not (i) consider an off-the-shelf external radar, (ii) evaluate the performance in a real-world system, (iii) utilize machine learning, which may be a key for ISAC systems [8], and (iv) use the beam index of the communication system for identification, which is readily available in the deployments. Therefore, in this work, we first define the user identification problem in radar-aided communication systems that use out-of-band frequency modulated continuous wave (FMCW) radars. Specifically, using the radar-generated measurements of the detected objects and the beam indices selected to serve the communication user, we develop a robust and scalable deep neural network (DNN) solution for this problem. For the evaluation, we build a real-world dataset as a part of the Deepsense 6G framework [9] and compare our approach with baseline solutions on this dataset. In our evaluations, the proposed DNN solution offers 93.4\% accuracy with over \%20 gain over the baselines and shows promising potential for real-world radar-aided communication systems."
https://arxiv.org/html/2411.06550v1,A Practical Validation of RIS Detection and Identification,"Reconfigurable intelligent surface (RIS)-assisted communication is a key enabling technology for next-generation wireless communication networks, allowing for the reshaping of wireless channels without requiring traditional radio frequency (RF) active components. While their passive nature makes RISs highly attractive, it also presents a challenge: RISs cannot actively identify themselves to user equipments (UEs). Recently, a new method has been proposed to detect and identify RISs by letting them modulate their identities in the signals reflected from their surfaces. In this letter, we first propose a new and simpler modulation method for RISs and then validate the concept of RIS detection and identification (RIS-ID) using a real-world experimental setup. The obtained results validate the RIS-ID concept and show the effectiveness of our proposed modulation method over different operating scenarios and systems settings.","Reconfigurable intelligent surfaces (RISs), composed of large arrays of controllable elements, have emerged as an enabling technology for next-generation wireless communication systems, particularly in the context of 6G networks. By controlling the amplitude, phase, and polarization of the signals hitting their surfaces, RISs reshape the propagation environment and bring several advantages, such as extended coverage, enhanced data rates, and increased energy efficiency [1]. Moreover, RISs can facilitate better interference management [2], provide robust security through signal manipulation [3], and enable precise localization for user equipment (UE) by altering the signal propagation paths[4]. While RISs are commonly used as passive beamforming arrays in wireless systems to control the propagation environment, several works have explored their potential to be used as an over-the-air modulator in wireless transmission systems[5]. In [6], an RIS-based 8-PSK transmitter for single-input-single-output (SISO) transmission is proposed, which modulates the incident signal by controlling the phase response of the RIS elements. This approach achieves data transmission at a rate of 6.144 Mb/s without the need for traditional RF components. The authors of [7] extended the idea to a multiple-input-multiple-output (MIMO) systems and developed an RIS-based RF chain-free 16-QAM transmitter, achieving a data rate of 20 Mb/s. Another notable application of RIS-based modulation is studied in [8], where RISs are utilized for UE localization. In this system, the base station (BS) transmits an unmodulated carrier signal, which is then modulated by multiple RISs at different time slots, with each RIS imparting a unique m-sequence. These distinct m-sequences enable the UE to differentiate received signals from different RISs. Finally, UE’s location is estimated by applying time-difference-of-arrival (TDOA) method on the received signals. However, existing studies often presume that UEs are informed about the presence of deployed RISs, which is a reasonable assumption when the network provides this information to the UE. Nevertheless, the existence of RISs nearby, reported to the UE by the network, does not guarantee the establishment of a communication link due to potential obstacles between the RIS and the UE [9]. Therefore, to use an RIS effectively, it is essential first to determine whether the RIS is reachable by the UE. To the best of the authors’ knowledge, this problem was first addressed in the literature in [9], where the authors proposed a method called RIS-ID to enable UE to identify reachable RISs in its environment. The RIS-ID method utilizes binary phase shift keying (BPSK) modulation by leveraging phase changes at the RIS. This method allowed the embedding of unique phase shift reflection patterns (PSRPs) into the carrier signal impinging on the RIS surfaces, enabling the UE to detect and uniquely identify reachable RISs. However, in [8], since the RIS detection process is performed before synchronization, reflected BPSK symbols are expected to be distorted due to time, frequency, and phase offsets at the UE side, negatively affecting the correlation amplitude. In this letter, we first propose a new modulation method that is less sensitive to synchronization issues, particularly phase and frequency offsets, by leveraging the phase-dependent amplitude variations associated with RIS elements to mimic amplitude shift keying (ASK) modulation. Second, we validate the RIS-ID concept in a real-world experimental setup using different operating scenarios and systems settings. The remainder of the letter is organized as follows. Section II presents the system model used for the proposed method and the detection algorithm that was developed to determine RIS reachability. Section III outlines the experimental setup and implementation. Section IV provides the experimental results and performance evaluation. Finally, Section V concludes the letter."
https://arxiv.org/html/2411.06508v1,Understanding the Role of Equivariance in Self-supervised Learning,"Contrastive learning has been a leading paradigm for self-supervised learning, but it is widely observed that it comes at the price of sacrificing useful features (e.g., colors) by being invariant to data augmentations. Given this limitation, there has been a surge of interest in equivariant self-supervised learning (E-SSL) that learns features to be augmentation-aware. However, even for the simplest rotation prediction method, there is a lack of rigorous understanding of why, when, and how E-SSL learns useful features for downstream tasks. To bridge this gap between practice and theory, we establish an information-theoretic perspective to understand the generalization ability of E-SSL. In particular, we identify a critical explaining-away effect in E-SSL that creates a synergy between the equivariant and classification tasks. This synergy effect encourages models to extract class-relevant features to improve its equivariant prediction, which, in turn, benefits downstream tasks requiring semantic features. Based on this perspective, we theoretically analyze the influence of data transformations and reveal several principles for practical designs of E-SSL. Our theory not only aligns well with existing E-SSL methods but also sheds light on new directions by exploring the benefits of model equivariance. We believe that a theoretically grounded understanding on the role of equivariance would inspire more principled and advanced designs in this field. Code is available at https://github.com/kaotty/Understanding-ESSL.","Self-supervised learning (SSL) of data representations has made remarkable progress. Existing SSL methods can be categorized into two types: invariant SSL (I-SSL) and equivariant SSL (E-SSL). The idea of I-SSL is to encourage the representation to be invariant to input augmentations (e.g., color jittering). Contrastive learning that pulls positive samples closer and pushes negative samples apart is widely believed to be a prominent I-SSL paradigm, leading to rapid progress in recent years [13, 50, 5, 80, 46, 30, 3, 32, 33, 60, 49, 14, 37, 15, 77, 64, 81]. Nevertheless, since invariant representations lose augmentation-related information (e.g., color information), their performance on downstream tasks can be hindered, as frequently observed in practice [47, 17, 34]. In view of these limitations of I-SSL, there has been a growing interest in revisiting E-SSL. Contrary to I-SSL, E-SSL learns representations that are sensitive to (or aware of) the applied transformation.111A rigorous definition of feature equivariance requires more restrictions; for example, the transformations must be invertible. In existing SSL literature, equivariance is (loosely) referred to as the property that features are aware of general input transformations (not necessarily invertible). We follow this convention in this paper. For instance, RotNet [31] is an early exemplar of E-SSL that learns discriminative features by predicting the rotation angles from randomly rotated images [43]. It has also been exploited in recent works and achieves promising improvements in conjunction with I-SSL [73, 67, 17, 18, 25, 54, 34]. Recently, E-SSL has shown potential for serving as the foundation for building visual world models [26]. Despite this intriguing progress in practice, compared to invariant SSL methods with a vast literature of theoretical analyses [58, 66, 48, 35, 68, 59, 78], there is little theoretical understanding of equivariant SSL methods. A particular difficulty lies in the understanding of the pretraining tasks, which may seem quite irrelevant to downstream classification. Taking RotNet as an example, the random rotation angle is independent of the image class, so it is unclear how rotation-equivariant representations are helpful for image classification. Generally speaking, it is unclear why, when, and how equivariant representations can generalize to downstream tasks. In view of this situation, the primary goal of this paper is not to design a new E-SSL variant, but to revisit the basic E-SSL methods and understand their essential working mechanisms. We fulfil this goal by proposing a simple yet theoretically grounded explanation for understanding general E-SSL from an information-theoretic perspective. We show that the effectiveness of E-SSL can be understood via the “explaining-away” effect in statistics, which implies an intriguing synergy effect between the image class C and the equivariant transformation A (e.g., rotation) such that almost surely, they have strictly positive mutual information when given the input X, i.e., I(C;A|X)>0 that explains the effectiveness of E-SSL. This understanding also provides valuable guidelines for practical E-SSL design with three principles to pursue a large synergy effect I(C;A|X): lossy transformations, class relevance, and shortcut pruning, as been validated on practical datasets. Theoretically, we also quantitatively analyze the influence of data transformation on the synergy effect with a theory model. Equipped with these theoretical findings, we further revisit advanced E-SSL methods in the recent literature [73, 67, 17, 18, 25, 54, 34] and find that many of these empirical successes can be well explained in our framework from two aspects: finer equivariance and multivariate equivariance. Besides, motivated by our theory, we also discover an under-explored aspect of E-SSL, model equivariance, where we show that adopting equivariant neural networks can yield strong improvements for certain E-SSL methods. These fruitful theoretical and practical merits suggest that our E-SSL theory provides a general and practically useful explanation for understanding and designing E-SSL methods that have the potential to guide future E-SSL designs."
https://arxiv.org/html/2411.06291v1,TinyML NLP Approach for Semantic Wireless Sentiment Classification,"Natural Language Processing (NLP) operations, such as semantic sentiment analysis and text synthesis, may often impair users privacy and demand significant on device computational resources. Centralized learning (CL) on the edge offer alternative energy efficient approach, yet requires the collection of raw information, which affects the users privacy. While Federated learning (FL) preserves privacy, it requires high computational energy on board tiny user devices. We introduce split learning (SL) as an energy efficient alternative, privacy preserving tiny machine learning (TinyML) scheme and compare it to FL and CL in the presence Rayleigh fading and additive noise. Our results show that SL reduces processing power and CO2 emissions while maintaining high accuracy, whereas FL offers a balanced compromise between efficiency and privacy. Hence, this study provides insights into deploying energy-efficient, privacy-preserving NLP models on edge devices.","Artificial Intelligence (AI) has gained widespread adoption, with applications ranging from text and image classification to text and image generation. A key area of growth is NLP, which powers virtual assistants and human language classification systems. Large language models (LLMs), such as OpenAI’s GPT series [1], Gemini [2], and BERT, built on Transformer architectures [3], have transformed NLP by enabling machines to perform complex language tasks with high accuracy. However, these models require significant computational resources for both training and inference, posing challenges for deployment on resource-constrained devices. LLMs demand substantial storage and processing power. The high dimensionality of language data and large vocabularies further increase the computational burden [4]. Data privacy is another significant concern, as training robust models often requires diverse datasets, which can raise issues when handling sensitive information, such as in healthcare or government sectors. Additionally, deploying models on edge devices introduces communication challenges. Wireless data transmission over channels like WiFi is susceptible to noise, fading, limited bandwidth and unstable connections, which ,ay affect communication efficiency. TinyML mixed models have evolved to address the above concerns. For instance, model compression techniques, such as pruning [5], quantization [6], and knowledge distillation [7], help reduce model sizes and computational requirements. TinyBERT [8] and MobileBERT [9], for example, utilize knowledge distillation to create smaller models, while quantization techniques, like in LLaMA [10], enable efficient execution on low-resource devices. FL offers a decentralized model training approach, allowing multiple users to collaboratively train a global model while keeping their data local. Although, this method addresses data privacy concerns [11], it might be power hungry for tiny device batteries. To this end, SL [12] divides the model training process between users and a server. Users transmit activations from the initial model layers, reducing computational load and enhancing data privacy. In this paper, we propose two frameworks to address computational challenges and privacy concerns in text emotion classification: one based on FL and the other on SL. First, we focus on semantic extraction by utilizing quantization to significantly reduce model size, enabling deployment on resource-limited devices. Second, we emphasize privacy preservation by ensuring that data remains on the device while transmitting only the necessary information for model training. The proposed methods prove roubustness in challenging channel conditions while reducing the overall energy consumption and CO2 emissions, contributing to TinyML initiatives. The remainder of this paper is structured as follows: Section II covers the system design and experimental setup, including both frameworks of FL and SL techniques. Section III presents the experimental results, focusing on accuracy, energy consumption, and the impact of noise and fading. Finally, Section IV provides conclusions and discusses potential directions for future work. Figure 1: Federated learning system design"
https://arxiv.org/html/2411.06155v1,HiHa: Introducing Hierarchical Harmonic Decomposition to Implicit Neural Compression for Atmospheric Data,"The rapid development of large climate models has created the requirement of storing and transferring massive atmospheric data worldwide. Therefore, data compression is essential for meteorological research, but an efficient compression scheme capable of keeping high accuracy with high compressibility is still lacking. As an emerging technique, Implicit Neural Representation (INR) has recently acquired impressive momentum and demonstrates high promise for compressing diverse natural data. However, the INR-based compression encounters a bottleneck due to the sophisticated spatio-temporal properties and variability. To address this issue, we propose Hierarchical Harmonic decomposition implicit neural compression (HiHa) for atmospheric data. HiHa firstly segments the data into multi-frequency signals through decomposition of multiple complex harmonic, and then tackles each harmonic respectively with a frequency-based hierarchical compression module consisting of sparse storage, multi-scale INR and iterative decomposition sub-modules. We additionally design a temporal residual compression module to accelerate compression by utilizing temporal continuity. Experiments depict that HiHa outperforms both mainstream compressors and other INR-based methods in both compression fidelity and capabilities, and also demonstrate that using compressed data in existing data-driven models can achieve the same accuracy as raw data. The source code can be found at https://anonymous.4open.science/r/HiHa-EB13/.","Meteorology, a significant natural science, necessitates the analysis and integration of multiple atmospheric variables over hundreds of years (Bi et al. 2023). Produced by meteorological organizations (e.g. ECMWF, CMA, JMA, etc.), petabytes of atmospheric data requires to be shared with researchers globally per day. Therefore, the rapid development of meteorological research has spawned a huge demand for atmospheric data storage and transmission, while bringing about substantial costs citeprasp2024weatherbench. This presents an enduring challenge, bringing huge stress to data storage and transmission (Han, Guo et al. 2024). To alleviate the issue, many compression methods have been developed, such as BUFR, GRIB1, GRIB2 (Murrieta-Mendoza 2015), NetCDF (Rew Russ 1990), etc. These lossless compressions are able to provide up to 4\times compression ratio, but still has >100 TB for 40 years’ hourly data of 5 variables (basic data for training Pangu (Bi et al. 2023)), which is insufficient in addressing the performance bottleneck of atmospheric data transmission (Han, Guo et al. 2024). Figure 1: Harmonic decomposition of atmospheric data (an example of humidity in 500hpa). Implicit Neural Representation (INR), using periodic activation function (Sitzmann et al. 2020), has brought innovation to data representation, and possesses the ability to fit models accurately and rapidly in a concise manner (Mildenhall, Srinivasan et al. 2020). The INR-based compression technique, Implicit Neural Compression (INC), is gaining success on natural data compression ratio and enhanced spatial continuity, such as SCI (Yang, Xiao et al. 2023), MINER (Saragadam et al. ) and Gaussian Splatting (Zhang, Ge et al. 2024), etc. The inherent continuity in INR is highly compatible with the spectral characteristics of dynamic equations of atmospheric motion (Sitzmann et al. 2020). In addition, given sufficient parameters, the universal approximation theorem of neural networks promises high fidelity representation (Gallant 1988). The above perspectives illustrate the potential of INR to generate an efficient and compact representation of atmospheric data. Despite the high efficiency on other natural data (Yang 2023; Kim, Bauer et al. 2024), the INC methods often encounter over-smoothness and low efficiency on dealing with atmospheric data. As shown in Fig. 1, the sophisticated spatio-temporal properties and variability caused by superposition of multiple complex harmonics leads to a high requirement of the fitting ability of neural networks(Sasamori 1972), and thereby causing the issue. The issue can be further listed into the following crucial insights: • Atmospheric data contain various harmonics and the fitting rules are sophisticated. The description of such processes within a confined parameter space poses significant challenges (Shin, Kim et al. 2024); • Spatial singularities will affect the searching process of the best parametric space as noisy bias, increasing the difficulty of the INR convergence (Martel, Lindell et al. 2021); • Due to the spherical topology of earth, employing Cartesian basis vector would result in the geographical information loss (Rußwurm, Klemmer et al. 2023); • The existing methods disregard the temporal continuity in atmospheric data, causing inefficiency in temporal data compression(Yang 2023); Inspired by the above insights, we made statistical analysis of different harmonic components and propose Hierarchical Harmonic decomposition implicit neural compression for atmospheric data (HiHa). We explore the characteristics and spatial distribution of multiple harmonics in atmospheric data, and decompose the harmonic components into low, mid and high-frequency based on the harmonic frequency. Leveraging spherical coordinates basis, we conduct a frequency-based hierarchical compression strategy including a multi-scale INR module, an iterative decomposition module and a sparse storage module on harmonics of low, medium and high frequency, hierarchically. Moreover, we institute temporal residual compression module and utilizes a temporal multiscale Laplacian pyramid architecture for accelerating compression of atmospheric data over successive periods. Comprehensive experimental results demonstrates that HiHa achieves impressive compression accuracy and efficiency compared with other baselines. Specifically, at an atmospheric acceptable accuracy, HiHa achieves a compression ratio of over 200\times within 43 seconds in error of 1e-3, surpassing other INC baselines in terms of both speed and accuracy. Moreover, HiHa can achieve error of 1e-5 compared to other methods, surpassing their limitations, with a compression ratio of up to 27\times within minutes. Overall, the contribution of this paper are summarized in the following three aspects: • The spatial characteristics are explored and analyzed in mathematical analysis, and theoretically deduce the separation criterion for harmonic; • A frequency-based hierarchical compression strategy is proposed, incorporating hierarchical harmonic decomposition and utilizing spherical coordinates and atmospheric pressure-level as the fundamental vectors; • Temporal residual module is established which contains a multiscale Laplacian Pyramid architecture and a retraining process to accelerate compression over successive periods; • The results of comprehensive experiments demonstrate that HiHa can achieve better compression accuracy while incurring minimal compression overhead compared with other methods."
https://arxiv.org/html/2411.05936v1,Mitigating Hallucination | ZeroG: An Advanced Knowledge Management Engine,"The growth of digital documents presents significant challenges in efficient management and knowledge extraction. Traditional methods often struggle with complex documents, leading to issues such as hallucinations and high latency in responses from Large Language Models (LLMs). ZeroG, an innovative approach, significantly mitigates these challenges by leveraging knowledge distillation and prompt tuning to enhance model performance.ZeroG utilizes a smaller model that replicates the behavior of a larger teacher model, ensuring contextually relevant and grounded responses, by employing a black-box distillation approach, it creates a distilled dataset without relying on intermediate features, optimizing computational efficiency. This method significantly enhances accuracy and reduces response times, providing a balanced solution for modern document management.Incorporating advanced techniques for document ingestion and metadata utilization, ZeroG improves the accuracy of question-and-answer systems. The integration of graph databases and robust metadata management further streamlines information retrieval, allowing for precise and context-aware responses. By transforming how organizations interact with complex data, ZeroG enhances productivity and user experience, offering a scalable solution for the growing demands of digital document management.","ZeroG significantly improves the quality of responses by a large margin by mitigating hallucinations through the implementation of knowledge distillation and prompt tuning, ensuring responses are accurate and grounded. We differ from [1], which involves fine-tuning the student model, by utilizing a black-box distillation approach without fine-tuning. This approach reduces response latency and enhances overall system reliability. ZeroG leverages LLMs to generate Question and Answer (QnA) pairs from existing documents, storing them in a vector store. When a user query is received, similarity searches using techniques like MMR determine whether it can be addressed by pre-existing QnA pairs or requires a more tailored response using document-specific information. Despite advances in natural language processing, traditional methods often struggle with real-time data updates and accurately handling complex documents, which include sensitive data. This paper explores transforming these presentations into markdown files for easier ingestion into vector stores, enhancing QnA accuracy without frequent reengineering. We also investigate integrating graph databases and utilizing document metadata to refine search and organization capabilities. By pre-generating question sets and caching commonly asked queries, the system streamlines responses, ensuring they are precise and contextually relevant. This paper presents some of the techniques we explored and employed to overcome current limitations in document and knowledge management, significantly improving productivity and effectiveness in handling complex document types."
https://arxiv.org/html/2411.04370v1,"Non-Reciprocal Beyond Diagonal RIS:
Multiport Network Models and Performance Benefits in Full-Duplex Systems","Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) is a new advance in RIS techniques that introduces reconfigurable inter-element connections to generate scattering matrices not limited to being diagonal. BD-RIS has been recently proposed and proven to have benefits in enhancing channel gain and enlarging coverage in wireless communications. Uniquely, BD-RIS enables reciprocal and non-reciprocal architectures characterized by symmetric and non-symmetric scattering matrices. However, the performance benefits and new use cases enabled by non-reciprocal BD-RIS for wireless systems remain unexplored. This work takes a first step toward closing this knowledge gap and studies the non-reciprocal BD-RIS in full-duplex systems and its performance benefits over reciprocal counterparts. We start by deriving a general RIS aided full-duplex system model using a multiport circuit theory, followed by a simplified channel model based on physically consistent assumptions. With the considered channel model, we investigate the effect of BD-RIS non-reciprocity and identify the theoretical conditions for reciprocal and non-reciprocal BD-RISs to simultaneously achieve the maximum received power of the signal of interest in the uplink and the downlink. Simulation results validate the theories and highlight the significant benefits offered by non-reciprocal BD-RIS in full-duplex systems. The significant gains are achieved because of the non-reciprocity principle which implies that if a wave hits the non-reciprocal BD-RIS from one direction, the surface behaves differently than if it hits from the opposite direction. This enables an uplink user and a downlink user at different locations to optimally communicate with the same full-duplex base station via a non-reciprocal BD-RIS, which would not be possible with reciprocal surfaces.","As an energy-efficient passive planar surface which could be flexibly deployed in wireless propagation environments, reconfigurable intelligent surface (RIS) has been proven to have benefits in enhancing the communication quality and enlarging the wireless coverage in various scenarios [1, 2, 3]. Based on microwave engineering theory [4], RIS can be generally modeled as a large number of scattering elements connected to a multiport reconfigurable impedance network [5]. Most of the existing literature focuses on the use of diagonal (D) RIS, in which each port of the reconfigurable impedance network is connected to its own impedance to ground, mathematically leading to a diagonal scattering matrix [5]. Benefiting from the flexible circuit topology design of the reconfigurable impedance network, a new advance in RIS techniques has been recently proposed, namely beyond diagonal (BD) RIS [6]. The concept of BD-RIS is proposed by inter-connecting ports with additional reconfigurable impedance components, which mathematically generates scattering matrices not limited to being diagonal. This enables waves impinging on BD-RIS to travel through the surfaces, hence offering a new degree of freedom for wave manipulation in the analog RF domain. As such, BD-RIS includes D-RIS as a special case, while it goes beyond D-RIS to enable more flexible beam manipulations to the wireless signals and thus provide significant performance gains [6, 5, 7]. An N_{I}-element BD-RIS with an N_{I}-port lossless reconfigurable impedance network is generally characterized by a unitary scattering matrix \mathbf{\Theta}, \mathbf{\Theta}^{\mathsf{H}}\mathbf{\Theta}=\mathbf{I}_{N_{I}}. In addition, based on if the reconfigurable impedance network is reciprocal or not, BD-RIS can be categorized as two branches, namely, reciprocal BD-RIS and non-reciprocal BD-RIS, resulting in mathematically symmetric matrices with \mathbf{\Theta}=\mathbf{\Theta}^{\mathsf{T}}, or asymmetric scattering matrices with \mathbf{\Theta}\neq\mathbf{\Theta}^{\mathsf{T}}. Based on the above classification, D-RIS is a special case of reciprocal BD-RIS with \mathbf{\Theta} being diagonal and symmetric, while non-reciprocity of the reconfigurable impedance network is an additional degree of freedom arising from BD-RIS111Conventional D-RIS are always reciprocal since the scattering matrix is a simple diagonal phase shift matrix that is symmetric, hence non-reciprocity can only be enabled by BD-RIS.. Reciprocal BD-RIS has been studied covering perspectives in modeling and architecture design, such as designing the circuit topologies to generate group/fully/forest/tree-connected architectures [5, 7], in mode analysis [6], in beamforming design [8, 9], and in hardware impairment analysis [10]. Non-reciprocal BD-RIS, however, is less studied. There has been one representative work focusing on the modeling and implementation of a specific model, whose scattering matrix is non-diagonal and asymmetric with N_{I} nonzero off-diagonal entries [11]. This work is further generalized to a non-diagonal group-connected design [12], which provides additional flexibility than the model in [11] in wave manipulation due to the increasing number of nonzero entries of the scattering matrix. To find the scenarios where non-reciprocal BD-RIS gives high performance and unique advantages over reciprocal BD-RIS and D-RIS, one interesting direction has recently been discovered in [13]. In this work, the non-reciprocal BD-RIS proposed in [11] has been proven to have benefits over D-RIS in channel attack by breaking the reciprocity of RIS-aided uplink and downlink channels. Inspired by this work, another meaningful potential direction envisioned in [14] is to analyze the behavior of reciprocal and non-reciprocal BD-RISs in wireless full-duplex systems [15, 16, 17], which enable simultaneous uplink and downlink transmissions and are thus sensitive to the wireless channel reciprocity. Based on the above considerations, in this paper, we identify a first scenario where gains arising from non-reciprocity in BD-RIS can be very significant. This further leads to the following contributions. First, we use multiport network theory to derive the general RIS aided full-duplex system model, which consists of a multi-antenna full-duplex base station, an RIS, an uplink multi-antenna user, and a downlink multi-antenna user. We also derive its simplified version based on physically consistent assumptions, where the impact of self-interference at the full-duplex base station is highlighted. Second, in the derived system model, we analyze the impact of the structural scattering at BD-RIS, which refers to the “virtual” direct link between the base station and the user constructed by BD-RIS when it is turned OFF, i.e., its scattering matrix equals zero. Departing from most existing RIS literature [1, 2] where the structure scattering is simply ignored, we reach to a more accurate channel model and explicitly study its impact in full-duplex systems. Third, based on the proposed general model, we consider a simple BD-RIS aided full-duplex system, which consists of a single-antenna full-duplex base station, a BD-RIS, a single-antenna uplink user and a single-antenna downlink user. In this scenario, we derive the theoretical conditions for both reciprocal and non-reciprocal BD-RISs to simultaneously maximize the received powers of the signal of interest in the uplink and downlink. Fourth, we provide simulation results to verify the theoretical derivations. More importantly, we visualize the best choice for locating the base station and the users, such that applying the non-reciprocal BD-RIS has the most significant performance benefits in full-duplex systems. Our results demonstrate the uniqueness of non-reciprocal BD-RIS in full duplex systems. Since a non-reciprocal BD-RIS does not obey the principle of reciprocity, if a wave hits the non-reciprocal BD-RIS from one direction, the surface behaves differently than if it hits from the opposite direction. Consequently, this enables an uplink user and a downlink user at different locations to optimally communicate with the same full-duplex base station via a non-reciprocal BD-RIS. This would not be possible with a reciprocal surface unless the two users were aligned, which explains the observed significant performance gains offered by non-reciprocal BD-RIS. Organization: Section II introduces the multiport network analysis and classifies the RIS based on properties of the scattering matrix. Section III derives the RIS aided full-duplex system model. Section IV studies the theoretical conditions that non-reciprocal BD-RIS outperforms reciprocal BD-RIS in full-duplex systems. Section V numerically verifies the theoretical results and visualizes the benefit of non-reciprocal BD-RIS. Section VI concludes this work. Notations: Boldface lower- and upper-case letters indicate column vectors and matrices, respectively. (\cdot)^{\mathsf{T}}, (\cdot)^{*}, (\cdot)^{\mathsf{H}}, and (\cdot)^{-1} denote the transpose, conjugate, conjugate-transpose, and inverse operations, respectively. \mathbb{C} and \mathbb{R} denote the sets of complex and real numbers, respectively. \mathbb{E} denotes the statistical expectation. \Re\{\cdot\} denotes the real part of complex numbers. \mathsf{blkdiag}(\cdot) represents a block-diagonal matrix and \mathsf{diag}(\cdot) represents a diagonal matrix. \|\cdot\|_{2} and \|\cdot\|_{\mathsf{F}} denote the \ell_{2} norm and Frobenius norm, respectively. \jmath=\sqrt{-1} denotes the imaginary unit. \mathsf{Tr}(\cdot) denotes the trace of a matrix. \mathbf{I}_{M} denotes an M\times M identity matrix. \mathbf{0}_{M\times N} denotes an M\times N all-zero matrix. a\sim\mathcal{CN}(0,\sigma^{2}) characterizes the circular symmetric complex Gaussian distribution. [\mathbf{A}]_{i:i^{\prime},j:j^{\prime}} extracts the i-th to i^{\prime}-th rows and the j-th to j^{\prime}-th columns of \mathbf{A}. In microwave engineering, given an N-port network, its impedance parameter \mathbf{Z}\in\mathbb{C}^{N\times N} links its scattering parameter \mathbf{S}\in\mathbb{C}^{N\times N} by \mathbf{S}=(\mathbf{Z}+Z_{0}\mathbf{I}_{N})^{-1}(\mathbf{Z}-Z_{0}\mathbf{I}_{N% }), (1) where Z_{0} denotes the reference impedance with Z_{0}=50~{}\Omega."
