URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10284v1,Optimal Capacity Modiﬁcation for Strongly Stable Matchings,"We consider the Hospital/Residents (HR) problem in the presence of ties in preference lists. Among the three notions of stability, viz. weak, strong, and super stability, we focus on the notion of strong stability. Strong stability has many desirable properties both theoretically and practically; however, its existence is not guaranteed.In this paper, our objective is to optimally increase the quotas of hospitals to ensure that a strongly stable matching exists in the modified instance. First, we show that if ties are allowed in residents’ preference lists, it may not be possible to augment the hospital quotas to obtain an instance that admits a strongly stable matching. When residents’ preference lists are strict, we explore two natural optimization criteria: (i) minimizing the maximum capacity increase for any hospital (MinMax), and (ii) minimizing the total capacity increase across all hospitals (MinSum). We show that the MinMax problem is NP-hard in general. When hospital preference lists can have ties of length at most \ell+1, we give a polynomial-time algorithm that increases each hospital’s quota by at most \ell, ensuring the resulting instance admits a strongly stable matching.We show that the MinSum problem admits a polynomial-time algorithm. However, when each hospital incurs a cost for each capacity increase, the problem becomes NP-hard, even if the costs are 0 or 1. This also implies that the problem cannot be approximated to any multiplicative factor. We also consider a related problem under the MinSum objective. Given an HR instance and a forced pair (r^{*},h^{*}), the goal is to decide if it is possible to increase hospital quotas (if necessary) to obtain a strongly stable matching that matches the pair (r^{*},h^{*}). We show a polynomial-time algorithm for this problem.","The Hospital/Residents (HR) problem [19, 31] is a many-to-one generalization of the classical stable marriage problem [16]. As the name suggests, the HR problem models the assignment of junior doctors (residents) to hospitals where agents in both sets are allowed to rank acceptable agents from the other set in a preference order. The problem is extensively investigated since it has applications in a number of centralized matching schemes in many countries, including the National Resident Matching Program in the USA (NRMP), the Canadian Resident Matching Service (CaRMS), and the Scottish Foundation Allocation Scheme (SFAS), to name a few. In addition, the HR problem models several real-world applications like assigning children to schools [1] and students to undergraduate programs [5] where agents need to be matched to programs, and both sets express preferences over each other. We consider a generalization of the HR problem where ties are allowed in the preference lists. That is, agents can be indifferent between multiple agents from the other set. This problem is known as the Hospital/Residents problem with ties (HRT). Ties in preference lists play an important role in real-world matching applications. For instance, hospitals with a large number of applicants often find it difficult to generate strict preference lists. Many of these hospitals, within the framework of a centralized matching scheme, have expressed the desire to include ties in their preference lists [21]. In case of college admissions, it is natural for colleges to have all the students with equal scores in a single tie in their preference lists. The classical notion of stability defined for strict preferences has been generalized in the literature for the case of ties, in three different ways – weak stability, strong stability and super stability (see Definition 1.1 and the footnote therein). As indicated by the names, super stability is the strongest notion and weak stability is the weakest among the three. It is well-known that every instance of the HRT problem admits a weakly stable matching (and it can be obtained by breaking ties arbitrarily and computing a stable matching in the resulting instance); however, strong or super stable matchings are not guaranteed to exist [20]. The strongest notion of stability is super-stability. However, as highlighted in [22], insisting on super-stability in practical scenarios can be overly restrictive and is less likely to be attainable. Moreover, in applications like college admissions, it is natural to require students to express strict preferences over colleges, although colleges need to put students with equal scores in a tie111We refer to this as HR-HT in this paper. In such scenarios, super and strong stability coincide. On the other hand, weak stability is too weak, and as justified in [29], it is susceptible to compromise through persuasion or bribery (also see [22, 27] for further details). Moreover, from a social perspective, weak stability may not be an acceptable notion despite its guaranteed existence. For instance, according to the equal treatment policy used in Chile and Hungary, it is not acceptable that a student is rejected from a college preferred by her, even though other students with the same score are admitted (see [12] and the references therein). Thus, strong stability is not only appealing but also essential. Given that strong stability is desirable but not guaranteed to exist, a natural option for applications is to adjust the quotas (of, say, colleges and hospitals) so that a strongly stable matching exists after the adjustment. We address this problem in this paper. We use the hospital-residents terminology, as is customary in many-to-one stable matchings. Thus we seek to increase or augment the hospital quotas to obtain a modified instance which admits a strongly stable matching. We explore two natural optimization criteria: (i) minimize the total increase (sum) in quotas across all hospitals (MinSum), and (ii) minimize the maximum increase in quota for any hospital (MinMax). Our work falls in the broad theme of capacity planning / modification which has received significant attention [11, 18, 8, 6, 2, 7] motivated by practical applications where quotas are not rigid. To the best of our knowledge, our work is the first one to explore capacity augmentation for the notion of strong stability. 1.1 Preliminaries and notation The input to our problem is a bipartite graph G=(\mathcal{R}\cup\mathcal{H},E), where the vertex set \mathcal{R} represents the set of residents, \mathcal{H} represents the set of hospitals and the edge set E represents mutually acceptable resident-hospital pairs. We define n=|\mathcal{R}|+|\mathcal{H}| and m=|E|. Every hospital h\in\mathcal{H} has an associated quota q(h) denoting the maximum number of residents that can be assigned to h in any assignment. Each vertex v\in\mathcal{R}\cup\mathcal{H} ranks its neighbors as per its preference ordering, referred to as the preference list of v, denoted as Pref(v). We say that a vertex strictly prefers a neighbor with a smaller rank over another neighbor with a larger rank. If a vertex is allowed to be indifferent between some of its neighbors and is allowed to assign the same rank to such neighbors, it is referred to as a tie. The length of a tie is the number of neighbors having equal rank. If ties are not allowed (or equivalently, all ties have length 1), the preference lists are said to be strict. We use u_{1}\succ_{v}u_{2} to denote that v strictly prefers u_{1} over u_{2} and u_{1}\succeq_{v}u_{2} to denote that v either strictly prefers u_{1} over u_{2} or is indifferent between them. A matching M in G is a subset of E such that |M(r)|\leq 1 and |M(h)|\leq q(h) for each resident r\in\mathcal{R} and hospital h\in\mathcal{H} where M(v) denotes the set of matched partners of v in M. For a resident r, if |M(r)|=0, then r is unmatched in M. In this case, we denote the matched partner of r by M(r)=\bot. A hospital h\in\mathcal{H} is said to be fully subscribed in M with respect to its quota q(h), if |M(h)|=q(h), under-subscribed in M if |M(h)|<q(h). We abuse the term matching and say that h is over-subscribed in M if |M(h)|>q(h). If left unspecified, the quota under consideration for these terms is the original quota q(h). If h is under-subscribed, then we implicitly match the remaining q(h)-|M(h)| many positions of h to as many copies of \bot. A vertex prefers any of its neighbors over \bot. Definition 1.1 (Strong stability:) For a matching M, an edge (r,h)\in E\setminus M is a strong blocking pair w.r.t. M, if either (i) or (ii) holds: (i) h\succ_{r}M(r) and there exists r^{\prime}\in M(h) such that r\succeq_{h}r^{\prime} (ii) h\succeq_{r}M(r) and there exists r^{\prime}\in M(h) such that r\succ_{h}r^{\prime}. A matching M is strongly stable matching if there does not exist any strong blocking pair w.r.t. M. 222A pair (r,h) is a super blocking pair if both prefer each other strictly or equally to their matched partners. Also, (r,h) form a weak blocking pair if they prefer each other strictly more than their matched partners. Throughout the paper, we refer to a strong blocking pair as a blocking pair. We give a simple example to illustrate that a strongly stable matching is not guaranteed to exist. Consider an instance with one resident r and two hospitals h_{1},h_{2}, where r has h_{1} and h_{2} tied at rank-1, whereas h_{1},h_{2} have unit quota each and both of them rank r as a rank-1 vertex. No matching in this instance is strongly stable, since the matching M_{1}=\{(r,h_{1})\} is blocked by (r,h_{2}) and M_{2}=\{(r,h_{2})\} is blocked by (r,h_{1}). r : (h_{1},h_{2}) [1]\ h_{1} : r [1]\ h_{2} : r Moreover, the same example illustrates that increasing hospital quotas (alone) may not help in obtaining an instance which admits a strongly stable matching. This happens because there are ties in residents’ preference lists whereas quota augmentation is possible for hospitals only. What if resident preference lists are strict and ties appear only in hospitals’ preferences? We call such instances as HR-HT (Hospital/Residents problem with ties on hospitals’ side only). There exist simple instances of HR-HT which do not admit a strongly stable matching, however, for any such instance, we can construct an augmented instance G^{\prime} by setting the quota of each hospital h equal to its degree in G. It is easy to observe that the matching M^{\prime} that assigns each resident to its rank-1 hospital, is a strongly stable matching in G^{\prime}. Thus, unlike the general HRT case, an HR-HT instance can always be augmented so that the instance admits a strongly stable matching. Our objective in this paper is to optimally increase hospitals’ quotas to ensure that a strongly stable matching exists in the modified instance. We are ready to formally define our problems. 1.2 Our problems and contributions For all our problems, unless stated explicitly, we assume that the given HR-HT instance G=(\mathcal{R}\cup\mathcal{H},E) does not admit a strongly stable matching. Deciding whether an HRT instance admits a strongly stable matching can be done in polynomial time using the algorithm by Irving et al. [22] (see Appendix 0.A). Throughout this paper the augmented instance G^{\prime} is the same as G except that q^{\prime}(h)\geq q(h) for each h. Our first objective is to minimize the total increase in quotas across all hospitals. Our first problem under this objective is MinSum-SS. MinSum-SS: Given an HR-HT instance G=(\mathcal{R}\cup\mathcal{H},E), construct an augmented instance G^{\prime} such that G^{\prime} admits a strongly stable matching and the sum of the increase in quotas over all hospitals (that is, \sum_{h\in\mathcal{H}}(q^{\prime}(h)-q(h))) is minimized. Theorem 1.2 MinSum-SS problem is solvable in polynomial time. Given the polynomial-time solution for the MinSum-SS problem, we consider the optimal total quota augmentation (if possible) for matching a pair (r^{*},h^{*}) in G. We denote this problem as MinSum-SS-FP (forced pair) and define it formally below. MinSum-SS-FP: Given an HR-HT instance G=(\mathcal{R}\cup\mathcal{H},E), which possibly admits a strongly stable matching, and an edge (r^{*},h^{*})\in E, construct an augmented instance G^{\prime}, if possible, such that G^{\prime} admits a strongly stable matching that matches (r^{*},h^{*}) and the sum of the increase in quotas over all hospitals (that is, \sum_{h\in\mathcal{H}}(q^{\prime}(h)-q(h))) is minimized. Theorem 1.3 The MinSum-SS-FP problem is solvable in polynomial time. Next, we consider a generalization of the MinSum-SS problem, where increasing the quota of a hospital incurs a cost. This problem is denoted by MinSum-Cost. MinSum-Cost: Given an HR-HT instance G=(\mathcal{R}\cup\mathcal{H},E) with costs associated with hospitals, construct an augmented instance G^{\prime} such that G^{\prime} admits a strongly stable matching, and the total cost of the increase in quotas of all hospitals is minimized. In contrast to the polynomial-time solvability for MinSum-SS, we obtain a hardness result for the MinSum-Cost problem. Theorem 1.4 The MinSum-Cost problem is NP-hard and is inapproximable to within any multiplicative factor. We now turn our attention to the alternative objective: minimizing the maximum increase in quota for any hospital and define MinMax-SS problem. MinMax-SS: Given an HR-HT instance G=(\mathcal{R}\cup\mathcal{H},E), construct an augmented instance G^{\prime} such that G^{\prime} admits a strongly stable matching, and the maximum increase in the quota for any hospital is minimized, that is, \max_{h\in\mathcal{H}}\{q^{\prime}(h)-q(h)\} is minimized. Our result for MinMax-SS is shown in Theorem 1.5 Theorem 1.5 MinMax-SS is NP-hard even when resident preferences are single-peaked, and hospital preferences are derived from a master list. Moreover, the same minimization objective with the goal of constructing an instance that admits a resident-perfect strongly stable matching (one that matches all residents) is also NP-hard. 1.3 Related Work Capacity Modification: Chen and Csáji [11] studied a problem similar to ours for the case of strict preference lists. The goal was to augment the instance by increasing hospital quotas such that the resulting instance admits a perfect stable matching. They showed that with the MinMax objective, the problem admits a polynomial-time algorithm. In contrast, somewhat surprisingly, for strongly stable matching, we get an NP-hardness result ( Theorem 1.5) for MinMax. They also consider the MinSum objective, and show NP-hardness for getting an augmented instance that admits a stable and perfect matching under the MinSum objective. Note that this also implies NP-hardness for constructing an augmented instance in the HR-HT setting for achieving a strongly stable and perfect matching. However, without the perfectness requirement, our result in Theorem 1.2 gives a polynomial-time algorithm. Capacity modification to achieve specific objectives has attracted significant interest in recent years. Bobbio et al. [8] explored the complexity of determining the optimal variation (augmentation or reduction) of hospital quotas to achieve the best outcomes for residents, subject to stability and capacity variation constraints, and showed NP-hardness results. In a follow-up work, Bobbio et al.[6] developed a mixed integer linear program to address this issue, and in [7], they provided a comprehensive set of tools for obtaining near-optimal solutions. Gokhale et al. [18] considered the problem of modifying hospitals’ quotas to achieve two objectives – (i) to obtain a stable matching so as to match a given pair, and, (ii) to stabilize a given matching, either by only augmenting or only reducing hospital quotas. Afacan et al.[2] examined capacity design in the HR setting, to achieve a stable matching that is not Pareto-dominated by any other stable matching. Kavitha and Nasre [24] and Kavitha et al. [25] addressed the capacity augmentation problem for popular matchings in the one-sided preference list setting (where every hospital is indifferent between its neighbours). It is known that a popular matching is not guaranteed to exist in this setting. Therefore, their objective was to optimally increase hospital quotas to create an instance that admits a popular matching. Although we focus on a different setting (two-sided preference lists) and a different optimality notion – strong stability, it is interesting to note that our results closely resemble those obtained by Kavitha and Nasre [24] and Kavitha et al. [25]. Strong Stability: The notion of strong stability was first studied in the one-to-one setting for balanced, complete bipartite graphs (i.e. q(h)=1 for all h\in\mathcal{H}) by Irving [20], where they gave an O(n^{4}) algorithm to compute a strongly stable matching if it exists. Since then, the strongly stable matching problem has received a significant attention in the literature. Manlove [28] extended Irving’s results [20] to the general one-to-one setting (i.e. incomplete bipartite graphs) and also showed that all strongly stable matchings have the same size and match the same set of vertices. Irving et al. [22] further extended these results to the HRT setting and gave O(m^{2}) algorithm for the strongly stable matching problem, which was later improved to O(mn) by Kavitha et al. [23]. Manlove [29] studied the structure of the set of strongly stable matchings and showed that, similar to the classical stable matchings, the set of strongly stable matchings forms a distributive lattice. Kunysz et al. [27] showed that there exists a partial order with O(m) elements representing all strongly stable matchings and also provided an O(mn) algorithm to construct such a representation. In the presence of edge weights, Kunysz [26] showed that when edge weights are small, the maximum weight strongly stable matching problem can be solved in O(mn) time, and in O(mn\ \log(Wn)) if the maximum weight of an edge is W. Strong stability w.r.t. restricted edges viz. forced, forbidden and free edges has been studied by Cseh and Heeger [12] and by Boehmer and Heeger [9]. Organization of the paper In Sections 2, 3 and 4, the objective of our problems is to minimize the total increase in quotas. In Section 5, we study the MinMax-SS problem where the objective is to minimize maximum increase in quotas."
https://arxiv.org/html/2411.09854v1,Fair Secretaries with Unfair Predictions,"Algorithms with predictions is a recent framework for decision-making under uncertainty that leverages the power of machine-learned predictions without making any assumption about their quality. The goal in this framework is for algorithms to achieve an improved performance when the predictions are accurate while maintaining acceptable guarantees when the predictions are erroneous. A serious concern with algorithms that use predictions is that these predictions can be biased and, as a result, cause the algorithm to make decisions that are deemed unfair. We show that this concern manifests itself in the classical secretary problem in the learning-augmented setting—the state-of-the-art algorithm can have zero probability of accepting the best candidate, which we deem unfair, despite promising to accept a candidate whose expected value is at least \max\{\Omega(1),1-O(\operatorname{\varepsilon})\} times the optimal value, where \operatorname{\varepsilon} is the prediction error. We show how to preserve this promise while also guaranteeing to accept the best candidate with probability \Omega(1). Our algorithm and analysis are based on a new “pegging” idea that diverges from existing works and simplifies/unifies some of their results. Finally, we extend to the k-secretary problem and complement our theoretical analysis with experiments.","As machine learning algorithms are increasingly used in socially impactful decision-making applications, the fairness of those algorithms has become a primary concern. Many algorithms deployed in recent years have been shown to be explicitly unfair or reflect bias that is present in training data. Applications where automated decision-making algorithms have been used and fairness is of central importance include loan/credit-risk evaluation (Mukerjee et al., 2002; Khandani et al., 2010; Malhotra and Malhotra, 2003), hiring (Bogen and Rieke, 2018; Cohen et al., 2019), recidivism evaluation Mustard (2003); Angwin et al. (2016); Dressel and Farid (2018); Chouldechova (2017); COMPAS () (software), childhood welfare systems Chouldechova et al. (2018), job recommendations Lambrecht and Tucker (2019), and others Hern (2016); Grossman (2010); Howard and Borenstein (2018). A lot of work in recent years has been devoted to formally defining different notions of fairness Luong et al. (2011); Kamishima et al. (2012); Feldman et al. (2015); Dwork et al. (2012); Corbett-Davies et al. (2017); Kleinberg et al. (2017); Kleinberg and Raghavan (2017) and designing algorithms that satisfy these different definitions Kamishima et al. (2011); Joseph et al. (2016); Celis et al. (2018); Chierichetti et al. (2019); Yang and Stoyanovich (2017). While most fairness work concentrates on classification problems where the instance is known offline, we explore the problem of making fair decisions when the input is revealed in an online manner. Although fairness in online algorithms is an interesting line of research per se, fairness considerations have become increasingly important due to the recent interest in incorporating (possibly biased) machine learning predictions into the design of classical online algorithms. This framework, usually referred to as learning-augmented algorithms or algorithms with predictions, was first formalized in Lykouris and Vassilvitskii (2018). In contrast to classical online algorithms problems where it is assumed that no information is known about the future, learning-augmented online algorithms are given as input, possibly erroneous, predictions about the future. The main challenge is to simultaneously achieve an improved performance when the predictions are accurate and a robust performance when the predictions are arbitrarily inaccurate. A long list of online problems have been considered in this setting and we point to Lindermayr and Megow (2024) for an up-to-date list of papers. We enrich this active area of research by investigating how potentially biased predictions affect the fairness of decisions made by learning-augmented algorithms, and ask the following question: {mdframed}[hidealllines=true, backgroundcolor=gray!15] Can we design fair algorithms that take advantage of unfair predictions? In this paper, we study this question on a parsimonious formulation of the secretary problem with predictions, motivated by fairness in hiring candidates. The problem. In the classical secretary problem, there are n candidates who each have a value and arrive in a random order. Upon arrival of a candidate, the algorithm observes the value of that candidate and must irrevocably decide whether to accept or reject that candidate. It can only accept one candidate and the goal is to maximize the probability of accepting the candidate with maximum value. In the classical formulation, only the ordinal ranks of candidates matter, and the algorithm of Dynkin (1963) accepts the best candidate with a constant probability, that equals the best-possible 1/e. In the learning-augmented formulation of the problem proposed by Fujii and Yoshida (2023), the algorithm is initially given a predicted value about each candidate and the authors focus on comparing the expected cardinal value accepted by the algorithm to the maximum cardinal value. The authors derive an algorithm that obtains expected value at least \max\{\Omega(1),1-O(\operatorname{\varepsilon})\} times the maximum value, where \operatorname{\varepsilon}\geq 0 is the prediction error. The strength of this guarantee is that it approaches 1 as the prediction error decreases and it is a positive constant even when the error is arbitrarily large. However, because the algorithm is now using predictions that could be biased, the best candidate may no longer have any probability of being accepted. We view this as a form of unfairness, and aim to derive algorithms that are fair to the best candidate by guaranteeing them a constant probability of being accepted (we contrast with other notions of fairness in stopping problems in Section 1.1). Of course, a simple way to be fair by this metric is to ignore the predictions altogether and run the classical algorithm of Dynkin. However, this approach would ignore potentially valuable information and lose the improved guarantee of Fujii and Yoshida (2023) that approaches 1 when the prediction error is low. Outline of results. We first formally show that the algorithm of Fujii and Yoshida (2023) may in fact accept the best candidate with 0 probability. Our main result is then a new algorithm for secretary with predictions that: obtains expected value at least \max\{\Omega(1),1-O(\operatorname{\varepsilon})\} times the maximum value, like Fujii and Yoshida (2023); and ensures that, under any predictions, the probability that the best candidate is accepted is at least 1/16. This result takes advantage of potentially biased predictions to achieve a guarantee on expected value that approaches 1 when the prediction error is small, while also providing a fairness guarantee for the true best candidate irrespective of the predictions. We note that Antoniadis et al. (2020b) also derive an algorithm for secretary with predictions, where the prediction is of the maximum value. This algorithm accepts the best candidate with constant probability but it does not provide a guarantee on the expected value accepted that approaches 1 as the prediction error approaches 0. Similarly, Dynkin’s algorithm for the classical secretary problem accepts the best candidate with constant probability but does not make use of predictions at all. Finally, we note that the definitions of the prediction error \operatorname{\varepsilon} differ in (Fujii and Yoshida, 2023) and (Antoniadis et al., 2020b); the former error definition uses the maximum ratio over all candidates between their predicted and true value while the latter uses the maximum absolute difference. Our techniques present an arguably simpler analysis and extend to a general family of prediction error measures that includes both of these error definitions. We then extend our approach to the multiple choice or k-secretary problem where the goal is to accept at most k candidates and maximize the total of their values, which is the most technical part of the paper. We design an algorithm that obtains expected total value at least \max\{\Omega(1),1-O(\operatorname{\varepsilon})\} times the optimum (which is the sum of the k highest values), while simultaneously guaranteeing the k highest-valued candidates a constant probability of being accepted. We also have a refined guarantee that provides a higher acceptance probability for the (1-\delta)k highest-valued candidates, for any \delta\in(0,1). Finally, we simulate our algorithms in the exact experimental setup of Fujii and Yoshida (2023). We find that they perform well both in terms of expected value accepted and fairness, whereas benchmark algorithms compromise on one of these desiderata. 1.1 Related work The secretary problem. After Gardner (1960) introduced the secretary problem, Dynkin (1963) developed a simple and optimal stopping rule algorithm that, with probability at least 1/e, accepts the candidate with maximum value. Due to its general and simple formulation, the problem has received a lot of attention (see, e.g., Lindley (1961); Gilbert and Mosteller (1966) and references therein) and it was later extended to more general versions such as k-secretary (Kleinberg, 2005), matroid-secretary (Babaioff et al., 2007b) and knapsack-secretary (Babaioff et al., 2007a). Secretaries with predictions. The two works which are closest to our paper are those of Antoniadis et al. (2020b) and Fujii and Yoshida (2023). Both works design algorithms that use predictions regarding the values of the candidates to improve the performance guarantee of Dynkin’s algorithm when the predictions are accurate while also maintaining robustness guarantees when the predictions are arbitrarily wrong. Antoniadis et al. (2020b) uses as prediction only the maximum value and defines the prediction error as the additive difference between the predicted and true maximum value while Fujii and Yoshida (2023) receives a prediction for each candidate and defines the error as the maximum multiplicative difference between true and predicted value among all candidates. Very recently, Choo and Ling (2024) showed that any secretary algorithm that is 1-consistent cannot achieve robustness better than 1/3+o(1), even with predictions for each candidate. This result implies that, if we wish to maintain the 1-O(\operatorname{\varepsilon}) competitive ratio guarantee from (Fujii and Yoshida, 2023), then the probability of accepting the best candidate cannot be better than 1/3+o(1). Secretaries with distributional advice. Another active line of work is to explore how distributional advice can be used to surpass the 1/e barrier of the classical secretary problem. Examples of this line of work include the prophet secretary problems where each candidate draws its valuation from a known distribution Esfandiari et al. (2017); Correa et al. (2021b, c); Azar et al. (2018) and the sample secretary problem where the algorithm designer has only sample access to this distribution Kaplan et al. (2020); Correa et al. (2021a). We note that in the former models, predictions are either samples from distributions or distributions themselves which are assumed to be perfectly correct, while in the learning-augmented setting, we receive point predictions that could be completely incorrect. Dütting et al. (2021) investigate a general model for advice where both values and advice are revealed upon a candidate’s arrival and are drawn from a joint distribution \mathcal{F}. For example, their advice can be a noisy binary prediction about whether the current candidate is the best overall. Their main result uses linear programming to design optimal algorithms for a broad family of advice that satisfies two conditions. However, these two conditions are not satisfied by the predictions we consider. Additionally, we do not assume any prior knowledge of the prediction quality, whereas their noisy binary prediction setting assumes that the error probability of the binary advice is known. Fairness in stopping algorithms. We say that a learning-augmented algorithm for the secretary problem is F-fair if it accepts the candidate with the maximum true value with probability at least F. In that definition, we do not quantify unfairness as a prediction property but as an algorithmic one, since the algorithm has to accept the best candidate with probability at least F no matter how biased predictions are our fairness notion is a challenging one. That notion can be characterized as an individual fairness notion similar to the identity-independent fairness (IIF) and time-independent fairness (TIF) introduced in Arsenis and Kleinberg (2022). In the context of the secretary problem, IIF and TIF try to mitigate discrimination due to a person’s identity and arrival time respectively. While these are very appealing fairness notions, the fair algorithms designed in Arsenis and Kleinberg (2022) fall in the classical online algorithms setting as they do not make any assumptions about the future. Consequently, their performance is upper bound by the performance of the best algorithm in the classical worst-case analysis setting. It is also interesting to note the similarities with the poset secretary problem in Salem and Gupta (2023). In the latter work the set of candidates is split into several groups and candidates belonging to different groups cannot be compared due to different biases in the evaluation. In some sense, we try to do the same; different groups of candidates may have predictions that are affected by different biases making the comparison difficult before the true value of each candidate is revealed. Again, in Salem and Gupta (2023) no information about the values of future candidates is available and the performance of their algorithms is upper bounded by the best possible performance in the worst-case analysis setting."
https://arxiv.org/html/2411.09472v1,An Algorithm for the Longest Common Subsequence and Substring Problem for Multiple Strings,"Let X_{1},X_{2},...,X_{s} and Y_{1},Y_{2},...,Y_{t} be strings over an alphabet \Sigma, where s and t are positive integers. The longest common subsequence and substring problem for multiple strings X_{1},X_{2},...,X_{s} and Y_{1},Y_{2},...,Y_{t} is to find the longest string which is a subsequence of X_{1},X_{2},...,X_{s} and a substring of Y_{1},Y_{2},...,Y_{t}. In this paper, we propose an algorithm to solve the problem.","References [1] A. Apostolico, String editing and longest common subsequences, in: G. Rozenberg and A. Salomaa (Eds.), Linear Modeling: Background and Application, in: Handbook of Formal Languages, Vol. 2, Springer-Verlag, Berlin, 1997. [2] A. Apostolico, Chapter 13: General pattern matching, in: M. J. Atallah (Ed.), Handbook of Algorithms and Theory of Computation, CRC, Boca Raton, FL, 1998. [3] L. Bergroth, H. Hakonen, and T. Raita, A survey of longest common subsequence algorithms, in: SPIRE, A Coruña, Spain, 2000. [4] C. Blum, M. Djukanovic, A. Santini, H. Jiang, C. Li, F. Manyà, and G. R. Raidl, Solving longest common subsequence problems via a transformation to the maximum clique problem, Computers and Operations Research 125 (2021) 105089. [5] T. Cormen, C. Leiserson, R. Rivest, and C. Stein, Section 15.4: Longest common subsequence, Introduction to Algorithms (second edition), MIT Press, Cambridge, MA, 2001. [6] M. Crochemore, C. S. Iliopoulos, A. Langiu, and F. Mignosi, The longest common substring problem. Mathematical Structures in Computer Science, pp 1-19, Cambridge University Press 2015, doi:10.1017/S0960129515000110. [7] D. Gusfield, II: Suffix Trees and Their Uses, Algorithms on Strings, Trees, and Sequences: Computer Science and Computational Biology, Cambridge University Press, 1997. [8] D. Hirschberg, A linear space algorithm for computing maximal common subsequences, Comm. ACM 18 (June 1975) 341-343. [9] D. Hirschberg, Serial computations of Levenshtein distances, in: A. Apostolico and Z. Galil (Eds.), Pattern Matching Algorithms, Oxford University Press, Oxford, 1997. [10] J. Hunt and T. Szymanski, A fast algorithm for computing longest common subsequences, Communications of the ACM 20 (1977) 350-353. [11] R. Li, J. Deka, and K. Deka, An algorithm for the longest common subsequence and substring problem, Journal of Mathematics and Informatics, 25 (2023) 77-81. [12] S. R. Mousavi and F. Tabataba, An improved algorithm for the longest common subsequence problem, Computers and Operations Research, 39 (2012) 512-520. [13] C. Rick, New algorithms for the longest common subsequence problem, Research Report No. 85123-CS, University of Bonn, 1994. [14] P. Weiner, Linear pattern matching algorithms. In: 14th Annual Symposium on Switching and Automata Theory, Iowa City, Iowa, USA, October 15–17, 1973, pp. 1–11 (1973)."
https://arxiv.org/html/2411.09205v2,"FlexFlood: Efficiently Updatable 
Learned Multi-dimensional Index","A learned multi-dimensional index is a data structure that efficiently answers multi-dimensional orthogonal queries by understanding the data distribution using machine learning models. One of the existing problems is that the search performance significantly decreases when the distribution of data stored in the data structure becomes skewed due to update operations. To overcome this problem, we propose FlexFlood, a flexible variant of Flood. FlexFlood partially reconstructs the internal structure when the data distribution becomes skewed. Moreover, FlexFlood is the first learned multi-dimensional index that guarantees the time complexity of the update operation. Through experiments using both artificial and real-world data, we demonstrate that the search performance when the data distribution becomes skewed is up to 10 times faster than existing methods. We also found that partial reconstruction takes only about twice as much time as naive data updating.","Filtering, scanning, and updating of data are fundamental operations for databases, and various data structures have been studied to perform these operations efficiently. In the real world, we often need to handle multi-dimensional data, and Kd-tree and its variants [5, 20, 31] are typical data structures for handling them. These data structures are widely used in real-world applications [3, 23, 22]. Recently, there has been active research to improve data structures by learning the distribution of data and queries with machine learning models. Such data structures are called learned index [24]. One of the significant challenges in learned multi-dimensional indexes [32, 12, 25, 19, 8] is that many do not support data update operations. Even if they do, none describe the time complexity for updating. Therefore, we proposed a flexible variant of Flood (FlexFlood) that supports efficient data updating by adaptively modifying the internal structure of the existing learned multi-dimensional index, Flood [32]. We proved that the amortized time complexity of updating is O(D\log N) under two assumptions that the data increases at an approximately constant pace and that the training results of the ML model satisfy certain conditions. Here, D is the dimensionality of the data, and N is the total number of data. Furthermore, experiments using multiple artificial and real-world datasets confirm that the “certain conditions” can be sufficient. The original Flood’s search speed slows down as we update data, but FlexFlood remains fast. As a result, FlexFlood is up to 10 times faster than Flood after many updates. The source code for FlexFlood is available at https://github.com/mti-lab/FlexFlood."
https://arxiv.org/html/2411.09059v1,Sublinear Metric Steiner Tree via Improved Bounds for Set Cover,"We study the metric Steiner tree problem in the sublinear query model. In this problem, for a set of n points V in a metric space given to us by means of query access to an n\times n matrix w, and a set of terminals T\subseteq V, the goal is to find the minimum-weight subset of the edges that connects all the terminal vertices.Recently, Chen, Khanna and Tan [SODA’23] gave an algorithm that uses \widetilde{O}(n^{13/7}) queries and outputs a (2-\eta)-estimate of the metric Steiner tree weight, where \eta>0 is a universal constant. A key component in their algorithm is a sublinear algorithm for a particular set cover problem where, given a set system \mathcal{(}\mathcal{U},\mathcal{F}), the goal is to provide a multiplicative-additive estimate for |\mathcal{U}|-\textsf{SC}(\mathcal{U},\mathcal{F}). Here \mathcal{U} is the set of elements, \mathcal{F} is the collection of sets, and \textsf{SC}(\mathcal{U},\mathcal{F}) denotes the optimal set cover size of (\mathcal{U},\mathcal{F}). In particular, their algorithm returns a (1/4,\varepsilon\cdot|\mathcal{U}|)-multiplicative-additive estimate for this set cover problem using \widetilde{O}(|\mathcal{F}|^{7/4}) membership oracle queries (querying whether a set S\in\mathcal{S} contains an element e\in\mathcal{U}), where \varepsilon is a fixed constant.In this work, we improve the query complexity of (2-\eta)-estimating the metric Steiner tree weight to \widetilde{O}(n^{5/3}) by showing a (1/2,\varepsilon\cdot|\mathcal{U}|)-estimate for the above set cover problem using \widetilde{O}(|\mathcal{F}|^{5/3}) membership queries. To design our set cover algorithm, we estimate the size of a random greedy maximal matching for an auxiliary multigraph that the algorithm constructs implicitly, without access to its adjacency list or matrix. Previous analyses of random greedy maximal matching have focused on simple graphs, assuming access to their adjacency list or matrix. To address this, we extend the analysis of Behnezhad [FOCS’21] of random greedy maximal matching on simple graphs to multigraphs, and prove additional properties that may be of independent interest.","In the Steiner tree problem, we are given an undirected graph G=(V,E), where each edge e has an associated cost w(e), and a specified set of terminal vertices T\subseteq V. Then, the objective is to find a minimum-cost subgraph H of G that connects all terminals in T. The Steiner tree problem is one of the most fundamental problems in combinatorial optimization and has been extensively studied by the TCS community since it was included among Karp’s 21 NP-Complete problems [34]. The state-of-the-art approximation factor for the Steiner tree problem is \ln{4}+\varepsilon<1.39 [14], and it is known that approximating it to a factor better than 96/95 is NP-hard [17]. This Steiner tree problem has been studied in various domains, including approximation algorithms [41, 14], online algorithms [29, 3, 37, 25], stochastic algorithms [26, 27, 22], and massive data analysis models [15, 18, 16]. Definition 1.1 (Sublinear Metric Steiner Tree). In the metric Steiner tree problem, we are given a set of points V, a set of terminal points T\subseteq V, and query access to an oracle \mathcal{O} to the |V|\times|V| distance matrix of a metric space (V,w), where \mathcal{O}(u,v) returns the weight w(u,v) of the edge (u,v). Let \textsf{ST}(V,T,w) denote the weight of a minimum-weight Steiner tree on instance (V,T,w). Then, the goal is to design an algorithm that estimates \textsf{ST}(V,T,w) using the fewest possible queries to the distance matrix via the oracle \mathcal{O}. Czumaj and Sohler [18] presented the first sublinear query algorithm for the metric Steiner tree problem, showing a (2+\varepsilon)-approximation using \tilde{O}(k/\varepsilon^{O(1)}) queries through their improved algorithm for the minimum spanning tree (MST) problem. Specifically, this follows their sublinear (1+\varepsilon)-approximation for MST together with the well-known result by Gilbert and Pollak [23] showing that an \alpha-approximation for MST over the metric induced on the terminals T is a (2\alpha)-approximation for the metric Steiner tree instance with T as the terminal set. Recently, Chen, Khanna, and Tan [16] studied the design of sublinear algorithms with strictly better-than-2 approximation for the metric Steiner tree problem. On the lower bound side, they showed that for any \varepsilon>0, estimating the Steiner tree cost to within a (5/3-\varepsilon)-factor requires \Omega(n^{2}) queries, even when the number of terminals |T| is constant. Moreover, they showed that for any \varepsilon>0, estimating the Steiner tree cost to within a (2-\varepsilon)-factor requires \Omega(n+|T|^{6/5}) queries. Additionally, they proved that for any 0<\varepsilon<1/3, any algorithm that outputs a (2-\varepsilon)-approximate Steiner tree (not just its cost) requires \Omega(n|T|) queries. On the upper bound side, they showed that it is possible to achieve a better-than-2 estimate of the Steiner tree cost in sublinear time: there exists an algorithm that, with high probability, computes a (2-\eta)-approximation of the Steiner tree cost using \widetilde{O}(n^{13/7}) queries, where \eta>0 is a universal constant. At the core of their sublinear algorithm for metric Steiner tree with improved approximation guarantee, they relate the problem of achieving a better-than-2 estimation for the Steiner tree to a variant of set cover problem with a different objective. Definition 1.2 (Threshold Set Cover). Given a universe of elements \mathcal{U} and a collection \mathcal{F} of subsets of \mathcal{U}, in the Threshold Set Cover problem the goal is to estimate \textsf{ThSC}(\mathcal{U},\mathcal{F})\coloneqq|\mathcal{U}|-\textsf{SC}(% \mathcal{U},\mathcal{F}), where \textsf{SC}(\mathcal{U},\mathcal{F}) denotes the size of an optimal set cover solution for (\mathcal{U},\mathcal{F}), i.e., the minimal number of sets in \mathcal{F} whose union equals \mathcal{U}. Following the notation of [16] and for simplicity, in our technical sections, we also refer to this problem as set cover. Specifically, given access to the adjacency matrix of the graph representation of (\mathcal{U},\mathcal{F}), where there is an edge between e\in\mathcal{U} and S\in\mathcal{F} if and only if e\in S, Chen, Khanna, and Tan [16] designed an algorithm that, for any constant 0<\varepsilon<1, with high probability, outputs a multiplicative-additive (1/4,\varepsilon|\mathcal{U}|)-approximation for estimation of \textsf{ThSC}(\mathcal{U},\mathcal{F}) using \widetilde{O}_{\varepsilon}(|\mathcal{F}|^{3/2}+|\mathcal{F}|^{3/4}\cdot|% \mathcal{U}|) queries to the adjacency matrix (or, membership queries). An estimate \mathrm{SOL} for Threshold Set Cover on (\mathcal{U},\mathcal{F}) is a multiplicative-additive (\gamma_{1},\gamma_{2})-approximation, if \gamma_{1}\cdot\textsf{ThSC}(\mathcal{U},\mathcal{F})-\gamma_{2}\leq\mathrm{% SOL}\leq\textsf{ThSC}(\mathcal{U},\mathcal{F}). More broadly, there has been a large body of work on solving set cover problems in the massive data models of computation over the past decade [42, 19, 28, 20, 2, 30, 1, 5, 31, 24]. In particular the work of [31, 24] consider the set cover problem in the sublinear query model. However their algorithms assumes that it has an access to the adjacency list model as opposed to the adjacency matrix model, and thus cannot be directly employed here. 1.1 Our Results Our key contribution is an algorithm for Threshold Set Cover, offering improved approximation guarantees and query complexity, as detailed below: Theorem 1 (Our Algorithm for Threshold Set Cover). There exists an algorithm that, given a set system (\mathcal{U},\mathcal{F}) with oracle access to its adjacency matrix (also known as membership queries), outputs a multiplicative-additive (1/2,\varepsilon\cdot|\mathcal{U}|)-approximation to Threshold Set Cover, in \widetilde{O}(|\mathcal{F}|^{5/3}) time, with high probability. Note that both the query complexity and the running time of the algorithm are bounded by \widetilde{O}(|\mathcal{F}|^{5/3}), improving upon the algorithm by Chen, Khanna, and Tan [16] for large values of |\mathcal{U}|, which uses \widetilde{O}_{\varepsilon}(|\mathcal{F}|^{3/2}+|\mathcal{F}|^{3/4}\cdot|% \mathcal{U}|) membership queries and provides a multiplicative-additive (1/4,\varepsilon|\mathcal{U}|)-approximation for the problem. Notably, when |\mathcal{U}|=\omega(|\mathcal{F}|^{2/3}), the algorithm becomes sublinear in |\mathcal{U}|\cdot|\mathcal{F}|, making it especially relevant for applications in the metric Steiner tree problem. More specifically, our new algorithm for Threshold Set Cover results in the following improved sublinear query algorithm for the metric Steiner tree problem, which we show in Section 6. Theorem 2 (Sublinear Algorithm for Metric Steiner Tree). There exists an algorithm that, given an instance of metric Steiner tree denoted by (V,T,w) with oracle access \mathcal{O} to the distance matrix of (V,w), outputs a (2-\eta)-estimate of \textsf{ST}(V,T,w) using \widetilde{O}(n^{5/3}) queries to \mathcal{O}, where \eta>0 is a universal constant, with high probability. Notably, the query complexity of our algorithm improves upon the \widetilde{O}(n^{13/7}) query complexity of the algorithm of Chen, Khanna, and Tan [16]. For a detailed overview of our technical contribution, see Section 2."
https://arxiv.org/html/2411.09642v1,"On the Limits of Language Generation:
Trade-Offs Between Hallucination and Mode Collapse","Specifying all desirable properties of a language model is challenging, but certain requirements seem essential for any good model. Given samples drawn from an unknown language, the trained model should (1) produce valid strings that have not been seen in the training data, and (2) be expressive enough to capture the full richness of the language. Otherwise, if the language model outputs invalid strings, it “hallucinates,” and if it fails to capture the full range of the language, it suffers from “mode collapse.” In this paper, we ask whether it is possible for a language model to meet both of these requirements.We investigate this question within a statistical setting of language generation, building on the seminal works of \citet[Inf. Control]gold1967language, \citet[STOC]angluin1979finding, and \citet[Tech. Report]angluin1988identifying. In this setting, the language model is presented with randomly sampled strings from a distribution supported on an unknown language K, which is only known to belong to a possibly infinite collection of candidate languages. The goal of the model is to generate unseen strings from this target language. We say that the language model generates from K with consistency and breadth if, as the size of the training set increases, the set of strings it can output converges to the set of all unseen strings in K.[NeurIPS]kleinberg2024language posed an open question of whether consistency and breadth in language generation are both possible. We answer this question negatively: for a large class of language models – including next-token-prediction-based models – this is impossible for most collections of candidate languages. This contrasts with the recent positive result of \citet[NeurIPS]kleinberg2024language, which demonstrated that consistent generation, without requiring breadth, is possible for any countable collection of candidate languages. Our finding highlights that generation with breadth is fundamentally different from generation without breadth.As a byproduct of our result, we also examine how many samples are required for generation with or without breadth, establishing near-tight bounds on the “learning curves” for generation in the statistical framework of \citet*[STOC]bousquet2021theory.Finally, our results also give some hope for consistent generation with breadth: it is achievable for any countable collection of languages when negative examples – in the form of strings outside of K – are available in addition to strings inside of K. This suggests that feedback in post-training, which encodes negative examples, can be crucial in reducing hallucinations while also limiting mode collapse.","Language acquisition is a fundamental mystery across multiple scientific fields, ranging from Biology and Neuroscience to Sociology \citepbresnan2007syntactic,saffran1996statistical,clark2014distributional,mahowald2024dissociating. Theoretical Computer Scientists have been fascinated by language since the early days of the field: in the 1950s, \citetturing1950computing introduced his famous test using language as an interface to cognition, \citetshannon1951prediction studied statistics of printed English aiming at understanding its entropy and the extent to which it could be compressed, and \citetmandelbrot1953informational designed a statistical model to capture connections between language and the brain. Over the years, language modeling has advanced through simple models, such as the word n-gram model introduced by \citetshannon1951redundancy and widely used in natural language processing \citepbrown1992class. In the early 2000s, neural networks achieved a significant breakthrough in the field \citepbengio2000neural, leading to fascinating deep learning systems \citepmikolov2010recurrent,goldberg2016primer,lecun2015deep built using traditional architectures like Recurrent Neural Networks \citeprumelhart1986learning and Long Short-Term Memory \citephochreiter1997long. In 2017, the field of language modeling was revolutionized by the introduction of the Transformer architecture \citepsutskever2014sequence,bahdanau2014neural,vaswani2017attention, which led to the development of Large Language Models (LLMs). The achievements of LLMs have been groundbreaking; recent models can perform well on tasks far beyond natural language processing \citepbubeck2023sparks,touvron2023llama. Despite their impressive performance, their extensive use has revealed that LLMs exhibit various bizarre behaviors even in seemingly mundane tasks \citepborji2023categorical. Perhaps the most well-known issue with current LLMs is hallucinations: the models generate false but plausible-sounding text with surprising frequency \citepzhang2023siren,ji2023survey.111We stress that LLMs outputting wrong facts based on errors in training data (e.g., “The Earth is flat”) or miscalculations (e.g., “1+1 = 3”) do not constitute hallucinations. A hallucination is a plausible but false text with unclear origin (e.g., “Barack Obama was the president of the US and was born on January 1, 1958”). Such hallucinations, highlighted by popular media \citepweise2023ai, could significantly impact safety, reliability, and user trust as the adoption of these systems extends to new tasks \citephendrycks2021unsolved,amodei2016concrete. The importance of this problem, among other concerns, led both the US \citepbiden2023executive and the EU \citepsatariano2023eu to issue calls for safeguards against misleading outputs generated by LLMs. In this direction, designing LLMs that generate responses consistent with the ground truth is an effort that has gained a lot of attention from Machine Learning (ML) practitioners \citepandriopoulos2023augmenting,gunasekar2023textbooks,wei2022chain,huang2023survey,feng2024don,kang2024unfamiliar,ji2023survey, policymakers \citepbiden2023executive,satariano2023eu,satariano2023nations, and theorists \citephanneke2018actively,kalai2024calibrated,kleinberg2024language. If the sole goal is to avoid hallucinations, then, of course, one could simply limit the range of outputs generated by the language model. As an extreme example, consider a language model that only outputs “I am a language model” and, therefore, never hallucinates. However, modern LLMs do not just aim to generate a few valid outputs; their goal is to obtain the ability to express a wide range of plausible outputs, thus capturing the richness of human language. The key challenge lies in avoiding hallucinations while achieving breadth. The problem of achieving consistent generation with breadth is not new in the ML community, dating back at least to the era of Generative Adversarial Networks (GANs) \citepgoodfellow2020generative. In this line of work, mode collapse \citepgoodfellow2020generative is the analog of lack of breadth; it refers to the phenomenon where the GAN assigns non-zero mass only to a few modes of the true data distribution, thus producing a limited variety of samples and becoming repetitive \citeparjovsky2017towards,bau2019seeing,shmelkov2018good. The starting point of our work is exactly this puzzling tension between consistent generation and breadth in language generation. We start with a mathematical specification inspired by classical work on learning theory, tracing back to the seminal work of \citetangluin1988identifying, and the recent formulation of \citetkleinberg2024language: the domain \euscr{X} is a countable collection of strings, and there is an unknown target language K which is a subset of this domain. We know that the true language lies within a collection of possibly infinite but countably many languages \euscr{L}=\{L_{1},L_{2},\dots\}. There exists an unknown distribution \euscr{P} over strings in K\in\euscr{L} that satisfies \operatorname{supp}(\euscr{P})=K; any distribution with this property is said to be valid for K. The algorithm observes i.i.d. samples from \euscr{P} and aims to learn how to generate unseen strings from the target language K – this, at a high level, is the language generation problem. Intuitively, the target language K is capturing “facts” of the world; everything that belongs to K is correct, whereas everything outside of K is unambiguously incorrect and can be thought of as a “hallucination.” Observe that K has to be infinite for the problem to be well-defined as, otherwise, at some point, the algorithm will see all possible strings of K and, from then on, would have no unseen strings to generate from. Let us explore language generation further, with the immediate aim of quantifying an algorithm’s progress toward becoming a useful generator. Consider a generating algorithm \mathpzc{G}_{n}222Formally, a generating algorithm is a sequence of mappings (\mathpzc{G}_{n})_{n\in\mathbb{N}}: for each n, it is a computable mapping from a training dataset of size n to a (computable) distribution (i.e., a sampling algorithm) over \euscr{X}. We will use the notation (\mathpzc{G}_{n})_{n} to refer to the generating algorithm and the notation \mathpzc{G}_{n} or simply \mathpzc{G} for the induced distribution (generator) after training; hence when we write x\sim\mathpzc{G}_{n} or \operatorname{supp}(\mathpzc{G}_{n}), we refer to the distribution obtained after training. that is trained on a set S of n i.i.d. examples from \euscr{P}. To quantify the inconsistency of \mathpzc{G}_{n}, we need an objective. As discussed above, this objective should penalize \mathpzc{G}_{n} for outputting strings outside of K and for repeating examples already seen in the training data S.333When we require generating algorithm to achieve breadth, it is not important to enforce that the support does not contain S. We will elaborate after the formal statement of Definition 4. For a target language K and a model \mathpzc{G}_{n} trained on S, we consider the following generation error \mathrm{gen\_er}(\mathpzc{G}_{n})\coloneqq\Pr_{S\sim\euscr{P}^{n}}[% \operatorname{supp}(\mathpzc{G}_{n})\supset K\setminus S]\,. (1) In words, a model errs according to \mathrm{gen\_er}(\cdot) if it either hallucinates by outputting strings from \euscr{X}\setminus K or if it outputs something already contained in the training set S. This is inspired by the notion of generation considered by \citetkleinberg2024language; they call an algorithm a consistent generator if its support becomes a subset of K\setminus S after seeing finitely many training examples S. We relax this definition and call an algorithm a consistent generator for the collection \euscr{L} if its error, as defined in Equation 1, asymptotically goes to zero for any valid distribution \euscr{P}. Let us now review how prior work has approached issues with language generation algorithms – foremost, hallucination. Under the above statistical setting, \citetkalai2024calibrated made important progress showing that calibrated models must hallucinate by lower bounding the hallucination rate by the model’s calibration. For a detailed comparison with our work, we refer to Section 1.5. Closer to our paper, the work of \citetkleinberg2024language explored language generators that must not hallucinate, i.e., they must be consistent. They studied language generation in an online setting where the data are not drawn from \euscr{P} but are given as a stream to the learner, i.e., as an adversarial enumeration of the strings of the true language K. In their setting, \mathpzc{G}_{n} is said to generate in the limit from K if, after some finite time n_{0} in the enumeration of K, \mathpzc{G}_{n} is able to generate new unseen strings from K for all subsequent times n\geq n_{0}. They showed that there exists an algorithm that can generate in the limit from every countable list of candidate languages. This result is surprising because it contrasts with strong negative results for the well-studied problem of language identification in the limit (where one wants to identify K in the limit and not simply generate from it;444 Very briefly, a language collection \euscr{L}=\{L_{1},L_{2},\dots\} is called identifiable in the limit if there exists an algorithm (\euscr{A}_{n}\colon\euscr{X}^{n}\to\mathbb{N})_{n} such that for any K\in\euscr{L} and any enumeration x_{1},x_{2},\dots of the strings of K appearing as a stream to (\euscr{A}_{n}), there is a finite time n_{0}\in\mathbb{N} after which the algorithm predicts the correct index of the true language, i.e., L_{\euscr{A}_{n}(x_{1},\dots,x_{n})}=K for any n\geq n_{0}. see also Definition 9). The family of languages identifiable in the limit is very limited: the results of \citetgold1967language,angluin1979finding showed that language identification is a very difficult problem and most collections of languages are non-identifiable (in fact, there is a tight characterization due to \citetangluin1980inductive which we state in Definition 10). Hence, the algorithm of \citetkleinberg2024language shows that language generation in the limit is much more tractable than identification. We note that while their algorithm operates in a non-statistical setting, it will be an important building block for our results. \citet kleinberg2024language observed that their algorithm eventually becomes a consistent generator but suffers from mode collapse: initially, it generates with breadth while being inconsistent with the target language; later on, as a larger part of the stream is seen, it starts sacrificing breadth in order to generate valid outputs. This behavior led them to leave the existence of a consistent generator that achieves breadth as an interesting open question. In this work, we will formally introduce a notion of breadth for language generation in our statistical setting (Section 1.1.1). For now, we mention that our definition roots in the notion of mode collapse from Generative Adversarial Networks (GANs) \citepgoodfellow2020generative,arjovsky2017towards and, roughly speaking, states that an algorithm (\mathpzc{G}_{n}) generates with breadth from K if the probability that its support contains all the unseen examples from the target language goes to 1, as the training samples from a valid distribution go to infinity. Now it is a good point to contrast breadth with consistency: consistent generators aim at avoiding any elements outside of K while generators achieving breadth try to cover all unseen elements of K. The question of \citetkleinberg2024language is asking whether the equilibrium condition that the support of the generator exactly matches the unseen elements of K can eventually be achieved by some algorithm. This is the main question we aim to address in this paper. Is it possible to achieve consistent language generation with breadth or is there some inherent trade-off between consistency and breadth? 1.1 Informal Results Our main results confirm the tension between consistent generation and breadth for language models, conjectured by \citetkleinberg2024language, in a strong way: informally, we show that A language model that generates with breadth must be inconsistent, i.e., it must hallucinate. We focus on the probabilistic setting of \citetangluin1988identifying which we have already introduced informally. En route to our results in the probabilistic setting, we also obtain results in the online setting of \citetgold1967language, \citetangluin1979finding, and \citetkleinberg2024language, as we will see later. To facilitate a formal discussion of our contributions, we need to introduce some further definitions. 1.1.1 Setup and Definitions A generating (or learning) algorithm is a sequence of computable mappings (\mathpzc{G}_{n})=(\mathpzc{G}_{n})_{n\in\mathbb{N}} from samples S\subseteq\euscr{X}^{n} to generators, which are simply distributions over the domain \euscr{X}. More formally, a generating algorithm is a sequence of mappings from samples to Turing machines that generate samples from an (explicitly or implicitly) defined distribution over strings. In the statistical setting we consider, the learner observes samples from an unknown distribution which is valid for some unknown language K in the collection \euscr{L}=\{L_{1},L_{2},\dots\}. Definition 1 (Valid Distribution \citepangluin1988identifying). A distribution \euscr{P} over a countable domain \euscr{X} is valid with respect to a countable language collection \euscr{L} if its support is the same as some language K\in\euscr{L}. In this case, when we want to be specific about the language that \euscr{P} draws samples from, we say \euscr{P} is valid for K. If the collection \euscr{L} is clear from context, we will simply say that \euscr{P} is valid. Based on this definition and building on the model studied by \citetkleinberg2024language, we give the following adaptation for consistent generation from a collection \euscr{L} in the statistical setting. Definition 2 (Consistency). A generating algorithm (\mathpzc{G}_{n}) for a language collection \euscr{L} is consistent if for any valid distribution \euscr{P}, it holds that \lim_{n\to\infty}\mathrm{gen\_er}(\mathpzc{G}_{n})=0. Otherwise, the algorithm is said to be inconsistent. Hence, an algorithm is said to be consistent if the generators it produces by training on any valid distribution \euscr{P} converge to generating examples from the unseen part of \euscr{P}. Some of our results explore when asymptotic consistency is achievable. However, the main focus of our work is on understanding the rates at which consistency (and other desirable properties) can be attained – if possible at all. In particular, we want to study the rate at which the generation error \mathrm{gen\_er}(\mathpzc{G}_{n}) decreases as the number of samples n goes to infinity – that is, we want to study the learning curve of consistent generation (and other tasks that we introduce later in this section). Bousquet, Hanneke, Moran, van Handel, and Yehudayoff \citepbousquet2021theory characterized learning curves for binary classification, formalizing the universal rates framework, earlier explored by \citetschuurmans1997characterizing and \citetantos1996strong. To this end, we borrow their definition of universal rates. Definition 3 (Informal, Universal Rates; \citepbousquet2021theory, see Definition 12). A generating algorithm (\mathpzc{G}_{n}) has rate R(\cdot), where \lim_{n\rightarrow\infty}R(n)=0, for a language collection \euscr{L} if \forall\euscr{P}\in\mathrm{Val}(\euscr{L})~{}~{}\exists C,c>0\quad\text{such % that}\quad\mathrm{gen\_er}(\mathpzc{G}_{n})\leq C\cdot R(c\cdot n)\quad\forall n% \in\mathbb{N}\,, where \mathrm{Val}(\euscr{L}) is the class of valid (realizable) distributions for \euscr{L}. Observe that these learning curves are distribution-dependent since the constants c and C are allowed to depend on \euscr{P}. This difference turns out to be crucial and can, sometimes, lead to significant differences between universal rates and the corresponding distribution-independent rates \citepbousquet2021theory. Among different universal rates, exponential universal rates are of specific interest as they are often the best possible rate, as we will see later. We say that the algorithm (\mathpzc{G}_{n}) generates with an exponential universal rate if R(n)=\exp(-n) in the above definition. Next, we turn to language generation with breadth. Definition 4 (Breadth). A generating algorithm (\mathpzc{G}_{n}) for a language collection \euscr{L} is said to achieve breadth if, for any valid distribution \euscr{P}, it holds that \lim_{n\to\infty}\Pr[\operatorname{supp}(\mathpzc{G}_{n})\supseteq K\setminus S% _{n}]=1, where S_{n} is the dataset used to train \mathpzc{G}_{n}, i.i.d. from \euscr{P}. Otherwise, the algorithm suffers from mode collapse. Definition 4 is inspired by the literature on GANs (see e.g., \citepgoodfellow2020generative,arjovsky2017towards). For instance, consider the work of \citetarjovsky2017towards, which studies distributions \mathpzc{G} and \euscr{P} induced by the generator and nature, respectively, and says that mode collapse occurs when the KL divergence \operatornamewithlimits{\mathsf{KL}}\left(\euscr{P}\|\mathpzc{G}\right)% \coloneqq\int\log\left(\nicefrac{{\euscr{P}(x)}}{{\mathpzc{G}(x)}}\right)~{}{% \rm d}\euscr{P}(x)\to\infty. In particular, mode collapse happens when there is some string x\in\operatorname{supp}(\euscr{P}) for which \mathpzc{G}(x)=0. In other words, the generator has breadth when \operatorname{supp}(\mathpzc{G})\cup S_{n}\supseteq\operatorname{supp}(\euscr{% P}), which recovers our definition for breadth by noting that \operatorname{supp}(\euscr{P})=K since \euscr{P} is valid for K and that, to be compatible with the definition of consistency (Definition 2), we bar a generator from repeating strings it has already seen. (It is worth mentioning that one can modify the definition of breadth to require \operatorname{supp}(\mathpzc{G}_{n})\supseteq K without changing any of our results; see Remark 2.) We also note that the definition of consistency we use can also be derived in an analogous fashion by requiring the reverse KL divergence (i.e., \operatornamewithlimits{\mathsf{KL}}\left(\mathpzc{G}\|\euscr{P}\right)) to be finite. Putting the definitions of consistency and breadth together implies that an algorithm generates with consistency and breadth if, eventually, its support matches the set of unseen strings in K, i.e., K\setminus S_{n} at the n-th step. After presenting our main results, in Section 1.3, we discuss relaxations of this notion of consistent generation with breadth. A last ingredient for our results concerns the decidability of a folklore Theoretical Computer Science problem, which we call the membership oracle problem, that has motivated extensive work in formal languages and complexity theory \citepsipser2012introduction,soare1999recursively. A generator \mathpzc{G}, which is the output of some generating algorithm, corresponds to some Turing machine, as is standard in the language inference literature, that samples according to a distribution over \euscr{X} \citepangluin1979finding,blum1975toward,angluin1983inductive,adleman1991inductive. Definition 5 (Membership Oracle Problem). Given a generator \mathpzc{G}, the membership oracle problem for \mathpzc{G}, denoted as \mathsf{MOP}(\mathpzc{G}), is defined as follows: given the description of \mathpzc{G} and a string x, output Yes if x\in\operatorname{supp}(\mathpzc{G}) and output No otherwise. This problem is, in general, undecidable due to a reduction to the halting problem (Section A); nevertheless, its decidability depends on the structure of the Turing machine as we will see shortly. The above definition naturally extends to generating algorithms. Definition 6 (MOP for Generating Algorithms). The membership oracle problem is decidable for a generating algorithm (\mathpzc{G}_{n}) if, for any n\in\mathbb{N} and any S\subseteq\euscr{X}^{n}, \mathsf{MOP}(\cdot) is decidable for the induced generator \mathpzc{G}=\mathpzc{G}_{n}(S). We note that the above definitions implicitly assume that the generator \mathpzc{G}_{n}(S) depends only on the randomness of S; we could extend this by allowing \mathpzc{G}_{n}(S) to be a distribution over generators. 1.1.2 Main Results We now have all the ingredients to state our first result, which establishes that, for all generating algorithms for which \mathsf{MOP}(\cdot) is decidable, (consistent) generation with breadth is as hard as language identification in the statistical setting. As in Definition 3, we will say that the generating algorithm (\mathpzc{G}_{n}) generates with breadth from \euscr{L} at some rate R(\cdot) if, for any K\in\euscr{L}, valid distribution \euscr{P}, and n\in\mathbb{N}, \operatornamewithlimits{\mathbb{E}}_{S\sim\euscr{P}^{n}}\mathds{1}\left\{% \operatorname{supp}(\mathpzc{G}_{n})\neq K\setminus S\right\}\leq C\cdot R(c% \cdot n)\,, for some distribution-dependent constants C,c>0. If no rate R(\cdot) satisfying \lim_{n\to\infty}R(n)=0 exists, we will say that (\mathpzc{G}_{n}) does not generate with breadth at any rate. Informal Theorem 1 (see Theorem 3.3). For every language collection \euscr{L} that is not identifiable in the limit, no generating algorithm (\mathpzc{G}_{n}), for which \mathsf{MOP}{}(\cdot) is decidable, can generate from \euscr{L} with breadth at any rate. Recall that the family of languages non-identifiable in the limit is quite broad. Based on the results of \citetgold1967language,angluin1979finding,angluin1980inductive on the problem of language identification in the limit, our impossibility result holds for most interesting collections of languages. For Informal Theorem 1 to be valuable and meaningful though, we further need to show that there exists an algorithm that generates without breadth for the collections of languages for which our impossibility result is true. Our next result states that this is indeed possible: there exists an algorithm that generates with (almost) exponential universal rates for any countable language collection \euscr{L}. Informal Theorem 2 (see Theorem 3.3). For every language collection \euscr{L} that is not identifiable in the limit, there exists a generating algorithm (\mathpzc{G}_{n}), for which \mathsf{MOP}(\cdot) is decidable, that generates (possibly) without breadth from \euscr{L} at exponential rates. Further, if \euscr{L} is identifiable in the limit, then there exists a generating algorithm (\mathpzc{G}_{n}), for which \mathsf{MOP}(\cdot) is decidable, that generates with breadth from \euscr{L} at (almost) exponential rates. Informal Theorem 2 shows that any countable collection of languages not only admits a consistent generator in the limit under an adversarial enumeration of the target language (as shown by \citetkleinberg2024language), but the statistical rate at which consistency (as per Definition 2) is achieved is exponential in the number of samples. Further, for identifiable collections of languages, we give an algorithm that generates with breadth at an (almost) exponential rate. The combination of Informal Theorem 1 and 2, reveals a strong separation between generation with and without breadth for any generating algorithm for which \mathsf{MOP}(\cdot) is decidable. What is missing is an answer to: how large is the class of generators for which the membership oracle problem \mathsf{MOP}(\cdot) is decidable? It turns out there is a very broad class of language generators for which this is the case and which also captures modern LLMs, as we show next. A Family of Generators for Which \mathsf{MOP}{}(\cdot) Is Decidable. Motivated by the structure of modern language models \citepbahl1983maximum,brown1990statistical,touvron2023llama,bubeck2023sparks,achiam2023gpt, we consider a family of iterative generators. A generator is said to be iterative if it generates text one alphabet or “token” at a time (see Definition 14). To generate each token, the generator can perform an arbitrary (but finite) amount of computation and, possibly, use randomness. For this to make sense, one has to imagine strings of \euscr{X} as strings over some finite alphabet \Sigma. This holds without loss of generality as \euscr{X} is countably infinite and, hence, there is a one-to-one mapping from \euscr{X} to strings over \Sigma (due to which \euscr{X} can be thought of as a set of strings over \Sigma).555 In a bit more detail, since \euscr{X} and \Sigma^{*} are countably infinite, they have enumerations x_{1},x_{2},\dots and s_{1},s_{2},\dots. Therefore, given any string s_{i}\in\Sigma^{*} generated by an iterative generator, one can map it to a string x_{i}\in\euscr{X}, thereby getting a generator for \euscr{X}. We show that for any iterative generator, the membership oracle problem is decidable and our Informal Theorem 1 is applicable. Informal Theorem 3 (see Theorem 3.4). For any iterative generator \mathpzc{G}, \mathsf{MOP}(\mathpzc{G}) is decidable. Observe that this family of next-token generators is very general. First, it captures existing large language models: for instance, to simulate an LLM L, we define the next-token predictor as a Turing machine that simulates L on the provided string until L generates one new token. Next, it also captures systems where an LLM can interact with another Generative AI model or algorithmic system (such as a diffusion model or a code interpreter) – as these auxiliary systems can also be simulated by the generator. Given this, it becomes evident that this class of generators for which \mathsf{MOP}{}(\cdot) is decidable is fairly large and interesting. Implications for the Gold-Angluin Model. We repeat that all the aforementioned results hold in the statistical setting. En route to obtaining our results in this setting (Informal Theorems 1 and 2), we show several connections to the online setting of \citetgold1967language, angluin1979finding,angluin1980inductive,kleinberg2024language, which lead to the following result. Informal Theorem 4 (see Theorem 3.5). For any language collection \euscr{L} that is not identifiable in the limit, no generating algorithm (\mathpzc{G}_{n}), for which \mathsf{MOP}{}(\cdot) is decidable, can generate from \euscr{L} with breadth in the limit. To be more concrete, a generating algorithm generates with breadth in the limit if its support is eventually K\setminus S_{n}, where S_{n} is the set of the first n positive examples (i.e., examples that belong to K). We emphasize that Informal Theorem 4 is in a similar spirit as our Informal Theorem 1, but holds in the online model instead of the statistical model discussed earlier. In particular, Informal Theorem 4 combined with the algorithm of \citetkleinberg2024language give a separation between consistent generation with and without breadth in the Gold-Angluin model. Further, as explained before, this result applies to any iterative generator due to Informal Theorem 3. Moreover, as \mathsf{MOP}{}(\cdot) is decidable for the generating algorithm of \citetkleinberg2024language (since its support contains a singleton element x which can be computed by running their algorithm), the above result, in particular, shows that the algorithm of \citetkleinberg2024language cannot generate with breadth in the limit from any non-identifiable collection. Organization of Rest of the Introduction. We proceed with an exposition of our techniques in order to obtain our main results presented above. In Section 1.3, we relax the definitions of consistency and breadth and give more “robust” trade-offs between hallucination and breadth. Next, in Section 1.4, we give a list of open problems for future work. Finally, Section 1.5 contains an extensive overview of related works. 1.2 Technical Overview In this section, we present the technical tools we develop to obtain our main results. A Natural Strategy to Prove Informal Theorem 1. At first glance, there seems to be a natural strategy to prove Informal Theorem 1: assume that there exists a consistent generating algorithm with breadth \mathpzc{G}=(\mathpzc{G}_{n}) for some non-identifiable collection \euscr{L} in the statistical setting and then show that this implies identification in the statistical setting, which would contradict the fact that \euscr{L} is non-identifiable. To implement this strategy one needs a method to utilize \mathpzc{G}, along with the positive samples from the target language K, for identification. This raises the question: what additional power can \mathpzc{G} give that the positive samples do not already provide? Initial Attempts to Implement the Strategy. Indeed, if one uses no additional properties of \mathpzc{G}, then its outputs provide no more information than an adversarial enumeration of K. To develop some intuition, we begin by considering some properties of the generator and explaining why they are insufficient to enable identification. 1. \mathpzc{G} is non-adaptive. First, one may want to utilize the fact that the generator \mathpzc{G}{} is fixed and, hence, the samples it outputs cannot adapt to the specific algorithm being used based on the outputs of the algorithm. Hence, it will probably provide an algorithm-independent enumeration of the true language. However, this is not helpful in general since there exist simple non-identifiable language collections that remain non-identifiable for many enumerations of the target language. 2. \mathpzc{G} samples from a fixed distribution. Another property one may want to leverage is the stochasticity of the generator: \mathpzc{G} samples its outputs from a fixed distribution (which is valid for K). However, even this does not enable the identification of non-identifiable collections due to a result by \citetangluin1988identifying. Angluin shows that even if the positive examples are i.i.d. from a valid distribution and do not appear as an adversarial enumeration (as in \citetgold1967language), this does not enable identification of any collection \euscr{L} that is non-identifiable in the limit. (We prove a stronger version of this result in Lemma 5.5.) 3. \mathpzc{G} samples from a simple distribution. Moreover, the difficulty in the above negative result is not the complexity of the encoded distribution: it holds even when \mathpzc{G} samples from a distribution that is computable by a Turing machine. At this point, it is not clear how to utilize access to a generator \mathpzc{G} which generates with breadth from K. Next, we present a strong form of access to the generator \mathpzc{G} that is useful for identification. 4. Access to Subset Queries “\operatorname{supp}(\mathpzc{G})\subseteq L_{i}” and “L_{i}\subseteq L_{j}”. For one of their algorithms, \citetkleinberg2024language utilize a subset oracle that answers queries of the form “is L_{i}\subseteq L_{j}?”. (In general, this oracle is not guaranteed to be computable). One can imagine an extension of this oracle that, given an index i and description of the generator \mathpzc{G}, outputs whether \operatorname{supp}(G)\subseteq L_{i}. The existence of this oracle turns out to be sufficient to identify K, as we explain next: After a finite amount of time, \citetkleinberg2024language’s algorithm creates a list of “critical” languages C_{1},C_{2},\dots, of the following form (see Theorem 4.1 in \citetkleinberg2024language) C_{1}\supseteq C_{2}\supseteq\dots\supseteq\left(C_{i}\coloneqq K\right)% \supseteq C_{i+1}\supseteq\dots\,. In words, this list has two properties (1) K appears in this list, say, at C_{i}=K for some i<\infty and (2) each language C_{j} in the list is a subset of the preceding language C_{j-1}. Given this list and the aforementioned subset oracle, one can easily identify the index of K as the largest j for which \operatorname{supp}(\mathpzc{G})=K\subseteq C_{j}. This assumption allows to identify any collection in the limit given access to a consistent generation \mathpzc{G} with breadth. However, this type of access is not very practical since it is not clear when such an oracle is implementable. Our Approach. Our first idea is that a much weaker form of access to \mathpzc{G} – membership oracle to \operatorname{supp}(\mathpzc{G}) – is sufficient for identification. This is where the membership oracle problem \mathsf{MOP}{}(\cdot) (Definition 5) appears in the proof. In fact, given this idea, it is not difficult to show that with that type of access, we can go from a generator with breadth in the online setting to an identification algorithm in the online setting; and, hence, get Informal Theorem 4. However, our focus is the statistical setting where there are several additional challenges in using the membership oracle to \operatorname{supp}(\mathpzc{G}). A. Need for Universal Rates for Generation and Identification. The key issue is the following: In the statistical setting, if we assume that we have a generator with breadth at rate R(\cdot), then we can hope to show an implication that we can get an identification algorithm at rate R(\cdot). However, this need not imply a contradiction to the identifiability of \euscr{L} as in the online setting. This is because, even though \euscr{L} is non-identifiable in the online setting, it may become identifiable at some rate R^{\prime}(\cdot) in the statistical setting. Indeed, this is the case in binary classification, where there are simple hypothesis classes (such as thresholds over reals) that are not learnable in Littlestone’s online setting \citeplittlestone1988learning but become learnable (at a universal – and uniform – linear rate) in the statistical setting; in fact, any hypothesis class is learnable in the statistical setting under universal rates, since there is a Bayes consistent algorithm, under benign assumptions \citepbousquet2021theory. Hence, to get a contradiction, we first need to understand the taxonomy of universal rates for generation and identification. We remark here that both the learning task (e.g., classification, regression, identification, and generation) and loss function used in the problem are pivotal for the landscape of rates that one gets; for instance, with the zero-one loss for binary classification one gets a trichotomy of rates \citepbousquet2021theory, but with the L_{1}-loss for regression, one gets infinitely many rates \citepattias2024universal. To overcome the above challenge, we provide statistical rates for identification and generation. We start with identification. We show that if \euscr{L} is identifiable in the limit in the adversarial Gold-Angluin setting with positive examples \citepgold1967language,angluin1980inductive, then it is identifiable under Definition 12 with (almost) exponential (universal) rates. This is the less technical part of the proof so we will give a high-level approach. B. Identification in the Limit \implies Identification at (Almost) Exponential Rates. Our idea is reminiscent of \citet*bousquet2021theory and requires splitting the input dataset into multiple batches whose size is carefully selected, running the online algorithm on each batch, and then taking a majority vote over the outputs of the algorithm. We remark that there are some technical issues which require further care, compared to \citetbousquet2021theory. First, unlike the setting of \citetbousquet2021theory, we only see positive examples and we get no feedback about our guesses. Thus, we cannot use their approach to “estimate” a time after which the learner will stop making mistakes. Moreover, when we run the learners on multiple batches, it can be the case that different batches output different indices of languages that correspond to K (since the target language can appear at multiple positions in the countable collection \euscr{L}). Thus, taking a majority vote over these indices might not work. Nevertheless, we manage to handle these issues and get almost exponential rates for collections that satisfy Angluin’s criterion for identification in the limit \citepangluin1979finding. A bit more concretely, to circumvent the first issue, our approach is to “guess” the right batch size, and this guess needs to be an increasing function of n – this is why we get almost exponential rates instead of exactly exponential rates (Lemma 5.5). The second issue is more subtle. At a high level, we use a voting scheme where the output of every batch \widehat{L}_{i} gives a “vote” to every language L\in\euscr{L} such that \widehat{L}_{i}=L, and we predict the lowest-indexed language that is voted by at least half of the batches. In its current form, this scheme is not computable, nevertheless, we show that it can be modified so that it becomes computable (Lemma 5.4). The more interesting half of establishing universal rates for identification is the lower bound showing that if a collection is not identifiable in the limit, it is also not identifiable in the statistical setting at any rate R(\cdot) such that \lim_{n\to\infty}R(n)=0. C. Impossible to Identify in the Limit \implies Impossible to Identify at Any Rate. Recall that the statistical setting was studied by \citetangluin1988identifying. \citetangluin1988identifying showed that every learner, with probability at least \nicefrac{{1}}{{3,}} does not converge to outputting a (stable) index of the target language in an infinite stream of examples drawn from a valid distribution. In other words, with probability at least \nicefrac{{1}}{{3,}} the algorithm will either stabilize to an index that does not correspond to the target language or it will not stabilize to any index. Notice that this does not rule out algorithms that output different indices of the target language, for all but finitely many n\in\mathbb{N}. The first step towards establishing our desired lower bound is to strengthen Angluin’s result: we show that any learning algorithm, with probability at least \nicefrac{{1}}{{3}}, outputs indices that do not correspond to the target language infinitely often. More formally, let us consider an identification algorithm h_{n}, which maps a training set of n examples x_{1},\dots,x_{n} to an index h_{n}(x_{1},\dots,x_{n}) so that L_{h_{n}(x_{1},\dots,x_{n})} is the n-th prediction for the true language. The aforementioned lower bound means that666 Informally, \limsup of a sequence of events captures the events that occur infinitely often. For instance, \Pr[\limsup_{n\to\infty}\mathscr{E}_{n}] represents the probability that infinitely many of the events \mathscr{E}_{1},\mathscr{E}_{2},\dots occur. On the other hand, \limsup_{n\to\infty}\Pr[\mathscr{E}_{n}], roughly speaking, denotes the largest value that the probabilities \Pr[\mathscr{E}_{1}],\Pr[\mathscr{E}_{2}],\dots,\dots approach infinitely often as n\to\infty. \Pr_{\left\{x_{i}\colon i\in\mathbb{N}\right\}\sim\euscr{P}^{\infty}}\left[% \limsup_{n\rightarrow\infty}\left\{L_{h_{n}\left(x_{1},\ldots,x_{n}\right)}% \neq K\right\}\right]\geq\frac{1}{3}\,, where X\sim\euscr{P}^{\infty} corresponds to an infinite i.i.d. draw from \euscr{P}. One may be tempted to conclude that this implies that with probability \nicefrac{{1}}{{3}} we cannot identify the target language (in the statistical setting). However, the quantity we wish to bound away from 0 to derive the desired lower bound is \limsup_{n\rightarrow\infty}\Pr_{x_{1},\ldots,x_{n}\sim\euscr{P}^{n}}\left[% \left\{L_{h_{n}\left(x_{1},\ldots,x_{n}\right)}\neq K\right\}\right]\,. It is well-known that for any sequence of events \{\mathscr{E}_{n}\}_{n\in\mathbb{N}}, \Pr\left[\limsup_{n\rightarrow\infty}\mathscr{E}_{n}\right]\geq\limsup_{n% \rightarrow\infty}\Pr[\mathscr{E}_{n}]\,. This, however, is not sufficient to deduce the result we need; we need the opposite inequality. Hence, Angluin’s guarantee does not suffice to get our lower bound. In order to show our result, we use a boosting argument (Lemma 5.8): if there exists a learner h_{n} whose probability of misidentification \Pr_{x_{1},\dots,x_{n}\sim\euscr{P}^{n}}\left[L_{h_{n}\left(x_{1},\dots,x_{n}% \right)}\neq K\right] converges to a number strictly less that \nicefrac{{1}}{{2}}, then we can convert it to a learner whose error rate decreases (almost) exponentially quickly. This (almost) exponential rate, in particular, implies that \sum_{n=1}^{\infty}\Pr_{x_{1},\ldots,x_{n}\sim\euscr{P}^{n}}\left[L_{h_{n}% \left(x_{1},\ldots,x_{n}\right)}\neq K\right]<\infty\,. This, crucially, enables us to use the Borel-Cantelli lemma (see Lemma E.1) which gives us that \Pr\left[\limsup_{n\rightarrow\infty}\left\{L_{h_{n}\left(x_{1},\ldots,x_{n}% \right)}\neq K\right\}\right]=0 , and, thus, a contradiction to Section 1.2. This implies the desired impossibility result. As consequence of the above results, we get a dichotomy for universal identification rates: Informal Theorem 5 (see Theorem 3.1). For any language collection \euscr{L} that is identifiable in the limit and for any g(n)=o(n), there exists a learner that identifies \euscr{L} at rate \exp(-g(n)). Otherwise, \euscr{L} is not identifiable at any rate. We remark that if we have access to subset queries for \euscr{L}, we can show that there exists an algorithm that achieves exactly exponential rates, for all identifiable collections (see Proposition 3.8). Next, we move to understanding universal rates for language generation. D. Universal Rates for Generation (Possibly Lacking Breadth) Without Boosting. One might suspect that a similar batching argument would give us exponential rates for generation: just run the online algorithm of \citetkleinberg2024language multiple times and aggregate. The issue is that aggregation for generation is different than prediction: for prediction, it is clear how to implement majority vote as a boosting technique; for generation, it is unclear how to aggregate different generated strings which is, typically, necessary to obtain a boosting algorithm. One immediate attempt is to take majority votes over the strings that each batch outputs; unfortunately, even if the majority of them are generating from the target language, they might be outputting different strings, thus, even a few batches outputting the same invalid strings are enough to fool our aggregation rule. Another tempting approach is to mimic the strategy we used to aggregate different indices of the target language in the identification setting: we go over every output of the batches and we let them give a vote to each of the languages in \euscr{L} they belong to.777The astute reader might realize that, as stated, this strategy is not computable – as we explain, even if one could implement it, this aggregation scheme does not work. It is not hard to see that every batch whose output corresponds to a valid generator will vote for the target language. Unfortunately, it will also vote for all supersets of the target language. This is exactly the heart of the difficulty of identification: telling apart supersets of the target language from the target language, which is colloquially called overgeneralization. Taking it to the extreme, imagine that the first language of the collection contains all the strings, i.e., L_{1}=\euscr{X}. Then, all the batches will vote for L_{1}. This is problematic for two reasons: generating a fresh string from the majority-voted language is as good as random guessing, and choosing a string among the ones that voted for the majority-voted language is as good as picking one of the outputs of all batches uniformly at random. Perhaps surprisingly, it turns out that a much simpler approach works: we show that the algorithm of \citetkleinberg2024language directly enjoys exponential rates in the statistical setting, without the use of batching and boosting. This observation is based on a sufficient condition that allows one to use an algorithm that works “in the limit” to obtain exponential rates in the statistical setting, without any modification (see Lemma 5.11). Informal Theorem 6 (see Theorem 3.2). For any countable language collection \euscr{L} there exists a generating algorithm that generates from \euscr{L} at an (optimal) exponential rate. This pair of results for identification (Informal Theorem 5) and generation (Informal Theorem 6) allow us to get Informal Theorem 1 and 2. The idea for Informal Theorem 1 is that we will use the algorithm \mathpzc{G} that generates with breadth at some rate R(\cdot) for an arbitrary non-identifiable collection \euscr{L} and membership oracle access to \mathpzc{G} in order to get an identification algorithm for \euscr{L} with some rate R^{\prime}(\cdot) such that \lim_{n\to\infty}R^{\prime}(n)=0. This is a contradiction since Informal Theorem 5 shows that \euscr{L} admits no rate in the universal setting. Finally, Informal Theorem 2 follows almost immediately from our universal rates result for generation. 1.3 Additional Results With Relaxation of Consistency and Breadth Next, we study a relaxation of consistent generation with breadth, which we call unambiguous generation, and ask: is there a generator that unambiguously generates from a non-identifiable collection? In this section, we will allow the generator to repeat examples in the training data. Like all of our results with breadth, this choice is not crucial, and all of the results have analogs where the generator does not repeat training examples (see Remark 2). We make this choice for simplicity. We show that unambiguous generation (which we define later in this section) from non-identifiable collections is impossible for any generator \mathpzc{G} for which \mathsf{MOP}{}(\mathpzc{G}) is decidable and that satisfies the natural property that \mathpzc{G} “stabilizes” after seeing sufficiently many examples: Definition 7 (Stability). A generating algorithm (\mathpzc{G}_{n}) is stable for a language collection \euscr{L} if for any target language K\in\euscr{L} and for any enumeration of K, there is some finite n^{*}\in\mathbb{N} such that for all n,n^{\prime}\geq n^{*}, it holds that \operatorname{supp}(\mathpzc{G}_{n})=\operatorname{supp}(\mathpzc{G}_{n^{% \prime}}). We make some initial remarks about stable generators. First, any generator \mathpzc{G} that is consistent and achieves breadth is also stable, since after some finite time its support, union the training set, becomes K and remains so. (Here, whether \mathpzc{G} repeats training examples or not is not crucial – the two types of generators are interchangeable; see Remark 2.) Second, this notion of stability can be seen as trying to capture practical heuristics such as learning rate schedules and early stopping that reduce the amount of changes to the generator as more and more samples are seen. Moreover, the original work of \citetgold1967language also requires the identifier to stabilize to a consistent guess, and, more recently, the stability property of learning algorithms was explored in the PEC learning setting of \citetmalliaris2022unstable. Having defined stability, we proceed to discuss relaxations of generation with breadth. Intuitively, consistent generation with breadth requires the generator to eventually stop making mistakes – where a mistake is any element x that \mathpzc{G} incorrectly includes (if x\not\in K or x is part of the training samples) or excludes (if x\in K) from its support. We now relax this and only require that, eventually, the generator \mathpzc{G} makes finitely many mistakes. Observe that this is a non-trivial requirement because the languages contain infinitely many strings and, so, at the start, \mathpzc{G} is expected to make infinitely many mistakes. A valuable observation is that it is possible for two languages L_{1} and L_{2} to only differ in finitely many strings even if each contains infinitely many strings. With this observation, it is not too hard to see that the aforementioned requirement is too weak to capture a reasonable notion of generation from the target language K. Indeed, it would allow generators that, given examples from K, perpetually generate outputs (with breadth) from a language L that is not the actual target language – which is a severe form of hallucination. Hence, to create a meaningful model, we must impose some further restrictions on the mistakes of the generator \mathpzc{G}. The above example motivates that, at the least, the generator \mathpzc{G} should be “closer” to generating from K than some language L\neq K with L\in\euscr{L}. We call such a generator unambiguous. Definition 8 (Unambiguous Generator). A generating algorithm \mathpzc{G}=(\mathpzc{G}_{n}) is unambiguous for a language collection \euscr{L} if, for any K\in\euscr{L} and every enumeration of K, its support eventually becomes closer to K than to any other language L\neq K in \euscr{L} in terms of the symmetric difference metric, i.e., there exists some n^{*}\in\mathbb{N} such that for all n\geq n^{*} it holds that \left|\operatorname{supp}(\mathpzc{G}_{n})\triangle K\right|<\min_{L\in\euscr{% L}\colon L\neq K}\left|\operatorname{supp}(\mathpzc{G}_{n})\triangle L\right|, where recall that for two sets S and T, S\triangle T\coloneqq\left(S\setminus T\right)\cup\left(T\setminus S\right). Figure 1: An Unambiguous Generator That neither Has Consistency nor Breadth. In this example, the language collection \euscr{L} has two languages L and K, where K denotes the target language. The red curve denotes L, the dashed green curve denotes K, and the blue curve denotes the support of \operatorname{supp}(\mathpzc{G}_{n}). The generator \mathpzc{G}_{n} hallucinates since \operatorname{supp}(\mathpzc{G}_{n})\setminus K\neq\emptyset and does not achieve breadth for the target K since B=K\setminus\operatorname{supp}(\mathpzc{G}_{n}) is non-empty. Nevertheless, this generator is unambiguous as \left|\operatorname{supp}(\mathpzc{G}_{n})\setminus K\right|+\left|B\right|<% \left|\operatorname{supp}(\mathpzc{G}_{n})\setminus L\right|+\left|A\right|. Here, we pause to observe that this notion of generation is a significant relaxation of generation with breadth that we considered earlier (Definition 4). Not only does it allow the generator to hallucinate certain strings not in the target K and omit strings actually in K for arbitrarily long, the number of hallucinations and omissions can be arbitrarily large, depending on the structure of the language collection \euscr{L}. Surprisingly, we show that even this very weak notion of “consistent generation with breadth” is not achievable by a large class of generators. Informal Theorem 7 (see Theorem 3.6). For every language collection \euscr{L} that is not identifiable in the limit, no stable generating algorithm \left(\mathpzc{G}_{n}\right) for which \mathsf{MOP}{}(\cdot) is decidable, can generate unambiguously from \euscr{L} at any rate. Thus, under mild conditions, no stable algorithm can generate unambiguously from a non-identifiable collection. Moreover, we also prove an analog of Informal Theorem 7 in the online setting (see Theorem 3.7), which extends our earlier result for generation with breadth in the online setting (Informal Theorem 4). This raises several questions regarding unambiguous generation, which we leave as interesting open problems (see Section 1.4). Note that while this impossibility result has a benign requirement that the generator is stable, it already considerably extends our main result Informal Theorem 1, since any generator that achieves breadth must be stable – otherwise, its support cannot settle on the target language K. (Note that while Informal Theorem 1 requires the generator to not repeat training examples, any generator that repeats training examples can be converted into one that does not repeat training examples and vice-versa; see Remark 2.) 1.4 Takeaways, Discussion, and Open Problems We believe that a key takeaway of our results is that the question of \citetkleinberg2024language seems to open an avenue towards a formal modern theory of language generation bridging learning theory and traditional TCS fields, like complexity theory and formal languages. As we explain in the subsequent technical overview, our tools contribute to this direction by connecting classical lines of work on identification of formal languages tracing back to \citetgold1967language, \citetangluin1979finding,angluin1980inductive,angluin1988identifying and computability theory \citepsipser2012introduction,soare1999recursively, to modern learning paradigms such as learning curves \citepbousquet2021theory and language generation \citepkleinberg2024language,kalai2024calibrated. Next, we emphasize that our impossibility result (Theorem 3.3) is not a dead end for language generation. Instead, it illustrates the need for additional human feedback during the post-training process – which provides additional information over positive samples alone – to achieve effective language models. Indeed, if both positive and negative examples are available, then generation with breadth is achievable for all countable collections of languages.888This follows from the work of \citetgold1967language, which showed that any countable collection of languages can be identified with such feedback. Using appropriate batching and boosting, we show that this identification algorithm (which works in the limit) can be converted to a generation algorithm with breadth that achieves an exponential rate. Concretely, Theorem 3.11 shows how to identify at an exponential rate and Proposition 6.5 shows how to convert this to a generation algorithm. In other words, our results can be seen as further theoretical evidence of the benefits of post-training with human feedback, highlighting its importance in developing language models that achieve both consistency and breadth, and adding to prior theoretical results from \citetkalai2024calibrated. Further, we underline that even though we focus on a prompt-less generation setting \citepkalai2024calibrated,kleinberg2024language, most of our results immediately extend to a prompted setting using the approach of \citetkleinberg2024language. Remarks and Open Questions. We now state a few remarks regarding our results and pose some interesting open questions. First, as a byproduct of our results, we establish almost tight rates for identification and generation with positive examples (see Section 3.1 and Section 3.4 for formal statements and discussion). Obtaining tight rates for these tasks is an interesting problem. Next, our impossibility results capture a large class of language-generating algorithms but do not completely forbid consistent generation with breadth. An immediate open question is how much further we can extend the class of generating algorithms for which the impossibility result in Informal Theorem 1 holds. Open Question 1. Is there a class of generative algorithms for which the induced generators can be modeled as Turing machines and which achieve breadth and consistency for all countable collections of languages? Further, we also proved a more robust version of our main result (Informal Theorem 1), namely, Informal Theorem 7, which showed that no algorithm from a large class of generators can generate while making a “small” number of hallucinations or omissions (also see Section 3.3 for another robust version of Informal Theorem 1). It is interesting to understand if one can prove a more robust version of Informal Theorem 1. To this end, we propose the following problem. Open Question 2. What is the Pareto frontier of an approximate notion of breadth and consistency? In other words, if we fix a collection of languages and allow the generator to hallucinate at some given rate, what is the minimal fraction of the mass from the target language that this generator has to miss? Next, to the best of our knowledge, it is not possible to test if a language collection is identifiable in the limit (without access to a strong oracle); this, for instance, becomes evident by inspecting Angluin’s criterion for identifiable collections (see Definition 10). Hence, we would like to know the following: Open Question 3. Is there a best-of-both-worlds algorithm between consistent generation and generation with breadth, i.e., is there an algorithm that will always generate in the limit from the target language consistently but, whenever identification is possible, it will also achieve breadth? We make some initial progress on this question by showing that the algorithm proposed by \citetkleinberg2024language already achieves this best-of-both worlds guarantee, provided it has access to a subset oracle for \euscr{L} that answers queries of the form “is L_{i}\subseteq L_{j}?” (see Section B.2). Finally, our algorithm that achieves (almost) exponential rates for identification uses an algorithm for identification in the limit as a black box. However, our algorithm that achieves exponential rates for generation makes use of certain specific properties of the algorithm of \citetkleinberg2024language. Thus, we ask the following question. Open Question 4. Is there a black-box transformation from an algorithm that generates in the limit in the online setting to an algorithm that generates with exactly exponential rates in the statistical setting? 1.5 Further Related Works Our setting is based on the statistical formulation of \citetangluin1988identifying, who studied identification from stochastic examples in the limit. However, \citetangluin1988identifying does not provide any learning rates which is one of the main aspects of our work. In terms of techniques, our inspiration for the statistical rates comes from universal learning, initiated by \citet*bousquet2021theory and studied in \citetbousquet2021theory,kalavasis2022multiclass,hanneke2022universal,hanneke2023universal,attias2024universal,bousquet2023fine. However, as we have already explained there are various differences between our setting and our techniques (we provide a more extensive and self-contained discussion in Section D). Our work connects various disjoint strands of research and we discuss each one of them below. Theory on Hallucinations. In terms of rigorous evidence about hallucinations in LLMs, we have already mentioned the work of \citetkalai2024calibrated at the start of Section 1. The result of \citetkalai2024calibrated is that calibrated999The exact definition of calibration is not important for this work: a language model is calibrated if, roughly speaking, the strings that the model assigns probability mass p, appear in a p fraction of the true distribution \citepdawid1982well. language models must hallucinate. The fascinating implication of this result is that one can lower bound the rate of hallucination, i.e., the quantity \operatornamewithlimits{\mathbb{E}}_{S\sim\euscr{P}^{n},~{}x\sim\mathpzc{G}_{n% }}\mathds{1}\left\{x\notin K\right\}, by the extent of a model’s calibration. Their intuition is that the root of hallucinations are rare patterns in the training data. Informally, their main result (under assumptions on K and \euscr{P}) is that for any trained model \mathpzc{G}_{n} with n samples, the hallucination rate \operatornamewithlimits{\mathbb{E}}_{S\sim\euscr{P}^{n},~{}x\sim\mathpzc{G}_{n% }}\mathds{1}\left\{x\notin K\right\}\geq\widehat{R}-\mathrm{Mis}_{\euscr{P}}(% \mathpzc{G}_{n})-\nicefrac{{1}}{{\sqrt{n}}}, where \widehat{R} is the fraction of facts that only appear once in the training data and \mathrm{Mis}_{\euscr{P}}(\mathpzc{G}_{n}) is the amount of miscalibration of the model. Hence, if the model is calibrated, i.e., \mathrm{Mis}_{\euscr{P}}(\mathpzc{G}_{n})\approx 0, the hallucination rate is lower bounded by the rare facts’ rate. Compared to our work, their goal is to show a quantitative lower bound, which is obtained under assumptions on the training distribution \euscr{P} and the fact that the model is calibrated. Our goal is different: we want to understand whether a model can achieve breadth while avoiding hallucinations building on the recent work of \citetkleinberg2024language. We also refer the reader to \citetkalai2024calibrated for an extensive overview of applied works on hallucinations. \citet peng2024limitations use communication complexity to prove that the transformer layer is incapable of composing functions if the domains of the functions are large enough. This work could also be seen as rigorous evidence about the hallucinations of LLMs since function composition is a fundamental task for reasoning \citepguan2024mitigating. The work of \citetxu2024hallucination is also studying hallucinations of LLMs. They define hallucination as a failure to identify the target function which belongs to an uncountable collection of functions. This is significantly stronger than the definition we and prior works \citepkalai2024calibrated,kleinberg2024language have considered (making their impossibility results significantly easier to prove). Their main result is that all LLMs must hallucinate. This is easy to see: consider an LLM learning to predict the next element in a sequence of 0s and 1s, after observing only a finite prefix of the enumeration, it has no way of knowing the next element in the order (since they allow both continuations) and, hence, the target sequence cannot be identified. Finally, the work of \citetaithal2024understanding, which is mainly empirical, aims to explain hallucinations on the other important family of generative models, namely diffusion-based models, via mode interpolation which, in theory, relies on difficulties in approximating non-smooth parts of the score function. Language Learning. In our results, we make no implicit assumption about the architecture of our models; this is in accordance with the works of \citetsolomonoff1964formal,gold1967language,angluin1982inference,angluin1983inductive,angluin1988identifying,pitt1989probabilistic,kleinberg2024language. However, there are various works aiming at understanding language learning capabilities of specific architectures, e.g., \citephahn2020theoretical,elman1990finding,gers2001lstm,bhattamishra2020ability,hewitt2020rnns,merrill2019sequential,merrill2023parallelism,yao2021self,ebrahimi2020can. For instance, \citetliu2022transformers show that low-depth transformers can represent the computations of any finite-state automaton, while \citetsanford2024representational identify a particular mathematical problem that cannot be computed by single-layer multi-head transformers. The aforementioned works share some similarities with us in the sense that they focus on whether models can be trained to generate or recognize strings in a fixed formal language. \citetakyurek2024context study in-context language learning: the language model is prompted with a finite collection of strings from an unknown regular language (which changes across different tasks), and must infer the distribution over strings corresponding to the full language. In a similar spirit, \citetedelman2024evolution study in-context learning of Markov chains. Other related works are those of \citethahn2023theory,xie2021explanation that study conditions under which in-context learning can arise for language learning. \citet allen2023physics design context-free grammars and empirically study the consistent generation (accuracy) and breadth (diversity) of GPT models on these synthetic examples. In comparison to this work, we provide a theoretical treatment of the trade-off between consistency and breadth under a very abstract model, studied by \citetgold1967language,angluin1979finding,angluin1988identifying, kleinberg2024language. Our results indicate that, even in a very idealized framework, achieving (perfect) consistency and breadth is impossible. We view the empirical findings of \citetallen2023physics as an exciting indication that, in the real world (or more concretely in controlled experiments on “small” models and synthetic datasets), a balance between (imperfect) consistency and breadth is possible and modern LLMs can achieve it. Further understanding how much consistency and breadth one can achieve at the same time theoretically is an exciting direction. Finally, in a concurrent and independent work, \citetli2024generationlenslearningtheory also study language generation, interpreting it in a learning-theoretic setting reminiscent of the PAC framework and the online learning setting of \citetlittlestone1988learning. They propose “non-uniform generatability” – which relaxes “uniform generatability” \citepkleinberg2024language – and characterize the collections for which uniform and non-uniform generatability are achievable in the Gold-Angluin model; in particular, unlike \citetkleinberg2024language they also allow the collection \euscr{L} to contain uncountably many languages. These dimensions are analogs to the Littlestone dimension (and its extension to the non-uniform setting \citeplu2023non), which only holds for finite collections of languages. Moreover, they show the proposed dimension is incomparable to the VC dimension. Finally, they give analogous characterizations in the “prompted generation” setting, extending some of the results of \citetkleinberg2024language. Our work is orthogonal to theirs: first, we study trade-offs between generating with and without breadth – both in a statistical setting and the Gold-Angluin model – and, second, we study the “learning curves” for generation and identification in the framework of \citetbousquet2021theory. Probably Eventually Correct Learning. As we mentioned Gold’s model is a predecessor of the famous PAC model of \citetvapnik2013nature and \citetvaliant1984theory. A natural question is whether there is a conceptual meeting point for the two works. Is there a notion of “PAC learning in the limit?” The answer to this question is affirmative and comes from the field of algorithmic stability (see e.g., \citepalon2022private,moran2023bayesian,kalavasis2023statistical,bun2023stability,chase2023stability and the references therein), studied in the context of binary classification \citepmalliaris2022unstable. \citet malliaris2022unstable introduce the Probably Eventually Correct (PEC) model of learning. Here we fix a collection \euscr{L}=\{L_{1},L_{2},\dots\} of languages and a distribution \euscr{P} over positive and negative labeled examples (in contrast to the standard identification setting of Gold). PEC learning focuses on distributions \euscr{P} realizable by the collection \euscr{L} in the sense of \citetbousquet2021theory (see Section D). An algorithm is said to PEC learn \euscr{L} if for any realizable distribution \euscr{P}, with probability 1 over i.i.d. samples \left\{(x_{i},y_{i})\colon i\in\mathbb{N}\right\} drawn from \euscr{P}, there exists time t^{*}\in\mathbb{N} such that for all t\geq t^{*}, given \left\{(x_{i},y_{i})\colon 1\leq i\leq t\right\}, the algorithm outputs an L_{t}\in\euscr{L} such that \Pr_{(x,y)\sim\euscr{P}}[L_{t}(x)\neq y]=0\,. Malliaris and Moran give a combinatorial characterization of the collections of languages that are PEC learnable: a collection of languages \euscr{L} is PEC learnable if and only if it does not shatter an infinite Littlestone tree. We stress that, when the learner has access to positive and negative examples, the absence of an infinite Littlestone tree does not characterize identification in our setting. This is in stark contrast with binary classification. In particular, in Section D, we show that there exists a set of languages that have an infinite Littlestone tree, hence not learnable in the online setting of \citetbousquet2021theory, but it allows for identification in the limit with positive and negative examples. In fact, the collection we use in Example 3 is identifiable in the limit even with just positive examples. This already sets the stage for a starkly different landscape of optimal learning rates between the setting of \citetbousquet2021theory and \citetangluin1988identifying, as we will see in Section 3.1. As we said before, the online model of \citetgold1967language and the classical online setting of \citetlittlestone1988learning have various differences. \citetlu2023non studies non-uniform online learning in order to bridge the gaps between the inductive inference model of \citetgold1967language and classical online learning. In this setting, the adversary is oblivious and fixes the true language K in advance (as in Gold’s model). At each round, an example from K is revealed, the learner makes a prediction but then she observes feedback. The model is non-uniform in the sense that the mistake bound depends on K. Learning from Positive Examples. Learning from positive examples occurs very frequently in real-world applications and has been extensively studied. A lot of work has been done on learning from positive examples in Gold’s model of learning in the limit \citepgold1967language,angluin1980inductive,angluin1988identifying,berwick1986learning,shinohara1989inductive,zeugmann2005guided. Apart from that, an extension of Valiant’s PAC model has been also studied \citepnatarajan1987learning,denis1998pac. \citetnatarajan1987learning considered the setting where the learner only has access to positive examples and showed that even very simple classes such as halfspaces in two dimensions are not learnable from positive examples alone. \citetdenis1998pac relaxed this requirement: they study a setting where the learner has access to both positively labeled examples but also to unlabeled examples \citepdenis2005learning. At the heart of virtually all of the results in this line of work is the use of unlabeled samples in order to generate negative examples. When the original distribution is uniform, better algorithms are known: \citetde2014learning gave efficient learning algorithms for DNFs and LTFs, \citetfrieze1996learning,anderson2013efficient gave efficient learning algorithms for learning d-dimensional simplices. On the other side, \citeteldan2011polynomial,goyal2009learning give lower bounds for learning with positive examples. Recently, interest in learning from positive examples has sparked from work on truncated statistics (e.g., \citepdaskalakis2018efficient,daskalakis2019computationally,Kontonis2019EfficientTS,fotakis2020efficient,daskalakis2021statistical,de2023testing,de2024detecting,plevrakis2021learning,de2024detecting,diakonikolas2024statistical,lee2024efficient). \citetKontonis2019EfficientTS show how to learn concept classes of bounded Gaussian surface area from positive Gaussian examples and \citetlee2024efficient generalize this to show how to learn concept classes approximable by polynomials in the L_{2}-norm from positive examples. However, all these works focus on computationally efficient learning/testing while we focus on statistical consistency of identification and generation without any restrictions on computation time."
https://arxiv.org/html/2411.09473v1,Sample Paper Title,"Influence Maximization (IM) is vital in viral marketing and biological network analysis for identifying key influencers. Given its NP-hard nature, approximate solutions are employed. This paper addresses scalability challenges in scale-out shared memory system by focusing on the state-of-the-art Influence Maximization via Martingales (IMM) benchmark. To enhance the work efficiency of the current IMM implementation, we propose EfficientIMM with key strategies, including new parallelization scheme, NUMA-aware memory usage, dynamic load balancing and fine-grained adaptive data structures. Benchmarking on a 128-core CPU system with 8 NUMA nodes, EfficientIMM demonstrated significant performance improvements, achieving an average 5.9x speedup over Ripples across 8 diverse SNAP datasets, when compared to the best execution times of the original Ripples framework. Additionally, on the Youtube graph, EfficientIMM demonstrates a better memory access pattern with 357.4x reduction in L1+L2 cache misses as compared to Ripples.","The advent of large-scale data and advanced computational frameworks has significantly deepened our exploration of social networks, positioning Influence Maximization (IM) as a pivotal research area. This research domain aims to identify the most influential nodes within a network, optimizing the spread of information, behaviors, or products. These insights are invaluable not only for marketing and public health initiatives but also for enhancing our understanding of the complex dynamics of human interaction and information dissemination across vast networks [3, 6, 15]. The IM problem is formally delineated within the framework of graph theory. In brief, the goal of influence maximization is to be capable of identifying a subset of the most influential vertices in an input graph. The challenge inherent to the IM problem arises from its NP-hard nature, indicating the absence of a deterministic polynomial-time algorithm capable of deriving the optimal solution [5]. Therefore, it has prompted the development of numerous approximation algorithms. As a sketch-based approximation algorithm, Influence Maximization via Martingales (IMM) is renowned for its robust efficiency and broad adaptability, making it ideal for large-scale social networks [7]. As first introduced by Tang et al. [13], IMM employs advanced sampling techniques known as Reverse Influence Sampling (RIS) to generate sketches known as random reverse reachable sets or RRRsets for the input graph. To guarantee the quality of the sampled sketches, IMM utilizes martingale probability theory, which also ensures the linear time-to-solution cost corresponding to the increasing graph size [13]. Recognizing the growing significance and potential of IMM, it has been identified as a key workflow for further development and research. Significant efforts have been made to adapt IMM for handling different large-scale data inputs [11, 9, 8]. We focused on Ripples, a widely adopted open-source IMM framework, particularly suited to the complex and large-scale structure of modern social networks [9]. One of the primary challenges posed by Ripples is algorithm’s inability to scale effectively on the latest shared memory server-grade CPUs with multi-NUMA and multi-socket architecture. The system used for evaluation in the original Ripples paper, as described by Minutoli et al. [9], consists of a CPU with 10 cores, shared memory and cache spaces, and no NUMA control. Given the trend of shifting to a CPU system with many more NUMA nodes and also the increasing interest of designing scale-out shared memory system, many important benchmarks and frameworks have been adapted into this trend in system [16]. Therefore, it is crucial for us to strive for better performance on Ripples targeting the multi-NUMA systems. With our assessments of the Ripples algorithm across a variety of datasets on a multi-NUMA CPU system, we have pinpointed several critical limitations that hinder its performance: (i) The parallelization strategy employed for RIS sketches demonstrates suboptimal scalability across all CPU workers, (ii) excessive data access coupled with poor data locality, (iii) workload imbalance resulted from several aspects of graph processing. To address these challenges, this paper first analyzes social graphs and identifies features that impede the scalability of the algorithm. Then, this work introduces a new parallelization strategy that improves scalability far beyond what the current Ripples framework achieves. In addition to the parallelization strategy, we also redesigned the IMM algorithm for NUMA-awareness and employed optimizations based on fundamental characteristics of social graphs. This paper makes several contributions to the field of IMM, outlined as follows: • We conduct a comprehensive profiling of the current state-of-the-art solutions for the IMM problem with various contexts of the social graphs, pinpointing critical bottlenecks that necessitate optimization. • We introduce a new shared-memory partitioning and distribution strategy that greatly enhances the efficiency of constructing the influence counts for each vertices based on the sampled RIS sketches through concurrent updates. Using the new parallelization technique, we further adapted the algorithm with NUMA-aware data structures and greatly improved data reuse. • We have developed optimization techniques to address workload imbalances arising from the varying attributes of different graphs, including adaptive data structures and dynamic job balancing strategies. • We applied these optimizations to eight selected SNAP datasets, achieving an impressive performance speedup ranging from 1.6 to 12.1 times compare to Ripples’ best runtime. Also, our work efficient algorithm also brings 22.4x to 357.4x less L1+L2 cache misses as compared to Ripples."
https://arxiv.org/html/2411.09117v1,Efficiently learning and sampling multimodal distributions with data-based initialization,"We consider the problem of sampling a multimodal distribution with a Markov chain given a small number of samples from the stationary measure. Although mixing can be arbitrarily slow, we show that if the Markov chain has a kth order spectral gap, initialization from a set of \tilde{O}(k/\varepsilon^{2}) samples from the stationary distribution will, with high probability over the samples, efficiently generate a sample whose conditional law is \varepsilon-close in TV distance to the stationary measure. In particular, this applies to mixtures of k distributions satisfying a Poincaré inequality, with faster convergence when they satisfy a log-Sobolev inequality. Our bounds are stable to perturbations to the Markov chain, and in particular work for Langevin diffusion over \mathbb{R}^{d} with score estimation error, as well as Glauber dynamics combined with approximation error from pseudolikelihood estimation. This justifies the success of data-based initialization for score matching methods despite slow mixing for the data distribution, and improves and generalizes the results of [koehler2023sampling] to have linear, rather than exponential, dependence on k and apply to arbitrary semigroups. As a consequence of our results, we show for the first time that a natural class of low-complexity Ising measures can be efficiently learned from samples.","Since its introduction in 1953 by \textcitemetropolis1953equation, Markov-Chain Monte Carlo (MCMC) has become the one of the dominant approaches to sampling and integration of high-dimensional distributions in Bayesian statistics, computational physics, biostatistics, astronomy, machine learning, and many other areas. Typically, in MCMC we sample from a distribution of interest by simulating a Markov chain which converges to the correct stationary measure. One of the key mathematical questions concerning a Markov chain is its mixing time—how quickly does the process forget its initialization and converge to stationarity? While some Markov chains rapidly mix to their stationary distributions, it is well-known that in many other cases, the existence of “bottlenecks” (i.e., sparse cuts) between modes leads to slow or “torpid” mixing, oftentimes exponential in the dimension of the problem. In general, whenever the distribution of interest is supported on multiple well-separated clusters or modes, standard MCMC methods like Metropolis-Hastings, Langevin dyamics, Glauber dynamics, and so on which make “local” moves will get stuck in the first cluster they reach. This phenomena is often referred to as metastability in the literature [gayrard2004metastability, gayrard2005metastability]. A large body of research in MCMC, both in theory and practice, is on developing ways to overcome this difficulty. For example, popular methods such as simulated tempering [marinari1992simulated] and parallel tempering [swendsen1986replica] attempt to improve connectivity by varying the temperature of the system. In other situations, alternative Markov chains can be constructed which are able to cross between the modes — for example, the celebrated Swendsen-Wang dynamics [swendsen1987nonuniversal] which are provably able to sample from the ferromagnetic Ising model at all temperatures in polynomial time [jerrum1993polynomial, guo2017random]. In other cases, the sampling problem is provably hard (see e.g. [sly2012computational, galanis2016inapproximability]) so no computationally efficient Markov chain could possibly mix rapidly to the stationary measure unless \mathsf{P}=\mathsf{NP}. Hence, sampling can be computationally intractable in general. However, many cases where standard Markov chains are known to fail actually correspond to very simple distributions. For example, even a simple mixture of two well-separated Gaussians leads to exponentially large mixing time for the Langevin dynamics (in the separation distance). Previous work in MCMC theory has studied in depth some of these failure cases (e.g. in the Curie-Weiss model, see related work below) and developed specialized solutions to resolve the mixing time issue in a particular setting. We might hope that a more general approach can resolve the difficulty with multimodality for a large class of models. Our contribution. In this work, we develop general tools to analyze MCMC chains in multimodal situations. Analogous to the role of the spectral gap in the unimodal setting, the key mathematical object in our theory is the higher-order spectral gap of the transition matrix or generator of a Markov process. Looking at such a notion of gap is very natural from the perspective of higher-order analogues of Cheeger’s inequality [lee2014multiway, louis2012many, gharan2014partitioning, Miclo2014OnHA]. These results roughly tell us that if the vertices of a graph can be separated into a small number of well-connected parts whose boundaries are sparse cuts, then there has to be a corresponding gap in the spectrum of the Laplacian after a small number of eigenvalues, and vice versa. When we have only a higher-order, rather than standard, spectral gap, we cannot hope for rapid mixing of the dynamics from an arbitrary initialization. However, in some applications there is a natural candidate for a warm start for the dynamics. In particular, in the application of density estimation or generative modeling, a distribution is learned from access to samples from the ground truth distribution. In these settings, samples from the ground truth are available, which naturally suggests the idea of data-based initialization — starting the dynamics from the empirical measure. The idea of data-based initialization has appeared in the empirical machine learning literature in many different forms, for example as a part of the mechanics of “contrastive divergence” training for energy-based methods and other approximations to Maximum Likelihood Estimation. For a few related references in the empirical literature, see [hinton2002training, xie2016theory, gao2018learning, nijkamp2019learning, nijkamp2020anatomy, wenliang2019learning], and see also [koehler2023sampling] for more discussion. In particular, the terminology of “data-based initialization” is as used in [nijkamp2020anatomy]. Intuitively, if the underlying distribution is a mixture distribution, then each mixture component will have a roughly proportional representation in the samples from the empirical measure, so we might hope that the dynamics run for a polynomial amount of time can actually recover the ground truth distribution. A direct analysis along these lines was done in [koehler2023sampling] in the case of a mixture of strongly log-concave distributions; however, handling the behavior of overlapping clusters complicated the analysis and ultimately led to a poor (exponential) dependence on the number of clusters or mixture components in the distribution. From here on, we revisit the analysis of data-based initialization from the spectral perspective. This yields a much more elegant proof with dramatically improved quantitative dependencies. Our approach applies to general Markov semigroups, and in particular lets us prove new results for the Glauber dynamics as well as the Langevin dynamics. We also can easily obtain natural extensions of our results, such as more rapid mixing under a component-wise log-Sobolev inequality. Crucially for density estimation applications, we also show that our results are robust to perturbations in the Markov chain, which is very important when the chain transitions are themselves estimated from data. The quantitative improvements in this theory are key to an illustrative new application—a new result for learning a class of Ising models well beyond the regime where previous approaches were known to succeed. 1.1 Main results The heart of this work in the following theorem which holds in a very general setting—it applies to all Markov semigroups, and shows that a higher-order spectral gap implies rapid mixing from data-based initialization. Theorem (Theorem 8, simplified). Let P_{t}=e^{t\mathscr{L}} be a reversible Markov semigroup with self-adjoint generator \mathscr{L} and stationary measure \pi defined over \mathcal{D}. Suppose that the generator satisfies \lambda_{k+1}(-\mathscr{L})\geq\alpha and there are constants t_{0},R such that \left(\text{warm start after time $t_{0}$}\right)\quad\forall y\in\mathcal{D},% \quad\chi^{2}(\delta_{y}P_{t_{0}}\|\pi)\leq R. Let \mu_{0}=\frac{1}{n}\sum_{j=1}^{n}\delta_{Y_{j}} where Y_{1},\ldots,Y_{n}\sim\pi are independent samples, and define \mu_{t}=\mu_{0}P_{t}. Then with probability \geq 1-\delta, for n=\Omega\left({\frac{k}{\varepsilon_{\textup{TV}}^{2}}\ln\left({\frac{k}{% \delta}}\right)}\right) and t\geq t_{0}+\frac{1}{\alpha}\ln\left({\frac{4R}{\varepsilon_{\textup{TV}}^{2}}% }\right), we have \operatorname{TV}(\mu_{t},\pi)\leq\varepsilon_{\textup{TV}}. In fact, we only need a weaker version of the warm-start condition, which is important in some applications—see Theorem 8 and Theorem 15 for the more general result. A higher-order spectral gap is easy to show for Glauber or Langevin dynamics if our distribution is a mixture of well-connected components—see Lemma 9. Langevin dynamics on mixtures. Our first application is to Langevin dynamics on mixture distributions. In this application, we include a perturbation analysis which shows that an L_{2} approximate score function suffices for sampling—this is important if the score function is learned from data via score matching (see e.g. [hyvarinen2005estimation]). Theorem (Langevin with score matching, Theorem 25, Theorem 29, simplified). Assume \pi=\sum_{i=1}^{k}p_{i}\pi_{i}, where \pi_{i} are O(1)-smooth and the means of the \pi_{i} are at distance \lesssim\sqrt{d}. Suppose that the approximate score function s satisfies \mathbb{E}_{\pi}\left\|{s-\nabla\ln\pi}\right\|^{2}\leq\varepsilon_{\textup{% score}}^{2}. Let \mu_{0}=\frac{1}{n}\sum_{j=1}^{n}\delta_{Y_{j}}, where Y_{1},\ldots,Y_{n}\sim\pi are independent samples, and suppose n=\Omega\left({\frac{k\ln(k/\delta)}{\varepsilon_{\textup{TV}}^{2}}}\right). Let (\bar{X}_{t})_{t} be the continuous Langevin diffusion wrt \pi initialized at \mu_{0} and driven by s, so it satisfies the SDE d\bar{X}_{t}=s(\bar{X}_{t})dt+\sqrt{2}\,dW_{t} for an independent Brownian motion W_{t}, and \bar{X}_{0}\sim\mu_{0}. Let \mu_{t} be the law of \bar{X}_{t} conditioned on the empirical samples Y_{1},\dots,Y_{n}, i.e., \mu_{t}=\mathcal{L}(\bar{X}_{t}|Y_{1},\dots,Y_{n}). Suppose that either: 1. Each \pi_{i} satisfies a Poincaré inequality with constant \leq\frac{1}{\alpha}, and T=\Omega\left({\frac{1}{\alpha}\left({d+\ln\left({\frac{k}{\varepsilon_{% \textup{TV}}}}\right)^{2}}\right)}\right). 2. Each \pi_{i} satisfies a log-Sobolev inequality with constant \leq\frac{1}{\alpha}, and T=\Omega\left({\frac{1}{\alpha}\ln\left({\frac{dk}{\varepsilon_{\textup{TV}}}}% \right)}\right). Then with probability at least 1-\delta over the randomness of Y_{1},\ldots,Y_{n}, \operatorname{TV}(\mu_{T},\pi)\leq\sqrt{T}\varepsilon_{\textup{score}}+% \varepsilon_{\textup{TV}} The above result is stated for the continuous-time Langevin diffusion, but we also prove a version of this result for its discrete-time analogue, Langevin Monte Carlo Theorem 30. We note there are previous results that quantify mixing up to multimodality in the distribution (e.g., [balasubramanian2022towards] for convergence in Fisher information for averaged LMC, or [tzen2018local, zhang2017hitting]); our innovation is to show that data-based initialization can lead to the much stronger condition of mixing. This is analogous to the difference between finding a stationary point vs. a global optimum in nonconvex optimization. Remark 1 (Matching sample complexity lower bound). It is a classical fact that \Theta(k/\varepsilon_{\textup{TV}}^{2}) samples are needed to learn a distribution on the alphabet \{1,\ldots,k\} within total variation distance \varepsilon_{\textup{TV}} (see e.g. [han2015minimax] for references). This is a special case of our problem: it corresponds to the case where \pi is a mixture of k known components with disjoint support where only the mixing weights are unknown. (Note that the score function in this case does not depend on the mixing weights.) Thus, the dependence on n in both of the previous theorems is optimal up to the \log factor in k. Remark 2 (Using score matching in Gaussian mixture models). Recent works [chen2024learning, gatmiry2024learning] show how to learn a mixture of well-conditioned Gaussians from samples using a computationally efficient score matching approach. The key step is to show that the score function of such a distribution can be well-approximated using a piecewise-polynomial function, which can be efficiently estimated from data. Because mixtures of Gaussians are closed under convolution with noise, this implies that they can use the learned score functions at different noise levels to approximately sample via a denoising diffusion process (see e.g. [benton2023linear, chen2023improved] and references therein). Since they show that the score function can be accurately estimated from samples (at least for a slightly noised version of the distribution, which is close in TV—see Proposition 2.1 and the proof of Theorem 4.1 in [chen2023improved]), their score function estimate could be combined with our method (data-based initialization of the vanilla Langevin dynamics) to give an alternative and arguably simpler algorithm. Glauber dynamics and an application to learning. A similar result to Theorem 29 holds for Glauber dynamics (see Lemma 19)—in this context, we also show that the dynamics are robust to a small error in the KL divergence, which would occur if we estimate the dynamics via pseudolikelihood estimation [besag1975statistical]. Pseudolikelihood is a very classical and popular method, and the exact analogue of score matching for Glauber—see [hyvarinen2007connections, koehler2022statistical] for more discussion. As a concrete end-to-end application of the result for Glauber dynamics, we prove a new theorem about learning a large class of Ising models: those which are in some sense low complexity or approximately low rank. This class of models has been extensively studied in probability theory due to its connection to mean-field approximation—see the discussion of related work below. As we discuss therein, this class of models is well outside of the realm where previous learning results (e.g. [wu2019sparse, gaitonde2024unified]) can be applied. Theorem (Learning approximate low-rank Ising models, Theorem 39, simplified). Suppose \pi is an Ising model, i.e. a probability measure on \{\pm 1\}^{n} satisfying \pi(x)\propto\exp\left(\frac{1}{2}\langle x,Jx\rangle+\langle h,x\rangle\right) for some symmetric interaction matrix J\in\mathbb{R}^{n\times n} and external field vector h\in\mathbb{R}^{n}. Suppose J has eigenvalues (ordered from the largest) \lambda_{1}\geq\cdots\lambda_{r}>1-\frac{1}{c}\geq\lambda_{r+1}\geq\cdots\geq% \lambda_{n}, for a constant c>1 and -\sum_{j:\lambda_{j}<0}\lambda_{j}=O(1). Given (nr\lambda_{1})^{O(r)}/\varepsilon_{\textup{TV}}^{4} samples from \pi_{J,h}, with high probability over the samples, the distribution output pseudolikelihood estimation and Glauber dynamics from data-based initialization is within TV error \varepsilon_{\textup{TV}} of \pi_{J,h}. See the full statement of the theorem for more details and the precise definition of pseudolikelihood estimation. 1.2 Other related work Learning Markov random fields from samples. There have been too many works on learning Markov random fields from samples to give an exhaustive list, so we instead summarize some of the most recent and directly relevant works. Information-theoretically, it is known that density estimation of Ising models in TV distance can be done with polynomial dependence on the dimension n and target accuracy \epsilon [devroye2020minimax]. However, all existing results for learning Ising models with computationally efficient algorithms, which typically use some variant of pseudolikelihood estimation and include works such as [ravikumar2010high, lokhov2018optimal, bresler2017learning, klivans2017learning, wu2019sparse, gaitonde2024unified], either restrict the model to be in a high-temperature regime, or have an exponential dependence on some parameter in the sample complexity—typically the maximum \ell_{1}-norm of any row of the interaction matrix. In many examples this \ell_{1}-norm is polynomial in the dimension (see e.g. [anari2024universality, gaitonde2024unified] for more discussion), and it is always linear in the “inverse temperature” \beta of the system. So in particular, all of these results have an exponential dependence on \beta. In contrast, our result has polynomial dependence on these parameters when the interaction matrix is (approximately) low rank. See Remark 40 for a much more detailed discussion of the limitations of previous techniques. Tempering and annealing on multimodal distributions. The empirical community has developed many algorithms for sampling from multimodal distributions. This includes tempering methods such as simulated tempering [marinari1992simulated] and parallel tempering [swendsen1986replica], which involve constructing a Markov chain which varies the temperature of the system, as well as annealing or sequential methods such as sequential Monte Carlo [liu1998sequential] and annealed importance sampling [neal2001annealed], which vary the temperature unidirectionally over time. Efficient theoretical guarantees are known only in special cases; a necessary condition for all known results is that the distribution is decomposable into parts which are not too imbalanced (do not have a bottleneck) between different temperatures. For simulated tempering, these results can be used to show that simulated tempering with Langevin dynamics can sample from an isotropic mixture of Gaussians (or more generally, translates of a fixed log-concave distribution) [ge2018beyond, ge2018simulated]. A version of simulated tempering was also used in [koehler2022sampling] to sample from multimodal Ising models. There are analogous results for sampling from multimodal distributions under stronger assumptions for parallel tempering [woodard2009conditions, lee2023improved] and sequential Monte Carlo [schweizer2012nonasymptotic, paulin2018error, mathews2022finite, lee2024convergence]. However, even simple multimodal distributions can violate the condition of balance between temperatures and cause sampling to be provably hard. In particular, [ge2018simulated, Appendix F] show an exponential query complexity lower bound for sampling from a L^{\infty}-perturbed mixture of two Gaussians with different covariances. Here, the key difficulty in their setting is finding the components, whereas our results apply without issue. Simulated tempering also fails for the mean-field Potts models [bhatnagar2004torpid] (whereas our method will succeed, see Theorem 38). The problem of sampling from multimodal distributions given warm starts to the different modes has also been considered, for which the Annealed Leap Point Sampler [tawn2021annealed, Roberts_Rosenthal_Tawn_2022] has been proposed. We note this is a weaker notion of “advice” than ours, and guarantees have only been given in a limit where the components are approximately Gaussian. Glauber dynamics in multimodal/metastable settings. There has been a lot of work on understanding the behavior of Glauber dynamics with respect to metastability in spin systems, especially for complete graph models, random graphs, and the square lattice. See e.g. [gheissari2022low, blanca2024mean, bovier2021metastability, cuff2012glauber, levin2010glauber, ding2009censored, ding2009mixing, galanis2024planting] for rigorous results. For the most part, this literature focuses on settings where there are a small number of metastable states which can be explicitly characterized, often taking advantage of symmetry considerations. For example, when the Ising model has no external field, it is symmetric under interchange of + and -, so initializations like (1/2)(\delta_{\vec{1}}+\delta_{-\vec{1}}) are natural and have been studied in some of the aforementioned works. Generally speaking, our results hold in a general setting and do not rely on any structure of the underlying distribution besides the higher-order eigenvalue gap, but unlike those works we do not obtain explicit characterizations of the metastable states. In Section 7, we show how to combine our general technique with results from this literature in the case of the Curie-Weiss model, which lets us make more precise statements about the spectrum of the generator and mixing from non-data-based initialization. Learning from dynamics. There have also been recent works on learning a distribution from the Glauber dynamics, rather than from i.i.d. samples. For example, see [bresler2017learning, gaitonde2024efficiently]. The work [jayakumar2024discrete] is in spirit closely related—they study learning the Ising model when given i.i.d. samples from a metastable state (i.e. a region where Glauber dynamics becomes trapped for a long time). These results do not have new implications for the i.i.d. setting we study, but combining the ideas from our work with this setting may be an interesting direction for future work. Low-complexity Ising models. The class of Ising models which are close to being low rank is significant, because informally these are the models for which the “naive mean-field approximation” from statistical physics is appropriate. (Naive mean field is, generally speaking, the most common type of variational approximation when doing variational inference in practice. See e.g. [wainwright2008graphical] for some background.) One significance of this class of models is that it includes models in all of the high temperature, critical temperature, and low temperature regimes, and in particular many settings where the mixing time of natural Markov chains are exponential in the dimension due to multimodality or metastability. There have been many works in probability theory studying the structural properties of this class of models and generalizations—see e.g. [basak2017universality, eldan2018gaussian, eldan2018decomposition, jain2019mean, austin2019structure, augeri2021transportation]. As in [koehler2022sampling], the class of models we consider for learning are somewhat broader, in that we allow the bulk of the spectrum to have diameter at most 1 instead of requiring the bulk to be asymptotically negligible; this means the class also includes some models where naive mean field approximation is highly inaccurate (e.g. sparse models and spin glasses at high temperature). Theory for score matching. There has been a lot of recent work on score matching, diffusion models, and related topics which we cannot exhaustively survey; instead, we mention a few relevant works. Denoising diffusion models are a popular approach to generative modeling which use approximations to the score function of the distribution convolved with different levels of Gaussian noise; recent works showed that these methods are robust to L_{2}-approximation of the score function (see e.g. [chen2023sampling, chen2023improved, benton2023linear] and references within). The method we study is different in that only the original (“vanilla”) score function is needed; see [koehler2023sampling] for more discussion. One of the motivations for score matching is that it can be easier to compute than the maximum likelihood estimator; for example, in some cases computing the MLE is NP-hard but vanilla score matching is statistically effective and computationally efficient [pabbaraju2024provable, hyvarinen2005estimation, hyvarinen2007connections]. When the vanilla score function is estimated from data, it turns out that data-based initialization is not only needed for computational reasons—if Langevin dynamics on the estimated score function is run to stationarity, then in many multimodal settings the resulting distribution will be a poor estimate of the ground truth [lee2022convergence, koehler2022statistical, balasubramanian2022towards]. If the distribution is unimodal, more specifically satisfies the log-Sobolev inequality, then the same work shows that vanilla score matching is statistically efficient even when Langevin is run to stationarity. Concurrent work. During the preparation of this manuscript, we were made aware of independent and concurrent work [huang2024weak] which also gives guarantees for sampling mixture distributions using Langevin with data-based initialization, with a different proof technique based on weak Poincaré inequalities. We note that their number of samples in the data-based initialization (see [huang2024weak, Theorem 5.1]) has \frac{1}{p_{*}} dependence on the minimum mixture weight p_{*}, while ours depends only on the number of components k. 1.3 Technical overview The proof of our main result, Theorem 8, is conceptually simple. We aim to prove that the process initialized at the empirical samples contracts in \chi^{2}-divergence, which corresponds to the contraction in L^{2}(\pi)-norm where \pi is the stationary distribution. When the Markov process has a higher order spectral gap, i.e., \lambda_{k+1}(-\mathscr{L})\geq\alpha where \mathscr{L} is the generator of the Markov process and \lambda_{k+1}(-\mathscr{L}) is the (k+1)-th smallest eigenvalue, this contraction holds for any function \phi which is orthogonal to the subspace V spanned by the eigenfunctions corresponding to the k smallest eigenvalues of -\mathscr{L}. The conclusion still holds if the projection of \phi to V has a sufficiently small norm, a condition we name eigenfunction balanced (see Definition 11). Hence, to prove rapid mixing from data-based initialization, we only need to show that the empirical distribution satisfies this condition. This is also the key technical challenge of our main result. For ease of presentation, we summarize our argument in the simpler finite-dimensional setting. We observe that when \phi corresponds to the empirical distribution, the expected projection111taken over the randomness of the empirical dataset is precisely zero, due to the orthogonality of the eigenfunctions/eigenvectors. Our task is thus to establish a strong (Chernoff-like) concentration bound for this projection norm. A key technical difficulty is that we do not have high moment bounds; we only have a second moment bound due to orthonormality. A second moment bound typically leads to a weaker concentration bound, where the number of samples n has linear dependency on the failure probability \delta, instead of the expected \log(1/\delta) dependency. For concreteness, let \pi be the stationary distribution of the Markov process and (f_{i})_{i=1}^{\infty} be an orthonormal basis of eigenvectors of -\mathscr{L} with eigenvalues \lambda_{1}=0\leq\lambda_{2}\leq\lambda_{3}\leq\cdots. Then for y\sim\pi \mathbb{E}_{y\sim\pi}[\langle\delta_{y},f_{1}\rangle_{L^{2}(\pi)}]=\mathbb{E}_% {y\sim\pi}[f_{i}(y)]=\langle f_{i},f_{1}\rangle_{L^{2}(\pi)}=0 since f_{1}\equiv 1. We can also bound the second moment of the projection by \mathbb{E}_{y\sim\pi}[\langle\delta_{y},f_{1}\rangle_{L^{2}(\pi)}^{2}]=\mathbb% {E}_{y\sim\pi}[f_{i}^{2}(y)]=\langle f_{i},f_{i}\rangle_{L^{2}(\pi)}=1. More generally, for \phi=\frac{1}{n}\sum_{i=1}^{n}\delta_{y_{i}} where y_{1},\cdots,y_{n}\sim\pi are i.i.d., \mathbb{E}_{y_{1},\dots,y_{n}\sim\pi\text{ i.i.d}}[\langle\phi,f_{1}\rangle_{L% ^{2}(\pi)}]=0\quad\text{and}\quad\mathbb{E}_{y_{1},\dots,y_{n}\sim\pi\text{ i.% i.d}}[\langle\phi,f_{1}\rangle_{L^{2}(\pi)}^{2}]=1/n. A naive application of standard concentration inequality such as Chebyshev’s inequality gives us the following \mathbb{P}_{y_{1},\cdots,y_{n}\sim\pi\text{ i.i.d.}}[|\langle\phi,f_{1}\rangle% _{L^{2}(\pi)}|\geq\varepsilon_{\textup{TV}}]\leq\delta when n\geq\frac{1}{\varepsilon_{\textup{TV}}^{2}\langle\phi,f_{1}\rangle_{L^{2}(\pi% )}^{2}}, which has sub-optimal dependency on \delta. We obtain an exponential improvement on the \delta-dependency by restricting the domain to those with bounded projection norm. We then show a strong concentration bound on this restricted domain using standard concentration inequalities for bounded random variables (Bernstein’s inequality). This implies that the process initialized at samples from the restricted domain is rapidly mixing. By an appropriate choice of parameters, we can ensure that most of the samples will be from the restricted domain, and thus the result followed from a standard comparison argument. An important case satisfying the higher-order spectral gap is when the stationary distribution \pi admits a decomposition into a mixture of distributions each satisfying a Poincaré inequality (see Lemma 9). For this case, our mixing time bound matches the state-of-the-art worst-case-start mixing for a single distribution satisfying the Poincaré inequality (see Theorem 25(1)). If we further assume that each component of the mixture satisfies the stronger log-Sobolev inequality, then using the hyper-contractivity argument from [lee2024convergence], we can obtain a tighter bound on the mixing time. For the continuous Langevin diffusion on mixtures of distributions satisfying log-Sobolev inequality, our mixing time bound has an optimal dependency on all parameters (see Theorem 29). Markov chain perturbation. In many applications, we suffer errors when implementing the Markov process. For example, we can only implement a discretization of the continuous Langevin diffusion, i.e., the Langevin Monte-Carlo. Furthermore, in learning problems, we might not have access to the chain transition probabilities but need to estimate them from data, e.g., using score matching or pseudolikelihood estimation. We show that our analysis is robust to such perturbations. In particular, we establish that data-based initialization is a natural and elegant way to exploit the guarantees on transition probabilities estimators learned from data, which is typically of the form \mathbb{E}_{x\sim\pi}[\text{dist}(\hat{u}(x),u(x))]\leq\varepsilon_{\textup{% score}} where \hat{u},u stand for the estimated and the true transition probabilities, respectively. A priori, it is unclear how to use such a guarantee in the initial stage of the Markov process when the distribution is very far from the stationary distribution \pi. Even when \pi has rapid convergence to stationarity from worst-case start, most previous works [lee2022convergence] can only handle such perturbation by assuming that the process is initialized at a a distribution \nu s.t. \chi^{2}(\nu||\mu) is small. However, the empirical distribution does not satisfy this condition. For example, if \pi a continuous distribution and \nu is the empirical distribution then \chi^{2}(\nu||\pi)=+\infty since \nu is discrete. If \pi is the uniform distribution over the hypercube \left\{\pm 1\right\}^{d} and \nu is the empirical distribution formed by n=o(2^{d}) samples, then \chi^{2}(\nu||\pi)=\Omega(2^{d}). Nevertheless, the empirical distribution is closely related to \pi in an average sense, and [koehler2023sampling] exploited this fact in their perturbation analysis; however, their analysis is lossy, incurring an extra \operatorname{poly}(1/\varepsilon_{\textup{TV}}) factor in the number of samples. In Theorem 20, we directly reduce the perturbation analysis from processes initialized at data samples to the perturbation analysis when initialized at the stationary distribution. Unlike [koehler2023sampling], we do not incur any loss in the number of samples (see Theorem 30). The key idea is to bound the expected TV distance between two processes X_{t} and \tilde{X}_{t} when initialized at a data-sample Y\sim\pi by the KL-divergence when initialized at the stationary distribution \pi by applying Jensen’s inequality, Pinsker’s inequality and the chain rule for KL-divergence. \displaystyle\mathbb{E}_{Y\sim\pi}[\operatorname{TV}(\mathcal{L}((X^{Y}_{t})_{% 0\leq t\leq T}),\mathcal{L}((\tilde{X}^{Y}_{t})_{0\leq t\leq T}))]\leq\sqrt{% \frac{1}{2}\operatorname{KL}(\mathcal{L}((X^{\pi}_{t})_{0\leq t\leq T})\|% \mathcal{L}((\tilde{X}^{\pi}_{t})_{0\leq t\leq T}))} We note that we can bound the second moment using a similar argument. We can then obtain a strong concentration bound using Bernstein’s inequality and the fact that \operatorname{TV}-distance is bounded by 1. Finally, we perform perturbation analysis for processes initialized at the stationary distribution. For continuous processes such as the Langevin diffusion with smooth stationary distribution, such a bound follows from the Girsanov’s theorem (see Lemma 17). In our application, the stationary distribution is not necessarily smooth, but is a mixture of smooth distributions satisfying a Poincaré inequality. In that case, we can establish quantitatively similar results using higher moment bounds implied by the Poincaré inequality on each component (see Lemma 18). For the Glauber dynamics, we derive a qualitatively similar result in Lemma 19 when the transition probabilities, i.e., the conditional marginals, are estimated using pseudo-likelihood. Application to low-complexity Ising models. The learning result follows from our general theory provided we can: (1) prove such a distribution has a higher-order spectral gap, and (2) estimate the needed Glauber transitions from data. For (1), we do this using a two-step argument; first, we use techniques from [koehler2022sampling] and a result from [anari2024trickle] to prove that such an Ising model can be approximately decomposed into a small mixture of rapidly mixing Ising models. Because our approximate decomposition has a density which is within a constant factor of the true model, we can boost this to an exact mixture decomposition into a mixture of Poincaré distributions by using the robustness of spectral gap to small changes of measure. For problem (2) of learning the transitions from data, this is exactly the problem solved by pseudolikelihood estimation, which we can analyze using standard symmetrization techniques from statistical learning theory. 1.4 Organization We cover the mathematical preliminaries in Section 2. Section 3 is devoted to the proof of our main result, Theorem 8. In Section 4, we show the robustness of Langevin and Glauber dynamics in our setting to perturbations in the dynamics. Section 5 covers the application of our theory to Langevin dynamics on mixtures, and Section 6 illustrates the application to Glauber dynamics for sampling and learning Ising models. Finally, in Section 7 we give some examples of non-sample initializations which also satisfy eigenfunction balance."
https://arxiv.org/html/2411.08987v1,Non-Euclidean High-Order Smooth Convex Optimization,"We develop algorithms for the optimization of convex objectives that have Hölder continuous q-th derivatives with respect to a p-norm by using a q-th order oracle, for p,q\geq 1. We can also optimize other structured functions. We do this by developing a non-Euclidean inexact accelerated proximal point method that makes use of an inexact uniformly convex regularizer. We also provide nearly matching lower bounds for any deterministic algorithm that interacts with the function via a local oracle.","In this work, we study the optimization of a general convex q-times differentiable function f whose q-th derivative is (L,\nu)-Hölder continuous with respect to \|\cdot\|_{p}, for p\in[1,\infty], that is, \|\nabla^{q}f(x)-\nabla^{q}f(y)\|_{p_{\ast}}\leq L\|x-y\|_{p}\text{ for all }x% ,y\in\mathbb{R}^{\hyperlink{def:dimension}{\normalcolor d}}, (1) where p_{\ast}\stackrel{{\scriptstyle\mathrm{\scriptscriptstyle def}}}{{=}}(1-1/p)^{% -1}, q\in\mathbb{Z}_{+} and \nu\in(0,1]. In this case, we say f is q-th order (L,\nu)-Hölder smooth. We make use of an oracle that returns all derivatives of f at a point up to order q. We also study the optimization of convex functions with a reduction to inexact p-norm ball optimization oracles. That is, using an oracle to approximately minimizing the function in balls of fixed radius with respecto to a p-norm, we minimize the function globally. The oracle can be implemented fast for some functions with structure. We note that (baes2009estimate) was the first work to develop (unaccelerated) general high-order methods under convexity and high-order smoothness, defined with respect to the Euclidean norm. (nesterov2021implementable) showed that choosing the right weight for the regularizer, the proximal subproblems appearing in (baes2009estimate) are convex. Previously, monteiro2013accelerated developed a general accelerated inexact proximal point algorithm, for which they achieved near optimal second-order oracle complexity for convex functions with a Lipschitz Hessian with respect to the Euclidean norm. Building on this framework, three works (gasnikov2019optimal; bubeck2019near; jiang2019optimal) independently achieved near optimal q-th order oracle complexity for high-order Euclidean smooth convex optimization. Later (kovalev2022first; carmon2022optimal) concurrently achieved optimal q-th order oracle complexity, up to constants, by improving over previous solutions by logarithmic factors, via two very different techniques. (song2019unified) studied the problem above in its full generality for functions with p-norm regularity, but they only solved the case where p<q+1, where q is the degree of the high-order oracle. Besides, their algorithm requires solving two different regularized Taylor expansions of the function with different regularization functions, and also a binary search per iteration. In this work, we propose an inexact accelerated proximal point algorithm that, by making use of an inexact uniformly convex regularizer and a q-th order oracle, it solves the problem for every p,q\geq 1, and does not need a binary search per iteration. We also provide lower bounds for any deterministic algorithm that interacts with a local oracle of the function. The upper and lower bounds match up to constant and logarithmic factors. Regarding lower bounds, arjevani2019oracle showed a lower bound for deterministic algorithms for convex functions with Lipschitz q-th derivatives with respect to the Euclidean norm, by providing a hard function in the form of a (q+1)-degree polynomial, which afterward the algorithms mentioned proved to be optimal. Later and independently, (agarwal2018lower) developed some suboptimal lower bounds by an interesting technique consisting of compounding randomized smoothing by repeated convolution of a hard convex Lipschitz instance resulting in a function with Lipschitz high-order derivatives. In this spirit and inspired by them, (garg2021nearoptimal) developed a nearly optimal lower bound via applying randomized smoothing to a construction similar to the classical Lipschitz instance consisting of a maximum of linear functions, but using the maximum of a variant of these functions via applying several softmax. They achieve, up to logarithmic factors, the lower bound in (arjevani2019oracle), but they also provide lower bounds for highly parallel randomized algorithms, and for quantum algorithms. To the best of our knowledge, before this work no lower bound was developed for the non-Euclidean convex q-th order Hölder smooth case, except for q=1. In this work, in the spirit of (garg2021nearoptimal), we construct lower bounds by composing a non-Euclidean randomized smoothing with a hard Lipschitz instance built as the maximum of softmax of an increasing sequence of linear functions. We firstly prove by the divergence theorem that if a function f is G-Lipschitz with respect to a p-norm, then the function that at each point x evaluates to the average of f in a p-norm ball of fixed radius is differentiable with Lipschitz gradient with respect to \|\cdot\|_{p}. Interestingly, our technique to construct a smoothing of a hard instance for the convex Lipschitz case to obtain a hard instance for the convex high-order smooth case works seamlessly for all values of p\in[1,\infty], whereas all previous non-Euclidean smoothing techniques, e.g. (guzman2015lower; paredes2015information; diakonikolas2020lower), would only work for p\geq 2. All existing lower bounds for smooth convex optimization with respect to \|\cdot\|_{p}, and p\in[1,2) had come from intricate reductions based on high-dimensional embeddings from the p=\infty case, even for deterministic algorithms in the first-order smooth case. In fact, it is known that the requirements for a local infimal convolution smoothing kernel are unattainable for p\in[1,2) without paying polynomial in the dimension factors (this is implicit in e.g. (aspremont2018optimal, Example 5.1)). However, our combination of composing a local randomized smoothing with the construction based on the softmax function circumvents this difficulty. We believe this technique will simplify current non-Euclidean lower-bound analyses and will become suitable for generalizations. Concurrent independent work. We note that the concurrent work (adil2024convex), independently showed primal convergence of an analogous accelerated non-Euclidean proximal algorithm. As opposed to them, we also introduced the notion of inexact uniformly convex regularizers and proved primal-dual convergence when we use such regularizers, as well as when we allow for the inexact implementation of the proximal oracles. (adil2024convex) also apply their framework to the optimization of non-Euclidean high-order smooth convex functions by exactly solving a regularized Taylor expansion of the function. However, we studied the more general q-order \nu-Hölder smooth case with respect to a p-norm and established the optimal or near-optimal convergence, by inexactly solving a regularized Taylor expansion, for all cases p\geq 1, q\geq 1, \nu\in(0,1], where the smooth case corresponds to \nu=1. The analysis of (adil2024convex) is limited to p\geq 2 and q+1\leq p, ."
https://arxiv.org/html/2411.08805v1,Stochastic Matching via In-n-Out Local Computation Algorithms,"Consider the following stochastic matching problem. We are given a known graph G=(V,E). An unknown subgraph G_{p}=(V,E_{p}) is realized where E_{p} includes every edge of E independently with some probability p\in(0,1]. The goal is to query a sparse subgraph H of G, such that the realized edges in H include an approximate maximum matching of G_{p}.This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets. For any fixed \varepsilon>0, [BDH STOC’20] showed that any graph G has a subgraph H with \mathrm{quasipoly}(1/p)=(1/p)^{\mathrm{poly}(\log(1/p))} maximum degree, achieving a (1-\varepsilon)-approximation. A major open question is the best approximation achievable with \mathrm{poly}(1/p)-degree subgraphs. A long line of work has progressively improved the approximation in the \mathrm{poly}(1/p)-degree regime from .5 [BDH+ EC’15] to .501 [AKL EC’17], .656 [BHFR SODA’19], .666 [AB SOSA’19], .731 [BBD SODA’22] (bipartite graphs), and most recently to .68 [DS ’24].In this work, we show that a \mathrm{poly}(1/p)-degree subgraph can obtain a (1-\varepsilon)-approximation for any desirably small fixed \varepsilon>0, achieving the best of both worlds.Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time. While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex). We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings.","We study the stochastic matching problem. This is a natural graph sparsification problem that has been studied extensively over the last decade [18, 6, 7, 29, 12, 15, 4, 13, 19, 16, 10, 17, 20] due to its various applications from kidney exchange [19] to online dating and labor markets [12]. Problem Definition: Given a graph G=(V,E) and a parameter p\in(0,1], let G_{p}=(V,E_{p}) be a random subgraph of G that includes each edge e\in E independently with probability p (we say e\in E is realized iff e\in E_{p}).111In this work, we solve a generalization of this problem where edges may have different realization probabilities. The goal is to select a subgraph H of G without knowing edge realizations such that (i) H is sparse, and (ii) the realized edges of H have as large of a matching as the realized edges of the whole graph G in expectation. Formally, using \mu(\cdot) to denote maximum matching size, we desire a sparse choice of H that achieves a large approximation ratio defined as: \operatorname{\textbf{E}}[\mu(H\cap G_{p})]/\operatorname{\textbf{E}}[\mu(G_{p% })]. Without the sparsity property (i), one can choose H=G and achieve an exact solution (i.e., approximation ratio 1) trivially. Another extreme solution is to take H to be a maximum matching of G which is extremely sparse, but this only achieves a p approximation as only p fraction of the matching is realized in expectation. A simple argument shows that to obtain any constant approximation (independent of p), subgraph H needs to have \Omega(1/p) average degree as otherwise most vertices in H\cap G_{p} will not have any edges and thus remain unmatched. But can we keep the degrees in H independent of the size of G, and obtain a good approximation? This is precisely the question studied in the literature of the stochastic matching problem. Motivation: This setting is motivated by applications where every edge of G has a chance of failure and detecting such failures—referred to as querying the edge—is time-consuming or costly. In such cases, instead of querying every edge in G, one can (non-adaptively) query the edges of a much sparser subgraph H and still identify a large matching. In kidney exchange, edges of G correspond to donor/patient pairs that are potentially eligible for a kidney transplant (some pairs can be ruled out based on available information such as blood types). But to fully verify the eligibility of an edge, one has to perform the costly operation of mixing the bloods of the donor/patient pairs. The stochastic matching problem can be used to minimize such operations while maximizing the number of kidney transplants. We refer interested readers to the paper of Blum et al. [19] for an extensive overview of this application of stochastic matching in kidney exchange. Prior Work: The stochastic matching problem is part of a broader class of problems that aim to sparsify graphs while preserving their various properties under random edge failures. Minimum spanning trees and matroids were studied by Goemans and Vondrák [24] in this exact setting more than two decades ago. Many other graph properties have been studied since then including minimum vertex cover [17], various packing problems [29, 25], and shortest paths metric problems such as Steiner tree and the traveling salesperson problem (TSP) [28]. The first work to study matchings in this setting was that of Blum et al. [18] who proved every graph G admits a subgraph H of maximum degree \mathrm{poly}(1/p), achieving a (1/2-\varepsilon) approximation for any fixed \varepsilon>0. The approximation was improved in a long and beautiful line of work which led to the discovery of many unexpected connections between stochastic matchings and other areas of TCS. In particular, after a sequence of works [6, 7, 15, 3], Assadi and Bernstein [3] showed that a (2/3-\varepsilon)-approximation can be obtained with a graph of maximum degree \mathrm{poly}(1/p), building on connections to dynamic graph algorithms. It was already observed by Assadi, Khanna, and Li [6] (see also [16]) that 2/3-approximation is a natural barrier for the problem based on a connection to Ruzsa-Szemerédi graphs, a problem in combinatorics which is now known to have applications across various subfields of TCS [23, 1, 11, 5, 9, 22]. This barrier was finally broken 5 years ago by Behnezhad, Derakhshan, and Hajiaghayi [16] who showed, building on a connection to distributed algorithms, that any graph G admits a subgraph H of maximum degree \mathrm{quasipoly}(1/p)=(1/p)^{\mathrm{poly}\log(1/p)} (but still independent of the size of G), achieving a (1-\varepsilon)-approximation for any fixed \varepsilon>0. See Table 1 for an overview of these bounds. To summarize, we know that any graph G admits a subgraph H of max-degree \mathrm{poly}(1/p) achieving a (2/3-\varepsilon)-approximation [3, 15], and one of maximum degree \mathrm{quasipoly}(1/p) achieving a (1-\varepsilon)-approximation [16] for any fixed \varepsilon>0. A major open problem of the area is: Does every graph G admit a \mathrm{poly}(1/p)-degree subgraph achieving a (1-\varepsilon)-approximation? More recently, [17, 20] made progress towards this open problem by showing that it is possible to break the 2/3-approximation with a \mathrm{poly}(1/p)-degree choice of H. The former obtains a .73-approximation provided that the graph is bipartite [17], and the latter obtains a .68-approximation for general graphs [20]. Nonetheless, the open problem above, and equivalently, the best approximation achievable with \mathrm{poly}(1/p) per-vertex queries remain wide open. In this paper, we answer the open question above affirmatively by proving the following. Result 1 (formalized as Theorem 1). For every fixed \varepsilon>0 and every p\in(0,1], every graph G has a subgraph H of maximum degree \mathrm{poly}(1/p) such that \operatorname{\textbf{E}}[\mu(H\cap G_{p})]\geq(1-\varepsilon)\cdot% \operatorname{\textbf{E}}[\mu(G_{p})]. Reference Approximation Degree Graph [18, 6] 1/2-\varepsilon \mathrm{poly}(1/p) General [7] .52 General [15] .65 General [3] 2/3-\varepsilon General [17] .73 Bipartite [20] .68 General [16] 1-\varepsilon \mathrm{quasipoly}(1/p)=(1/p)^{\mathrm{poly}\log(1/p)} General This Work 1-\varepsilon \mathrm{poly}(1/p) General Table 1: Overview of prior bounds. Here, \varepsilon>0 can be any arbitrarily small constant. In order to prove Result 1, we present a novel analysis of an extremely simple and elegant algorithm of the literature introduced first by Behnezhad, Farhadi, Hajiaghayi, and Reyhani [14] for constructing H. The algorithm (see Algorithm 1) draws \mathrm{poly}(1/p) independent realizations of the graph and picks an arbitrary maximum matching of each, then takes H to be the union of these matchings. It is clear from the construction that H will have \mathrm{poly}(1/p) maximum degree. It remains to prove that it obtains a (1-\varepsilon)-approximation. This is what our work focuses on. Our approximation analysis crucially relies on local computation algorithms (LCAs) introduced by Alon et al. [2] and Rubinfeld et al. [27], which we adapt to the stochastic matching problem for the first time. An LCA for a graph problem (e.g. graph coloring) does not return the whole output but rather provides an oracle that upon querying a vertex v, returns its part of the solution (say the color of v). While LCAs are typically used to solve problems on massive graphs, we use them merely for our approximation analysis and in an entirely different way, to bound correlation. Traditionally, the main measure of complexity for LCAs has been their out-queries, which is the number of vertices probed to produce the output of a given vertex. One of the main conceptual contributions of our work is to motivate the study of in-queries for LCAs as well. Informally, the in-query of a vertex v is the number of vertices u that probe v to produce their output (see Section 3.1 for formal definitions of in- and out-queries). In Section 2.1, we provide an overview of how LCAs with bounded in- and out-queries (which we call in-n-out LCAs for short) have limited correlation in their outputs. This limited correlation is crucial for our analysis and proving Result 1. We believe that the techniques we develop in studying in-n-out LCAs (particularly our generic results of Section 3.1) may find applications beyond the stochastic matching problem (see Section 3.4)."
https://arxiv.org/html/2411.08792v1,An alignment problem,"This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps. Here, we introduce the problem of optimally aligning k collections of m spatial supports over n spatial units in a d-dimensional Euclidean space. We show that the 1-dimensional case is solvable in time polynomial in k, m and n. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports. Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case.","This work concerns the problem of aligning collections of spatial supports which share a common set of spatial units. For example, Figures 1a and 1b each depicts a collection of four supports (green, yellow, orange, and blue) which shares a common set of 16 spatial units (rectangular blocks). The goal is to swap units from one support to another within each collection (change the colors of blocks) until the collections are identical, i.e., are aligned, as depicted in Figure 1c. Note that there are many different ways to align the supports, i.e., the alignment depicted in Figure 1c is not unique. With this in mind, it would be preferable to align such collections using the minimum number of (possibly weighted) swaps. This optimization problem is easy in some cases, and (NP-) hard in others. In general, the alignment problem is on a set U of n spatial units, each unit u\in U having a population count p(u) within a certain spatial boundary, disjoint from other units. These spatial units can represent census tracts or ZIP code tabulation areas. Constructing maps, e.g., choropleth maps, which reflect certain rates within a population, such as cancer incidence, provides an intuitive way to portray the geospatial patterns of such rates. This can provide decision support in public health surveillance, which can aid officials to form the appropriate policies. Building such a map at the level of an individual unit can produce misleading results due to small populations in some units, resulting in statistically unstable rates. To remedy this issue, sets s\subseteq U of contiguous units are aggregated to create larger spatial supports with adequate population counts to ensure a stable rate calculation, as depicted in Figure 1a. (a) (b) (c) Figure 1: Collections (a) \mathcal{S}=\{s_{1},s_{2},s_{3},s_{4}\} and (b) \mathcal{T}=\{t_{1},t_{2},t_{3},t_{4}\} of spatial supports over the set U=\{u_{1,1},u_{1,2},\dots,u_{4,4}\} of 16 spatial units. An alignment (c) of \mathcal{S} and \mathcal{T}. The red dots mark the units (u_{2,1},u_{3,1},u_{1,2},u_{2,2},u_{3,2},u_{2,3},u_{2,4}) on which \mathcal{S} and \mathcal{T} disagree. Suppose a certain rate, e.g., prostate cancer incidence, can be mostly explained by a factor such as age. In this case, we want to create several maps, which represent each age stratum in order to more clearly portray this factor in determining such rate. For the sake of illustration, suppose that \mathcal{S} and \mathcal{T}, depicted in Figures 1a and 1b are two such maps, represented as collections of supports over U. In \mathcal{S}, the populations p_{\mathcal{S}}(u) of each unit u in s_{1},s_{2},s_{3},s_{4} are 20, 20, 10, 15, respectively—e.g., p_{\mathcal{S}}(u_{1,1})=20 (u_{1,1}\in s_{1}), and p_{\mathcal{S}}(u_{4,4})=10 (u_{4,4}\in s_{3})—while the populations p_{\mathcal{T}}(u) of each unit u in t_{1},t_{2},t_{3},t_{4} are 15, 15, 12, 20, respectively. In this way, the total population in any support (of \mathcal{S} or \mathcal{T}) is 60. We want to consolidate the information across these maps onto a single map, however, and this requires to align their collections of supports. To align collections of supports is to modify the supports of all collections, in terms of the units they contain, such that the resulting supports remain contiguous, and the resulting collections are identical. This can be viewed as “swapping” units between neighboring supports until the desired alignment is reached. For example, Figure 1c depicts an alignment of collections \mathcal{S} and \mathcal{T}. Such an alignment is obtained from \mathcal{S} by swapping u_{1,2} and u_{2,2} from s_{4} (blue) to s_{1} (green), u_{2,3} from s_{3} (orange) to s_{1} (green), and u_{2,4} from s_{3} (orange) to s_{4} (blue). The alignment is obtained from \mathcal{T} by swapping u_{2,1} and u_{3,1} from t_{2} (yellow) to t_{1} (green), and u_{3,2} from t_{3} (orange) to t_{2} (yellow). Since any collection of contiguous supports—including supports that may not be currently present, e.g., a hypothetical s_{5}—is an alignment, it is desirable to produce an alignment that minimizes the maximum number of changes in any one collection. Since \mathcal{S} and \mathcal{T} disagree on 7 units (u_{2,1},u_{3,1},u_{1,2},u_{2,2},u_{3,2},u_{2,3},u_{2,4}, annotated with the red dots in Figure 1c), one collection must have at least 4 changes (the other collection having 3 changes), hence the alignment depicted in Figure 1c satisfies this criterion. This need to adjust leads to a notion of a distance, d(\mathcal{S},\mathcal{T}), between a pair \mathcal{S} and \mathcal{T} of collections of spatial supports, namely the number of swaps needed to transform \mathcal{S} into \mathcal{T}—this is simply the number of units on which the pair of collections disagree. Here, d(\mathcal{S},\mathcal{T})=7, and since an alignment is just another collection, if we denote the alignment of Figure 1c as collection \mathcal{A} of supports, then d(\mathcal{S},\mathcal{A})=4, and d(\mathcal{T},\mathcal{A})=3. Note that this distance is symmetric. The units of the different collections being swapped contain populations, however. Hence each swap has an associated cost, namely the population p_{\mathcal{C}}(u) of the unit u in the collection \mathcal{C} being swapped. For example, in \mathcal{S}, swapping u_{1,2} from s_{4} (blue) to s_{1} (green) costs p_{S}(u_{1,2})=15. This idea leads to a notion of a weighted distance d_{w}(\mathcal{S},\mathcal{A}) between a pair \mathcal{S} and \mathcal{A} of collections of spatial supports, or the overall cost of the swaps needed to transform \mathcal{S} into \mathcal{A}. Here, d_{w}(\mathcal{S},\mathcal{A})=p_{S}(u_{1,2})+p_{S}(u_{2,2})+p_{S}(u_{2,3})+p_% {S}(u_{2,4})=15+15+10+10=50, while d_{w}(\mathcal{T},\mathcal{A})=p_{T}(u_{2,1})+p_{T}(u_{3,1})+p_{T}(u_{3,2})=15% +15+12=42. Note that this weighted distance is not symmetric, i.e., d_{w}(\mathcal{S},\mathcal{T})\neq d_{w}(\mathcal{T},\mathcal{S}) in general. So, more precisely, it is desirable to produce an alignment \mathcal{A} that minimizes the maximum weighted distance d_{w}(\mathcal{C},\mathcal{A}) between any collection \mathcal{C} of spatial supports and \mathcal{A}. After careful inspection, no alignment can achieve such a weighted distance less than 50, hence the alignment depicted in Figure 1c satisfies this weighted criterion as well. We formalize the alignment problem as follows. Problem 1 (The Alignment Problem). Input: A base set U=\{u_{1},\dots,u_{n}\} of units over some Euclidean geospatial region and set \mathscr{C}=\{\mathcal{C}_{1},\dots,\mathcal{C}_{k}\} of collections of spatial supports. Each unit u\in U has population p_{\mathcal{C}}(u) from p_{\mathcal{C}}:U\rightarrow\mathbb{N}, specific to each collection \mathcal{C}\in\mathscr{C}. Each \mathcal{C}\in\mathscr{C} is a collection \{s_{\mathcal{C}}^{1},\dots s_{\mathcal{C}}^{m}\} of contiguous supports such that: (a) s\subseteq U for each s\in\mathcal{C}; (b) s\cap t=\emptyset for any pair s,t\in\mathcal{C} of distinct supports; and (c) \bigcup_{s\in\mathcal{C}}s=U. Output: A collection \mathcal{A} of contiguous supports which satisfies properties (a–c) above, such that \max\{d_{w}(\mathcal{C},\mathcal{A})~{}|~{}\mathcal{C}\in\mathscr{C}\} is minimized. Note that properties (a–c) ensure that the set of supports partitions the base set U. That is, (a) supports contain sets of contiguous units, (b) pairs of distinct supports are disjoint, and (c) the supports cover the base set U. In Section 2, we show that if the Euclidean geospatial region, that the set U of units is over, is 1-dimensional, then Problem 1—which we will refer to as the Alignment Problem, when the context is clear—is solvable in time polynomial in k, m and n. In Section 3, we show that if the geospatial region is 2-dimensional—which is the typical case in this context of constructing age-adjusted maps—then the Alignment Problem is NP-hard, even in the case of 2 collections, each with 2 supports. Finally, in Section 4, we outline a heuristic for the Alignment Problem in the 2-dimensional case. Section 5 concludes the paper and outlines future work."
https://arxiv.org/html/2411.08671v1,Theoretical Analysis of Byte-Pair Encoding,"Byte-Pair Encoding (BPE) is a widely used method for subword tokenization, with origins in grammar-based text compression. It is employed in a variety of language processing tasks such as machine translation or large language model (LLM) pretraining, to create a token dictionary of a prescribed size. Most evaluations of BPE to date are empirical, and the reasons for its good practical performance are not well understood.In this paper we focus on the optimization problem underlying BPE: finding a pair encoding that achieves optimal compression utility. We show that this problem is APX-complete, indicating that it is unlikely to admit a polynomial-time approximation scheme. This answers, in a stronger form, a question recently raised by Zouhar et al. [ZMG+23].On the positive side, we show that BPE approximates the compression utility of the optimal pair encoding to a worst-case factor between 0.333 and 0.625. Our results aim to explain the ongoing success of BPE and are, to our knowledge, the first rigorous guarantees on its compression utility that hold for all inputs.","A common step in the modern NLP application pipeline is tokenization: given an input text, the task is to partition it into tokens, i.e., frequently occurring consecutive groups of symbols. The main goal is to identify semantically meaningful units (words or subwords) in order to facilitate higher level tasks (e.g., translation or text generation) [MAS+21, AFT+23]. As this goal is difficult to directly optimize for, tokenization is usually solved heuristically, or formulated as a different but closely related task: data compression. Indeed, the dictionary-encoding of tokens reduces text length; the amount of compression is easy to measure, and was found to be a good predictor of the quality of tokenization for downstream tasks, e.g., for translation accuracy [Gal19]. It is thus natural to study tokenization with the proxy optimization goal of compression utility. Byte-Pair Encoding (BPE), introduced by Gage in 1994 [Gag94], is a commonly used heuristic for tokenization. It proceeds by repeatedly identifying the most frequently occurring pair of symbols and replacing all occurrences of this pair with a new symbol, thereby shortening the text. The new symbols, together with the pairs they replace, are stored in a lookup-table, which allows the reconstruction of the original text. In typical applications, the number of new symbols (and thus the size of the lookup-table) is fixed upfront, and the goal is to achieve the best compression within this budget. The symbols of the resulting (shortened) text correspond to the tokens of the input. Figure 1 shows an example of the encoding of a text by BPE. BPE has become a de-facto standard in NLP applications, widely employed in machine translation [Sen15, XZG+21, DGMH+19, Gal19, GVBS23] and in the preprocessing stage of training large language models [BMR+20, LLSZ21, TLI+23, RWC+19, LSFA+23, WGC+23]111See also https://github.com/google/sentencepiece and https://github.com/openai/tiktoken.. Besides its effectiveness, the popularity of BPE is likely due to its simplicity and computational efficiency, when compared with more sophisticated or linguistically motivated methods (e.g., see [BD20, SRZ+24]). A careful implementation of BPE has a total runtime that is linear in the input length, for an arbitrary number of replacement rounds. In addition, a BPE-encoded representation can support efficient random access and pattern-matching on the original text, which is important in some applications [SKF+99]. Given the popularity and good empirical performance of BPE, there is a surprising lack of rigorous guarantees for the quality of its output. In this paper we study the problem of compressing a text (a string s over some alphabet \Sigma) by successive encoding of pairs (strings of length two). Adopting the framework of approximation algorithms [WS11] we study how well BPE, as a natural greedy heuristic, approximates this problem. Our optimization goal is to maximize compression utility, i.e., the reduction in text length, within k pair-encoding rounds, where s and k are given as the input (we precisely define this problem – optimal pair encoding – later in this section). The problem formulation we use closely resembles the one recently introduced by Zouhar et al. [ZMG+23] for the same task. This abstract setting presents a challenging algorithm design problem of independent interest and allows a clean theoretical analysis of BPE. Note however, that we necessarily ignore some practical aspects and optimizations of BPE-variants (e.g., special treatment of whitespace and punctuation or language-specific rules [RWC+19, AFT+23]). An algorithm \mathscr{A} for optimal pair encoding has approximation ratio \upalpha\leq 1, if the compression utility of \mathscr{A} is at least \upalpha times the optimum for all inputs (s,k). The greedy step of BPE is locally optimal, and thus, for k=1 it achieves optimal compression. For k>1, however, simple examples show that BPE may not achieve optimal compression (see Figure 1). As our main complexity-result, we show that optimal pair encoding is APX-complete. This means (informally) that no polynomial-time algorithm can approximate it to a factor arbitrarily close to 1, unless P=NP. On the positive side, we show that BPE achieves an approximation ratio \upalpha, with 0.333<\upalpha\leq 0.625. We note that previously no constant-approximation guarantee was known for BPE or other algorithms. The question of whether optimal pair encoding is NP-complete was raised recently by Zouhar et al. [ZMG+23]; our result settles this question in a stronger form. \setcapindent 0em \displaystyle\mathtt{aabaaaba\rightarrow XbXaba\rightarrow YXaba\rightarrow Zaba} \displaystyle\mathtt{aabaaaba\rightarrow aXaaXa\rightarrow YaYa\rightarrow ZZ} Figure 1: Input s=\mathtt{aabaaaba} encoded by BPE merge sequence (\mathtt{aa\rightarrow X,\,Xb\rightarrow Y,\,YX\rightarrow Z)} (above). An optimal encoding by the merge sequence (\mathtt{ab\rightarrow X,\,aX\rightarrow Y,\,Ya\rightarrow Z}) (below). Before precisely stating our results, we review some further related work and give a formal definition of the problem and the algorithms that we study. Related work. BPE has its origins in text compression, in particular, the class of grammar-based compression methods or macro schemes, e.g., see [SS82, KY00, CLL+05, Loh12] for surveys. (The encoding obtained by BPE can be seen as a restricted kind of context-free grammar or string straight-line program.) A compression method closely related to BPE is Re-Pair [LM00]. Re-Pair differs from BPE in that its number of replacement rounds k is not fixed; instead, it performs replacements as long as they achieve a saving (i.e., as long as some pair appears in at least two disjoint copies). Re-Pair is widely used, e.g., in bioinformatics, and several variants and practical improvements of it have been proposed [KVOB24, GJ17, GIM+19, FTN+19]. The central question of grammar-based compression is to find a minimal grammar that generates a given text. This task is known to be NP-hard, as well as hard to approximate [SS82, CLL+05] (by some constant factor). The best known approximation ratio for the grammar-based compression of an input of length n is O(\log{n}) [Ryt03, Jeż14]. The approximation ratio of Re-Pair is O((n/\log{n})^{2/3}) and \Omega(\log{n}/\log\log{n}) [CLL+05, BHH+20]. Note that these results relate the size of the obtained grammar to that of the minimal grammar, where the latter can be of a more general kind than what Re-Pair (or BPE) can produce. Navarro and Russo [NR08] show a different kind of theoretical guarantee for Re-Pair, namely that its cost approximates the order-t entropy of the input, for a certain range of t and alphabet size. Furuya et al. [FTN+19] bound the gap between runs of Re-Pair with different tie-breaking. These results use a different cost measure (compressed length versus reduction, which will be discussed in deail later) and are not directly comparable to ours; nevertheless, a construction from [FTN+19] is also useful in our context, as shown below. Closest to our work is the recent paper of Zouhar et al. [ZMG+23], which initiated the formal study of BPE and optimal pair encoding that we also largely follow in this paper, apart from small notational differences and a more general problem formulation. Using the theory of submodular functions, they relate the approximation ratio of BPE to a certain parameter (total backward curvature) that depends on the unknown optimum. Zouhar et al. also observe an empirical bound on this quantity, however, without giving any worst-case guarantees. Problem definition. We consider strings (sequences of symbols) over some alphabet \Sigma and denote concatenation of strings a and b by a\cdot b, omitting the \cdot when clear from context. We denote the length of a string s by |s|, the i-th symbol of s by s[i], and the substring s[i]\cdot s[{i+1}]\cdots s[j] by s[i:j]. We thus have s=s[{1:|s|}]. A replacement rule is a function \operatorname{\mathsf{replace}}_{x\rightarrow y} that transforms a string s by replacing all occurrences of the string x in s with the string y. Formally, \operatorname{\mathsf{replace}}_{x\rightarrow y}(s)=s if s does not contain x, and otherwise \operatorname{\mathsf{replace}}_{x\rightarrow y}(s)=s[{1:i}]\cdot y\cdot% \operatorname{\mathsf{replace}}_{x\rightarrow y}(s[{i+|x|+1:|s|}]), where i is the smallest index for which s[{i+1:i+|x|}]=x. A sequence of replacement rules \mathscr{R}=(\mathscr{R}_{1},\dots,\mathscr{R}_{k}) with \mathscr{R}_{i}=\operatorname{\mathsf{replace}}_{a_{i}b_{i}\rightarrow c_{i}}, where a_{i},b_{i},c_{i} are symbols, is called a merge sequence of length k. Denoting s^{\prime}=\left(\mathscr{R}_{k}\circ\cdots\circ\mathscr{R}_{1}\right)(s), where \circ is the function composition, we refer to |s^{\prime}| as the compressed length, and |s|-|s^{\prime}| as the utility of \mathscr{R} for s. In words, s^{\prime} is obtained from s by applying the sequence of replacement rules \mathscr{R}_{1},\dots,\mathscr{R}_{k}. We refer to the i-th step, i.e., the application of \mathscr{R}_{i} as the i-th merge. We sometimes use the term full merge to emphasize that no copies of a_{i}b_{i} remain after the operation. Given the resulting encoded (compressed) string s^{\prime}, we can recover s by applying the sequence of reverse transformations \mathscr{R}^{\prime}=(\mathscr{R}^{\prime}_{k},\dots,\mathscr{R}^{\prime}_{1}) to s^{\prime}, with \mathscr{R}^{\prime}_{i}=\operatorname{\mathsf{replace}}_{c_{i}\rightarrow a_{% i}b_{i}}. Notice that the symbols c_{i}, for all i\in[k], can be assumed w.l.o.g., to be new, i.e., not appearing in s or in \left(\mathscr{R}_{j}\circ\cdots\circ\mathscr{R}_{1}\right)(s) for j<i. Indeed, if c_{i} already appears in the string, then the replacement a_{i}b_{i}\rightarrow c_{i} may not be unambiguously reversible. We can now formulate our main optimization problems. Given a string s and an integer k>0, find a merge sequence \mathscr{R} of length k, of maximal utility for s (or equivalently, of minimal compressed length). We denote this optimal utility as \operatorname{\mathsf{OPT}}^{m}(s,k), and call the task of computing it the optimal merge sequence (OMS) problem.222Apart from slightly different notation that is more convenient for our arguments, the OMS problem is identical to the problem defined by Zouhar et al. [ZMG+23]. Note that maximizing compression utility and minimizing compressed length are equivalent for exact computation, but not necessarily for approximability. We also define a more general optimization problem where we do not require to replace every occurrence of a pair. Formally, a partial replacement rule \mathscr{R}_{i}^{*}=\operatorname{\mathsf{replace}}^{*}_{a_{i}b_{i}\rightarrow c% _{i}} can be any function that satisfies \operatorname{\mathsf{replace}}_{c_{i}\rightarrow a_{i}b_{i}}(\operatorname{% \mathsf{replace}}^{*}_{a_{i}b_{i}\rightarrow c_{i}}(s))=s for all s. In words, \mathscr{R}_{i}^{*} replaces some occurrences of a_{i}b_{i} with c_{i}. A sequence of partial replacement functions \mathscr{R}^{*}=(\mathscr{R}_{1}^{*},\dots,\mathscr{R}_{k}^{*}) is a partial merge sequence. Denoting s^{\prime}=\left(\mathscr{R}_{k}^{*}\circ\cdots\circ\mathscr{R}_{1}^{*}\right)% (s), we define utility and compressed length of \mathscr{R}^{*} analogously to merge sequences. Notice that s can be recovered from s^{\prime} identically to the case of merge sequences. The optimal pair encoding (OPE) problem asks, given a string s and an integer k>0, to find a partial merge sequence \mathscr{R}^{*} of length k, of maximal utility for s. We denote this optimal utility as \operatorname{\mathsf{OPT}}(s,k). While the OMS problem is perhaps more natural, OPE is more general, and as shown in Figure 2, it can indeed be stronger (i.e., it is sometimes worth not merging every occurrence of a pair). Most of our results in this paper apply to both problems. \setcapindent 0em \displaystyle\mathtt{abcd\,|\,bc\,|\,bcda\,|\,cd\,|\,cdab\,|\,da\,|\,dabc\,|\,ab} \displaystyle\mathtt{~{}\rightarrow~{}XY\,|\,Z\,|\,ZT\,|\,Y\,|\,YX\,|\,T\,|\,% TZ\,|\,X} \displaystyle\mathtt{abcd\,|\,bc\,|\,bcda\,|\,cd\,|\,cdab\,|\,da\,|\,dabc\,|\,ab} \displaystyle\mathtt{~{}\rightarrow~{}XZ\,|\,Y\,|\,YT\,|\,Z\,|\,ZX\,|\,T\,|\,% dXc\,|\,X} Figure 2: Input s=\mathtt{abcd\,|\,bc\,|\,bcda\,|\,cd\,|\,cdab\,|\,da\,|\,dabc\,|\,ab}, where | denotes a distinct symbol for each occurrence. An optimal OPE encoding of s (above) with utility \operatorname{\mathsf{OPT}}(s,4)=12. An optimal OMS encoding of s (below) with utility \operatorname{\mathsf{OPT}}^{m}(s,4)=11. The OMS solution is obtained via the merge sequence (\mathtt{ab\rightarrow X,~{}bc\rightarrow Y,~{}cd\rightarrow Z,~{}da% \rightarrow T}). Byte-pair encoding (BPE). BPE solves both the OPE and OMS problem as follows. Starting with the input string s, it performs k locally optimal full merge steps, always choosing a pair whose replacement maximizes compression utility. Formally, for input (s,k), we output \mathscr{R}=(\mathscr{R}_{1},\dots,\mathscr{R}_{k}), where \mathscr{R}_{i}=\operatorname{\mathsf{replace}}_{a_{i}b_{i}\rightarrow c_{i}}. Denoting s^{(0)}=s, and s^{(i)}=\mathscr{R}_{i}(s^{(i-1)}) for i\in[k], each c_{i} is a new symbol, i.e., not occurring in s^{(j)} with j<i, and for i=1,\dots,k, the pair a_{i}b_{i} is chosen so that |\mathscr{R}_{i}(s^{(i-1)})| is minimal. With careful data structuring, identifying a_{i}b_{i} and performing \mathscr{R}_{i} can be done in linear total time over all k merge steps, e.g., see [SKF+99]. In this paper, we ignore such implementation details and focus on the total utility of BPE, i.e., |s|-|s^{\prime}|, where s^{\prime}=s^{(k)}. We denote this quantity as \operatorname{\mathsf{BPE}}(s,k). Note that clearly \operatorname{\mathsf{BPE}}(s,k)\leq\operatorname{\mathsf{OPT}}^{m}(s,k)\leq% \operatorname{\mathsf{OPT}}(s,k). We remark that a number of choices allow for small variation in the definition of BPE (and partly of \operatorname{\mathsf{OPT}}^{m}): (1) when choosing a pair to replace, in case of a tie in utility, we pick the pair that appears first; (2) the utility of a chosen pair equals its number of occurrences, except for the case of overlapping pairs (e.g., the pair \mathtt{aa} appears twice in \mathtt{aaa}, but only one of its copies can be replaced) – one could also decide based on the number of occurrences; and (3) in case of such overlapping pairs, we do the replacements left-to-right, e.g., \mathtt{aaa\rightarrow Xa}, whereas \mathtt{aaa\rightarrow aX} would also be a valid choice. Overall, the effect of these design decisions appears negligible. Our results hold regardless of the tie-breaking strategy for (1). As for (2) and (3), the implementation we chose appears better motivated than the alternatives, but our results can easily be adapted to the other variants; see also [LM00, ZMG+23] for discussion. Our results. As defined, OPE and OMS are natural string compression problems (maximizing compression utility), and BPE is a straightforward greedy heuristic for both. Surprisingly, no worst-case guarantee is known for BPE or for any other algorithm solving OPE or OMS. Zouhar et al. [ZMG+23] formulated the OMS problem (under slightly different terminology), and raised the question whether its exact decision problem is NP-hard. Our first result, shown in § 2 answers this question in a stronger form. We show that both OMS and OPE are in fact APX-complete, ruling out the existence of a polynomial time approximation scheme (PTAS), unless P=NP. Theorem 1.1. OPE and OMS are APX-complete. The fact that the number k of merge-steps is part of the input is crucial; for fixed values of k a polynomial-time exact algorithm is easy to derive. The APX-hardness also holds for the problem of minimizing compressed length, as well as for some other variants of the problem, as discussed in § 2. As for BPE, we analyze its approximation ratio for compression utility, showing in § 3: Theorem 1.2. BPE approximates OPE with a ratio of \upalpha, where 0.333<\upalpha\leq 0.625. Closing this gap is an intriguing open question. Note that the result also implies an approximation of OMS with the same or better ratio, as well as that \operatorname{\mathsf{OPT}} and \operatorname{\mathsf{OPT}}^{m} are within a constant factor of each other. Unlike the hardness result, this guarantee does not transfer to the dual optimization problem of minimizing compressed length. In particular, we show in § 4 that BPE cannot achieve a constant approximation for this measure. Theorem 1.3. The approximation ratio of BPE for compression length in OPE or OMS is \Omega(n). While our main focus is on the BPE algorithm, we find the OPE optimization problem of independent interest. We give in § 5 a simple algorithm we call EvenOdd, that achieves an approximation ratio of 0.5. We stress that despite this guarantee, on most inputs BPE likely behaves better than EvenOdd, which should be seen as a proof of concept. Theorem 1.4. EvenOdd is a 0.5-approximation for OPE. The following four sections are dedicated to the proofs of Theorems 1.1–1.4. In § 6 we conclude with a list of open questions."
https://arxiv.org/html/2411.08332v1,Learning-Augmented Algorithms for Online Concave Packing and Convex Covering Problems,"Learning-augmented algorithms have been extensively studied across the computer science community in the recent years, driven by advances in machine learning predictors, which can provide additional information to augment classical algorithms. Such predictions are especially powerful in the context of online problems, where decisions have to be made without knowledge of the future, and which traditionally exhibits impossibility results bounding the performance of any online algorithm. The study of learning-augmented algorithms thus aims to use external advice prudently, to overcome classical impossibility results when the advice is accurate, and still perform comparably to the state-of-the-art online algorithms even when the advice is inaccurate.In this paper, we present learning-augmented algorithmic frameworks for two fundamental optimizations settings, extending and generalizing prior works. For online packing with concave objectives, we present a simple but overarching strategy that switches between the advice and the state-of-the-art online algorithm. For online covering with convex objectives, we greatly extend primal-dual methods for online convex covering programs by [ABC+16] (FOCS 2016) and previous learning-augmented framework for online covering linear programs from the literature, to many new applications. We show that our algorithms break impossibility results when the advice is accurate, while maintaining comparable performance with state-of-the-art classical online algorithms even when the advice is erroneous.","In the classical online model, algorithms are given parts of the input over time, and must make irrevocable decisions to process the input elements as they arrive, without knowledge of the future. The performance of an online algorithm is often measured by its “competitive ratio”, which is defined as the ratio between the “cost” or “value” of the algorithm’s solution and that of the optimal solution in hindsight, or equivalently that of the solution of an optimal offline algorithm. Due to the uncertainty around future inputs, online problems are traditionally hard, and often exhibit impossibility results, which are lower bounds on the competitive ratio of any online algorithm (e.g., [KMMO94, AAA+09, BG19]). We refer the readers to [BN09b] and [HSLZ21] for excellent surveys on online algorithms. The on-going success of machine learning has led to the break-through concept of using predictions [PSK18, LV21], i.e., additional information inferred from historical data about future inputs or the problem instance as a whole, and incorporating them into classical online algorithms, to achieve better performance and break impossibility results. However, due to the probabilistic nature of machine learning, as well as the inability of online algorithms to verify the accuracy of these predictions, blindly trusting and following the advice can lead to undesirable performance compared to even online algorithms without predictions, as established by [SZS+13] and [BMS20]. As a result, the focus of the community has shifted to learning-augmented algorithms, namely algorithms that utilize the advice prudently, maintaining rigorous guarantees and high performance, both when the advice is accurate, in which case we say it maintains consistency, and when the advice is arbitrarily inaccurate, in which case we say that it satisfies robustness. We refer the readers to [MV22] for a survey on learning-augmented algorithms. Online covering and packing problems. A recent line of work studies learning-augmented algorithm in context of online covering linear programs (LPs). The seminal work of [BMS20] built upon the primal-dual framework of [BN09a] and presented the first primal-dual learning-augmented (PDLA) algorithm for online set cover. Combining their algorithms with ideas from [EKN16], the work of [GLS+22a] generalized the primal-dual learning-augmented framework to solve general online covering LPs and semidefinite programs, allowing for fractional cost, constraint, and advice. The PDLA framework utilizes the duality of covering and packing linear programs, and maintains a primal covering solution as well as a dual packing solution simultaneously, while fine-tuning the growth rate of each individual variable using the advice provided to the algorithm. Compared to many other learning-augmented algorithms for specific online problems, the PDLA framework is general-purpose, and can apply to a variety of problems oblivious of structure. Our contributions at a glance. In this paper, we extend the line of work on online covering and packing problems, by designing algorithmic frameworks for online packing maximization with concave objectives, and online covering minimization with convex objectives, further generalizing the setting of [GLS+22a]. Our settings and frameworks are general-purpose, and can be directly applied to a variety of problems, agnostic of problem structure. Concave packing and convex covering are traditionally considered strongly associated “dual” problems to each other in operations research and online optimization; Nonetheless, we show that these two settings admit vastly different learning-augmented algorithms despite their similarity. For online packing with concave objectives, we present a simple class of algorithms utilizing a similar “switching” strategy to that outlined in [GLS+22b] (attributed to Roie Levin), complementing their observation that even such simple strategies can outperform sophisticated algorithms for online covering linear programs. Switching between different algorithms has been a classical design philosophy in classical online algorithms [FKL+91], but is much less prevalent in learning-augmented algorithms (e.g., [ACE+23]). For online covering with convex objectives, it appears that “switching” strategies do not admit efficient algorithms, thus we instead present a primal-dual-based framework, taking inspiration from the classical primal-dual method for online convex covering in [ABC+16]. As an extended result, we adapt our PDLA framework to the online covering setting with \ell_{q}-norm objectives studied in [SN20], utilizing problem structure to obtain better analyses. Finally, we apply our proposed frameworks to a variety of online optimization problems, including network utility maximization, optimization under inventory constraints, mixed covering and packing, and buy-at-bulk network design. Conceptually, from our observations around the “switching” paradigm, we raise some basic questions: What properties enables these switching strategies to perform well, that is present in concave packing, but absent in convex covering? More generally, which online problems allow such simple algorithms and solutions to exist? We believe that understanding these conceptual questions are important for the field of learning-augmented algorithms. Organization. We state necessary background knowledge in Section 1.1, and outline our contributions in more detail in Section 1.2. We survey and provide additional references to prior works in Section 1.3. In Section 2, we present a simple “switching”-based overarching framework for online concave packing. In Section 3, we present an overview for our primal-dual learning-augmented framework for online convex covering. In Section 4, we present our extension of our PDLA framework onto online covering with \ell_{q}-norm objectives. In Section 5, we apply our algorithmic frameworks onto a variety of well-motivated practical problems. We conclude our paper with closing remarks and discussions of future directions in Section 6. 1.1 Preliminaries We denote by \mathbf{0}_{(n)} and \mathbf{1}_{(n)} the vector of all zeroes and all ones of length n, respectively. When the length of the vector is unambiguous, we omit the subscript and use \mathbf{0} and \mathbf{1}. We use x\geq y for x,y\in\mathbb{R}_{\geq 0}^{n} to denote the relation that x_{i}\geq y_{i} for all i\in[n]. A function f:\mathbb{R}^{n}\to\mathbb{R} is monotone if for all x\geq x^{\prime}, f(x)\geq f(x^{\prime}) as well111Such functions are usually called ‘monotone non-decreasing’. Since all monotone functions in this paper are non-decreasing, we omit the classifier for simplicity.. We use A:=\{a_{ij}\}_{i\in[m],j\in[n]}\in\mathbb{R}_{\geq 0}^{m\times n} to denote the constraint matrix of the covering and packing problems we study, and we use i\in[m] and j\in[n] to denote the row and column index of A, respectively. Online concave packing. The online packing setting with concave objectives we study is defined as follows: \displaystyle\begin{aligned} \text{max }&g(y)\text{ over }y\in\mathbb{R}_{\geq 0% }^{m}\text{ subject to }A^{T}y\leq b.\end{aligned} (1) Here, g:\mathbb{R}_{\geq 0}^{m}\to\mathbb{R}_{\geq 0} is a concave and monotone objective function with g(\mathbf{0})=0, and b\in\mathbb{R}_{>0}^{n} denotes an upper bound vector for the linear constraints. In the online setting, the objective function g, the values in b, and the number of constraints n are given in advance. In each round i\in[m], a new packing variable y_{i} is introduced, along with all the associated coefficients a_{ij} for all j\in[n] (the i-th row of A). The number of packing variables m might be unknown, and each packing constraint is gradually revealed column-wise to the algorithm. In round i\in[m], the algorithm can only irrevocably assign a value for y_{i}. The goal is to approximately maximize g(y) by assigning values to the variables online while maintaining (approximate) feasibility. Online convex covering. The online covering setting with convex objectives we study is defined as follows: \displaystyle\begin{aligned} \text{min }&f(x)\text{ over }x\in\mathbb{R}_{\geq 0% }^{n}\text{ subject to }Ax\geq\mathbf{1}.\end{aligned} (2) Here, f:\mathbb{R}_{\geq 0}^{n}\to\mathbb{R}_{\geq 0} is a convex, monotone, and differentiable function, with f(\mathbf{0})=0. We make the technical assumption that the gradient of f, \nabla f, is monotone as well, and later show that it is possible to remove this assumption in a more structured setting. The online setting for convex covering is similar to that of concave packing: The objective function f and the numbers of covering variables n are given in advance, but the constraint matrix A and the number of constraints m is unknown to the algorithm. In each round i\in[m], the i-th row of A arrives online, and the algorithm must update x_{j} for all j\in[n] in a non-decreasing fashion to satisfy the constraint, while approximately minimizing f(x). Online optimization with advice. In the learning-augmented setting, the algorithm is additionally given an advice on the variables of interest: y^{\prime}\in\mathbb{R}_{\geq 0}^{m} for packing, and x^{\prime}\in\mathbb{R}_{\geq 0}^{n} for covering. We do not make any additional assumptions about the advice, and their objective values g(y^{\prime}) or f(x^{\prime}) can be arbitrarily worse compared to the optimal solution. Our frameworks additionally utilize a hyper-parameter \lambda\in[0,1], denoted the confidence parameter, chosen by the user a priori. The advice can be interpreted as a suggestion on what the solution, and thus what the main variables at the end of the algorithm’s execution should be, and the confidence parameter \lambda indicates how much the user trusts this advice. A value of \lambda close to 0 indicates that the advice is trusted and thus likely to be accurate, while a value close to 1 indicates that the advice should not be trusted. The algorithm’s goal is thus to incorporate the advice prudently, obtaining a final solution \bar{x} or \bar{y} whose performance is comparable to the advice when \lambda is small, and comparable to the state-of-the-art online algorithm when \lambda is large. We formalize the metrics we use to measure the performance of learning-augmented algorithms via two notions, consistency and robustness: Definition 1.1. An online (covering) solution \bar{x} is C(\lambda)-consistent if f(\bar{x})\leq C(\lambda)\cdot f(x^{\prime}), where f(x^{\prime}) is the cost of the advice. A learning-augmented algorithm is C(\lambda)-consistent if the solution it generates is C(\lambda)-consistent. Definition 1.2. An online (covering) solution \bar{x} is R(\lambda)-robust if f(\bar{x})\leq R(\lambda)\cdot\textsf{OPT}, where OPT is the cost of the optimal offline solution. A learning-augmented algorithm is R(\lambda)-robust if the solution it generates is R(\lambda)-robust. The packing version of these definitions follows symmetrically: A solution \bar{y} is C-consistent and R-robust if g(\bar{y})\geq\frac{1}{C}g(y^{\prime}) and g(\bar{y})\geq\frac{1}{R}\textsf{OPT}. For packing maximization problems, it is common practice to allow the solutions found by an online algorithm to violate the packing constraints by a certain factor; an exactly feasible solution can be recovered by scaling down the approximately feasible solution. We make this notion of approximate feasibility explicit in the following definition: Definition 1.3. An online (packing) solution \bar{y} is V(\lambda)-feasible if A^{T}\bar{y}\leq V(\lambda)\cdot b. An online algorithm is V(\lambda)-feasible if the solution it generates is V(\lambda)-feasible. Intuitively, when we are confident in the advice, we should follow it as much as possible and obtain a solution that is close to the advice, so C(\lambda) should tend to 1 as \lambda tends to 0. On the other hand, when the advice is possibly inaccurate, our algorithm should follow the non-learning-augmented classical online algorithm, so R(\lambda) should tend to the competitive ratio of the state-of-the-art online algorithm as \lambda tends to 1. The role of the confidence hyper-parameter \lambda is thus to control the tradeoff between consistency and robustness. 1.2 Our Contributions 1.2.1 Online Packing with Concave Objectives Our result for the online packing problem with concave objectives is a general framework for devising learning-augmented algorithms for all online concave packing problems. We present a simple algorithm utilizing a switching strategy, which is reminiscent of the switching algorithm mentioned in [GLS+22b], but ultimately relies on properties of maximization problems distinct to that for covering minimization problems. The algorithm uses any state-of-the-art classical online algorithm as a black-box subroutine, and obtains a solution that matches both the value of the advice and the value of the subroutine online algorithm asymptotically: Theorem 1.4 (Informal). Given an instance of the online concave packing problem (1), there exists an online algorithm that takes an \alpha-competitive \beta-feasible online algorithm as a subroutine, an advice y^{\prime}\in\mathbb{R}_{\geq 0}^{n} which is \beta-feasible, and a confidence parameter \lambda. The algorithm is \frac{1}{1-\lambda}-consistent, \frac{\alpha}{\lambda}-robust, and (2-\lambda)\beta-feasible. The formal version of Theorem 1.4 is Theorem 2.1. We state and analyze our algorithm in Section 2. We remark that our algorithm is a general-purpose framework, and does not rely on any specific classical online algorithm. This property absolves users of our framework from the responsibility of understanding potentially sophisticated online algorithm used as a black-box subroutine. In addition, future advancements in the field of classical online problems would immediately imply advances in their variants augmented by advice. Our advice model on the packing variables also generalizes many prior models (e.g.,[IKMQP21] for online knapsack problems), since any form of advice that suggests a course of action can be simulated by our packing program formulation by setting the advice entries to an appropriate value. The exact values of the advice entries depend on the exact problem and advice formulation: We give some examples of these reductions in Section 5.1. 1.2.2 Online Covering with Convex Objectives As our main result, we present a general framework for designing learning-augmented algorithms for online covering problems with convex objective functions (3) and possibly non-integral advice and constraints, which generalizes previous works such as online set cover [BMS20], and online general covering LPs [GLS+22a]. We employ the standard assumption that the objective function f is convex, monotone, differentiable, with f(\mathbf{0})=0. We additionally assume that the gradient \nabla f is monotone, which is a technical assumption made in works studying the classical online version of the problem as well [BCG+14, ABC+16]. We point out that the switching strategy for online covering linear programs in [GLS+22b] crucially relies on the linearity (more specifically, subadditivity) of the objective function, which is not satisfied by convex functions in general, even with the monotone gradient assumption. The cost of “switching” between solutions is at most a multiplicative factor of 2 in the linear case, but may be unbounded for convex objectives. Thus, such simple switching strategies do not apply to our setting. Motivated by this, our algorithm for online convex packing returns to more sophisticated methods and follows the primal-dual learning-augmented (PDLA) paradigm [BMS20, GLS+22a], taking the advice into consideration while carefully tuning the growth rate of each variable, in order to approximately minimize the cost of the solution. The PDLA algorithms we present are both robust and consistent, with performance close to that of the optimal offline solution when the advice is accurate, and close to that of the state-of-the-art online algorithm when the advice is inaccurate. The performance of our algorithm is (informally) characterized by the following theorem: Theorem 1.5 (Informal). Given an instance of the online convex covering problem (3), there exists an online algorithm that takes an advice x^{\prime}\in\mathbb{R}_{\geq 0}^{n} and a confidence parameter \lambda. The algorithm is O(\frac{1}{1-\lambda})-consistent and O((p\log\frac{d}{\lambda})^{p})-robust. Here, p:=\sup_{x\geq\mathbf{0}}\frac{\langle x,\nabla f(x)\rangle}{f(x)}, and d is the row sparsity of the constraint matrix. The formal version of Theorem 1.5 is Theorem 3.2 in Section 3, which addresses the case when the advice x^{\prime} is infeasible. We remark that our consistency ratio tends to 1 as \lambda tends to 0, and our robustness ratio tends to O((p\log d)^{p}) as \lambda tends to 1, matching the competitiveness of the online algorithm presented in [ABC+16], meeting the ideal expectations. While our algorithms and analyses resemble their counterparts in prior works, we employ some subtle yet vital modifications, since a more direct application of [GLS+22a]’s learning-augmentation model onto [ABC+16]’s primal-dual framework suffers from various technical issues and cannot yield satisfactory results. 1.2.3 Online Covering with \ell_{q}-norm Objectives Our technical assumption that the gradient is monotone follows from an identical assumption in [BCG+14] and [ABC+16]. Subsequently, [SN20] restricted their attention to online covering problems with \ell_{q}-norm objectives, and presented new analyses of a variant of [ABC+16]’s algorithm that removed the monotone gradient assumption, using the structural properties of \ell_{q}-norms. Specifically, they consider covering problems of the following form: \text{min }\sum_{e=1}^{r}c_{e}||x(S_{e})||_{q_{e}}\text{ over }x\in\mathbb{R}_% {\geq 0}^{n}\text{ subject to }Ax\geq 1 (3) where each S_{e}\subseteq[n] is a subset of indices, q_{e}\geq 1, c_{e}\geq 0, x(S) denote the vector x restricted to indices in S, and ||x(S)||_{q} is the \ell_{q}-norm, i.e., \left(\sum_{i\in S}x_{i}^{q}\right)^{1/q}. We adapt the analysis in [SN20] to our PDLA framework for general online convex covering problems, and show that it is also consistent and robust for online covering problems with \ell_{q}-norm objectives, similarly in lieu of the monotone gradient assumptions in [ABC+16]. The performance of our algorithm for online covering problems with \ell_{q}-norm objectives is (informally) described by the following theorem: Theorem 1.6 (Informal). Given an instance of the online covering problem with \ell_{q}-norm objectives (3), there exists an online algorithm that takes an advice x^{\prime}\in\mathbb{R}_{\geq 0}^{n} and a confidence parameter \lambda. The algorithm is O(\frac{1}{1-\lambda})-consistent and O(\log\frac{\kappa d}{\lambda})-robust. Here, \kappa is the condition number of the constraint matrix, and d is the row sparsity of the constraint matrix. The formal version of Theorem 1.6 is Theorem 4.1 in Section 4 which addresses the case when the advice x^{\prime} is infeasible. 1.2.4 When is switching optimal? Designing simple solutions to natural problems of wide general interest is an ultimate goal of both theory (as they can be taught even in undergraduate courses!) and practice (as they can be implemented with a few lines of code, and would have strong provable guarantees!). However, while the study of learning-augmented algorithm is currently flourishing, many solutions and formulations are often somewhat ad-hoc, and hence there is a need for general frameworks, techniques, and paradigms. Inspired by the switching strategy noted in [GLS+22b] and our own observations in this paper, we raise a basic question: Can one characterize the space of online problems augmented with advice, for which one may use classical online algorithms as a black-box to obtain optimal solutions? In particular, what are the necessary and sufficient conditions for such simple switching strategies to be close to being optimal? What features should a problem exhibit that would allow it to be solvable in a black-box fashion in the advice setting? Recently, [DKL+24] showed that a similar switching-based approach can achieve optimal constants in online knapsack with succinct predictions, which also raises similar questions. We believe that a better understanding of this conceptual direction may lead to unifying frameworks in the study of algorithms with advice. In this work, we make progress on sufficient conditions for the question above. In particular, we study online concave packing problems with advice and show that the switching framework is close to being optimal in this context. As a step towards necessary conditions, we show that switching strategies, at least ones found in [GLS+22b] and our algorithmic framework for online concave packing problems, are not applicable to online convex covering problems, and instead requires more sophisticated methods to solve in general. 1.2.5 Applications We explicitly study the application of our frameworks to well-motivated problems in both online concave packing and online convex covering settings in Section 5. Our algorithms match the state-of-the-art algorithms by setting \lambda=1 and can potentially outperform the best-known online algorithms when the advice is accurate. We apply Theorem 1.4 to a variety of packing problems, including knapsack, resource management benefit, throughput maximization, network utility maximization, and optimization with inventory constraints. We then present an application of Theorem 1.5 to online mixed covering and packing, and by extension a variety of sub-problems such as capacity-constrained facility location and capacitated multicast, and an application of Theorem 1.6 to online buy-at-bulk network design. 1.3 Additional Prior Works Learning-augmented algorithms. Learning-augmented algorithms have been extensively studied for many fundamental online problems. [Roh20] and [LV21] showed that accurate predictions can lead to competitive ratios better than classical impossibility results for online caching, and subsequent works studied problems such as set cover [BMS20], ski rental [PSK18, BMS20], clustering [EFS+22], graph problems [BCAGL23, BFNP24, HSSY24], facility location [JLL+21], knapsack [IKMQP21, BFL22, DKL+23], matching [DIL+21, JM22], and others [HIKV19, AGKK20, BMRS20, BMS20, LLMV20, DKT+21, DLPLV21, CEI+22, CSVZ22, CP23, KT23b, BFNP24]. While most works in learning-augmented algorithms treat the advice as a black-box device, there are some recent works that studies how to properly obtain such advices (e.g., [Bal20, KBTV22]). A comprehensive online archive of recent works in the field of learning-augmented algorithms can be found at [LM22]. Other lines of work exploring alternative forms of additional information given to the algorithm studies the stochastic setting, where the assumption is that the input instance is drawn from an underlying distribution known to the algorithm. Problems studied under this model include stochastic matching [LFKF18], graph optimization [APT22], and others [MNS12, Mit18]. In comparison, the advice model studied by the learning-augmented algorithm community at large considers only explicit advices about the future inputs of the instance. While these advices may take forms that admits a distributional interpretation, there is no assumption made on the input distribution itself. The primal-dual method. The primal-dual method, introduced in the seminal work of [GW95], is a powerful algorithmic technique used to solve a variety of problems in the field of approximation algorithms. The primal-dual method has been applied to individual problems such as online set cover [AAA+09], network optimization [AAA+06], ski rental [KMMO94], and generalized into a unifying framework for online LP-based problems by [BN09a]. We refer the readers to [BN09b] for a survey on the topic of primal-dual methods for online algorithms. In the field of learning-augmented algorithms, Bamas, Maggiori, and Svensson [BMS20] initiated the study of primal-dual learning-augmented algorithms, and inspired follow-up work to extend the framework to more generalized models. [AGKP22] considered PDLA algorithms on online covering LPs with multiple predictions; [GLS+22a] generalized the PDLA framework to general online covering problems with fractional constraints and advices, as well as online semidefinite programs [EKN16]. Towards generalizing the framework of [BN09a] and [GLS+22a] to non-linear objectives, a concurrent line of work by [TD21] and [KT23a] studies online packing and covering problems using configuration programs and multilinear extensions of monotone objective functions. We remark that their model admits more generality in allowing non-convex or non-concave objective functions, but also incurs a potential loss in performance due to the generalized setting, and thus are incomparable to ours. Their advice is also integral, while the form of advice we consider allows for fractional predictions. Some prior works have studied problems that allow a convex covering (e.g., [BMRS20, CP23, GJZ23, BPSW24, LCS+24]) and concave packing (e.g.,[IKMQP21, DLPLV21, JM22, KT23b]) program formulation in the context of learning-augmented algorithms. Our learning-augmented frameworks unifies and generalizes these settings and also applies to many other problems."
https://arxiv.org/html/2411.08218v1,Improved Approximations for Stationary Bipartite Matching: Beyond Probabilistic Independence,"We study stationary online bipartite matching, where both types of nodes—offline and online—arrive according to Poisson processes. Offline nodes wait to be matched for some random time, determined by an exponential distribution, while online nodes need to be matched immediately. This model captures scenarios such as deceased organ donation and time-sensitive task assignments, where there is an inflow of patients and workers (offline nodes) with limited patience, while organs and tasks (online nodes) must be assigned upon arrival.We present an efficient online algorithm that achieves a (1-1/e+\delta)-approximation to the optimal online policy’s reward for a constant \delta>0, simplifying and improving previous work by [AS22]. Our solution combines recent online matching techniques, particularly pivotal sampling, which enables correlated rounding of tighter linear programming approximations, and a greedy-like algorithm. A key technical component is the analysis of a stochastic process that exploits subtle correlations between offline nodes, using renewal theory. A byproduct of our result is an improvement to the best-known competitive ratio—that compares an algorithm’s performance to the optimal offline policy—via a (1-1/\sqrt{e}+\eta)-competitive algorithm for a universal constant \eta>0, advancing the results of [PW24].","Online bipartite matching has a storied history in computer science. The foundational work of Karp, Vazirani, and Vazirani introduced the problem along with the optimal RANKING algorithm, achieving a competitive ratio of 1-1/e [KVV90]. Karp et al.’s work catalyzed extensive future research improving our understanding of online matching. Extensions considered have included guarantees for vertex-/edge-weighted graphs [AGKM11, FHTZ20, GHH+21, BC22], stochastic arrivals [FMMM09, MGS12, JL13, HS21, TWW22, HSY22, CHS24], post-allocation stochasticity [MP12, GU23, HJS+23, HTW24], online matching mechanisms [CHMS10, FGL15, KW19], and settings incorporating partial information or predictions [JM22, AGKK23]. When offline nodes are given upfront and online arrivals are sampled from time-dependent distributions, edge-weighted online matching was studied from the perspective of “prophet inequalities”—namely, against the offline optimum. Numerous elegant 0.5-competitive online algorithms are known [FGL15, EFGT22, AM23]. Approximations to the online benchmark were introduced by [PPSW23], leading to “philosopher inequalities” [SW21, BDML22, NSW23, BDP+24] improving the approximation ratio to 0.67. The theoretical results in matching have found practical applications in online advertising [MSVV07], ride-sharing [DSSX21, ABD+23], and organ transplantation [DPS12, AR21]; see [HTW24] for a brief survey and [EIVR23, Chap. 5] for a comprehensive treatment. These markets are often characterized by continuous agent turnover: in the gig economy, a stream of arriving workers must be assigned to time-sensitive tasks within limited time windows. For example, drivers join and exit ride-hailing platforms at will. Similarly, organ transplant candidates arrive continuously and may exit the system unmatched. Many other resource allocation markets (like inventory management for a food bank) exhibit this dynamic structure, which affects the “market thickness”—the availability of compatible market participants for matching. This continuous flow of new offline agents and their limited patience are crucial considerations that are overlooked by the classic online matching models. A notable recent line of work considers the problem under adversarial arrivals and deadlines [HKT+18, HPT+19, HTWZ20, EKLS21, TZ22], or assumes that agents are available for a fixed “window” of time [ABD+23]. In the stochastic setting, a recently introduced stationary formulation of the online matching problem models the arrivals and departures as a continuous-time process, accounting for heterogeneity across agents. Aouad and Saritaç gave a (1-1/e)-approximation to the optimal online algorithm [AS22]. Despite extensive efforts, and further simplification of their algorithm and analysis, improving upon the (1-1/e) approximation ratio has been elusive. In the special case where there is a single type of offline node, an improvement was obtained by [KSSW22], who gave a 0.656-approximation. Against the offline benchmark, the best-known competitive ratio is 1-1/\sqrt{e}, which is a recent improvement due to [PW24], relative to the original result by [CILB+20]. The main contribution of this paper is an efficient online algorithm that achieves a (1-1/e+\delta)-approximation to the optimal online policy’s reward, where \delta>0 is a constant bounded away from zero. A byproduct of our result is an improvement to the best-known competitive ratio—that compares an algorithm to the optimal offline policy—via a (1-1/\sqrt{e}+\eta)-competitive algorithm for a universal constant \eta>0, advancing and simplifying the results of [PW24]. Problem formulation: Online stationary bipartite matching. We are given offline types I and online types J. Offline nodes of type i\in I arrive at rate \lambda_{i} and each one departs after time \text{Exp}(\mu_{i}), independently from others; online nodes of type j arrive at rate \gamma_{j}. Upon arrival of a type-j node, we must immediately and irrevocably decide how to match it (if at all). Matching to a present and unmatched offline node of type i gains some specified reward r_{i,j}\geq 0 while choosing not to match gains no reward. Naturally, each arriving node can be matched at most once. Our goal is to design an online matching policy maximizing the expected long-term average reward, i.e., \textsf{Gain(ALG)}:=\liminf_{t\rightarrow\infty}\frac{\textsf{ALG}[0,t]}{t} where \textsf{ALG}[0,t] denotes the reward ALG accrues during time [0,t]. Our main performance measure is the approximation ratio, which computes the ratio between the algorithm’s performance Gain(ALG) and that of the optimal online algorithm (\mathrm{OPT}_{\mathrm{on}}), which is the solution of a dynamic program solving Bellman’s equations [Ber12, Put14]. We also consider the measure of competitive ratio, which computes an analogous ratio with respect to the optimal offline algorithm (\mathrm{OPT}_{\mathrm{off}}), that has exact knowledge about all arrival and departure times a priori. 1.1 Our Results Our main result is an algorithm breaking the 1-1/e barrier for online stationary matching. {mdframed} [hidealllines=true, backgroundcolor=gray!20, leftmargin=0cm,innerleftmargin=0.35cm,innerrightmargin=0.35cm,innertopmargin=0.375cm,innerbottommargin=0.375cm,roundcorner=10pt] Theorem 1.1. There exists a polynomial-time algorithm for the online stationary matching problem that achieves expected average reward at least a (1-1/e+\delta)-factor of the optimal online algorithm, for some universal constant \delta>0. As a byproduct, we obtain an algorithm and analysis that improves on the best-known competitive ratio, and additionally simplifies the proof of the existing bound. In particular, we provide a polynomial-time algorithm for the online stationary matching problem that achieves expected average reward at least a (1-1/\sqrt{e}+\eta)-factor of the optimal offline algorithm, for some universal constant \eta>0, improving the results of [PW24]. As in [AS22, Thm. 2], we can additionally extend our main result to get improved approximation guarantees in settings where both sides of the graph have limited patience or where the graph is non-bipartite and all types are partially patient. Such extensions are deferred to Appendix F. 1.2 Our Techniques We introduce several new techniques to achieve an improved approximation ratio for online stationary matching. A tightened LP relaxation. At its core, our algorithm employs a polynomial-size LP relaxation of the optimal online policy. Extending ideas from prior literature [HS21, HSY22, KSSW22], we identify a new exponential family of constraints bounding the availability of offline types. Pivotal sampling for stationary matching. To round our LP online, upon the arrival of an online type j\in J, each available offline node of type i\in I proposes to match with node j with a “proposal probability” p_{i,j}, computed based an optimal solution to our LP relaxation. Drawing a connection with the discrete online matching literature [BDP+24], we correlate these proposals using pivotal sampling, and then match to the proposing node with maximum reward. We provide a simple and concise proof that this algorithm is (1-1/e)-approximate by coupling the random evolution of offline nodes with a simple Markov chain, where offline nodes are completely independent. In particular, we show that the true number of offline nodes stochastically dominates a stochastic process comprised of independent Markov chains, providing a new short proof of this baseline guarantee. This analysis holds even if the proposals are drawn independently. Independent proposals cannot beat 1-1/e. In contrast, we show that pivotal sampling achieves a better approximation in several cases. In particular, when the proposal probabilities are bounded away from 1, we leverage negative correlation of pivotal sampling for an improved guarantee. We also identify straightforward improvements when the LP solution does not saturate the capacity constraints of online nodes, or when rewards are not overwhelmingly vertex-weighted, i.e., the LP solution does not “concentrate” on edges of nearly equal weights. Via our tightened LP relaxation, we argue that the remaining cases are extremely structured instances, which we term vertex-weighted highly-connected. Here, breaching the (1-1/e)-approximation ratio requires a second algorithm, which we call Balanced Greedy. After removing edges and node types with negligible contributions to the LP solution, Balanced Greedy matches each arriving online node myopically, using a form of “balanced” tie-breaking between offline nodes (instead of prioritizing those with larger rewards). To this end, we split each offline type into “top” and “bottom” copies uniformly at random, and prioritize matches to top copies when possible. Key technical component. Unlike discrete settings, where offline nodes’ availability progresses from empty to full over a known time horizon, the stationary nature of this problem prevents us from beating the 1-1/e bound using independent availability (as in, e.g., [NSW23, BDP+24]). Instead, the core of our improvement stems from demonstrating that the deprioritization of “bottom nodes” when running Balanced Greedy leads to a higher probability of availability in steady-state. Intuitively, the prioritization in Balanced Greedy means that bottom types are not depleted continuously over time—in the intervals where top types are present, the bottom nodes are not matched. Formalizing this idea via a new process with weakly correlated Markov chains, we show that an arriving online node of type j has no available neighbor with probability 1/e-\delta^{\prime} for some constant \delta^{\prime}>0. We first bound the probability that j sees no available neighboring top node via the simpler independent Markov chains. Conditioned on its top neighbors being unavailable, we analyze the joint probability that j’s bottom neighbors are unavailable by exploiting independence of arrivals/departures across types, and applying the Hardy-Littlewood inequality to bound the remaining correlation. The central challenge is to analyze the conditional probability that an individual bottom neighbor i\sim j is unavailable; we do so by applying techniques from renewal theory and an analysis of mixing times. 1.3 Further related work Online matching with announced departures. In the unweighted case, a beautiful recent line of work [HKT+18, HPT+19, HTWZ20, EKLS21, TZ22] considers the problem under adversarial arrivals and deadlines, giving algorithms significantly beating the 0.5 baseline of Greedy and showing the 1-1/e guarantee of [KVV90] is unattainable. It is even possible to slightly beat greedy for general vertex arrivals when arriving nodes must be matched immediately or to later arrivals [WW15, GKS19]. In settings with edge-weights, results on “windowed matching” study policies when agents stay in a marketplace for a fixed number of time periods, or for certain i.i.d. random durations [ABD+23]. Online stationary matching. The stationary (or dynamic) problem was studied by [CILB+20, AS22].111There is extensive work on the control of matching queues in the applied probability literature, with a focus on stability criteria [BGM13, MM16], implicit solutions for the steady-state distribution [MBM21], waiting times [CDB22], and large-market approximations [ÖW20] or heavy-traffic [VM21]. Notably, however, the combinatorial aspect of the problem, and the design of policies through the lens of approximation algorithms, has received less attention. Here, the central planner is not notified before agents depart. More recently, [PW24] develop a generalization of the stationary setting to combinatorial allocation, and leverage a reduction to offline contention resolution schemes to obtain constant-factor competitive algorithms. [LWY23] consider more general distribution of departure times. While it is unknown if the stationary matching is NP-hard or APX-hard, [AAS24] devise a fully polynomial-time approximation scheme in the special case where the number of offline nodes is a constant."
https://arxiv.org/html/2411.08151v1,New Separations and Reductions for Directed Preservers and Hopsets,"We study distance preservers, hopsets, and shortcut sets in n-node, m-edge directed graphs, and show improved bounds and new reductions for various settings of these problems. Our first set of results is about exact and approximate distance preservers. We give the following bounds on the size of directed distance preservers with p demand pairs:\widetilde{O}(n^{5/6}p^{2/3}+n) edges for exact distance preservers in unweighted graphs, and\Omega(n^{2/3}p^{2/3}) edges for approximate distance preservers with any given finite stretch, in graphs with arbitrary aspect ratio.Additionally, we establish a new directed-to-undirected reduction for exact distance preservers. We show that if undirected distance preservers have size O(n^{\lambda}p^{\mu}+n) for constants \lambda,\mu>0, then directed distance preservers have size O\left(n^{\frac{1}{2-\lambda}}p^{\frac{1+\mu-\lambda}{2-\lambda}}+n^{1/2}p+n% \right). As a consequence of the reduction, if state-of-the-art upper bounds for undirected preservers can be improved for some p\leq n, then so can state-of-the-art upper bounds for directed preservers.Our second set of results is about directed hopsets and shortcut sets. For hopsets in directed graphs, we prove that the hopbound is:\Omega(n^{2/9}) for O(m)-size shortcut sets, improving the previous \Omega(n^{1/5}) bound [Vassilevska Williams, Xu and Xu, SODA 2024],\Omega(n^{2/7}) for O(m)-size exact hopsets in unweighted graphs, improving the previous \Omega(n^{1/4}) bound [Bodwin and Hoppenworth, FOCS 2023], and\Omega(n^{1/2}) for O(n)-size approximate hopsets with any given finite stretch, in graphs with arbitrary aspect ratio. This result establishes a separation between this setting and O(n)-size approximate hopsets for graphs with polynomial aspect ratio, which are known to have an \widetilde{O}(n^{1/3}) upper bound [Bernstein and Wein, SODA 2023].","In network design, two commonly studied categories of problems are graph augmentation problems, where the goal is to augment the graph so that it gains some useful property, and graph sparsification problems, where the goal is to sparsify the graph while preserving some of its features. In this work, we study two fundamental problems from these two categories: hopsets and distance preservers. The hopset problem is a typical graph augmentation problem. We are given a graph111We assume graphs to be directed unless otherwise specified., and we want to add a small number of additional edges to the graph so that all pairs of vertices (s,t) have an approximate shortest s\leadsto t path with few edges. Another popular graph augmentation object, the shortcut set (first introduced by [45]), is actually a special case of hopsets where we only care about reachability. Hopsets and shortcut sets have a wide range of applications in areas such as parallel computing and distributed computing (e.g. [41, 35, 27, 32, 38, 42, 28, 31, 6, 8, 20, 26]). On the other hand, the (approximate) distance preserver problem is a graph sparsification problem. Here, we are given an input graph G and a set of demand pairs P\subseteq V(G)\times V(G), and we need to find a sparse subgraph H of G that preserves all distances between demand pairs in G up to an approximation factor \alpha. Approximate distance preservers are a generalization of another well-studied graph sparsification object, reachability preservers. Distance preservers have applications to problems such as distance oracles [29, 30] and spanners [7, 16, 1, 2, 3, 24, 33, 17]. Despite being graph augmentation and graph sparsification problems respectively, hopsets and distance preservers are known to be related in some ways. For instance, distance preserver lower bounds imply lower bounds for hopsets [39, 11], and small-stretch hopsets can be translated into small-stretch distance preservers in a black-box way [39]. In this paper, we develop better understandings of hopsets and distance preservers in directed graphs. We discuss our results and compare them with prior work in Sections 1.2 and 1.1. 1.1 Preservers The problem of constructing sparse distance preservers is an important basic combinatorial problem with connections to incidence geometry [19, 43], distance oracles [29, 30], and fast graph algorithms [5, 21, 30]. We now formally define the more general object of approximate distance preservers, or approximate preservers for short. Definition 1.1 (Approximate Preservers). Given an n-node graph G and a set of demand pairs P\subseteq V(G)\times V(G) of size |P|=p, a subgraph H of G is an \alpha-approximate distance preserver of G,P if \operatorname{dist}_{H}(s,t)\leq\alpha\cdot\operatorname{dist}_{G}(s,t) for all (s,t)\in P. There are three settings of approximate preservers that have received special attention in prior work: • \alpha=1 (also known as Exact Distance Preservers.) • \alpha=1+\varepsilon (also known as (1+\varepsilon)-Approximate Preservers.) • \alpha=\infty (also known as Reachability Preservers.) Setting Upper Bound Lower Bound Beats Consistency? \alpha=1 undirected O(\min\{n^{1/2}p+n,np^{1/2}\}) [19] \Omega(n^{2/3}p^{2/3}+n) [19] ✗ \alpha=1 undirected unweighted O\left(\min\left\{n^{2/3}p^{2/3}+np^{1/3},\frac{n^{2}}{\texttt{RS}(n)}\right\}\right) [17, 13] \Omega(n^{2/(d+1)}p^{(d-1)/d}) for integer d\geq 1 [19] ✓ \alpha=1 directed O(\min\{n^{2/3}p+n,np^{1/2}\}) [19, 14] \Omega(n^{2/3}p^{2/3}+n) [19] ✗ \alpha=1+\varepsilon undirected \widetilde{O}_{\varepsilon}((n+p)\cdot n^{o(1)}) [39, 30] \Omega(n+p) ✓ \alpha=1+\varepsilon directed \widetilde{O}_{\varepsilon}(n^{2/3}p^{2/3}+np^{1/3}) [39, 18] \Omega(n^{2/(d+1)}p^{(d-1)/d}) for integer d\geq 1 [19] ✓ \alpha=\infty directed O(n^{3/4}p^{1/2}+n^{5/8}p^{11/16}+n) [19, 11] \Omega(n^{2/(d+1)}p^{(d-1)/d}) for integer d\geq 1 [19] ✓ Table 1: Some previous bounds for various settings of approximate preservers on n-node graphs with p demand pairs. We say existing upper bounds for approximate preservers beat consistency if they imply a separation with the bounds for consistent tiebreaking schemes for some p\in[1,n^{2}]. In the second row, \texttt{RS}(n) denotes the Rusza-Szemerédi function from extremal graph theory. Exact distance preservers were first formally introduced in the seminal work of Coppersmith and Elkin [19]. In their work, Coppersmith and Elkin proved upper bounds and lower bounds for exact distance preservers in several different settings. As can be seen in Table 1, many of the bounds proved in [19] are still state-of-the-art. A fundamental tool used in the upper bounds of [19] is consistent tiebreaking schemes. Given an n-node graph G, a tiebreaking scheme roughly corresponds to a collection of shortest paths \Pi in G. Informally, we say that tiebreaking scheme \Pi is consistent if no two shortest paths \pi_{1},\pi_{2}\in\Pi intersect, split apart, and then intersect later again (see Definition 3.2 for a formal definition). Upper bounds for the number of distinct edges in consistent tiebreaking schemes imply upper bounds for exact distance preservers, since we may assume without loss of generality that shortest paths in the input graph are consistent. A line of work initiated by [19] has established tight bounds on the size of consistent tiebreaking schemes. Theorem 1.2 (Consistent Tiebreaking Schemes). Consistent tiebreaking schemes on n nodes and p paths have • \Theta(\min(n^{1/2}p+n,np^{1/2})) edges in undirected graphs [19, 17], and • \Theta(\min(n^{2/3}p+n,np^{1/2})) edges in directed graphs [19, 13, 11]. As we mentioned earlier, upper bounds on the number of edges in consistent tiebreaking schemes yield upper bounds for exact distance preservers, which in turn imply upper bounds for \alpha-approximate preservers for all \alpha>1. Recently, there has been a tremendous amount of progress in constructing approximate preservers with sparsity better than consistent tiebreaking schemes. We summarize this progress below. • Exact distance preservers of size O(n^{2/3}p^{2/3}+np^{1/3}) edges in undirected, unweighted graphs were constructed in [17]. • Almost-optimal (1+\varepsilon)-preservers in undirected graphs were constructed in [39, 30]. Approximate preservers of size \widetilde{O}_{\varepsilon}(n^{2/3}p^{2/3}+np^{1/3}) edges for directed graphs were constructed in [39, 18]. • Reachability preservers of size O(n^{3/4}p^{1/2}+n^{2-\sqrt{2}+o(1)}p^{1/\sqrt{2}}+n) edges were constructed in [11, 12], and online reachability preservers of size O(n^{0.72}p^{0.56}+n^{0.6}p^{0.7}+n) were constructed in [12]. All of these preserver constructions are significantly sparser than consistent tiebreaking schemes in some regime of p. However, as we can see in Table 1, the state-of-the-art bounds for exact distance preservers in weighted (un)directed graphs do not achieve sparsity better than consistent tiebreaking. This motivates the following question. Open Question 1. Is there a separation between exact distance preservers and consistent tiebreaking schemes? In addition to asking when we can separate approximate preservers from consistent tiebreaking schemes, we can also ask whether we can separate different settings of \alpha-approximate preservers from each other. For example, the \Omega(n^{2/3}p^{2/3}) lower bound for exact distance preservers in weighted graphs due to [19], along with the recent progress on reachability preserver upper bounds due to [11], imply a separation between \alpha-approximate preservers when \alpha=1 and \alpha-approximate preservers when \alpha=\infty. However, the following questions remained: Open Question 2. Is there a separation between approximate preservers with finite stretch and approximate preservers with infinite stretch (reachability preservers)? Is there a separation between exact preservers and approximate preservers with finite stretch? Towards answering 1 and 2, we prove the following results for distance preservers: Theorem 1.3 (Main Result 1). For n-node graphs and p demand pairs, the size of the distance preserver is: 1. (Theorem 5.1) \widetilde{O}(n^{5/6}p^{2/3}+n) edges, for exact distance preservers in unweighted graphs, and 2. (Theorem 6.1) \Omega(n^{2/3}p^{2/3}) edges, for any given finite stretch. Remark. At first glance, the lower bound in Theorem 1.3 Item 2 appears to nearly tightly match the \widetilde{O}_{\varepsilon}(n^{2/3}p^{2/3}+np^{1/3}) upper bound for (1+\varepsilon)-approximate preservers due to [39, 18]. However, the upper bounds of [39, 18] hold only for graphs with 2^{\widetilde{O}(1)} aspect ratio, while our lower bound graph has \text{exp}(n) aspect ratio. Theorem 1.3 has the following consequences: • Theorem 1.3 Item 1 answers 1 in the affirmative in the natural graph class of unweighted directed graphs. Specifically, the upper bound of Theorem 1.3 Item 1 beats consistent tiebreaking in the regime of n^{1/2}\leq p\leq n. • Theorem 1.3 Item 2 partially answers 2 in the affirmative for general graphs, establishing a separation between approximate preservers with finite stretch and reachability preservers. This can be verified by comparing the bound in Theorem 1.3 Item 2 to the upper bound for \alpha=\infty in Table 1. Additionally, we establish a new directed-to-undirected reduction for exact distance preservers. Let \textsc{UDP}(n,p) denote the best upper bound for undirected distance preservers on n vertices and p demand pairs, and let \textsc{DDP}(n,p) denotes the same for directed distance preservers. Theorem 1.4 (Main Result 2). If \textnormal{{UDP}}(n,p)=O(n^{\lambda}p^{\mu}+n) for constants \lambda,\mu>0, then \textnormal{{DDP}}(n,p)=O\left(n^{\frac{1}{2-\lambda}}p^{\frac{1+\mu-\lambda}{% 2-\lambda}}+n^{1/2}p+n\right). This reduction has the property that if we plug the state-of-the-art O(n^{1/2}p+n) upper bound for undirected distance preservers into the reduction, we recover the state-of-the-art O(n^{2/3}p+n) upper bound for directed distance preservers. More generally, we obtain the following consequence of the reduction. Corollary 1.5. Consistent tiebreaking is optimal for directed distance preservers when p\leq n^{2/3} only if consistent tiebreaking is optimal for undirected distance preservers when p\leq n. Our reduction makes significant progress on 1. If consistent tiebreaking is optimal for directed distance preservers for p\leq n^{2/3}, then consistent tiebreaking is optimal for undirected distance preservers for p\leq n. Conversely, if consistent tiebreaking is suboptimal in undirected graphs for some p\leq n, then consistent tiebreaking is suboptimal in directed graphs for some p\leq n^{2/3}. Along the way to proving Theorem 1.4, we also obtain the following interesting algorithmic result (Corollary 4.7 in the main body), which does not seem to appear in the literature to the best of our knowledge, though it could be folklore. Corollary 1.6. All-pairs shortest paths (APSP) on n-node, m-edge directed acyclic graphs can be reduced to APSP on n-node, m-edge undirected graphs in O(m) time. A related result is the asymptotic equivalence between all-pairs shortest paths in directed dense graphs and all-pairs shortest paths in undirected dense graphs as shown by Vassilevska Williams and Williams [47]; however, such an equivalence is not known for sparse graphs. 1.2 Hopsets A fundamental problem in algorithm design is how to compute (approximate) shortest paths and reachability in directed graphs efficiently. In many algorithmic settings where we want to compute shortest paths, it is useful to assume that shortest paths in the input graph contain few edges. However, in general this assumption does not hold. Instead, we can try adding a small set of additional edges to the input graph and hope that these edges reduce the lengths of shortest paths. This is the idea behind hopsets, which we now formally define. Definition 1.7 (Approximate Hopsets). Given a graph G, an \alpha-approximate hopset with hopbound \beta is a set of additional edges H such that: • Every edge (u,v)\in H has weight w(u,v)=\operatorname{dist}_{G}(u,v). • For every pair of nodes (s,t) in the transitive closure of G, there exists an s\leadsto t path \pi in G\cup H with at most |\pi|\leq\beta edges and weight at most w(\pi)\leq\alpha\cdot\operatorname{dist}_{G}(s,t). There are three settings of approximate hopsets that have received special attention in prior work: • \alpha=1 (also known as Exact Hopsets.) • \alpha=1+\varepsilon (also known as (1+\varepsilon)-Approximate Hopsets.) • \alpha=\infty (also known as Shortcut Sets.) Setting Size Upper Bound Lower Bound Beats Folklore Sampling? \alpha=1 O(n) O(\sqrt{n}) [46, 15] \widetilde{\Omega}(\sqrt{n}) [9] ✗ \alpha=1+\varepsilon O_{\varepsilon}(n) \widetilde{O}(n^{1/3}) [18] \Omega(n^{1/4}) [9, 48] ✓ \alpha=\infty O(n) \widetilde{O}(n^{1/3}) [40] \Omega(n^{1/4}) [9, 48] ✓ \alpha=\infty O(m) \widetilde{O}((n^{2}/m)^{1/3}) [40] \Omega(n^{1/5}) [48] ✓ Table 2: Some previous bounds on various settings of \alpha-approximate hopsets in directed graphs. Note that the upper bound for \alpha=1+\varepsilon holds specifically for graphs with aspect ratio 2^{\widetilde{O}(1)}. Hopsets were first studied implicitly in the 90’s by Ullman and Yannakakis [46], and defined explicitly by Cohen [22]. In particular, Ullman and Yannakakis gave an implicit construction for exact hopsets using a simple sampling scheme, which has since become folklore (and slightly improved [15]). Theorem 1.8 (Folklore Sampling [46, 15]). Every n-node graph has an O(n)-size hopset with hopbound O(n^{1/2}). While many algorithmic applications for hopsets have been found since the 90’s, no progress had been made on approximate hopset upper bounds in directed graphs until recently. In 2003, Hesse gave the first polynomial lower bounds for O(n)-size and O(m)-size shortcut sets, proving that indeed polynomial hopbound is necessary for hopsets [34]. Nevertheless, it remained open whether the folklore sampling algorithm could be improved, even in the easiest setting of \alpha=\infty. In a breakthrough result by Kogan and Parter [40], it was shown that there exist O(n)-size shortcut sets (\infty-approximate hopsets) with hopbound \widetilde{O}(n^{1/3}). Kogan and Parter also proved that there exist O(n)-size (1+\varepsilon)-approximate hopsets with hopbound \widetilde{O}_{\varepsilon}(n^{2/5}). The hopbound for (1+\varepsilon)-approximate hopsets was subsequently improved to \widetilde{O}_{\varepsilon}(n^{1/3}) by Bernstein and Wein [18], using a careful analysis of approximate shortest paths in directed graphs.222\widetilde{O} hides \operatorname{polylog}(n) factors. The possibility of extending these improvements to exact hopsets was ruled out by [9], where it was proved that O(n)-size hopsets have hopbound \widetilde{\Omega}(n^{1/2}) in the worst case. This lower bound proved that folklore sampling is indeed optimal for exact hopsets. Additionally, this lower bound, along with the upper bounds of [40, 18], established a separation between exact hopsets and approximate hopsets. However, the following question remained: Open Question 3. Is there a separation between approximate hopsets with finite stretch and approximate hopsets with infinite stretch (shortcut sets)? One of the barriers to making progress on this question is that all known lower bounds for hopsets follow from existing lower bounds for shortcut sets (with the exception of [9, 39]). Indeed, while there has been a long series of work improving lower bounds for shortcut sets [34, 37, 44, 9, 48], there has been relatively little progress in proving lower bounds for hopsets that surpass existing lower bounds for shortcut sets. This barrier motivates the following question. Open Question 4. Can we prove new lower bounds for hopsets that surpass existing lower bounds for shortcut sets? Towards answering these open questions, we show a range of new lower bounds for various settings of hopsets, summarized in Theorem 1.9 below: Theorem 1.9 (Main Result 3). For hopsets in directed graphs, the hopbound is: 1. (Theorem 7.1.) \Omega(n^{1/2}) for O(n)-size approximate hopsets with any given finite stretch, 2. (Theorem 8.1.) \Omega(n^{2/9}) for O(m)-size hopsets and stretch infinity (shortcut sets), and 3. (Theorem 9.1.) \Omega(n^{2/7}), for O(m)-size exact hopsets, in unweighted graphs (this bound holds even for undirected graphs). Remark. At first glance, the \Omega(n^{1/2}) lower bound in Item 1 of Theorem 1.9 for O(n)-size approximate hopsets seems to contradict the O(n^{1/3}) upper bound for \widetilde{O}_{\varepsilon}(n)-size (1+\varepsilon)-approximate hopsets due to [18]. However, the upper bounds of [18] hold only for graphs with 2^{\widetilde{O}(1)} aspect ratio. Our lower bound graph has \text{exp}(n) aspect ratio. Theorem 1.9 has the following consequences: • Theorem 1.9 Item 1 answers 3 in the affirmative for general graphs. In particular, it shows that for graphs with exponential aspect ratio, the folklore sampling O(\sqrt{n}) bound of [46, 15] is optimal. • Theorem 1.9 Item 1 also separates approximate hopsets in graphs with polynomial aspect ratio from approximate hopsets in graphs with exponential aspect ratio. This is highly unusual behavior in network design problems. For example, in undirected graphs the state-of-the-art bounds for multiplicative spanners [4], approximate distance preservers [39], and hopsets [28, 36, 39] have no dependency on the aspect ratio of the input graph. • Theorem 1.9 Item 2 improves the previous \Omega(n^{1/5}) lower bound for O(m)-size shortcut sets from [48] to \Omega(n^{2/9}). • Theorem 1.9 Item 3 makes progress on 4. The best known lower bound for O(m)-size shortcut is \Omega(n^{2/9}), as shown in Item 2. Our bound in Item 3 beats the current best bound for O(m)-size shortcut, establishing another example where the current best lower bound for some setting of hopset is higher than that for shortcut set. In fact, our \Omega(n^{2/7}) lower bound is even higher than the \Omega(n^{1/4}) lower bound for O(n)-size shortcut set [9, 48]. Improving existing lower bounds for O(n)-size shortcut set beyond \Omega(n^{1/4}) is likely to be difficult due to known barriers for improving reachability preserver lower bounds [11]."
https://arxiv.org/html/2411.08765v1,Tolerant Testing of Stabilizer States with Mixed State Inputs,"We study the problem of tolerant testing of stabilizer states. In particular, we give the first such algorithm that accepts mixed state inputs. Formally, given a mixed state \rho that either has fidelity at least \varepsilon_{1} with some stabilizer pure state or fidelity at most \varepsilon_{2} with all such states, where \varepsilon_{2}\leq\varepsilon_{1}^{O(1)}, our algorithm distinguishes the two cases with sample complexity \poly(1/\varepsilon_{1}) and time complexity O(n\cdot\poly(1/\varepsilon_{1})).","In the property testing model, one is given an input state \rho and a class of states \mathcal{P}, known as a property, and must decide whether \rho is in \mathcal{P} or far from every state in \mathcal{P}. We refer to [MW16] for an introduction to quantum property testing. This task can be generalized to tolerant testing (which was introduced classically in [PRR06]): is \rho \varepsilon_{1}-close to something in \mathcal{P} or \varepsilon_{2}-far from everything in \mathcal{P}? Formally, denoting the fidelity between states \rho and \sigma as \mathcal{F}(\rho,\sigma), the problem is as follows: Problem 1.1. Fix a set of quantum states \mathcal{P} (this is usually referred to as a property) that is known in advance. Given copies of an unknown quantum state \rho and parameters \varepsilon_{1} and \varepsilon_{2} such that 1\geq\varepsilon_{1}>\varepsilon_{2}\geq 0, decide if \sup_{\sigma\in\mathcal{P}}\mathcal{F}(\rho,\sigma)\geq\varepsilon_{1} or \sup_{\sigma\in\mathcal{P}}\mathcal{F}(\rho,\sigma)\leq\varepsilon_{2} promised that one of the cases is true. Significant process has been made when \mathcal{P} is the set of stabilizer states. The fidelity to the closest stabilizer state \ket{\phi} is commonly referred to as the stabilizer fidelity \mathcal{F}(\rho)\coloneqq\max_{\ket{\phi}}\braket{\phi}{\rho}{\phi}. The first test was introduced by [GNW21] (henceforth, the GNW test) for when \varepsilon_{1}=0, with follow-up work by [Dam18]. [GIKL23b, GIKL24a] made the first steps towards tolerant testing by improving the completeness beyond \varepsilon_{1}=0 for GNW test, but the soundness analysis has limitations in certain regimes. This has now been (partially) remedied by [AD24, ABD24, BvDH24, MT24] by giving an improved soundness analysis in the ‘far’ setting of stabilizer state property testing. We note that [HK23] gave a related test with perfect completeness, but (to the authors’ knowledge) no rigorous proof of soundness exists. [BGJ23] derive a quantum generalization of the convolution and give a tolerant test with identical performance to the GNW test on pure states. The test works by making a pure state become more mixed the farther it is from a stabilizer state. The purity of the resulting state can then be measured using a SWAP test. [HH24] interestingly gave the first test that only uses single-copy measurements with provable soundness guarantees, but (to the authors’ knowledge) no provable completeness analysis beyond \varepsilon_{1}=0 has been given, and it also has an inherent system-size dependence, unlike the work using the GNW test. 1.1 This Work The major caveat is that in the analysis of all of the previous works on stabilizer state property testing, the input state was assumed to be a pure state. Due to the inherent nature of property testing and noise, an algorithm that works when given mixed state inputs is desirable. To that end, we propose a new test, based on the GNW test, that provably works for mixed state inputs. Theorem 1.2. Let \varepsilon_{1},\varepsilon_{2}\in[0,1] such that \varepsilon_{2}\leq O\!\left(\varepsilon_{1}^{O(1)}\right). There exists an algorithm that takes \poly(1\varepsilon_{1}) copies of \rho and n\cdot\poly(1/\varepsilon_{1}) time and can perform property testing in this scenario with success probability greater than 2/3 even when the input is a mixed state. Our new test and accompanying proof has the following properties: 1. Performs identically to that of [GNW21] and follow-up work [GIKL23b, GIKL24a, AD24, ABD24, BvDH24, MT24] on pure states, 2. Provides equivalent scaling in terms of stabilizer fidelity compared to that of recent art [GIKL24a, ABD24, BvDH24], even when given mixed states. 3. Maintains the same asymptotic runtime per iteration and hardware requirements as the previous tests. We establish this result by generalizing and modifying the proofs of tolerant stabilizer testing in the pure state input setting of [GIKL24a, AD24, ABD24, BvDH24] to when the input state is mixed. We also show that the symplectic Fourier spectrum of the Pauli decomposition for mixed states has interesting properties that likely warrant further study. We note that the GNW test has additional nice properties such as 1) uses 6 copies per iteration, 2) runs in linear time per iteration, 3) uses only 2 copies at any given time, 4) only uses Clifford gates, and 5) no additional ancilla qubits. Our new test matches the GNW test in these properties. Additionally, for any pure input state \ket{\psi}, the two tests have identical acceptance probabilities, so that any future updates to pure state input analyses will immediately extend to this test. Remark 1.3. The bounds that we achieve are equivalent to [GIKL23b, GIKL24a] in the completeness case, and those of [AD24, ABD24, BvDH24] in the soundness case.111They also match [GNW21, GIKL24a] in the close regime. See Appendix A. That said, there has been no real attempt made by any work yet (including this one) to optimize these constants. During the writing this note, [MT24] has since come out with a better dependence on the exponent for soundness. It is not immediately clear (to the authors) how to generalize their proofs to the mixed state case, since it (at the intuitive level) relies on a connection with phase states, which are inherently pure states. Related Works After writing this note, we became aware that the measurement that our test implements is identical to that of [HLK24, Algorithm 1] with n=3. However, their analysis is solely for pure states, as they use the property that p_{\Psi}, the squares of the coefficients in the Pauli decomposition, forms a distribution to then study the entropy of p_{\Psi} (i.e., the stabilizer entropy). Much of their analysis is very specific to properties of p_{\Psi} that do not hold when moving to p_{\rho}."
https://arxiv.org/html/2411.08355v1,Communication Efficient Decentralization for Smoothed Online Convex Optimization,"We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where N agents interact through a communication graph. In each round, each agent i receives a strongly convex hitting cost function f^{i}_{t} in an online fashion and selects an action x^{i}_{t}\in\mathbb{R}^{d}. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs f^{i}_{t}(x^{i}_{t}), a temporal “switching cost” for changing decisions, and a spatial “dissimilarity cost” that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon T and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.","We study a class of multi-agent smoothed online convex optimization (SOCO) problems where each agent i\in\{1,\ldots,N\}=[N] has to take online decision x^{i}_{t}\in\mathbb{R}^{d} in response to strongly convex hitting costs f^{i}_{t}(\cdot) while keeping in mind that it is additionally penalized for a temporal switching cost \frac{1}{2}\|x^{i}_{t}-x^{i}_{t-1}\|_{2}^{2} and a spatial dissimilarity cost s_{t}^{(i,j)}\big{(}x^{i}_{t},x^{j}_{t}\big{)}, with respect to agent j’s action, when they share an edge in graph \mathcal{G}_{t}=([N],\mathcal{E}_{t}). The dissimilarity cost penalizes deviations in decisions among neighboring agents. These costs emerge from the necessity for neighboring agents to coordinate their actions, and they are particularly important in statistical inference [73], dynamic multi-product pricing [69, 50], graph based combinatorial optimization [35, 28, 29] and economic team theory [57, 58]. We consider this problem over a finite time horizon T, where at time t\in[T], agents can only communicate their actions amongst each other along the edges of the graph \mathcal{G}_{t}. While the single-agent SOCO problem has received significant attention over the last decade due to its wide range of applications in data center management [47, 46, 53], power systems [61, 52, 40], electrical vehicle charging [30, 41], video transmission [38, 20] and chip thermal management [80, 81], its decentralization has remained a crucial challenge for large-scale implementations. This multi-agent problem emerges in areas like power systems control [60, 68], formation control [21, 62] and multi-product price optimization [15, 13, 34]. Appendix A summarizes the literature in SOCO, online decentralized optimization and its applications. The combination of dissimilarity cost and switching costs induces a complex spatio-temporal coupling of decisions across agents, which makes the design of decentralized algorithms particularly challenging. It is not hard to see that a naive handling of this coupling may lead to arbitrarily bad performance over the horizon T (e.g., see Appendix H). To the best of our knowledge, the only work that attempts to provide a decentralized competitive algorithm in a related framework is by Lin et al. [48], which proposed a variation of Model Predictive Control (MPC) called Localized Predictive Control (LPC). However, their algorithm depends on perfect predictions of future cost functions and involves communication of infinite-dimensional hitting cost functions among all agents. This motivates the following question, which forms the basis of this paper: “Is it possible to design a scalable, decentralized online algorithm that matches the performance of the centralized optimal?"" Contributions. We design the first decentralized algorithm: Alternating Coupled Online Regularized Descent (acord, Algorithm 1) that maintains a near-optimal competitive ratio (Theorem 4.1) without communication of hitting costs amongst the agents and without the use of predictions. Further, acord is computationally efficient, using only d-dimensional agent-local computations. Additionally, we prove that acord asymptotically matches the performance of the online optimal, fully centralized algorithm robd [31], without requiring agents to communicate hitting costs (Theorem 3.1). This makes it the first algorithm in the decentralized SOCO literature with zero inherent bias. We emphasize that Algorithm 1’s performance guarantees hold in general and dynamic environments, including heterogeneous hitting costs between agents, heterogeneous dissimilarity costs across edges of the graph, and dynamically changing graph structures \mathcal{G}_{t}. Our results also highlight the dependence of the performance guarantees for Algorithm 1 on the graph properties. In particular, the runtime complexity of Algorithm 1 for \mathcal{D}-regular graphs is \Theta\left(\mathcal{D}\log(N\mathcal{D})\right) (Theorem 4.5). The weak dependence on N highlights the scalability of the algorithm, and the strong dependence on \mathcal{D} indicates the dissimilarity’s cost’s influence. Underlying our results is a new analytic approach that addresses the challenges of decentralizing computations in the SOCO setting. We adapt tools from offline optimization to the SOCO framework, combining the Alternating Minimization approach [9] (from block-iterative algorithms) and the use of auxiliary variables (in Decentralized ADMM [66, 55, 54, 56]) with techniques from the SOCO literature to build the acord algorithm."
https://arxiv.org/html/2411.07782v1,Elastic-Degenerate String Comparison,"An elastic-degenerate (ED) string T is a sequence of n sets T[1],\ldots,T[n] containing m strings in total whose cumulative length is N. We call n, m, and N the length, the cardinality and the size of T, respectively. The language of T is defined as \mathcal{L}(T)=\{S_{1}\cdots S_{n}\,:\,S_{i}\in T[i]\text{ for all }i\in[1,n]\}. ED strings have been introduced to represent a set of closely-related DNA sequences, also known as a pangenome. The basic question we investigate here is: Given two ED strings, how fast can we check whether the two languages they represent have a nonempty intersection? We call the underlying problem the ED String Intersection (EDSI) problem. For two ED strings T_{1} and T_{2} of lengths n_{1} and n_{2}, cardinalities m_{1} and m_{2}, and sizes N_{1} and N_{2}, respectively, we show the following:There is no \mathcal{O}((N_{1}N_{2})^{1-\epsilon})-time algorithm, thus no \mathcal{O}\left((N_{1}m_{2}+N_{2}m_{1})^{1-\epsilon}\right)-time algorithm and no \mathcal{O}\left((N_{1}n_{2}+N_{2}n_{1})^{1-\epsilon}\right)-time algorithm, for any constant \epsilon>0, for EDSI even when T_{1} and T_{2} are over a binary alphabet, unless the Strong Exponential-Time Hypothesis is false.There is no combinatorial \mathcal{O}((N_{1}+N_{2})^{1.2-\epsilon}f(n_{1},n_{2}))-time algorithm, for any constant \epsilon>0 and any function f, for EDSI even when T_{1} and T_{2} are over a binary alphabet, unless the Boolean Matrix Multiplication conjecture is false.An \mathcal{O}(N_{1}\log N_{1}\log n_{1}+N_{2}\log N_{2}\log n_{2})-time algorithm for outputting a compact (RLE) representation of the intersection language of two unary ED strings. In the case when T_{1} and T_{2} are given in a compact representation, we show that the problem is NP-complete.An \mathcal{O}(N_{1}m_{2}+N_{2}m_{1})-time algorithm for EDSI.An \mathcal{\tilde{O}}(N_{1}^{\omega-1}n_{2}+N_{2}^{\omega-1}n_{1})-time algorithm for EDSI, where \omega is the exponent of matrix multiplication; the \mathcal{\tilde{O}} notation suppresses factors that are polylogarithmic in the input size.We also show that the techniques we develop here have many applications even outside of bioinformatics.","Sequence (or string) comparison is a fundamental task in computer science, with numerous applications in computational biology [37], signal processing [25], information retrieval [10], file comparison [38], pattern recognition [6], security [53], and elsewhere [54]. Given two or more sequences and a distance function, the task is to compare the sequences in order to infer or visualize their (dis)similarities [23]. Many sequence representations have been introduced over the years to account for unknown or uncertain letters, a phenomenon that often occurs in data that comes from experiments [12]. In the context of computational biology, for example, the IUPAC notation [42] is used to represent loci in a DNA sequence for which several alternative nucleotides are possible as variants. This gives rise to the notion of degenerate string (or indeterminate string): a sequence of finite sets of letters [3]. When all sets are of size 1, we are in the special case of a standard string (or deterministic string). Degenerate strings can encode the consensus of a population of DNA sequences [26] in a gapless multiple sequence alignment (MSA). Iliopoulos et al. generalized this notion to also encode insertions and deletions (gaps) occurring in MSAs by introducing the notion of elastic-degenerate string: a sequence of finite sets of strings [39]. The main motivation to consider elastic-degenerate (ED) strings is that they can be used to represent a pangenome: a collection of closely-related genomic sequences that are meant to be analyzed together [58]. Several other, more powerful, pangenome representations have been proposed in the literature, mostly graph-based ones; see the comprehensive survey by Carletti et al. [20] or by Baaijens et al. [7]. Compared to these more powerful representations, ED strings have algorithmic advantages, as they support: (i) fast and simple on-line string matching [36, 21]; (ii) (deterministic) subquadratic string matching [4, 14, 15]; and (iii) efficient approximate string matching [16, 13]. Our main goal here is to give the first algorithms and lower bounds for comparing two pangenomes represented by two ED strings.111Pangenome comparison is one of the central goals of two large EU funded projects on computational pangenomics: PANGAIA (https://www.pangenome.eu/) and ALPACA (https://alpaca-itn.eu/). We consider the most basic notion of matching, namely, to decide whether two ED strings, each encoding a language, have a nonempty intersection. Like with standard strings, algorithms for pairwise ED string comparison can serve as computational primitives for many analysis tasks (e.g., phylogeny reconstruction); lower bounds for pairwise ED string comparison can serve as meaningful lower bounds for the comparison of more powerful pangenome representations such as, for instance, variation graphs [20]. Let us start with some basic definitions and notation. An alphabet \Sigma is a finite nonempty set of elements called letters. By \Sigma^{*} we denote the set of all strings over \Sigma including the empty string \varepsilon of length 0. For a string S=S[1]\cdots S[n] over \Sigma, we call n=|S| its length. The fragment S[i\mathinner{.\,.}j] of S is an occurrence of the underlying substring P=S[i]\cdots S[j]. We also say that P occurs at position i in S. A prefix of S is a fragment of S of the form S[1\mathinner{.\,.}j] and a suffix of S is a fragment of S of the form S[i\mathinner{.\,.}n]. An elastic-degenerate string (ED string, in short) T is a sequence T=T[1]\cdots T[n] of n finite sets, where T[i] is a subset of \Sigma^{*}. The total size of T is defined as N=N_{\varepsilon}+\sum^{n}_{i=1}\sum_{S\in T[i]}|S|, where N_{\varepsilon} is the total number of empty strings in T. By m we denote the total number of strings in all T[i], i.e., m=\sum_{i=1}^{n}|T[i]|. We say that T has length n=|T|, cardinality m and size N=||T||. An ED string T can be treated as a compacted nondeterministic finite automaton (NFA) with n+1 states, called segments, numbered 1,\ldots,n+1, and m transitions labeled by strings in \Sigma^{*}. State 1 is starting and state n+1 is accepting. For each index i\in[1,n] and string S\in T[i], there is a transition from state i to state i+1 with label S; inspect also Fig. 1 for an example. The language \mathcal{L}(T) generated by the ED string T is the language accepted by this compacted NFA. That is, \mathcal{L}(T)=\{S_{1}\cdots S_{n}\,:\,S_{i}\in T[i]\text{ for all }i\in[1,n]\}. Figure 1: An example of an MSA and its corresponding (non-unique) ED string T of length n=7, cardinality m=11 and size N=20, and the compacted NFA for T. The compacted NFA can be seen as a special case of an edge-labeled directed acyclic graph. We next define the main problem in scope; inspect also Figure 2 for an example. ED String Intersection (EDSI) Input: Two ED strings, T_{1} of length n_{1}, cardinality m_{1} and size N_{1}, and T_{2} of length n_{2}, cardinality m_{2} and size N_{2}. Output: YES if \mathcal{L}(T_{1}) and \mathcal{L}(T_{2}) have a nonempty intersection, NO otherwise. Figure 2: An example of two ED strings T_{1} and T_{2} with their parameters and the intersection of their languages. In this instance, we see that \mathcal{L}(T_{1}) and \mathcal{L}(T_{2}) have a nonempty intersection. Our Results We make the following specific contributions: 1. In Section 2.1, we give several conditional lower bounds. In particular, we show that there is no \mathcal{O}((N_{1}N_{2})^{1-\epsilon})-time algorithm, thus no \mathcal{O}\left((N_{1}m_{2}+N_{2}m_{1})^{1-\epsilon}\right)-time algorithm and no \mathcal{O}\left((N_{1}n_{2}+N_{2}n_{1})^{1-\epsilon}\right)-time algorithm, for any constant \epsilon>0, for EDSI even when T_{1} and T_{2} are over a binary alphabet, unless the Strong Exponential-Time Hypothesis (SETH) [40, 41] or the Orthogonal Vectors (OV) conjecture [62] is false. 2. In Section 2.2, we present other conditional lower bounds. In particular, we show that there is no combinatorial222The notion of “combinatorial algorithm” is informal but widely used in the literature. Typically, we call an algorithm “combinatorial” if it does not not call an oracle for ring matrix multiplication. \mathcal{O}((N_{1}+N_{2})^{1.2-\epsilon}f(n_{1},n_{2}))-time algorithm, for any constant \epsilon>0 and any function f, for EDSI even when T_{1} and T_{2} are over a binary alphabet, unless the Boolean Matrix Multiplication (BMM) conjecture [1] is false. 3. In Section 3, we show an \mathcal{O}(N_{1}\log N_{1}\log n_{1}+N_{2}\log N_{2}\log n_{2})-time algorithm for outputting a compact (RLE) representation of the intersection language of two unary ED strings. In the case when T_{1} and T_{2} are given in a compact representation, we show that the problem is NP-complete. 4. In Section 4.1, we show an \mathcal{O}(N_{1}m_{2}+N_{2}m_{1})-time combinatorial algorithm for EDSI in which we assume that the ED strings are over an integer alphabet [1,(N_{1}+N_{2})^{\mathcal{O}(1)}]. 5. In Section 4.2, we show an \mathcal{\tilde{O}}(N_{1}^{\omega-1}n_{2}+N_{2}^{\omega-1}n_{1})-time algorithm for EDSI, where \omega is the matrix multiplication exponent. Interestingly, we show that the techniques we develop here have applications outside of bioinformatics. Given a sequence P=P_{1},\ldots,P_{n} of n standard strings, we define an acronym of P as a string A=A_{1}\cdots A_{n}, where A_{i} is a possibly empty prefix of P_{i}, for all i\in[1,n]. In the Acronym Generation (AG) problem, we are given a dictionary D of k strings of total length K and a sequence P of n strings of total length N, and we are asked to say YES if and only if some acronym of P belongs to D. In Section 5, we show how our techniques for EDSI can be modified to solve AG in \mathcal{O}(nK+N) time. In Section 6, we show how intersection graphs can be used to solve different ED string comparison tasks. In Section 7, we show how intersection graphs can be used for string matching in the general case when both the pattern and the text are ED strings. In Section 8, we extend our results for EDSI to the approximate case (under the Hamming or edit distance). We conclude this paper in Section 9 with some open problems. This is a full and extended version of a conference paper [31]. Related Work Apart from its applications to pangenome comparison, EDSI is interesting theoretically on its own as a special case of regular expression (regex) matching. Regex is a basic notion in formal languages and automata theory. Regular expressions are commonly used in practical applications to define search patterns. Regex matching and membership testing are widely used as computational primitives in programming languages and text processing utilities (e.g., the widely-used agrep). The classic algorithm for solving these problems constructs and simulates an NFA corresponding to the regex, which gives an \mathcal{O}(MN) running time, where M is the length of the pattern and N is the length of the text. Unfortunately, significantly faster solutions are unknown and unlikely [8]. However, much faster algorithms exist for many special cases of the problem: dictionary matching, wildcard matching, subset matching, and the word break problem (see [8] and references therein) as well as for sparse regex matching [17]. Special cases of EDSI have also been studied. First, let us consider the case when both T_{1} and T_{2} are degenerate strings. In this case, the problem is trivial: EDSI has a positive answer if and only if for every i, T_{1}[i]\cap T_{2}[i] is nonempty. Alzamel et al. [2, 3] studied the case when T_{1} and T_{2} are generalized degenerate strings: for any i\in[1,n_{1}] and j\in[1,n_{2}] all strings in T_{1}[i] have the same length \ell_{1,i} and all strings in T_{2}[j] have the same length \ell_{2,j}. In the case of generalized degenerate strings, they showed that deciding if \mathcal{L}(T_{1}) and \mathcal{L}(T_{2}) have a nonempty intersection can be done in \mathcal{O}(N_{1}+N_{2}) time. If T_{2} is a standard string, i.e., an ED string with m_{2}=n_{2}=1, then we can resort to the results of Bernardini et al. [15] for ED string matching. In particular: there is no combinatorial algorithm for EDSI working in \mathcal{O}(n_{1}N_{2}^{1.5-\epsilon}+N_{1}) time unless the BMM conjecture is false; and we can solve EDSI in \mathcal{\tilde{O}}(n_{1}N_{2}^{\omega-1}+N_{1}) time. Moreover, Gawrychowski et al. [34] provided a systematic study of the complexity of degenerate string comparison under different notions of matching: Cartesian tree matching; order-preserving matching; and parameterized matching. Similar to ED strings (and to generalized degenerate strings) is the representation of pangenomes via founder graphs. The idea behind founder graphs is that a multiple alignment of few founder sequences can be used to approximate the input MSA, with the feature that each row of the MSA is a recombination of the founders. Like founder graphs, ED strings support the recombination of different rows of the MSA between consecutive columns. Unlike ED strings, for which no efficient index is probable [35] (and indeed their value is to enable fast on-line string matching), some subclasses of founder graphs are indexable, and a recent research line is devoted to constructing and indexing such structures [5, 28, 52, 55]. In general, both ED strings and founder graphs are special cases of labeled graphs. Unfortunately, indexing labeled graphs is unlikely to have an efficient solution [27]."
https://arxiv.org/html/2411.07553v1,A Simple Algorithm for Dynamic Carpooling with Recourse,"We give an algorithm for the fully-dynamic carpooling problem with recourse: Edges arrive and depart online from a graph G with n nodes according to an adaptive adversary. Our goal is to maintain an orientation H of G that keeps the discrepancy, defined as \max_{v\in V}|\deg_{H}^{+}(v)-\deg_{H}^{-}(v)|, small at all times.We present a simple algorithm and analysis for this problem with recourse based on cycles that simplifies and improves on a result of Gupta et al. [SODA ’22].","In this paper, we consider the graphical carpooling problem: Given a graph G=(V,E), find an orientation H of G that minimizes the discrepancy, which is the absolute difference between the in-degree and out-degree of any vertex i.e. \max_{v\in V}|\deg^{-}_{H}(v)-\deg^{+}_{H}(v)|. The problem was first studied by Ajtai et al. [AAN+98] as a special case of the general carpooling problem for hypergraphs posed by Faige and Williams in [FW83] and is motivated by fairness in scheduling. Indeed, the above problem exactly corresponds to a set of drivers who wish to carpool in pairs where each driver wishes to drive roughly half the time. If all the edges of the graph are known beforehand, a simple scheme of directing cycles yields a solution of discrepancy at most one. That said, the more natural setting is arguably when the edges arrive online. In this setting, edges arrive sequentially, and one must irrevocably decide on the orientation of an edge before observing the next edge in the sequence. In this model, [AAN+98] showed that in the presence of an adaptive adversary, any orientation algorithm must have \Omega(n) discrepancy in the worst case. There are several approaches in the literature for circumventing such a lower bound. One, explored in [AAN+98, GKKS20], considers a stochastic version of the problem, namely when edge arrivals are sampled from a known distribution. In such a setting, [GKKS20] obtain a solution achieving \mathrm{polylog}(n,m)-discrepancy. In a recent work, [ALS21] improved this bound by showing that one can achieve discrepancy O(\log(nm)) in the presence of any oblivious adversary. In fact, they proved this result for the more general \mathsf{OnlineVectorBalancing} problem, where vectors v_{1},\dots,v_{m}\in\mathbb{R}^{n} with \|v_{i}\|_{2}=O(1) arrive online and must be assigned \pm 1 signs \varepsilon_{1},\dots,\varepsilon_{m} so as to minimize \max_{t}\|\sum_{i\leq t}\varepsilon_{i}v_{i}\|_{\infty}. Note this is more general as the online graphical carpooling problem can be written as a special instance of the vector balancing problem in which the vectors are of the form e_{j}-e_{k} for j,k\in[n]. An additional approach, mainly aimed at circumventing the adaptive lower bound, is by introducing recourse, i.e. allowing the player to change the orientation of a limited number of edges each time a new edge arrives. We refer to the number of edges whose sign has changed as the recourse. With such a relaxation, one can consider an even harder model in which the player is required to maintain good discrepancy not only under edge arrivals (henceforth called insertion updates) but also edge removals (henceforth called deletion updates). This setting is usually dubbed the Fully-Dynamic setting. The work of [GGK+22] was the first to consider such a setting for both the graphical carpooling problem and the \mathsf{OnlineVectorBalancing} problem. For \mathsf{OnlineVectorBalancing}, they show that one can deterministically maintain a near-optimal discrepancy of O(\sqrt{\log(n)}) with amortized recourse of O(n\log m) per update. For the fully-dynamic, graphical carpooling problem, they design a deterministic algorithm achieving O(\log^{7}n) discrepancy and amortized recourse of O(\log^{5}n) per update. While their algorithm for \mathsf{OnlineVectorBalancing} is simple and elegant, their result in the carpooling setting involves clever and sophisticated machinery that maintains an expander decomposition of the graph and orients edges via a local search procedure. In this work, we present both a simplification of their result for the graphical carpooling problem and an improvement upon their parameters. Namely, our main result is the following Theorem 1. Theorem 1. There exists a deterministic algorithm for the fully-dynamic, graphical carpooling problem that maintains a solution of discrepancy 3 and worst case recourse O(\log^{2}(n)). Our main technical tool and major difference to the work of [GGK+22] is noticing that maintaining a solution for graphs with no short cycles, i.e. a graph of high girth, is simple (cf. Lemma 5). For a general graph, we can then maintain a solution to a high girth subgraph H. If the addition of an edge creates a short cycle in H, we simple remove all edges in the cycle from H and direct the cycle clockwise. For deletions, our algorithm for high girth graphs can handle the removal of any edge from H (cf. Lemma 5). On the other hand, if we delete an edge e from a short cycle C, then we remove every edge from the cycle C and subsequently simulate inserting every edge in C\setminus e to update our orientation. Conceptually, we note that when the edges are viewed as vectors vis-à-vis the correspondence described in the reduction to the \mathsf{OnlineVectorBalancing} problem short cycles correspond exactly to linear dependencies, which also form the backbone for the algorithm of [GGK+22] for the \mathsf{OnlineVectorBalancing} problem that achieves O(n\log(m)) recourse. We note that while our algorithms are efficient, we do not pay close attention to their run times. That said, a closely related problem for which dynamic graph algorithms are well-studied is to minimize the maximum out-degree, rather than the discrepancy. Various algorithms achieve tradeoffs between update time, maximum out-degree, and number of edge flips, typically in (pseudo) forests. Brodal and Fagerberg [BF99] showed that maintaining an orientation with bounded out-degree takes amortized O({\log n}) insertion time and worst-case O(1) deletion time. Several works have given improved results and different tradeoffs, see, e.g. [HTZ14, KKPS14, BB17, BKK+21] for more details."
https://arxiv.org/html/2411.07526v1,QR Sort: A Novel Non-Comparative Sorting Algorithm,"In this paper, we introduce and prove QR Sort, a novel non-comparative integer sorting algorithm. This algorithm uses principles derived from the Quotient-Remainder Theorem and Counting Sort subroutines to sort input sequences stably. QR Sort exhibits the general time and space complexity \mathcal{O}(n+d+\frac{m}{d}), where n denotes the input sequence length, d denotes a predetermined positive integer, and m denotes the range of input sequence values plus 1. Setting d=\sqrt{m} minimizes time and space to \mathcal{O}(n+\sqrt{m}), resulting in linear time and space \mathcal{O}(n) when m\leq\mathcal{O}(n^{2}). We provide implementation optimizations for minimizing the time and space complexity, runtime, and number of computations expended by QR Sort, showcasing its adaptability. Our results reveal that QR Sort frequently outperforms established algorithms and serves as a reliable sorting algorithm for input sequences that exhibit large m relative to n.","In computer science, sorting algorithms arrange sequences of values into a specific order to improve data processing and optimize performance across various computational tasks (Cormen et al., 2009). Common operations that benefit from sorting include binary search for quick lookup (Lin, 2023), median finding for statistical analysis (Schönhage et al., [n. d.]), and prioritization for organizing tasks (Khan and Rehman, [n. d.]). Comparison-based algorithms represent a common sorting paradigm that leverages a specified abstract comparison operator, such as “less than or equal to,” to order elements in a given sequence (Dey, 2021). These algorithms possess the proven lower bound time complexity \mathcal{O}(n\log{n}), where n denotes the length of the input sequence S (Morris, [n. d.]). Time complexity helps assess the general performance of algorithms by bounding the computational time relative to the given input size. Likewise, space complexity helps assess algorithm performance by bounding the memory required relative to input size (Cormen et al., 2009). Comparison-based algorithms may each possess different space complexities. Merge Sort and Quicksort (Cormen et al., 2009) serve as classic examples of comparison-based sorting algorithms. We provide the time and space complexities of these algorithms in Table 1. Non-comparative integer sorting algorithms classify a distinct group of sorting methods with no proven lower-bound time complexity greater than \mathcal{O}(n). These algorithms associate input values with integer keys and distribute them into ordered bins to enable efficient derivation of the final sorted order, circumventing the comparison-based lower bound (Cormen et al., 2009). This paper introduces QR Sort, a novel non-comparative integer sorting algorithm that divides each input element by a user-specified divisor and uses the acquired quotient and remainder values as sorting keys. We proved QR Sort qualifies as a stable sorting algorithm that ensures elements with equal keys maintain their initial relative order after sorting (Tang, 2012). We also provided implementation optimizations for the time and space complexity, runtime, and number of computations expended by QR Sort. Our results reveal that QR Sort frequently outperforms established algorithms and serves as a reliable sorting algorithm for input sequences that exhibit larger input sequence element ranges."
https://arxiv.org/html/2411.07505v1,Subsetwise and Multi-Level Additive Spanners with Lightness Guarantees,"An (\alpha,\beta) spanner of an edge weighted graph G=(V,E) is a subgraph H of G such that for every pair of vertices u and v, d_{H}(u,v)\leq\alpha\cdot d_{G}(u,v)+\beta W, where d_{G}(u,v) is the shortest path length from u to v in G; we consider two settings: in one setting W=W_{G}(u,v), the maximum edge weight in a shortest path from u to v in G, and in the other setting W=W_{max}, the maximum edge weight of G.If \alpha>1 and \beta=0, then H is called a multiplicative \alpha-spanner. If \alpha=1, then H is called an additive +\beta W spanner. While multiplicative spanners are very well studied in the literature, spanners that are both additive and lightweight have been introduced more recently [Ahmed et al., WG 2021]. Here the lightness is the ratio of the spanner weight to the weight of a minimum spanning tree of G. In this paper, we examine the widely known subsetwise setting when the distance conditions need to hold only among the pairs of a given subset S. We generalize the concept of lightness to subset-lightness using a Steiner tree and provide polynomial-time algorithms to compute subsetwise additive +\epsilon W(\cdot,\cdot) spanner and +(4+\epsilon)W(\cdot,\cdot) spanner with O_{\epsilon}(|S|) and O_{\epsilon}(|V_{H}|^{1/3}|S|^{1/3}) subset-lightness, respectively, where \epsilon is an arbitrary positive constant. We next examine a multi-level version of spanners that often arises in network visualization and modeling the quality of service requirements in communication networks. The goal here is to compute a nested sequence of spanners with the minimum total edge weight. We provide an e-approximation algorithm to compute multi-level spanners assuming that an oracle is given to compute single-level spanners, improving a previously known 4-approximation [Ahmed et al., IWOCA 2023].","Given a graph G, a spanner of G is a subgraph that preserves lengths of shortest paths in G up to some multiplicative or additive error [26, 25]. A subgraph H=(V,E^{\prime}\subseteq E) of G is called a multiplicative \alpha–spanner if the lengths of shortest paths in G are preserved in H up to a multiplicative factor of \alpha, that is, d_{H}(u,v)\leq\alpha\cdot d_{G}(u,v) for all u,v\in V, where d_{G}(u,v) denotes the length of the shortest path from u to v in G. For being an additive +\beta spanner, H must satisfy the inequality d_{H}(u,v)\leq d_{G}(u,v)+\beta. Figure 1: (a) A graph G, where the subset S is shown in squares. A subgraph corresponding to the pairwise shortest paths determined by S is highlighted in blue. Here W_{G}(a,b)=W_{G}(a,d)=W_{G}(b,d)=10 and W_{G}(a,c)=W_{G}(b,c)=W_{G}(c,d)=20. (b) A +2W(\cdot,\cdot)-spanner (in bold) of lightness 50/60=0.83 considering a spanning tree of the blue subgraph as the Steiner tree. (c) Illustration for a multi-level spanner. Multiplicative spanners were introduced by Peleg and Schäffer [26] in 1989. Since then a rich body of research has attempted to find sparse and lightweight spanners on unweighted graphs. Such spanners find applications in computing graph summaries, building distributed computing models, and designing communication networks [7, 3]. Finding a multiplicative \alpha–spanner with m or fewer edges is NP–hard [26]. It is also NP–hard to find a c\log|V|-approximate solution where c<1, even for bipartite graphs [23]. However, every n-vertex graph admits a multiplicative (2k-1)-spanner with O(n^{1+1/k}) edges and O(n/k) lightness [6], which has been improved in subsequent research [19, 18, 14, 11, 24]. A multiplicative factor allows for larger distances in a spanner, especially for pairs that have larger graph distances. Therefore, an additive spanner is sometimes more desirable even with the cost of having a larger number of edges. For unweighted graphs, there exist additive +2,+4 and +6 spanners with O(n^{3/2}) [5, 22], \tilde{O}(n^{7/5}) [13] and O(n^{4/3}) edges [9, 22], respectively, whereas any additive +n^{o(1)} spanners requires \Omega(n^{4/3-\epsilon}) edges [1]. Here \tilde{O}() hides polylogarithmic factors. These results have been extended to weighted graphs with the additive factors +\beta W_{G}(\cdot,\cdot), where W_{G}(\cdot,\cdot) represents the maximum weight on a shortest path between u and v in G, i.e., d_{H}(u,v)\leq d_{G}(u,v)+\beta W_{G}(u,v). We use W(u,v) instead of W_{G}(u,v) if the graph G is clear from context. Specifically, there exist additive +2W(\cdot,\cdot),+4W(\cdot,\cdot) and +(6+\epsilon)W(\cdot,\cdot) spanners of size O(n^{3/2}) [16], \tilde{O}(n^{7/5}) [3] and O_{\epsilon}(n^{4/3}) [17], respectively, where O_{\epsilon}() hides poly(1/\epsilon) factors. Researchers have also attempted to guarantee a good lightness bound for such spanners, where the lightness is the ratio of the spanner weight to the weight of a minimum spanning tree of G. So far, non-trivial lightness guarantees have been obtained only for (all-pairs) additive +\epsilon W(\cdot,\cdot) and +(4+\epsilon)W(\cdot,\cdot) spanners, where the lightness bounds are O_{\epsilon}(n) and O_{\epsilon}(n^{2/3}), respectively [2]. Real-life graphs can be very large, which motivates computing a subgraph that approximately preserves the shortest path distances among a subset of important vertices. Subsetwise spanner (also known as terminal spanners [15, 8]) is another commonly studied version, where in addition to G, the input consists of a vertex subset S of G, known as terminals. The goal is to compute an additive or multiplicative spanner that guarantees that for every u,v\in S, d_{H}(u,v) is within an additive or multiplicative factor of d_{G}(u,v). Computing a subsetwise spanner comes with additional challenges, e.g., consider computing a minimum spanning tree vs. a minimum Steiner tree for an analogy. There exist additive +2 and additive +(2+\epsilon)W(\cdot,\cdot) subsetwise spanners with size O(n\sqrt{|S|}) and O_{\epsilon}(n\sqrt{|S|}), respectively [3], however they do not come with any non-trivial lightness guarantees. The algorithms that construct such spanners often follow a greedy construction framework, i.e., they construct an initial graph and then examine the pairs in sorted nondecreasing order of the maximum weight, i.e., W(\cdot,\cdot). For each pair (u,v), if it still fails to satisfy the distance condition of an additive spanner, then all the edges on the corresponding shortest path are added to the spanner. In this paper, we focus on computing subsetwise additive spanners that are also light with respect to a Steiner tree T. To this end, we define subset-lightness. Specifically, let P\subseteq S\times S be the pairs that do not satisfy the spanner condition in a minimum Steiner tree R with terminal set S. Let T be a minimum Steiner tree with terminal set (S\cup S^{*}), where S^{*} is the set of vertices on the shortest paths of the pairs in P. Then, the subset-lightness is the ratio of the spanner weight to the weight of the minimum Steiner tree T. Although it may initially appear that R could be a simpler choice over T when defining lightness for subsetwise spanners, R may be a very loose lower bound. For example, consider a 2n-vertex complete graph G with vertex set S and let A,B be a partition of S into equal-size subsets. Assume that the weight of each edge that is crossing the partition is 2 and the weight of each remaining edge is (2+\delta), where \delta>0. A minimum spanning tree M of G is a star graph with weight O(n). Let G^{\prime} be a graph obtained by subdividing each edge of G once and distributing the weight of the edge equally among the two new edges. It is straightforward to verify that M determines a minimum Steiner tree R in G^{\prime} with terminal set S. Consider a pair a,b, where a\in A, b\in B and the edge (a,b) does not belong to R. Then the weight of the shortest path a,\ldots,b in R is 4+\delta>4 and thus does not satisfy the distance condition for a +2 spanner. There are \Omega(n^{2}) pairs with one element in A and the other in B, and any +2 spanner must take all these shortest paths. Therefore, the ratio of a +2 spanner over the weight of R would be very large, i.e., \Omega(|S|), whereas T (i.e., a minimum Steiner tree with terminals (S\cup S^{*})) is a better lower bound and gives a constant ratio. Therefore, we use T to define subset-lightness. The definition of subset-lightness naturally extends to the general case, i.e., when |S|=n, where a minimum Steiner tree coincides with a minimum spanning tree. However, the techniques used to compute all-pairs additive spanners do not generalize to subsetwise additive spanners [2]. Therefore, a natural question is whether we can compute subsetwise spanners with non-trivial guarantees on subset-lightness, and in this paper, we answer this question affirmatively. Our contribution. Let \epsilon>0 be a positive number, G be a weighted graph and S be a subset of vertices in G. We show the following (also see Table 1). 1. G has a subsetwise +\epsilon W(\cdot,\cdot) spanner with O_{\epsilon}(|S|) subset-lightness (Theorem 2.1) and the spanner can be constructed deterministically. 2. G has a subsetwise +(4+\epsilon)W(\cdot,\cdot) spanner with O_{\epsilon}(|V_{H}|^{1/3}|S|^{1/3}) subset-lightness (Theorem 2.2) and the spanner can be constructed deterministically. 3. G has a subsetwise +(4+\epsilon)W_{\max} spanner with \tilde{O}_{\epsilon}(|S|\sqrt{|V^{\prime}_{H}|/|V_{H}|}) subset-lightness, where W_{\max} is the maximum edge weight of the graph; V_{H} and V^{\prime}_{H} are the sets of vertices of the Steiner trees connecting S and a randomly sampled subset of S, respectively (Theorem 2.3). Table 1: Results on lightweight additive spanners. All-pairs Additive Spanners Subsetwise Additive Spanners Unweighted Weighted Weighted +\beta Lightness Ref +\beta Lightness Ref Subset-Lightness Ref 0 O(n) [21] +\epsilon W(\cdot,\cdot) O_{\epsilon}(n) [2] O_{\epsilon}(|S|) Th 2.1 +2 O(n^{1/2}) [5, 22] - - - - - +4 O(n^{2/5}) [13] +(4+\epsilon)W(\cdot,\cdot) O_{\epsilon}(n^{2/3}) [2] O_{\epsilon}(|V_{H}|^{1/3}|S|^{1/3}), \tilde{O}_{\epsilon}(|S|\sqrt{|V^{\prime}_{H}|/|V_{H}|}) Th 2.2, 2.3 +6 O(n^{1/3}) [9, 22] - - - - - Notice that the results of Theorem 2.1 and Theorem 2.2 exactly match the bounds provided for all-pairs spanners [2] if we set S=V. Hence, our results are not only answering stronger questions, but they are also directly comparable with the existing results. The main challenge to generalizing the all-pairs results to subsetwise results is that the former compares against the minimum spanning tree. A counting argument that is often used in additive spanner constructions is based on the number of improvements, i.e., the number of improvements that may occur for all pairs of vertices is no more than an upper bound. Here, an improvement means that the difference in the shortest path between the pair before and after adding a set of edges is non-zero. However, this idea does not work in the subsetwise setting if we only compute a Steiner tree that spans S. A key contribution of our work is that we address this problem by computing Steiner trees that not only span S but also the vertices in the shortest paths of some vertex pairs from S. We next consider computing multi-level (multiplicative/additive) spanner, where the goal is to compute a hierarchy of (multiplicative/additive) spanners that minimizes the total number of edges or the total edge weight of all the spanners. Specifically, the input consists of a graph and some subsets S_{1},S_{2},\ldots,S_{k} of its vertices where S_{1}\subseteq S_{2}\subseteq\ldots\subseteq S_{k}. The goal is to find a hierarchy of spanners such that the spanner at the ith level connects S_{i} and for i>2, the spanner S_{i} includes the edges of the spanners S_{1},\ldots,S_{i-1}. Multi-level spanners can model real-world scenarios where different levels of importance are assigned to different sets of vertices. Examples of such scenarios include modeling the quality of service requirements for the nodes in communication networks [12], or visualizing a graph on a map when the details are revealed as the users zoom in [20]. There exists a 4-approximation algorithm for this problem [4], and we give an improved e-approximation (Theorem 3.1). The rest of the paper is organized as follows. Section 2 discusses the results on lightweight additive spanners. Section 3 presents the e-approximation algorithm for multilevel spanners. Finally, Section 4 concludes the paper with directions for future research."
https://arxiv.org/html/2411.07499v1,Listing 6-Cycles in Sparse Graphs,"This work considers the problem of output-sensitive listing of occurrences of 2k-cycles for fixed constant k\geq 2 in an undirected host graph with m edges and t 2k-cycles. Recent work of Jin and Xu (and independently Abboud, Khoury, Leibowitz, and Safier) [STOC 2023] gives an O(m^{4/3}+t) time algorithm for listing 4-cycles, and recent work by Jin, Vassilevska Williams and Zhou [SOSA 2024] gives an \widetilde{O}(n^{2}+t) time algorithm for listing 6-cycles in n node graphs. We focus on resolving the next natural question: obtaining listing algorithms for 6-cycles in the sparse setting, i.e., in terms of m rather than n. Previously, the best known result here is the better of Jin, Vassilevska Williams and Zhou’s \widetilde{O}(n^{2}+t) algorithm and Alon, Yuster and Zwick’s O(m^{5/3}+t) algorithm.We give an algorithm for listing 6-cycles with running time \widetilde{O}(m^{1.6}+t). Our algorithm is a natural extension of Dahlgaard, Knudsen and Stöckel’s [STOC 2017] algorithm for detecting a 2k-cycle. Our main technical contribution is the analysis of the algorithm which involves a type of “supersaturation” lemma relating the number of 2k-cycles in a bipartite graph to the sizes of the parts in the bipartition and the number of edges. We also give a simplified analysis of Dahlgaard, Knudsen and Stöckel’s 2k-cycle detection algorithm (with a small polylogarithmic increase in the running time), which is helpful in analyzing our listing algorithm.","Listing copies of a small pattern graph that occur as subgraphs of a host graph is a fundamental problem in algorithmic graph theory. In this work, we consider the problem of listing C_{2k}’s (i.e., 2k-cycles) for fixed constant k\geq 2. Some examples of applications of C_{2k} listing include analyzing social networks [motivationSocial], and understanding causal relationships in biological interaction graphs [motivationBIO]. (See e.g. [dense_cycle_detection_YZ] for further motivation.) In the following discussion we consider an n vertex m edge graph G with t C_{2k}’s (where k\geq 2 will be clear from context and t is not necessarily known). The main reason for focusing on even length cycles is that while there are dense graphs that contain no odd cycles (e.g. bipartite graphs), a classic result of Bondy and Simonovits [evenextremal] states that any graph with at least 100kn^{1+1/k} edges contains a C_{2k}, for any integer k\geq 2. This fact enables efficient “combinatorial” algorithms for C_{2k} detection, in contrast to the case of odd length cycles where efficient C_{2k+1} detection algorithms are based on matrix multiplication. In fact, very simple reductions (e.g. [vthesis]) show that for any k\geq 1, C_{2k+1} detection is at least as hard as triangle detection, and the latter problem is known to be fine-grained subcubically equivalent to Boolean Matrix Multiplication [focsy]. Thus, fast algorithms for odd cycles cannot avoid matrix multiplication. We focus on even cycles from now on. A classic result of Yuster and Zwick [dense_cycle_detection_YZ] shows how to determine whether a graph contains a C_{2k} in O(n^{2}) time for any given constant k\geq 2. This quadratic running time is conjectured to be optimal in general (see [short_cycle_removal, LincolnVyas, Kn17], also discussed below); in particular, [short_cycle_removal] gave concrete evidence for the hardness of C_{4} detection. Nevertheless, in the regime of sparser graphs, where m<o(n^{1+1/k}) improvements are possible. For C_{4}’s there is a simple O(m^{4/3}) algorithm [alon1997finding] that matches the performance of the O(n^{2}) algorithm of [dense_cycle_detection_YZ] for m=\Theta(n^{3/2}), and improves on the performance for all m<o(n^{3/2}). Dahlgaard, Knudsen and Stöckel [Kn17] give an algorithm for C_{2k} detection with running time O(m^{2k/(k+1)}) for every constant k\geq 2. This matches the O(n^{2}) running time from [dense_cycle_detection_YZ] for m=\Theta(n^{1+1/k}) and improves on it for m<o(n^{1+1/k}). In fine-grained complexity, it is common to assume widely-believed hypotheses and use reductions to obtain conditional lower bounds for fundamental problems. For the special case of cycle detection problems, most conditional lower bounds are based on hypotheses related to triangle detection. One of the most common hypotheses is that triangle detection in n-node graphs does not have a “combinatorial” 222The class of combinatorial algorithms is not well defined, but intuitively refers to algorithms that do not use fast matrix multiplication as a subroutine. O(n^{3-\varepsilon}) time algorithm for \varepsilon>0 (in the word-RAM model). Vassilevska W. and Williams [focsy] showed that this hypothesis is equivalent to the so called BMM Hypothesis that postulates that there is no O(n^{3-\varepsilon}) time combinatorial algorithm for multiplying two n\times n Boolean matrices. As mentioned earlier, it is easy to show that under the BMM hypothesis, detecting any odd cycle C_{2k+1} requires n^{3-o(1)} time. Dahlgaard, Knudsen and Stöckel [Kn17] gave lower bounds for combinatorial detection of even cycles of fixed length in sparse graphs. They show that there is no combinatorial algorithm for C_{6} detection, or C_{2k} detection for any k>4, with running time O(m^{3/2-\varepsilon}) for \varepsilon>0. Lincoln and Vyas [LincolnVyas] give a similar conditional lower bound under a different hypothesis, extending the lower bounds for potentially non-combinatorial algorithms. Lincoln and Vyas show that, for large enough constant k, a C_{2k} detection algorithm in graphs with m\leq O(n) with running time m^{3/2-\varepsilon} would imply an algorithm for \max-3-SAT with running time 2^{(1-\varepsilon^{\prime})n}n^{O(1)}. The problem of listing even cycles is less well-understood. Without improving the C_{2k} detection algorithms discussed above, the best result that we could hope for in general is an algorithm with running time O(n^{2}+t), where t is the number of 2k-cycles in the graph, and O(m^{2k/(k+1)}+t) in the sparse setting where m<o(n^{1+1/k}). Recently, [Ab22] and [3sumLBCe] gave such an algorithm for C_{4} listing. In fact, Jin and Xu’s [3sumLBCe] algorithm gives a stronger guarantee: After O(m^{4/3}) pre-processing time, they can (deterministically) enumerate 4-cycles with O(1) delay per cycle. Jin and Xu [3sumLBCe] (and concurrently by Abboud, Bringmann, and Fischer [3sumLBAmir]) shows that, under the 3SUM Hypothesis, there is no algorithm for C_{4} enumeration with O(n^{2-\varepsilon}) or O(m^{4/3-\varepsilon}) pre-processing time and n^{o(1)} delay, for \varepsilon>0. For C_{6}’s, Jin, Zhou and Vassilevska Williams [C6sCe] give an \widetilde{O}(n^{2}+t) listing algorithm. For sparse listing algorithms, the previous state of the art is [alon1997finding] whose work implies an O(m^{(2k-1)/k}+t) time C_{2k} listing algorithm. See also [bringmannclass] where the complexity of the harder problem of listing H-partite333A k-node H is an H-partite subgraph of a k-partite graph G with vertex set V=\cup_{a\in V(H)}V_{a} if there are k vertices v_{1},\ldots,v_{k} such that v_{a}\in V_{a} for each a\in\{1,\ldots,k\} and the mapping a\rightarrow v_{a} is an isomorphism between H and the subgraph of G induced by v_{1},\ldots,v_{k}. In other words, instead of looking for an arbitrary subgraph of G isomorphic to H, one only focuses on the subgraphs with exactly one node in each V_{a} and such that the node picked from V_{a} corresponds to node a of H. subgraphs is investigated. 1.1 Our contributions We consider the problem of listing all C_{6}s in an m-edge graph. The best known result so far is an O(m^{5/3}+t) time algorithm that follows from the work of [alon1997finding]. Our main result is the first improvement over this 27 year old running time: {restatable*}theoremlistfast There is an algorithm for listing C_{6}’s in time \widetilde{O}(m^{1.6}+t). We now summarize the ideas needed to prove Section 1.1. Section 1.1 follows easily after establishing a certain bound on the number of capped k-walks in a graph. Capped k-walks are a notion introduced by Dahlgaard, Knudsen and Stöckel in [Kn17]. Roughly speaking, a capped k-walk is a walk of length k where the first vertex in the walk has higher degree than the remaining vertices in the walk (handling vertices of equal degree requires a bit of additional care). [Kn17]’s O(m^{2k/(k+1)}) time C_{2k} detection algorithm is based on the following fact: {restatable*}theoremthmcappedwalks[Kn17] Let G be a C_{2k}-free graph with maximum degree \Delta(G)\leq m^{2/(k+1)}. Then, there are at most \widetilde{O}(m^{2k/(k+1)}) capped k-walks in G. One of our main contributions is a simplified proof of Section 1.1, although with polylogarthmically worse guarantees than [Kn17]. This simplified analysis of capped k-walks is quite helpful in obtaining Section 1.1. The key lemma used to prove Section 1.1 is a generalization to bipartite graphs of Bondy and Simonovits’ classic theorem on the extremal number of C_{2k}’s. Specifically, the result is: Theorem 1.1. [Kn17] Let G be a bipartite graph with vertex parts of sizes L,R and with m edges. If m>100k(L+R+(LR)^{(k+1)/(2k)}) then G contains a C_{2k}. In order to use capped k-walks for a listing algorithm, it would be useful to have a Definition 1. supersaturation variant of Theorem 1.1, which would guarantee the presence of many C_{2k}’s if the edge density is large; the fact that this supersaturation result could help with listing was communicated to us by Jin and Zhou [supersat_observation]. The supersaturation analog of Bondy and Simonovits’ [evenextremal] extremal number for C_{2k}’s is known: Theorem 1.2. [JiangYep20] For every integer k\geq 2, there exist constants c,C such that if G is an n-node graph with m\geq Cn^{1+1/k} edges, then G contains at least c(m/n)^{2k} copies of C_{2k}. Jin and Zhou [supersat_observation] formulated the following conjectured generalization of Theorem 1.2: {restatable*} conjecturesupersatconj The Unbalanced Supersaturation Conjecture [Jin and Zhou’24]: Let G be an m edge bipartite graph with vertex bipartition A\sqcup B, with t C_{2k}’s. Suppose m\geq 100k(|A|+|B|+(|A||B|)^{(k+1)/2k}). Then, t\geq\Omega\left(\frac{m^{2k}}{|A|^{k}|B|^{k}}\right). Jin and Zhou obtained the following conclusion using the approach of [Kn17]: Fact 2 ([supersat_observation]). If the Unbalanced Supersaturation Conjecture is true, then there is an \widetilde{O}(t+m^{2k/(k+1)}) time algorithm for 2k-cycle listing for all k\geq 2. In LABEL:thm:conditional_listing we give a simple proof of Jin and Zhou’s fact above. Thus, an approach to obtaining the conjectured optimal running time of \widetilde{O}(t+m^{2k/(k+1)}) for C_{2k}-listing would be to prove Theorem 1.2. Unfortunately, establishing or refuting Theorem 1.2 remains a challenging open problem. Our main technical contribution is a proof of a weaker version of Theorem 1.2 for k=3. Then, we show that this partial progress towards Theorem 1.2 can be used in our simplified method for analyzing capped k-walks to obtain a bound on the number of capped k-walks, and consequentially an improved C_{6} listing algorithm in the sparse setting (namely, Section 1.1). 1.2 Open Questions Proving or refuting Theorem 1.2 is an important open question. It also is valuable to consider other avenues towards obtaining C_{2k} listing algorithms, especially in case Theorem 1.2 turns out to be false. The listing algorithms of [C6sCe], [3sumLBCe], [Ab22] use a variety of combinatorial insights that could potentially be generalized to larger k. It is also possible that a hybrid approach is productive: one can first use progress towards proving Theorem 1.2 to force the instance to have a specific structure, and then use different combinatorial insights to solve the structured version of the problem. 1.3 Paper Outline In LABEL:sec:simple_capped we present our simplified analysis of [Kn17]’s C_{2k} detection algorithm. In LABEL:sec:listing_with_supersat we show how to modify our simple analysis of [Kn17]’s C_{2k} detection algorithm to get a C_{2k} listing algorithm, assuming the Unbalanced Supersaturation Conjecture. In LABEL:sec:supsersat_progress we present progress towards resolving the Unbalanced Supersaturation Conjecture. In LABEL:sec:listing_progress we show how to use our progress towards Theorem 1.2 in our simplified capped k-walk analysis to obtain a listing algorithm for C_{6}’s with running time \widetilde{O}(m^{1.6}+t). 1.4 Notations We use \Delta(G) to denote the maximum degree of graph G. We write N(v) to denote the neighborhood of vertex v, and for S\subseteq V(G) we write N_{S}(v) to denote N(v)\cap S. For graph G, we will use V(G),E(G) to denote the vertex and edge sets of G. When G is clear from the context we also denote V(G) by V and E(G) by E. We let n=|V|,m=|E| (when the graph being discussed is clear), and assume m\geq n. For vertex subsets A,B we write e(A,B) to denote |E\cap(A\times B)|. A walk / path of length k will refer to a walk / path with k edges. Given A,B\subseteq V, we will write G[A,B] to denote the induced subgraph on A,B, i.e., a graph with vertex set A\cup B and edge set E(G)\cap(A\times B). We will write G[A] to denote G[A,A]. We write [x] to denote the set \left\{1,2,\ldots,\lceil x\rceil\right\}. We use \log to denote the base-2 logarithm. Define the"
https://arxiv.org/html/2411.07389v1,An Improved Algorithm for Sparse Instances of SAT,"We show that the CNF satisfiability problem (SAT) can be solved in time O^{*}(1.1199^{(d-2)n}), where d is either the maximum number of occurrences of any variable or the average number of occurrences of all variables if no variable occurs only once. This improves upon the known upper bound of O^{*}(1.1279^{(d-2)n}) by Wahlstr\ddot{\text{o}}m (SAT 2005) and O^{*}(1.1238^{(d-2)n}) by Peng and Xiao (IJCAI 2023). For d\leq 4, our algorithm is better than previous results. Our main technical result is an algorithm that runs in O^{*}(1.1199^{n}) for 3-occur-SAT, a restricted instance of SAT where all variables have at most 3 occurrences. Through deeper case analysis and a reduction rule that allows us to resolve many variables under a relatively broad criteria, we are able to circumvent the bottlenecks in previous algorithms.","The Boolean satisfiability problem (SAT) is the problem of deciding the satisfiability of formulas in conjunctive normal form (CNF). As the first discovered NP-complete problem [6], SAT and its many variants and extensions remain some of the most extensively studied NP-complete problems. Beyond its theoretical significance, the advent of SAT-solvers [9] has led to practical applications in computer assisted proofs [26], AI planning and especially software verification [16]. While SAT-solvers work well in practice, their worst-case upper bound is the trivial bound of O^{*}(2^{n}). Despite decades of research, no algorithm for SAT with worst-case runtime of O^{*}(c^{n}) for c<2 is known. In fact, the widely believed Strong Exponential Time Hypothesis [12] conjectures that such an algorithm do not exist. Consequently, a substantial amount of work has been done on faster algorithms for restricted instances of SAT. For example, k-SAT is a restricted instance of SAT where every clause has at most k literals. When k=3, this is the famous 3-SAT problem. 3-SAT can be solved by a deterministic algorithm in time O^{*}(1.32793^{n}) [15] and by a randomised algorithm in time O^{*}(1.30698^{n}) [19]. The main focus of this paper are sparse instances of SAT. This include instances where the maximum number of occurrences of any variable in a formula is at most d. The problem can be solved in linear-time when d=2 and becomes NP-complete when d\geq 3 [20]. 3-occur-SAT is the restricted instance of SAT when d=3. The first non-trivial bound for 3-occur-SAT was achieved by Kullmann and Luckhardt [14] with an algorithm that runs in time O^{*}(1.1299^{n}). Subsequently, Wahlstr\ddot{\text{o}}m [23] and later Peng and Xiao [17] presented algorithms for sparse formulas with upper bounds of O^{*}(1.1279^{(d-2)n}) and O^{*}(1.1238^{(d-2)n}) respectively. By setting d=3, we can see that an O^{*}(\alpha^{(d-2)n}) algorithm for SAT is an O^{*}(\alpha^{n}) algorithm for 3-occur-SAT. An alternative approach for tackling sparse instances of SAT are algorithms measured against the formula length L. This problem has been extensively studied [21, 14, 10, 11] and more recent improvements of the upper bound include an O^{*}(1.0663^{L}) algorithm by [22], an O^{*}(1.0652^{L}) algorithm by [4] and an O^{*}(1.0638^{L}) algorithm by [18] . Notably, these latest attempts have all incorporated Wahlstr\ddot{\text{o}}m’s algorithm [23] as a 3-occur-SAT sub-procedure, with the runtime of the 3-occur-SAT procedure often being one of the bottleneck cases. For the maximum satisfiability problem (MAXSAT), the restricted instance when d=3 has also been extensively studied. MAXSAT is the optimisation variant of SAT where the objective is to satisfy the maximum number of clauses. More recent improvements of the upper bound include an O^{*}(1.194^{n}) algorithm by [25], an O^{*}(1.191^{n}) algorithm by [2] and an O^{*}(1.1749^{n}) algorithm by [3]. Our Contributions. In this paper, we improve the worst-case upper bound for 3-occur-SAT to O^{*}(1.1199^{n}). Our algorithm (refer to section 3), like Wahlstr\ddot{\text{o}}m [23] and Peng and Xiao [17], is a modified branch-and-reduce algorithm. We apply reduction and branching rules until our formula acquires sufficient structure to enable the use of a fast 3-SAT algorithm by Beigel and Eppstein [1] as a sub-procedure. For branch-and-reduce algorithms targeting variants and restricted instances of SAT, the key to improving the upper bound often hinges on effectively managing the cases with poor branching factors. For 3-occur-SAT, these critical bottlenecks for the previous attempts (directly or indirectly) are the branching rules to make the formula monotone and to handle all-negative clauses of length 2 and 3. For handling all-negative clauses of length 3 and greater, a more comprehensive analysis, by strategically selecting which variable to branch on and delving into additional cases, proves sufficient. The other bottlenecks are more challenging and requires new algorithmic ideas. We introduced a new reduction rule (step 6d) that generalizes many common reduction rules and allows us to resolve many variables at once. This new reduction rule enables us to impose significantly more structure of our formula. Hence, after branching on one variable, a reduction rule based on an autarkic set [5] (step 8) allow us to achieves monotonicity. To effectively handle all-negative clauses of length two, we also resort to branching on two variables (step 9) when branching on one does not achieve a desirable branching factor. Finally, we extend our algorithm to an O^{*}(1.1199^{(d-2)n}) algorithm for SAT. d=3 d=4 Reference O^{*}(1.1299^{n}) O^{*}(1.2766^{n}) Kullmann and Luckhardt [14] O^{*}(1.1279^{n}) O^{*}(1.2721^{n}) Wahlstr\ddot{\text{o}}m [23] O^{*}(1.1238^{n}) O^{*}(1.2628^{n}) Peng and Xiao [17] O^{*}(1.1199^{n}) O^{*}(1.2541^{n}) This paper Table 1: Progress for SAT with d=3,4"
https://arxiv.org/html/2411.07273v2,Compressed Game Solving,"We recast move generators for solving board games as operations on compressed sets of strings. We aim for compressed representations with space sublinear in the number of game positions for interesting sets of positions, move generation in time roughly linear in the compressed size and membership tests in constant time. To the extent that we achieve these tradeoffs empirically, we can strongly solve board games in time sublinear in the state space. We demonstrate this concept with the game Breakthrough where we empirically realize compressed representations taking roughly n^{0.5} to n^{0.7} space to store relevant sets of n positions.","Computer game playing has been an interest nearly as long as general purpose computers have existed; Alan Turing’s “Proposed Electronic Calculator” report in 1946 predicted that computers “could probably be made to play very good chess” [25]. The idea of methodically solving a game to determine the winner under perfect play goes back farther to Zermelo’s theorem in 1913 [22]; previously, it was not even clear that games could be solved in general. The first example of solving a game is even older – the game of Nim was strongly solved in [4], and there are likely older examples of small games such as Tic-tac-toe being solved. So what keeps us from solving all the games of interest? Interesting games tend to have too many positions for our generic techniques to work, so we end up looking for knowledge-based short cuts or investing inordinate amounts of compute power. If the game is too small or a trick is too powerful, we lose interest in the game. For example, Tic-tac-toe is often solved informally by elementary school children, and Nim has a trivial to calculate rule to determine both the winner and ideal moves. Early game solutions such as Qubic [16], Connect 4 [3], and Gomoku [1] were achieved by integrating knowledge into the solving program to significantly reduce the search space. The earliest non-trivial game solved without a substantial advantage from knowledge is generally held to be Nine Men’s Morris which solved by Gasser in 1993 [7]. The solution of Nine Men’s Morris comprised of an endgame database of about 10^{10} states solving the midgame and endgame phases and an 18 ply alphabeta search from the beginning of the game to the midgame. At the time, this was a non-trivial amount of resources. Since this first interesting solution, Checkers has also been shown to be a draw through a combination of a ten piece endgame database, and proof number search from the beginning of the game [21]. More recently, Othello was also shown to be drawn [24]. Table 1 provides a longer list of games solved with such strategies. Game Year State Space Positions Solved Solve Strength Nine Men’s Morris 1993 [7] 10^{10} 10^{10} strong Awari 2002 [17] 9\times 10^{11} 9\times 10^{11} strong Checkers 2007 [21] 5\times 10^{20} 3.9\times 10^{13} weak Fanorona 2008 [19] 10^{21} 6.3\times 10^{9} weak Pentago 2014 [12] 3\times 10^{15} 3\times 10^{15} strong Othello 2023 [24] 10^{28} 1.5\times 10^{9} weak Table 1: Games solved with the help of endgame databases. A strategy shared across these solutions was the identification of a set of intermediate positions whose solution would prune a substantial fraction of a search tree from the beginning of the game. That intermediate set of positions was then solved via a brute force method (retrograde analysis except for Othello), and then a search from the root was used to construct a proof solving the starting position of the game. A key design decision is identifying the set of intermediate positions to solve. A smaller set of intermediate positions will require a larger search process, while a larger set of intermediate positions will require more time to solve. In previous work, solving the set of intermediate positions took time at least linear in the size of that set; linear time was required just to write the solutions, and individual positions might need to be processed multiple times to resolve them. The most common strategy, retrograde analysis, solves a set of intermediate positions that is closed under reachability by working from the end of the game, and efficient implementations can be close to that linear ideal. Our work aims to break that linear time requirement by compressing the sets of positions into sublinear representations, and performing move generation directly on those compressed sublinear representations. Our contributions are as follows. We recast the move generation operations of retrograde analysis as set operations, similar to the exposition by Von Neumann and Morgenstern [15], and argue that suitable compressed set representations can radically change the cost of retrograde analysis. We then show how to instantiate this compressed set approach using deterministic finite automata. We demonstrate this approach for multiple games showing its strengths and weaknesses, and ultimately solve several new sizes of the game Breakthrough on a single commodity laptop. We also show that this particular implementation has more modest leverage for the games of Amazons and Chess, and close speculating on possible improvements to the compressed set representations."
https://arxiv.org/html/2411.07536v1,Model Stealing for Any Low-Rank Language Model,"Model stealing, where a learner tries to recover an unknown model via carefully chosen queries, is a critical problem in machine learning, as it threatens the security of proprietary models and the privacy of data they are trained on. In recent years, there has been particular interest in stealing large language models (LLMs). In this paper, we aim to build a theoretical understanding of stealing language models by studying a simple and mathematically tractable setting. We study model stealing for Hidden Markov Models (HMMs), and more generally low-rank language models.We assume that the learner works in the conditional query model, introduced by Kakade, Krishnamurthy, Mahajan and Zhang [KKMZ24]. Our main result is an efficient algorithm in the conditional query model, for learning any low-rank distribution. In other words, our algorithm succeeds at stealing any language model whose output distribution is low-rank. This improves upon the result in [KKMZ24] which also requires the unknown distribution to have high “fidelity” – a property that holds only in restricted cases. There are two key insights behind our algorithm: First, we represent the conditional distributions at each timestep by constructing barycentric spanners among a collection of vectors of exponentially large dimension. Second, for sampling from our representation, we iteratively solve a sequence of convex optimization problems that involve projection in relative entropy to prevent compounding of errors over the length of the sequence. This is an interesting example where, at least theoretically, allowing a machine learning model to solve more complex problems at inference time can lead to drastic improvements in its performance.","Proprietary machine learning models are often highly confidential. Not only are their weights not publicly released, but even their architecture and hyperparameters used in training are kept a closely guarded secret. And yet these models are often deployed as a service, allowing users to make queries to the model and receive answers. These answers can take the form of labels or completions of prompts, and sometimes a model will even report additional information such as its confidence scores. This raises a natural question: Question. Are these black-box models actually secure, or is it possible to reverse engineer their parameters or replicate their functionality just from query access to them? This task is called model stealing and it threatens the security of proprietary models and the privacy of data they are trained on. Beyond nefarious reasons, it can also be used in model distillation [MCH+21], where we have trained a large and highly complex model and we want to transfer its knowledge to a much smaller model. It can also be a useful tool for identifying vulnerabilities, as those are often inherited by stolen models. In any case, model stealing continues to be a very active area of research. The influential work in [TZJ+16] showed that there are simple and efficient attacks on popular models like logistic regression, decision trees and deep neural networks that often work in practice. Since then, many new attacks and defenses have been formulated [HLXS21, HJB+21, RST19, WG18, JSMA19, OMR23, OSF19, WXGD20]. There are also approaches based on embedding watermarks [JCCCP21, ZWL23, LZJ+22] that make it possible to detect when one model has been stolen from another. In recent years, there has been particular interest in stealing large language models (LLMs). Various works have shown how to steal isolated components of a language model such as the decoding algorithm [NKIH23], prompts used to fine-tune the model [SZ24], and even the entire weight matrix of the last layer (the embedding projection layer) [CPD+24]. In this work, our main interest will be in theoretical foundations for stealing language models. As is all too familiar, proving rigorous end-to-end guarantees when working with modern machine learning models with all their bells and whistles seems to be an extremely difficult task. For example, while we can understand the training dynamics on multilayer neural networks in terms of gradient flow in the Wasserstein space of probability distributions [MMM19, NP23], it has turned out to be quite difficult to analyze these dynamics except in simplified settings with a high degree of symmetry. Even worse, there are strong lower bounds for learning deep neural networks [KS09] even with respect to nice input distributions [GGJ+20, DKKZ20, GGK20]. The task of reasoning about modern language models seems no easier, as they are built on transformers [VSP+17] with many building blocks such as word embeddings, positional encodings, queries, keys, values, attention, masking, feed-forward neural networks and layer normalization. Nevertheless there are often simplified models that abstract important features of more complex models and give us a sandbox in which to try to find theoretical explanations of empirical phenomena. For example, analyzing the dynamics of gradient descent when training a deep neural network is notoriously difficult. But in an appropriate scaling limit, and when the network is wide enough, it can be approximated through the neural tangent kernel [JGH18]. For recurrent neural networks, a popular approach is to analyze gradient descent on linear dynamical systems instead [HMR18]. Likewise for language models, it is natural to work with Hidden Markov Models (HMMs), which are in some sense the original language model, dating back to the work of Claude Shannon in 1951 [Sha51] and were the basis of other early natural language processing systems including the IBM alignment models. More broadly, we can consider a generalization called low-rank language models (Definition 1.1). This brings us to our main questions: Question. Is there an efficient algorithm for stealing HMMs from query access? What about more generally for low-rank language models? These questions were first introduced and studied in an exciting recent work of Kakade, Krishnamurthy, Mahajan and Zhang [KKMZ24]. However their motivation and framing was somewhat different, as we will explain. 1.1 Main Results Formally, we view a language model as a distribution \mathbb{H} over \mathcal{O}^{T} for some alphabet \mathcal{O} and sequence length T. For simplicity, we treat the sequence length as fixed. Following Kakade, Krishnamurthy, Mahajan and Zhang [KKMZ24], the rank of the distribution generated by a language model is defined as follows: Definition 1.1. [Low Rank Distribution] A distribution \mathbb{H} over \mathcal{O}^{T} for alphabet \mathcal{O} of size O and sequence length T is rank S if for all t<T, the O^{T-t}\times O^{t} matrix, \mathbf{M}^{(t)}, with entries equal to \Pr_{\mathbb{H}}[f|h] for f\in\mathcal{O}^{T-t} and h\in\mathcal{O}^{t} has rank at most S. In other words, a distribution is rank-S if for any t<T, the information in the prefix of length t can be embedded in an S-dimensional space such that the distribution of the future tokens can be represented as a linear function of this embedding. We note that low-rank distributions are expressive and encompass distributions generated by a Hidden Markov Model (HMM) with S hidden states (see Fact 2.2). Next, we formalize the setup for studying model stealing. We allow the learner to make conditional queries – that is, the learner can specify a history of observations, and then receives a random sample from the conditional distribution on the future observations. Formally, we have the following definition: Definition 1.2 (Conditional Query). The learner may make conditional queries to a distribution \mathbb{H} by querying a string h\in\mathcal{O}^{t} where 0\leq t<T. Upon making this query, the learner obtains a string f of length T-t drawn from the distribution \Pr_{\mathbb{H}}[f|h]. In this model, our goal is to design an algorithm that makes a total number of queries that is polynomial in S,O,T and learns an efficiently samplable distribution that is \epsilon-close in total variation distance to \mathbb{H}. This conditional query model was recently introduced by Kakade, Krishnamurthy, Mahajan and Zhang [KKMZ24]. Their motivation was two-fold: First, while learning an HMM from random samples is known to be computationally hard [MR05], in principle one can circumvent these barriers if we are allowed conditional samples. Second, a solution to their problem would generalize Angluin’s classic L^{*} algorithm which learns deterministic finite automata from membership queries [Ang87]. In terms of results, Kakade, Krishnamurthy, Mahajan and Zhang [KKMZ24] introduced a notion that they called fidelity and gave a polynomial time algorithm to learn any low-rank distribution (and thus any HMM) which has high fidelity through conditional queries. However this property does not always hold. Thus, their main question still remains: Is it possible to learn arbitrary low-rank distributions through conditional queries? Here we resolve this question in the affirmative. We show: Theorem 1.3. Assume we are given conditional query access to an unknown rank S distribution \mathbb{H} over \mathcal{O}^{T} where |\mathcal{O}|=O. Then given a parameter 0<\eta<1, there is an algorithm that takes \mathrm{poly}(S,O,T,1/\eta) conditional queries and running time and with probability 1-\eta outputs a description of a distribution \mathbb{H}^{\prime} such that \mathbb{H}^{\prime} is \eta-close in TV distance to \mathbb{H}. Moreover there is an algorithm that samples from \mathbb{H}^{\prime} in \mathrm{poly}(S,O,T,\log(1/\eta)) time. Note that crucially, the algorithm only makes conditional queries for learning the representation of \mathbb{H}^{\prime}. Once we have this learned representation, we may draw as many samples as we want without making any more queries to the original distribution \mathbb{H}. 1.2 Discussion Theorem 1.3 shows that we can efficiently learn any low-rank distribution via conditional queries. Thus, we can view our results as showing that in some sense, the rank of a distribution can be a useful proxy for understanding the complexity of model stealing, similar to how complexity measures, such as Bellman rank [JKA+17] and its relatives [FKQR21], are useful for understanding the statistical complexity of learning a near optimal policy in reinforcement learning. There is a key conceptual insight driving our algorithm. One of the challenges in learning sequential distributions is that the error can grow exponentially in the sequence length T. In particular if we imagine sampling from \mathbb{H} one token at a time, the low-rank structure ensures that we only need to keep track of an S-dimensional hidden state at each step. However, each step involves multiplication by a change-of-basis matrix and these repeated multiplications cause the error to grow exponentially. The key to mitigating this error blowup is that we combine each change-of-basis with a projection step, where we solve a convex optimization problem that performs a projection with respect to KL divergence. Crucially, projection in KL divergence has a contractive property (see Fact 3.9) that does not hold for other natural measures of distance between distributions, such as TV distance. We give a more detailed overview of our algorithm in Section 3. This is an interesting example where allowing a machine learning model to solve more complex problems at inference time can lead to drastic improvements in its performance. Of course, phrased in general terms, this is a driving philosophy behind OpenAI’s o1 model. But so far we have little theoretical understanding of the provable benefits of allowing more compute at inference time. 1.3 Related Work There has been a long line of work on learning HMMs from random samples. Mossel and Roch [MR05] gave the first polynomial time algorithms that work when under appropriate full rankness conditions on the transition and observation matrices. Other works gave spectral [HKZ12] and method of moments based approaches [AHK12]. Learning HMMs can also be thought of as a special case of learning phylogenetic trees [CGG01, MR05]. Other approaches assume the output distributions belong to a parametric family [KNW13], or study quasi-HMMs [HGKD15]. The main computational obstruction in this area is that HMMs, without full rankness conditions, can encode noisy parities [MR05], which are believed to be computationally hard to learn. In the overcomplete setting, where the hidden state space is allowed to be larger than the observation space, there are ways around these lower bounds. First, one can aim to predict the sequence of observations, rather than learning the parameters [SKLV18]. Under a natural condition called multi-step observability one can get quasi-polynomial time algorithms [GMR23]. Second, one can make structural assumptions that the transition matrices are sparse, well-conditioned, and have small probability mass on short cycles [SKLV17]. Alternatively there are polynomial time algorithms that work under the assumption that the transition and observation matrices are smoothed [BCPV19]. There are also related models called linear dynamical systems where the hidden states and observations are represented as vectors. In contrast, in HMMs the hidden states and observations take on only a finite set of possible values. There is a long line of work on learning linear dynamical systems too [HMR18, OO19, TP19, SRD19, SBR19, BLMY23a, CP22, BLMY23b]. However, these algorithms require various structural assumptions, and even the weakest ones, namely condition-number bounds on the called observability and controllability matrices, are known to be necessary [BLMY23a]. The conditional query model has also been studied for other statistical problems such as testing discrete distributions and learning juntas [CFGM13, CRS15, BC18, CJLW21]. However, in most of these settings, the goal of studying the conditional query model is to obtain improved statistical rates rather than sidestep computational hardness. We remark that there are also many classic examples of problems in computational learning theory where, when allowed to make queries, there are better algorithms [Jac97] than if we are only given passive samples."
https://arxiv.org/html/2411.06857v1,Phase Transitions via Complex Extensions of Markov Chains,"We study algebraic properties of partition functions, particularly the location of zeros, through the lens of rapidly mixing Markov chains. The classical Lee-Yang program initiated the study of phase transitions via locating complex zeros of partition functions. Markov chains, besides serving as algorithms, have also been used to model physical processes tending to equilibrium. In many scenarios, rapid mixing of Markov chains coincides with the absence of phase transitions (complex zeros). Prior works have shown that the absence of phase transitions implies rapid mixing of Markov chains. We reveal a converse connection by lifting probabilistic tools for the analysis of Markov chains to study complex zeros of partition functions.Our motivating example is the independence polynomial on k-uniform hypergraphs, where the best-known zero-free regime has been significantly lagging behind the regime where we have rapidly mixing Markov chains for the underlying hypergraph independent sets. Specifically, the Glauber dynamics is known to mix rapidly on independent sets in a k-uniform hypergraph of maximum degree \Delta provided that \Delta\lesssim 2^{k/2}. On the other hand, the best-known zero-freeness around the point 1 of the independence polynomial on k-uniform hypergraphs requires \Delta\leq 5, the same bound as on a graph.By introducing a complex extension of Markov chains, we lift an existing percolation argument to the complex plane, and show that if \Delta\lesssim 2^{k/2}, the Markov chain converges in a complex neighborhood, and the independence polynomial itself does not vanish in the same neighborhood. In the same regime, our result also implies central limit theorems for the size of a uniformly random independent set, and deterministic approximation algorithms for the number of hypergraph independent sets of size k\leq\alpha n for some constant \alpha.","More than a few important recent advances in theoretical computer science, in combinatorics and probability theory, have been made possible through locating the zeros of suitably chosen multivariate polynomials. These include improved approximation algorithms for the traveling salesman problem [28, 39], construction of Ramanujan graphs of every degree [52, 53], deterministic approximate counting algorithms for spin systems [8, 56, 46, 47], an algebraic proof of a generalization of the van der Waerden Conjecture [29], a resolution of the long-standing Kadison-Singer conjecture [54], and notably the theory of negatively dependent random variables [11]. Furthermore, there has been a fruitful line of work that exploits a more general form of geometry, notably the development of log-concave polynomials and Lorentzian polynomials, which have led to novel analyses of Markov chains and the resolution of Mason’s conjecture [4, 15]. The development of multivariate stability theory dates back to the famous Lee-Yang program [49] in statistical physics. In their seminal work, Lee and Yang initiated the study of phase transitions through the location of complex zeros of the partition function while also establishing identities relating key physical quantities to the density function of zeros. A key insight is that to understand the macroscopic properties of a system at the thermodynamic limit (that is, as the size of the system tends to infinity), one studies the complex zeros in a neighborhood for any finite systems so as to determine whether the quantities of interest remain analytic or can have a discontinuity. One key quantity of particular interest is the so-called free-energy density. There have also been various generalizations and extensions of Lee-Yang type theorem in statistical physics and combinatorics [44, 30, 67], Chernoff bounds [41], asymptotic normality [38] and central limit theorems [43, 51, 36]. Stability theory for a univariate polynomial is also extensively studied in control theory and can be traced back to the famous Routh-Hurwitz criterion [60, 34]. Roughly speaking, a phase transition occurs when the macroscopic property of a system is not fully determined by local interactions in the thermodynamic limit (that is, there could be multiple phases). To formalize such a notion, three types of mathematical definitions have been studied: (1) Probabilistic: Conditions under which a Gibbs distribution exhibits decay of long-range correlations with respect to distance. (2) Algebraic: Conditions under which a partition function vanishes in the thermodynamic limit. This is also Lee-Yang’s view of phase transition. (3) Algorithmic: Conditions under which a spin system out-of-equilibrium quickly returns to thermal equilibrium; in particular, when does a Glauber dynamics mix rapidly to the Gibbs distribution. Notably, Glauber dynamics can be seen as both a model of physical processes tending to equilibrium, and also an algorithm that can be efficiently simulated. To this date, each of these distinct-looking definitions has seen fruitful algorithmic applications, giving rise to algorithms based on the decay of correlations [68], the absence of zeros [8], and the direct simulation of Glauber dynamics. Numerous efforts have been made to understand the relationship between these three definitions and their relative strengths. For amenable graphs such as lattices, Dobrushin and Shlosman [19, 20] studied the first two types in the form of complete analyticity and showed that they are equivalent. Stroock and Zegarlinski [66] showed the equivalence of all three types via log-Sobolev inequalities. These analyses crucially rely on the amenability of the lattices. In more general settings, Barvinok [9] posed an open question concerning establishing the absence of zeros from the analysis of any rapidly mixing Markov chain. A key challenge, as pointed out by Barvinok, is that while an inverse polynomial spectral gap is sufficient to prove the rapid mixing of Markov chains, a constant radius of zero-free region is often desired for practical applications. Until now, little progress has been made in this specific direction. In contrast, the other direction has seen more success. Assuming decay of correlation in the form of contraction, the absence of zeros follows from the contraction method [57, 47, 65]. Furthermore, [6, 16] showed that contraction also implies rapid mixing of Glauber dynamics. Additionally, the absence of zeros has been shown to imply the decay of correlations (in the form of strong spatial mixing) for self-reducible problems [26, 59] and to imply rapid mixing of Glauber dynamics [1, 17] through a different form of correlation decay known as bounded total influence. Moreover, rapid mixing is known to imply spectral independence [3], which can be seen as a form of bounded correlations. We give a rough summary of the state-of-the-art in Figure 1. zero-freenessrapid mixingdecay of correlations[26, 59][57, 47, 65][6, 16][3][1, 17]This work Figure 1. A rough summary of connections between three types of phase transitions. We do not distinguish the exact form of phase transitions within each type. 1.1. Hypergraph independence polynomial Our motivating example is the independence polynomial on a k-uniform hypergraph. Given a hypergraph H=(V,\mathcal{E}), we say that H is k-uniform if every hyperedge e\in\mathcal{E} has size \left|e\right|=k. The maximum degree \Delta is the maximum number of hyperedges incident to a vertex. An independent set in H is a subset S\subset V of vertices that does not contain any e\in E, that is, every hyperedge e must have at least one endpoint not chosen by S. We use \sigma\in\left\{0,1\right\}^{n} to indicate the set S, meaning that \sigma(v)=1 iff v\in S. Let \mathcal{I}(H) denote the set of independent sets in H. Then, the independence polynomial of H is a generating polynomial in the variables \bm{\lambda}: Z_{H}(\bm{\lambda})=\sum_{\sigma\in\mathcal{I}(H)}\prod_{v:\sigma(v)=1}\lambda% _{v}. When k=2, this is the standard independence polynomial, which has been studied in many branches of mathematics, physics, and computer science. To name a few, Shearer [62] obtained instance-optimal sufficient criterion in Lovász local lemma using the largest root of the independence polynomial; a tight runtime analysis of the celebrated Moser-Tardos algorithm for the algorithmic Lovász local lemma is characterized by the independence polynomial [40]; independence polynomial is also known as the hardcore model for equilibrium of lattice-gas in statistical physics [64]; it is also the first example where a sharp computational complexity of approximate counting and sampling is known [68, 63]. We will refer to the complex zeros of the independence polynomial in \bm{\lambda} as Lee-Yang zeros, as \bm{\lambda}’s are playing the role of external fields here. Henceforth, we denote the above polynomial by Z^{\mathrm{ly}}_{H}(\bm{\lambda}). Scott and Sokal also proposed a soft-core version of independence polynomial [64], with which they derived a weak dependency version of the local lemma. This inspired us to study a soft-core independence polynomial parameterized by the interactions: Z_{H}^{\mathrm{fs}}(\bm{\beta})=\sum\limits_{S\subset V}\prod\limits_{\begin{% subarray}{c}e:e\subset S\end{subarray}}\beta_{e}. Intuitively, for every hyperedge e completely contained in a set S, we assign a “penalty” \beta_{e} for violating the “hard-core” constraint. Zeros in the interaction parameter are also known as Fisher zeros [25]. Compared to Lee-Yang zeros that have been extensively studied, general results for Fisher zeros have been limited until the recent introduction of contraction method [57, 47, 65]. However, these contraction methods crucially rely on a self-avoiding walk construction, which breaks up the uniformity of hypergraphs and is therefore ill-suited for our purpose. The point \bm{\lambda}=1 in Z^{\mathrm{ly}}_{H}(\bm{\lambda}) and the point \bm{\beta}=0 in Z_{H}^{\mathrm{fs}}(\bm{\beta}) are of particular interests, as they correspond to the uniform enumeration of independent sets. This is a prominent example of models where the known regime of zero-freeness, corresponding to an algebraic phase transition, has significantly lagged behind the known regime where efficient algorithms are available. As one of the early examples where approximate counting and sampling algorithms were devised for a constraint satisfaction problem under a local lemma type condition, [33] showed that the Glauber dynamics on independent sets of k-uniform hypergraph mixes rapidly provided the maximum degree \Delta\lesssim 2^{k/2}, and this is matched, up to the leading constants, by an earlier NP-hardness result for \Delta\gtrsim 2^{k/2} in [14]. Since then, several developments have followed suit, including perfect samplers [32, 58] and a local sampler [23], all within similar regimes, albeit with poly(k) factors. Remarkably, the latter can be derandomized to yield a deterministic approximate counting algorithm. For zero-freeness results, however, progress has lagged significantly despite numerous efforts. While there is a rich literature on models with pairwise interactions, understanding of the more physically relevant regime involving higher-order interactions remains limited, and techniques for locating complex zeros for higher-order interactions are less developed. Only recently, Galvin, McKinley, Perkins, Sarantis and Tetali [27] established the existence of a zero-free disk for \lambda centered at the origin with radius \approx\frac{1}{\mathrm{e}\Delta} for hypergraphs of maximum degree \Delta. Later, Bencs and Buys [10] improved this result to match Shearer’s bound for the independence polynomial on graphs. For zero-freeness in a complex neighborhood around the positive real axis, it implicitly follows from the lifting paradigm of [47, 65] applied to the contraction method of [42, 50], that zero-freeness holds around \bm{\lambda}=1 for \Delta\leq 5. This is also carried out more explicitly by [48, 10]. Despite these advances, a significant gap remains compared to the algorithmic transition, which holds up to \Delta\lesssim 2^{k/2}. Essentially, existing techniques for proving zero-freeness are insufficient to exploit the uniformity of hyperedges. 1.2. Our contributions We demonstrate how one can establish the absence of complex zeros through a powerful probabilistic tool in the analysis of Markov chains: percolation applied to a complex extension of Markov chains. We show zero-free regions for both the Lee-Yang zeros of Z^{\mathrm{ly}}_{H}(\bm{\lambda}), and the Fisher zeros of Z_{H}^{\mathrm{fs}}(\bm{\beta}), in regimes that match the algorithmic transition of \Delta\lesssim 2^{k/2} up to poly(k) factors. We also show convergence of a systematic scan Glauber dynamics with complex transition weights in the same regime. To the best of our knowledge, this is the first such result for a complex dynamics. Theorem 1.1 (Lee-Yang zeros of hypergraph independence polynomial). Fix k\geq 2 and \Delta\geq 3. Let 0<\varepsilon<\frac{1}{9k^{5}\Delta^{2}}, and let [0,\lambda_{c,\varepsilon}) be the real segment such that the following holds for all \lambda\in[0,\lambda_{c,\varepsilon}): \left(\frac{\lambda+\varepsilon}{1+\lambda-\varepsilon}\right)^{k/2}<\frac{1}{% 2\sqrt{2}\mathrm{e}\Delta k^{2}}. Let \mathcal{D}_{\varepsilon} be the union of \varepsilon-balls around the segment given by \mathcal{D}_{\varepsilon}=\left\{z\in\mathbb{C}\mid\exists\lambda\in[0,\lambda% _{c,\varepsilon})\text{ s.t. }|z-\lambda|\leq\varepsilon\right\}. Then, for any k-uniform hypergraph H=(V,\mathcal{E}) with maximum degree \Delta, the partition function Z^{\mathrm{ly}}_{H}(\bm{\lambda}) is non-zero for all \bm{\lambda}\in\mathcal{D}^{V}_{\varepsilon}, i.e. \forall\bm{\lambda}\in\mathcal{D}^{V}_{\varepsilon},Z^{\mathrm{ly}}_{H}(\bm{% \lambda})\neq 0. As a corollary, there is no phase transition in \lambda\in[0,1] up till the “algorithmic transition” at \Delta\lesssim 2^{k/2}: Corollary 1.2. Let \delta>0, k\geq 2 and \Delta\geq 3 be constants with \Delta\leq\frac{1-\delta}{2\sqrt{2}\mathrm{e}k^{2}}\cdot 2^{\frac{k}{2}}. For any k-uniform hypergraph H=(V,\mathcal{E}) with maximum degree \Delta, Z^{\mathrm{ly}}_{H}(\lambda)\neq 0 around an open strip containing [0,1]. This is a significant improvement on [27] for k-uniform hypergraphs. We also prove a Fisher zero-free region. Theorem 1.3 (Fisher zeros of hypergraph independence polynomial). Fix k\geq 2 and \Delta\geq 3. Let 0<\varepsilon<\frac{1}{16(k+1)^{5}\Delta^{2}} and \mathcal{D}_{\varepsilon}=\left\{z\in\mathbb{C}\mid\exists\beta\in[0,1]\text{ % s.t. }|z-\beta|\leq\varepsilon\right\} be the union of \varepsilon-balls around [0,1]. If the following condition holds: \sqrt{1+2\varepsilon}2^{-k/2}<\frac{1}{2\sqrt{2}\mathrm{e}\Delta(k+1)^{2}}, then for any k-uniform hypergraph H=(V,\mathcal{E}) with maximum degree \Delta, the partition function Z^{\mathrm{fs}}_{H}(\bm{\beta}) is non-zero for all \bm{\beta}\in\mathcal{D}^{\mathcal{E}}_{\varepsilon}, i.e. \forall\bm{\beta}\in\mathcal{D}^{\mathcal{E}}_{\varepsilon},Z^{\mathrm{fs}}_{H% }(\bm{\beta})\neq 0. Remark 1.4 (implications for deterministic counting). FPTASes for the partition functions Z^{\mathrm{ly}}_{H}(\bm{\lambda}) and Z^{\mathrm{fs}}_{H}(\bm{\beta}) can be derived from the above zero-freeness results by applying Barvionk’s interpolation method [8, 56, 46]. The cumulants, such as the average size and variance of a random independent set, can also be approximated through a similar interpolation [36]. We note that in the regime of Theorem 1.1 specifically at the point \bm{\lambda}=1 (or in the regime of Theorem 1.3 at the point \bm{\beta}=0), an FPTAS for the partition function that counts the number of independent sets in the hypergraph H has already been found in [23], utilizing a different approach based on derandomization. However, as showcased by the following examples, zero-freeness have much broader applications beyond deterministic approximation of partition functions. Through the well-known connection between central limit theorems and the zero-freeness of univariate polynomials [43, 51, 36], we derive central limit theorems for hypergraph independent sets. We consider the Gibbs measure \mu_{H,\bm{\lambda}} associated with Z^{\mathrm{ly}}_{H}(\bm{\lambda}), defined as follows: \forall\sigma\in\mathcal{I}(H),\quad\mu_{H,\bm{\lambda}}(\sigma)=\frac{1}{Z^{% \mathrm{ly}}_{H}(\bm{\lambda})}\prod_{v:\sigma(v)=1}\lambda_{v}. The measure \mu_{H,\bm{\lambda}} can be analytically continued to the complex plane through a connected zero-free region, that is, regions where Z^{\mathrm{ly}}_{H}(\bm{\lambda})\neq 0. Our multivariate zero-freeness for the hypergraph independence polynomial is especially powerful. In principle, one can derive a central limit theorem for any univariate projection of the polynomial. We demonstrate a natural example by giving a quantitative central limit theorem (also known as Berry-Esseen inequality) for the size of a random independent set, drawn from the Gibbs measure of hypergraph independent sets. Our new zero-free region and central limit theorem (CLT) can be lifted to a local CLT as in [36]. We defer the proof to Appendix A. Theorem 1.5 (Central limit theorem for hypergraph independent sets). Fix k\geq 2 and \Delta\geq 3. Let H=(V,\mathcal{E}) be a k-uniform hypergraph with maximum degree \Delta. Let n=\left|V\right|. Fix any \delta>0, \varepsilon\in\left(0,\frac{1}{9k^{5}\Delta^{2}}\right). Let \lambda_{c,\varepsilon} be defined as in Theorem 1.1. For any \lambda\in(\delta,\lambda_{c,\varepsilon}], let I\sim\mu_{H,\lambda}, and define X=\left|I\right|, \bar{\mu}=\mathbb{E}[X] and \sigma^{2}=\mathrm{Var}[X]. Then we have \sigma^{2}=\Theta_{k,\Delta,\varepsilon}(\lambda n) and \sup_{t\in\mathbb{R}}\left|\mathbb{P}[(X-\bar{\mu})/\sigma\leq t]-\mathbb{P}[% \mathcal{Z}\leq t]\right|=O_{k,\Delta,\delta,\varepsilon}\left(\frac{\log n}{% \sqrt{n}}\right), where \mathcal{Z}\sim N(0,1) is a standard Gaussian random variable. Furthermore, let \mathcal{N}(x)=\mathrm{e}^{-x^{2}/2}/\sqrt{2\pi} denote the density of the standard normal distribution, we have \sup\limits_{t\in\mathbb{Z}}\left|\mathbb{P}[X=t]-\sigma^{-1}\mathcal{N}((t-% \bar{\mu})/\sigma)\right|=O_{k,\Delta,\varepsilon}\left(\min\left(\frac{(\log n% )^{5/2}}{\sigma^{2}},\frac{1}{\sigma^{2}}+\frac{\sigma^{2k}(\log n)^{2}}{n^{k-% 1}}\right)\right). As a side note, while there is rich literature on Markov chain central limit theorems (CLT), these do not seem to apply to our context. Specifically, our CLT crucially captures the unimodality of the stationary distribution itself, while Markov chain CLT concerns the sum of samples generated by a Markov chain, and does not seem to distinguish between unimodal and multimodal distributions. Log-Sobolev type inequalities (LSI), if available, would also give concentration tail estimates. But the recent spectral independence framework for establishing LSI for Markov chains requires arbitrary pinnings, which breaks the uniformity of hyperedges. Inspired by [36], we give an FPTAS based on zero-freeness and local CLT, to approximate the number of hypergraph independent sets of size t. The proofs are deferred to Appendix B. Theorem 1.6. Fix k\geq 2, \Delta\geq 3. Let H=(V,\mathcal{E}) be a k-uniform hypergraph with maximum degree \Delta and n=\left|V\right|. Let \varepsilon, \lambda_{c,\varepsilon} be defined as in Theorem 1.1. There exists a deterministic algorithm which, on input H, an integer 1\leq t\leq n\left(1-\frac{1}{1+\lambda_{c,\varepsilon}}\cdot\left(1+\frac{1}{% 4\mathrm{e}\Delta k^{3}}\right)\right), and an error parameter \eta\in(0,1), outputs an \eta-relative approximation to the number of hypergraph independent sets of size t in time (n/\eta)^{O_{k,\Delta,\varepsilon}(1)}. A consequence of the Perron-Frobenius theorem for nonnegative matrices is that any ergodic Markov chain converges to a unique stationary distribution. However, the convergence behavior for complex transition matrices is much less understood. Central to our analysis is the systematic scan Glauber dynamics with complex transition weights (see Definition 3.2 for a formal definition). We show that it converges to the stationary measure in the same regime of Theorem 1.1. Theorem 1.7 (Convergence of systematic scan Glauber dynamics with complex transitions). Under the condition of Theorem 1.1, the systematic scan Glauber dynamics for the complex measure associated with the independence polynomial Z^{\mathrm{ly}}_{H}(\bm{\lambda}) converges. 1.3. Technical overview A few challenges arise when trying to locate complex zeros through a percolation-type argument. To extend the notion of probability measures to the complex plane, one can formally define complex normalized measures as ratios between partition functions. However, a generalization of statements such as “stochastically dominated by a sub-critical branching process” for complex measures appears very challenging. In particular, the monotonicity of probability measures crucially relies on the non-negativity axiom. Our key observation is that a factorization property, which arises in decomposing the Glauber dynamics, can be translated to the complex plane. Our starting point for locating complex zeros of Z^{\mathrm{ly}}_{H}(\bm{\lambda}) is an induction on marginal measures. This approach is implicit in the Lee-Yang theorem and the Asano-Ruelle lemma [49, 7, 61], and is applied more explicitly in the contraction method [57, 47, 65]. We give a quick review below. 1.3.1. Locating complex zeros through marginal measures Here we use the standard edge-wise self-reducibility, consider a hypergraph H=(V,\mathcal{E}) with \mathcal{E}=\{e_{1},e_{2},\dots,e_{m}\}, and let H_{i}=(V,\mathcal{E}_{i}) where \mathcal{E}_{i}=\{e_{1},e_{2},\dots,e_{i}\}. We write the partition function as: Z_{H}=Z_{H_{0}}\prod_{i=1}^{m}\frac{Z_{H_{i}}}{Z_{H_{i-1}}}. To establish Z_{H}\neq 0, it suffices to show \frac{Z_{H_{i}}}{Z_{H_{i-1}}}\neq 0 as it is clear that Z_{H_{0}}\neq 0. The ratio \frac{Z_{H_{i}}}{Z_{H_{i-1}}} corresponds to a marginal measure, which we explain in the context of hypergraph independence polynomial. A hypergraph independent set \sigma in H_{i-1} is an independent set in H_{i} if and only if \sigma_{e_{i}}\neq 1^{k}. Thus, \frac{Z_{H_{i}}}{Z_{H_{i-1}}}=1-\mu_{H_{i-1}}\left(\sigma_{e_{i}}=1^{k}\right), where \mu_{H_{i-1}} is the measure associated with Z_{H_{i-1}}. Then, one can set up an induction on i: assuming that Z_{H_{i-1}}\neq 0, one shows that the marginal measure \mu_{H_{i-1}}\left(\sigma_{e_{i}}=1^{k}\right)\neq 1, this implies Z_{H_{i}}\neq 0. 1.3.2. Marginal measures through information percolation on complex Markov chains Our departure from previous works on the absence of zeros is that we introduce a systematic scan Glauber dynamics to analyze the marginal measures. Introducing Glauber dynamics is crucial in bypassing a barrier to a better zero-free region for the hypergraph independence polynomial: strong spatial mixing does not hold, and a computational tree construction does not preserve the uniformity of hyperedges. Given a measure \mu_{H,\bm{\lambda}}, Glauber dynamics is a canonical way of constructing a Markov chain with stationary measure \mu_{H,\bm{\lambda}}. In particular, the transition matrix of the Glauber dynamics, denoted by P_{\bm{\lambda}}, can also be analytically continued to the complex plane through a connected zero-free region as \mu_{H,\bm{\lambda}} is well-defined. In particular, \mu_{H,\bm{\lambda}} is a left eigenvector for P_{\bm{\lambda}} with eigenvalue 1. The analysis of Markov chains for \lambda\in\mathbb{R} mainly concerns the spectral gap of P_{\bm{\lambda}}, but the spectral gap usually tends to zero as n goes to infinity (in the thermodynamics limit). Instead of attempting a complex extension of spectral theory, we work with the marginal measures generated by powers of the transition matrix P_{\bm{\lambda}}. To get a handle on the marginal measures, we take inspirations from the decomposition of Glauber dynamics that arises in information percolation arguments for Markov chains [45, 33, 32, 58, 23]. In these applications, one starts by formulating the Markov chain on a space-time slab (also known as a witness graph) so that updates, when viewed backward in time, behave like a subcritical percolation. To do so, each step of the dynamics is decomposed into an oblivious update part, which updates a site independent of its neighbors, and an adaptive (non-oblivious) part in which one tries to make up the correct transition probability. By revealing the randomness used in these updates backward in time, we either continue the revealing process due to an adaptive update or terminate it upon encountering an oblivious update. Previously, this percolation argument has primarily been used to bound the mixing rates of classical Markov chains [45, 33] and to analyze the time required for coalescence in grand coupling processes, such as coupling from the past (CFTP) [32, 58] and its variant, coupling towards the past (CTTP) [23]. Our idea is to interpret a decomposition of Glauber dynamics as implicitly a decomposition of the transition matrix P_{\bm{\lambda}}, also into an oblivious part and an adaptive part. Say we “initialize” the Glauber dynamics with a complex measure \mu, viewed as a row vector, and we consider the measure generated by T steps of Glauber dynamics, which is the vector-matrix product \mu P_{\bm{\lambda}}^{T}. By expanding this summation, one can see that, upon encountering an oblivious part, the contribution to the sum “factorizes”. In fact, the result of \mu P_{\bm{\lambda}}^{T} formally corresponds to summing over walks of length T over a space-time slab, where each node is weighted by the corresponding entry in the transition matrix. And the factorization is what leads us to define “independence” for complex measures, which effectively allows us to “terminate the percolation” just as in a standard argument. Central to our analysis is to show that, after running the dynamics for sufficiently long, we can use the “oblivious updates” as a certificate/witness for the measure of any event, in the sense that these witness sequences dominate the complex measure \mu P_{\bm{\lambda}}^{T}. This is formalized as 3.9. These oblivious updates themselves are much easier to analyze as they correspond to a product of complex measures. By identifying the measure generated by \mu P_{\bm{\lambda}}^{T} as contributions from an information percolation on a space-time slab (formally defined as witness graphs in Definition 4.4) , we introduce several dynamics-related quantities — bad vertices, bad components, bad trees (Definition 4.6) — to trace the information percolation process (formally through Lemmas 4.7, 4.8 and 4.10). Then, we express the measure of any configuration by these quantities. When the information percolation process terminates quickly (in the sense of 3.9), we can control the marginal measure using a product of complex measures. 1.3.3. Convergence of the complex systematic scan Glauber dynamics The convergence of Markov chains in the real case is well understood thanks to the Perron-Frobenius theory and the coupling method. It is unclear what the right generalizations to the complex plane should be. Using the information percolation framework, we categorize the percolation processes as follows: (1) processes that terminate before reaching the starting time (Lemma 4.7); (2) processes that do not terminate before reaching the starting time (Lemma 4.10). To establish convergence, it suffices to show that the contributions from type (2) processes diminish to zero. Unlike standard percolation theory where the existence of limits are guaranteed by monotone events, we have to give non-asymptotic bounds before taking an appropriate limit (see Lemma 4.10). Combined, this allows us to show that the measure of any event is dominated by witness sequences (3.9), and we give a proof of convergence in Lemma 3.10."
https://arxiv.org/html/2411.06546v1,Lower Bounds for Adaptive Relaxation-Based Algorithms for Single-Source Shortest Paths,"We consider the classical single-source shortest path problem in directed weighted graphs. D. Eppstein proved recently an \Omega(n^{3}) lower bound for oblivious algorithms that use relaxation operations to update the tentative distances from the source vertex. We generalize this result by extending this \Omega(n^{3}) lower bound to adaptive algorithms that, in addition to relaxations, can perform queries involving some simple types of linear inequalities between edge weights and tentative distances. Our model captures as a special case the operations on tentative distances used by Dijkstra’s algorithm.","We consider the classical single-source shortest path problem in directed weighted graphs. In the case when all edge weights are non-negative, Dijkstra’s algorithm [8], if implemented using Fibonacci heaps, computes the shortest paths in time O(m+n\log n), where n is the number of vertices and m is the number of edges. In the general case, when negative weights are allowed (but not negative cycles), the Bellman-Ford algorithm [20, 2, 19, 12] solves this problem in time O(nm). Both algorithms work by repeatedly executing operations of relaxations. (This type of algorithms are also sometimes called label-setting algorithms [7].) Let \ell_{uv} denote the weight of an edge (u,v). For each vertex v, these algorithms maintain a value D[v] (that we will refer to as the D-value at v) that represents the current upper bound on the distance from the source vertex s to v. A relaxation operation for an edge (u,v) replaces D[v] by \min{\left\{{D[v],D[u]+\ell_{uv}}\right\}}. That is, D[v] is replaced by D[u]+\ell_{uv} if visiting v via u turns out to give a shorter distance to v, based on the current distance estimates. When the algorithm completes, each value D[v] is equal to the correct distance from s to v. Dijkstra’s algorithm executes only one relaxation for each edge, while in the Bellman-Ford algorithm each edge can be relaxed \Theta(n) times. We focus on the case of complete directed graphs, in which case m=n(n-1). For complete graphs, the number of relaxations in Dijkstra’s algorithm is \Theta(n^{2}). In contrast, the Bellman-Ford algorithm executes \Theta(n^{3}) relaxations. This raises the following natural question: is it possible to solve the shortest-path problem by using asymptotically fewer than O(n^{3}) relaxations, even if negative weights are allowed? To make this question meaningful, some restrictions need to be imposed on allowed algorithms. Otherwise, an algorithm can “cheat”: it can compute the shortest paths without any explicit use of relaxations, and then execute n-1 relaxations on the edges in the shortest-path tree, in order of their hop-distance from s, thus making only n-1 relaxations. Eppstein [9] circumvented this issue by assuming a model where the sequence of relaxations is independent of the weight assignment. Then the question is whether there is a short “universal” sequence of relaxations, namely one that works for an arbitrary weight assignment. The Bellman-Ford algorithm is essentially such a universal sequence of length O(n^{3}). Eppstein [9] proved that this is asymptotically best possible; that is, each universal relaxation sequence must have \Omega(n^{3}) relaxations. This lower bound applies even in the randomized case, when the relaxation sequence is generated randomly and the objective is to minimize the expected number of relaxations. The question left open in [9] is whether the \Omega(n^{3}) lower bound applies to relaxation-based adaptive algorithms, that generate relaxations based on information collected during the computation. (This problem is also mentioned by Hu and Kozma [15], who remark that lower bounds for adaptive algorithms have been “elusive”.) We answer this question in the affirmative for some natural types of adaptive algorithms. In our computation model, an algorithm is allowed to perform two types of operations: (i) queries, which are simple linear inequalities involving edge weights and D-values, and (ii) relaxation updates, that modify D-values. The action at each step depends on the outcomes of the earlier executed queries. Such algorithms can be represented as decision trees, with queries and updates in their nodes, and with each query node having two children, one corresponding to the “yes” outcome and the other to the “no” outcome. Specifically, we study query/relaxation-based algorithms that can make queries of three types: D-comparison query: “D[u]<D[v]?”, for two vertices u, v, Weight-comparison query: “\ell_{uv}<\ell_{xy}?”, for two edges (u,v), (x,y), Edge query: “D[u]+\ell_{uv}<D[v]?”, for an edge (u,v), and can update D-values as follows: Relaxation update: “D[v]\,{\leftarrow}\,\min{\left\{{D[v],D[u]+\ell_{uv}}\right\}}”, for an edge (u,v). Throughout the paper, for brevity, we will write “D-query” instead of “D-comparison query” and “weight query” instead of “weight-comparison query”. We assume that initially D[s]=0 and D[v]=\ell_{sv} for all vertices v\neq s. This initialization and the form of relaxation updates ensure that at all times each value D[v] represents the length of some simple path from s to v. Thus D-queries and edge queries amount to comparing the lengths of two paths from s. Further, the D-values induce a tentative approximation of the shortest-path tree, where a node u is the parent of a node v if the last decrease of D[v] resulted from a relaxation of edge (u,v). So the algorithm’s decision at each step depends on this tentative shortest-path tree. Our contributions. We start by considering algorithms that use only edge queries. For such algorithms we prove the following \Omega(n^{3}) lower bound: Theorem 1. (a) Let \mathcal{A} be a deterministic query/relaxation-based algorithm for the single-source shortest path problem that uses only edge queries. Then the running time of \mathcal{A} is \Omega(n^{3}), even if the weights are non-negative and symmetric (that is, the graph is undirected). (b) If \mathcal{A} is a randomized algorithm then the same \Omega(n^{3}) lower bound holds for \mathcal{A}’s expected running time. We first give the proof of Theorem 1(a), the lower bound for deterministic algorithms. In this proof, (in Section 3), we view the computation of \mathcal{A} as a game against an adversary who gradually constructs a weight assignment, consistent with the queries, on which most of the edge queries performed by \mathcal{A} will have negative outcomes, thus revealing little information to \mathcal{A} about the structure of the shortest-path tree. Then, in Section 4, we show how to extend this lower bound to all three types of queries if negative weights are allowed, proving Theorem 2(a) below. Theorem 2. (a) Let \mathcal{A} be a deterministic query/relaxation algorithm for the single-source shortest path problem that uses the three types of queries: D-queries, weight-queries, and edge queries, as well as relaxation updates. Then the running time of \mathcal{A} is \Omega(n^{3}). (b) If \mathcal{A} is a randomized algorithm then the same \Omega(n^{3}) lower bound holds for \mathcal{A}’s expected running time. Our query/relaxation model captures as a special case the operations on tentative distances used by Dijkstra’s algorithm, because D-queries are sufficient to maintain the ordering of vertices according to their D-values. More broadly, Theorem 2 may be helpful in guiding future research on speeding up shortest-path algorithms for the general case, when negative weights are allowed, by showing limitations of naïve approaches based on extending Dijkstra’s algorithm. The proof of Theorem 2(a) is essentially via a reduction, showing that the model with all three types of queries can be reduced to the one with only edge queries, and then applying the lower bound from Theorem 1(a). This reduction modifies the weight assignment, making it asymmetric and introducing negative weights. As a side result, we also observe in Theorem 4 that this reduction works even for arbitrary (not necessarily complete) graphs, giving a lower bound that generalizes the one in [9], as it applies to adaptive algorithms in our query/relaxation model. Finally, in Section 5 we extend both lower bounds to randomized algorithms. The proofs are based on Yao’s principle [22]; that is, we give a probability distribution on weight assignments on which any deterministic algorithm performs poorly. Our lower bound results are valid even if all weights are integers of polynomial size. In the proof of Theorem 1 all weights are non-negative integers with maximum value {\ell}_{\textrm{max}}=O(n). The proof of Theorem 2 uses Golomb rulers [21, 10, 4] (also known as Sidon sets) to construct weight assignments with maximum value {\ell}_{\textrm{max}}=O(n^{4}). In the randomized case, these bounds increase by a factor of O(n). As explained near the end of Section 5, the lower bounds for expectation in Theorems 1(b) and 2(b) can be quite easily extended to high-probability bounds. Related work. As earlier mentioned, the Bellman-Ford algorithm can be thought of as a universal relaxation sequence. It consists of n-1 iterations with each iteration relaxing all edges in some pre-determined order, so the length of this sequence is (1+o(1))n^{3}. The leading constant 1 in this bound was reduced to \textstyle{\frac{1}{2}} by Yen [23], who designed a universal sequence with (\textstyle{\frac{1}{2}}+o(1))n^{3} relaxations. Eppstein’s lower bound in [9] shows in fact a lower bound of \textstyle{\frac{1}{6}} on the leading constant, and just recently Hu and Kozma [15] proved that constant \textstyle{\frac{1}{2}} is in fact optimal. Bannister and Eppstein [1] showed that the leading constant can be reduced to \textstyle{\frac{1}{3}} with randomization, namely that there is a probability distribution on relaxation sequences for which a sequence, drawn from this distribution, will compute correct distances in expected time (\textstyle{\frac{1}{3}}+o(1))n^{3} (or even with high probability). Eppstein’s lower bound proof [9] for randomized sequences shows that this constant is at least \textstyle{\frac{1}{12}}. Some of the above-mentioned papers extend the results to graphs that are not necessarily complete. In particular, Eppstein [9] proved that for n-vertex graphs with m edges, \Omega(mn/\log n) relaxations are necessary. The average-case complexity of the Bellman-Ford and Dijkstra’s algorithms has also been studied. For example, Meyer et al. [18] show that the Bellman-Ford algorithm requires \Omega(n^{2}) steps on average, if the weights are uniformly distributed random numbers from interval [0,1]. Some work has been done on improving lower and upper bounds in models beyond our query/relaxation setting. Of those, the recent breakthrough paper by Fineman [11] is particularly relevant. It gives a randomized {\tilde{O}}(mn^{8/9})-expected-time algorithm for computing single-source shortest paths with arbitrary weights. Fineman’s computation model is not far from ours in the sense that the weights are arbitrary real numbers and the only arithmetic operations on weights are additions and subtractions, but it also needs branch instructions that cannot be expressed using our queries. The special case when weights are integers is natural and has been extensively investigated (see [6, 13, 3], for example). In the integer domain one can extract information about the weight distribution, and thus about the structure of the shortest-path tree, using operations other than linear inequalities involving weights. The state-of-the-art in this model is the (randomized) algorithm by Bernstein et al. [3] that achieves running time O(m\log^{8}n\log W) with high probability for weight assignments where the smallest weight is at least -W (and W\geq 2). Some lower bounds have also been reported for related problems, for example for shortest paths with restrictions on the number of hops [5, 14, 17] or k-walks [16]."
https://arxiv.org/html/2411.06405v1,Parallel Higher-order Truss Decomposition,"The k-truss model is one of the most important models in cohesive subgraph analysis. The k-truss decomposition problem is to compute the trussness of each edge in a given graph, and has been extensively studied. However, the conventional k-truss model is difficult to characterize the fine-grained hierarchical structures in networks due to the neglect of high order information. To overcome the limitation, the higher-order truss model is proposed in the literature. However, the previous solutions only consider non-parallel scenarios. To fill the gap, in this paper, we conduct the first research to study the problem of parallel higher-order truss decomposition. Specifically, a parallel framework is first proposed. Moreover, several optimizations are further developed to accelerate the processing. Finally, experiments over 6 real-world networks are conducted to verify the performance of proposed methods.","Graphs are widely used to model the complex relationships among entities, such as social networks, protein-protein interaction networks and finance networks (Wang et al., 2016; Cheng et al., 2021; Wu et al., 2024). As one of the most fundamental tasks in graph analysis, cohesive subgraph detection has been extensively studied, and different models are proposed in the literature, such as k-core, k-truss, k-plex and clique (Wu et al., 2020; Chen et al., 2021c, a). Among them, k-truss has received a lot of attention for its excellent balance between density and efficiency. k-truss leverages the properties of triangle to model the strength of connections. Specifically, given a graph G and positive integer k, the k-truss is the maximal subgraph S of G, such that the support of each edge e(u,v) in S is no less than k-2. The support of e(u,v) is the number of triangles that contain the edge in S, i.e., the number of common neighborhoods of u and v in the subgraph. The trussness of an edge is the largest k that k-truss contains the edge, i.e., the edge is in k-truss but not (k+1)-truss. Then, the k-truss can be computed by returning all the edges with trussness no less than k. However, the k-truss model also has certain limitations. k-truss more focuses on describing pairwise interactions in the subgraph, while real-world systems may have many higher-order interactions involving groups of three or more units, which limits its application. Therefore, the higher-order truss model is proposed and studied in the literature to better capture the hierarchy of substructures (Chen et al., 2021b). In particular, given a graph G, an integer k, and a hop threshold h, the higher-order (k,h)-truss of G is the maximal subgraph S, where the h-support of each edge in S is no less than k-2. h-support is the number of h-hop common neighbors for a given edge. The following motivating example illustrates that higher-order truss enables us to find more find-grained substructures in the underlying graph. (a) 1-hop neighborhood (b) 2-hop neighborhood Figure 1. Motivation example of higher-order truss decomposition Example 0. Figure 1 shows a toy social network with 14 nodes. The numbers on the edges in Figures 1(a) and 1(b) denote the corresponding trussness and higher-order trussness, respectively. If we adopt the k-truss model, the graph G will be decomposed into 2-truss and 3-truss as shown in Figure 1(a) which lacks a sense of hierarchy. On the other hand, if we consider h=2, the (k,h)-truss model will find (4,2)-truss, (5,2)-truss and (6,2)-truss with a hierarchical structure. Specifically, the trusses are shown in Figure 1(b) with different shades. For the higher-order scenario, given a graph G, the h-trussness of an edge e is the largest k such that the (k,h)-truss contains e, i.e., e belongs to (k,h)-truss but not (k+1,h)-truss. The higher-order truss decomposition problem is to compute the h-trussness of all the edges for a given h. Similar as k-truss, based on h-trussness, we can easily retrieve the higher-order truss for any given k. Naively, we can extend the peeling framework for k-truss decomposition to solve the higher-order case (Chen et al., 2021b). However, it will generate much computation due to the larger search space in high order neighbors. Moreover, the computation cost would increase rapidly for higher h. To solve the problem, we conduct the first research to investigate the alternative of parallel solution. Contributions. The contributions of this paper are summarized as follows. • In this paper, we propose a parallel framework for higher-order truss decomposition based on the H-index computation paradigm. • Several optimization techniques are further proposed to accelerate the computation by considering the possibility of asynchronous update and redundant computation pruning. • We conducted extensive experiments on 6 real-world graphs to demonstrate the performance of proposed techniques. Roadmap. The rest of the paper is organized as follows. We formally introduces the problem studied in Section 2, and present a baseline non-parallel approach in Section 3. In Section 4, we present the parallel framework and optimization techniques proposed. In Section 5, we demonstrate the performance of the proposed techniques. We introduce the related works in Section 6 and conclude the paper in Section 7."
https://arxiv.org/html/2411.06370v1,One Attack to Rule Them All: Tight Quadratic Bounds for Adaptive Queries on Cardinality Sketches,"Cardinality sketches are compact data structures for representing sets or vectors, enabling efficient approximation of their cardinality (or the number of nonzero entries). These sketches are space-efficient, typically requiring only logarithmic storage relative to input size, and support incremental updates, allowing for dynamic modifications. A critical property of many cardinality sketches is composability, meaning that the sketch of a union of sets can be computed from individual sketches. Existing designs typically provide strong statistical guarantees, accurately answering an exponential number of queries in terms of sketch size k. However, these guarantees degrade to quadratic in k when queries are adaptive and may depend on previous responses.Prior works on statistical queries (Steinke and Ullman, 2015) and specific MinHash cardinality sketches (Ahmadian and Cohen, 2024) established that the quadratic bound on the number of adaptive queries is, in fact, unavoidable. In this work, we develop a unified framework that generalizes these results across broad classes of cardinality sketches. We show that any union-composable sketching map is vulnerable to attack with \tilde{O}(k^{4}) queries and, if the sketching map is also monotone (as for MinHash and statistical queries), we obtain a tight bound of \tilde{O}(k^{2}) queries. Additionally, we demonstrate that linear sketches over the reals \mathbb{R} and fields \mathbb{F}_{p} can be attacked using \tilde{O}(k^{2}) adaptive queries, which is optimal and strengthens some of the recent results by Gribelyuk et al. (2024), which required a larger polynomial number of rounds for such matrices.","Cardinality sketches are compact representations of subsets U\in 2^{\mathcal{U}} of a ground set \mathcal{U} of size n=|\mathcal{U}|. These sketches enable efficient approximations of a set’s cardinality, using a much smaller representation than the original set. A key feature is composability – support for essential set operations directly in the sketch space, such as adding elements and merging sets (see Definition 5.1 for a precise definition). Specifically, the sketch of U\cup\{x\} can be computed from the sketch of U without additional access to U, and the sketch of U\cup V can be computed from the sketches of (potentially overlapping) subsets U and V. Composability also allows for efficient sketching of distributed or streaming data. Cardinality sketches were extensively studied Flajolet and Martin (1985); Flajolet et al. (2007b); Cohen (1997); Alon et al. (1999); Bar-Yossef et al. (2002); Kane et al. (2010); Cohen (2015); Blasiok (2020) and widely applied in practice (Apache Software Foundation, Accessed: 2024; Google Cloud, Accessed: 2024). Notable methods include the variety of MinHash sketches – k-partition Flajolet and Martin (1985); Flajolet et al. (2007b), k-mins (Cohen, 1997; Broder, 2000), and bottom-k (Rosén, 1997; Cohen, 1997; Broder, 1997; Bar-Yossef et al., 2002) (see survey Cohen (2008, 2023)) and linear sketches (Cormode et al., 2003; Ganguly, 2007; Kane et al., 2010). Most prevalent in practice are implementations based on the HyperLogLog MinHash sketch Flajolet et al. (2007a); Heule et al. (2013). These methods are parametrized by the sketch size k. They define a distribution from which a sketching map S, which maps sets to their sketches, is randomly sampled. To facilitate composability,111and to support additional approximate queries in sketch space such as set similarity it is crucial that the same sketching map S is consistently applied to all subsets. The methods pair each sketching map S with an estimator that maps sketches S(U) to estimates of the cardinality |U|. These methods provide statistical guarantees on accuracy: for any particular subset U, the probability of a mistake (relative error that exceeds the specification) over the sampling of the sketching and estimator map pairs decreases exponentially with the sketch size k. Therefore, with a sketch size of k, an exponential number of queries in k can be approximated with a small relative error. Importantly, this assumes that the queries are non-adaptive, meaning they do not depend on the specific sampled sketching map S (for the purpose of analysis, the queries can be considered as fixed in advance, before the map is sampled). Adaptive vs non-adaptive settings In adaptive settings, inputs are generated interactively, with each input potentially depending on previous outputs. These outputs – and thus subsequent inputs – may be influenced by the randomness of the sketching map. Therefore, analyses that assume query independence from the map no longer hold. The issue is that even if the map errs on only a small fraction of possible inputs that appear randomly distributed, and hence hard to find without information on the map, an adaptive querying algorithm might be able to quickly focus on these problematic inputs. Research works on the adaptive settings span multiple sub-areas including statistical queries (Freedman, 1983; Ioannidis, 2005; Lukacs et al., 2009; Hardt and Ullman, 2014; Dwork et al., 2015a), sketching and streaming algorithms (Mironov et al., 2008; Hardt and Woodruff, 2013; Ben-Eliezer et al., 2021b; Hassidim et al., 2020; Woodruff and Zhou, 2021; Attias et al., 2021; Ben-Eliezer et al., 2021a; Cohen et al., 2022a, b; Ahmadian and Cohen, 2024), dynamic graph algorithms (Shiloach and Even, 1981; Ahn et al., 2012; Gawrychowski et al., 2020; Gutenberg and Wulff-Nilsen, 2020; Wajc, 2020; Beimel et al., 2021), and machine learning (Szegedy et al., 2013; Goodfellow et al., 2014; Athalye et al., 2018; Papernot et al., 2017). Positive results via wrapper methods Statistical guarantees for adaptive queries can be obtained by robustness wrapper methods that use in a black box manner multiple independent copies of a randomized data structure that only provides statistical guarantees for non-adaptive queries. A straightforward wrapper maintains k copies and responds to each query using a separate copy, thus only supporting at most k adaptive queries (in fact slightly less, since once has to apply a union bound to argue that all copies succeeded). The robust approaches allow for a number of queries that is quadratic in the number of copies k. That is, answer \tilde{O}(k^{2}) queries using k independent sketching maps. This result was first established for adaptive statistical queries Kearns (1998) by (Dwork et al., 2015b; Bassily et al., 2021). The idea was to use differential privacy to protect the identity of the sampled keys. The quadratic boost followed from the advanced composition property of differential privacy (Dwork et al., 2006) (that for a fixed privacy budget, allows for a number of privacy-preserving queries that is quadratic in the number of protected units). The robustness wrapper method of Hassidim et al. (2020) lifted this framework from statistical queries to any randomized data structure by interpreting the protected unit as the randomness initializing the data structure. An interesting alternative approach to obtain this quadratic boost without engaging the theory of differential privacy was given by Blanc (2023) who established that it suffices to randomly sample a copy and use it to respond to each query. Negative results by attack constructions Lower bounds were obtained using explicit constructions of attacks that specify an adaptive sequence of queries. Hardt and Ullman (2014); Steinke and Ullman (2015) presented quadratic size attacks for adaptive statistical queries, based on Fingerprinting Codes (Boneh and Shaw, 1998). Hardt and Woodruff (2013) designed a polynomial-size attack on general linear sketches for \ell_{2} norm estimation, with any estimator map. Cherapanamjeri and Nelson (2020) constructed an \tilde{O}(k) size attack on the Johnson Lindenstrauss Transform with the standard estimator. Ben-Eliezer et al. (2021b) presented an \tilde{O}(k) size attack on the AMS sketch (Alon et al., 1999) with the standard estimator. Cohen et al. (2022a) presented an \tilde{O}(k) size attack on Count-Sketch (Charikar et al., 2002) with the standard estimator map. Cohen et al. (2022b) constructed an \tilde{O}(k^{2}) attack on the AMS sketch and on Count-Sketch (when used for heavy hitter or inner product queries) that applies with any estimator map. Specifically for cardinality sketches, Reviriego and Ting (2020) and Paterson and Raynal (2021) constructed \tilde{O}(k) size attacks on the popular HLL sketch Flajolet et al. (2007a) with the standard estimator (Heule et al., 2013). Ahmadian and Cohen (2024) constructed single-batch \tilde{O}(k) size attacks on the standard estimator and \tilde{O}(k^{2}) attacks on any estimator maps for MinHash sketching maps. Finally, a recent work by Gribelyuk et al. (2024) on linear sketch maps construct attacks of a polynomial size O(\mathrm{poly}(k)) over the reals \mathbbm{R}, of O(k^{8}) size over the integers \mathbbm{Z}, and of O(k^{3}) size over a finite field \mathbbm{F}_{p}. To summarize, existing upper bounds for norm sketching problems, including cardinality sketching, allow for a number of adaptive queries that is quadratic in sketch size. Existing lower bound results are either of super-quadratic polynomial size or are specific to particular sketching maps or even to specific estimator maps. This raises the following natural questions: Question 1.1. Can we devise a unified adaptive attack that broadly applies to all composable cardinality sketches? What is the broadest class of cardinality sketches for which we can design such an attack of polynomial size? Of quadratic size? 1.1 Overview of contributions Our results affirmatively settle Question 1.1 for a broad classes of sketching maps, namely composable sketches and linear sketches. Our main contribution is an attack framework that unifies, simplifies, and generalizes prior works including the method of Ahmadian and Cohen (2024), which was specifically tailored for certain known MinHash cardinality sketch designs, and the lower bound of Ullman et al. (2018); Hardt and Ullman (2014); Steinke and Ullman (2015) that was specific for adaptive statistical queries (Kearns, 1998) and based on fingerprinting codes (Boneh and Shaw, 1998). A sketching map is specified by a pair (S,\mathcal{U}), where \mathcal{U} is a ground set of keys of size |\mathcal{U}|=n and S:2^{\mathcal{U}} represents a map from sets to their sketches. Our interaction model follows prior work and is described in detail in Section 2. An attacker issues a sequence of adaptive queries (U_{i}) where U_{i}\in 2^{\mathcal{U}} is a subset of our ground set. A query responder (QR) receives the sketch S(U_{i}) of the query and returns a response Z_{i}.222Observe that this can be casted in a streaming setting, by using updates to turn U_{i} into U_{i+1} (just delete U_{i}\setminus U_{i+1} and then insert U_{i+1}\setminus U_{i}). Instead of approximate cardinality queries, we task the query responder with the simpler soft threshold queries. For fixed values A<B, the response is a single bit Z that is correct if Z=0 when the cardinality is |U|\leq A and Z=1 when |U|\geq B. Any response Z\in\{0,1\} is acceptable as correct when |U|\in(A,B). Observe that these simpler queries, and in particular larger ratios B/A, only makes the query responder more resilient to attacks. Our attacks apply with B/A=\Omega(1). The goal of the attack is to force the query response algorithm to make mistakes on at least some constant fraction \eta of the queries. 1.1.1 Attack Framework Our attack (see details in Section 3) specifies a distribution \mathcal{Q} over 2^{\mathcal{U}} where a rate q is sampled from some distribution and a subset U\sim\textnormal{{Bern}}[q]^{\mathcal{U}} is sampled by including each key independently with probability q. The actual query subset is U\cup M, where M\subset\mathcal{U} is an initially empty set that we refer to as a mask. The query responder answers a soft threshold query based on the sketch S(U\cup M). When the response is 1, the attacker increments the score of all keys in U\setminus M. Keys in \mathcal{U}\setminus M with scores that are sufficiently above the median score are added to M. The goal of the attack is to force an incorrect response on at least some fixed constant \eta fraction of the specified number of r queries. The analysis idea is as follows: if the responder makes many intentional unforced errors, and thus does not reveal enough about the map S, then our goal is achieved. Otherwise, the attacker makes progress in building the mask M and specifically towards making the distribution \mathcal{Q}\cup M333The notation V\sim\mathcal{Q}\cup M means that we sample U\sim\mathcal{Q} and take V=U\cup M. adversarial to the sketching map S. The distribution is \eta-adversarial if for any estimator map \phi, \phi(S(V)) is incorrect with probability at least \eta. When the distribution becomes adversarial, the query responder, even if it knows \mathcal{Q}\cup M, must make forced errors on at least an \eta fraction of the remaining queries. Our analysis of the attack relies on the existence of a determining pool L\subset\mathcal{U}, a smaller set of keys |L|\ll|\mathcal{U}| such that we can determine the sketch of the query U\cup M only from its intersection with the pool: Definition 1.2 (Determining pool; simplified). For a sketching map (S,\mathcal{U}), a set L\in 2^{\mathcal{U}} is a determining pool if for any M\subset L, with probability at least 1-\delta over U\sim\mathcal{Q}, the sketch S(U\cup M) can be computed from M and U\cap(L\setminus M). Theorem 1.3 (Informal; See Theorem 3.6 and Lemma 3.13). If the sketching map (S,\mathcal{U}) has a determining pool L\in 2^{\mathcal{U}} so that |L|\ll n,444|L|<cn for some universal constant c<1 our unified attack succeeds with probability 1-\delta after r=O(\log(1/\delta)|L|^{2}\log n) queries. This holds even against a powerful and strategic query response algorithm that is tailored to our query distribution at each step. To establish that our attack works for a class of sketches \mathcal{S}, all we need to do is to prove that a determining pool of size \ell\ll n exists for each sketching map in the class. We demonstrate (see Section 1.3) how the lower bound of Steinke and Ullman (2015) on statistical queries and the results of Ahmadian and Cohen (2024) for MinHash sketches can be obtained by simply specifying the determining pool of the sketching map. We also apply our framework to obtain new results for very broad classes of sketching maps: composable sketches and linear sketches. Remark 1.4 (Implication for Differentially Private Data Analysis). The existence of small determining pools for any composable sketch reveals inherent limitations of performing differentially private data analysis in the sketch space rather than directly on the original query sets. Specifically, the “sensitivity” depends inversely on the pool size \tilde{O}(k) rather than on the potentially much larger query set size. This generalizes findings by Desfontaines et al. (2019) for specific sketching maps. 1.1.2 Application to Composable Sketches (See details in Section 5 and Sections 7–9 for analysis) A sketching map (S,\mathcal{U}) is composable if for any two subsets U,V\in 2^{\mathcal{U}}, the sketch S(U\cup V) can be composed solely from the sketches S(U) and S(V) (without access to U or V). We say that a composable map has rank k if the representation of each sketch uses at most k bits. Alternatively, it suffices that for each sketch \sigma, the cardinality of a minimal subset with sketch \sigma is at most k, that is, when U is minimal such that S(U)=\sigma (we say U is a core of \sigma), then |U|\leq k. A composable sketching map is monotone (simplified; see Definition 5.3) if for any U\subset V, the cardinality of the cores of S(U) is no larger than the cardinality of the cores of S(V). Monotonicity is a natural property which means that the sketching maps are “efficient” in that they are no less informative for larger sets than for smaller sets. The sketching maps of statistical queries and of MinHash sketches are monotone and composable (see Section 1.3). Theorem 1.5 (Informal, see Theorem 5.5). For any composable sketching map (S,\mathcal{U}) of rank k such that n=\tilde{\Omega}(k^{2}), the attack succeeds using \tilde{O}(k^{4}) queries. If the map is also monotone and n=\tilde{\Omega}(k), the attack succeeds using \tilde{O}(k^{2}) queries. We prove the theorem by constructing a determining pool that is of size O(k^{2}\log(k/\delta)) for any composable sketching map and of size O(k\log(k/\delta)) for any monotone composable sketching map, and then applying Theorem 1.3. The pool construction is simple and is based on a peeling process of the ground set \mathcal{U}, where in each step we peel a core of the sketch of the remaining keys that is contained in the remaining keys. That is, a minimal subset A_{i}\subset\mathcal{U}\setminus\bigcup_{j<i}A_{j} so that S(A_{i})=S(\mathcal{U}\setminus\bigcup_{j<i}A_{j}). For maps with rank k, the size of each layer satisfies |A_{i}|\leq k and we establish that the number of layers we need is O(k\log(k/\delta)) for general composable sketching maps and O(\log(k/\delta)) for monotone maps. We also (Section 8.4) give an example of a (non-monotone) composable map of rank k where \Theta(k\log k) layers of size \Theta(k) are necessary for a pool, and hence, our analysis for the peeling construction is tight. Observe that if the size of the ground set is n\leq k, we can represent S(U) by U. This makes (S,\mathcal{U}) trivially composable of rank k. Furthermore, since S is injective, it is resilient to attacks, as the goal of an attack is essentially to identify sets with very different cardinalities that produce the same sketch. Consequently, attacks are feasible only when n>k, meaning that our attacks, which operate when n=\tilde{O}(k), are nearly optimal in terms of the required ground set size. 1.2 Application to Linear Sketches (see details in Section 6) With linear sketches over a field \mathbbm{F}, the input is represented as a vector \boldsymbol{v}\in\mathbbm{F}^{n}, the sketching map is specified by a sketching matrix A\in\mathbbm{F}^{n\times k} where k\ll n, and the sketch of \boldsymbol{v} is the product A\boldsymbol{v}\in\mathbbm{F}^{k}. When linear sketches are used as cardinality sketches, the ground set are the entries \mathcal{U}\equiv[n] and the query set corresponds to the nonzero entries of \boldsymbol{v}. The cardinality \|\boldsymbol{v}\|_{0} is the number of nonzero entries, also called the \ell_{0} norm. We establish the following: Theorem 1.6 (Informal, see Theorem 6.10). Over a field \mathbbm{F} that is \mathbbm{R} (the real numbers) or \mathbbm{F}_{p} (the finite field of prime order p, for any p), there is a constant C so that for any sketching matrix A\in\mathbbm{F}^{k\times n}, when n>C\cdot k\log k, there is an attack that succeeds using O(k^{2}\log^{2}k\log n) queries. Our results for \mathbbm{R} are in the real RAM model, which assumes that the sketch has the exact values in A\boldsymbol{v}. We specify a parameter \gamma_{0}(A) that depends on sub-determinants of A and our attack is parametrized by an upper bound \gamma>\gamma_{0}(A). In the case of {\mathbb{F}}_{p}, our quadratic attack size improves upon the corresponding result in Gribelyuk et al. (2024), which used a cubic attack size. In the case of {\mathbb{R}}, the quadratic attack size is also smaller than that of Gribelyuk et al. (2024) (which used an unspecified polynomial number of queries), though the entries of our query vector are exponentially far in magnitude (unless we make a further “naturalness” assumption on the query responder, see Remark 1.7). Our quadratic bounds are tight in that respective quadratic upper bounds are guaranteed in the same models, that is, with \mathbbm{F}_{p} and specifically with \mathbbm{R}, even when the input values are unrestricted. To see this, recall that the cardinality sketch of (Ganguly, 2007) or folklore linear sketches for \ell_{0} sampling or estimation (designed for non-adaptive queries) use a sketching matrix and estimators that only depend on whether measurement values (that is, the values in the sketch) are zero or not: each measurement simply tests if the nonzero entries in the measurement vector intersect with those in the input. The measurement vectors correspond to random sets of different sizes and have randomly chosen values. The main property needed is that the probability that such a measurement is 0 when the intersection is not empty is very small, and this goes through. We can then apply the robustness wrapper method mentioned above Hassidim et al. (2020) to k independent random maps to obtain a sketch that supports a quadratic number of adaptive queries. Remark 1.7 (Magnitude of values). The query vectors used in our attack for \mathbbm{R} have nonzero entries where the logarithm of the ratio between the largest and smallest nonzero magnitudes is O(n\log\gamma). We propose an alternative specification of the nonzero values (see Section 3.3) where the logarithm of the ratio is O(\log(n\gamma)), but this attack requires that the query responder is natural (uses only components of the sketch that contain information on the cardinality — see Definition 3.12 for a precise definition). For that, we establish a weaker property that is the existence of a limited determining pool of size O(k\log k) (A pool is limited if a sufficient statistic for |U|, but not necessarily the full sketch, can be computed from (U\setminus M)\cap L). We then establish a variant of Theorem 1.3 (see Lemma 3.13) where the statement holds when the determining pool is limited but the query responder is natural. Note that the known cardinality sketches are natural and therefore so are the respective robust algorithms obtained via the mentioned wrapper methods. 1.2.1 Ideas in our Attacks on Linear Sketches Observe that the sketching map is a linear operator that is not composable, therefore, we can not directly apply Theorem 1.5 to establish Theorem 1.6. Moreover, when specifying the attack, it is insufficient to specify the queries as sets because the same set U\subset[n] has multiple representations, which are all the vectors with the set of nonzero entries being U, and there are multiple sketches of the same set. We therefore need to augment the description of the attack queries so that it specifies a vector, that is, values for the nonzero entries. Note that simply choosing the values of the nonzero entries to be v_{i}=1 will not work: A sketching matrix that includes the measurement row vector \boldsymbol{1}_{n} would have the measurement value A\boldsymbol{v}=\mathbbm{1}_{n}\cdot\boldsymbol{v}=\|\boldsymbol{v}\|_{0}, which is the exact cardinality value. Additionally, the smallest determining pool would be the full set [n], because inclusion of any new key impacts the sketch. Therefore, for an attack that is effective against any sketching matrix, we need to specify these nonzero entries in our attack queries with some cleverness – so that a determining pool of size \tilde{O}(k) would exist. We do so using different and ad hoc approaches for the real RAM, for the real RAM with smaller entries (see Remark 1.7), and for the fields \mathbbm{F}_{p}. There is, however, one common ingredient in all these constructions: The determining pool L is constructed from what we call a basis pool of the column vectors a^{(i)}\in\mathbbm{F}^{k} of the sketching matrix A. A basis pool has the property that for any M\subset[n], with probability at least 1-\delta over U\sim\mathcal{Q}, the span of the column vectors (A_{\cdot j})_{j\in U\cup M} is equal to the span of the column vectors (A_{\cdot j})_{j\in M\cup U\cap L}. Surprisingly, the existence of such a basis pool of size O(k\log k) falls out as a special case of the existence of pools for composable sketches (Theorem 1.5) by observing that the span of a set of vectors in vector spaces is a monotone composable map of rank k. So after all, and indirectly, we do use our analysis for composable sketches. 1.3 Statistical queries and MinHash Sketches As a warm up and additional context for the reader, we recover prior results on statistical queries (Steinke and Ullman, 2015) and MinHash cardinality sketches (Ahmadian and Cohen, 2024) as applications of our framework. We do so by demonstrating that the respective sketching maps are monotone composable. Statistical Queries The perhaps simplest composable cardinality sketches utilize a uniform random sample R\subset\mathcal{U} of size |R|=k. The sketching map S, maps each set U to its intersection with the sample, S(U)=R\cap U. This map is clearly composable since S(U\cup V)=(U\cup V)\cap R=U\cap R\cup V\cap R=S(U)\cup S(V). The map is also monotone: When U\subset V, U\cap R\subset V\cap R and hence |S(U)|\leq|S(V)|. The determining pool for the sketching map, with \delta=0, is simply the set R, which has size k. Cardinality queries are statistical queries and the estimate |R\cap U|\cdot n/k is a good approximation of |U| when U is sufficiently large, that is, |U|=\Theta(|\mathcal{U}|). Observe that when the queries are non-adaptive (do not depend on the sample), we can accurately answer a number of queries that is exponential in the sample size k. This simple fixed-size sample sketch is effective when the queries have large cardinality. When the query set U is small, the intersection with the sample would be small or even empty, making it impossible to reliably approximate |U| to within a relative error. MinHash sketches (Flajolet and Martin, 1985; Cohen, 1997; Flajolet et al., 2007b; Rosén, 1997; Cohen, 1997; Broder, 2000; Bar-Yossef et al., 2002), which provide statistical guarantees for all cardinality values, can be viewed as drill-down samples instead of a fixed size sample. We sample a partial order of random priorities for all keys in \mathcal{U}. This determines the sketching map, roughly by selecting the k top priority keys that are in the set according to the partial order. In this way, there is a size k sketch for any subset and enough information also in the sketches of small sets to facilitate accurate estimates. We examine two MinHash sketch types, describe the sketching maps, argue they are monotone composable, and describe the determining pool. HyperLogLog (k-partition) sketch A sketching map of k-partition sketches such as the HyperLogLog (HLL) sketch Flajolet et al. (2007b) is specified by a (randomly chosen) partition of the keys in \mathcal{U} to k buckets and a (random) priority order on the keys in each bucket. For a fixed such partition and order, the sketch S(U) of a subset U depends on the lowest priority key in each of the buckets. This sketching map is composable since the sketch S(U\cup V) can be obtained by taking from each bucket, the highest priority key in the bucket among those in S(U) and S(V). The sketching map is monotone since the sketch size S(U) is the number of buckets for which there is at least one representative from U. When U\subset V, V has at least as many buckets represented as U. The \delta-determining pool L includes the \log(k/\delta)/q_{\min} lowest priority keys from each of the k buckets. Observe that a randomly chosen U with rate at least q_{\textnormal{min}} is (1-\delta) likely to have its highest priority key in each of the buckets present in L. Bottom-k sketch A sketching map of bottom-k sketches (Rosén, 1997; Cohen, 1997; Broder, 1997; Bar-Yossef et al., 2002) is specified by priorities according to a random permutation of \mathcal{U}. For a fixed permutation, the sketch S(U) depends on the k highest priority keys in U. The map is composable because the k highest priority keys in U\cup V are the k highest priority keys in S(U)\cup S(V). The size of the sketch S(U) is \min\{|U|,k\} and the map is clearly monotone. The determining pool L includes the k\log(k/\delta)/q_{\min} highest priority keys. It is easy to verify that the probability for a random U selected with rate at least q_{\textnormal{min}} that its k highest priority keys are not included in the pool L is at most \delta."
https://arxiv.org/html/2411.07030v1,Hyperplanes Avoiding Problem and Integer Points Counting in Polyhedra,"In our work, we consider the problem of computing a vector x\in\operatorname{\mathbb{Z}}^{n} of minimum \norm{\cdot}_{p}-norm such that a^{\top}x\not=a_{0}, for any vector (a,a_{0}) from a given finite set \operatorname{\mathcal{A}}\subseteq\operatorname{\mathbb{Z}}^{n}. In other words, we search for a vector of minimum norm that avoids a given finite set of hyperplanes, which is natural to call as the Hyperplanes Avoiding Problem. This problem naturally appears as a subproblem in Barvinok-type algorithms for counting integer points in polyhedra. More precisely, it appears when one needs to evaluate certain rational generating functions in an avoidable critical point.We show that:With respect to \norm{\cdot}_{1}, the problem admits a feasible solution x with \norm{x}_{1}\leq(m+n)/2, where m=\abs{\operatorname{\mathcal{A}}}, and show that such solution can be constructed by a deterministic polynomial-time algorithm with O(n\cdot m) operations. Moreover, this inequality is the best possible. This is a significant improvement over the previous randomized algorithm, which computes x with a guaranty \norm{x}_{1}\leq n\cdot m. The original approach of A. Barvinok can guarantee only \norm{x}_{1}=O\bigl{(}(n\cdot m)^{n}\bigr{)};The problem is \operatorname{N\!P}-hard with respect to any norm \norm{\cdot}_{p}, for p\in\bigl{(}\operatorname{\mathbb{R}}_{\geq 1}\cup\{\infty\}\bigr{)}.As an application, we show that the problem to count integer points in a polytope \operatorname{\mathcal{P}}=\{x\in\operatorname{\mathbb{R}}^{n}\colon Ax\leq b\}, for given A\in\operatorname{\mathbb{Z}}^{m\times n} and b\in\operatorname{\mathbb{Q}}^{m}, can be solved by an algorithm with O\bigl{(}\nu^{2}\cdot n^{3}\cdot\Delta^{3}\bigr{)} operations, where \nu is the maximum size of a normal fan triangulation of \operatorname{\mathcal{P}}, and \Delta is the maximum value of rank-order subdeterminants of A. It refines the previous state-of-the-art O\bigl{(}\nu^{2}\cdot n^{4}\cdot\Delta^{3}\bigr{)}-time algorithm.","Let \operatorname{\mathcal{A}}\subseteq\operatorname{\mathbb{Z}}^{n+1} be a set of pairs (a,a_{0}) with a\in\operatorname{\mathbb{Z}}^{n}\setminus\{\operatorname{\mathbf{0}}\} and a_{0}\in\operatorname{\mathbb{Z}}, and denote m:=\abs{\operatorname{\mathcal{A}}}<\infty. Consider the system \begin{cases}a^{\top}\cdot x\not=a_{0},\quad\forall(a,a_{0})\in\operatorname{% \mathcal{A}}\\ x\in\operatorname{\mathbb{Z}}^{n}.\end{cases} (HyperplanesAvoiding) The system (HyperplanesAvoiding) has infinitely many solutions, and it is interesting to find solutions having small norm (we are mainly interested in the \norm{\cdot}_{1}-norm). The latter motivates the following problem, which is natural to call the Hyperplanes Avoiding Problem: \displaystyle\norm{x}_{p}\to\min \displaystyle\begin{cases}a^{\top}\cdot x\not=a_{0},\quad\forall(a,a_{0})\in% \operatorname{\mathcal{A}}\\ x\in\operatorname{\mathbb{Z}}^{n}.\end{cases} (p-HyperplanesAvoiding) In other words, we are just trying to find an integer vector of the smallest norm that does not lie in any of the m given hyperplanes. It is also interesting to consider the Homogeneous forms of the system (HyperplanesAvoiding) and problem (p-HyperplanesAvoiding), when a_{0}=0 for any (a,a_{0})\in\operatorname{\mathcal{A}}. In this case, we are trying to find an integer vector of the smallest norm that does not lie in any of the m given (n-1)-dimensional subspaces. 1.1 Motivation: The integer Points Counting in Polyhedra The problem (p-HyperplanesAvoiding) naturally appears as a subproblem in algorithms for integer points counting in polyhedra. Let us give a brief sketch of how it appears. Consider a rational polytope \operatorname{\mathcal{P}} defined by a system of linear inequalities. The seminal work of A. Barvinok [5] (see also [3, 4]) proposes an algorithm to count the number of points inside \operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}, which is polynomial for a fixed dimension. His approach is based on a representation of \operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n} via some rational generating function. More precisely, the Barvinok’s algorithm computes a set of indices \operatorname{\mathcal{I}}, and for each i\in\operatorname{\mathcal{I}}, it computes a number \epsilon^{(i)}\in\operatorname{\mathbb{Z}} and vectors v^{(i)},u_{1}^{(i)},\dots,u_{n}^{(i)}\in\operatorname{\mathbb{Z}}^{n} such that \sum\limits_{x\in\operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}}z% ^{x}=f_{\operatorname{\mathcal{P}}}(z):=\sum\limits_{i\in\operatorname{% \mathcal{I}}}\epsilon^{(i)}\cdot\frac{z^{v^{(i)}}}{\bigl{(}1-z^{u_{1}^{(i)}}% \bigr{)}\cdot\ldots\cdot\bigl{(}1-z^{u_{n}^{(i)}}\bigr{)}}. (1) Here, the notation z^{x} means z^{x}=z_{1}^{x_{1}}\cdot\ldots\cdot z_{n}^{x_{n}}. The right-hand-side of (1), i.e. the function f_{\operatorname{\mathcal{P}}}(z), is called the short rational generating function of \operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}. Since the left part of (1) is a finite sum, the point z=\operatorname{\mathbf{1}} is an avoidable critical point of f_{\operatorname{\mathcal{P}}}(z). Therefore, \abs{\operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}}=\lim\limits_% {z\to\operatorname{\mathbf{1}}}f_{\operatorname{\mathcal{P}}}(z). (2) One possible approach to find this limit, is to compute a vector c\in\operatorname{\mathbb{Z}}^{n} such that c^{\top}u^{(i)}_{j}\not=0, for any i\in\operatorname{\mathcal{I}} and j\in\left\{1,\dots,n\right\}. Note that c is a solution of the system (HyperplanesAvoiding) with \operatorname{\mathcal{A}}=\bigl{\{}u^{(i)}_{j}\bigr{\}}, and m=\abs{\operatorname{\mathcal{A}}}=(n+1)\cdot\abs{\operatorname{\mathcal{I}}}. Using the substitution z_{i}\to e^{\tau\cdot c_{i}}, the function f_{\operatorname{\mathcal{P}}}(z) transforms to the function \hat{f}_{\operatorname{\mathcal{P}}}(\tau), depending on the single complex variable \tau, defined by \hat{f}_{\operatorname{\mathcal{P}}}(\tau)=\sum\limits_{i\in\operatorname{% \mathcal{I}}}\epsilon^{(i)}\cdot\frac{e^{\langle c,v^{(i)}\rangle\cdot\tau}}{% \bigl{(}1-e^{\langle c,u_{1}^{(i)}\rangle\cdot\tau}\bigr{)}\cdot\ldots\cdot% \bigl{(}1-e^{\langle c,u_{n}^{(i)}\rangle\cdot\tau}\bigr{)}}. (3) Now, since \hat{f}_{\operatorname{\mathcal{P}}} is analytical, the limit (2) just equals to the [\tau^{0}]-term of the Tailor’s series for \hat{f}_{\operatorname{\mathcal{P}}}(\tau): \abs{\operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}}=\lim\limits_% {\tau\to 0}\hat{f}_{\operatorname{\mathcal{P}}}(\tau)=[\tau^{0}]\hat{f}_{% \operatorname{\mathcal{P}}}. We note that it is preferable to calculate the vector c satisfying c^{\top}u^{(i)}_{j}\not=0 with the smallest possible norm, because it will reduce the size of the numbers \langle c,v^{(i)}\rangle and \langle c,u_{j}^{(i)}\rangle, which in turn will speed up practical computations. However, the norm of c does not affect the computational complexity in terms of the number of operations. It only reduces the variable sizes. Assuming that the polyhedron \operatorname{\mathcal{P}} is defined by a system Ax\leq b, for given A\in\operatorname{\mathbb{Z}}^{m\times n} and b\in\operatorname{\mathbb{Q}}^{m}, the computational complexity of the Barvinok’s algorithm in terms of operations number can be bounded by \nu\cdot\bigl{(}O(\log\Delta)\bigr{)}^{n\ln n}, (4) where \nu is the maximum size of a normal fan triangulation of \operatorname{\mathcal{P}}, and \Delta is the maximum value of the rank-order subdeterminants of A. Thus, finding a good solution to (HyperplanesAvoiding) has only effect on the variable sizes of the Barvinok’s algorithm. However, there is an alternative algorithmic approach to integer point counting, which allows obtaining complexity bounds of the type \operatorname{poly}(\nu,n,\Delta). It was developed in a series of works [10, 11, 8, 9, 7].111For the latest perspective see [9], for the parametric case see [7], the paper [8] is a correction of [11]. In this alternative approach, the norm of the solution to (HyperplanesAvoiding) is a multiplicative factor in the bound on its computational complexity. More precisely, the following result was obtained in [9]. Proposition 1 (D. Gribanov, I. Shumilov, D. Malyshev & N. Zolotykh [9]) Assume that, for any collection \operatorname{\mathcal{A}} of vectors of size m, there exists a solution x of the system (HyperplanesAvoiding) with \norm{x}_{1}\leq L(m,n). Assume additionally that such x can be calculated for free. Then the number \abs{\operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}} can be calculated with O\bigl{(}\nu\cdot L(\nu\cdot n,n)\cdot n^{2}\cdot\Delta^{3}\bigr{)}\quad\text{% operations}. It was shown in [9] that L(m,n)\leq n\cdot m, and such x can be constructed by a randomized polynomial-time algorithm with O(n\cdot m) operations. It means that the counting complexity can be estimated by O\bigl{(}\nu^{2}\cdot n^{4}\cdot\Delta^{3}\bigr{)}. In the current paper, we show that L(m,n)\leq(m+n)/2, and such x can be constructed by a deterministic O(n\cdot m)-time algorithm. The latter yields the counting complexity O\bigl{(}\nu^{2}\cdot n^{3}\cdot\Delta^{3}\bigr{)}, which is the main application of our results. Additionally, we hope that our result can significantly accelerate the evaluation part of the Barvinok-type algorithms. To this end, we propose some experimental results showing that the new algorithm constructs solutions of significantly lower norm than random sampling in a cross-polytope, see Section Experimental Evaluation. Finally, we note that this paper is not considering the dual-type algorithms for counting integer points in polyhedra. A great survey of this approach could be found in the book [12] of J. Lasserre. 1.2 Complexity Model Assumptions All the algorithms that are considered in our work correspond to the Word-RAM computational model. In other words, we assume that additions, subtractions, multiplications, and divisions with rational numbers of the specified size, which is called the word size, can be done in O(1)-time. In our work, we chose the word size to be equal to some fixed polynomial on the input size of the corresponding computational problem. More precisely, considering the problem (p-HyperplanesAvoiding), we assume that the input size is bounded by n\cdot m\cdot(1+\lceil\log_{2}\alpha\rceil), where \alpha is the maximum absolute value of coordinates of a, for a\in\operatorname{\mathcal{A}}. 1.3 Main Results and Related Work Let us summarize our results below. 1. With respect to \norm{\cdot}_{1}, the problem (p-HyperplanesAvoiding) admits a feasible solution x with \norm{x}_{1}\leq(m+n)/2, where m=\abs{\operatorname{\mathcal{A}}}, and we show that such solution can be constructed by a deterministic polynomial-time algorithm with O(n\cdot m) operations, see Theorem 2.3 of Section Approximate Solution via Combinatorial Nullstellensatz. The inequality is the best possible, see the discussion afterward. This is a significant improvement over the previous O(n\cdot m)-time randomized algorithm of [9], which computes x with a guaranty \norm{x}_{1}\leq n\cdot m. In contrast, the original approach of A. Barvinok searches x in the form x=(1,t,t^{2},\dots,t^{n-1}). Since, for each a\in\operatorname{\mathcal{A}}, a^{\top}x=\sum_{i=1}^{n}a_{i}\cdot t^{i-1} is a polynomial of degree at most n-1, there exists a suitable t with t\leq n\cdot m. However, this reasoning can guaranty only \norm{x}_{1}=O\bigl{(}(n\cdot m)^{n}\bigr{)}. 2. For any p\in\bigl{(}\operatorname{\mathbb{R}}_{\geq 1}\cup\{\infty\}\bigr{)}, the problem (p-HyperplanesAvoiding) is \operatorname{N\!P}-hard with respect to any norm \norm{\cdot}_{p}, even in its homogeneous form. See Theorem 3.1 of Section Computational Complexity of the Exact Solution; 3. We show that the problem to calculate the value \abs{\operatorname{\mathcal{P}}\cap\operatorname{\mathbb{Z}}^{n}} for a polyhedron \operatorname{\mathcal{P}} defined by the system Ax\leq b, for agiven A\in\operatorname{\mathbb{Z}}^{m\times n} and b\in\operatorname{\mathbb{Q}}^{m}, can be solved with O\bigl{(}\nu^{2}\cdot n^{3}\cdot\Delta^{3}\bigr{)} operations, where \nu is the maximum size of a normal fan triangulation of \operatorname{\mathcal{P}}, and \Delta is the maximum value of rank-order subdeterminants of A. It refines the O\bigl{(}\nu^{2}\cdot n^{4}\cdot\Delta^{3}\bigr{)}-time algorithm of [9]. See Subsection Motivation: The integer Points Counting in Polyhedra, more specifically, see the discussion alongside Proposition 1; It is easy to see that the guaranty \norm{x}_{1}\leq(m+n)/2 on an existing solution x of the system (HyperplanesAvoiding) is the best possible. Proposition 2 There exists a family of systems (HyperplanesAvoiding) such that \norm{x}_{1}\geq(m+n)/2 for any solution x. Proof Fix some positive integer k. The desired system consists of the constraints x_{i}\not=j, for any i\in\left\{1,\dots,n\right\} and j\in\left\{-k,\dots,k\right\}. So, the total number of constraints is m=(2k+1)\cdot n. It is easy to see that \abs{x_{i}}\geq k+1, for any i\in\left\{1,\dots,n\right\} and any solution x of the system. Therefore, \norm{x}_{1}\geq(k+1)\cdot n=(m+n)/2. However, for the homogeneous form of the system (HyperplanesAvoiding), the asymptotics of the solution quality with respect to the parameter m can be slightly improved. This observation is based on the following result of I. Bárány, G. Harcos, J. Pach, & G. Tardos [2]. Let \operatorname{\mathbb{B}}_{1} be the unit ball with respect to \norm{x}_{1} and g(r) be a minimal number of subspaces needed to cover all points of the set r\cdot\operatorname{\mathbb{B}}_{1}\cap\operatorname{\mathbb{Z}}^{n}. Theorem 1.1 (I. Bárány, G. Harcos, J. Pach, & G. Tardos [2]) There exist absolute constants C_{1} and C_{2} such that C_{1}\cdot\frac{1}{n^{2}}\cdot r^{\frac{n}{n-1}}\leq g(r)\leq C_{2}\cdot 2^{n}% \cdot r^{\frac{n}{n-1}}. Note that the original work [2] contains a more general result concerning arbitrary convex bodies in \operatorname{\mathbb{R}}^{n}, albeit with a worse dependence on n. The Theorem 1.1 is a straightforward adaptation of the original proof to the case of \operatorname{\mathbb{B}}_{1}. As a corollary, it follows that the system (HyperplanesAvoiding) always has a solution with an asymptotics that is slightly better in m, but worse in n. Corollary 1 The system (HyperplanesAvoiding) has a solution x, such that \norm{x}_{1}=O\bigl{(}n^{2}\cdot m^{\frac{n-1}{n}}\bigr{)}. At the same time, the theorem implies that solutions of significantly smaller norm do not exist in general. In particular, it implies that our constructive bound \norm{x}_{1}\leq(m+n)/2 is almost optimal with respect to m even in the homogeneous case. Corollary 2 There exists a system (HyperplanesAvoiding) such that, for any solution x, \norm{x}_{1}=\Omega\bigl{(}\frac{1}{2^{n}}\cdot m^{\frac{n-1}{n}}\bigr{)}."
https://arxiv.org/html/2411.07006v1,Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs,"Lifting uses a representative of indistinguishable individuals to exploit symmetries in probabilistic relational models, denoted as parametric factor graphs, to speed up inference while maintaining exact answers. In this paper, we show how lifting can be applied to causal inference in partially directed graphs, i.e., graphs that contain both directed and undirected edges to represent causal relationships between random variables. We present partially directed parametric causal factor graphs as a generalisation of previously introduced parametric causal factor graphs, which require a fully directed graph. We further show how causal inference can be performed on a lifted level in PPCFGs, thereby extending the applicability of lifted causal inference to a broader range of models requiring less prior knowledge about causal relationships.","A fundamental problem for an intelligent agent performing reasoning under uncertainty is to compute the effect of an action on a certain random variable (randvar) on other randvars. When computing the effect of an action on a specific randvar, it is crucial to deploy the semantics of an intervention instead of performing a classical conditioning on that randvar [22, Chapter 4]. An intervention acting on a randvar R can be thought of as setting R to a fixed value and removing all incoming influences on the value of R. In practice, generally not all causal relationships in a given model are known and thus, only a partially directed graphical model is available. In such a partially directed graph, directed edges represent cause-effect relationships and undirected edges represent causal relationships whose direction is unknown. In this paper, we solve the problem of efficiently estimating causal effects of actions in partially directed lifted probabilistic models, denoted as parametric factor graphs. Lifted representations are not only more expressive than propositional models such as factor graphs, but also allow for tractable probabilistic inference with respect to domain sizes of logical variables by exploiting symmetries. Previous Work. The estimation of causal effects using causal graphical models in form of directed acyclic graphs in combination with observational data has been extensively studied in the literature (see, e.g., [22, 23, 27]). Some works incorporate causal knowledge into (propositional) factor graphs (which are originally undirected graphical models) to enable the estimation of causal effects in factor graphs [6, 29]. In practice, the underlying causal graph is often not fully known and hence, identifying and estimating causal effects when provided with observational data and a partially directed graph has been investigated [7, 10, 16, 24]. However, all of these works perform causal effect estimation on a propositional level and thus lack the expressivity of relational logic, for example to capture the relationships between individual objects. To represent individual objects and the relationships between them, Poole [25] introduces parametric factor graphs as lifted representations, which combine relational logic and probabilistic models, thereby allowing to encode that certain properties hold for groups of indistinguishable objects. In probabilistic inference, lifting exploits symmetries to speed up inference while maintaining exact answers [20]. Over the past years, both algorithms for symmetry detection [1, 8, 11, 13, 14, 15] allowing the construction of lifted representations such as parametric factor graphs as well as various lifted inference algorithms operating on parametric factor graphs have been developed and further refined [2, 3, 4, 5, 9, 18, 25, 28]. More recently, Luttermann et al. [12] introduce parametric causal factor graphs as an extension of parametric factor graphs allowing to incorporate causal knowledge into a lifted representation. Nevertheless, the authors assume that the causal relationships between the involved randvars are fully known, which is rarely the case in practical settings. Our Contributions. We introduce PPCFGs as a generalisation of PCFGs to obtain a formalism that compactly encodes a full joint distribution over a set of randvars and at the same time incorporates causal knowledge in the model, if available. The major advantage of a PPCFG over an PCFG is that not all causal relationships between the involved randvars need to be known, thereby reducing the amount of prior knowledge required and thus making the model more suitable for many practical settings. We further define d-separation in PPCFGs to reason about conditional independence. In addition to that, we present an algorithm to efficiently estimate causal effects in PPCFGs on a lifted level, i.e., a representative of indistinguishable objects is used for computations to speed up inference. Our algorithm identifies whether a causal effect can be uniquely determined from the given PPCFG and if so, outputs the causal effect. If the undirected edges in the PPCFG lead to a causal effect being not uniquely identifiable, our algorithm efficiently enumerates all possible causal effects while operating on a lifted level. Structure of this Paper. We begin by introducing necessary background information and notations. Afterwards, we present PPCFGs as a generalisation of PCFGs, allowing both for directed and undirected edges in the model and then define d-separation in PPCFGs. Thereafter, we provide an algorithm to efficiently estimate causal effects in PPCFGs before we conclude."
https://arxiv.org/html/2411.06822v1,Efficient Classical Computation of Single-Qubit Marginal Measurement Probabilities to Simulate Certain Classes of Quantum Algorithms,"Classical simulations of quantum circuits are essential for verifying and benchmarking quantum algorithms, particularly for large circuits, where computational demands increase exponentially with the number of qubits. Among available methods, the classical simulation of quantum circuits inspired by density functional theory—the so-called QC-DFT method, shows promise for large circuit simulations as it approximates the quantum circuits using single-qubit reduced density matrices to model multi-qubit systems. However, the QC-DFT method performs very poorly when dealing with multi-qubit gates. In this work, we introduce a novel CNOT ”functional” that leverages neural networks to generate unitary transformations, effectively mitigating the simulation errors observed in the original QC-DFT method. For random circuit simulations, our modified QC-DFT enables efficient computation of single-qubit marginal measurement probabilities, or single-qubit probability (SQPs), and achieves lower SQP errors and higher fidelities than the original QC-DFT method. Despite limitations in capturing full entanglement and joint probability distributions, we find potential applications of SQPs in simulating Shor’s and Grover’s algorithms for specific solution classes. These findings advance the capabilities of classical simulations for some quantum problems and provide insights into managing entanglement and gate errors in practical quantum computing.","References Bravyi and Gosset [2016] S. Bravyi and D. Gosset, “Improved classical simulation of quantum circuits dominated by Clifford gates,” Phys. Rev. Lett. 116, 250501 (2016). Jozsa [2006] R. Jozsa, “On the simulation of quantum circuits,” (2006), arXiv:0603163 [quant-ph] . Jozsa and Miyake [2008] R. Jozsa and A. Miyake, “Matchgates and classical simulation of quantum circuits,” Proc. R. Soc. A 464, 3089–3106 (2008). Chen et al. [2018] J. Chen, F. Zhang, C. Huang, M. Newman, and Y. Shi, “Classical simulation of intermediate-size quantum circuits,” (2018), arXiv:1805.01450 [quant-ph] . Kissinger, van de Wetering, and Vilmart [2022] A. Kissinger, J. van de Wetering, and R. Vilmart, “Classical simulation of quantum circuits with partial and graphical stabiliser decompositions,” (2022), arXiv:2202.09202 [quant-ph] . Terhal and DiVincenzo [2002] B. M. Terhal and D. P. DiVincenzo, “Classical simulation of noninteracting-fermion quantum circuits,” Phys. Rev. A 65, 032325 (2002). Napp et al. [2022] J. C. Napp, R. L. La Placa, A. M. Dalzell, F. G. Brandao, and A. W. Harrow, “Efficient classical simulation of random shallow 2D quantum circuits,” Phys. Rev. X 12, 021021 (2022). Noh, Jiang, and Fefferman [2020] K. Noh, L. Jiang, and B. Fefferman, “Efficient classical simulation of noisy random quantum circuits in one dimension,” Quantum 4, 318 (2020). Qassim, Wallman, and Emerson [2019] H. Qassim, J. J. Wallman, and J. Emerson, “Clifford recompilation for faster classical simulation of quantum circuits,” Quantum 3, 170 (2019). Jones et al. [2019] T. Jones, A. Brown, I. Bush, and S. C. Benjamin, “QuEST and high performance simulation of quantum computers,” Sci. Rep. 9, 10736 (2019). Broadbent [2015] A. Broadbent, “How to verify a quantum computation,” (2015), arXiv:1509.09180 [quant-ph] . Magesan, Gambetta, and Emerson [2012] E. Magesan, J. M. Gambetta, and J. Emerson, “Characterizing quantum gates via randomized benchmarking,” Phys. Rev. A 85, 042311 (2012). Katsuda, Mitarai, and Fujii [2024] M. Katsuda, K. Mitarai, and K. Fujii, “Simulation and performance analysis of quantum error correction with a rotated surface code under a realistic noise model,” Phys. Rev. Res. 6, 013024 (2024). Bernardi [2023] M. Bernardi, “Efficient mean-field simulation of quantum circuits inspired by density functional theory,” J. Chem. Theory Comput. 19, 8066–8075 (2023). Jozsa [1994] R. Jozsa, “Fidelity for mixed quantum states,” J. Mod. Opt. 41, 2315–2323 (1994). Nielsen and Chuang [2010] M. Nielsen and I. Chuang, Quantum Computation and Quantum Information: 10th Anniversary Edition (Cambridge University Press, 2010). Robbins and Monro [1951] H. Robbins and S. Monro, “A stochastic approximation method,” Ann. Math. Stat. 22, 400–407 (1951). Shor [1994] P. W. Shor, “Algorithms for quantum computation: Discrete logarithms and factoring,” in Proceedings 35th Annual Symposium on Foundations of Computer Science (IEEE, 1994) pp. 124–134. Mermin [2007] N. D. Mermin, Quantum Computer Science: An Introduction (Cambridge University Press, 2007). Vathsan [2015] R. Vathsan, Introduction to Quantum Physics and Information Processing (CRC Press, 2015)."
https://arxiv.org/html/2411.06697v1,"Learning a Single Neuron Robustly
to Distributional Shifts and Adversarial Label Noise","We study the problem of learning a single neuron with respect to the L_{2}^{2}-loss in the presence of adversarial distribution shifts, where the labels can be arbitrary, and the goal is to find a “best-fit” function. More precisely, given training samples from a reference distribution {\mathcal{p}}_{0}, the goal is to approximate the vector \mathbf{w}^{*} which minimizes the squared loss with respect to the worst-case distribution that is close in \chi^{2}-divergence to {\mathcal{p}}_{0}. We design a computationally efficient algorithm that recovers a vector \hat{\mathbf{w}} satisfying \mathbb{E}_{{\mathcal{p}}^{*}}(\sigma(\hat{\mathbf{w}}\cdot\mathbf{x})-y)^{2}% \leq C\,\mathbb{E}_{{\mathcal{p}}^{*}}(\sigma(\mathbf{w}^{*}\cdot\mathbf{x})-y% )^{2}+\epsilon, where C>1 is a dimension-independent constant and (\mathbf{w}^{*},{\mathcal{p}}^{*}) is the witness attaining the min-max risk \min_{\mathbf{w}~{}:~{}\|\mathbf{w}\|\leq W}\max_{{\mathcal{p}}}\mathbb{E}_{(% \mathbf{x},y)\sim{\mathcal{p}}}(\sigma(\mathbf{w}\cdot\mathbf{x})-y)^{2}-\nu% \chi^{2}({\mathcal{p}},{\mathcal{p}}_{0}). Our algorithm follows a primal-dual framework and is designed by directly bounding the risk with respect to the original, nonconvex L_{2}^{2} loss. From an optimization standpoint, our work opens new avenues for the design of primal-dual algorithms under structured nonconvexity.","The problem of learning a single neuron from randomly drawn labeled examples is a fundamental problem extensively studied in the machine learning literature. Given labeled examples \{({\bm{x}}_{i},y_{i}):({\bm{x}}_{i},y_{i})\in\mathbb{R}^{d}\times\mathbb{R}\}% _{i=1}^{N} drawn from a reference distribution {\mathcal{p}}_{0}, the goal in this context is to recover a parameter vector {\bm{w}}^{*}_{0} that minimizes the squared loss \Lambda_{\sigma,{\mathcal{p}}_{0}}({\bm{w}}) over a ball of radius W>0: {\bm{w}}^{*}_{0}:=\operatorname*{arg\,min}_{{\bm{w}}\in\mathbb{R}^{d}:\|{\bm{w% }}\|_{2}\leq W}\Lambda_{\sigma,{\mathcal{p}}_{0}}({\bm{w}});\quad\Lambda_{% \sigma,{\mathcal{p}}_{0}}({\bm{w}}):=\mathbb{E}_{({\bm{x}},y)\sim{\mathcal{p}}% _{0}}(\sigma({\bm{w}}\cdot{\bm{x}})-y)^{2}, (1) where \sigma:\mathbb{R}\rightarrow\mathbb{R} is a known (typically non-linear) non-decreasing activation function (e.g., the ReLU activation \sigma(t)=\max(0,t)) and we denote by \operatorname{OPT}_{0}=\min_{{\bm{w}}:\|{\bm{w}}\|_{2}\leq W}\Lambda_{\sigma,{% \mathcal{p}}_{0}}({\bm{w}}) the minimum squared loss. In the realizable setting — where y=\sigma({\bm{w}}_{0}^{*}\cdot{\bm{x}}) and thus \operatorname{OPT}_{0}=0 — this problem is well-understood and by now part of the folklore (see, e.g., [kakade2011efficient, kalai2009isotron, yehudai2020learning, soltanolkotabi2017learning]). The results for the realizable setting also naturally extend to zero-mean bounded-variance label noise. The more realistic agnostic (a.k.a. adversarial label noise) model [Haussler:92, kearns1992toward] aims to identify the best-fitting neuron for a reference distribution of the examples, without any assumptions on label structure. However, it is known that in this setting finding a parameter vector with square loss \operatorname{OPT}_{0}+{\epsilon} requires d^{\text{poly}(1/\epsilon)} time, even if the {\bm{x}}-marginal distribution is Gaussian [DKZ20-sq-reg, GGK20, DKPZ21-SQ, diakonikolas2023near]. Even if we relax our goal to achieve error O(\operatorname{OPT}_{0})+{\epsilon}, efficient algorithms only exist under strong distributional assumptions. In fact, without such assumptions, this problem is NP-hard [vsima2002training, MR18]. Recent work has also shown that (under cryptographic assumptions) no polynomial-time constant-factor improper learner exists even for distributions supported on the unit ball [diakonikolas22a-hardness]. Given these intractability results, recent work has focused on developing efficient constant-factor approximate learners under minimal distributional assumptions (see, e.g.,[DGKKS20, frei2020agnostic, DKTZ22, ATV22, wang2023robustly-learning, GGKS23, ZWDD2024]). This recent progress notwithstanding, prior work primarily focused on the setting where only the labels might be corrupted, without considering possible distributional shifts or heterogeneity of the data. Such distributional corruptions are frequently observed in practice and have motivated a long line of research in areas such as domain adaptation and (related to it) distributionally robust optimization (DRO); see e.g., [Blanchet2024DistributionallyRO, ben2009robust, namkoong2016stochastic, rahimian2022frameworks] and references therein. Thus, the main question motivating our work is: How do adversarial changes in the underlying distribution impact the learnability of a neuron? We study this question within the DRO framework, where the goal is to minimize the model’s loss on a worst-case distribution from a set of distributions close to the reference distribution.111We contrast here robustness to perturbed data distribution studied within the DRO framework to robustness to perturbed data examples referred to as the adversarial robustness in modern deep learning literature (e.g., [goodfellow2014explaining]). Our paper is concerned with the former (and not the latter) model of robustness. This set of distributions, known as the ambiguity set, models possible distributional shifts of the data. In addition to being interesting on its own merits, the DRO framework arises in diverse contexts, including algorithmic fairness [hashimoto2018fairness] and class imbalance [xu2020class]. Moreover, it has recently found a range of applications in reinforcement learning [Lotidis2023, Yang2023, Wang2023a, Yu2023, Kallus2022, Liu2022], robotics [Sharma2020], language modeling [Liu2021], sparse neural network training [Sapkota2023], and defense against model extraction [Wang2023b]. Despite a range of impressive results in the DRO literature (see, e.g., recent surveys [rahimian2022frameworks, chen2020distributionally, Blanchet2024DistributionallyRO, kuhn2019wasserstein] and references therein), algorithmic results with rigorous approximation guarantees for the loss have almost exclusively been obtained under fairly strong assumptions about the loss function involving both convexity and either smoothness or Lipschitzness, with linear regression being the prototypical example; see, e.g., [blanchet2021statistical, duchi2021learning, chen2018robust]. Unfortunately, this vanilla setting does not capture a range of machine learning applications, where a typical loss function is nonconvex. In particular, even the simplest ReLU learning problem in the realizable setting (with noise-free labels) is nonconvex. Further, existing DRO approaches for nonconvex loss functions such as [qi2021online, sinha2018certifying] only guarantee convergence to a stationary point, which is insufficient for learning a ReLU neuron even without distributional ambiguity [yehudai2020learning]. Motivated by this gap in our understanding, in this work we initiate a rigorous algorithmic investigation of learning a neuron (arguably the simplest non-convex problem) in the DRO setting. We hope that this work will stimulate future research in this direction, potentially addressing more complex models in a principled manner. Due to space constraints, we defer further discussion of related work to Appendix A. 1.1 Problem Setup To formally define our setting, we recall the definition of \chi^{2}-divergence between distributions {\mathcal{p}} and {\mathcal{p}}^{\prime}, given by \chi^{2}({\mathcal{p}},{\mathcal{p}}^{\prime}):=\int\big{(}\frac{\mathrm{d}{% \mathcal{p}}}{\mathrm{d}{\mathcal{p}}^{\prime}}-1\big{)}^{2}\mathrm{d}{% \mathcal{p}}^{\prime}. We focus on the class of monotone unbounded activations introduced in [DKTZ22], for which we additionally assume convexity. Example activations in this class include the ReLU, leaky ReLU, exponential linear unit (ELU), and normalized222Normalization, which ensures \sigma(0)=0, is without loss of generality, as it corresponds to a simple change of variable: \hat{\sigma}(t)\leftarrow\sigma(t)-\sigma(0) and \hat{y}\leftarrow y+\sigma(0), which does not affect the loss value or its approximation. SoftPlus. Definition 1.1 (Unbounded [DKTZ22] + Convex Activation). Let \sigma:\mathbb{R}\rightarrow\mathbb{R} be a non-decreasing convex function, and let \alpha,\beta>0. We say \sigma is (\alpha,\beta)-unbounded if it satisfies the following: (i) \sigma is \beta-Lipschitz; (ii) \sigma(t_{1})-\sigma(t_{2})\geq\alpha(t_{1}-t_{2}) for all t_{1}\geq t_{2}\geq 0, and (iii) \sigma(0)=0. To formally state the problem, we further define the loss, risk, and optimal value (denoted by \operatorname{OPT}). Definition 1.2 (Loss, Risk, and \operatorname{OPT}). Given a regularization parameter \nu and a reference distribution {\mathcal{p}}_{0}, let {\mathcal{P}}={\mathcal{P}}({\mathcal{p}}_{0}) denote the set of all distributions that are absolutely continuous with respect to {\mathcal{p}}_{0} and {\mathcal{B}}(W):=\{{\bm{w}}:\|{\bm{w}}\|_{2}\leq W\}. We define the following: \displaystyle L_{\sigma}({\bm{w}},{\mathcal{p}};{\mathcal{p}}_{0}) \displaystyle:=\mathbb{E}_{({\bm{x}},y)\sim{\mathcal{p}}}(\sigma({\bm{w}}\cdot% {\bm{x}})-y)^{2}-\nu\chi^{2}({\mathcal{p}},{\mathcal{p}}_{0})=\Lambda_{\sigma,% {\mathcal{p}}}({\bm{w}})-\nu\chi^{2}({\mathcal{p}},{\mathcal{p}}_{0}), \displaystyle R({\bm{w}};{\mathcal{p}}_{0}) \displaystyle:=\max_{{\mathcal{p}}\in{\mathcal{P}}({\mathcal{p}}_{0})}L_{% \sigma}({\bm{w}},{\mathcal{p}};{\mathcal{p}}_{0}),\;{\mathcal{q}}_{{\bm{w}}}:=% \operatorname*{arg\,max}_{{\mathcal{p}}\in{\mathcal{P}}({\mathcal{p}}_{0})}L_{% \sigma}({\bm{w}},{\mathcal{p}};{\mathcal{p}}_{0}), \displaystyle{\bm{w}}^{*} \displaystyle:=\operatorname*{arg\,min}_{{\bm{w}}\in{\mathcal{B}}(W)}R({\bm{w}% };{\mathcal{p}}_{0}),\quad{\mathcal{p}}^{*}:={\mathcal{q}}_{{\bm{w}}^{*}}, \displaystyle\operatorname{OPT} \displaystyle:=\mathbb{E}_{({\bm{x}},y)\sim{\mathcal{p}}^{*}}(\sigma({\bm{w}}^% {*}\cdot{\bm{x}})-y)^{2}=\Lambda_{\sigma,{\mathcal{p}}^{*}}({\bm{w}}^{*}). We say that L_{\sigma}({\bm{w}},{\mathcal{p}};{\mathcal{p}}_{0}) is the regularized square loss function of a vector {\bm{w}} and a distribution {\mathcal{p}}\in{\mathcal{P}}; and R({\bm{w}};{\mathcal{p}}_{0}) is the DRO risk of {\bm{w}} with respect to {\mathcal{p}}_{0}. We call {\mathcal{p}}^{*} the target distribution. The minimization of the DRO risk as defined above corresponds to the regularized/penalized DRO formulation studied in prior work; see, e.g., [mehta2024primal, Wang2023b, sinha2018certifying]. An alternate formulation would have been to instead optimize over a restricted domain. The two are equivalent because of Lagrangian duality. We show in Claim E.1 a concrete relation between our regularization parameter \nu and the chi-squared distance between the population distribution {\mathcal{p}}_{0} and the target distribution {\mathcal{p}}^{*}. We further require that \nu is sufficiently large to ensure that the resulting \chi^{2}({\mathcal{p}}^{*},{\mathcal{p}}_{0}) is smaller than an absolute constant, which is in line with the DRO being used for not too large ambiguity sets [rahimian2022frameworks]. Empirical Version If the reference distribution is the uniform distribution on N labeled examples ({\bm{x}}_{i},y_{i})\in\mathbb{R}^{d}\times\mathbb{R} drawn from {\mathcal{p}}_{0}, we call it \widehat{\mathcal{p}}_{0}=\widehat{\mathcal{p}}_{0}(N), and similarly define \widehat{\mathcal{p}}\in{\mathcal{P}}(\widehat{\mathcal{p}}_{0}). Note that R({\bm{w}}^{*};\widehat{\mathcal{p}}_{0})=\max_{\widehat{\mathcal{p}}\in{% \mathcal{P}}(\widehat{\mathcal{p}}_{0})}\mathbb{E}_{({\bm{x}},y)\sim\widehat{% \mathcal{p}}}(\sigma({\bm{w}}^{*}\cdot{\bm{x}})-y)^{2}-\nu\chi^{2}(\widehat{% \mathcal{p}},\widehat{\mathcal{p}}_{0}); if we let \widehat{\mathcal{p}}^{*} denote the distribution that achieves the maximum, \widehat{\mathcal{p}}^{*} has the same support as \widehat{\mathcal{p}}_{0} and can be interpreted as the reweighting of the samples that maximizes the regularized loss. Formally, our goal is to solve the following learning problem. Problem 1.3 (Robustly Learning a Single Neuron Under Distributional Shifts). Given error parameters \epsilon,\delta\in(0,1), regularization parameter \nu>0, set radius W>0, and sample access to labeled examples ({\bm{x}},y) drawn i.i.d. from an unknown reference distribution {\mathcal{p}}_{0}, output a parameter vector \hat{{\bm{w}}}\in{\mathcal{B}}(W) that is competitive with the DRO risk minimizer {\bm{w}}^{*}=\operatorname*{arg\,min}_{{\bm{w}}\in{\mathcal{B}}(W)}R({\bm{w}};% {\mathcal{p}}_{0}) in the sense that with probability at least 1-\delta, \|\hat{\bm{w}}-{\bm{w}}^{*}\|_{2}^{2}\leq C{\operatorname{OPT}}+{\epsilon} for an absolute constant C. While the stated goal is expressed in terms of \|\hat{{\bm{w}}}-{\bm{w}}^{*}\|_{2}, under mild distributional assumptions that we make on the reference and target distributions, this guarantee implies being competitive with the best-fit function on {\mathcal{p}}^{*} in terms of both the square loss and the risk, namely \Lambda_{\sigma,{\mathcal{p}}^{*}}(\hat{{\bm{w}}})=O(\operatorname{OPT})+\epsilon and R({\bm{w}},{\mathcal{p}}_{0})-\min_{{\bm{w}}\in{\mathcal{B}}(W)}R(\hat{\bm{w}}% ,{\mathcal{p}}_{0})\leq O(\operatorname{OPT})+\epsilon. Further, our algorithm is primal-dual and it outputs a distribution \widehat{\mathcal{p}} that is close to \widehat{\mathcal{p}}^{*} in the chi-squared divergence. Since the solution to Problem 1.3 has an error of O(\operatorname{OPT})+\epsilon, when we use the term “convergence” in our paper, we refer to the following weaker notion: the iterates of our algorithm converge to the (set of) solutions such that asymptotically all iterates lie within the set of O(\operatorname{OPT})+\epsilon solutions, which are the target solutions, as stated in Problem 1.3. 1.2 Main Result Our main contribution is the first polynomial sample and time algorithm for learning a neuron in a distributionally robust setting for a broad class of activations (Definition 1.1) and under mild distributional assumption on the target distribution (Assumptions 2.1 and 2.2 in Section 2.1). Theorem 1.4 (Main Theorem — Informal). Suppose that the learner has access to N=\tilde{\Omega}(d/\epsilon^{2}) samples drawn from the reference distribution {{\mathcal{p}}_{0}}. If all samples are bounded and the distribution {\mathcal{p}}^{*} satisfies the “margin-like” condition and concentration (Assumptions 2.1 and 2.2 in Section 2.1), then after \widetilde{O}(d\log(1/\epsilon)) iterations, each running in sample near-linear time, with high probability Algorithm 1 recovers \hat{{\bm{w}}} such that \|\hat{{\bm{w}}}-{\bm{w}}^{*}\|_{2}^{2}\leq C\operatorname{OPT}+\epsilon, for an absolute constant C. We emphasize that Theorem 1.4 simultaneously addresses two types of robustness: firstly, robustness concerning labels (y); and secondly, robustness due to shifts in the distribution ({\mathcal{p}}_{0} being perturbed). This result is new even when specialized to any nontrivial activation like ReLU, realizable case (where \operatorname{OPT}=0), and the simplest Gaussian {\bm{x}}-marginal distribution. Without distributional robustness, existing approaches, as previously discussed, yield an error of O(\operatorname{OPT})+\epsilon under certain {\bm{x}}-marginal conditions. We demonstrate that this error rate can be also achieved with respect to {\mathcal{p}}^{*} in a distributionally robust context, as long as {\mathcal{p}}^{*} meets the same conditions specified in [wang2023robustly-learning] — among the mildest in the literature addressing non-distributionally robust agnostic setting. 1.3 Technical Overview Our technical approach relies on three main components, described below: Local Error Bounds Our work is inspired by optimization-theory local error bounds (“sharpness”) obtained for learning a single neuron with monotone unbounded activations under structured distributions without considering distributional shift or ambiguity [MBM2018, wang2023robustly-learning]. These bounds are crucial as they quantify growth of a loss function outside the set of target solutions, essentially acting as a “signal” to guide algorithms toward target solutions in our learning problems. Concretely, under distributional assumptions on {\mathcal{p}}^{*} from [wang2023robustly-learning], the following sharpness property can be established: there is an absolute constant c_{1}>0 such that \forall{\bm{w}}\in{\mathcal{B}}(2\|{\bm{w}}^{*}\|_{2}), \|{\bm{w}}-{\bm{w}}^{*}\|_{2}^{2}=\Omega(\operatorname{OPT})\;\Rightarrow\;% \Lambda_{\sigma,{\mathcal{p}}^{*}}({\bm{w}})-\Lambda_{\sigma,{\mathcal{p}}^{*}% }({\bm{w}}^{*})\geq c_{1}\|{\bm{w}}-{\bm{w}}^{*}\|_{2}^{2}. (2) The local error bounds in [MBM2018, wang2023robustly-learning] assume identical reference and target distributions. Introducing distributional ambiguity — as in our work — invalidates this assumption, and as a result necessary distributional assumptions for sharpness may not apply to all distributions in the ambiguity set. In this work, distributional assumptions are exclusively applied to the target distribution to exploit the sharpness property proved in [wang2023robustly-learning]. We also assume that the sample covariates from the reference distribution are polynomially bounded; this assumption, which is without loss of generality, impacts only the sample and computational complexities and is satisfied by standard distributions. Primal-Dual Algorithm Our algorithm is a principled, primal-dual algorithm leveraging the sharpness property on the target distribution, the structure of the square loss, and properties of chi-squared divergence. We control a “gap-like” function of the iterates, \mathrm{Gap}(\widehat{\bm{w}},\widehat{\mathcal{p}};\widehat{\mathcal{p}}_{0})% :=L_{\sigma}(\widehat{\bm{w}},\widehat{\mathcal{p}}^{*};\widehat{\mathcal{p}}_% {0})-L_{\sigma}({\bm{w}}^{*},\widehat{\mathcal{p}};\widehat{\mathcal{p}}_{0}). The idea of approximating a gap and showing it reduces at a rate 1/A_{k}, where A_{k} is a monotonically increasing function of k, comes from [Diakonikolas2017TheAD] and has been extended to primal-dual methods, including DRO settings, in [song2021variance, diakonikolas2022fast, mehta2024primal, song2022coordinate]. Unlike past work [song2021variance, diakonikolas2022fast, mehta2024primal, song2022coordinate], our primal problem is nonconvex, even for ReLU activations without distributional ambiguity. Unfortunately, the previously mentioned results relying on convexity do not apply in our setting. Additionally, sharpness — which appears crucial to approximating the target loss — is a local property, applying only to {\bm{w}} such that \|{\bm{w}}\|_{2}\leq 2\|{\bm{w}}^{*}\|_{2}, where \|{\bm{w}}^{*}\|_{2} is unknown. This condition is trivially met at initialization, but proving it holds for all iterates requires convergence. We address this issue via an inductive argument, effectively coupling convergence analysis with localization of the iterates. Additionally, standard primal-dual methods [chambolle2011first, chambolle2018stochastic, alacaoglu2022complexity, song2021variance, song2022coordinate] rely on bilinear coupling between primal and dual variables in L_{\sigma}({\bm{w}},\widehat{\mathcal{p}};\widehat{\mathcal{p}}_{0}). In our case, L_{\sigma}({\bm{w}},\widehat{\mathcal{p}};\widehat{\mathcal{p}}_{0}) is nonlinear and nonconvex in the first argument. Recent work [mehta2024primal] handled nonlinearity by linearizing the function using convexity of the loss, which makes the function bounded below by its linear approximation at any point. However, this approach cannot be applied to our problem as the loss is nonconvex. Instead, we control the chi-squared divergence between the target distribution and the algorithm dual iterates to bound L_{\sigma}({\bm{w}},\widehat{\mathcal{p}}^{*};\widehat{\mathcal{p}}_{0}) from below, using a key structural result that we establish in Lemma 3.4. The challenges involved in proving this structural result require us to rely on chi-squared regularization and convex activation \sigma. Generalizing our result to all monotone unbounded activations and other strongly convex divergences like KL would need a similar structural lemma under these broader assumptions. An interesting aspect of our analysis is that we do not rely on a convex surrogate for our problem. Instead, we constructively bound a quantity related to the DRO risk of the original square loss, justifying our algorithmic choices directly from the analysis. Although we do not consider convex surrogates, the vector field {\bm{v}}({\bm{w}};{\bm{x}},y), scaled by 2\beta, corresponds to the gradient of the convex surrogate loss \int_{0}^{{\bm{w}}\cdot{\bm{x}}}(\sigma(t)-y)\,\mathrm{d}t, which has been used in prior literature on learning a single neuron under similar settings without distributional ambiguity [kakade2011efficient, DGKKS20, wang2023robustly-learning]. In our analysis, the vector field {\bm{v}}({\bm{w}};{\bm{x}},y) is naturally motivated by the argument in the proof of Lemma 3.4. “Concentration” of the Target Distribution To prove that our primal-dual algorithm converges, we need to prove both an upper bound and a lower bound for \mathrm{Gap}(\widehat{\bm{w}},\widehat{\mathcal{p}};\widehat{\mathcal{p}}_{0}). The lower bound relies on sharpness; however, we need it to hold for the empirical target distribution (\widehat{\mathcal{p}}^{*}). This requires us to translate distributional assumptions and/or their implications from {\mathcal{p}}^{*} to \widehat{\mathcal{p}}^{*}. Unfortunately, \widehat{\mathcal{p}}^{*} is not the uniform distribution over samples drawn from {\mathcal{p}}^{*}. Rather, it is the maximizing distribution in the empirical DRO risk, defined w.r.t. \widehat{\mathcal{p}}_{0}. This means that prior uniform convergence results do not apply. Additionally, minimax risk rates from prior statistical results, such as those in [duchi2021learning], relate R({\bm{w}};\widehat{\mathcal{p}}_{0}) and R({\bm{w}};{\mathcal{p}}_{0}). However, they do not help in our algorithmic analysis since they do not guarantee that the sharpness holds for \widehat{\mathcal{p}}^{*}. To address these challenges, we prove (in Corollary C.2) that as long as \nu is sufficiently large, there is a simple closed-form expression for \widehat{\mathcal{p}}^{*} as a function of \widehat{\mathcal{p}}_{0} and an analogous relationship holds between {\mathcal{p}}^{*} and {\mathcal{p}}_{0}. This allows us to leverage the fact that expectations of bounded functions with respect to \widehat{\mathcal{p}}_{0} closely approximate those with respect to {\mathcal{p}}_{0} to show that expectations with respect to \widehat{\mathcal{p}}^{*} and {\mathcal{p}}^{*} are similarly close. This result then implies that the sharpness also holds for \widehat{\mathcal{p}}^{*} (Lemma C.6). Full details are provided in Appendix C."
https://arxiv.org/html/2411.06360v1,Optimized Inference for 1.58-bit LLMs: A Time and Memory-Efficient Algorithm for Binary and Ternary Matrix Multiplication,"Despite their tremendous success and versatility, Large Language Models (LLMs) suffer from inference inefficiency while relying on advanced computational infrastructure.To address these challenges and make LLMs more accessible and cost-effective, in this paper, we propose algorithms to improve the inference time and memory efficiency of 1.58-bit LLMs with ternary weight matrices.Particularly focusing on matrix multiplication as the bottle-neck operation of inference, we observe that, once trained, the weight matrices of a model no longer change. This allows us to preprocess these matrices and create indices that help reduce the storage requirements by a logarithmic factor while enabling our efficient inference algorithms. Specifically, for a n by n weight matrix, our efficient algorithm guarantees a time complexity of O(\frac{n^{2}}{\log n}), a logarithmic factor improvement over the standard O(n^{2}) vector-matrix multiplication.Besides theoretical analysis, we conduct extensive experiments to evaluate the practical efficiency of our algorithms. Our results confirm the superiority of the approach both with respect to time and memory, as we observed a reduction in inference time up to 29x and memory usage up to 6x.111Our code is publicly available on Github: https://github.com/UIC-InDeXLab/RSR.","Large Language Models (LLMs) have achieved remarkable success and demonstrated versatility across a wide range of domains, yet they encounter significant challenges related to inference inefficiency. These models demand substantial computational resources, including specialized, costly GPUs with ample memory to achieve real-time inference. This inefficiency leads to slower response times, elevated energy consumption, higher operational expenses, and, perhaps more importantly, limited accessibility for everyday users who lack access to advanced computational infrastructure. Given these limitations, current deployments of LLMs on typical consumer devices rely predominantly on API calls to powerful, remote servers (OpenAI, 2024; AI21 Labs, 2024; Hu et al., 2021; Hugging Face, 2023). While this approach enables users to leverage LLMs without needing advanced hardware, it introduces additional costs and delays due to network dependency, along with potential privacy concerns stemming from data transmitted to and processed by external servers (Yao et al., 2024; Pearce et al., 2023; Das et al., 2024; Finlayson et al., 2024). Consequently, optimizing inference time and memory efficiency on standard, widely available hardware has become essential to make LLMs more practical and accessible for broader, real-world applications. To that end, recent efforts have focused on quantizing the weights of LLMs, and more generally, Deep Neural Networks (DNNs), to enhance their computational efficiency and reduce energy consumption (Moons et al., 2017; Hubara et al., 2018; Wang et al., 2023; Chen et al., 2024; Ma et al., 2024). Particularly, limiting the weights to ternary values \{-1,0,1\} in 1.58-bit LLMs has demonstrated to preserve accuracy comparable to that of general LLMs, thereby offering a more effective alternative for inference tasks (Ma et al., 2024). Expanding on recent advancements of ternary-weight LLMs (and DNNs), in this paper, we propose algorithms that improve their inference time and memory efficiency. Our approach makes deploying these models viable on a broader range of devices, including those with limited computational power, ultimately making these tools more widely accessible and cost-effective. Specifically, while viewing the inference process as sequences of multiplying activation vectors to ternary weight matrices, we make a critical observation: once the model is trained, the weight matrices remain fixed and do not change. Therefore, focusing on matrix multiplication as the bottleneck operation, we preprocess the weight matrices of the trained model and create indices that enable efficient multiplication during the inference time. At a high level, the indices are bucketized permutation lists. Interestingly, by replacing each weight matrix with its preprocessed indices, our approach reduces the space complexity required for storing the weights by a logarithmic factor. We propose two algorithms for efficient multiplication of input vectors to the preprocessed weight matrices. At a high level, our algorithms transform each ternary matrix to two binary matrices222Note that our algorithms readily apply to DNNs with binary weight matrices, including BitNet (Wang et al., 2023)., while partitioning each matrix into a set of column blocks. Then, permuting the rows based on a lexical order, they compute a set of aggregate values that contribute to different elements of the result vector. This process guarantees a time complexity of O(\frac{n^{2}}{\log(n)-\log\log(n)}) for n\times n matrices in our first algorithm. Furthermore, introducing an efficient approach for writing the aggregate values in the result vector, our second algorithm improves the time complexity to O(\frac{n^{2}}{\log(n)}). The run-time of our algorithms further improves by fine-tuning their blocking parameter. Many widely used large language models (LLMs) are characterized by substantial matrix weight sizes. For instance, the matrix size of GPT-3 is 12,288 (\approx 2^{13}) (Tsai, 2020; Tech, 2023; Brown, 2020), and this value is even greater for GPT-4. Consequently, achieving even a logarithmic factor improvement can have a significant impact, potentially resulting in up to a 13x reduction in inference time for models such as GPT-3. In addition to theoretical analysis, we perform rigorous experiments to evaluate the time and memory of our algorithms in practice. Confirming our theoretical findings, our experiments demonstrate the superiority of algorithms over the standard O(n^{2}) multiplications approach. In particular, our algorithms reduced the inference time by up to 29x and reduced memory usage by up to 6x. 1.1 Summary of Contribution In summary, our contributions are as follows: • (Section 3) We provide a formal definition of the vector-ternary-matrix multiplication problem and demonstrate its reduction to the vector-binary-matrix multiplication problem. • (Section 4) Following the observation that weight metrics are fixed once a model is trained, we preprocess them and construct indices that enable the development of our efficient algorithms while reducing the memory requirements by a logarithmic factor. • (Section 5) We introduce the RSR algorithm with a time complexity of O\left(\frac{n^{2}}{\log(n)-\log(\log(n))}\right) for vector-binary-matrix multiplication for n by n matrices. We further optimize this algorithm and introduce RSR++ that achieves a faster running time of O(\frac{n^{2}}{\log(n)}). • (Sections 6 and 7) We conduct various experiments to demonstrate the applicability of our algorithms for matrix multiplication using different implementation configurations. We show that we can achieve up to 29x faster run time and 6x less space usage on matrix multiplication task. Finally, we discuss the advantages and limitations of our algorithm in Section 7."
https://arxiv.org/html/2411.06200v1,Weak to Strong Learning from Aggregate Labels,"In learning from aggregate labels, the training data consists of sets or “bags” of feature-vectors (instances) along with an aggregate label for each bag derived from the (usually \{0,1\}-valued) labels of its constituent instances. In the learning from label proportions (LLP) setting, the aggregate label of a bag is the average of the instance labels, whereas in multiple instance learning (MIL) it is the OR. The goal is to train an instance-level predictor, which is typically achieved by fitting a model on the training data, in particular one that maximizes the accuracy which is the fraction of satisfied bags i.e., those on which the model’s induced labels are consistent with the target aggregate label. A weak learner in this context is one which has at a constant accuracy <1 on the training bags, while a strong learner’s accuracy can be arbitrarily close to 1. We study the problem of using a weak learner on such training bags with aggregate labels to obtain a strong learner, analogous to supervised learning for which boosting algorithms are known. Our first result shows the impossibility of boosting in the LLP setting using weak classifiers of any accuracy <1 by constructing a collection of bags for which such weak learners (for any weight assignment) exist, while not admitting any strong learner. A variant of this construction also rules out boosting in MIL for a non-trivial range of weak learner accuracy. In the LLP setting however, we show that a weak learner (with small accuracy) on large enough bags can in fact be used to obtain a strong learner for small bags, in polynomial time. We also provide more efficient, sampling based variant of our procedure with probabilistic guarantees which are empirically validated on three real and two synthetic datasets. Our work is the first to theoretically study weak to strong learning from aggregate labels, with an algorithm to achieve the same for LLP, while proving the impossibility of boosting for both LLP and MIL.","In traditional, fully supervised learning, the training data consists of a collection of labeled feature-vectors (i.e., training examples) \{({\mathbf{x}}_{i}\in\bm{\mathcal{X}},y_{i}=y({\mathbf{x}}_{i}))\}_{i=1}^{n}, for some domain \bm{\mathcal{X}} where the mapping y provides the feature-vector labels. In this paper we will consider the binary setting i.e., the labels are \{0,1\}-valued. The usual training goal is to find a good classifier f:\bm{\mathcal{X}}\to\{0,1\} which maximizes the training accuracy \left|\{i:f({\mathbf{x}}_{i})=y_{i}\}\right|/n. In recent times however, due to privacy (Rueping, 2010) or feasibility (Chen et al., 2004) constraints, in many applications the training label for each training example is not available. Instead, the training data consists of sets or bags of feature-vectors along with only the average or equivalently sum of the labels for each bag since bag size is known. This is called learning from label proportions (LLP) in which the training set consists of labeled bags \{(B_{j},\overline{y}_{j}\}_{j=1}^{m} where B_{j}\subseteq\bm{\mathcal{X}} and \overline{y}_{j}=\sum_{{\mathbf{x}}\in B_{j}}y({\mathbf{x}}). The training goal is to fit a good classifier f:\bm{\mathcal{X}}\to\{0,1\} on this bag-level training data. A related problem is multiple instance learning (MIL) in which the label for each bag is the OR of the boolean labels of its constituent feature vectors, while the goal of fitting a good feature-vector classifier remains the same. A natural metric for the goodness of fit in the LLP setting is to maximize the bag-level accuracy i.e., the fraction of satisfied training bags, where a bag (B,\overline{y}) is satisfied if \overline{y}=\left(\sum_{{\mathbf{x}}\in B}f({\mathbf{x}})\right). An analogous notion of accuracy for MIL is if \overline{y}=\left(\bigvee_{{\mathbf{x}}\in B}f({\mathbf{x}})\right). Recent works (Saket, 2021, 2022) have studied the the computational learning aspect of LLP and MIL, and in particular showed that the problem of finding classifiers (even in the realizable case) of high bag-level accuracy can be NP-hard. In supervised classification, boosting (see (Freund and Schapire, 1995; Schapire and Freund, 2012)) is a well known meta-technique which, given a training dataset uses an ensemble (typically a majority) of weak classifiers (on reweighed data) to output a hypothesis which has accuracy arbitrarily close to 1 i.e., a strong classifier. In the \{0,1\}-labels case a weak classifier has accuracy at least (1/2+\varepsilon) for some \varepsilon>0, while that for a strong classifier is (1-\nu) where \nu can be made arbitrarily small. Note that the threshold of 1/2 for weak classification is the expected accuracy of random prediction on the training set. To address the algorithmic learning problems in LLP and MIL, one could hope to apply boosting techniques to LLP and MIL settings as well. Here, we can define a weak classifier having some constant accuracy on the bags, while the notion of a strong classifier remains the same: that with an arbitrarily high accuracy. A natural question to ask is: is there a way to do boosting using weak-classifiers to obtain a strong classifier in learning from aggregate labels? In this work we show that the above is impossible even on 2-sized bags for (i) LLP using weak classifiers of any accuracy <1, and (ii) for MIL using weak classifiers of any accuracy <2/3. Specifically, we construct a collection of bags such that any reweighing of the bags admits a weak classifier of the desired accuracy while the original collection does not have admit any strong classifier i.e., any labeling to the underlying feature vectors satisfies at most some constant <1 fraction of the bags. We note that on bags of size 2, for both LLP and MIL the worst-case accuracy obtained by using the random or any constant-valued classifier (all 0s or all 1s), is 1/2. So, even for MIL we rule out boosting using weak classifiers with non-trivial accuracy in [1/2,2/3). Our impossibility of boosting stands in contrast to previous work (e.g. (Auer and Ortner, 2004; Qi et al., 2018)) which empirically evaluate boosting heuristics for LLP and MIL – our results are the first to show that such algorithms cannot provably yield a strong classifier. While the above impossibility results are applicable to the boosting framework, one can ask: is there some other way to derive a strong classifier from weak classifiers? Our next result answers this question in the affirmative for LLP: a weak classifier (of any constant accuracy \gamma>0) on large bags can be used to derive a strong classifier on a training set of (smaller) bags. These large bags are each a union of t training bags, where t depends only on \gamma and the desired accuracy of the strong classifier. While on m training bags, the number of (\approx m^{t}) unions are polynomial-time for constant t, we also provide a significantly more efficient sampling version of this approach which provides the same guarantees with high probability. These are to the best of our knowledge the first methods obtaining strong classifiers from weak classifiers for LLP. For MIL on the other hand the question of such weak to strong learning remains open. 1.1 Previous Related Work Multiple Instance Learning (MIL). The study by Dietterich et al. (1997) introduced MIL for drug activity detection, where the bag label is modeled as an OR of its (unknown) instance labels, all labels are \{0,1\}-valued. The goal, given such a dataset of bags, is to train a classifier for instance labels. Theoretically, Blum and Kalai (1998) proved that noise tolerant PAC learnability implies MIL PAC learnability for iid bags, and generalization bounds for the classification error on bags were provided by Sabato and Tishby (2012). Methods including logistic regression, maximum likelihood and boosting with differentiable approximations to the OR function (Ray and Craven, 2005; Ramon and De Raedt, 2000; Zhang et al., 2005) have been proposed. Diverse-density (DD) method (Maron and Lozano-Pérez, 1997) and its EM-based variant, EM-DD (Zhang and Goldman, 2001) are specialised MIL techniques. Over the years this approach has found many applications in numerous areas, including drug discovery (Maron and Lozano-Pérez, 1997), analysis of videos (Sikka et al., 2013), medical images (Wu et al., 2015), time series (Maron, 1998) and information retrieval (Lozano-Pérez and Yang, 2000). Learning from Label Proportions (LLP). A variety of specialized LLP methods have been introduced till date: de Freitas and Kück (2005) and Hernández-González et al. (2013) developed MCMC techniques, Musicant et al. (2007) adapted traditional supervised learning techniques like k-NN and SVM, while clustering based methods were proposed by Chen et al. (2009) and Stolpe and Morik (2011). Further, Quadrianto et al. (2009) and Patrini et al. (2014) devised specialized learning algorithms using bag-label mean estimates, and Yu et al. (2013) developed an SVM approach with bag-level constraints. Newer methods involve deep learning (Kotzias et al., 2015; Dulac-Arnold et al., 2019; Liu et al., 2019; Nandy et al., 2022) and others leverage characteristics of the distribution of bags (Saket et al., 2022; Zhang et al., 2022; Chen et al., 2023; Busa-Fekete et al., 2023). The theoretical foundations of LLP were investigated by Yu et al. (2014), who defined the problem within the PAC framework and established bounds on the generalization error for the label proportion regression task. Recent work by Saket (2021), Saket (2022) and Brahmbhatt et al. (2023) addressed bag-classification using linear classifiers, providing algorithmic and hardness bounds. Applications of LLP include privacy in online advertising (O’Brien et al., 2022), high energy physics (Dery et al., 2017) and IVF predictions (Hernández-González et al., 2018). Boosting. The first boosting algorithm was given by Schapire (1989) which was followed by a more efficient algorithm by Freund (1990) and subsequently the famous AdaBoost algorithm (Freund and Schapire, 1995). Further work (Chen and Guestrin, 2016; Warmuth et al., 2008; Freund, 2001) resulted in the development of several boosting techniques, while Mason et al. (1999) showed that several boosting algorithms (including AdaBoost (Freund and Schapire, 1995) and LogitBoost (Friedman et al., 2000)) implicitly perform gradient descent in the functional space and fall into the AnyBoost framework. If we consider bags themselves as examples, one can directly apply existing boosting frameworks to obtain strong bag-level classifiers (see for e.g. (Lai et al., 2023)). However, our goal is to obtain feature-vector level strong classifiers with high accuracy on bags. Previous works have adapted a subset of the above mentioned boosting approaches to LLP (Viola et al., 2005; Auer and Ortner, 2004; Qi et al., 2018) – however they are empirically evaluated heuristics and not guaranteed to output strong classifiers. 1.2 Problem Definition and Our Results Let \bm{\mathcal{X}}\subseteq\mathbb{R}^{d} for some d\in\mathbb{Z}^{+} be the space of feature-vectors, while a bag B is a finite subset of \bm{\mathcal{X}}. Let \mathcal{Y}\subseteq\mathbb{R} be the space of feature-vector labels, and \overline{\mathcal{Y}}\subseteq\mathbb{R} be the space of bag-level aggregate labels with some aggregation function {\sf Agg} mapping finite \mathcal{Y}-valued tuples to \overline{\mathcal{Y}}. We say that a bag B=({\mathbf{x}}_{1},\dots,{\mathbf{x}}_{q}) with aggregate label \sigma is satisfied by a classifier f:\bm{\mathcal{X}}\to\mathcal{Y} if {\sf Agg}(f({\mathbf{x}}_{1}),\dots,f({\mathbf{x}}_{q}))=\sigma. For convenience we will use bag to refer to a bag and its aggregate-label. An m-sized training set \mathcal{B} is a collection \{(B_{j},\sigma_{j})\in 2^{\bm{\mathcal{X}}}\times\overline{\mathcal{Y}}\}_{j=% 1}^{m} of m bags and their aggregate-labels along with weights w_{j}\geq 0 for bag B_{j} (j=1,\dots,m) such that \sum_{j=1}^{m}w_{j}=1. The accuracy of a classifier on \mathcal{B} is the weighted fraction of bags satisfied by it. We define a weak classifier to be one with constant accuracy \gamma>0, and a \nu-strong classifier to have an accuracy (1-\nu). For ease of exposition we call the latter a strong classifier when \nu can be taken to be an arbitrarily small positive constant. For this study, the underlying feature-vector level task is binary classification, so \mathcal{Y}=\{0,1\}. For multiple instance learning (MIL) the aggregation function is {\sf OR} i.e., the boolean disjunction and therefore \overline{\mathcal{Y}}=\{0,1\}. On the other hand, in learning from label proportions (LLP) we take the aggregation function to be {\sf SUM} i.e., the real sum of labels, and therefore \overline{\mathcal{Y}}=\mathbb{Z}^{\geq 0}. Note that for LLP we could have equivalently taken average as the aggregation (since the size of any bag is known), however for convenience we use {\sf SUM}. We also define the {\sf Trv}_{\sf LLP}(\mathcal{B}) for a collection of LLP bags, to denote the trivial accuracy threshold on \mathcal{B}. Specifically, it is the minimum weighted accuracy given by the best among the random classifier and the two constant valued classifiers (all 0s and all 1s classifiers), over all possible weight assignments to the bags \mathcal{B}. For a collection of MIL bags \mathcal{B}, {\sf Trv}_{\sf MIL}(\mathcal{B}) is defined analogously. We shall also use the halfspace classifier whose value at point {\mathbf{x}}\in\mathbb{R}^{d} is given by {\sf pos}\left(\langle{\mathbf{r}},{\mathbf{x}}\rangle+c\right) for some {\mathbf{r}}\in\mathbb{R}^{d}, c\in\mathbb{R} where {\sf{pos}}(a)=1 if a>0 and 0 otherwise. We say that the halfspace passes through the origin i.e., is homogeneous if c=0. Next we state this paper’s results. 1.2.1 Our Results We begin with the impossibility results for boosting in the LLP (Theorem 1.1) and MIL (Theorem 1.2) settings. These theorems coupled with the definition of the boosting meta algorithm (Section 2.1) imply our impossibility results. Theorem 1.1 (Impossibility of boosting in LLP). Let \alpha\in[1/2,1) be any constant. Then, for any arbitrarily small constant \varepsilon>0 there exists d,m\in\mathbb{Z}^{+} and a collection of bags \mathcal{B}=\{B_{j}\subseteq\mathbb{R}^{d}\}_{j=1}^{m} where |B_{j}|=2 and the aggregate label (i.e. sum of labels in LLP setting) of B_{j} is 1 (j=1,\dots,m) and the following properties are satisfied: (Existence of weak halfspace classifiers): For any assignment of weights w_{j} to B_{j} (j=1,\dots,m) such that \sum_{j=1}^{m}w_{j}=1, for the weighted collection of bags there is a halfspace classifier with accuracy \alpha. (No Strong Classifier): For the unweighted set of bags \{B_{j}\subseteq\mathbb{R}^{d}\}_{j=1}^{m} there is no classifier f:\cup_{j=1}^{m}B_{j}\to\{0,1\} having accuracy greater than \alpha+\varepsilon. The above theorem, proved in Section 3, is optimal from multiple perspectives: firstly the bags are of size at most 2 whereas when bags are all of size 1 (i.e., supervised learning) boosting is indeed possible, showing that as soon as we transition from the fully supervised to the LLP setting in terms of bag size, boosting becomes impossible. Secondly, the result shows that even if weak learners of any constant accuracy in [1/2,1) exist, there is no classifier with even a slightly greater accuracy, thus ruling out any non-trivial advantage of boosting, let alone obtaining a strong classifier. In Appendix A we give a simple argument showing that {\sf Trv}_{\sf LLP}(\mathcal{B})=1/2 for the bags \mathcal{B} constructed in the above theorem. We now state our result (proved in Section 4) on the impossibility of boosting in the MIL setting. Theorem 1.2 (Impossibility of boosting in MIL). For any arbitrarily small constant \varepsilon>0 there exist m\in\mathbb{Z}^{+} and a collection of bags \mathcal{B}=\{B_{j}\subseteq\mathbb{R}^{d}\}_{j=1}^{m} along with the aggregate labels \sigma_{j} for B_{j} where |B_{j}|=2 (j=1,\dots,m) and the following properties are satisfied: (Existence of weak halfspace classifiers): For any assignment of weights w_{j} to B_{j} (j=1,\dots,m) such that \sum_{j=1}^{m}w_{j}=1, for the weighted collection of bags there is a halfspace classifier with accuracy 2/3-\varepsilon. (No Strong Classifier): For the unweighted set of bags \{B_{j}\subseteq\mathbb{R}^{d}\}_{j=1}^{m} there is no classifier f:\cup_{j=1}^{m}B_{j}\to\{0,1\} having accuracy greater than 3/4. The above theorem shows that in the MIL setting, weak classifiers with any accuracy <2/3 cannot be boosted to a strong classifier with accuracy >3/4. As shown in Appendix A, {\sf Trv}_{\sf MIL}(\mathcal{B})=1/2 for the bags \mathcal{B} of the above theorem, and therefore our result applies to w non-trivial weak classifier accuracy in (1/2,2/3). Next we state our results (proved in Section 5) in the LLP setting for obtaining a strong classifier on a collection of bags using a weak classifier on a derived collection of larger bags. In this case we consider unweighted collection of bags, since a weighted collection of m bags can easily be converted into an unweighted collection of Tm bags while preserving the accuracy of any classifier up to an additive error of O(1/T) (see Appendix B). To state our result we assume that there is an oracle \mathcal{O}_{q,\alpha}(\overline{\mathcal{B}}) which given weighted collection of bags \overline{\mathcal{B}} along with their aggregate labels, where each bag has size at most q, outputs a classifier f with weighted accuracy \alpha on \overline{\mathcal{B}}. Theorem 1.3 (Weak to Strong LLP Learning). For parameters \alpha,\varepsilon>0 there exists t=O(1/(\varepsilon\alpha^{2})), and algorithms \mathcal{A}_{1} and \mathcal{A}_{2} s.t. given an unweighted collection of m bags \mathcal{B}, where k=\max_{(B,\sigma)\in\mathcal{B}}\left|B\right| and n:=\left|\cup_{(B,\sigma)\in\mathcal{B}}B\right|, and assuming that \mathcal{O}_{kt,\alpha} exists, • \mathcal{A}_{1} creates a weighted collection \overline{\mathcal{B}}_{1} of at most m^{t+1} bags each of size at most kt such that \mathcal{O}_{kt,\alpha}(\overline{\mathcal{B}}_{1}) outputs a classifier which has accuracy (1-\varepsilon) on \mathcal{B}. • for any \delta>0, \mathcal{A}_{2} creates a random collection \overline{\mathcal{B}}_{2} of s=O\left(\frac{1}{\alpha}\left(n+\log\left(\frac{1}{\delta}\right)\right)\right) each of size at most kt such that \mathcal{O}_{kt,\alpha}(\overline{\mathcal{B}}_{2}) has accuracy (1-\varepsilon) on \mathcal{B} with probability at least (1-\delta). If \mathcal{O}_{kt,\alpha} is guaranteed to output a classifier of VC dimension r then s=O\left(\frac{r}{\alpha}\log\left(\frac{n}{r}\right)+\log\left(\frac{1}{% \delta}\right)\right) suffices. Theorem 1.3 presents algorithms that, when applied to collections of bags in the LLP setting, yields high-accuracy classifiers by employing weak classifiers trained on a reasonably sized collections of large bags. This can in particular be achieved by an efficient randomized algorithm \mathcal{A}_{2}. We also conduct experiments (see Section 6) – on both real and synthetic datasets – to demonstrate the effectiveness of \mathcal{A}_{2}. We use it to construct a limited collection of large bags from a given collection of small bags and experimentally show that a weak classifier on the large bags yields one with significantly higher accuracy on the constituent small bags. 1.3 Overview of Techniques Impossibility of Boosting in LLP (Theorem 1.1). Our construction follows from the well-known semi-definite programming (SDP) integrality gap of Feige and Schechtman (2002) for the Max-Cut problem. In this, for some arbitrarily small \varepsilon>0, with d depending on \varepsilon, the vertices of the graph are given by points on the (d-1)-dimensional unit sphere \mathbb{S}^{d-1}. For any constant \alpha\in[1/2,1), each edge is between points that are at an angle of at least \alpha\pi. Using techniques related to spherical isoperimetry and concentration of measure in high dimensions, the authors prove that there is no cut in the graph separating more than (\alpha+\varepsilon)-fraction of the edges. By creating a 2-sized bag corresponding to each edge with latter’s two end-points being the bag’s two feature-vectors, we create a collection of bags, and for each one we assign an aggregate label 1 i.e., any bag is satisfied if exactly one of its feature-vectors is labeled 1 or equivalently the corresponding edge is separated. The cut upper bound of (\alpha+\varepsilon) thus directly gives us the upper bound on the best possible accuracy of any classifier. On the other hand, since the angle between the feature-vectors of any edge is at least \alpha\pi, a random halfspace passing through the origin – given by {\sf pos}\left({\mathbf{r}}^{\sf T}{\mathbf{x}}\right) for a random unit vector {\mathbf{r}} – has expected accuracy \alpha for any weight assignment to the bags, and therefore there is some halfspace achieving accuracy \alpha. Impossibility of Boosting in MIL (Theorem 1.2). Since the aggregation function is {\sf OR} the Max-Cut construction of Feige and Schechtman (2002) is not applicable. Instead we hand-craft the set of bags as follows. The set of feature-vectors is all points on the unit circle \mathbb{S}^{1} and for some \alpha\in(1/2,1), we create a bag with two points if the angle between them is exactly \alpha\pi and give an aggregate label 1 to all such two sized bags (let us call them 1-bags). We also construct 2-sized bags with aggregate label 0 when the angle between two points is exactly (1-\alpha)\pi (called as 0-bags). If we consider any reweighted collection of these bags then a simple threshold based case-analysis yields weak classifier of accuracy 2/3-(1-\alpha)/2. To rule out any strong classifier, we consider a labeling where z-fraction of the points in \mathbb{S}^{1} are labeled as 1. We show that the maximum accuracy possible is 3/4 which is achieved at z=1/2. We choose \alpha=1-\varepsilon while losing an additional error of \varepsilon/2 in the weak-classifier accuracy due to discretization to obtain the desired bounds. Weak to Strong LLP Learning (Theorem 1.3). The main idea is, given a target collection of bags \mathcal{B}, to construct all possible bags which are unions of up to t bags from \mathcal{B}. Note that the aggregate label for the union is simply the sum of the aggregate labels of the constituent bags, and the error of a classifier w.r.t. the aggregate label on the union of bags is the sum of errors on the constituent bags. Let f be a classifier with accuracy \gamma>0 on these larger bags, and assume for a contradiction that f has accuracy less than (1-\varepsilon) on \mathcal{B}, for some \varepsilon>0. Call those bags in \mathcal{B} on which f has a non-zero error \in\mathbb{Z}\setminus\{0\} w.r.t. the aggregate label, as the error bags. Now, if t is large enough then a random set of t bags from \mathcal{B} has, with high probability \approx\varepsilon t error bags. Using a sampling argument we show that the error on the union of t random bags from \mathcal{B} is distributed like a random Bernoulli combination of the errors on \approx 2\varepsilon t bags. We then apply the Littlewood-Offord-Erdős anti-concentration lemma to obtain that with probability at least (1-O(1/(\sqrt{\varepsilon t})), the the union of the bags has non-zero error induced by f. By choosing t large enough we obtain a contradiction with the accuracy of \alpha on the large bags. Standard sampling techniques can be applied to obtain a more efficient procedure with high probability guarantees."
