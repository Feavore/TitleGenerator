URL,Title,Abstract,Introduction
https://arxiv.org/html/2411.10188v1,Reachability Analysis of the Domain Name System,"The high complexity of DNS poses unique challenges for ensuring its security and reliability. Despite continuous advances in DNS testing, monitoring, and verification, protocol-level defects still give rise to numerous bugs and attacks. In this paper, we provide the first decision procedure for the DNS verification problem, establishing its complexity as \mathsf{2ExpTime}, which was previously unknown.We begin by formalizing the semantics of DNS as a system of recursive communicating processes extended with timers and an infinite message alphabet. We provide an algebraic abstraction of the alphabet with finitely many equivalence classes, using the subclass of semigroups that recognize positive prefix-testable languages. We then introduce a novel generalization of bisimulation for labelled transition systems, weaker than strong bisimulation, to show that our abstraction is sound and complete. Finally, using this abstraction, we reduce the DNS verification problem to the verification problem for pushdown systems. To show the expressiveness of our framework, we model two of the most prominent attack vectors on DNS, namely amplification attacks and rewrite blackholing.","The Domain Name System (DNS) is a central component of the Internet’s infrastructure. It translates human-readable domain names, such as www.sigplan.org, into machine-recognizable IP addresses via name resolution, thereby simplifying Internet navigation and resource access for users. This seemingly simple translation service, handled by recursive resolvers, is underpinned by an intricate, hierarchical, globally distributed database. Each organization, like Google or Cloudflare, provides name resolution for its portion or zone of the entire DNS namespace. Operators within each organization manage that zone through, often manually configured, zone files. These zone files, stored on authoritative nameservers, map domain names to IP addresses as well as other types of DNS records, specifying further actions to be taken such as query rewriting or delegation. The IETF (Internet Engineering Task Force) (IETF, 0 15) publishes requests for comments (RFCs), which are technical documents describing the Internet’s technical foundations. To date, hundreds of RFCs (e.g., (Mockapetris, 1987a, b; Rose and Wijngaards, 2012; Elz and Bush, 1997)) have been published that define and guide the design, implementation, and operation of DNS. The sophisticated nature and large scale of DNS pose unique challenges for developers and operators, who have invested considerable efforts to ensure its functional correctness, security, and availability. These challenges often stem from name resolution failures, which result mainly from misconfigurations or attacks, and have historically led to large-scale outages (Whittaker, 2 07; Wikipedia, 2024; Tung, 2024). Of particular concern are denial of service (DoS) vectors, which have been frequently identified over the past decade (Maury, 2015; Afek et al., 2023; Li et al., 2024). In particular, amplification attacks, which exploit the DNS protocol to significantly increase the query load on the victim (resolvers or authoritative nameservers), have seen a surge in recent years (Afek et al., 2020; Liu et al., 2023; Xu et al., 2023; Moura et al., 2021; Duan et al., 2024). Despite continuous advances in DNS testing and monitoring (Bushart and Rossow, 2024; Zhang et al., 2024; ThousandEyes, 2024; Host, 2024; Kakarla and Beckett, 2023; Kakarla et al., 2022), numerous issues, like those just mentioned, still arise from RFCs or protocol-level defects in extensively tested production resolvers and nameservers. This highlights the necessity for a principled, proactive way to mitigate such problems, preferably at an early design stage. Two recent formal efforts (Liu et al., 2023; Kakarla et al., 2020) have attempted to address this issue. GRoot (Kakarla et al., 2020) is the first static verifier for DNS configuration errors, building on the protocol-level DNS resolution semantics. It has been successfully applied to identify misconfigurations in DNS zone files, prior to their deployment. DNSMaude (Liu et al., 2023) is a formal framework, implemented in the Maude (Clavel et al., 2007) language, for both the qualitative (e.g., functional correctness) and quantitative (e.g., amplification) analysis of DNS protocols. It is based on a semantics for the entire end-to-end name resolution, covering essential features such as resolver caching and recursive subqueries, which GRoot abstracts away. Henceforth, when we refer to DNS, we consider this more comprehensive semantics. DNSMaude’s accompanying analyzer has also discovered multiple attacks on DNS with large amplification effects. Research Gaps. Both works have provided partial solutions to the DNS verification (\mathsf{DNSVERIF}) problem where, given the DNS zone files \cal Z, one asks whether a property \phi of interest holds for some behavior of DNS (see Section 5 for its formal definition). Intuitively, the property \phi captures the bad behaviors exhibiting attacks. As every behavior of DNS starts with an initial query from the resolver, on behalf of a client, an immediate challenge in this problem is to explore the infinite space of queries exhaustively. A priori, this was infeasible. GRoot tackles this problem by introducing an equivalence relation on the query space, with finitely many equivalence classes (ECs), such that queries within an EC are resolved in the same manner and yield the same result. While this equivalence is proven to be sound under a simplified DNS semantics, it is unsound with respect to the more realistic semantics involving resolver caching (formalized in DNSMaude). Moreover, GRoot must be supplied with a pre-determined bound on the length of runs in DNS, making it incomplete by design. Additionally, the number of ECs increases explosively with query rewrites, to the order of n^{255} in the size of zone files, due to advanced DNS features like dname rewriting (Rose and Wijngaards, 2012) (see also Section 2.1), which can quickly inflate GRoot’s verification time. Finally, GRoot is inherently incapable of specifying behavioural vulnerabilities like amplification DoS attacks within its semantic framework. DNSMaude also works with GRoot’s ECs but supports specifying common behavioural vulnerabilities. However, it still struggles with attack discovery. Since it uses GRoot’s ECs, it may fail to explore certain bad behaviours that it believes are equivalent to those that have already been explored. It may then incorrectly conclude that there is an absence of bad behaviours, rendering its search procedure incomplete. Moreover, DNSMaude’s search procedure is also incomplete by design; it uses bounded, explicit-state, linear temporal logic (LTL) model checking (Clavel et al., 2007) for functional correctness properties, searching for bugs or potential attacks. DNSMaude also employs statistical model checking (SMC) (Sen et al., 2005) for quantitative properties like amplification. SMC verifies a property probabilistically, up to a given confidence level, by running Monte Carlo simulations. As a result, the search for attacks is again bounded, for example, in the number of simulations, and attacks may be missed.111We have experimented with DNSMaude’s simulation mode, which is used to discover attacks as presented in (Liu et al., 2023). We observe that around 30% of the runs do not achieve the maximum amplification factor, thus potentially overlooking attacks. Overall, neither of these two efforts provides a decision procedure for the \mathsf{DNSVERIF} problem. Moreover, an upper bound on the complexity of this problem still remains unknown (Kakarla et al., 2021). Our Approach. In this paper, we aim to address the above challenges. As the first step, we must faithfully model the semantics of DNS. We consider the well-studied model of a system of recursive communicating processes (Heußner et al., 2010, 2012), and extend it with timers. We call this extension, a system of recursive communicating processes with timers (trCPS). We model the DNS semantics as an instance of a trCPS. Intuitively, the timer keeps track of the age of a resource record in a resolver’s cache. As resolvers are stateful (due to referrals or query rewriting), we utilize stacks to model how they track the resolution process, where each stack entry corresponds to a subquery being resolved. Nameservers just behave as labelled transition systems (LTSs) as they are stateless. DNS is Eager It is well-known that reachability is undecidable for networks of LTSs that contain cycles in the underlying topology, assuming a finite message alphabet and perfect channels (Brand and Zafiropulo, 1983). However, this problem becomes decidable with lossy communications (Finkel and Schnoebelen, 2001; Abdulla and Jonsson, 1996). Since DNS typically operates over UDP (User Datagram Protocol) (Mockapetris, 1987b), which is inherently lossy, we can use lossy channels. Nevertheless, the problem once again becomes undecidable if a cycle contains a process that is a pushdown system (PDS) (Aiswarya, 2020, Thm. 1). Unfortunately, DNS falls within this class, as a resolver is modeled as a PDS with timers and communicates bidirectionally with nameservers (sending queries and receiving answers). Heussner et al. (Heußner et al., 2010, 2012) show that the reachability problem for networks of PDSs over perfect channels and a finite message alphabet, is decidable for eager runs and pointed network topologies. We show that all runs of DNS are eager by design, and that the underlying topology is pointed. This makes DNS fall within this decidable class of systems. Congruence Since DNS operates over both (i) an infinite query space and (ii) infinitely many timer valuations, the eagerness of DNS by itself is insufficient to obtain decidability. This is because an infinite query space also necessitates an infinite message alphabet. We propose a novel congruence on the domain space with finitely many equivalence classes, derived using syntactic congruences for carefully constructed regular languages (Nerode, 1958; Rabin and Scott, 1959), from the given zone file configuration \cal Z. We then show that the domains in any two DNS configurations only need to be syntactically congruent to each other with respect to certain positive prefix-testable languages (see Section 4.1). Moreover, these languages are parametric only in the names and values appearing in \cal Z’s resource records (see Section 3.1), in order to exhibit equivalent behaviours with respect to the DNS semantics. Notably, owing to the nature of these languages, the equivalence is robust to an unbounded number of dname rewrites (unlike GRoot), enabling an unbounded analysis. This effectively yields an abstraction with an equivalent finite message alphabet for the system. Finally, the set of timer valuations are abstracted using a standard region construction. Kernel Bisimulation The domain congruence induces a homomorphism on the semantics of DNS, allowing us to reduce it to a recursive CPS with finitely many control states. However, to show that the reduction is both sound and complete, we introduce a novel, generalized notion of bisimulation, called generalized kernel bisimulation. A crucial property of this bisimulation is the pointwise equivalence of runs from equivalent states up to the equivalence of transitions. We prove that the homomorphism induces a generalized kernel bisimulation on the DNS semantics such that any run in the abstract semantics corresponds to a class of equivalent runs in the original semantics. We use this to establish both soundness and completeness of our abstract model with respect to DNS behavior. Reduction to Reachability As we prove that DNS is an eager trCPS over a pointed network topology, the reduced abstract DNS is also an eager recursive CPS over the same topology. We then reduce the \mathsf{DNSVERIF} problem to an instance of the reachability problem for PDSs, which is known to be decidable (Bouajjani et al., 1997). Thus, we obtain the decidability of this problem. In addition, we establish that it is solvable in doubly-exponential time in the size of the zone file configuration \cal Z. Contributions. Overall, we make the following contributions. • We establish the first decision procedure for the \mathsf{DNSVERIF} problem (Theorem 4.14). Moreover, we show that our algorithm has an upper-bound of \mathsf{2ExpTime} complexity (Lemma 5.3), which was previously unknown. • At the technical level, we initially propose trCPS, a model for networks of recursive communicating processes with timers, as the underlying formal model for DNS (Section 3). But it comprises an infinite message alphabet due to the infinite query space. Owing to the monoidal nature of queries, we devise an algebraic abstraction for them (Section 4.3), with finitely many equivalence classes, using a special class of semigroups (Lemma 4.5). We then introduce a novel generalization of bisimulation for LTSs, weaker than strong bisimulation (Milner, 1980) but incomparable to weak bisimulation, to show that our abstraction is sound and complete (Section 4.2). Both these tools may also be of independent theoretical interest. • We show how our framework can be applied to instantiate two of the most prominent attacks on DNS, namely amplification attacks and rewrite blackholing (Section 6). This demonstrates the versatility of our approach."
https://arxiv.org/html/2411.09366v1,LTLf+ and PPLTL+: Extending LTLf and PPLTL to Infinite Traces,"We introduce LTLf+ and PPLTL+, two logics to express properties of infinite traces, that are based on the linear-time temporal logics LTLf and PPLTL on finite traces. LTLf+/PPLTL+ use levels of Manna and Pnueli’s LTL safety-progress hierarchy, and thus have the same expressive power as LTL. However, they also retain a crucial characteristic of the reactive synthesis problem for the base logics: the game arena for strategy extraction can be derived from deterministic finite automata (DFA). Consequently, these logics circumvent the notorious difficulties associated with determinizing infinite trace automata, typical of LTL reactive synthesis. We present DFA-based synthesis techniques for LTLf+/PPLTL+, and show that synthesis is 2EXPTIME-complete for LTLf+ (matching LTLf) and EXPTIME-complete for PPLTL+ (matching PPLTL). Notably, while PPLTL+ retains the full expressive power of LTL, reactive synthesis is EXPTIME-complete instead of 2EXPTIME-complete. The techniques are also adapted to optimally solve satisfiability, validity, and model-checking, to get EXPSPACE-complete for LTLf+ (extending a recent result for the guarantee level using LTLf), and PSPACE-complete for PPLTL+.","Reactive synthesis is concerned with synthesizing programs (aka, strategies) for reactive computations (e.g., processes, protocols, controllers, robots) in active environments (Pnueli and Rosner 1989; Finkbeiner 2016; Ehlers et al. 2017). The basic techniques for reactive synthesis share several similarities with Model Checking, and are based on the connections between Logics, Automata, and Games (Fijalkow et al. 2023). The most common specification language is possibly Linear Temporal Logic (LTL) (Pnueli 1977). Reactive Synthesis for LTL involves the following Steps: (1) having a specification \varphi of the desired system behavior in LTL, in which one distinguishes controllable and uncontrollable variables; (2) extracting from the specification an equivalent automaton on infinite words, corresponding to the infinite traces satisfying \varphi; (3) (differently from Model Checking) determinizing the automaton to obtain an arena for a game between the system and the environment; (4) solving the game, by fixpoint computation, for an objective determined by the automaton’s accepting condition (e.g., a parity objective for LTL), yielding a strategy for the system that fulfills the original specification \varphi. Model Checking is mature, and many of its techniques may be exploited in Reactive Synthesis as well, e.g., symbolic techniques based on Boolean encodings may be used to compactly represent the game arena and to compute fixpoints over it. However, despite this, Step (3) remains a major performance obstacle. For LTL, this involves determinizing nondeterministic Büchi automata, which is notoriously difficult (Vardi 2007). This has held back the use of reactive synthesis in applications. Reactive synthesis is deeply related to Planning (De Giacomo and Rubin 2018; Alberto, Bienvenu, and McIlraith 2019), and in particular to (strong) planning for temporally extended goals in fully observable nondeterministic domains (Cimatti et al. 2003; Bacchus and Kabanza 1998, 2000; Calvanese, De Giacomo, and Vardi 2002; Baier and McIlraith 2006; Baier, Fritz, and McIlraith 2007; Gerevini et al. 2009). A key characteristic of Planning is that the system continuously receives a goal, “thinks” about how to achieve it, synthesizes a plan, executes the plan, and repeats (Geffner and Bonet 2013). This suggests to focus on goal specifications that can be satisfied on finite traces. Recently, this led to a shift in Reactive Synthesis to focus on logics on finite traces (instead of infinite traces), e.g., LTLf (De Giacomo and Vardi 2013, 2015). The advantage of focusing on finite traces is that in Step (3) one can rely on (classic) automata operating on finite traces, including deterministic finite automata (DFA), and use known determinization algorithms with good practical performance. The development of LTLf synthesis (De Giacomo and Vardi 2015) has brought about scalable tools that are unprecedented in reactive synthesis (Zhu et al. 2017; Bansal et al. 2020; De Giacomo and Favorito 2021; De Giacomo et al. 2022). Beside LTLf, another finite-trace logic that is gaining popularity in AI is Pure Past LTL (PPLTL) (De Giacomo et al. 2020; Cimatti et al. 2020; Bonassi et al. 2023b, a, 2024). This is a variant of LTLf that sees the trace backwards and has the notable property that one can obtain a symbolic (i.e., factorized) DFA directly from the formula in linear time; moreover, while the size of the (non-symbolic) DFA corresponding to an LTLf formula can be double-exponential in the size of the formula itself, the size of the DFA corresponding to a PPLTL formula is at most a single-exponential in the size of the formula. Nevertheless, not all specifications of interest can be expressed on finite traces. For example, the planning domain is an infinite-trace specification: the planning domain will continue to respond to actions (with preconditions satisfied) by producing its possibly nondeterministic effects, forever. Not to mention recurrence, persistence, reactivity, and other properties typically used in Model Checking. When dealing with infinite traces, using (same variants of ) LTL as the specification language is an obvious choice. Can we lift the DFA techniques at the base of the success story of LTLf and PPLTL synthesis to full LTL? In this paper we answer this question positively! To do so, we leverage the classic hierarchy of LTL properties — the safety-progress hierarchy (Manna and Pnueli 1990).111 The hierarchy was introduced by Lichtenstein, Pnueli, and Zuck in 1985, later described in detail by Manna and Pnueli in 1990 and in their books (Manna and Pnueli 1992, 1995, 2010); also, see the survey (Piterman and Pnueli 2018). It consists of six classes of semantic properties, organized by inclusion. The bottom, first, level has, on the one hand, the safety properties (that intuitively express that nothing bad ever happens), and on the other the guarantee properties, sometimes also called co-safety properties, (that express that something good eventually happens); the second level consists of the class of obligation properties, obtained as positive Boolean combination of safety and guarantee properties; the third level contains, on the one hand, the recurrence properties (that express that something good occurs infinitely often), and on the other the persistence properties (that say that nothing bad occurs infinitely often); and the fourth level contains the reactivity properties, which are obtained as positive Boolean combination of recurrence and persistence properties. Each property is semantically defined in terms of sets of finite traces, e.g., a set F of finite-traces induces a basic safety (resp. progress) property that consists of an infinite trace iff every prefix (resp. all but finitely many prefixes) of the trace are in F. The reactivity properties contain all properties expressible in LTL.222The hierarchy is not limited to LTL, i.e., to properties that are expressible in first-order logic (FO) over infinite sequences (Kamp 1968), but extends to omega-regular properties, i.e., to monadic-second order logic (MSO) over infinite sequences. Indeed all the results we present here can be extended to omega-regular properties by substituting LTLf (resp. PPLTL) by its MSO-complete variant LDLf (resp. PPLDL) (De Giacomo and Vardi 2013). We revisit Manna and Pnueli’s hierarchy, and exploit it to define extensions of LTLf and PPLTL, which we call LTLf+ and PPLTL+, that can express arbitrary LTL properties on infinite traces. These new logics retain a crucial characteristic for reactive synthesis of their base logics: one can exploit the techniques for translating LTLf and PPLTL formulas into DFAs (De Giacomo and Vardi 2015; De Giacomo et al. 2020). These DFAs combine in a simple product to form the game arena for strategy extraction of LTLf+/PPLTL+ specifications. Naturally, the game objectives for LTLf+/PPLTL+ go beyond the simple adversarial reachability for LTLf/PPLTL. In particular, we exploit a variation of the Emerson-Lei condition (Emerson and Lei 1987) for handling Boolean combinations, and the possibility of translating these conditions into parity conditions (typically used for LTL) or to fixpoint computations (Hausmann, Lehaut, and Piterman 2024). We show that the worst-case complexity for synthesis of LTLf+ (resp. PPLTL+) is the same as for the base logics LTLf (resp. PPLTL), i.e., 2EXPTIME-complete (resp. EXPTIME-complete). The EXPTIME-complete result for synthesis in PPLTL+ is particularly interesting because, on the one hand, it shows that the exponential gap between PPLTL and LTLf (De Giacomo et al. 2020; Bonassi et al. 2023b) is maintained when extended to handle the full safety-progress hierarchy; and, on the other hand, it gives one a logic with the same expressive power as LTL but for which synthesis can be solved in EXPTIME instead of 2EXPTIME. Previous efforts to achieve reactive synthesis with exponential complexity focused on proper fragments of LTL (Arteche and Hermo 2024). We also adapt our DFA-based techniques and establish that reasoning — satisfiability, validity, and model-checking — for LTLf+ (resp. PPLTL+) is EXPSPACE-complete (resp. PSPACE-complete). The EXPSPACE-completeness result, which may appear surprising since satisfiability and model checking for LTL are both PSPACE-complete (Clarke et al. 2018), in fact confirms and extends a recent EXPSPACE-hardness result for model checking the fragment of LTLf+ limited to the guarantee class (Bansal et al. 2023). In other words, although LTLf+ defines infinite-trace properties using explicit reference to finite-trace properties defined in LTLf, it provides a computational advantage for synthesis but not for reasoning. Conversely, reasoning in PPLTL has the same cost as reasoning in LTL."
https://arxiv.org/html/2411.09121v1,": From Verification of Quantum Circuits
to Verification of Quantum Programs","We present a verifier of quantum programs called AutoQ 2.0. Quantum programs extend quantum circuits (the domain of AutoQ 1.0) by classical control flow constructs, which enable users to describe advanced quantum algorithms in a formal and precise manner. The extension is highly non-trivial, as we needed to tackle both theoretical challenges (such as the treatment of measurement, the normalization problem, and lifting techniques for verification of classical programs with loops to the quantum world), and engineering issues (such as extending the input format with a support for specifying loop invariants). We have successfully used AutoQ 2.0 to verify two types of advanced quantum programs that cannot be expressed using only quantum circuits: the repeat-until-success (RUS) algorithm and the weak-measurement-based version of Grover’s search algorithm. AutoQ 2.0 can efficiently verify all our benchmarks: all RUS algorithms were verified instantly and, for the weak-measurement-based version of Grover’s search, we were able to handle the case of 100 qubits in \sim20 minutes.","Quantum programs are an extension of quantum circuits that provide users with greater control over quantum computing by allowing them to use more complex programming constructs like branches and loops. Some of the most advanced quantum algorithms cannot be defined by quantum circuits alone. For example, certain class of programs, such as the repeat-until-success (RUS) algorithms [40] (which are commonly used in generating special quantum gates) and the weak-measurement-based version [7] of Grover’s search algorithm [30], use a loop with the condition being a classical value (0 or 1) obtained by measuring a particular qubit. This added expressivity presents new challenges, particularly in terms of verification. The additional complexity comes from the measurement operation, where a particular qubit is measured to obtain a classical value (and the quantum state is partially collapsed, which might require normalization), and reasoning about control flow induced by branches and loops. In classical program verification, a prominent role is played by deductive verification [29, 33, 31], represented, e.g., by the tools Dafny [36], KeY [5], Frama-C [9], VeriFast [35], VCC [22], and many more. These tools only require the users to provide specifications in the form of pre- and post-conditions, along with appropriate loop invariants. The rest of the proving process is entirely (in the ideal case) automated. Unfortunately, in the realm of quantum computing, similar fully automated deductive verification tools are, to the best of our knowledge, missing. Advanced tools for analysis and verification of quantum programs—based on, e.g., quantum Hoare logic and the tool CoqQ [49] or the path-sum formalism [6] and the tool Qbricks [15]—are quite powerful but require a significant amount of human effort. To bridge this gap, we present AutoQ 2.0, a major update over AutoQ 1.0 [19] with an added support for quantum programs (AutoQ 1.0 only supported quantum circuits). In AutoQ 1.0, given a triple \{P\}\,C\,\{Q\}, where P and Q are the pre- and post-conditions recognizing sets of (pure) quantum states (represented by tree automata) and C is a quantum circuit, we can verify if all quantum states in P reach some state in Q after executing C. In AutoQ 2.0, we addressed several key challenges to make the support of quantum programs possible. First, we need to handle branch statements. The key issue here is to handle measurement of quantum states whose value is used in a branch condition. For this we developed automata-based algorithms to compute the quantum states after the measurement (Section 5). The second challenge is the handling of loop statements. Similarly to deductive verification of classical programs, we require the users to provide an invariant for each loop. With the loop invariant provided, we developed a framework handling the rest of the verification process fully automatically. Moreover, we show that a naive implementation of the measurement operation will encounter the probability amplitude normalization problem. This is handled by designing a new algorithm for entailment testing (Section 6). Under this framework, the preconditions, postconditions, and invariants are all described using a new automata model called level-synchronized tree automata (LSTAs) [2]. LSTAs are specifically designed to efficiently encode quantum states and gate operations. As the core data structure of the tool, we provide a formal definition of LSTAs in Section 2.2 to facilitate the presentation of our new entailment testing approach. We used AutoQ 2.0 to verify various quantum programs using the repeat-until-success (RUS) paradigm [40], as well as the weak-measurement-based version [7] of Grover’s search [30] (Section 7). AutoQ 2.0 can efficiently verify all our benchmarks. The verification process for all RUS algorithms was instantaneous and for the weakly measured versions of Grover, we were able to handle the case of 100 qubits in \sim20 min. To the best of our knowledge, AutoQ 2.0 is currently the only tool for verification of quantum programs with such a degree of automation. Related work. Our work aligns with Hoare-style verification of quantum programs, a topic extensively explored in prior studies [50, 42, 47, 26, 38]. This approach, inspired by D’Hondt and Panangaden, utilizes diverse Hermitian operators as quantum predicates, resulting in a robust and comprehensive proof system [24]. However, specifying properties with Hermitian operators is often non-intuitive and difficult for automation due to their vast matrix sizes. Consequently, these methods are typically implemented using proof assistants like Coq [10], Isabelle [44], or standalone tools built on top of Coq, like CoqQ [49]. These tools require substantial manual effort in the proof search. The Qbricks approach [16] addresses the challenge of proof search by combining cutting-edge theorem provers with decision procedures, leveraging the Why3 platform [28]. Nevertheless, this approach still demands considerable human intervention. In the realm of automatic quantum software analysis tools, circuit equivalence checkers [6, 21, 32, 46, 22] prove to be efficient but less flexible in specifying desired properties, primarily focusing on equivalence. These tools are valuable in compiler validation, with notable examples being QCEC [14], Feynman [6], and SliQEC [18, 43]. Quantum model checking, supporting a rich specification language (various temporal logics [27, 39, 45]), is, due to its limited scalability, more suited for verifying high-level protocols [8]. QPMC [27] stands out as a notable tool in this category. Quantum abstract interpretation [48, 41] over-approximates the reachable state space to achieve better scalability, but so far handles only circuits. The work in [51, 25] aims at the verification of parameterized quantum programs like variational quantum eigensolver (VQE) or quantum approximate optimization algorithm (QAOA). However, the correctness properties they focused are very different from what AutoQ 2.0 can handle. While the mentioned tools are fully automated, they serve different purposes or address different phases of the development cycle compared to AutoQ 2.0."
https://arxiv.org/html/2411.07741v1,Vulnerabilities Analysis and Secure Controlling for Unmanned Aerial System Based on Reactive Synthesis,"Complex Cyber-Physical System (CPS) such as Unmanned Aerial System (UAS) got rapid development these years, but also became vulnerable to GPS spoofing, packets injection, buffer-overflow and other malicious attacks. Ensuring the behaviors of UAS always keeping secure no matter how the environment changes, would be a prospective direction for UAS security. This paper aims at introducing a pattern-based framework to describe the security properties of UAS, and presenting a reactive synthesis-based approach to implement the automatic generation of secure UAS controller. First, we study the operating mechanism of UAS and construct a high-level model consisting of actuator and monitor. Besides, we analyze the security threats of UAS from the perspective of hardware, software and cyber physics, and then summarize the corresponding specification patterns of security properties with LTL formulas. With the UAS model and security specification patterns, automatons for controller can be constructed by General Reactivity of Rank 1 (GR(1)) synthesis algorithm, which is a two-player game process between Unmanned Aerial Vehicle (UAV) and its environment. Finally, we expand the function of LTLMoP platform to implement the control simulation in multi-robot systems, providing secure behavior strategies under several attack scenarios.","With the rapid development of technologies, people will focus more on the CPS area in the future. Unmanned Aerial System, an Artificial Intelligence based complex CPS, which deeply integrates the technologies of environmental awareness, data analysis, authentication and heterogeneous networks, has already been widely used in different fields. According to the application scenario, UAS can usually be divided into three main categories: military drones, industrial drones, and commercial drones. Today, UAS plays an important role in the deployment of cooperative engagement, reconnaissance, remote sensing, aerial photography, agroforestry and Smart City service, because of the advantages of small-size, low-cost, high-speed, convenience and good flexibility, etc. Along with the increasing development, the security threats of UAS are also increasing. Even with the integration of advanced technologies, these CPSs are still prone to faults due to unpredicted state transitions and external interference. Attackers can implement the attacks through the hardware, software, or network of system, to compromise the confidentiality, integrity and availability, such as malicious injection, authentication bypass, GPS spoofing and DDoS attack, etc. For example, the unencrypted real-time video signal transmission of MQ-1 Predator resulted in a video feed interception by Iranian militants in 2009. A GPS spoofing attack was performed by Iranian forces on RQ-170, resulting in a successful capture on American UAV in 2011. The Ground Control Station (GCS) of Creech Air Force Base in Nevada has been infected by a computer virus named “keylogger” in 2011[11]. In recent years, major security conferences and competitions are devoted to the researches regarding attack-defense on products from commercial drone manufacturers such as Parrot and DJI, and various vulnerabilities are exposed. Yet, CPS security, especially UAS security is more severe than conventional security. Complex network architectures, flexible physical environment, and excessive access interfaces, may lead to more vulnerabilities and attack interfaces when manufacturers try to improve the quality of drones. Attackers can exploit the vulnerabilities to cause the sensitive data leaked, the system hijacked and even the drones crashed instantly. Reactive synthesis is a methodology about synthesizing a correct-by-construc-tion reactive system automatically, from given formal specifications. The obtained system is usually represented in the form of automaton satisfying the specifications. The input of the automaton can be viewed as the environmental virables from sensors of robots, and the output is the actions performed by the actuators. The synthesis algorithm introduced in this paper is based on the GR(1) game[2]. In this paper, we design a patterns-based framework to describe the security properties of UAS, expand the work in[10] and introduce a novel approach implementing the automatic generation of the secure controller for UAS with GR(1) reactive synthesis. The contributions can be summarized as follows: 1) we study the operating mechanism of UAS and abstract a high-level model of UAS with two components actuator and monitor; 2) we study the vulnerabilities and security properties of UAS, so as to extract the security specification patterns according to our requirements. The model and specifications are described in Linear Temporal Logic (LTL)[5]; 3) we implement the automatic generation of the secure controller for UAS with the GR(1) game-based reactive synthesis algorithm applied in multi-robot systems; 4) we expand the function of LTLMoP platform and construct the secure controller providing UAS the secure behavior strategies under several typical attack scenarios such as GPS spoofing attack, risk commands attack and DDoS attack, etc."
https://arxiv.org/html/2411.07275v1,The Equivalence Problem of E-Pattern Languages with Regular Constraints is Undecidable,"Patterns are words with terminals and variables. The language of a pattern is the set of words obtained by uniformly substituting all variables with words that contain only terminals. Regular constraints restrict valid substitutions of variables by associating with each variable a regular language representable by, e.g., finite automata. Pattern languages with regular constraints contain only words in which each variable is substituted according to a set of regular constraints. We consider the membership, inclusion, and equivalence problems for erasing and non-erasing pattern languages with regular constraints. Our main result shows that the erasing equivalence problem—one of the most prominent open problems in the realm of patterns—becomes undecidable if regular constraints are allowed in addition to variable equality.","A pattern is a finite word consisting of symbols from a finite set of letters \Sigma=\{a_{1},...,a_{\sigma}\}, also called terminals, and from an infinite set of variables X=\{x_{1},x_{2},...\} with \Sigma\cap X=\emptyset. It is a natural and compact device to define formal languages. Words consisting of only terminal symbols are obtained from patterns by a substitution h, a terminal preserving morphism which maps all variables from a pattern to words over the terminal alphabet. The language of a pattern consists of all words obtainable from that pattern by substitutions. We differentiate between two kinds of substitutions. Originally, pattern languages introduced by Angluin [1] only consisted of words obtained by non-erasing substitutions that required all variables to be mapped to non-empty words. Thus, those languages are also called NE-pattern languages. Later, so called erasing-/extended- or just E-pattern languages have been introduced by Shinohara [24]. In these, substitutions are also allowed to map variables to the empty word. Consider, for example, the pattern \alpha:=x_{1}\mathtt{a}\mathtt{b}x_{2}x_{2}. Then, by mapping x_{1} to \mathtt{a}\mathtt{a}\mathtt{a} and x_{2} to \mathtt{b}\mathtt{a} with a substitution h, we obtain the word h(\alpha)=\mathtt{a}\mathtt{a}\mathtt{a}\mathtt{a}\mathtt{b}\mathtt{b}\mathtt{% a}\mathtt{b}\mathtt{a}. If we consider the E-pattern language of \alpha, we could also map x_{2} to the empty word \varepsilon with a substitution h^{\prime} which also maps x_{1} to \mathtt{a}\mathtt{a}\mathtt{a} and obtain h^{\prime}(\alpha)=\mathtt{a}\mathtt{a}\mathtt{a}\mathtt{a}\mathtt{b}. Due to its practical and simple definition, patterns and their corresponding languages occur in numerous areas regarding computer science and discrete mathematics, including unavoidable patterns [14, 17], algorithmic learning theory [1, 5, 25], word equations [17], theory of extended regular expressions with back references [9], and database theory [7, 23]. The main problems regarding patterns and pattern languages are the membership problem (and its variations [10, 11, 6]), the inclusion problem, and the equivalence problem in both the erasing (E) and non-erasing (NE) cases. The membership problem determines if a word belongs to a pattern’s language. This problem is NP-complete for both E- and NE-pattern languages [1, 14]. The inclusion problem asks if one pattern’s language is included in another’s. Jiang et al. [15] showed that it is generally undecidable for E- and NE-pattern languages. Freydenberger and Reidenbach [8], and Bremer and Freydenberger [2] proved its undecidability for all alphabets with size \geq 2 in both E- and NE-pattern languages. The equivalence problem tests if two patterns generate the same language. It is trivially decidable for NE-pattern languages [1]. Whether its decidable for E-pattern languages is one of the major open problems in the field [15, 21, 20, 19, 22]. However, for terminal-free patterns, the inclusion and equivalence problems in E-pattern languages have been characterized and shown to be NP-complete [15, 4]. The decidability of the inclusion problem for terminal-free NE-pattern languages remains unresolved, though. Various extensions to patterns and pattern languages have been introduced over time. Some examples are the bounded scope coincidence degree, patterns with bounded treewidth, k-local patterns, and strongly-nested patterns (see [3] and references therein). Koshiba [16] introduced so called typed patterns to enhance the expressiveness of pattern languages by restricting substitutions of variables to types, i.e., arbitrary recursive languages. This has recently been extended by Geilke and Zilles [12] who introduced the notion of relational patterns and relational pattern languages. We consider a specific class of typed- or relational patterns called patterns with regular constraints. Let \mathcal{L}_{Reg} be the set of all regular languages. Then, we say that a mapping r:X\rightarrow\mathcal{L}_{Reg} is a regular constraint that implicitly defines languages on variables x\in X by L_{r}(x)=r(x). Let \mathcal{C}_{Reg} be the set of all regular constraints. A patterns with regular constraints (\alpha,r_{\alpha})\in(\Sigma\cup X)^{*}\times\mathcal{C}_{Reg} is a pattern which is associated with a regular constraint. A substitution h is r_{\alpha}-valid if all variables are substituted according to r_{\alpha}. The language of (\alpha,r_{\alpha}) is defined analogously to pattern languages with the additional requirement that all substitutions must be r_{\alpha}-valid. This paper examines erasing (E) and non-erasing (NE) pattern languages with regular constraints. The membership problem for both is NP-complete, while the inclusion problem is undecidable for the general and terminal-free versions. This immediately follows from known results. The main finding of this paper is that the equivalence problem for erasing pattern languages with regular constraints is indeed undecidable."
https://arxiv.org/html/2411.08003v1,Can adversarial attacks by large language models be attributed?,"Attributing outputs from Large Language Models (LLMs) in adversarial settings—such as cyberattacks and disinformation—presents significant challenges that are likely to grow in importance. We investigate this attribution problem using formal language theory, specifically language identification in the limit as introduced by Gold and extended by Angluin. By modeling LLM outputs as formal languages, we analyze whether finite text samples can uniquely pinpoint the originating model. Our results show that due to the non-identifiability of certain language classes, under some mild assumptions about overlapping outputs from fine-tuned models it is theoretically impossible to attribute outputs to specific LLMs with certainty. This holds also when accounting for expressivity limitations of Transformer architectures. Even with direct model access or comprehensive monitoring, significant computational hurdles impede attribution efforts. These findings highlight an urgent need for proactive measures to mitigate risks posed by adversarial LLM use as their influence continues to expand.","References [1] Dana Angluin. Inductive inference of formal languages from positive data. Information and Control, 45(2):117–135, 1980. [2] Umar Anwar, Aziz Saparov, Julia Rando, Daniel Paleka, Michael Turpin, Pete Hase, et al. Foundational challenges in assuring alignment and safety of large language models. arXiv preprint arXiv:2404.09932, 2024. [3] Robert Axelrod and Radoslav Iliev. Timing of cyber conflict. Proceedings of the National Academy of Sciences, 111(4):1298–1303, 2014. [4] Satwik Bhattamishra, Arkil Patel, and Navin Goyal. On the computational power of transformers and its implications in sequence modeling. arXiv preprint arXiv:2006.09286, 2020. [5] Alexander Bick, Adam Blandin, and David J. Deming. The rapid adoption of generative ai. Working Paper w32966, National Bureau of Economic Research, Cambridge, MA, September 2024. [6] Rishi Bommasani, Dilara Soylu, Thomas I. Liao, Kathleen A. Creel, and Percy Liang. Ecosystem graphs: The social footprint of foundation models. March 2023. [7] Manuel Cebrian. A time-critical crowdsourced computational search for the origins of covid-19. Nature Electronics, 4(7):450–451, 2021. [8] Nicholas A Christakis and James H Fowler. Connected: The surprising power of our social networks and how they shape our lives. Little, Brown Spark, 2009. [9] Brian Edwards, Allen Furnas, Steve Forrest, and Robert Axelrod. Strategic aspects of cyberattack, attribution, and blame. Proceedings of the National Academy of Sciences, 114(11):2825–2830, 2017. [10] E.M. Gold. Language identification in the limit. Information and Control, 10(5):447–474, 1967. [11] Kent Johnson. Gold’s theorem and cognitive science. Philosophy of Science, 71(4):571–592, 2004. [12] Jon Kleinberg and Sendhil Mullainathan. Language generation in the limit. arXiv preprint arXiv:2404.06757, 2024. [13] William Merrill, Vivek Ramanujan, Yoav Goldberg, Roy Schwartz, and Noah Smith. Effects of parameter norm growth during transformer training: Inductive bias from gradient descent. arXiv preprint arXiv:2010.09697, 2020. [14] Mark Ed Newman, Albert-László Ed Barabási, and Duncan J Watts. The structure and dynamics of networks. Princeton university press, 2006. [15] Oak Ridge Leadership Computing Facility. Frontier supercomputer. [16] Bin Peng, Srikumar Narayanan, and Christos Papadimitriou. On limitations of the transformer architecture. arXiv preprint arXiv:2309.06863, 2023. [17] Nicole Perlroth. This is how they tell me the world ends: The cyberweapons arms race. Bloomsbury publishing, 2021. [18] Iyad Rahwan, Manuel Cebrian, Nicholas Obradovich, Josh Bongard, Jean-François Bonnefon, Cynthia Breazeal, Joshua W Crandall, Nicholas A Christakis, Iain D Couzin, Michael O Jackson, et al. Machine behaviour. Nature, 568(7753):477–486, 2019. [19] Yuval Shavit, Shuchi Agarwal, Miles Brundage, Saurabh Adler, Courtney O’Keefe, Riley Campbell, and David G Robinson. Practices for governing agentic ai systems. Research Paper, OpenAI, December 2023, 2023. [20] Lutz Strobl, William Merrill, Gregory Weiss, Daniel Chiang, and Dana Angluin. What formal languages can transformers express? a survey. Transactions of the Association for Computational Linguistics, 12:543–561, 2024. [21] Fabio Urbina, Filippa Lentzos, Cédric Invernizzi, and Sean Ekins. Dual use of artificial-intelligence-powered drug discovery. Nature Machine Intelligence, 4(3):189–191, 2022. [22] Marcin Waniek, Petter Holme, Manuel Cebrian, and Talal Rahwan. Social diffusion sources can escape detection. Iscience, 25(9):104956, 2022. [23] Marcin Waniek, Petter Holme, Katayoun Farrahi, Rémi Emonet, Manuel Cebrian, and Talal Rahwan. Trading contact tracing efficiency for finding patient zero. Scientific reports, 12(1):22582, 2022. [24] Jiajia Xu, Alice Smith, Liam Johnson, and Kevin Lee. Autoattacker: A large language model guided system to implement automatic cyber-attacks. arXiv preprint arXiv:2403.01038, 2024."
https://arxiv.org/html/2411.06904v1,The Equivalence Problem of E-Pattern Languages with Length Constraints is Undecidable,"Patterns are words with terminals and variables. The language of a pattern is the set of words obtained by uniformly substituting all variables with words that contain only terminals. Length constraints restrict valid substitutions of variables by associating the variables of a pattern with a system (or disjunction of systems) of linear diophantine inequalities. Pattern languages with length constraints contain only words in which all variables are substituted to words with lengths that fulfill such a given set of length constraints. We consider membership, inclusion, and equivalence problems for erasing and non-erasing pattern languages with length constraints. Our main result shows that the erasing equivalence problem, one of the most prominent open problems in the realm of patterns-becomes undecidable if length constraints are allowed in addition to variable equality. Additionally, it is shown that the terminal-free inclusion problem-another prominent open problem in the realm of patterns-is also undecidable in this setting.It is also shown that considering regular constraints, i.e., associating variables also with regular languages as additional restrictions together with length constraints for valid substitutions, results in undecidability of the non-erasing equivalence problem. This sets a first upper bound on constraints to obtain undecidability in this case, as this problem is trivially decidable in the case of no constraints and as it has unknown decidability if only regular- or only length-constraints are considered.","A pattern is a finite word consisting only of symbols from a finite set of letters \Sigma=\{\mathtt{a}_{1},...,\mathtt{a}_{\sigma}\}, also called terminals, and from an infinite set of variables X=\{x_{1},x_{2},...\} such that we have \Sigma\cap X=\emptyset. It is a natural and compact device to define formal languages. From patterns, we obtain words consisting only of terminals using a substitution h, a terminal preserving morphism that maps all variables in a pattern to words over the terminal alphabet. The language of a pattern is the set of all words obtainable from that pattern using arbitrary substitutions. We differentiate between two kinds of substitutions. In the original definition of patterns and pattern languages introduced by Angluin [1], only words obtained by non-erasing substitutions are considered. Here, all variables are required to be mapped to non-empty words. The resulting languages are called non-erasing (NE) pattern languages. Later, so called erasing-/extended- or just E-pattern languages have been introduced by Shinohara [27]. Here, variables may also be substituted by the empty word \varepsilon. Consider, for example, the pattern \alpha:=x_{1}\mathtt{a}x_{2}\mathtt{b}x_{1}. Then, if we map x_{1} to \mathtt{a}\mathtt{b} and x_{2} to \mathtt{b}\mathtt{b}\mathtt{a}\mathtt{a} using a substitution h, we obtain the word h(\alpha)=\mathtt{a}\mathtt{b}\mathtt{a}\mathtt{b}\mathtt{b}\mathtt{a}\mathtt{% a}\mathtt{b}\mathtt{a}\mathtt{b}. Considering the E-pattern language of \alpha, we could also map x_{1} to the empty word and obtain any word in the language \{\mathtt{a}\}\cdot\Sigma^{*}\cdot\{\mathtt{b}\}. Due to its practical and simple definition, patterns and their corresponding languages occur in numerous areas in computer science and discrete mathematics. These include, for example, unavoidable patterns [14, 18], algorithmic learning theory [1, 5, 28], word equations [18], theory of extended regular expressions with back references [9], or database theory [7, 26]. There are three main decision problems regarding patterns and pattern languages. Those are the membership problem (and its variations [10, 11, 6]), the inclusion problem, and the equivalence problem. All are considered in the erasing (E) and non-erasing (NE). The membership problem determines if a word belongs to the language of a pattern. This problem has been shown to be NP-complete for both, erasing- and non-erasing, pattern languages [1, 14]. The inclusion problem determines whether the language of one pattern is a subset of the language of another pattern. It has been shown to be generally undecidable by Jiang et al. in [15]. Freydenberger and Reidenbach [8] as well as Bremer and Freydenberger [2] improved that result and showed that it is undecidable for all bounded alphabets of size |\Sigma|\geq 2 for both erasing and non-erasing pattern languages. The equivalence problem asks whether the languages of two patterns are equal. For NE-pattern languages, this problem is trivially decidable and characterized by the equality of patterns up to a renaming of their variables [1]. The decidability of the erasing case is one of the major open problems in the field [15, 23, 22, 21, 24]. For terminal-free patterns, however, i.e., patterns without any terminal letters, the inclusion problem as well as the equivalence problem for E-pattern languages have been characterized and shown to be NP-complete [15, 4]. What remains unresolved, though, is the decidability of the inclusion problem of terminal-free NE-pattern languages. Over time, various extensions to patterns and pattern languages have been introduced, either, to obtain additional expressibility due to some practical context or to get closer to an answer for the remaining open problems. Some examples are the bounded scope coincidence degree, patterns with bounded treewidth, k-local patterns, or strongly-nested patterns (see [3] and references therein). Koshiba [16] introduced so called typed patterns that restrict substitutions of variables to types, i.e., arbitrary recursive languages. Geilke and Zilles [12] extended this recently to the notion of relational patterns and relational pattern languages. In [20], a special form of typed patterns has been considered, i.e., patterns with regular constraints. Here, variables may be restricted by arbitrary regular languages and the same variable may occur more than once. It has been shown that this notion suffices to obtain undecidability for both main open problems regarding pattern languages, i.e., the equivalence of E-pattern languages and the inclusion of terminal-free NE-pattern languages. Another natural extension other than regular constraints is the notion of length constraints. Here, instead of restricting the choice of words for the substitution of variables, length constraints just restrict the lengths of substitution of variables in relation to each other. In the field of word equations, length constraints have been considered as a natural extension for a long time and, e.g., answering the decidability of the question whether word equations with length constraints have a solution, is a long outstanding problem (see, e.g., [17] and the references therein). In this paper, we consider that natural extension on patterns, resulting in the class of patterns called patterns with length constraints. In general, we say that a length constraint \ell is a disjunction of systems of linear (diophantine) inequalities over the variables of X. We denote the set of all length constraints by \mathcal{C}_{Len}. A pattern with length constraints (\alpha,\ell_{\alpha})\in(\Sigma\cup X)^{*}\times\mathcal{C}_{Len} is a pattern associated with a length constraint. We say that a substitution h is \ell_{\alpha}-valid if all variables are substituted according to \ell_{\alpha}. Now, the language of (\alpha,\ell_{\alpha}) is defined analogously to pattern languages but restricted to \ell_{\alpha}-valid substitutions in the erasing- and non-erasing cases. We examine erasing (E) and non-erasing (NE) pattern languages with length constraints. It can be shown that the membership problem for both cases in NP-complete. The inclusion problem is shown to be undecidable in both cases, too, notably even for terminal-free patterns, which is a difference to the decidability of the inclusion problem in the erasing case for patterns without any constraints, and which is an answer to a problem which is still open for non-erasing patterns without constraints. The main result of this paper is the undecidability of the equivalence problem for erasing pattern languages with length constraints in both cases, terminal-free and general, giving an answer to a problem of which the decidability has been an open problem for a long time in the case of no constraints. The final result shows that regular constraints and length constraints combined suffice to show undecidability of the equivalence problem for non-erasing pattern languages, a problem that is trivially decidable in case of no constraints and still open in the cases of just regular- or just length-constraints."
https://arxiv.org/html/2411.06358v1,"Topoi of automata I:
Four topoi of automata and regular languages","Both topos theory and automata theory are known for their multi-faceted nature and relationship with topology, algebra, logic, and category theory. This paper aims to clarify the topos-theoretic aspects of automata theory, particularly demonstrating through two main theorems how regular (and non-regular) languages arise in topos-theoretic calculation. First, it is shown that the four different notions of automata form four types of Grothendieck topoi, illustrating how the technical details of automata theory are described by topos theory. Second, we observe that the four characterizations of regular languages (DFA, Myhill-Nerode theorem, finite monoids, profinite words) provide Morita-equivalent definitions of a single Boolean-ringed topos, situating this within the context of Olivia Caramello’s ‘Toposes as Bridges.’This paper also serves as a preparation for follow-up papers, which deal with the relationship between hyperconnected geometric morphisms and algebraic/geometric aspects of formal language theory.","This series of papers aims to propose a topos-theoretic framework for automata theory with the following future goals: • to unify aspects of automata theory in terms of topoi, and • to introduce geometric methods into automata theory. The connection between category theory and automata theory is a richly historic area. There are a vast number of studies on the connection between category theory and automata theory, including [adamek1974free, jacobs2017introduction, rutten2019method, colcombet2020automata, goy2022powerset], and also connections between topos theory and automata theory [lawvere2004functorial, uramoto2017semi, goy2022powerset, iwaniack2024automata]. As far as the author knows, the novelty of this paper is to consider the topoi (consisting) of automata (not automata in topoi or topoi constructed from automata-theoretic gadgets.) Our starting point is the following fact: the category of automata (defined as a coalgebra Q\to Q^{\Sigma}\times\{\top,\bot\}) is a presheaf topos (over the category of languages). (see corollary 2.13). In this series of papers, we will provide various “Grothendieck topoi of automata”, which can be regarded as variants of this topos. Some of them are presheaf topoi, but some are not. The structure of this first paper is as follows: section 2: Introducing four topoi of automata. section 3: Proving that four characterizations of regular languages provide four descriptions of a single boolean-ringed topos ({\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}},\mathcal{R}). 1. Introducing four topoi of automata. In section 2, introducing and calculating four topoi of automata, we will see some automata-theoretic topics naturally arise in our approach of ‘topoi of automata.’ Those include language recognition, coalgebraic treatment, automata minimalization, the quotient of language, and regular languages. (See table 1 table 2, and table 3, though some rows in the tables will be treated in the follow-up papers). topos theory automata theory sheaf in \Sigma\text{-}\mathbf{Set} \leftrightsquigarrow word action point of \Sigma\text{-}\mathbf{Set} \leftrightsquigarrow infinite word The canonical point p of \Sigma\text{-}\mathbf{Set} \leftrightsquigarrow Run of Moore machine The internal Boolean algebra p_{\ast}\{\top,\bot\} \leftrightsquigarrow Boolean algebra of languages Path action on p_{\ast}\{\top,\bot\} \leftrightsquigarrow Quotient of language Morphism to p_{\ast}\{\top,\bot\} \leftrightsquigarrow automaton = 2x^{\Sigma}-coalgebra Image of the Yoneda map \textrm{\!\maljapanese\char 72\relax}(\ast)\to\mathcal{L} \leftrightsquigarrow minimal automata hyperconnected quotient \Sigma\text{-}\mathbf{Set}\to{\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}} \leftrightsquigarrow Regular languages Generated hyperconnected quotient \leftrightsquigarrow Syntactic monoid Table 1. Some correspondence on \Sigma\text{-}\mathbf{Set} topos theory automata theory sheaf in \mathbf{Atmt} \leftrightsquigarrow automaton = 2x^{\Sigma}-coalgebra Structure map of an étale space \leftrightsquigarrow language recognition = coinduction étale covering \mathbf{Atmt}\twoheadrightarrow\Sigma\text{-}\mathbf{Set} \leftrightsquigarrow Forgetting the accept states essential point of \mathbf{Atmt} \leftrightsquigarrow a language Open subtopos of \mathbf{Atmt} \leftrightsquigarrow a quotient-stable language class Table 2. Some correspondence on \mathbf{Atmt} the canonical Boolean algebra \leftrightsquigarrow Boolean algebra of regular languages The ringed site (\Sigma\text{-}\mathbf{FinSet},J),\mathrm{DFA} \leftrightsquigarrow recognition by DFA The ringed site (\Sigma\text{-}\mathbf{FinMon},J),\mathcal{P} \leftrightsquigarrow recognition by finite monoids The topological monoid action {\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}}\simeq\mathbf{Cont}(\widehat{{{% \Sigma}^{\ast}}}) \leftrightsquigarrow profinite words description Table 3. Some correspondence on {\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}} 2. Proving that four characterizations of regular languages provide four descriptions of a single boolean-ringed topos ({\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}},\mathcal{R}). In section 3, we will deal with regular languages. Regular languages are a class of languages defined by certain finiteness properties and are known to have many characterizations (see fig. 1): • They are accepted by finite automata. • They are recognized by finite monoids. • They are (pullbacks of) clopen sets of profinite words. • Their corresponding Nerode congruence has only finitely many equivalence classes. DFAfinite monoidsMyhill-Nerodeprofinite wordsThe ringed topos ({\Sigma\text{-}\mathbf{Set}}_{\mathrm{o.f.}},\mathcal{R})ringed site (\Sigma\text{-}\mathbf{FinSet},\mathrm{DFA})ringed site (\Sigma\text{-}\mathbf{FinMon},\mathcal{P})hyperconnected geometric morphism\mathbf{Cont}\left(\widehat{{{\Sigma}^{\ast}}}\right) Figure 1. Four characterizations of regular languages are Morita equivalent. We show that these data are Morita equivalent, in the sense that we construct (a priori four) Boolean-ringed topoi from these four data and prove that they are equivalent. The author regards this as an example of Olivia Caramello’s slogan of ‘toposes as bridges’ (see [caramello2023unification]), at least in a broader sense. This unified perspective demonstrates that the diverse views on regular languages can be interpreted as a single multifaceted topos. On the follow-up papers The contents of the follow-up papers include how points of the topoi categorify infinite words and how the complete lattice of hyperconnected quotients generalizes classes of languages and corresponding syntactic monoids. Acknowledgement The author would like to thank his supervisor, Ryu Hasegawa, for his continuous and helpful advice. I would like to thank Takeo Uramoto for his advice and for suggesting a connection with the variety theorem, Yuhi Kamio for his enlightening explanation of algebraic language theory, Morgan Rogers for the discussion on automata as topological monoid actions, Victor Iwaniack for topos theoretic automata theory, and Ryoma Sin’ya for his fascinating introduction to the field of automata. I would like to extend my gratitude to Keisuke Hoshino, Takao Yuyama, Yusuke Inoue, Isao Ishikawa, Yuzuki Haga, David Jaz Myers, Ivan Tomasic, Igor Bakovic, and Joshua Wrigley for their helpful and encouraging discussions. This research is supported by FoPM, WINGS Program, the University of Tokyo. Notation 1.1. In this note, we will fix a finite set of alphabet \Sigma. Let {{\Sigma}^{\ast}} denote the set of all words, i.e., the free monoid over the set \Sigma."
https://arxiv.org/html/2411.06383v2,Program Analysis via Multiple Context Free Language Reachability,"Context-free language (CFL) reachability is a standard approach in static analyses, where the analysis question (e.g., is there a dataflow from x to y?) is phrased as a language reachability problem on a graph G wrt a CFL \mathcal{L}. However, CFLs lack the expressiveness needed for high analysis precision. On the other hand, common formalisms for context-sensitive languages are too expressive, in the sense that the corresponding reachability problem becomes undecidable. Are there useful context-sensitive language-reachability models for static analysis?In this paper, we introduce Multiple Context-Free Language (MCFL) reachability as an expressive yet tractable model for static program analysis. MCFLs form an infinite hierarchy of mildly context sensitive languages parameterized by a dimension d and a rank r. Larger d and r yield progressively more expressive MCFLs, offering tunable analysis precision. We showcase the utility of MCFL reachability by developing a family of MCFLs that approximate interleaved Dyck reachability, a common but undecidable static analysis problem.Given the increased expressiveness of MCFLs, one natural question pertains to their algorithmic complexity, i.e., how fast can MCFL reachability be computed? We show that the problem takes O(n^{2d+1}) time on a graph of n nodes when r=1, and O(n^{d(r+1)}) time when r>1. Moreover, we show that when r=1, even the simpler membership problem has a lower bound of n^{2d} based on the Strong Exponential Time Hypothesis, while reachability for d=1 has a lower bound of n^{3} based on the combinatorial Boolean Matrix Multiplication Hypothesis. Thus, for r=1, our algorithm is optimal within a factor n for all levels of the hierarchy based on the dimension d (and fully optimal for d=1).We implement our MCFL reachability algorithm and evaluate it by underapproximating interleaved Dyck reachability for a standard taint analysis for Android. When combined with existing overapproximate methods, MCFL reachability discovers all tainted information on 8 out of 11 benchmarks, while it has remarkable coverage (confirming 94.3\% of the reachable pairs reported by the overapproximation) on the remaining 3. To our knowledge, this is the first report of high and provable coverage for this challenging benchmark set.","Static analysis via language reachability. Static analyses are a standard approach to determining program correctness, as well as other useful properties of programs. They normally operate by establishing an approximate model for the program, effectively reducing questions about program behavior to algorithmic questions about the model. One popular type of modeling in this direction is language reachability, where the program abstraction is via an edge-labeled graph G (Reps, 1997; Reps et al., 1995). Language reachability is a generalization of standard graph reachability, parameterized by a language \mathcal{L}. Intuitively, given two nodes u, v, the problem asks to determine whether v is reachable from u via a path whose sequence of labels produce a string that belongs to \mathcal{L}. Such a path captures program executions that relate the objects represented by v and u (e.g., control-flow between two program locations or data-flow between two variables). The role of \mathcal{L} is normally to increase the analysis precision by filtering out paths that represent spurious program executions, owing to the approximate nature of G. Context-free language reachability. Language-reachability based static analyses are most frequently phrased with respect to context free languages (CFL), known as CFL reachability, which have various uses. For example, they are used to increase the precision of interprocedural analyses (aka whole-program analyses), where modeled executions cross function boundaries, and the analysis has to be calling-context sensitive111It might sound paradoxical that a context-free language makes the analysis context-sensitive, but this is just a naming coincidence. “Context sensitivity” refers to calling contexts, and the CFL simulates the call stack.. A CFL \mathcal{L} captures that a path following an invocation from a caller function \mathtt{foo}() to a callee \mathtt{tie}() must return to the call site of \mathtt{foo}() when \mathtt{tie}() returns (as opposed to some other function \mathsf{bar}() that also calls \mathtt{tie}()). This approach is followed in a wide range of interprocedural static analyses, including data-flow and shape analysis (Reps et al., 1995), type-based flow analysis (Rehof and Fähndrich, 2001) and taint analysis (Huang et al., 2015), to name a few. In practice, widely-used tools, such as Wala (Wal, 2003) and Soot (Bodden, 2012), equip CFL-reachability techniques to perform the analysis. Another common use of CFLs is to track dataflow information between composite objects in a field-sensitive manner. Here, a CFL \mathcal{L} captures a dataflow between variables x and y if, for example x flows into z.f (i.e., field f of composite object z), and z.f itself flows into y (as opposed to z.g flowing into y). This approach is standard in a plethora of pointer, alias and data dependence analyses (Lhoták and Hendren, 2006; Reps, 1997; Chatterjee et al., 2018; Sridharan et al., 2005; Sridharan and Bodík, 2006; Lu and Xue, 2019). The need for context-sensitive models. Although CFLs offer increased analysis precision over simpler, regular abstractions, there is often a need for more precise, context sensitive models. For example, almost all analyses are designed with both context and field sensitivity, as this leads to obvious precision improvements (Milanova, 2020; Lhoták and Hendren, 2006; Sridharan and Bodík, 2006; Späth et al., 2019). The underlying language modeling both sensitivities is the free interleaving of the two corresponding CFLs, which is not a CFL, and is commonly phrased as interleaved Dyck reachability. Unfortunately, interleaved Dyck reachability is well-known to be undecidable (Reps, 2000). Since it is desirable to maintain at least some precision of each type, there have been various approximations that generally fall into two categories: (i) apply some kind of k-limiting, which approximates one of the CFLs by a regular (or even finite) language (the most common approach), or (ii) solve for each type of sensitivity independently (Späth et al., 2019), possibly in a refinement loop (Ding and Zhang, 2023; Conrado and Pavlogiannis, 2024). Observe that both cases essentially fall back to context-free models, forgoing the desirable precision of context sensitivity for which the analysis was designed in the first place. This leads to a natural question: Are there natural, efficient (polynomial-time), and practically precise, context-sensitive approximations for interleaved Dyck reachability? Multiple Context Free Languages. One of the most natural generalizations of CFLs towards mild context sensitivity is that of Multiple Context Free Languages (MCFLs) (Seki et al., 1991). These languages are generated by the corresponding Multiple Context Free Grammars (MCFGs), which form a hierarchy of expressiveness parameterized by a dimension d and rank r (concisely denoted as d\text{-}\operatorname{MCFG}(r)). Intuitively, an MCFG in d dimensions performs simultaneous context-free parsing on d substrings of a word, and can thus capture bounded context-sensitivity between these substrings. The rank r limits the number of non-terminals that can appear in a single production rule. MCFGs have received considerable attention, as they are regarded as a realistic formalism for natural languages (Clark, 2014), while several popular classes of formal languages fall into specific levels in this hierarchy, e.g., CFLs are MCFLs of dimension 1, and Tree Adjoining Languages (TALs) (Joshi, 1987) and Head Languages (Pollard, 1984) fall in dimension 2 (Seki et al., 1991). Despite the context sensitivity, for each r\geq 2, d\text{-}\operatorname{MCFL}(r) forms a full abstract family of languages (AFL – closed under homomorphism, inverse homomorphism, intersection with regular sets, union, and Kleene closure) (Rambow and Satta, 1999), with decidable membership and emptiness (Vijay-Shanker et al., 1987). As such, they form an elegant class of mildly context sensitive languages that are amenable to algorithmic treatment. In a static analysis setting, language reachability with MCFLs has the potential to yield higher modeling power. Moreover, this power is utilized in a controllable way, owing to the higher expressivity along the MCFL hierarchy. However, neither (i) the modeling power of MCFL reachability (what can MCFLs express in a program analysis setting?) nor (ii) the algorithmic question (how fast can we solve MCFL reachability?) have been studied. This paper addresses these questions, by (1) designing a family of MCFLs for approximating the common static analysis problem of interleaved Dyck reachability, with remarkable coverage in practice, and (2) developing a generic algorithm for MCFL reachability (for any dimension d and rank r), as well as proving fine-grained complexity lower bounds for the problem. The following motivating example illustrates the problem setting and our approach. 1.1. Motivating Example In a standard dataflow analysis setting, the task is to identify pairs of variables x, y such that the value of x may affect the value of y. This is achieved by following def-use chains in the program P. The program model is a dataflow graph G, where nodes represent variables, and an edge x\to y results from an instruction of the form x=f(y) (for some uninterpreted function f). To address the common issue of high false positives, the analysis must be both context-sensitive and field-sensitive. For example, consider the program P in Fig. 1, and the dataflow graph G in Fig. 2(a). {mdframed} [backgroundcolor=black!7!white,rightline=false,leftline=false,linewidth=0.25mm,] ⬇ 1pair tie(int x,int y){ 2 pair p; 3 p.first = x; 4 p.second = y; 5 return p; 6} ⬇ 1void foo() { 2 int a = 2; 3 int b = 3; 4 pair q = tie(a,b); 5 int c = q.first; 6 return; 7} ⬇ 6void bar() { 7 int d = 5; 8 pair r = tie(d,7); 9 int e = r.second; 10 return; 11} Figure 1. A program P containing three functions tie(), foo(), bar() and composite objects of type pair. adbxyp\text{tie}_{\text{ret}}qrce{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{10}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{16}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{10}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{% 1}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{% 2}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706})_{10}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706})_{16}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 1}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 2}} (a) A graph G modeling context-sensitive and field-sensitive data flow in program P from Fig. 1. efghijk{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{% 1}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{100}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 1}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{% 1}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 1}}{\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706})_{100}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 1}} (b) A subgraph of the uranai benchmark in a taint analysis for Android. Figure 2. Two graphs modeling context and field sensitivity through edge labels. Context sensitivity. Let us momentarily ignore edge labels in G. We have a path b\rightsquigarrow e, signifying a dataflow from b to e. This, however, does not correspond to a valid program execution: the path goes through the call of function tie() from foo() (where b is declared), but when tie() returns, the execution continues on foo, rather than bar() where e is declared. Call-context sensitivity is achieved by modeling call sites using parenthesis labels, and only considering reachability as witnessed by paths that produce a properly balanced parenthesis string. Formally we require that the label of the path forms a string that belongs to the Dyck language over parentheses (which is a CFL). Now, the path b\rightsquigarrow e is invalid, since {\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{10}} (along the edge b\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% (_{10}}}y) does not match {\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706})_{16}} (along the edge \text{tie}_{\text{ret}}\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{16}}}r), thus the analysis avoids reporting this false positive. Field sensitivity. With parentheses modeling call-context sensitivity, consider the path d\rightsquigarrow e. The parenthesis string along this path is {\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{16}}{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{16}}, which is balanced, representing the fact that call contexts are respected. However, in P there is no dataflow from d to e, this time due to unmatched fields: x is assigned to \mathit{p.first}, and although there is a dataflow from p to r, e gets assigned \mathit{r.second}. Field-sensitivity is achieved by modeling object fields using (square) bracket labels, and only considering reachability as witnessed by paths that produce a properly balanced bracket string. Formally we require that the label of the path forms a string that belongs to the Dyck language over brackets. Now, the path d\rightsquigarrow e is invalid, since {\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{% 1}} (along the edge x\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}[_{1}}}p) does not match {\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 2}} (along the edge r\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}]_{2}}}e), thus the analysis avoids reporting this false positive. Context and field sensitivity, simultaneously. To capture both context and field sensitivity, the analysis must decide reachability via paths that are well-balanced wrt both parentheses and brackets. However, these two types of symbols can be interleaved in an arbitrary way. For example, out of all 6 possible source-sink pairs \{a,d,b\}\times\{c,e\}, the only real dataflow is from a to c, witnessed by a path producing the string {\color[rgb]{0.2549019607843137,0.2117647058823529,0.9823529411764706}% \definecolor[named]{pgfstrokecolor}{rgb}{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}(_{10}}{\color[rgb]{% 0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{0.24,0.24,0.24}% \pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{1}}{\color[rgb]% {0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{10}}{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{rgb}{% 0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}]_{% 1}}. As the corresponding reachability problem is undecidable (Reps, 2000), existing techniques focus on overapproximating interleaved Dyck reachability, mostly by some context-free model. This implies that these analysis results may still contain false positives in terms of reachability in the dataflow graph. Illustration on a real benchmark. To further illustrate the challenge, consider the dataflow graph in Fig. 2(b), which is a subgraph of a common taint analysis for Android (Huang et al., 2015). From an overapproximation standpoint, consider the potential reachability from e to j. Notice that there are valid context-sensitive paths and valid field-sensitive paths e\rightsquigarrow j; these are, respectively e\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}[_{1}}}g\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}i\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{100}}}j\qquad\text{and}\qquad e\xrightarrow{{\color[rgb]{0.24,0.24,0.24}% \definecolor[named]{pgfstrokecolor}{rgb}{0.24,0.24,0.24}% \pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{1}}}g% \xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% (_{100}}}h\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}f\xrightarrow{{\color[rgb]{0.24,0.24,0.24}% \definecolor[named]{pgfstrokecolor}{rgb}{0.24,0.24,0.24}% \pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{1}}}e% \xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}[_{1}}}g\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}i\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{100}}}j Because of the presence of both paths, an overapproximation algorithm may fail to conclude that e does not reach j through a path that is simultaneously context and field-sensitive. In fact, even newer overapproximation methods such as (Ding and Zhang, 2023) indeed report that e reaches j, thereby producing a false positive. From an underapproximation standpoint, consider the reachability from e to k, witnessed by the path e\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}[_{1}}}g\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% (_{100}}}h\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}f\xrightarrow{{\color[rgb]{0.24,0.24,0.24}% \definecolor[named]{pgfstrokecolor}{rgb}{0.24,0.24,0.24}% \pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.24}[_{1}}}e% \xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{pgfstrokecolor}{% rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}\pgfsys@color@gray@fill{0.2% 4}[_{1}}}g\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}i\xrightarrow{{\color[rgb]{% 0.2549019607843137,0.2117647058823529,0.9823529411764706}\definecolor[named]{% pgfstrokecolor}{rgb}{0.2549019607843137,0.2117647058823529,0.9823529411764706}% )_{100}}}j\xrightarrow{{\color[rgb]{0.24,0.24,0.24}\definecolor[named]{% pgfstrokecolor}{rgb}{0.24,0.24,0.24}\pgfsys@color@gray@stroke{0.24}% \pgfsys@color@gray@fill{0.24}]_{1}}}k Observe that the path is non-simple, as we have to traverse the cycle once to obtain a valid string. Moreover, the string interleaves parentheses with brackets, which means that it cannot be captured in a single Dyck language involving both parentheses and brackets. In this work we demonstrate that MCFLs are an effective and tractable context-sensitive language formalism for underapproximating interleaved Dyck reachability that yields good approximations for real-world benchmarks. 1.2. Summary of Results To benefit readability, we summarize here the main results of the paper, referring to the following sections for details. We relegate all proofs to the Appendix. 1. MCFL reachability as a program model. We introduce MCFL reachability as an expressive, yet tractable, context-sensitive formalism for static analyses. Parameterized by the dimension d and rank r, d\text{-}\operatorname{MCFL}(r) yields an infinite hierarchy of progressively more expressive models that become Turing-complete in the limit. We illustrate the usefulness of MCFL reachability by using it to under-approximate the (generally, undecidable) problem of interleaved Dyck reachability, which is the standard formulation of a plethora of static analyses. In particular, for each d\geq 1, we obtain a d\text{-}\operatorname{MCFL}(2) that achieves increased precision as d increases (i.e., it discovers more reachable pairs of nodes), and becomes complete (i.e., it discovers all reachable pairs) in the limit of d\to\infty. Our MCFL formulation is, to our knowledge, the first non-trivial method that approximates the reachability set from below, thus having no false positives. Although underapproximations are less common in static analyses, they have many uses, such as excluding false positives (Psalm, 2024; Hicken, 2023), reporting concrete witnesses, acting as a tool for bug-finding (Le et al., 2022; Bessey et al., 2010) and performing “must” analyses (Godefroid et al., 2010; Xu et al., 2009; Smaragdakis and Balatsouras, 2015). Our underapproximation, when paired with existing overapproximate methods, allows limiting the set of potentially false negatives dramatically, and even find a fully-precise answer (as often is the case in our experiments). 2. MCFL reachability algorithm. We develop a generic algorithm for solving d\text{-}\operatorname{MCFL}(r) reachability, for any value of d and r. Our algorithm generalizes the existing algorithms for CFL reachability (Yannakakis, 1990) and TAL reachability (Tang et al., 2017). In particular, we establish the following theorem. {restatable} theoremthmupperbound All-pairs d\text{-}\operatorname{MCFL}(r)-reachability given a grammar \mathcal{G} on a graph G of n nodes can be solved in (1) O(\operatorname{poly}(|\mathcal{G}|)\cdot\delta\cdot n^{2d}) time, if r=1, where \delta is the maximum degree of G, and (2) O(\operatorname{poly}(|\mathcal{G}|)\cdot n^{d(r+1)}) time, if r>1. As CFLs and TALs are 1\text{-}\operatorname{MCFL}(2) and 2\text{-}\operatorname{MCFL}(2), respectively, Section 1.2 recovers the known bounds of O(n^{3}) and O(n^{6}) for the corresponding reachability problems. We also remark that the simpler problem of d\text{-}\operatorname{MCFL}(r) membership is solved in time O(n^{d(r+1)}) time on strings of length n (Seki et al., 1991). Section 1.2 states that reachability is no harder than membership, as long as the current bounds hold, for bounded-degree graphs (\delta=O(1)) or when r>1. 3. MCFL membership and reachability lower bounds. Observe that the bounds in Section 1.2 grow exponentially on the dimension d and rank r of the language. The next natural question is whether this dependency is tight, or it can be improved further. Given the role of MCFL reachability as an abstraction mechanism, this question is also practically relevant. For example, consider a scenario where a 3-dimensional MCFL is used in a static analysis setting, but the analysis is too heavy for the task at hand. The designer faces a dilemma: “should we attempt to improve the analysis algorithm, or should we find a simpler model, e.g., based on a 2-dimensional MCFL?”. A proven lower bound resolves this dilemma in favor of receding to 2 dimensions222Of course, one should also look for heuristics that offer practical speedups. We touch on this in Section 8.. We prove two such lower bounds based on arguments from fine-grained complexity theory. First, we study the dependency of the exponent on the dimension d. For this, we fix r=1 and arbitrary d, for which the membership problem, as well as the reachability problem on bounded-degree graphs, takes O(n^{2d}) time. We establish a lower-bound of n^{2d} based on the Strong Exponential Time Hypothesis (SETH). {restatable} theoremthmovhard For any integer d and any fixed \epsilon>0, the d\text{-}\operatorname{MCFL}(1) membership problem on strings of length n has no algorithm in time O(n^{2d-\epsilon}), under SETH. Section 1.2 is based on a fine-grained reduction from Orthogonal Vectors. The k-Orthogonal Vectors (OV) problem asks, given a set of m\cdot k Boolean vectors, to identify k vectors that are orthogonal. The corresponding hypothesis k-OVH states that this problem cannot be solved in O(m^{k-\epsilon}) time, for any fixed \epsilon>0 (it is also known that SETH implies k-OVH (Williams, 2005)). Section 1.2 is obtained by proving that a d\text{-}\operatorname{MCFL}(1) can express the orthogonality of 2d vectors. This implies that the dependency 2d in the exponent of Section 1.2 cannot be improved, while for r=1 our reachability algorithm is optimal on sparse graphs. Second, note that, on dense graphs (i.e., when \delta=\Theta(n)), the bound in Section 1.2 Item 1 is a factor n worse than the lower bound of Section 1.2. Are further improvements possible in this case? To address this question, we focus on the case of d=1, for which this upper bound becomes O(n^{3}). We show that the problem has no subcubic combinatorial algorithm based on the combinatorial Boolean Matrix Multiplication Hypothesis (BMMH). {restatable} theoremthmtrianglehard For any fixed \epsilon>0, the single-pair 1\text{-}\operatorname{MCFL}(1)-reachability problem on graphs of n nodes has no algorithm in time O(n^{3-\epsilon}) under BMMH. Hence, the \delta factor increase in the complexity cannot be improved in general, while Section 1.2 is tight for d=1 and r=1, among combinatorial algorithms. 4. Implementation and experimental evaluation. We implement our algorithm for MCFL reachability and run it with our family of d\text{-}\operatorname{MCFL}(2)s on standard benchmarks of interleaved Dyck reachability that capture taint analysis for Android (Huang et al., 2015). To get an indication of coverage, we compare our underapproximations with recent overapproximations. Remarkably, our underapproximation matches the overapproximation on most benchmarks, meaning that we have fully sound and complete results. For the remaining benchmarks, our underapproximation is able to confirm (94.3\%) of the taint information reported by the overapproximation. To our knowledge, this is the first report of such high, provable coverage for this challenging benchmark set."
